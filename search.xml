<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>C 集锦</title>
    <url>/2013/02/02/00-c-all/</url>
    <content><![CDATA[C 集锦汇总并总结一下关于C的命令集

 C语言 recv/recvfrom/recvmsg系统调用
 C语言 简化struct的使用
 C语言 最适合学习C语言的开发环境
 C语言 逻辑运算符
 C语言 按位运算符
 c语言 file如何判断文件是否存在
 C语言 源码、反码和补码
 C语言 存储相同类型的数组
 C 集锦
 Linux GNUplot
 C语言 for循环语句
 C语言 关于break和continue
 C语言 自定义函数
 C语言 指针初探
 C语言 gcc对文件扩展名的解释
 迷你计算器 bc
 C语言 常量
 C  递归和迭代
 C语言 基于Doxygen的C/C++注释原则
 C语言 作用域
 C语言 历史
 C语言 访问struct的方式
 C语言 标准函数库
 C语言 函数
 c语言 Linux下的off_t类型
 MAC 集锦
 C语言 存储类型关键字auto/register和static
 C语言编程开发步骤
 C语言 memcpy和strcpy比较
 C语言 macro函数宏
 C语言 文本文件读写
 c语言 使用FILE指针文件操作
 C语言 memory释放内存
 C语言 测试等值运算符
 C语言 解决存储的共用体
 C语言 赏心悦目的输出
 C语言 “Hello”和 ‘H’,’e’,’l’,’l’,’o’的区别
 C语言 atan函数与atan2函数的一点区别
 C语言 if语句
 C语言 extern用法解析
 C语言 sizeof和strlen的区别
 Linux GNUplot
 C语言 动态内存分配
 C语言 segment fault
 C语言 pseudocode 伪码
 C语言 Makefile
 更改linux的MAC地址
 C语言 函数指针
 C语言 assert的使用
 C语言 唯一的三元操作符
 C语言 字符与数字的转换工作
 C语言 read/write系统调用
 C语言 怎样从函数返回多个值
 C语言 存储类型关键字extern
 C语言 鲜为人知的“三字母词”
 C语言 Hello World
 C语言 left value左值
 C语言 枚举类型
 C语言 switch分支选择语句
 C语言 赏心悦目的输出
 C语言 GUI开发图形界面
 C语言 语句
 Linux rsync
 电磁波传播基础
 Linux 语义化版本
 Linux的 wc 命令
 C语言 共用体的成员访问
 C语言 abort函数
 C语言 函数调用三种方式–传值调用–引用调用和传地址调用
 C语言 使用struct描述一个学生
 C语言 main函数
 C语言 库函数和系统调用的区别
 C 语言入门汇总
 C语言 程序编译
 反向显示之 tac
 C语言 关键字
 C语言 static的作用
 C语言 assert的使用
 C语言 输入和输出续
 C语言 优美的C语言命名方法
 C语言 操作符和表达式
 C语言 const
 使用gnuplot来理解数据
 C语言 time函数学习
 CentOS 安装C++17
 C语言 value
 Linux GNUplot
 C语言 符号常量
 C语言 历史
 C语言的各种标准
 c语言 file如何判断文件是否存在
 C语言 空指针
 C语言 调试-linux程序设计
 C语言 字符串、字符和字节
 C语言 argc和argv
 C语言 输入和输出
 C语言 终端输入scanf函数
 C语言 struct的位域
 C语言 数据运算符
 C语言 加减乘除运算符
 C语言 选择哪种循环语句
 C 集锦 一分钟看完C运算符
 C语言 i++和++i
 C语言 基本输入和输出操作
 C语言 字符与字符串处理
 C语言 赋值运算符
 C语言 typedef
 C语言 最适合学习C语言的编辑器
 Linux Debian 时区设定
 C语言 while循环语句
 c语言 漫谈C语言及如何学习C语言
 C语言 struct结构体
 C语言 malloc的使用
 C语言 清洗一个流
 C语言 实参和形参
 C语言 main函数

]]></content>
      <categories>
        <category>集锦</category>
      </categories>
      <tags>
        <tag>集锦</tag>
      </tags>
  </entry>
  <entry>
    <title>BOOK 集锦</title>
    <url>/2013/02/02/00-book-all/</url>
    <content><![CDATA[BOOK 集锦汇总并总结一下关于BOOK的命令集

 BOOK 集锦
 如何阅读一本书? – 范多伦,艾德勒
 Python 参考书
 幸福了吗？
 黑洞里面有什么
 清晨8问夜晚8思８大自我提醒８大生活信念
 用小刀划开
 Vim书签命令的快速总结
 Gitbook
 二十几岁比别人幸运，就靠这9个好习惯
 Python JupternNotebook
 超级时间整理术
 每天最终好的3件事
 不做乔布斯，做最好的自己
 小行星会撞地球吗
 超级时间整理术
 其他星球上有生命吗
 改变世界是一种信仰：乔布斯和他的苹果神话
 循序渐进学Docker
 不做乔布斯，做最好的自己
 吃掉那只青蛙
 跑步，该怎么跑
 不做乔布斯，做最好的自己

]]></content>
      <categories>
        <category>集锦</category>
      </categories>
      <tags>
        <tag>集锦</tag>
      </tags>
  </entry>
  <entry>
    <title>CPP 集锦</title>
    <url>/2013/02/02/00-cpp-all/</url>
    <content><![CDATA[CPP 集锦汇总并总结一下关于CPP的命令集

 C++语言 入门汇总
 C++语言 入门汇总
 C语言 基于Doxygen的C/C++注释原则
 C++语言 简介
 Cpp extern用法解析
 C++语言 入门汇总
 C++关键字
 第一个简单的C++程序
 C++语言 学习参考材料
 C++语言 简介
 编译运行第一个C++程序
 C++中const常量和define宏定义的区别联系
[ C++语言 入门汇总](http://shaoguangleo.github.io/2015/02/22/cpp-io - 副本)
 C++语言 网上流传的最好的10个用于开发C/C++的IDE环境。
 CPP 集锦


]]></content>
      <categories>
        <category>集锦</category>
      </categories>
      <tags>
        <tag>集锦</tag>
      </tags>
  </entry>
  <entry>
    <title>GIT 集锦</title>
    <url>/2013/02/02/00-git-all/</url>
    <content><![CDATA[GIT 集锦汇总并总结一下关于GIT的命令集

 GIT 集锦
 聊聊版本
 Git 新功能Actions
 Git 分支
 git 初始配置
 git contribution policy
 Git 的 fetch与pull
 Git关于文件权限修改引起的冲突及忽略文件权限的办法
 核弹级的git指令 git filter-branch
 Git gitlab服务器迁移
 Git 好习惯
 Git Generating a new GPG key and use it with GitHub
 git Markdown 格式
 服务器上的Git
 Git Pro学习手册
 Git linux服务器git pull/push时不输入密码
 git push用法
 Git 参考材料
 Git rm删除文件
 Git 使用git将本地文件上传至github
 Git 向Github增加SSH keys
 Git 向Github增加SSH keys
 Git svn项目转移到git
 Git标签tag相关操作
 github上更新fork的代码
 git修改远程仓库地址
 Gitbook
 什么是github
 CentOS7安装gitlab-ce
 CentOS7升级gitlab-ce

]]></content>
      <categories>
        <category>集锦</category>
      </categories>
      <tags>
        <tag>集锦</tag>
      </tags>
  </entry>
  <entry>
    <title>LINUX 集锦</title>
    <url>/2013/02/02/00-linux-all/</url>
    <content><![CDATA[LINUX 集锦汇总并总结一下关于LINUX的命令集

 Linux No such device eth0
 汇报磁盘空间的df
 好看的字体
 时间日期 集锦
 Linux的stat命令
 远程登录不需要密码
 Linux GNUplot
 放开了去的 ulimit 命令
 显示管理磁盘分区 fdisk
 Linux的 rmdir 命令
 Linux换行符和Windows换行符的区别与转换
 Linux的source命令
 Linux PS1参数
 你是唯一的 uniq
 Linux xfs文件系统
 CentOS安装IDLE
 CentOS安装IDLE
 Linux 的 whatis 命令
 Linux package-cleanup的使用
 Linux package-cleanup的使用
 Linux useradd

 Linux的 tee 命令
 Linux的 whoami命令
 groupadd 集锦
 任务管理器的 top
 software 集锦
 Linux GNUplot
 Linux的tcpdump命令
 远程登陆利器 ssh
 Linux GNUplot
 linux之figlet命令
 文档查看 集锦
 Linux Automake 7 目录
 可看黄道吉日的 cal
 mkdir 集锦
 CentOS7升级gitlab-ce
 CentOS7升级gitlab-ce
 探索网络信息的利器 whois
 Linux GNUplot
 Linux的 wall 命令
 Linux之修改文件属性 —— chattr和lsattr命令
 时光总是催人老 time
 任务管理器的 top
 Linux的 rm 命令
 Linux的 top 命令
 Linux的su命令
 Linux du命令
 linux中最常用的文件传输命令
 CentOS7安装gitlab-ce
 CentOS7安装gitlab-ce
 Linux awk 命令
 linux之screenfetch命令
 Linux OpenGL
 Linux之修改文件属性 —— chattr和lsattr命令
 安全起见，拷贝为先 - cp
 Linux的 grep 命令
 LINUX 集锦
 Linux的tracepath命令
 不明所以的core文件，就这样出现了
 Linux的 ls 命令
 Linux的 cp 命令
 稍显底层的红帽系软件管理工具 - rpm
 Linux的hostnamectl
 System BootOrder not found. Initializing defaults
 System BootOrder not found. Initializing defaults
 Linux的hostname
 Linux reboot/poweroff/halt 命令
 用户信息 集锦
 Linux Debian sources.list
 Linux的 HPC
 迷你计算器 bc
 Linux查看内存信息（型号、大小、速率等）
 显示进程状态 ps
 Linux 安装 man 帮助程序
 touch 集锦
 一日难再晨及时当勉励 date
 Linux VirutalBox
 Linux sed命令
 Linux的 cal 命令
 Linux shell系统时间
 ssh 集锦
 anjuta的安装、配置以及第一个hello程序
 kill 集锦
 CentOS 上源码升级安装xfs软件包
 Linux最常用的几个软件包管理命令
 Linux 入门的100+个命令 终于阶段性完结
 Linux的 ulimit 命令
 Linux的 cat 命令
 Linux 的 tar 命令
 OpenCL
 Linux wait函数进程进程
 linux中最常用的文件操作命令
 Linux的语言设置
 Linux 之 man 命令
 Linux unzip
 Linux tmux终端复用神器
 Linux shutdown 命令
 没有规矩不成方圆 sort
 谁？ who
 Linux Fedora 升级
 你或他是否可读写  chmod
 Linux du命令
 Linux的 htop 命令
 Centos问题集锦
 Centos问题集锦
 Linux Automake 6  解析configure.ac
 linux之cowsay命令
 Linux的sudo命令
 Linux的 pgrep/pkill 命令
 linux 设置文件所有者命令 chmod
 Linux Redhat配置网络
 Linux Redhat配置网络
 深入研究Linux内核
 Linux的快捷方式的创建ln
 Linux的快捷方式的创建ln
 Linux的 lspci 命令
 ubuntu10.04后不支持gtk-config
 Linux的 who 命令
 more 集锦
 Linux的 mv 命令
 Linux xargs 命令
 归档压缩命令 集锦
 放空一下自我  free
 Linux查看物理CPU个数、核数、逻辑CPU个数
 Linux 的 which 命令
 CentOS 如何安装hexo
 CentOS 如何安装hexo
 Linux之修改文件属性 —— chattr和lsattr命令
 Linux最常用的硬件相关的命令
 Linux passwd
 Linux 炫技收集
 Linux最有趣的几个命令
 Linux的 uniq 命令
 Centos 如何安装Django环境
 Centos 如何安装Django环境
 Linux gnuplot的第一幅绘图
 少就是多的 less
 Linux debug 停下来环顾程序
 Environment Modules
 Linux 集锦 之 最常用的几个命令
 网络中不中，先看ping行不行
 Windows下使用Ubuntu
 列出系统硬件信息的lshw
 Linux的 whoami命令
 linux设置特定的用户组
 Linux的 tty
 系统管理 集锦
 Linux gunzip
 CentOS 7 安装配置Docker
 CentOS 7 安装配置Docker
 Linux之修改文件属性 —— chattr和lsattr命令
 使用Linux环境变量
 apropos 集锦
 Linux dos2unix命令
 你是干什么的 whatis
[ Linux - Resource temporarily unavailable](http://shaoguangleo.github.io/2022/06/11/linux-Resource temporarily unavailable)
 Linux的 lscpu 命令
[ undefined reference to GTK_TEXT](http://shaoguangleo.github.io/2011/12/27/linux-gtk-text copy)
 Linux Automake 15 Support for test suites
 Linux 之 ifconfig 命令
 whatis 集锦
 Linux 权限设置
 ping 集锦
 Linux shell 编写规范化、标准化
 Linux GNUplot
 解压方法之一 zip
 Linux 入门命令汇总
 Linux的sysctl命令
 Linux 的 more 命令
 Linux Automake 8 编译程序和库
 Linux 集锦
 存同求异 join
 Linux的 socket.gaierror
 Linux 之 zip 命令 压缩文件
 VirtualBox虚拟机Linux忘记密码
 更改linux的MAC地址
 Linux slurm 作业提交系统
 执行以特定字开头的历史命令
 真假转换之间 tr
 usermod 集锦
 显示CPU架构的有关信息lscpu
 删除Linux多余的内核
 炫技 集锦
 Linux uname
 Linux 十大发行版
 Linux的 write命令
 文件操作 集锦
 Linux的 chmod 命令
 linux技巧
 Linux Automake 3 General ideas
 Linux base64命令
 Linux的 pkill 命令
 Linux CentOS下查看. 更新. 删除yum安装包
 Linux CentOS下查看. 更新. 删除yum安装包
 Linux的 socket 相关
 Linux CentOS的版本
 Linux CentOS的版本
 非交互的下载工具 wget
 Linux的 od 命令
 Linux userdel

 Linux nohup 命令
 Windows 7开启NFS共享
 Linux history命令

 网络配置的大拿 ip
 文件内容搜索利器 - grep
 Linux的 mkdir 命令
 System-Management-Commands 集锦
 linux中最常用的文件管理命令
 解压方法之一 tar
 Linux的 tree 命令
 换一种环境 的 env
 Linux Shell遍历文件夹所有文件
 Linux的 lsblk 命令
 Linux rsync
 pkg-config 自动解决依赖
 危险命令 集锦
 红帽系的软件管理利器 - yum
 Linux下碰到的一些问题
 pwd 集锦
 Linux apropos命令
 Linux的 bc 命令
 不可狗尾续貂的tail
 Linux tail 命令
 Linux df命令
 关于NTP及ntpdate
 Linux XTerm的使用
 Linux的 mailx 命令
 Linux rsync
 Linux的 /usr/bin/ld  cannot find -lxxx 的解决办法
 念念不忘，必有回响 的 echo
 Linux的 wc 命令
 CentOS下安装微软雅黑字体
 CentOS下安装微软雅黑字体
 Linux 语义化版本
 Glib数据类型
 Linux Shell遍历文件夹所有文件
 Linux的 wc 命令
 Linux fdisk
 一去不复还的rm 命令
 Linux的hostname
 Linux VirutalBox 无法打开终端肿么办
 CentOS 集锦
 Linux GNUplot
 通过其他文件修改模式
 Linux GNUplot
 Linux nice 命令
 数据处理 集锦
 Linux 我知道的一些文件系统
 bash内建指令 集锦
 Linux的 w 命令
 Linux find命令print0和xargs命令-0
 Linux的 time 命令
 Linux 自动化编译autotools的使用
 什么？谁？w (who &amp; what)
 Linux中的共享内存及其配置
 清空历史，忘掉从前 - clear
 有所依靠的chgrp
 Linux的 tee 命令
 Linux uname
 undefined reference to GTK_TEXT
 Linux 的 scp 命令
 Linux usermod
 Linux Automake 27 Frequently Asked Questions about Automake
 查看网络信息的原初 ifconfig
 Linux的 ping 命令
 Linux xargs 命令
 Linux shell变量
 Linux GNUplot
 Linux 命令行快捷键
 我是谁 whoami
 Linux wget 命令
 Linux 的 scp 命令
 极具归属感的 - chown
 休息一会 sleep
 Linux userdel
 网络命令 集锦
 Linux的 pstree 命令
 探索网络连接的netstat
 sed 入门
 Linux gnuplot安装与启动
 Linux halt 命令
 目录导航 集锦
 极易被人忽略却又如此重要的readline
 反向显示之 tac
 超凡脱俗的 sudo
 解压命令之一 gzip
 Linux cd命令
 linux中最常用的帮助命令
 Linux 之 killall 命令
 不要告诉别人的passwd
 磁盘管理 集锦
 Linux shell系统时间
 Linux 进程和线程
 Linux的 mysql数据库安装和配置
 解压命令之一 unzip
 Linux echo命令
 远看高低各不同 diff
 软件管理利器  - Debian系的apt
 通配符 - 命令行的倚天剑、屠龙刀
 shutdown 集锦
 Linux集锦大全
 Linux 的 history 命令
 Fedora17初始配置
 在文件开头插入一行或一段文本
 Ubuntu11.10初始配置
 Ubuntu11.10初始配置
 Linux Automake 2 Autotools 简介
 Linux数据处理的几个命令
 Linux CentOS修改MAC地址
 lsblk 集锦
 使用gnuplot来理解数据
 精准终止 之 kill
 Ubuntu busybox 无法启动问题
 Ubuntu busybox 无法启动问题
 Linux GNUplot
 Linux的 pgrep/pkill 命令
 disk-space 集锦
 Linux 的 find 命令
 write 集锦
 linux中最常用的搜索命令
 chmod 集锦
 Linux shell中的for循环用法详解
 CentOS xfs 疑难解决
 别有一番风趣的alias
 Linux 调试预备知识
 CentOS 安装C++17
 man 集锦
 Linux centos自动挂载ntfs
 Linux centos自动挂载ntfs
 cat 集锦
 Linux的 lshw 命令
 Linux RPM 软件包
 焕然一新的 su
 此man非man的意思
 Linux的 lspci 命令
 Linux的 info 命令
 Linux ssh命令
 tree 集锦
 Linux mount挂载nfs
 刚刚好合适的 apropos 命令
 solved - RPMDB altered outside of yum
 solved - RPMDB altered outside of yum
 Linux 进程信号
 LINUX 入门集锦
 从头开始的head
 Linux的 rmdir 命令
 Linux 的 history 命令
 Linux GNUplot
 硬件信息 集锦
 Linux useradd
 How to Remove Duplicate Packages in CentOS/RHEL
 Ubuntu 安装Intel IPP
 Ubuntu 安装Intel IPP
 Linux 的 tty 是个什么东西？
 Linux 启动命令如何不输入./
 alias 集锦
 Linux debug 程序崩溃处理
 Linux的静态库和动态库
 linux中最常用的用户信息命令
 管理员 集锦
 Linux 編輯器
 Linux的 less 命令
 who 集锦
 Linux最常用的几个时间日期命令
 DiFX Ubuntu 安装包依赖
 一切皆可查的 find
 Linux命令lolcat
 Linux下清理缓存，以释放内存
 Linux VNCViewer远程桌面按d后最小化桌面
 Linux 查看网络流量
 Linux Drop Caches
 Linux 的 which 命令
 帮助命令 集锦
 Linux 调试编译其他工具
 Linux ARG_MAX, maximum length of arguments for a new process
 低调但大胆的 - dd 命令
 CentOS 7 安装配置Docker-CE
 CentOS 7 安装配置Docker-CE
 我也是有身份…证的人 之 id
 Ubuntu 安装GTK
 Ubuntu 安装GTK
 指定目录的定位 whereis
 linux中最常用的目录导航命令
 Linux nice 命令
 CentOS 安装 DiFX
 Linux gnuplot的坐标取值范围及刻度
 Linux的几种可选shell
 Linux 之 ping 命令
 使用iperf测试网络性能
 GTK 创建最简单的一个创建窗口的示例
 探索未知世界的cd
 Linux 之 ps 命令
 Linux GNUplot
 Linux aio异步读写
 还有谁 last
 CentOS 6 安装配置VNC
 CentOS 6 安装配置VNC
 低调但大胆的 - dd 命令
 Linux的 wall 命令
 Linux 解决lnurses库问题之/usr/bin/ld
 Linux的 loop循环
 Linux 的 find 命令
 Linux的 tr 命令
 CentOS 安装 docker
 Linux arp命令
 Linux diff命令
 锁定Linux文件夹
 Linux 之 ip 命令
 Cleaning up duplicate packages when yum has failed
 Linux的 crontab 命令
 Linux 调试预备知识
 终端技巧
 Linux下 修正GDBus 错误
 Linux poweroff 命令
 shell 集锦
 Linux最常用的几个归档和压缩命令
 查看块设备的lsblk
 dangerous 集锦
 Linux的stat命令
 unzip 集锦
 locate  - 精准快速定位
 Linux学习之道
 GLib 编译应用程序
 Windows下使用Ubuntu
 Linux的 last 命令
 Linux GNUplot
 Linux的touch命令
 每个人都应该知道的100+个命令
 精准快速定位的locate
 显示硬件信息的hwinfo
 Linux最危险的几个命令
 查看目录命令pwd
 Linux的 head 命令
 Linux Automake 1 简介
 IBM 收购 Redhat &amp;&amp; 咏远有李
 Ubuntu 问题集锦
 du 集锦
 Linux NFS 配置
 如何在CentOS上安装VLC
 如何在CentOS上安装VLC
 Linux的touch命令
  Linux 3.11已经发布了
 Linux的 RAID 冗余磁盘阵列
 Linux命令cmatrix
 Linux Automake 5  创建Makefile.in
 终端链接 tty
 CentOS 添加 EPEL 源
 CentOS 添加 EPEL 源
 checking LD_LIBRARY_PATH variable… contains current directory
 树状结构的tree
 split - 精准快速定位
 linux 命令 pwd 查看目录命令
 Linux的tracepath命令
 Linux的几种可选shell
 linux grafana使用教程
 Linux的file命令
 Linux的 mv 命令
 Linux的file命令
 数据传输 集锦
 Linux的 mkdir 命令
 Linux Out of Memory
 查看庐山真面貌的cat
 Linux 之 kill 命令
 Linux的traceroute命令
 文件管理 集锦
 Linux Automake 4  一些示例包
 Linux GNUplot
 CentOS 安装配置zabbix库
 Linux 终端中漂亮的几款字体
 Redhat使用CentOS的源
 Redhat使用CentOS的源
 Installing Google Chrome on CentOS
 Linux sed命令
 Linux GNUplot
 Linux 入门命令汇总
 split - 精准快速定位
 Linux IDE
 Ubuntu 删除多余内核
 Ubuntu 删除多余内核
 Linux炫技 集锦
 sort 集锦
 Linux 入门命令汇总
 GNU 实用程序Shell
 Linux Debian 时区设定
 OpenCV
 Linux free命令
 linux中最常用的网络命令
 Linux gnuplot的数学表达式
 Linux的 uniq 命令
 Linux 之 skill 命令
 Linux CentOS7图形界面与命令行界面切换
 Linux CentOS7图形界面与命令行界面切换
 Linux的 write命令
 Linux Tracker-extract and Tracker-store processes consuming huge Amount of RAM
 Linux usermod
 Linux Fedora安装gnome-gtk开发环境
 ubuntu10.4的更新源因过期无法更新的解决方法
 最常用的且没有之一的  ls
 Linux 的 more 命令
 Linux命令fortune
 Linux gnuplot的坐标取值范围及刻度
 超多协议传输的 - curl
 YUM已死，DNF永生
 sudo 集锦
 Linux 强大的网络工具 ethtool

]]></content>
      <categories>
        <category>集锦</category>
      </categories>
      <tags>
        <tag>集锦</tag>
      </tags>
  </entry>
  <entry>
    <title>LINUX 入门集锦</title>
    <url>/2016/12/02/00-linux-beginner-all/</url>
    <content><![CDATA[LINUX 入门集锦汇总并总结一下关于LINUX的命令集

 汇报磁盘空间的df
 Linux的stat命令
 Linux的 ulimit 命令
 显示管理磁盘分区 fdisk
 Linux的source命令
 你是唯一的 uniq
 Linux useradd
 Linux的 tee 命令
 任务管理器的 top
 Linux的tcpdump命令
 远程登陆利器 ssh
 可看黄道吉日的 cal
 探索网络信息的利器 whois
 时光总是催人老 time
 任务管理器的 top
 安全起见，拷贝为先 - cp
 稍显底层的红帽系软件管理工具 - rpm
 Linux的hostname
 Linux reboot/poweroff/halt 命令
 迷你计算器 bc
 显示进程状态 ps
 一日难再晨及时当勉励 date
 Linux 入门的100+个命令 终于阶段性完结
 Linux shutdown 命令
 没有规矩不成方圆 sort
 谁？ who
 Linux的 chmod 命令
 Linux du命令
 Linux的快捷方式的创建ln
 Linux xargs 命令
 放空一下自我  free
 Linux 的 which 命令
 Linux的 less 命令
 网络中不中，先看ping行不行
 列出系统硬件信息的lshw
 Linux gunzip
 你是干什么的 whatis
 解压方法之一 zip
 Linux 的 more 命令
 存同求异 join
 真假转换之间 tr
 显示CPU架构的有关信息lscpu
 Linux uname
 Linux的 pkill 命令
 非交互的下载工具 wget
 Linux userdel

 网络配置的大拿 ip
 文件内容搜索利器 - grep
 Linux的 mkdir 命令
 解压方法之一 tar
 Linux的 env 命令
 红帽系的软件管理利器 - yum
 不可狗尾续貂的tail
 Linux rsync
 Linux echo命令
 Linux的 wc 命令
 Linux的 rm 命令
 Linux nice 命令
 什么？谁？w (who &amp; what)
 清空历史，忘掉从前 - clear
 有所依靠的chgrp
 Linux 的 scp 命令
 查看网络信息的原初 ifconfig
 我是谁 whoami
 极具归属感的 - chown
 休息一会 sleep
 Linux的 pstree 命令
 探索网络连接的netstat
 sed 入门
 Linux halt 命令
 反向显示之 tac
 超凡脱俗的 sudo
 解压命令之一 gzip
 Linux 之 killall 命令
 不要告诉别人的passwd
 解压命令之一
 远看高低各不同 diff
 软件管理利器  - Debian系的apt
 Linux 的 history 命令
 Linux 之 kill 命令
 Linux的 pgrep/pkill 命令
 别有一番风趣的alias
 Linux的su命令
 此man非man的意思
 Linux的 lspci 命令
 刚刚好合适的 apropos 命令
 从头开始的head
 Linux的 rmdir 命令
 一切皆可查的 find
 Linux的 whoami命令
 指定目录的定位 whereis
 探索未知世界的cd
 还有谁 last
 Linux dd命令
 Linux的 wall 命令
 Linux poweroff 命令
 查看块设备的lsblk
 Linux的touch命令
 精准快速定位的locate
 显示硬件信息的hwinfo
 查看目录命令pwd
 终端链接 tty
 树状结构的tree
 split - 精准快速定位
 Linux的tracepath命令
 Linux的file命令
 Linux的 mv 命令
 查看庐山真面貌的cat
 Linux的traceroute命令
 Linux 入门命令汇总
 致谢
 Linux 之 skill 命令
 Linux的 write命令
 Linux usermod
 最常用的且没有之一的  ls
 超多协议传输的 - curl

]]></content>
      <categories>
        <category>集锦</category>
      </categories>
      <tags>
        <tag>集锦</tag>
      </tags>
  </entry>
  <entry>
    <title>MAC 集锦</title>
    <url>/2013/02/02/00-mac-all/</url>
    <content><![CDATA[MAC 集锦汇总并总结一下关于MAC的命令集

 MAC 集锦
 MacOSX 上安装 Difmap
 在Mac OS X平台上运行Docker GUI程序
 更改linux的MAC地址
 Linux GNUplot
 Linux CentOS修改MAC地址
 Mac 平台上 13 款实用的代码编辑器推荐
 Mac不能复制拷贝写入文件到移动硬盘,U盘怎么办
 Mac 锁屏利器Nearlock
 Mac Mounting NFS shares on Mac OS X
 MacOSX 如何安装hexo
 MacOSX 上 安装及使用homebrew
 MacOS系统MacPort的按照与使用
 MacOSX dyld - Library not loaded /usr/local/gfortran/lib/libgfortran.3.dylib Reason image not found
 MacOSX svnadmin无法使用的问题
 MacOSX 集锦
 MacOSX的好工具
 MacOSX import的定义
 Mac OSX 安装Python3和pip3
 Vim 记录和使用宏

]]></content>
      <categories>
        <category>集锦</category>
      </categories>
      <tags>
        <tag>集锦</tag>
      </tags>
  </entry>
  <entry>
    <title>MATPLOTLIB 集锦</title>
    <url>/2013/02/02/00-matplotlib-all/</url>
    <content><![CDATA[MATPLOTLIB 集锦汇总并总结一下关于MATPLOTLIB的命令集

 Python开发者Matplotlib指南
 Python matplotlib scatter 的使用
 MATPLOTLIB 集锦
 python中文档SPHINX的使用

]]></content>
      <categories>
        <category>集锦</category>
      </categories>
      <tags>
        <tag>集锦</tag>
      </tags>
  </entry>
  <entry>
    <title>PGPLOT 集锦</title>
    <url>/2013/02/02/00-pgplot-all/</url>
    <content><![CDATA[PGPLOT 集锦汇总并总结一下关于PGPLOT的命令集

 PGPLOT 集锦
 PGPLOT手册
 关于PGPLOT的翻译
 PGPLOT简介
 PGPLOT安装
 PGPLOT手册简介安装
 PGPLOT图像设备
 PGPLOT环境变量
 PGPLOT的简单使用
 PGPLOT的简单使用简介
 PGPLOT 编译和运行
 PGPLOT的一个示例程序
 PGPLOT的数据初始化
 PGPLOT 开始使用
 PGPLOT 绘图比例和坐标轴
 PGPLOT 标记坐标轴
 PGPLOT 绘制图形标记
 PGPLOT 绘制线
 PGPLOT 结束绘图
 PGPLOT的窗口和视图
 PGPLOT的视图选择
 PGPLOT的视图选择
 PGPLOT的窗口特性
 PGPLOT的窗口特性
 PGPLOT 集大成函数PGENV
 PGPLOT的基元简介
 PGPLOT的基元剪裁
 PGPLOT的基元线条
 PGPLOT的基元图标记
 PGPLOT的基元文字
 PGPLOT的基元区域填充
 PGPLOT的属性简介
 PGPLOT的属性简介 获取属性
 PGPLOT的属性 保存与复原
 PGPLOT的属性简介 颜色索引
 PGPLOT的属性简介 颜色显示
 PGPLOT的属性简介 线条类型
 PGPLOT的属性简介 线条宽度
 PGPLOT的属性简介 字符高度
 PGPLOT的属性简介 字符字体
 PGPLOT的属性简介 文本背景
 PGPLOT的属性简介 填充区域类型
 PGPLOT的高级应用
 PGPLOT的高级应用 XY绘图
 PGPLOT的高级应用 直方图
 PGPLOT的高级应用 两个变量的函数
 PGPLOT图形交互 简介
 PGPLOT图形交互 光标
 PGPLOT图形交互 使用光标
 PGPLOT图形交互 缓冲
 PGPLOT 附录a - 子函数描述
 PGPLOT 附录 符号
 PGPLOT 附录 C语言调用PGPLOT
 PGPLOT 附录 支持的设备
 PGPLOT 附录 写入设备
 PGPLOT 附录 安装说明
 PGPLOT 附录 G 移植
 PGPLOT 附录
 PGPLOT 在C 中的使用
 PGPLOT cpgarro绘制箭头
 PGPLOT cpgask控制新页的提示
 PGPLOT cpgaxis绘制一个坐标轴
 PGPLOT cpgband读取有锚定点的光标位置
 PGPLOT cpgbbuf开始批处理输出
 PGPLOT cpgbeg 打开一个图形设备
 PGPLOT cpgbin – 数据的直方图
 PGPLOT cpgbox - 在视口周围的框架上标记标签
 PGPLOT cpgclos – 关闭选定的图形设备
 PGPLOT cpgconb 绘制等高线图
 PGPLOT cpgconb 绘制等高线图
 PGPLOT cpgenv 设置窗口、视口及标签框架
 PGPLOT cpgconb 绘制等高线图
 PGPLOT cpgiden – 在图形的底端标记上用户名、日期和时间
 PGPLOT cpglab
 PGPLOT cpglcur – 使用光标绘制线条
 PGPLOT cpgldev –在标准输出上列出可用的设备类型
 PGPLOT cpglen – 计算字符串的长度（不同单位）
 PGPLOT cpgline – 绘制一个多线段的线条
 PGPLOT cpgmove – 移动点(改变当前的点位置)
 PGPLOT cpgmtxt – 在视口相关位置做文本标记
 PGPLOT cpgopen – 打开一个图形设备
 PGPLOT cpgpage – 前进到新的页面
 PGPLOT cpgpanl – 切换到当前视图的不同面板
 PGPLOT cpgpap – 改变视图表面的大小
 PGPLOT cpgtext
 PGPLOT 非标准函数
 Ubuntu/Debain/Fedora/Mac/CentOS 安装PGPLOT

]]></content>
      <categories>
        <category>集锦</category>
      </categories>
      <tags>
        <tag>集锦</tag>
      </tags>
  </entry>
  <entry>
    <title>PYTHON 集锦</title>
    <url>/2013/02/02/00-python-all/</url>
    <content><![CDATA[PYTHON 集锦汇总并总结一下关于PYTHON的命令集

 PYTHON 集锦
 Python argparse
 Python 参考书
 Python class类
 Python 注释
 python 虚拟环境conda
 Python 的数据类型
 Python Django 教程1
 Python Django 教程2
 Python Django 教程3
 Python Django 教程4
 Python Django 教程5
 Python Django 教程6
 Python 如何提取python中的一列
 Python 的文件类型
 Python格式化字符串
 第一个Python程序
 Python 历史及由来
 Python IDE 之 终端开发环境IPython
 Python IDE 之开发利器PyCharm
 Python 条件判断语句
 Python init.py的作用
 Mac OSX 安装Python3和pip3
 Python 编程概述
 Python lambda表达式
 Python List列表
 python中文档SPHINX的使用
 Python开发者Matplotlib指南
 Python matplotlib scatter 的使用
 Python 导入模块
 Python 命名规则
 构建Python开源包
 Python os mkdir
 Python 包收集
 Python 发布可执行文件
 Python 编写一个自己的包
 Python 模块的搜索路径
 pip换源（更换软件镜像源）
 pip 使用
 Python property函数
 Python PyGtk 学习笔记
 python pyinstaller打包
 python PyQt 界面设计
 python 环境变量设置PYTHONPATH
 PyQt 教程
 PyQt 教程
 PyQt5 教程
 Python read() readline()以及readlines()用法
 Python学习
 python中文档SPHINX的使用
 python中文档SPHINX的使用
 python 字符串操作
 Python 什么是Tkinter

 Python Tkinter 你好
 Python Tkinter 你好2
 Python Tkinter Button窗口组件类
 Python Tkinter 的窗口组件类
 Python Tkinter 组件配置
 Python Tkinter 组件外观
 Python Tkinter 事件和绑定
 Python Tkinter 应用程序窗口
 Python Tkinter 标准对话框
 Python GUI编程(Tkinter)
 Python 工具集大全
 Python 常量和变量
 python3 内置虚拟环境venv
 python 虚拟环境virtualenv
 python 虚拟环境管理工具virtualenvwrapper
 python 虚拟环境virtualenv
 python 虚拟环境管理工具virtualenvwrapper
 Python 循环语句
 python-casacore  installation

]]></content>
      <categories>
        <category>集锦</category>
      </categories>
      <tags>
        <tag>集锦</tag>
      </tags>
  </entry>
  <entry>
    <title>QT 集锦</title>
    <url>/2013/02/02/00-qt-all/</url>
    <content><![CDATA[QT 集锦汇总并总结一下关于QT的命令集

 QT 集锦
 python PyQt 界面设计
 PyQt 教程
 PyQt 教程
 PyQt5 教程
 Qt中显示消息框
 Qt模态对话框
 qt新建一个动作并与菜单连接
 Qt右键弹出菜单
 Qt PyQt5 简介
 创建一个Qt Quick 应用
 QT读取写入二进制文件
 QT读取写入配置文件
 QT中设置窗口图标
 Qt信号和槽
 Qt如何编写程序启动界面
 Qt问题集锦
 QT中定时更新日期时间控件
 Qt窗口时候更改过

]]></content>
      <categories>
        <category>集锦</category>
      </categories>
      <tags>
        <tag>集锦</tag>
      </tags>
  </entry>
  <entry>
    <title>我们编程吧 集锦</title>
    <url>/2025/06/19/00-summary-all/</url>
    <content><![CDATA[我们编程吧 集锦BOOK目前共分享了** 59 ** 个技巧，详细参考: BOOK 集锦
C目前共分享了** 128 ** 个技巧，详细参考: C 集锦
CPP目前共分享了** 16 ** 个技巧，详细参考: CPP 集锦
GIT目前共分享了** 115 ** 个技巧，详细参考: GIT 集锦
LINUX目前共分享了** 528 ** 个技巧，详细参考: LINUX 集锦
MAC目前共分享了** 6 ** 个技巧，详细参考: MAC 集锦
PGPLOT目前共分享了** 86 ** 个技巧，详细参考: PGPLOT 集锦
PYTHON目前共分享了** 114 ** 个技巧，详细参考: PYTHON 集锦
MATPLOTLIB目前共分享了** 12 ** 个技巧，详细参考: MATPLOTLIB 集锦
QT目前共分享了** 34 ** 个技巧，详细参考: QT 集锦
VIM目前共分享了** 50 ** 个技巧，详细参考: VIM 集锦
后记目前共分享了** 1571  个技巧，平均每天  0.24 **个。持续更新中，欢迎来访。

]]></content>
      <categories>
        <category>集锦</category>
      </categories>
      <tags>
        <tag>集锦</tag>
      </tags>
  </entry>
  <entry>
    <title>VIM 集锦</title>
    <url>/2013/02/02/00-vim-all/</url>
    <content><![CDATA[VIM 集锦汇总并总结一下关于VIM的命令集

 vim .(点)命令的强大功能
 vim使用跳转列表来跟踪导航
 VIM快速选中并复制粘贴替换一个单词
 Vim 补全
 vim出错warning setlocale LC_CTYPE cannot change locale
 Vim 中文乱码
 Vim 编程工具
 vim 导航
 Vim 写文件的部分内容到另一个文件
 Vim swap文件
 gvim技巧
 Vim 退出
 Vim排序文件内容
 交换相邻的字符
 在插入模式下执行一个Vim命令
 Vim 使用vimdiff查看文件之间的不同
 Vim 打开文件
 Vim 为什么使用vim
 替换文本
 Vim书签命令的快速总结
 Vim gVim
 Vim 改变配置颜色
 在拷贝行/词/其它之后或之前粘贴
 VIM 重绘窗口
 Vim 保存文件
 vim中的删除操作大全
 vim 命令行技巧
 使用CTRL键来增加和减少数量
 vim的一些基础知识
 Vim高级导航
 Vim 入门联系
 Vim 配置文件
 vim寄存器、文件浏览器、大小写转换
 Vim命令行导航
 从Vim中访问Unix的函数帮助页
 Vim 帮助信息
 Vim 记录和使用宏
 在Vim 加密解密文件：
 从文件中插入内容到剪切板
 vim 移动操作
 Vim改变大小写
 vim搜索技巧
 VIM 集锦
 让Vim智能的高亮你的代码
 vim 额外小技巧
 vim 插入操作
 VIM 重复命令
 VIM 撤销和重做
 Vim 工作模式
 vim 插件

]]></content>
      <categories>
        <category>集锦</category>
      </categories>
      <tags>
        <tag>集锦</tag>
      </tags>
  </entry>
  <entry>
    <title>注释与提示Difmap</title>
    <url>/2017/11/22/astronomy-algorithm-1/</url>
    <content><![CDATA[注释与提示解释如何计算和编程的内容并不属于本书范围，读者可以自行查阅读有关书籍。然而能写出好的程序并非一日之功，这是一门需要循序渐进的艺术，只有通过实践锻炼才能写出既短又好的程序。
超出0～360°范围的角度的三角函数超出0～360°范围的角度经常出现在天文计算中，在例24.a中我们可以看到1992年10月13日太阳的平经度角是－2318.19281°。快速运动的天体，比如月球、木星的伽利略卫星或者行星的自转中甚至还会出现更大的角度（可以看例41.a中第9步中的角w的计算实例）。把角度转化到0～360°范围之内有时是很必要的，因为一些计算器或者程序设计语言对于大的角度的三角函数计算结果是不准确的。例如，你可以试试计算3600030°的正弦。正确结果应该为0.5。

译者注：事实上，对于现代计算机而言，上一行所述的问题基本不存在。不过，很多情况下，我们仍需把一个角度转换到0到360度。

角度的表示方法计算机不能直接计算出以度分秒方式表示的角度的三角函数。在使用三角函数之前，应该把角度转换成以度为单位的十进制小数形式。因此，在计算23°26′49″的余弦时要先把角度转化成为23.44694444°,然后再用余弦函数计算。遗憾的是，几乎所有的电脑都是用弧度而不是度来计算，所以还应把度转为弧度单位，通常是一件麻烦的事情。
赤经赤经通常用时、分、秒方式来表示。如果需要计算赤经的三角函数，需要把赤经转换成用度为单位来表示（然后再转换成以弧度为单位），请注意1h对应于15°。例1.a ——计算 $\alpha$ = 9h 14m 55 s8的tan$\alpha$。我们首先把$\alpha$转化成以时为单位的十进制小数：9h 14m 55 s8＝9＋14/60+55.8/3600=9.248833333时然后再乘以15。$\alpha$＝138.73250°然后在除以180/$\pi$得到以弧度为单位的57.295779513…。然后得出 tan$\alpha$=-0.877517
修正角所在的象限当已知一个角的正弦、余弦或正切值时，可以通过三角函数对应的反函数——如正弦对应的反正弦（arcsin），余弦对应的反余弦(arccos)，正切对应的反正切(arctan)来得出角的大小。但是请注意在一些计算机上和一些程序设计语言中，尤其是大部分早期的微型计算机中都没有提供反正弦和反余弦函数。反三角函数并不是单值函数，例如，如果sinα=0.5，那么$\alpha$可以是30°、150°、390°等等。基于这个原因，计算机中的反三角函数的取值范围只有0～360°的一半：反正弦和反正切的取值范围是在－90～＋90°，而反余弦的取值范围则是0～180°。例如，计算cos147°，结果是－0.8387，用反余弦函数计算－0.8387的结果正是147°，但是，cos213°的结果也是－0.8387，而我们用反余弦函数计算的结果则是147°。因此当使用反正弦、反余弦和反正切的时候，必要时需要通过一个或多个值来弄清楚它代表的角度，消除结果的不确定性。另外，每个问题都要单独检查。例如，公式（12.4）和（24.7）给出了天体赤纬的正弦。因为赤纬的取值范围在－90～＋90°，所以反正弦函数可以在正确的象限算出赤纬，因此这里就不必进行检验。公式（16.1）给出了角度差的余弦也是同样情况，实际上角度差的取值范围在0～180°，这正与反余弦函数的取值范围一致。但是请看从赤经（$\alpha$）赤纬（$\beta$）转换到黄经（$\beta$）黄纬（$\lambda$）的公式：$$cosβsinλ=sinδsinε+cosδcosεsin$\alpha$$$
$$cosβcosλ=cosδcos$\alpha$$$
令第一个方程为A，第二个方程为B，用A式除以B式，我们可以得到tanλ=A/B，则对A/B使用反正切函数可以求出角λ，该角的取值在－90～＋90°范围内，角度结果可能会相差±180°（由于正切函数的周期为180°）。确定角所在的正确象限可以通过如下测试：如果B&lt;0，求得的结果加上180°。不过一些程序设计语言(如C语言、javascript、VB)还提供了重要的第二个反正切函数ATAN2，这个函数有两个参数A和B，这个函数会求出正确的结果并转化到正确的象限。例如，设A=－0.45，B=-0.72，使用ATAN(A/B)=32°，而使用ATAN2(A,B)可以求得正确结果是－148°，或＋212°。
负的角度值的输入以度分秒方式表示的角度可以用三个独立的参数（D,M,S）输入。例如，21°44′07″可以用三个数字21，44，07输入，然后程序中使用H=D+M/60+S/3600转化成为以度为单位。我们还应该仔细考虑负的角度的情况，比如角度是－13°47′22″，代表的是－13°，－47′和－22″，这样的话D=－13，M=－47,S=－22。所以的参数都应该有同样的正负号。对－13°47′22″可能的错误理解是输入－13°，＋47′和＋22″，这样输入的结果实际上是－12°12′38″。
时间的幂一些数值需要通过含有时间的幂（如T，T2，T3，……）的公式来计算，应当注意的是这样的多项式只是在T的值不是太大的情况下才是合理的，比如公式：e=0.04629590－0.000027337T+0.0000000790T2    （1.1）给出了天王星的轨道偏心率；T是以自2000年起算的儒略世纪数（每世纪36525天），显然该式只有在公元2000年前后，比如T在＋30～－30范围内有效。如果|T|&gt;30，这个公式就不再有效，比如T= -3305.8，公式的结果将是e=1。一个认为“计算机从不犯错的”人可能会认为T= -3305.8时，天王星轨道是抛物线，进而认为天王星起源于太阳系之外—这显然是伪科学。实际上尽管行星轨道的偏心率e在超过了定义的时间上限后变化并不是有规律的，但是时间在很少的几个千年纪之内，偏心率是可以用像（1.1）那样的多项式精确表示的。进一步的观察我们可以发现公式中有周期项（公式中的正弦和余弦项，在几个世纪内变化很小）和长期项的不同（如公式中含有T，T2，T3，……的项，它随着时间的增加快速增大）。当T很小的时候，T2项会变得很小，但是当|T|值很大的时候这一项会变得非常重要。因此当|T|值比较大的时候考虑含有T2等项的周期项是没有意义的，在计算中也不用考虑。
避免幂计算假设我们计算这样一个多项式：Y=A+BX+CX2+DX3+EX4其中A，B，C，D，E是常数，X是变量。现在可以在计算机中一项项直接相加来求出每一个给定X的多项式的值。然而可以采用一些聪明的方法来避免计算X的幂，比如：Y=A+X(B+X(C+X(D+EX)))在这个式子中幂计算都消失了，采用了乘积来替代幂的计算。这种多项式的表示方法被称为Horner方法，这种方法因为避免了幂计算，所以特别适合自动计算。不用幂计算，而采用计算A*A的方法来计算A的平方也是一个聪明的办法，我们使用这样一段程序在HP-85计算机上计算前200个正整数的平方：
FOR I=1 TO 200  K=I^2NEXT I完成计算需要费时10.75秒。但是，当我们把第二行换成K=I*I的话，完成整个计算只需费时0.96秒！
缩短一个程序把程序写尽可能短小通常不仅是代表着艺术，而且在计算机内存受限情况下也是必须的。即使对于简单的计算，也存在一些把程序缩短的技巧。假设我们要计算下面多项相加的和S：
S=0.0003233sin(2.6782+15.54204T)+0.0000984sin(2.6351+79.62980T)+0.0000721sin(1.5905+77.55226T)+0.0000198sin(3.2588+21.32993T)+……

首先因为正弦的系数都是很小的数，可以通过采用以一个常数作为计数单位（在这个例子中是10－7）来避免输入那么多的数字，比如我们用3233来代替0.0003233。因此在计算了所有项之后，我们再把和除以10－7。其次，在程序中声明全部数值项也是不明智的。相反，我们应该采用所谓的循环来完成计算。上面A*sin(B＋CT)的每一项的A，B，C值应作为程序的数据部分。假如有50项，程序可以这样写：
Double s=0Double data[50*3]={3233,2.6782,15.54204,……}; //每3个一组int i,p;for(i=0;i&lt;50;i++){  p = i*3;  s += data[p]*sin( data[p+1]+data[p+2]*T );}s/=1e-7;


译者注：如果数据量较大，应考虑将数据与程序合理的分离；数据可以放在程序中的“数组”之中，如果数据量多达几万行或更多，多数情况下我们会考虑放在外部文件之中。

安全性测试在可能出现“不可能”出现的情况下，需要进行安全性测试。例如，在迭代到特定数量之后计算停止却没有达到要求的精度。或者考虑月掩星的情况，在程序中根据当地的环境来计算被掩恒星消失和再次出现的时间。然而，可能在给定的地点根本看不到这颗恒星被掩。在这种情况下，初切时间和终切时间根本就不存在，试着计算这两个时间会碰到计算一个负数的平方根的情况。为了避免出现这个问题，程序应该首先计算这颗恒星到月面中心的最短距离（从给定的地点观看），而且当且仅当这个距离小于月面半径的情况下才计算初切和终切时间。
调试在程序写完之后必须要检查被称为Bug的错误。定位和修改程序中Bug的过程被称为调试。在无论使用什么程序设计语言编程，可能会有如下几种类型的Bug：

语法错误：不符合程序设计语言的规则，比如拼写错误、遗漏了括号，或者编程语言的保留字。
语义错误：比如遗漏程序行，例如在程序中不存在800行的情况下有GOTO 800语句。
运行错误：在程序运行中出现的错误。例如：A=SQR(B)，在程序中计算B的平方根，但是B的值为负值。
其他编程错误：下面的几种错误经常会发生：
错把字母“o”当作数字“0”输入，或者把字母“I”当作数字“1”输入。
同一变量名在程序中使用了两次（变量代表不同意思）。
输入数值常数的的错误（比如错把127.3当作127.03，或者错把15当作0.15），把*错当+。
使用单位错误。例如一个角没有用弧度而是用度来作为单位，或者赤经用时做单位而没有转换成度或者弧度。
角定位在错误象限。请见“修正角所在的象限”一节。
数值舍入错误。例如一个人在计算d的余弦值，在d很小的情况下使用cos()效果不好。实际上如果d非常小，它的余弦值就几乎等于1，而且除弦值随d变化非常缓慢。在这种情况下计算出来余弦值是不准确的。
比如，cos15″=0.99999997，而cos0″的准确值为1。如果想计算角度d的值非常小，可以通过其他方法来计算d的余弦值。比如，可以参考第16章。
一个不能保证覆盖各种情况的迭代过程。请见第5章（迭代）和第29章（Kepler方程的解法）。



检查结果当然，一个程序不仅要在“语法”正确，还要给出正确的结果。要用已知的方法检查你的程序，比如，如果你写了一个程序计算行星位置或者月相的时间，应该把计算结果和天文年历上给出的数值进行比较。要在一些“特殊”情况下检查你的程序。比如，你的程序在赤纬为负值的情况下计算结果是否仍然正确？或者，在赤纬在0°和－1°之间是否正确？或者，观测者的纬度正好为0时是否正确？或者，时间为负值时是否正确？

参考徐剑伟翻译的天文算法，

]]></content>
      <categories>
        <category>天文算法</category>
        <category>Astronomy algorithm</category>
      </categories>
      <tags>
        <tag>astronomy</tag>
        <tag>algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title>Astro AIPS测试</title>
    <url>/2011/01/26/astronomy-aips-test/</url>
    <content><![CDATA[AIPS 测试与退出折腾了几天aips了，终于能打开，读数据，关闭了。虽然对数据定标等还一头雾水，但为免连怎么读数据都忘了，在这里记一笔。
开aips 在aips数据目录下
[XX @XX FITS]$ .   /the/path/of/aips/LOGIN.SH

这里新版本多了一个$CDTST
可以把这个写到bashrc中，这样就可以每次开终端自动载入了。
[XX @XX FITS]$ aips tv=local

读数据（对aips友好的格式，假设数据文件为AL554_1，AL554_2等等）
&gt;task ‘fillm’&gt;datain ‘AL554_’&gt;go

关闭aips，最好不要
&gt;exit

而是要
&gt;kleenex

如果对已有的数据区不满意想加一个？没问题。在……/aips/DA00/DADEVS.LIST文件里加一行新数据目录的路径，然后创建此目录，在此目录（比如叫LOCALHOST_3）中
[xx@xx LOCALHOST_3]$ touch SPACE[xx@xx LOCALHOST_3]$ chmod 771 SPACE

然后新的数据区就创建好了。
这次就写这些吧。等会定标了再接上。
]]></content>
      <categories>
        <category>Astronomy</category>
      </categories>
      <tags>
        <tag>aips</tag>
        <tag>bashrc</tag>
        <tag>LOGIN</tag>
        <tag>datain</tag>
        <tag>task</tag>
        <tag>exit</tag>
        <tag>kleenex</tag>
        <tag>CDTST</tag>
      </tags>
  </entry>
  <entry>
    <title>DiFX问题集锦</title>
    <url>/2013/04/10/astronomy-difx-troubleshooting/</url>
    <content><![CDATA[DiFX问题集锦DiFX 使用中找不到flDiFX使用中遇到/usr/bin/ld can not find –fl
这个主要是因为安装DiFX时没有把安装包装全。
可以参考CentOS 安装DiFX。
解决方法为安装flex*，全包（包括开发库）而不只是flex。
DiFX-HOPS出现的lpng12问题在使用difx的install附加安装HOPS的时候，报错说是-lpng12没有找到，自己看了一下，丫的libpng我装了呀，使用yum search了一下，发现libpng还有libpng10、libpng12，囧。
解决方法很简单：
yum install libpng12*

当然，对于centos而言，如果找不到这个package，可以去http://fr2.rpmfind.net/linux/rpm2html/search.php?query=libpng12.so.0&amp;submit=Search+…&amp;system=centos&amp;arch=进行下载，直接安装rpm包也是ok的。
unable to find rpm tool在安装DiFX的时候出现这个问题。
运行install.sh出现：
ERROR: Unable to find rpm tool, please add its location to your PATH and restart installationInstallation failed.Please see /var/log/ipp_em64t_install.log for details.
Installation is complete:Thank you for using Intel Software Development Products, tools for improving application performance.
解决方法为： /install/install –nonrpm
这个bug在ipp5.3和ipp6.0都是存在的，从ipp6.1开始修复，对于全新的IPP，多个版本可以共存安装。
ImportError：No module named mx.dateTimeDiFX中getEOP.py问题
使用getEOP.py的时候出现
ImportError：No module named mx.dateTime

缺少mx包，解决方法使用yum install python-egenix-mx-base即可。
DiFX 使用中RPC无法使用的问题及解决方法
最新更新，直接执行startCalcServer即可解决这个问题了。

我记得去年貌似就碰到这个问题，不过只是不同的发行版而已，今天是Fedora 17，Pro.Z的机器。
问题就是difx的calcserver程序是需要调用rpc的，而大部分情况下，出错的原因是因为rpc支撑环境没有安装，其实如果使用了NFS，这个问题一般是没有问题的。
解决方法少许有些不同，不过还是可以只使用的：即安装portmap程序包，然后尝试service rpcbind start。
$ apt-get install portmap$ service rpcbind start


这里很高兴还记得ALT+F2，然后r重启X11 shell的技巧。

关于difx的troubleshooting也有提及RPC service unavailable

If an RPC error is encountered when starting the calcserver program, it is possible that the portmap service is either not installed or not running. Please consult your OS distribution documentation for rectifying this. In the case of Debian or Ubuntu Linux, the solution may be as simple as:

关于portmap端口映射端口映射是一个服务器，将RPC程序号转换为DARPA的协议端口号。在使用RPC调用时它必须运行。
portmap进程的主要功能是把RPC程序号转化为Internet的端口号。
当一个RPC服务器启动时，会选择一个空闲的端口号并在上面监听（每次启动后的端口号各不相同），同时它作为一个可用的服务会在portmap进程注册。一个RPC服务器对应惟一一个RPC程序号，RPC服务器告诉portmap进程它在哪个端口号上监听连接请求和为哪个RPC程序号提供服务。经过这个过程，portmap进程就知道了每一个已注册的RPC服务器所用的Internet端口号，而且还知道哪个程序号在这个端口上是可用的。portmap进程维护着一张RPC程序号到Internet端口号之间的映射表，它的字段包括程序号、版本号、所用协议、端口号和服务名，portmap进程通过这张映射表来提供程序号-端口号之间的转化功能
如果portmap进程停止了运行或异常终止，那么该系统上的所有RPC服务器必须重新启动。首先停止NFS服务器上的所有NFS服务进程，然后启动portmap进程，再启动服务器上的NFS进程。
RPC远程过程调用（Remote Procedure Call，RPC）是一个计算机通信协议。该协议允许运行于一台计算机的程序调用另一台计算机的子程序，而程序员无需额外地为这个交互作用编程。如果涉及的软件采用面向对象编程，那么远程过程调用亦可称作远程调用或远程方法调用。
]]></content>
      <categories>
        <category>Linux</category>
        <category>Fedora</category>
        <category>CentOS</category>
        <category>DiFX</category>
        <category>HOPS</category>
      </categories>
      <tags>
        <tag>difx</tag>
        <tag>rpm</tag>
        <tag>nonrpm</tag>
        <tag>service</tag>
        <tag>rpcbind</tag>
        <tag>portmap</tag>
        <tag>apt-get</tag>
        <tag>libpng</tag>
        <tag>yum</tag>
        <tag>flex</tag>
        <tag>getEOP</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>CentOS 安装 DiFX</title>
    <url>/2018/01/24/astronomy-difx-install-on-centos/</url>
    <content><![CDATA[如何在CentOS上安装DiFX如果只是使用，那么可以使用下面一个命令来获取DiFX的运行环境(需要安装docker)：
$ docker run -it shaoguangleo/centos-difx

如果希望运行图形界面，运行下述命令：
$ docker run -it -e DISPLAY=unix$DISPLAY -v /tmp/.X11-unix:/tmp/.X11-unix shaoguangleo/centos-difx

如果希望体验一下DiFX的安装，那就开始吧。
最简单的安装方法可以参考一步安装DiFX,star或者follow后提供比较大的压缩包。
操作系统
CentOS 6.3
CentOS-7.0
CentOS-8.0

DiFX版本
DiFX-2.1
DiFX-2.4
DiFX-2.5.1
DiFX-2.6.2
DiFX-2.7.0
DiFX-2.8.1

前提配置：首先更新系统；
$ yum update$ yum upgrade

安装依赖软件包
$ yum install pkgconfig bison  $ yum install fftw-devel openmpi-dev openmpi-bin$ yum install openmpi gcc-gfortran libgfortan libgfortan-static expat expat-devel expat-static$ yum install subversion doxygen$ yum install automake autoconf$ yum install libtool* flex*$ yum install libfftw3-dev libopenmpi-dev libexpat1-dev

安装步骤：(一）、安装 Intel.Integrated.Performance.Primitives（IPP）一路默认安装就可以了，默认安装到/opt/intel/ipp中(假设安装的路径为：/opt/intel/ipp/5.3/ia32/)。添加环境变量：
如果是以前的版本，需要自己指定IPPROOT及相应信息，如下所示：
export IPPROOT=/opt/intel/ipp/5.3/ia32

对于比较新的版本，可以只指定
export IPPROOT=/opt/intel/

剩下的交给DiFX去处理。
在安装DiFX的时候出现这个问题。
运行install.sh出现：
*ERROR: Unable to find rpm tool, please add its location to your PATH and restart installation Installation failed. Please see /var/log/ipp_em64t_install.log for details.**Installation is complete:* * Thank you for using Intel Software Development Products, tools for improving application performance.



解决方法为： **/install/install --nonrpm**
这个bug在ipp5.3和ipp6.0都是存在的，从ipp6.1开始修复，对于全新的IPP，多个版本可以共存安装。
（二）、pgplot5.2.tar.gz的安装.参考 Ubuntu/Debain/Fedora/Mac/CentOS 安装PGPLOT
添加环境变量：
$ export  PGPLOT_DIR=/usr/local/pgplot/$ export PGPLOT_DEV=/xwindow

（三）、mpich的安装$./configure --prefix=/usr/local/mpich 2&gt;&amp;1 | tee c.txt$ make 2&gt;&amp;1 | tee m.txt$ make install 2&gt;&amp;1 | tee mi.txt

添加环境变量：
PATH=/usr/local/mpich/bin:$PATH; export PATHexport MPICXX=/usr/local/mpich/bin/mpicxx

（四）、 fftw的的安装$ ./configure --enable-shared --enable-threads --enable-float$ make -j 2$ make install$ make clean$ ./configure --enable-shared --enable-threads --enable-long-double$ make -j 4$ make install$ make clean$ ./configure --enable-sse2$ make -j 4$ make install$ make clean$ updatedb

（五）、 DiFX‐2.4.1的安装执行./genipppc
修改setup.bash文件的如下部分(深红的部分）
####### DIFX VERSION ########################export DIFX_VERSION=DiFX-2.1.1####### ROOT PATHS ##########################export DIFXROOT=/usr/local/difxexport DIFX_PREFIX=$DIFXROOTexport PGPLOTDIR=/usr/local/pgplotexport IPPROOT=/opt/intel/ipp/5.3/ia32####### COMPILER ############################export MPICXX=/usr/local/mpich/bin/mpicxx####### USE GFORTRAN IN PREFERENCE TO G77? ######### Comment out if not desired ##########$ mkdir /usr/local/difx$ Source setup.bash$ ./install-difx$ ./install-difx --withhops$ ./install-difx --withfb



$ cp init.d/calcserver  /etc/init.d




注：若不能运行成功则应向：DiFX-2.1/mpifxcorr/src/fxmanager.cpp 和 DiFX-2.1/mpifxcorr/utils/dedisperse_difx.cpp 中添加语句 #include &lt;cstring&gt; 若还不能成功运行则可根据错误提示安装相应的软件。
（六）、最后安装  portmap 程序包以启动rpc （yum install portmap 、yum install rpc）（七）、总结如下：DiFX的安装顺序如下：

difxio
difxmessage
mark5access
vdifio
mpifxcorr
calcserver
calcif2
difx2fits
vex2difx
difx2mark4
pulsar/difx2profile
misc
vsi2screen

OUTPUT\u@\h DiFX-2.4.1 \W&gt; source setup.bash DiFX version DiFX-2.4.1 is selected\u@\h DiFX-2.4.1 \W&gt; ./install-difx************************************Getting environmental variables************************************Setting up directories/home/AstroSoft/DiFX2.4.1/lib/pkgconfig/ipp.pc already exists************************************Building  difxio/libtoolize: putting auxiliary files in `.'.libtoolize: copying file `./ltmain.sh'libtoolize: Consider adding `AC_CONFIG_MACRO_DIR([m4])' to configure.ac andlibtoolize: rerunning libtoolize, to keep the correct libtool macros in-tree.libtoolize: Consider adding `-I m4' to ACLOCAL_AMFLAGS in Makefile.am.difxio/Makefile.am:43: warning: 'INCLUDES' is the old name for 'AM_CPPFLAGS' (or '*_CPPFLAGS')tests/Makefile.am:1: warning: 'INCLUDES' is the old name for 'AM_CPPFLAGS' (or '*_CPPFLAGS')utils/Makefile.am:1: warning: 'INCLUDES' is the old name for 'AM_CPPFLAGS' (or '*_CPPFLAGS')checking for a BSD-compatible install... /usr/bin/install -cchecking whether build environment is sane... yeschecking for a thread-safe mkdir -p... /usr/bin/mkdir -pchecking for gawk... gawkchecking whether make sets $(MAKE)... yeschecking whether make supports nested variables... yeschecking for gcc... gccchecking whether the C compiler works... yeschecking for C compiler default output file name... a.outchecking for suffix of executables...checking whether we are cross compiling... nochecking for suffix of object files... ochecking whether we are using the GNU C compiler... yeschecking whether gcc accepts -g... yeschecking for gcc option to accept ISO C89... none neededchecking for style of include used by make... GNUchecking dependency style of gcc... gcc3checking build system type... x86_64-unknown-linux-gnuchecking host system type... x86_64-unknown-linux-gnuchecking how to print strings... printfchecking for a sed that does not truncate output... /usr/bin/sedchecking for grep that handles long lines and -e... /usr/bin/grepchecking for egrep... /usr/bin/grep -Echecking for fgrep... /usr/bin/grep -Fchecking for ld used by gcc... /usr/bin/ldchecking if the linker (/usr/bin/ld) is GNU ld... yeschecking for BSD- or MS-compatible name lister (nm)... /usr/bin/nm -Bchecking the name lister (/usr/bin/nm -B) interface... BSD nmchecking whether ln -s works... yeschecking the maximum length of command line arguments... 1572864checking whether the shell understands some XSI constructs... yeschecking whether the shell understands "+="... yeschecking how to convert x86_64-unknown-linux-gnu file names to x86_64-unknown-linux-gnu format... func_convert_file_noopchecking how to convert x86_64-unknown-linux-gnu file names to toolchain format... func_convert_file_noopchecking for /usr/bin/ld option to reload object files... -rchecking for objdump... objdumpchecking how to recognize dependent libraries... pass_allchecking for dlltool... nochecking how to associate runtime and link libraries... printf %s\nchecking for ar... archecking for archiver @FILE support... @checking for strip... stripchecking for ranlib... ranlibchecking command to parse /usr/bin/nm -B output from gcc object... okchecking for sysroot... nochecking for mt... nochecking if : is a manifest tool... nochecking how to run the C preprocessor... gcc -Echecking for ANSI C header files... yeschecking for sys/types.h... yeschecking for sys/stat.h... yeschecking for stdlib.h... yeschecking for string.h... yeschecking for memory.h... yeschecking for strings.h... yeschecking for inttypes.h... yeschecking for stdint.h... yeschecking for unistd.h... yeschecking for dlfcn.h... yesBuilding page list...Search for main page...Computing page relations...Determining the scope of groups...Sorting lists...Freeing entry treeDetermining which enums are documentedComputing member relations...Building full member lists recursively...Adding members to member groups.Computing member references...Inheriting documentation...Generating disk names...Adding source references...Adding xrefitems...Sorting member lists...Computing dependencies between directories...Generating citations page...Counting data structures...Resolving user defined references...Finding anchors and sections in the documentation...Transferring function references...Combining using relations...Adding members to index pages...Generating style sheet...Generating example documentation...Generating file sources...Generating file documentation...Generating docs for file src/alert.cpp...Generating docs for file src/alert.h...Generating docs for file src/architecture.h...Generating docs for file src/configuration.cpp...Generating docs for file src/configuration.h...Generating docs for file src/core.cpp...Generating docs for file src/core.h...Generating docs for file src/datamuxer.cpp...Generating docs for file src/datamuxer.h...Generating docs for file src/datastream.cpp...Generating docs for file src/datastream.h...Generating docs for file src/fxmanager.cpp...Generating docs for file src/fxmanager.h...Generating docs for file src/mark5bfile.cpp...Generating docs for file src/mark5bfile.h...Generating docs for file src/mark5bmark5.cpp...Generating docs for file src/mark5bmark5.h...Generating docs for file src/mark5bmark5_stubs.cpp...Generating docs for file src/mark5dir.cpp...Generating docs for file src/mark5dir.h...Generating docs for file src/mark5directorystructs.cpp...Generating docs for file src/mark5directorystructs.h...Generating docs for file src/mark5utils.cpp...Generating docs for file src/mark5utils.h...Generating docs for file src/mk5.cpp...Generating docs for file src/mk5.h...Generating docs for file src/mk5mode.cpp...Generating docs for file src/mk5mode.h...Generating docs for file src/mode.cpp...Generating docs for file src/mode.h...Generating docs for file src/model.cpp...Generating docs for file src/model.h...Generating docs for file src/mpifxcorr.cpp...Generating docs for file src/mpifxcorr.h...Generating docs for file src/nativemk5.cpp...Generating docs for file src/nativemk5.h...Generating docs for file src/nativemk5_stubs.cpp...Generating docs for file src/pcal.cpp...Generating docs for file src/pcal.h...Generating docs for file src/pcal_impl.h...Generating docs for file src/polyco.cpp...Generating docs for file src/polyco.h...Generating docs for file src/pthreadbarrier.h...Generating docs for file src/switchedpower.cpp...Generating docs for file src/switchedpower.h...Generating docs for file src/vdiffake.cpp...Generating docs for file src/vdiffake.h...Generating docs for file src/vdiffile.cpp...Generating docs for file src/vdiffile.h...Generating docs for file src/vdifmark5.cpp...Generating docs for file src/vdifmark5.h...Generating docs for file src/vdifmark5_stubs.cpp...Generating docs for file src/vdifnetwork.cpp...Generating docs for file src/vdifnetwork.h...Generating docs for file src/visibility.cpp...Generating docs for file src/visibility.h...Generating docs for file src/watchdog.cpp...Generating docs for file src/watchdog.h...Generating page documentation...Generating group documentation...Generating class documentation...Generating docs for compound Alert...Generating docs for compound Configuration...Generating docs for nested compound Configuration::baselinedata...Generating docs for nested compound Configuration::configdata...Generating docs for nested compound Configuration::datastreamdata...Generating docs for nested compound Configuration::freqdata...Generating docs for nested compound Configuration::ruledata...Generating docs for nested compound Configuration::telescopedata...Generating docs for compound Core...Generating docs for nested compound Core::processslot...Generating docs for nested compound Core::processthreadinfo...Generating docs for nested compound Core::threadscratchspace...Generating docs for compound DataMuxer...Generating docs for compound DataStream...Generating docs for nested compound DataStream::readinfo...Generating docs for compound DriveInformation...Generating docs for compound FxManager...Generating docs for compound LBA16BitMode...Generating docs for compound LBA8BitMode...Generating docs for compound LBAMode...Generating docs for compound Mark5BDataStream...Generating docs for compound Mark5BMark5DataStream...Generating docs for compound Mark5DirectoryHeaderVer1...Generating docs for compound Mark5DirectoryInfo...Generating docs for compound Mark5DirectoryLegacyBodyVer1...Generating docs for compound Mark5DirectoryScanHeaderVer1...Generating docs for compound Mark5DirectoryVDIFBodyVer1...Generating docs for compound Mark5LegacyDirectory...Generating docs for compound Mark5Module...Generating docs for compound Mark5NeoLegacyDirectory...Generating docs for compound Mark5Scan...Generating docs for compound Mk5DataStream...Generating docs for compound Mk5Mode.../home/leo/Downloads/DiFX_Install/DiFX-2.4.1/mpifxcorr/src/mk5mode.h:36: warning: The following parameters of Mk5Mode::Mk5Mode(Configuration *conf, int confindex, int dsindex, int recordedbandchan, int chanstoavg, int bpersend, int gsamples, int nrecordedfreqs, double recordedbw, double *recordedfreqclkoffs, double *recordedfreqclkoffsdelta, double *recordedfreqphaseoffs, double *recordedfreqlooffs, int nrecordedbands, int nzoombands, int nbits, Configuration::datasampling sampling, Configuration::complextype tcomplex, bool fbank, bool linear2circular, int fringerotorder, int arraystridelen, bool cacorrs, int framebytes, int framesamples, Configuration::dataformat format) are not documented:  parameter 'recordedfreqclkoffsdelta'  parameter 'recordedfreqphaseoffs'Generating docs for compound Mode...Generating docs for compound Model...Generating docs for nested compound Model::eop...Generating docs for nested compound Model::scan...Generating docs for nested compound Model::source...Generating docs for nested compound Model::spacecraft...Generating docs for nested compound Model::station...Generating docs for compound NativeMk5DataStream...Generating docs for compound PCal.../home/leo/Downloads/DiFX_Install/DiFX-2.4.1/mpifxcorr/src/pcal.cpp:252: warning: argument 'pcalout' of command @param is not found in the argument list of PCal::extractAndIntegrate_reference(f32 const *data, const size_t len, cf32 *out, const uint64_t sampleoffset)Generating docs for compound pcal_config_pimpl...Generating docs for compound PCalExtractorComplex...Generating docs for compound PCalExtractorDummy.../home/leo/Downloads/DiFX_Install/DiFX-2.4.1/mpifxcorr/src/pcal.cpp:1248: warning: argument 'pointer' of command @param is not found in the argument list of PCalExtractorDummy::getFinalPCal(cf32 *out)Generating docs for compound PCalExtractorImplicitShift...Generating docs for compound PCalExtractorShifting...Generating docs for compound PCalExtractorTrivial...Generating docs for compound Polyco...Generating docs for compound pthread_barrier_t...Generating docs for compound SwitchedPower...Generating docs for compound VDIFDataStream...Generating docs for compound VDIFFakeDataStream...Generating docs for compound VDIFMark5DataStream...Generating docs for compound VDIFMuxer...Generating docs for compound VDIFNetworkDataStream...Generating docs for compound Visibility...Generating namespace index...Generating docs for namespace fxcorrGenerating graph info page...Generating directory documentation...Generating index page...Generating page index...Generating module index...Generating namespace index...Generating namespace member index...Generating annotated compound index...Generating alphabetical compound index...Generating hierarchical class index...Generating member index...Generating file index...Generating file member index...Generating example index...finalizing index lists...lookup cache used 2381/65536 hits=8086 misses=2456finished...Done!]]></content>
      <categories>
        <category>射电天文</category>
      </categories>
      <tags>
        <tag>astronomy</tag>
        <tag>portmap</tag>
        <tag>CentOS</tag>
        <tag>DiFX</tag>
        <tag>calcif2</tag>
        <tag>calcserver</tag>
        <tag>difx2fits</tag>
        <tag>difx2mark4</tag>
        <tag>difx2profile</tag>
        <tag>difxio</tag>
        <tag>difxmessage</tag>
        <tag>fftw</tag>
        <tag>ipp</tag>
        <tag>mark5acess</tag>
        <tag>mpich</tag>
        <tag>mpifxcorr</tag>
        <tag>pgplot</tag>
        <tag>rpc</tag>
        <tag>vdifio</tag>
        <tag>vex2difx</tag>
        <tag>vsi2screen</tag>
        <tag>Linux</tag>
        <tag>PGPLOT</tag>
        <tag>AstroSoft</tag>
        <tag>天文</tag>
        <tag>射电</tag>
      </tags>
  </entry>
  <entry>
    <title>天文相关会议</title>
    <url>/2018/10/30/astronomy-meetings/</url>
    <content><![CDATA[天文相关会议搜集系列相关会议，供大家参考。更好阅读体验参考原文天文会议汇总。
欢迎大家补充、修改PR、fork、star或clone，一般一月更新一次，谢谢。
原始文件请参考 天文会议汇总。
ForthcomingIn the following 90 days 2020悄然到来


Begin
End
Title
Location
Website



21 January 2020
24 January 2020
ION Precise Time and Time Interval Meeting (PTTI)
San Diego, CA, USA🇺🇸
TBA


2020-02-17
2020-02-20
Cosmic Flows, Large-Scale Structure and Visualization
stellenbosch, ZA🇿🇦
https://asaip.psu.edu/meetings/all-meetings/cosmic-flows-large-scale-structure-and-visualization


2020-03-09
2020-03-13
The Physical Chanllenges of Astro-Statistics
Sexten，Italy🇮🇹
https://asaip.psu.edu/meetings/all-meetings/the-physical-challenges-of-astro-statistics



2020-04-05
GOLD：The Golden Cosmological Surveys Decade
Orsay FR🇫🇷
https://asaip.psu.edu/meetings/all-meetings/gold-the-golden-cosmological-surveys-decade


01 April 2020
31 May 2020
European Navigation Conference 2020 (ENC 2020) [exact dates TBD]
Dresden, Germany
TBA


2020-03-22
2020-03-28
11th IVS General Meeting
Annapolis, Maryland, USA
https://ivsgm2020.com/


05 Jan 2020
09 Jan 2020
235th AAS Meeting — 235th meeting of the American Astronomical Society
Honolulu, HI, United States
https://aas.org/meetings/future-aas-meetings


05 Jan 2020
11 Jan 2020
TMEX-2020 — 16th Rencontres du Vietnam: Theory meeting experiment, Particle Astrophysics and Cosmology
Quy Nhon, Vietnam
http://vietnam.in2p3.fr/2020/tmex/


06 Jan 2020

Rocky Worlds: from the Solar System to Exoplanets
Cambridge, United Kingdom
https://www.kicc.cam.ac.uk/events/rocky-worlds-from-the-solar-system-to-exoplanets


06 Jan 2020
08 Jan 2020
Fundamentals of Astronomy
Jaipur, India
https://www.facebook.com/events/412406546335961/?ti=as


06 Jan 2020
10 Jan 2020
SWYA 5 — The 5th Scientific Writing School for Young Astronomers
Kunming, China
http://www.swya.org


11 Jan 2020
14 Jan 2020
NDM-2020 — International Conference on Neutrinos and Dark Matter
Hurgada, Egypt
https://indico.cern.ch/event/813648/


13 Jan 2020
24 Jan 2020
Nordita Advanced Winter School on Theoretical Cosmology
Stockholm, Sweden
http://www.nordita.org/events/winterschool2020


14 Jan 2020
16 Jan 2020
Tidal Disruptions in Kyoto: Confronting Theory with Observations
Kyoto, Japan
http://www2.yukawa.kyoto-u.ac.jp/~tde2020/TDK/index.php


14 Jan 2020
23 Jan 2020
1st Padova International School of Physics of the Universe: Multi Messenger Astrophysics
Asiago, Italy
https://agenda.infn.it/event/17979/


14 Jan 2020
25 Jan 2020
International Molecule-type Workshop: “Tidal Disruption Events: General Relativistic Transients”
Kyoto, Japan
http://www2.yukawa.kyoto-u.ac.jp/~tde2020/TDGR/index.php


20 Jan 2020
24 Jan 2020
International Conference on Observing The First Billion Years of the Universe Using Next Generation Telescopes
Indore, India
http://www.iiti.ac.in/people/~firstbillion/


27 Jan 2020
31 Jan 2020
School on Observing The First Billion Years of the Universe Using Next Generation Telescopes
Indore, India
http://www.iiti.ac.in/people/~firstbillion/


27 Jan 2020
31 Jan 2020
The Cosmic Web in the Local Universe
Leiden, Netherlands
https://lorentzcenter.nl/lc/web/2020/1184/info.php3?wsid=1184&amp;venue=Oort


27 Jan 2020
31 Jan 2020
2020 Sun-Climate Symposium
Tucson, Arizona, United States
http://lasp.colorado.edu/home/sorce/news-events/meetings/2020-scs/


02 Feb 2020

MODEST 20: Dense Star Clusters in the Era of Large Surveys
Tata Institute of Fundamental Research, Mumbai, India
http://www.tifr.res.in/~modest20/


02 Feb 2020
05 Feb 2020
APEX2020 — Science with the Atacama Pathfinder Experiment
Ringberg Castle, Germany
https://events.mpifr-bonn.mpg.de/indico/event/134/


03 Feb 2020
06 Feb 2020
Inflationary Reheating Meets Particle Physics Frontier
UC Santa Barbara, United States
https://www.kitp.ucsb.edu/activities/inflation-c20


03 Feb 2020
07 Feb 2020
Kavli-IAU Workshop — International co-ordination of multi-messenger transient observations in the 2020s and beyond
Cape Town, South Africa, South Africa
http://kavlitransients2020.saao.ac.za/


08 Feb 2020
13 Feb 2020
Galaxy Quenching and Transformation throughout Cosmic Time
Aspen, Colorado, United States
https://sites.google.com/view/aspengalaxyquenching2020/


10 Feb 2020
14 Feb 2020
RPC2020 — XV Workshop on Resistive Plate Chambers and related detectors
Rome, Italy
https://agenda.infn.it/event/19942/


10 Feb 2020
14 Feb 2020
Tackling the Complexities of Substellar Objects: From Brown Dwarfs to (exo-)Planets
Leiden, Netherlands
https://lorentzcenter.nl/lc/web/2020/1193/info.php3?wsid=1193&amp;venue=Oort


16 Feb 2020

Magnetic Fields in the Universe 7
Quy Nhon, Vietnam
https://www.icisequynhon.com/conferences/2020/magnetic_fields/


16 Feb 2020
21 Feb 2020
AstroWin’20 — International Winter School on Astronomy 2020
Hyderabad, India
https://astrowin19.wixsite.com/astrowin20


17 Feb 2020
19 Feb 2020
The 24th International Microlensing Conference
Beijing, China
http://kiaa.pku.edu.cn/microlensing2020/


17 Feb 2020
21 Feb 2020
Dynamical Reconstruction of Galaxies
Leiden, Netherlands
https://lorentzcenter.nl/lc/web/2020/1200/info.php3?wsid=1200&amp;venue=Oort


17 Feb 2020
21 Feb 2020
Cosmic Flows, Large-Scale Structure and Visualisation
Stellenbosch &amp; Cape Town, South Africa, South Africa
https://www.idia.ac.za/cosflow2020/


21 Feb 2020

The 35th Annual New Mexico Symposium
Socorro, NM, United States
http://www.aoc.nrao.edu/events/nmsymposium/2019/


25 Feb 2020
27 Feb 2020
PERC International symposium on Dust &amp; Parent bodies (IDP2020)
Chiba Institute of Technology, Tokyo Skytree Town , Japan
http://www.perc.it-chiba.ac.jp/meetings/IDP2020/


02 Mar 2020

PLANETS2020 — Ground and space observatories: a joint venture to planetary sciences
Santiago , Chile
https://conference.almaobservatory.org/planets2020/


02 Mar 2020
06 Mar 2020
NUSTAR Annual Meeting 2020
GSI, Darmstadt, Germany
https://indico.gsi.de/event/8591/


02 Mar 2020
27 Mar 2020
The Shifting Paradigm of Stellar Convection from Mixing Length Concepts to Realistic Turbulence Modeling
Stockholm, Sweden
https://www.nordita.org/events/convection2020/index.php


05 Mar 2020
08 Mar 2020
VICQG — VI Cosmology and the Quantum Vacuum
Barcelona, Spain
https://www.ice.csic.es/research/Workshop_Emilio2020/committees.html


08 Mar 2020

Cloud Academy II
Les Houches School of Physics, St-andrews, United Kingdom
https://leap2010.wp.st-andrews.ac.uk/the-project/cloud-academy-ii/


09 Mar 2020
11 Mar 2020
Star clusters and their role in the build-up of galaxies (Regional meeting).
La Serena, Chile
https://www.gemini.edu/clusters2020/


09 Mar 2020
13 Mar 2020
EDSU2020 — 3rd World Summit on Exploring the Dark Side of the Universe
Point a Pitre    Guadeloupe Islands, French Antilles
https://indico.cern.ch/event/801461/overview


09 Mar 2020
13 Mar 2020
The Physical Challenges of Astrostatistics
Sesto Val Pusteria, Italy
https://www.sexten-cfa.eu/event/the-challenges-of-astro-statistics/


09 Mar 2020
13 Mar 2020
XTCP — X Taller de Ciencias Planetarias
Punta del Este, Uruguay
http://tcp2020.cure.edu.uy/


10 Mar 2020
12 Mar 2020
MAXI 10 Year Workshop for the Time Domain Astronomy
Tokyo, Japan
http://maxi.riken.jp/conf/10year


13 Mar 2020
14 Mar 2020
GCGM9 — 9th Gulf Coast Gravity Meeting
Oxford, Mississippi, United States
https://www.phy.olemiss.edu/gcgm9/


15 Mar 2020
21 Mar 2020
17th RuÃbach School on Nuclear Astrophysics
RuÃbach am PaÃ GschÃ¼tt, Austria
https://indico.ph.tum.de/event/4364/


16 Mar 2020
20 Mar 2020
Mapping the X-ray Sky with SRG: First Results from eROSITA and ART-XC
Research Campus Garching, Germany
https://events.mpe.mpg.de/event/SRG2020/


17 Mar 2020
19 Mar 2020
Accurate Flux Calibration for 21st Century Astrophysics
Baltimore, United States
http://www.stsci.edu/contents/events/stsci/2020/march/accurate-flux-calibration-for-21st-century-astrophysics?timeframe=


18 Mar 2020
19 Mar 2020
Astronomy from the Moon: the next decades
London, United Kingdom
https://royalsociety.org/science-events-and-lectures/2020/03/astronomy-moon/


21 Mar 2020
28 Mar 2020
Moriond EW 2020 — 55th Rencontres de Moriond on Electroweak Interactions and Unified Theories
La Thuile, Italy
http://moriond.in2p3.fr/2020/


22 Mar 2020
27 Mar 2020
The Interstellar Shocks School
Les Houches, France
https://isss.sciencesconf.org/


23 Mar 2020
27 Mar 2020
IAU Symposium 360 Astropol2020 Astronomical Polarimetry 2020 – New Era of Multi-Wavelength Polarimetry
Hiroshima, Japan
https://astropol2020-iau.jp/


25 Mar 2020
28 Mar 2020
UCLA Dark Matter 2020 — 14th symposium on Sources and Detection of Dark Matter and Dark Energy in the Universe
Los Angeles, CA, United States
https://conferences.pa.ucla.edu/dark-matter-2020/


28 Mar 2020
04 Apr 2020
Moriond Cosmology 2020 — 55th Rencontres de Moriond on Cosmology
La Thuile, Italy
http://moriond.in2p3.fr/2020/


29 Mar 2020

9th International Fermi Symposium
Johannesburg, Azerbaijan
https://fermi.gsfc.nasa.gov/science/mtgs/symposia/2020/


29 Mar 2020
03 Apr 2020
SMuK —  84. Jahrestagung der DPG und DPG-FrÃ¼hjahrstagung: Sektion Materie und Kosmos
Bonn, Germany
https://bonn20.dpg-tagungen.de/


30 Mar 2020

Globular Clusters at the Nexus of Star and Galaxy Formation
Santa Barbara, CA, United States
https://www.kitp.ucsb.edu/activities/clusters20


30 Mar 2020
03 Apr 2020
Thermal infrared astronomy - past, present and future
Garching, Munich, Germany
http://www.eso.org/sci/meetings/2020/IR2020.html


30 Mar 2020
03 Apr 2020
PHAROS Conference 2020: The multi messenger physics and astrophysics of neutron stars
Patras, Greece
https://indico.cern.ch/e/pharos2020


30 Mar 2020
03 Apr 2020
Where the Star Formation Ends
Leiden, Netherlands
https://lorentzcenter.nl/lc/web/2020/1191/info.php3?wsid=1191&amp;venue=Oort


30 Mar 2020
03 Apr 2020
Adaptive Optics Workshop Week
Porto, Portugal
https://centra.tecnico.ulisboa.pt/events/?id=941


06 Apr 2020
10 Apr 2020
Cosmic Cartography 2020 — Exploring the Cosmic Web and Large-Scale Structure
Kashiwanoha, Japan
http://cosmic2020.ipmu.jp


13 Apr 2020
15 Apr 2020
Time-Domain Cosmology with Strong Gravitational Lensing
Kashiwa, Japan
https://indico.ipmu.jp/e/tdc_stronglens


19 Apr 2020

Growing Black Holes: Accretion and Mergers
Kathmandu, Nepal
http://nepal.oas.inaf.it/


19 Apr 2020
24 Apr 2020
ECLA2020 — European Conference on Laboratory Astrophysics ECLA 2020: Linking dust, ice and gas in space
Anacapri, Capri Island, Italy
http://www.frcongressi.it/ecla2020/


20 Apr 2020
23 Apr 2020
THE LOCAL GROUP. Assembly and Evolution
Baltimore, Maryland, United States
http://www.stsci.edu/contents/events/stsci/2020/april/the-local-group-assembly-and-evolution?page=2&amp;filterUUID=6fedb8a7-


20 Apr 2020
23 Apr 2020
15th International Astronomical Consortium for High Energy Calibration (IACHEC) meeting
Pembroke, VA, United States
http://iachec.org/


20 Apr 2020
24 Apr 2020
BEACON — Biennial European Astrobiology Conference
Fuencaliente de La Palma, Spain
http://europeanastrobiology.eu/BEACON2020


20 Apr 2020
24 Apr 2020
The Sharpest Eyes on the Sky: A 2020 vision for high angular resolution astronomy
Exeter, United Kingdom
http://sites.exeter.ac.uk/sharpesteyes2020/


2020


Begin
End
Title
Location
Website



2020-04-08
2020-04-10
3rd Sino-Italian Workshop on Astrostatistics
Roma IT🇮🇹
https://asaip.psu.edu/meetings/all-meetings/postponed-3rd-sino-italian-workshop-on-astrostatistics


03 May 2020
08 May 2020
EGU General Assembly 2020
Vienna, Austria
http://www.egu2020.eu


10 May 2020
14 May 2020
FIG Working Week 2020
Amsterdam, The Netherlands
http://www.fig.net/fig2020/


2020-06-01
2020-10-05
16th Summer School in Statistics for Astronomers
University Park PA USA🇺🇸
https://asaip.psu.edu/meetings/all-meetings/16th-summer-school-in-statistics-for-astronomers


2020-06-08
2020-06-12
IAU Symposium 362: The Predictive Power of Computational Astrophysics as a Discovery Tool
Chamonix FR🇫🇷
https://asaip.psu.edu/meetings/all-meetings/iau-symposium-362-the-predictive-power-of-computational-astrophysics-as-a-discovery-tool


2020-06-08
2020-06-12
2nd Summer School in Astroinformatics
University Park PA USA🇺🇸
https://asaip.psu.edu/meetings/all-meetings/2nd-summer-school-in-astroinformatics


2020-06-22
2020-06-24
Planetary Science Informatics and Data Analytics Conference

https://asaip.psu.edu/meetings/all-meetings/planetary-science-informatics-and-data-analytics-conference


28 June 2020
04 July 2020
AOGS 17th Annual Meeting
Gangwon, South Korea
TBA


2020-07-18
2020-07-23
16th International Conference on Machine Learning and Data Mining (MLDM 2020)
New York, USA美国
https://asaip.psu.edu/meetings/all-meetings/16th-international-conference-on-machine-learning-and-data-mining-mldm-2020


August 2020
August 2020
IGS 2020 Workshop
UNAVCO/UCAR, Boulder CO
TBA


15 August 2020
23 August 2020
43rd COSPAR Scientific Assembly
Sydney, Australia
http://www.cospar2020.org/


21 Sep 2020
25 Sep 2020
ION GNSS+ 2020
St. Louis, Missouri, USA
TBA


01 October 2020
31 October 2020
22nd International Workshop on Laser Ranging [exact dates TBD]
Kunming, China🇨🇳
TBA


01 November 2020
30 November 2020
15th Meeting of the International Committee on Global Navigation Satellite Systems (ICG) [exact dates TBD]
Vienna, Austria
TBA


2020-12-08
2020-12-12
ADASS 2020: Astronomical Data Analysis Software &amp; Systems
Granada，Spain 🇪🇸
https://asaip.psu.edu/meetings/all-meetings/adass-2020-astronomical-data-analysis-software-systems


07 December 2020
11 December 2020
AGU 2020 Fall Meeting
San Francisco, California, USA
TBA


04 May 2020
08 May 2020
IVOA Interoperability Meeting
Sydney, Australia
http://ivoa.net


04 May 2020
29 May 2020
The Accelerating Universe: The Physics and Astrophysics of Dark Energy and Gravitation
Munich, Germany
http://www.munich-iapp.de/accelerating-universe


11 May 2020

Uncovering the Physics of Formation of Globular Clusters and their Host Galaxies
Santa Barbara, CA, United States
https://www.kitp.ucsb.edu/activities/clusters-c20


11 May 2020
14 May 2020
Uncovering the Physics of Formation of Globular Clusters and their Host Galaxies
UC Santa Barbara, United States
https://www.kitp.ucsb.edu/activities/clusters-c20


11 May 2020
15 May 2020
17th AIP Thinkshop on “Protoplanetary Disk Chemodynamics”
Potsdam, Germany
https://thinkshop.aip.de/17


11 May 2020
15 May 2020
CAFFELattes — Cosmological analyses featuring Galactic foreground emission
Montpellier, France
https://caffelattes.sciencesconf.org/


12 May 2020
15 May 2020
THESEUS CONFERENCE 2020 — The Transient High-Energy Sky and Early Universe Surveyor
Malaga, Spain
https://www.isdc.unige.ch/theseus/theseus-conference-2020.html


13 May 2020
20 May 2020
17th NRAO Synthesis Imaging Workshop
Socorro, NM, United States
http://www.cvent.com/events/17th-synthesis-imaging-workshop/event-summary-0d59eb6cd1474978bce811194b2ff961.aspx


17 May 2020
20 May 2020
Galactic and Extragalactic High Velocity Clouds Workshop
University of Georgia, Athens, GA, United States
http://www.physast.uga.edu/workshops/high-velocity-clouds


18 May 2020

Massive Stars Near and Far
Ballyconnell, Cavan, Ireland
https://iau.org/science/meetings/future/symposia/2523/


18 May 2020
20 May 2020
Distorted Astrophysical Discs: New Insights and Future Directions
Cambridge, United Kingdom
https://www.kicc.cam.ac.uk/events/distorted_discs


25 May 2020
29 May 2020
Alvio@80: Conference in honor of Alvio Renzini
Island of Crete, Greece
https://alvio80.org/


25 May 2020
29 May 2020
XRU2020 — The X-ray Universe 2020
ESTEC/ESA, Noordwijk, Netherlands
https://www.cosmos.esa.int/web/xmm-newton/2020-symposium


25 May 2020
29 May 2020
9ICPDP 2020 — 9th International Conference on the Physics of Dusty Plasmas
Moscow, Russia
https://9icpdp.cosmos.ru/


31 May 2020
04 Jun 2020
236th Meeting of the American Astronomical Society
Madison, France
https://aas.org/meetings/aas236


01 Jun 2020
05 Jun 2020
TOE III: from Solar System to Exoplanets
Lamego, Douro Valley, Portugal
http://www.iastro.pt/toe3/


01 Jun 2020
05 Jun 2020
Michigan Cosmology Summer School
Ann Arbor, United States
https://sites.google.com/a/umich.edu/cosmology-summer-school-2020/


01 Jun 2020
26 Jun 2020
PLANET FORMATION: FROM DUST COAGULATION TO FINAL ORBITAL ASSEMBLY
Garching, Germany
http://www.munich-iapp.de/planetformation


07 Jun 2020
13 Jun 2020
QUARKS-2020 — XXI Seminar on High Energy Physics
Pereslavl-Zalessky, Russia
https://indico.quarks.ru/event/2020/


08 Jun 2020
10 Jun 2020
YAGN20 —   Young Astronomers on Galactic Nuclei
Copenhagen, Denmark
https://indico.nbi.ku.dk/event/1305/


08 Jun 2020
11 Jun 2020
AwRI2020 — Astronomy with Radioactive Isotopes
Budapest, Hungary
https://indico.cern.ch/event/820113/


08 Jun 2020
12 Jun 2020
IAU Symposium 362 —   The predictive power of computational astrophysics as a discovery tool
Chamonix, France
http://iaus362.astro.unistra.fr/IAUS362.html


08 Jun 2020
12 Jun 2020
LSST@EUROPE 4: Shaping the European contribution to LSST
Rome, Italy
https://indico.ict.inaf.it/e/LSST_EUROPE4


14 Jun 2020
19 Jun 2020
SPIE Astronomical Telescopes + Instrumentation 2020
Yokohama, Japan
http://spie.org/SPIE_Astronomical_Telescopes_Conference


14 Jun 2020
19 Jun 2020
SPIE AS20 — SPIE Astronomical Telescopes + Instrumentation 2020
Yokohama, United States
http://spie.org/SPIE_Astronomical_Telescopes_Conference


14 Jun 2020
05 Jul 2020
Aspen Center for Physics Summer Workshop: Black Hole Formation, Accretion, and Outflows Through Cosmic Time
Aspen, Colorado, United States
https://www.aspenphys.org/physicists/summer/program/currentworkshops.html


15 Jun 2020
19 Jun 2020
Extragalactic jets on all scales - launching, propagation, termination
Heidelberg, Germany
http://www2.mpia-hd.mpg.de/~jets2020/


15 Jun 2020
20 Jun 2020
The International Astrophysics and Space Conference 2020
Tbilisi, Georgia
http://www.astronomia.ge/


16 Jun 2020
19 Jun 2020
RATOP2020 — Relativistic astrophysics, Theory and observational perspectives
Warsaw, Poland
http://www.cft.edu.pl/ratop2020


21 Jun 2020

COOL STARS 21: Cambridge Workshop on Cool Stars, Stellar Systems and the Sun
Toulouse, France
https://coolstars21.github.io/


21 Jun 2020
25 Jun 2020
Gemini Science Meeting: 20th Anniversary and Beyond
Seoul, South Korea
https://www.gemini.edu/gsm2020


21 Jun 2020
27 Jun 2020
Neutrino 2020 — XIX International Conference on Neutrino Physics and Astrophysics
Chicago, Illinois, United States
https://conferences.fnal.gov/nu2020/


22 Jun 2020
24 Jun 2020
Planetary Science Informatics and Data Analytics 2020 Conference
Madrid, Spain
https://www.cosmos.esa.int/web/psida-2020


22 Jun 2020
26 Jun 2020
ICSLS2020 — 25th InternationaI Conference on Spectral Line Shapes
Caserta, Italy
http://www.icsls2020.unicampania.it/


23 Jun 2020
25 Jun 2020
Multiphase Gas in Galaxy Groups
Charlottesville, VA, United States
https://science.nrao.edu/facilities/alma/naasc-workshops/multiphase_gas/index


29 Jun 2020
03 Jul 2020
The Physics of Star Formation: From Stellar Cores to Galactic Scales
Lyon, France
https://cral.univ-lyon1.fr


29 Jun 2020
03 Jul 2020
RUSGRAV-17 — 17th Russian Gravitational Conference â International Conference  on Gravitation, Cosmology and Astrophysics
Saint Petersburg, Russia
http://rusgrav.spbstu.ru/2020/


06 Jul 2020

14th Asia-Pacific Regional IAU Meeting (APRIM)
Perth, Western Australia, Australia
http://www.aprim2020.org/


06 Jul 2020
09 Jul 2020
The First Penn State SETI Symposium
State College, Pennsylvania, United States
https://sites.psu.edu/setisymposium2020/


06 Jul 2020
10 Jul 2020
Gamma2020 — 7th Heidelberg International Symposium on High-Energy Gamma-Ray Astronomy
Barcelona, Spain
https://indico.icc.ub.edu/e/gamma2020


06 Jul 2020
10 Jul 2020
Illuminating the Dusty Universe: A Tribute to the Work of Bruce Draine
Florence, Italy
https://web.astro.princeton.edu/IlluminatingTheDustyUniverse


06 Jul 2020
10 Jul 2020
MULTIPHASE AGN FEEDING &amp; FEEDBACK II: Linking the Micro to Macro Scales in Galaxies, Groups, and Clusters
Sesto/Sexten, Italy
https://www.sexten-cfa.eu/event/multiphase-agn-feeding-feedback-ii-linking-the-micro-to-macro-scales-in-galaxies-groups-and-clusters/


06 Jul 2020
10 Jul 2020
A COMPREHENSIVE VIEW OF GALAXY EVOLUTION FROM THE MILKY WAY TO I ZWICKY 18 (A conference in honor of Monica Tosi).
Sesto/Sexten, Italy
https://www.sexten-cfa.eu/event/a-comprehensive-view-of-galaxy-evolution-from-the-milky-way-to-i-zwicky-18/


09 Jul 2020
17 Jul 2020
IFAS6 - Indo-French Astronomy School - Spectroscopy: Treasures in the voxels
Lyon, France
https://ifas6.sciencesconf.org/


12 Jul 2020

EPoS 2020 —  The Early Phase Star Formation - Insights from Dynamics
MPG Conference Center Castle Ringberg, Tegernsee, Germany
http://www.mpia.de/homes/stein/EPoS/2020/2020.php


12 Jul 2020
17 Jul 2020
TASC6/KASC13 Workshop
Leuven, Belgium
https://fys.kuleuven.be/ster/tasc6


13 Jul 2020
16 Jul 2020
Taking the Temperature: Statistical Nuclear Physics for Astrophysics and Applications
Athens, Ohio, United States
https://inpp.ohio.edu/~t3/


13 Jul 2020
17 Jul 2020
Dust2020 — The Rise of Metals and Dust in Galaxies through Cosmic Time
Marseille, France
https://metals-dust.sciencesconf.org/


14 Jul 2020
16 Jul 2020
Compact Objects and Energetic Phenomena in the Multi-Messenger Era
Saint Paul, Minnesota, United States
http://go.nrao.edu/ngvla20


20 Jul 2020
24 Jul 2020
Hot Stars: Life with Circumstellar Matter
Almaty, Kazakhstan
https://almaty-stars2020.org


20 Jul 2020
24 Jul 2020
Physics of Neutron Stars - 2020
Saint Petersburg, Russia
http://www.ioffe.ru/astro/NS2020/


20 Jul 2020
24 Jul 2020
2020 Sagan Summer Workshop on Extreme Precision Radial Velocity
Pasadena, California, United States
http://nexsci.caltech.edu/conferences/


27 Jul 2020

Exoplanets III
Heidelberg, Germany
http://mpia.de


27 Jul 2020
30 Jul 2020
NWCS20 — SIAM Conference on Nonlinear Waves and Coherent Structures
Bremen, Germany
https://www.siam.org/Conferences/CM/Conference/nwcs20


27 Jul 2020
31 Jul 2020
GAP TRANSIENTS/INTERMEDIATE LUMINOSITY OPTICAL TRANSIENTS: GIANT EURPIONS OR STELLAR MERGERS?
Alta Pusteria, Italy
https://www.sexten-cfa.eu/event/intermediate-luminosity-optical-transients-giant-eruptions-or-stellar-mergers/


15 Aug 2020

43rd COSPAR Scientific Assembly and Associated Events
Sydney, Australia, Australia
http://www.cospar-assembly.org


15 Aug 2020
22 Aug 2020
COSPAR2020 —  Unifying planetary system formation out of elementary building blocks: from dust, gas and ice to our Solar System and exoplanets
Sydney, Australia
https://www.cospar2020.org/


17 Aug 2020

EUROWD20: 22nd European Workshop on White Dwarfs
Tbingen, Germany
https://uni-tuebingen.de/de/146034


24 Aug 2020
28 Aug 2020
SFDE2020 — Star formation in different environments 2020
Quy Nhon, Vietnam
https://icisequynhon.com/conferences/sfde


25 Aug 2020
29 Aug 2020
IAU365 — IAU Symposium 365: Dynamics of solar and stellar convection zones and atmospheres
Moscow, Russia
http://iaus365.sinp.msu.ru/


06 Sep 2020

IWARA2020 — 9th International Workshop on Astronomy and Relativistic Astrophysics
Mexico City, Mexico
https://indico.cern.ch/event/822124/overview


2020-09-07
2020-09-11
SKA science conference and Key Science Project workshop 2020
Johannesburg，Africa
https://indico.skatelescope.org/event/633/


06 Sep 2020
12 Sep 2020
IWARA2020 - 9th International Workshop on Astronomy and Relativistic Astrophysics
Mexico City, Mexico
https://indico.cern.ch/event/822124/overview


06 Sep 2020
12 Sep 2020
Planetary Science: The Young Solar System
ICISE, Quy Nhon, Vietnam, Vietnam
https://www.icisequynhon.com/conferences/2020/planetary_science/


07 Sep 2020
11 Sep 2020
IPA 2020 — Interplay between Particle and Astroparticle physics 2020
Vienna, Austria
https://indico.cern.ch/event/837621/


07 Sep 2020
11 Sep 2020
The Epoch of Galaxy Quenching: Understanding the Decline in Star Formation from Cosmic Noon to the Present
Cambridge, United Kingdom
https://www.kicc.cam.ac.uk/events/quenching


13 Sep 2020
17 Sep 2020
HEAD18 — 18th Meeting of the High Energy Astrophysics Division
Tucson, AR, United States
https://aas.org/meetings/head18


14 Sep 2020
18 Sep 2020
Wheel of Star Formation: A conference dedicated to Prof. Jan PalouÅ¡
Prague, Czech Republic
https://janfest2020.asu.cas.cz


14 Sep 2020
18 Sep 2020
ESO-ESA JOINT 2020 SCIENCE WORKSHOP: NEW SCIENCE IN THE MULTI-MESSENGER ERA
Garching, Munich, Germany
http://www.eso.org/sci/meetings/2020/eso_esa_conference.html


14 Sep 2020
18 Sep 2020
EANAM2020 —  The 9-th East Asian Numerical Astrophysics Meeting
Tenbusu Naha, Okinawa, Japan
http://hpc.imit.chiba-u.jp/eanam9/


14 Sep 2020
18 Sep 2020
Advances and Challenges in Computational Relativity
Providence, Rhode Island, United States
https://icerm.brown.edu/programs/sp-f20/w1/


21 Sep 2020

Conditions and Impact of Star Formation - Across Times and Scales
Puerto Varas or Valdivia, Chile
https://www.sfb956.de/science/overview


21 Sep 2020
23 Sep 2020
Aaronson Symposium: Galactic Dynamics with Resolved Stars
Tucson, Arizona, United States
https://www.as.arizona.edu/aaronson-symposium-september-21-23-2020


21 Sep 2020
25 Sep 2020
NIC 2020 — 16th International Symposium on Nuclei in the Cosmos
Chengdu city, Sichuan province, China
http://www.juna.ac.cn/nic2020


21 Sep 2020
25 Sep 2020
9th Microquasar Workshop: Celebrating over 50 years of discovery
Cagliari, Italy
https://sites.google.com/inaf.it/microquasar-2020/home


23 Sep 2020
26 Sep 2020
CSS 2020 — Cosmology on Small Scales 2020: Excessive Extrapolations and Selected Controversies in Cosmology
Prague, Czech Republic
http://css2020.math.cas.cz


28 Sep 2020
02 Oct 2020
From Clouds to Planets II: The Astrochemical Link
Berlin, Germany
https://events.mpe.mpg.de/event/12/


28 Sep 2020
02 Oct 2020
PUMA2020 — Probing the universe with multi-messanger astronomy
Sestri Levante, Italy
https://agenda.infn.it/event/18651/


04 Oct 2020
10 Oct 2020
IAU Symposium 366: The origin of outflows in evolved stars
Leuven, Belgium
https://iaus366.be/


05 Oct 2020
30 Oct 2020
MIAPP Workshop — Star-forming clumps and clustered starbursts across cosmic time
Garching, Germany
http://www.munich-iapp.de/programmes-topical-workshops/2020/star-forming/


08 Nov 2020
12 Nov 2020
ADASS 2020 — The Annual Conference on Astronomical Data Analysis Software &amp; Systems
Granada, Spain
https://adass2020.es


30 Nov 2020
04 Dec 2020
Linking the Galactic and Extragalactic: stellar dynamics and stellar populations of the Milky Way and its siblings
Wollongong, NSW, Australia
http://extragalactic-milkyways.org/index.html


07 Dec 2020
11 Dec 2020
The aftermath of a revolution: planet formation five years after HL Tau
Cape Town, Chile
https://www.eso.org/sci/meetings/2020/hltau2020.html


09 Dec 2020
14 Dec 2020
IAUS367 — Education and Heritage in the Era of Big Data in Astronomy. First steps on the IAU 202-2030 Strategic Plan
San Carlos de Bariloche, Argentina
http://sion.frm.utn.edu.ar/iaus367/


08 Jan 2022
13 Jan 2022
239th AAS — 239th meeting of the American Astronomical Society
Washington DC, United States
https://aas.org/meetings/future-aas-meetings


2021


Begin
End
Title
Location



03 Jan 2021
07 Jan 2021
237th AAS Meeting — 237th meeting of the American Astronomical Society
Phoenix, AZ, United States


25 Jan 2021
28 Jan 2021
Multiwavelength Probes of Galactic Atmospheres
UC Santa Barbara, United States


25 January 2021
28 January 2021
ION Precise Time and Time Interval Meeting (PTTI)
San Diego, CA, USA


29 Mar 2021
01 Apr 2021
White Dwarfs from Physics to Astrophysics
UC Santa Barbara, United States


29 Mar 2021
01 Apr 2021
White Dwarfs as Probes of the Evolution of Planets, Stars, the Milky Way and the Expanding Universe
Santa Barbara, CA, United States


01 Apr 2021
07 Apr 2021
Protostars &amp; Planets VII
Kyoto, Japan


25 April 2021
30 April 2021
EGU General Assembly 2021
Vienna, Austria


01 May 2021
30 June 2021
FIG Working Week 2021
Accra, Ghana


01 August 2021
06 August 2021
AOGS 18th Annual Meeting
Singapore


16 August 2021
27 August 2021
IAU XXXI General Assembly
Busan, Republic of Korea


20 Sep 2021
24 Sep 2021
ION GNSS+ 2021
St. Louis, Missouri, USA


13 December 2021
17 December 2021
AGU 2021 Fall Meeting
New Orleans, Louisiana, USA


2022


Begin
End
Title
Location



03 April 2022
08 April 2022
EGU General Assembly 2022
Vienna, Austria


01 May 2022
30 June 2022
FIG XXVII Congress and General Assembly
Cape Town, South Africa


16 July 2022
24 July 2022
44th COSPAR Scientific Assembly
Athens, Greece


19 Sep 2022
23 Sep 2022
ION GNSS+ 2022
Denver, Colorado, USA


2023


Begin
End
Title
Location



08 Jan 2023
12 Jan 2023
241st AAS Meeting — 141th meeting of the American Astronomical Society
Seattle, WA, United States


23 April 2023
28 April 2023
EGU General Assembly 2023
Vienna, Austria


11 Sep 2023
15 Sep 2023
ION GNSS+ 2023
Denver, Colorado, USA


2024


Begin
End
Title
Location



14 April 2024
19 April 2024
EGU General Assembly 2024
Vienna, Austria


2025


Begin
End
Title
Location



12 Jan 2025
16 Jan 2025
245th AAS Meeting — 245th meeting of the American Astronomical Society
National Harbor, MD , United States


Refer
IERS
上海天文台
国家天文台
紫金山天文台
国家授时中心
中科院国际会议服务平台
云南天文台
中国天文学会

]]></content>
      <categories>
        <category>Astronomy</category>
      </categories>
      <tags>
        <tag>astronomy</tag>
        <tag>vlbi</tag>
        <tag>astromeeting</tag>
      </tags>
  </entry>
  <entry>
    <title>Miriad</title>
    <url>/2010/03/02/astronomy-miriad-introduction/</url>
    <content><![CDATA[Miriad.. _astronomy-software-miriad:
Aim：data-reduction, image-analysis and publication-quality image displays，适用于连续谱和谱线。
]]></content>
      <categories>
        <category>Radio</category>
      </categories>
      <tags>
        <tag>miriad</tag>
        <tag>interferometry</tag>
      </tags>
  </entry>
  <entry>
    <title>极化</title>
    <url>/2010/03/02/astronomy-polarization/</url>
    <content><![CDATA[极化线极化对于线极化，当收信天线的极化方向与线极化方向一致（电场方向）时，感应出的信号最大（电磁波在极化方向上投影最大）；随着收信天线的极化方向与线极化方向偏离越来越多时，感应出的信号越小（投影不断减小）；当收信天线的极化方向与线极化方向正交（磁场方向）时，感应出的信号为零（投影为零）。线极化方式对天线的方向要求较高。当然在实际条件下，电磁波传播途中遇到反射折射，会引起极化方向偏转，有时一个信号既可以被水平天线接收，也可以被垂直天线接收，但无论如何，天线的极化方向常常是需要考虑的重要问题。
圆极化对于圆极化，无论收信天线的极化方向如何，感应出的信号都是相同的，不会有什么差别（电磁波在任何方向上的投影都是一样的）。所以，采用圆极化方式，使得系统对天线的方位（这里的方位是天线的方位，和前面所提到的方向系统的方位是不同的）敏感性降低。因而，大多数场合都采用了圆极化方式。圆极化天线如C326003B。
比喻打个形象的比喻，线极化类似弯曲在地面上爬行的蛇，圆极化类似蛇绕在木棍上绕行。再打个比喻，你拿一根绳子，上下摆，绳子传递的波就是线极化形式的；不断地画圆，传递的波就是圆极化的。
circular polarization 对于transverse electromagnetic wave来说是E plane和H plane之间存在90度的phase difference。从传播方向来看，E 和H的和向量延圆形转动。linear polarization 是E和H的和向量成一个直线，可以为任意角度。从axial ratio来说，当最大的axis和最小axis之比为1或者0dB时是CP。当axial ratio 为 无穷大是为LP。CP antenna可以接收发射任意polarization的signal，而LP antenna只能有一个角度的signal。所以类似于手机用的天线，当天线周围环境会比较复杂的时候适合使用CP，这样周围环境引起的reflection所导致的polarization的变化对antenna 功能的影响会降到最低。而LP antenna会有更好的directivity，这对于定向的信号传播会更好。
]]></content>
      <categories>
        <category>Radio</category>
      </categories>
      <tags>
        <tag>polarization</tag>
      </tags>
  </entry>
  <entry>
    <title>射电天文介绍</title>
    <url>/2011/08/19/astronomy-radio-1-introduction/</url>
    <content><![CDATA[[TOC]
射电天文简介射电窗口
​	从大气的不透明度，可以看到射电波段还是有一个比较大的窗口，波长$\lambda$大约在1厘米 - 11米 。射电天文学也就是在这个波段进行的天文学研究。
​	长波因为地球电离层的影响，短波是因为大气吸收线的影响。比如22GHz的水汽线，60～70GHz的氧气线。
分贝dB为噪声源功率与基准功率比值的对数乘10的数值，不是一个单位。
$10log_{10}(\frac{I}{I_0})$

其中$I_0$为信号的基准功率
I为噪声源

Hot and Cold Radio AstronomyCOLD:

Planets
Neutral Hydrogen
Molecules
CMB, Cosmic Microwave Background,宇宙微波背景辐射

HOT：

Pulsars
Supernovae
AGN - Active Galactic Nuclei
GRBs - Gamma Ray Bursts

灵敏度:ref:灵敏度&lt;my-reference-sensitivity&gt;
分辨率区别两个天球上彼此靠近的射电点源的能力。
$\theta \approx \frac{\lambda}{D}$
对于光学而言，$\theta = 1.22 \times \frac{\lambda}{D}$
对于射电而言，$\theta = f \times \frac{\lambda}{D}$ ，理论上的HPBW（Half Power Beam Width）的$f$值在1-1.22之间。

对于单天线而言，$\lambda$为波长，D为直径
对于天线阵列而言，D为最长基线的长度

参考
Radio Astronomy Lecture Notes，Ian Browne
www.wikipedia.org

]]></content>
      <categories>
        <category>Radio</category>
      </categories>
      <tags>
        <tag>radio</tag>
      </tags>
  </entry>
  <entry>
    <title>Bandpass 带通</title>
    <url>/2019/03/02/astronomy-radio-bandpass/</url>
    <content><![CDATA[Bandpass 带通带通指在其跨越的范围内传递频率并衰减其他的频率。
带通的常见天文应用是在射电望远镜上使用的观测频率，它必须具有有限的带宽或带通。从这个意义上说，理想的带通类似于阶跃函数，在高频和低频边界处具有完美的截止，并在其间具有平坦的响应。在实践中存在一些”band edge roll-off”，即边界处的信号衰减，但不会完全降至零。因此，射电天文学家通常会丢弃在带通边缘收集的数据，这可能会受到带边缘滚降的影响。
参考：COSMOS (swin.edu.au)
]]></content>
      <categories>
        <category>射电天文</category>
      </categories>
      <tags>
        <tag>interferometry</tag>
        <tag>radio</tag>
        <tag>bandpass</tag>
        <tag>telescope</tag>
      </tags>
  </entry>
  <entry>
    <title>Baseline 基线</title>
    <url>/2019/03/02/astronomy-radio-baseline/</url>
    <content><![CDATA[Baseline 基线的概念在射电天文学中，基线是连接两个射电望远镜构成的矢量，主要用于干涉测量，以确定观测中某颗源”相位中心”的条纹率，一条基线对应傅里叶空间中的一个点。
对于具有N个元素的干涉仪，有N（N-1）/2个独立的基线。靠近在一起的天线对善于测量源中的大尺度结构，而长基线具有更好的分辨率和解析精细结构。
首先是“基线”，即干涉阵中两个天线所构成的矢量，它是干涉测量的基础概念，一条基线对应傅里叶空间中的一个点。基线由阵列的布局决定。
物理基线物理基线是在三维空间中，两个天线之间的几何连接。投影基线是该三维的物理基线在二维平面上的投影，该二维平面由观测方向决定。在地面参考系（In Terrestrial Reference Frame，ITRF）中，物理基线是常数，不会变，但是投影基线却会随着地球的自转而改变，因为在天空参考系里，源固定不动，因此投影基线所在的二维平面在随时变化。
杨氏双缝实验
干涉模式随基线baseline 𝐵B （两狭缝之间的距离）和波长𝜆λ 的变化。调整下面的baseline和wavelength滑块，观察右边条纹的变化：baseline越长，条纹频率越高（间隔越窄），波长越短，条纹频率也越高。




最早的双缝实验验证了光的波动性质，光源只是被用来照亮狭缝。现在反问一下自己，如果给定一个双缝装置，我们是否能利用它获得一些光源信息？是否能利用双缝实验做成一个测量设备，也就是 干涉仪 呢？
假定移动位置，我们注意到，长基线对源的位置变化很敏感，而短基线则没有那么敏感。在第四章我们将学习到，干涉仪的空间分辨率（可以区分出的最小源间距离）由𝜆/𝐵λ/B决定，而传统望远镜的空间分辨率由𝜆/𝐷λ/D决定，其中𝐷D为天线（或者镜子）的口径。这是一件非常幸运的事实，因为长基线的造价要比大口径低很多！
然而，由于干涉模式的周期性，长基线测到的位置并不明确。相反，短基线正好能解决上述问题.
如下：




短基线的效果：


最早的visibility的出现，在杨氏双缝实验就已经使用了术语“可见度”visibility，该术语最早指的是干涉模式中亮纹和暗纹间的对比度。
现代干涉仪用的是复可见度，是复数。一个复可见度的振幅，或者可见度振幅，对应了干涉模式的亮度，可见度相位对应了相对相位（在我们的模拟实验中，指的是屏幕中央条纹的相位）。一个复数就表示了光源了所有信息，然而，双缝实验显示了整个干涉模式，屏幕上模式的变化完全取决于“盒子”（一般是用于测量的仪器）的几何规格，光源的信息内容只有幅度和相位。
现代干涉仪用的是复可见度，是复数。一个复可见度的振幅，或者可见度振幅，对应了干涉模式的亮度，可见度相位对应了相对相位（在我们的模拟实验中，指的是屏幕中央条纹的相位）。一个复数就表示了光源了所有信息，然而，双缝实验显示了整个干涉模式，屏幕上模式的变化完全取决于“盒子”（一般是用于测量的仪器）的几何规格，光源的信息内容只有幅度和相位。
到目前为止，我们仅仅只是关注了测量源的属性。显然，干涉模式对仪器的几何性质也很敏感。根据上述现象引申出了干涉仪的许多其它应用，从大地测量VLBI（通过对已知源的射电干涉探测，精确测出天线位置的变化，从而得到大陆的漂移量），到最近LIGO做的引力波探测（以激光作为光源，通过干涉模式测出由引力波引起的时空的微小扭曲，也就是干涉仪的几何改变）。
上面的双缝实验模拟器已经向我们展示了，不同基线长度，其干涉模式传递了天空的某项特定信息。在下面的例子中，对同一条基线，三个不同的“天空”却得到了相同的干涉模式，因此，一次测量无法区分它们：



但是，改变基线长度再次进行测量，得到了截然不同的干涉模式：



使用更多基线，我们能收集到足够信息，重建得到天空图像。这是因为，本质上，每条基线测得的是天空亮度分布的一个傅立叶分量（详见第4章），知道了傅立叶分量，通过傅里叶变换，就能重建出天空图像。1960年代末，计算机的出现使该技术成为可能，射电干涉仪变成了通用化的成像仪器。若非特别说明，现代射电干涉测量指的就是孔径合成。
Michelson interferometer 迈克尔逊干涉仪完整起见，我们修改上面的函数，使之更接近现实的干涉仪。主要改了两处：

把光源改为无限远
按照迈克尔逊干涉仪修改光路

我们对程序做了如下改动。首先，光源位于无限远，因此我们根据入射波前的到达角度（0表示同轴，即沿垂直轴）来定义光源位置。然后用波长数定义基线长度。抵达干涉仪的两个臂的波前“相位差”完全根据到达角来定义，进入干涉仪外臂的两条“射线”指示了入射角。
在不同的position、intensity和baseline的情况下的效果如下所示：









此时用2个源来测试一下：

参考
COSMOS (swin.edu.au)
fundamentals of interferometry
fundamentals of interferometry chinese

]]></content>
      <categories>
        <category>射电天文</category>
      </categories>
      <tags>
        <tag>interferometry</tag>
        <tag>radio</tag>
        <tag>telescope</tag>
        <tag>baseline</tag>
        <tag>Resolution</tag>
      </tags>
  </entry>
  <entry>
    <title>Broadband 宽带</title>
    <url>/2019/03/02/astronomy-radio-broadband/</url>
    <content><![CDATA[Broadband 宽带在天文学中，术语”宽带“是指进行给定观测的频谱的宽度，用于区分连续体和光谱线观测（参见后者的窄带条目）。观测的带宽越宽，灵敏度越高，因此对于任何波长的连续观测或光度测量，都可以使用宽带（宽带）滤波器。
在射电天文学中，宽带观测通常是指约100 MHz的频率宽度。
参考：COSMOS (swin.edu.au)
]]></content>
      <categories>
        <category>射电天文</category>
      </categories>
      <tags>
        <tag>radio</tag>
        <tag>telescope</tag>
        <tag>baseline</tag>
        <tag>frequency</tag>
      </tags>
  </entry>
  <entry>
    <title>Softc - an Operational Software Correlator</title>
    <url>/2010/04/02/astronomy-softc/</url>
    <content><![CDATA[Softc: an Operational Software Correlator
By Stephen T. Lowe

概要Softc相关精度低于10-13秒。该程序可以关联真正的USB，真正的LSB或复杂的I/Q数据采样，支持1、2、4、8比特分辨率。
最近在一个Intel的CPU显示的softc时序测试处理延迟为8的1比特采样的采样率在10 M样点/秒。
介绍处理机只能定制，价格昂贵，维护和开发也需要很多费用。
解决方案：①用磁盘取代磁带；②用通用计算机取代定制硬件。
历史Softc历经艰难险阻。
功能Softc可移植性很好。softc的输入和输出数据格式十分简单，所以需要一个翻译程序来做一些转换。
代码调试softc创造了一个完整的蒙地卡罗数据发生器，该模拟发生器可以产生VLBI数据，然后通过softc处理，从而与通过预期的结果（可以被精确计算的先验，并从这些结果中的任何偏差表示与该相关的问题。）相比较，从而找到相关器的问题所在。
softc蒙特卡洛模拟数据有两种方法：

第一个是一个工程模式，通过用户选择的延迟，延迟率，分数采样偏移等产生数据；
第二个是使用相关模型模拟数据。

在完整的代码测试中，我们发现蒙地卡罗无法检测到由于建模错误而导致的错误。
喷气推进实验室的未来发展方向
部署softc软件、Fit（后相关软件）及Modest（参数估计软件）
总结softc的创建尽可能准确，基本上可以处理任何VLBI数据，用最通用的语言编写，且已被用于为航天器的导航业务2年以上，并将用于明年喷气推进实验室的Mark5相关。
原文Softc: an Operational Software CorrelatorBy Stephen T. LoweJet Propulsion Laboratory / California Institute of TechnologyIVS 2004 General Meeting ProceedingsAbstract:Softc has been used operationally for spacecraft navigation at JPL for over 2 years and will be JPL’s Mark 5 correlator next year. Softc was written to be as close to an ideal correlator as possible, making approximations only below clip_image001 seconds. The program can correlate real USB, real LSB, or complex I/Q data sampled with 1, 2, 4, or 8-bit resolution, and was developed with strong debugging tools that made final debugging relatively quick. Softc’s algorithms and program structure are fully documented. Timing tests on a recent Intel CPU show Softc processes 8 lags of 1-bit sampled data at 10 MSamples/sec, independent of sample rate.1. IntroductionLevel-one VLBI processing has traditionally required state-of-the-art processing power and data bandwidths that could only be implemented using custom electronic hardware and data storage equipment. These devices, correlators, often took many years to design and build followed by at least a year of use to excise the more obvious processing problems. This long development time also ensured that by the time a correlator was debugged and in a stable operational mode its equipment was obsolete. Because there was no other processing option, the VLBI community has endured high costs associated with these devices. These costs include many millions of dollars for development, on the order of $1M annually to pay for the ongoing debugging, capability improvements, and maintenance, a trained operator staff, and the infrastructure costs of the correlator room such as leasing, power, and air conditioning. Data storage and transport has used custom tape technology, but this is also expensive, and as the technology has been pushed to higher densities, tape drive/head maintenance costs have increased. Finally, some indirect correlator costs include lack of flexibility for novel experimental setups, lack of transparent processing algorithms, lack of repeatable output due to tape playback errors, and downtime for maintenance, testing, and modifications.It has been known for some time that all the disadvantages of the traditional correlator noted above could be eliminated if efficient data handling could be moved from tape to disk, and general-purpose computers could meet the processing requirements. Until recently, neither of these conditions could be met adequately, but interestingly it now appears the crossover points for both of these competing technologies, custom tape vs. disk, and custom hardware vs. general-purpose computer, is in the recent past. Both the recent Mark 5 disk format and software correlators such as Softc take advantage of huge commercial R&amp;D budgets worldwide. These are cases of custom VLBI hardware capabilities being overtaken by commercial products developed with enormous resources compared to those in the VLBI community. By extrapolation we are likely to experience other paradigm shifts soon in the remaining custom VLBI hardware, namely station electronics. We are also beginning to see how all these changes are significantly altering the optimum values of VLBI system parameters. For example, it will be more efficient to have smaller antennas with higher bandwidths, and reliability should increase with the improved hardware, disk storage, and real-time fringe verification.2. HistoryIn 1995 JPL began to decommission its Delta-Differenced One-way Range (DeltaDOR) spacecraft navigation system. The decommissioning process was to mothball the DeltaDOR capability, eliminate its near real-time Block I hardware correlator, and after a short time cease DeltaDOR funding. At around this same time, test programs were written to assess software correlation speed and to find fringes in old Block I quasar data. These tests showed the Block I bandwidths were low enough that it could be replaced with a software correlator. Since there was no other choice to preserve this capability, a project to replace the Block I with a software correlator began in 1996. This task was essentially completed but since this was a mothballing effort and DeltaDOR was not necessary for any mission, the program, called Softc, was never used. This was probably fortunate as the program, by design, exactly duplicated the Block I processing including its many approximations and flaws. In 1998, the RadioAstron project agreed to fund further development of Softc as a debugging tool for their project. This opportunity was used to essentially start over and build a true software correlator with all its intrinsic advantages without being constrained to a hardware correlator’s shortcomings. Unfortunately, this effort was canceled in 1999 just as full code testing began. Softc then remained complete but unused and untested until 2001 when the mis-navigation and demise of Mars Climate Orbiter prompted JPL to resurrect the DeltaDOR navigation technique. Softc underwent full-code testing using geodetic experiments and DeltaDOR passes of Mars Global Surveyor, in orbit at the time, and Mars Odyssey, which was on its way to Mars at the time. Softc’s first critical use was the successful Mars Odyssey orbit insertion in Oct 2001. Softc has also been used to successfully navigate both Mars Exploration Rover missions, Deep Space 1, Europe’s Mars Express, and Japan’s Nozomi and Muses-C (Hayabusa) missions.3. CapabilitiesSoftc was designed to be as close as possible to an ideal correlator, where ideal refers to processing accuracy; no compromise in accuracy greater than clip_image001[1] sec was made to increase performance (or for any other reason). Softc can correlate 1, 2, 4, and 8-bit sampled data, upper, lower or double (I/Q) sideband data, and data using either of two sample encoding schemes. Softc is quite portable, as it was developed on a little-endian Alpha running VMS, it works operationally on a large endian machine running Solaris, and has been tested on little-endian Intel machines running Linux. It produces identical output on these machines with no code modifications, even with different C compilers.Softc was designed to process essentially any VLBI data. To do this and remain independent of the hardware and post-correlation software interfaces, Softc has its own input and output data formats. These formats were designed to be as simple as possible, but a translation program is needed to convert the sampled data into Softc’s format, and another program is needed to translate from Softc’s output to the desired post-correlation format. It is also possible to place these translators inside Softc; this has been done on the output side for our DeltaDOR effort and will likely be done for Softc’s input in the future.4. Code DebuggingOne of the greatest hurdles in developing a VLBI correlator is the elimination of processing errors and inaccuracies. It is common for hardware correlator developers to spend years tracking down reasonably significant bugs. Also common are correlator users finding new, consequential errors long after all known problems were eliminated. An important limitation for correlator developers has been the lack of good debugging tools. For this reason, a significant effort, perhaps 40% of Softc’s development, went into the creation of a full Monte Carlo data generator. This generator creates simulated VLBI data that can then be processed by Softc. In this way, the expected results can be calculated exactly a priori, and any deviations from these results indicate problems with the correlator.The Softc Monte Carlo can simulate data in two ways. The first is an engineering mode where data can be generated with user selected delays, delay rates, fractional sample offsets, etc. This mode was very useful in the initial stages of debugging, as the implied geometric models were quite simple and covered a much greater parameter space than could be achieved by Earth-based station models. For example, data can be generated having a constant geometric fringe rate many times that possible for any Earth-based experiment; Softc’s performance under these extreme conditions is a good check that fringe-frequency related calculations are done correctly.The second Monte Carlo mode simulates data using the correlator model. Correlating this simulated data with Softc using the same model should result in no residual delays or phases, and tests Softc in its usual processing mode. The power of this type of test was confirmed when data were simulated using the Block I correlator model for an old experiment. When the Block I processed the simulated data, the residual delay was not zero, but a constant 1-sample delay. In other words, it appears the Block I had always reported delays with a constant 1-sample delay error, and this problem was never found throughout the life of the correlator, but was found immediately with this Monte Carlo test. Softc has passed a large number of extensive Monte Carlo tests, and this, combined with the fact that few calculational approximations are made, gives great confidence that any remaining processing errors are either insignificantly small or easily corrected.Other tools were also created to find errors early in Softc’s development. Because Softc was originally created to correlate 1 and 2-bit sampled data, the core processing routines perform extensive bit-level manipulations. Several test driver programs were developed for each bit-manipulation routine to check its function. Although these drivers are not part of the run-time portion of Softc, they should be considered part of the code package in the same way the Monte Carlo is part of Softc. These programs were designed to test the bit-manipulation routines under the most extreme conditions, and a significant effort went into trying to find processing errors in the core routines. The results of these tests were that the core routines, which perform the bulk of the processing, could be considered essentially bug-free. This made full-code debugging much easier because when a strange problem was seen in the results, many of the most perverse explanations one might imagine could be dropped from consideration.In full code testing we found the unresolved errors to be dominated by modeling errors. The Monte Carlo cannot detect such problems because the same bad model both generates and correlates the data, or in other words, Softc cannot assess what is or is not a realistic model. For example, the first significant problem found turned out to be a sign error in the troposphere model. The Monte Carlo did not detect this (and could not possibly have done so), so only full code testing of real data could find these types of errors.5. Future Directions at JPLWe recently obtained a new 18-CPU Beowulf computer and are currently porting Softc, Fit (our post-correlation software), and Modest (our parameter estimation software) onto this machine. We plan to interface this to two Mark 5 recorders by Jan 2004 and this will be JPL’s VLBI correlator. Work is in progress to update Fit and to add additional Softc capabilities so we should have a clean, modern software system in early 2004. Timing tests on this system show Softc can process 8 lags of 10 MHz sampled real USB single-bit data in real time, and that the processing time is roughly linear with sampling rates from 1 to 100 MHz.We are canceling the development of our 4-station hardware correlator, which is now essentially complete. There is nothing wrong with this correlator other than it is a hardware correlator with all its intrinsic disadvantages. Walking away from our hardware correlator now puts us on a path with a future and will likely save significant money. Because the economics of this decision are probably common to other institutions, we may not see another 4-station hardware correlator being developed anywhere. The economics may also favor replacing larger correlators even now, but the community probably needs to go up the software correlator learning curve beginning with the smaller systems.Work is under way to obtain an open software license for Softc so that others can benefit from this program. Softc and its algorithms are documented and that report should be publicly available very soon.6. SummarySoftc was created to be as accurate as possible, capable of processing essentially any VLBI data, pass strong debugging tests, have a simple user interface, have no platform dependencies, and be written modularly in the most common programming language. It has been used operationally for spacecraft navigation for over 2 years and will be JPL’s Mark 5 correlator next year.Bibliography1See Whitney, R., “Mark 5 Disk-Based Gbps VLBI Data System,” MIT Haystack Observatory, http://web.haystack.mit.edu/mark5/software.html for more on the tape vs. disk issue.2Lowe, S., “Softc: a Software VLBI Correlator,” JPL Report, in press.
]]></content>
      <categories>
        <category>Radio</category>
        <category>Astronomy</category>
        <category>VLBI</category>
      </categories>
      <tags>
        <tag>interferometry</tag>
        <tag>Softc</tag>
        <tag>correlator</tag>
        <tag>fits</tag>
        <tag>models</tag>
      </tags>
  </entry>
  <entry>
    <title>VLBI的定义</title>
    <url>/2010/09/24/astronomy-vlbi-defination/</url>
    <content><![CDATA[VLBI 定义Very Long Baseline Interferometry (VLBI) is a variant of the radio interferometry technique currently used in astronomy, but combining the signals of extremely distant telescopes.
VLBI provides observations of an object with an exquisite angular resolution, equivalent to that of a telescope whose size is the separation between the distant telescopes. This distance can reach thousands of km (transcontinental VLBI), thus allowing measurement of details as small as 10 milli-arcsec (mas), i.e., one hundred times ﬁner than with a conventional telescope in visible light. To achieve VLBI observations, the radio signal is locally recorded together with time stamps of an atomic clock and later the different data from all antennas are correlated using digital electronics and computers to produce the resulting image.
甚长基线干涉测量技术
简单来说，VLBI就是把几个小望远镜联合起来，达到一架大望远镜的观测效果。这是因为，虽然射电望远镜能“看到”光学望远镜无法看到的电磁辐射，从而进行远距离和异常天体的观测，但如果要达到足够清晰的分辨率，就得把望远镜的天线做成几百公里，甚至地球那么大。上世纪50年代，剑桥大学的天文学家马丁·赖尔建成了第一台射电干涉仪，使不同望远镜接收到的电磁波可以叠加成像，在此基础上，VLBI得以发展。1974年，赖尔以此获得了诺贝尔奖。
工作原理
天线输出的信号﹐进行低噪声高频放大后﹐经变频相继转换为中频信号和视频信号。在要求较高的工作中﹐使用频率稳定度达10 的氢原子钟﹐控制本振系统﹐并提供精密的时间信号，由处理机对两个“数据流”作相关处理﹐用寻找最大相关幅度的方法﹐求出两路信号的相对时间延迟和干涉条纹率。如果进行多源多次观测﹐则从求出的延迟和延迟率可得到射电源位置和基线的距离﹐以及根据基线的变化推算出的极移和世界时等参数。参数的精度主要取决于延迟时间的测量精度。因为﹐理想的干涉条纹仅与两路信号几何程差产生的延迟有关﹐而实际测得的延迟还包含有传播介质(大气对流层﹑电离层等)﹑接收机﹑处理机以及钟的同步误差产生的随机延迟﹐这就要作大气延迟和仪器延迟等项改正﹐改正的精度则关系到延迟的测量精度。目前延迟测量精度约为0.1毫微秒。
干涉条纹射电源辐射出的电磁波﹐通过地球大气到达地面﹐由基线两端的天线接收。由于地球自转﹐电磁波的波前到达两个天线的几何程差(除以光速就是时间延迟差)是不断改变的。两路信号相关的结果就得到干涉条纹。
由相关的概念可知：$$R(\tau) \propto \frac{1}{2} E^2 e^{j\omega \tau}$$干涉条纹的产生取决于具体观测的带宽、频率，以CVN为例，当前的时延精度为μs量级，时延率精度为ps量级。
如果条纹过多，修正时延的计算方法为：$$\tau = \frac{d\phi}{dt} \cdot \frac{\pi}{180}\cdot \frac{F}{x\times B} \cdot \frac{1}{360}$$其中$F$为FFTSize，$B$为bandwidth带宽。
用途
由于甚长基线干涉测量法具有很高的测量精度﹐所以用这种方法进行射电源的精确定位﹐测量数千公里范围内基线距离和方向的变化﹐对于建立以河外射电源为基准的惯性参考系﹐研究地球板块运动和地壳的形变﹐以及揭示极移和世界时的短周期变化规律等都具有重大意义。此外﹐在天体物理学方面﹐由于采用了独立本振和事后处理系统﹐基线加长不再受到限制﹐这就可以跨洲越洋﹐充分利用地球所提供的上万公里的基线距离﹐使干涉仪获得万分之几角秒的超高分辨率。而且﹐随着地球的自转﹐基线向量在波前平面上的投影﹐通常会扫描出一个椭圆来。这样﹐在一天内对某个射电源进行跟踪观测的干涉仪﹐就可以获得各个不同方向的超高分辨率测量数据。依据多副长基线干涉仪跟踪观测得到的相关幅度﹐应用模型拟合方法﹐便可得到关于射电源亮度分布的结构图。地球大气对天体射电信号产生的随机相位起伏﹐带来了干涉条纹相位的测量误差。这和其他一些的误差来源一道﹐限制了甚长基线干涉测量法的应用。若在三条基线上对射电源进行跟踪观测﹐则由三个条纹相位之和所形成的闭合相位﹐基本上可以消去大气和时钟误差的随机效应。用这种闭合相位参与运算﹐可以达到较好的模型拟合﹐从而减小结构图的误差。随着投入观测的站数不断增多﹐闭合相位也在增多﹐而且各基线扫描的椭圆覆盖情况也会逐渐改善﹐从而可以得到更精确的结构图。用甚长基线干涉仪测到的射电结构图表明﹕许多射电源呈扁长形﹐中心致密区的角径往往只有毫角秒量级﹐但却对应着类星体或星系这样的光学母体﹔有些致密源本身还呈现小尺度的双源结构甚至更复杂的结构﹔从射电结构随时间变化的情况看来﹐有的小双源好像以几倍于光速的视速度相分离。这些新发现给天体物理学和天体演化学提出了重大的研究课题。我国首次引入VLBI天文测量手段为嫦娥一号定轨 VLBI是英文的甚长基线干涉测量的一个缩写。它的主要特点是用分布在不同地点的两台或者是更多的望远镜在同一时刻观察同一个设定点，然后把数据录入到磁带或者硬盘上，送到VLBI的数据处理中心，用专门的相关处理机进行处理，以获得VLBI的观测量，也就是延迟率和卫星的角位置。
这种干涉测量的方法和特点，使观测的分辨率不再局限于单个望远镜的口径，而是望远镜的距离，我们把它称之为由基线的长度所决定的。中国科学院的VLBI网是测轨系统的一个分系统，它目前由北京、上海、昆明和乌鲁木齐的四个望远镜以及位于上海的天文台的数据处理中心组成。这样一个网所构成的望远镜分辨率相当于口径为3000多公里的巨大的综合望远镜，测角精度可以达到百分之几角秒，甚至更高。 VLBI测轨分系统的具体任务是获得卫星的VLBI测量数据，包括时延、延迟率和卫星的角位置，并参与轨道的确定和预报。具体的任务，比如说完成卫星在24小时、48小时周期的调相轨道段的测轨任务。完成卫星在地月转移轨道段、月球捕获轨道段以及环月轨道段的测轨任务。并且还要参加调相轨道、地月转移轨道、月球捕获轨道段的准实时轨道的确定和预报。的VLBI测量系统通常由两个或两个以上的VLBI观测站和一个数据处理中心组成。VLBI观测站的主要设备包括：高效射电天线、低噪声高灵敏度的接收机系统、VLBI高速数据采集系统、高稳定度的氢原子钟以及高精度时间比对系统等。应用于天文学研究和深空探测的VLBI测量系统的观测站通常需要装备口径数十米的大型射电天线。VLBI数据处理中心主要设备有专用的VLBI相关处理机和高速的通用计算机群。中科院VLBI天文测量系统由上海(25米天线)、北京(50米天线)、昆明(40米天线)、乌鲁木齐(25米天线)四个VLBI观测站和上海VLBI数据处理中心组成。VLBI的基本原理为：VLBI观测站同时跟踪观测同一目标(天然的射电天体或有无线电信标的人造天体)，各观测站将观测数据实时传送或记录在磁盘上运送到VLBI数据处理中心，然后进行数据回放和互相关计算，再利用得到的互相关谱数据，计算得到信号到达各观测站的时间差(时延观测值)及其变化率(时延率观测值)，最后利用这些VLBI观测值计算目标的角位置(赤经和赤纬)。测量精度可以达到百分之几角秒、千分之几角秒甚至更高。对于人造天体，如人造地球卫星、绕月卫星和深空探测器等的VLBI测轨，则利用VLBI观测值，综合测距、测速数据，进行精确的轨道测定。
TODOVLBI | NAOJ: National Astronomical Observatory of Japan - English
]]></content>
      <categories>
        <category>VLBI</category>
      </categories>
      <tags>
        <tag>vlbi</tag>
        <tag>mas</tag>
      </tags>
  </entry>
  <entry>
    <title>清晨8问夜晚8思８大自我提醒８大生活信念</title>
    <url>/2006/12/21/book-8-good-habits/</url>
    <content><![CDATA[清晨8问
我今天的目标是什么？
我的人生终极目标是什么？
今天最重要的一件事情是什么？
我今天如何和周围的人相处？
我今天要学那些新知识？
我今天要有怎样的心情？
我今天怎么比昨天过得更好？
我应该对什么心存感激？

夜晚8思
我今天是否完成了我的小目标？
我离我的大目标又更近一步了吗？
今天发生的一切对我有什么好处？
我如何才能活得更好？
今天我做事情竭尽所能了吗？
我明天的目标是什么？
我对生活中还有那些不满？
我应该为什么感到自豪？

８大自我提醒
人是为梦想而活，不是为金钱和名利而活。
你的内心改变了你的世界也就改变了。
永远不要放弃对成功的追求！
要让事情变好先让自己变好。
山不过来我就过去。
失败是从你放弃开始的！
要认真要快要全力以赴！
我对我生命完全负责!

８大生活信念
我是最棒的，我一定能成功！
成功是应为态度。
我要，我就能。
过去不等于未来。
不是不可能，只是暂时没找到方法。
成功者找方法，失败者找借口。
坚持到底永不放弃。
立即行动。

]]></content>
      <categories>
        <category>读书</category>
      </categories>
      <tags>
        <tag>人生</tag>
        <tag>励志</tag>
        <tag>心态</tag>
        <tag>时间</tag>
        <tag>目标</tag>
      </tags>
  </entry>
  <entry>
    <title>天文学推荐读物</title>
    <url>/2018/05/08/astronomy-radio-recommend-reading/</url>
    <content><![CDATA[[TOC]
天文学推荐读物射电天文学下面的这些书大部分为射电天文学，部分包含射电干涉。

Synthesis Imaging in Radio Astronomy II, G.B Taylor, C.L. Carilli, &amp; R.A. Perley eds, Astronomical Society of the Pacific Conference Series Volume 180.
The Fourier Transform and its Applications, R.N. Bracewell.
Interferometry and Synthesis in Radio Astronomy, A.R. Thompson, J.M. Moran &amp; G.W. Swenson.
Radio Astronomy, J.D. Kraus.
Radiotelescopes, W.N. Christiansen &amp; J.A. Högbom.
Tools of Radio Astronomy, K. Rohlfs &amp; T.L. Wilson.
Essential Radio Astronomy, James J. Condon &amp; Scott M. Ransom,2016
Very Long Baseline Interferometry Techniques and Applications, Marcello Felli, Ralph E. Spencer
Very Long Baseline Interferometry and the VLBA, Napier, Diamond &amp; Zensus

用射电望远镜可以做那些科学，参考一下书籍：

Galactic and Extragalactic Radio Astronomy, G.L. Verschuur &amp; K.I. Kellermann eds.

An Introduction to Radio Astronomy, B.F. Burke &amp; F. Graham-Smith.

Leiden Radio Classes materials



参考：www.atnf.csiro.au

]]></content>
      <categories>
        <category>Radio</category>
        <category>Astronomy</category>
      </categories>
      <tags>
        <tag>interferometry</tag>
        <tag>radio</tag>
        <tag>telescope</tag>
        <tag>imaging</tag>
        <tag>synthesis</tag>
        <tag>fourier tranform</tag>
      </tags>
  </entry>
  <entry>
    <title>不做乔布斯，做最好的自己</title>
    <url>/2015/03/24/book-applause-ppt/</url>
    <content><![CDATA[让掌声响起来-PPT制作达人速成真正的PPT模板，都是通过母版制作来实现的。
所以，其实对于PPT而言重要的在于母版的制作。
]]></content>
      <categories>
        <category>读书</category>
      </categories>
      <tags>
        <tag>PPT</tag>
      </tags>
  </entry>
  <entry>
    <title>小行星会撞地球吗</title>
    <url>/2007/04/07/book-asteroid-strike-earth/</url>
    <content><![CDATA[小行星会撞地球吗小行星小行星（asteroid）是太阳系内类似行星环绕太阳运动，但体积和质量比行星小得多的天体。太阳系中大部分小行星的运行轨道在火星和木星之间，称为小行星带。另外在海王星以外也分布有小行星，这片地带称为柯伊伯带（Kuiper Belt）。
主要成分为岩石、金属、碳以及冰块。
多数小行星的个头很小，只有小石块那么大，小行星带中最大的小行星为谷神星，直径933km。
由于在太阳系中的位置不同，小行星被分为四个不同的组别：

主带小行星：约90%已知的小行星的轨道位于小行星带中。小行星带是一个相当宽的位于火星和木星之间的地带。谷神星、智神星等首先被发现的小行星都是小行星带内的小行星；

特洛伊型小行星：在其它行星轨道的拉格朗日点上运行的小行星被称为特洛伊小行星。最早被发现的特洛伊小行星是在木星轨道上的小行星，它们中有些在木星前，有些在木星后运行。有代表性的木星特洛伊小行星有小行星588和小行星1172。1990年第一颗火星特洛伊小行星小行星5261被发现，此后还有其它四颗火星特洛伊小行星被发现。

半人马天体：土星和天王星之间的小行星有一群被称为半人马小行星群的小行星，它们的偏心率都相当大。最早被发现的半人马小行星群的小行星是小行星2060。估计这些小行星是从柯伊伯带中受到其它大行星的引力干扰而落入一个不稳定的轨道中的。

近地小行星：运行的轨道使其与地球的轨道特别靠近，甚至有机会撞向地球：

阿莫尔型小行星群：这一类小行星穿越火星轨道并来到地球轨道附近。其代表性的小行星是1898年发现的小行星433，这颗小行星可以到达离地球0.15天文单位的距离。1900年和1931年小行星433来到地球附近时天文学家用这个机会来确定太阳系的大小。1911年发现的小行星719后来又失踪了，一直到2000年它才重新被发现。这个小行星组的命名星小行星1221阿莫尔的轨道位于离太阳1.08到2.76天文单位，这是这个群相当典型的一个轨道。

阿波罗小行星群：这个小行星群的小行星的轨道位于火星和地球之间。这个组中一些小行星的轨道的偏心率非常高，它们的近日点一直到达金星轨道内。这个群典型的小行星轨道有1932年发现的小行星1862阿波罗，它的轨道在0.65到2.29天文单位之间。小行星69230在仅1.5月球距离处飞略地球。

阿登型小行星群：这个群的小行星的轨道一般在地球轨道以内。其命名星是1976年发现的小行星2062阿登。有些这个组的小行星的偏心率比较高，它们可能从地球轨道内与地球轨道相交




通过光谱分析所得到的数据可以证明小行星的表面组成很不一样，按照光谱的特性小行星可以分为：

C-小行星：这种小行星占所有小行星的75%，因此是数量最多的小行星。C-小行星的表面含碳，反照率非常低，只有0.05左右。一般认为C-小行星的构成与碳质球粒陨石（一种石陨石）的构成一样。一般C-小行星多分布于小行星带的外层。
S-小行星：这种小行星占所有小行星的17%，是数量第二多的小行星。S-小行星一般分布于小行星带的内层。S-小行星的反照率比较高，在0.15到0.25之间。它们的构成与普通球粒陨石类似。这类陨石一般由硅化物组成。
M-小行星：剩下的小行星中大多数属于这一类。这些小行星可能是过去比较大的小行星的金属核。它们的反照率与S-小行星的类似。它们的构成可能与镍–铁陨石类似。
E-小行星：这类小行星的表面主要由顽火辉石构成，它们的反照率比较高，一般在0.4以上。它们的构成可能与顽火辉石球粒陨石（另一类石陨石）相似。
V-小行星：这类非常稀有的小行星的组成与S-小行星差不多，唯一的不同是它们含有比较多的辉石。天文学家怀疑这类小行星是从灶神星的上层硅化物中分离出来的。灶神星的表面有一个非常大的环形山，可能在它形成的过程中V-小行星诞生了。
地球上偶尔会找到一种十分罕见的石陨石，HED-非球粒陨石，它们的组成可能与V-小行星相似，它们可能也来自灶神星。
G-小行星：它们可以被看做是C-小行星的一种。它们的光谱非常类似，但在紫外线部分G-小行星有不同的吸收线。
B-小行星：它们与C-小行星和G-小行星相似，但紫外线的光谱不同。
F-小行星：也是C-小行星的一种。它们在紫外线部分的光谱不同，而且缺乏水的吸收线。
P-小行星：这类小行星的反照率非常低，而且其光谱主要在红色部分。它们可能是由含碳的硅化物组成的。它们一般分布在小行星带的极外层。
D-小行星：这类小行星与P-小行星类似，反照率非常低，光谱偏红。
R-小行星：这类小行星与V-小行星类似，它们的光谱说明它们含较多的辉石和橄榄石。
A-小行星：这类小行星含很多橄榄石，它们，主要分布在小行星带的内层。
T-小行星：这类小行星也分布在小行星带的内层。它们的光谱比较红暗，但与P-小行星和R-小行星不同。

冥王星冥王星，或被称为134340号小行星，于1930年1月由克莱德·汤博根据美国天文学家洛韦尔的计算发现，并以罗马神话中的冥王普路托（Pluto）命名。它曾经是太阳系九大行星之一，但后来被降格为矮行星。与太阳平均距离59亿千米。直径2300千米，平均密度2.0克左右/立方厘米，质量1.290×10^22 千克。公转周期约248年，自转周期6.387天。表面温度在-220°c以下，表面可能有一层固态甲烷冰。
2006年8月24日，该行星经在布拉格举行的国际天文联合会(IAU)的讨论，从九大行星行列中排除，正式降格为矮行星，因为最近在太阳系边缘发现了小行星带，那里许多小行星都比冥王星大，而且主要是当时汤博计算其质量错误。
矮行星：或称“侏儒行星”，体积介于行星和小行星之间，围绕太阳运转，质量足以克服固体应力以达到流体静力平衡（近于圆球）形状，没有清空所在轨道上的其他天体，同时不是卫星。矮行星是一个新的分类。定义的标准尚不明确。
行星

一是必须围绕太阳运转的天体；
二是质量足够大，能依靠自身引力使天体呈圆球状；
三是其轨道附近应该没有其他物体。


Mark：其中冥王星不满足第三条，因为其轨道与海王星有交集。

科学家证实，大到足以影响整个地球的撞击一般10万年才能发生一次。
彗星当靠近太阳时能够较长时间大量挥发气体和尘埃的一种小天体。由冰冻物质和尘埃组成。当它靠近太阳时即为可见。太阳的热使彗星物质蒸发，在冰核周围形成朦胧的彗发和一条稀薄物质流构成的彗尾。由于太阳风的压力，彗尾总是指向背离太阳的方向。
彗星的轨道有椭圆、抛物线、双曲线三种。
由于每次接近一次太阳，彗星便损失一些气体和尘埃，所以最终可能消失。
彗星上的水：当数十年太阳刚形成时，行星都非常热，水和大气都消失在了太空中，即使地球上也没有空气和水，在形成之后很短的时间里，行星受到了来自小行星及彗星的撞击，彗星中含的水和气体在撞击中被释放出来。
彗星与流星的区别★ 彗星(Comet)彗星的本体主要是由冰冻的气体和微尘所组成，也因此有「脏雪球」的称号，它的直径通常只有数公里左右，10公里以上的就算非常巨大了，而它的轨道多为扁长的椭圆形或是抛物线，前者绕行太阳一圈的时间从几年到几万年以上都有，后者则在造访太阳一次之后就永远都不会回来了；平时的彗星因为距离太阳较远，因此都处於冰冻的状态，且光度极为黯淡，但只要一进入到地球的轨道附近，与太阳的距离缩短之后，就会开始活泼起来，同时释出许多的微尘形成彗发和彗尾，体积非常巨大，最大的甚至可以和太阳相较，但其密度却稀薄的比地球上所能制造的「真空」还要小。
肉眼即可见到的大彗星不会太常出现，但能用望远镜或摄影观测的彗星每年都会有一、二十个以上，若偶尔出现壮观明亮的大彗星时，就会引起广大的天文热潮，如前几年的百武彗星和海尔‧波普彗星即是，不过除了周期76年的哈雷彗星之外，能够引起大众注意的几乎全是非周期彗星(指周期大於200年或不会回归的彗星)了；2004年5月时预计将有2颗亮度达到1等以上的大彗星，在日落后将同时出现於西方天空，此一难得的天文奇观值得期待。
★ 流星(Meteor)流星的本体主要是一些漫游在太空中的灰尘微粒，体积非常的小，有些甚至小到连肉眼都看不见，它们因受到地球引力的吸引而掉落到地球上，通常以秒速1171公里的速度进入地球的大气层，和大气摩擦产生的高热便足以将它们本身汽化消失，并因为电子遭到激发而散发光芒，发光的高度约在80120公里左右，且只要几公厘的大小就可以很明亮了；而质量较大的流星体，或亮度在-2等以上的大流星我们通常称为「火球」或「火流星」，其中有些会在中途因爆炸而大量增光，有时甚至还能听到声音，有些明亮的流星在划过后会留下淡淡的流星痕，规模较大的还可以持续数分钟之久，而后将随著高空的强风而慢慢的散开消失。
平常的夜晚我们常常能看到几颗散落的流星飞过孤寂的夜晚，但除了这些随机出现的流星外，有时候在短时间之内会出现大量的流星(每小时数十颗以上)，并且都自同一个辐射点向外飞出，这就是我们所谓的「流星雨」；流星雨是在地球穿过一群彗星经过后而遗留下来的微尘时所发生的，能造成流星雨的彗星必须轨道和地球相交，因此我们常说彗星就是流星的母亲；每年地球都会定期的穿过某些流星群而形成流星雨(Meteor Shower)，
其中较为著名的有象限仪座(天龙座ι)流星雨、英仙座流星雨、狮子座流星雨和双子座流星…等，流星雨的命名方式通常以辐射点的位置而定，其每小时的流星数(ZHR)通常在几颗到上百颗不等，有时候还会出现罕见的「流星暴」现象，每小时的流星数可以到达1000颗甚至数十万颗以上，非常壮观；而其中最为著名的狮子座流星雨每隔33年就会有一次持续几年的极大期，在极大时就很有可能出现流星暴的盛况。
]]></content>
      <categories>
        <category>Book</category>
      </categories>
      <tags>
        <tag>Comet</tag>
        <tag>Meteor</tag>
        <tag>asteroid</tag>
        <tag>冥王星</tag>
        <tag>小行星</tag>
        <tag>彗星</tag>
        <tag>流星</tag>
        <tag>行星</tag>
      </tags>
  </entry>
  <entry>
    <title>改变世界是一种信仰：乔布斯和他的苹果神话</title>
    <url>/2015/04/10/book-change-world-is-a-faith/</url>
    <content><![CDATA[改变世界是一种信仰：乔布斯和他的苹果神话人类的文明史记录了三个关于苹果的重要故事：

亚当夏娃头吃苹果，人类因此有了智慧 –神话
苹果砸到牛顿，有了万有引力 –传说
史蒂夫乔布斯缔造苹果电脑  –真实故事


这辈子没法做太多事情，所以每一件都要做到精彩绝伦。


我们的目标并不在于制造出市场上最廉价的产品，而是制造出最优秀的产品。

苹果能制造出像iPod这样的产品，就是因为我们一直试图站在人文艺术和科学技术的交汇处，博采众长。
所有的产品一定会离开苹果商店但不能离开苹果系统，我们要帮助客户持续使用苹果产品，知道寿终正寝。
苹果不仅贩卖产品，更在贩卖一种文化。
细节的准确、生动可以成就一件伟大的作品。
创新不是创新者创出来的东西，而是消费者实际采纳的东西。
苹果创新的核心：简约。iPod放弃了屏幕，iPhone放弃了手写笔，iPad放弃了鼠标，iMac放弃了软盘，MacBook Air放弃了光驱。
有时生活会当头给你一棒，但不要灰心，我坚信让我一往无前的唯一力量就是我热爱我所做的一切。
让自己真正满意的唯一办法，是做自己认为有意义的工作；做有意义的工作的唯一办法，是热爱自己的工作。如果你还没有发现自己喜欢什么，那就不断地去寻找，不要急于做出决定。就像一切要凭着感觉去做的事情一样，一旦找到了自己喜欢的事情，感觉就会告诉你。
记住自己随时都会死掉，是防止你陷入畏首畏尾陷阱的最好方法。。。你已经一无所有了，没有理由不去追随你的心。
活着就是为了改变世界。
内心的喜好是推动事业进步的最大动力，它能帮你克服困难，坚持到底。如果你喜欢的事情有很多，要挑选自己最擅长做的事情，这样就能在感受快乐的同时取得超乎常人的成就。

如果你把每一天当做生命的最后一天过，总有一天你的假设会成为现实。

]]></content>
      <categories>
        <category>读书</category>
      </categories>
      <tags>
        <tag>读书</tag>
        <tag>MacOSX</tag>
        <tag>乔布斯</tag>
        <tag>库克</tag>
        <tag>苹果</tag>
        <tag>iMac</tag>
        <tag>iPad</tag>
        <tag>iPhone</tag>
      </tags>
  </entry>
  <entry>
    <title>循序渐进学Docker</title>
    <url>/2018/03/15/book-docker-learn-docker-step-by-step/</url>
    <content><![CDATA[循序渐进学Docker - 读书笔记第1章　全面认识DockerDocker使用容器引擎解决平台依赖问题，它在每台宿主机上都启动一个Docker的守护进程，守护进程屏蔽了与具体平台相关的信息，对上层应用提供统一的接口。
Java曾提出 Write once， Run anywhere，而Docker提出了 Build once， Run anywhere， Run anything
所以docker的含义就是管理软件部署的应用，把应用打包成一个镜像，镜像带有版本控制功能，每次的修改迭代都对应一个版本，制作好的镜像可以发布到镜像库，供别人使用。
第2章　初步体验Docker第3章　Ubuntu下使用DockerDocker是在Ubuntu下诞生和发展的，所以Docker的最新特性都是在Ubuntu下开发和测试的，所以Ubuntu是支持Docker最好的操作系统。
不过现在Docker支持各大主流操作系统，作为生产环境，还是使用REHL或者CentOS，红帽系列正合我意。
这里需要注意的是，如果不希望每次都输入sudo命令，需要把用户user加入到docker组中，命令如下：
$ sudo usermod -aG docker user


其中user为用户名，重启就可以生效了。

参考sameersbn/docker-gitlab来了解如何搭建gitlab的docker环境。
第4章　Docker的基础知识第5章　Docker容器管理第6章　Docker镜像管理第7章　Docker仓库管理第8章　Docker网络和存储管理第9章　Docker项目日常维护第10章　Docker Swarm容器集群第11章　Docker插件开发第12章　Docker离线系统应用案例第13章　Etcd、Cadvisor和Kubernetes实践第14章　构建Docker高可用及自动发现架构实践第15章　Docker Overlay Network实践第16章　Docker源码探索]]></content>
      <categories>
        <category>读书</category>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Uranus</tag>
        <tag>Venus</tag>
      </tags>
  </entry>
  <entry>
    <title>其他星球上有生命吗</title>
    <url>/2007/04/18/book-earth-live/</url>
    <content><![CDATA[其他星球上有生命吗太阳是太阳系的中心，是距离我们最近的恒星。
9颗大行星围绕太阳旋转，有160多颗卫星分别围绕行星旋转。
行星行星通常指自身不发光，环绕着恒星的天体。其公转方向常与所绕恒星的自转方向相同。一般来说行星需具有一定质量，行星的质量要足够的大且近似于圆球状，自身不能像恒星那样发生核聚变反应。
“行星”的新定义，这一定义包括以下三点：

必须是围绕恒星运转的天体；
质量必须足够大，来克服固体应力以达到流体静力平衡的形状（近于球体）；
必须清除轨道附近区域，公转轨道范围内不能有比它更大的天体

一般来说，行星的直径必须在800公里以上，质量必须在5亿亿吨以上。
按照这一定义，目前太阳系内有8颗行星，分别是：水星Mercury、金星Venus、地球Earth、火星Mars、木星Jupiter、土星Saturn、天王星Uranus、海王星Neptune。
分类类地行星水星、金星、地球、火星。
顾名思义，类地行星的许多特性与地球相接近，它们离太阳相对较近，质量和半径都较小，平均密度则较大。类地行星的表面都有一层硅酸盐类岩石组成的坚硬壳层，有着类似地球和月球的各种地貌特征。对于没有大气的星球（如水星），其外貌类似于月球，密布着环形山和沟纹；而对于像有浓密大气的金星，则其表面地形更像地球。
行星早在史前就已经被人类发现了，后来人类了解到，地球本身也是一颗行星。
巨行星和远日行星木星和土星是行星世界的巨人，称为巨行星。它们拥有浓密的大气层，在大气之下却并没有坚实的表面，而是一片沸腾着的氢组成的“汪洋大海”。所以它们实质上是液态行星。天王星，海王星这两颗遥远的行星称为远日行星，是在望远镜发明以后才被发现的。它们拥有主要由分子氢组成的大气，通常有一层非常厚的甲烷冰、氨冰之类的冰物质覆盖在其表面上，再以下就是坚硬的岩核。根据上述这一定义，冥王星失去行星地位。
]]></content>
      <categories>
        <category>读书</category>
      </categories>
      <tags>
        <tag>Uranus</tag>
        <tag>Venus</tag>
        <tag>Mars</tag>
        <tag>Jupiter</tag>
        <tag>Earth</tag>
        <tag>Mercury</tag>
        <tag>Neptune</tag>
        <tag>Saturn</tag>
      </tags>
  </entry>
  <entry>
    <title>吃掉那只青蛙</title>
    <url>/2020/02/06/book-eat-that-frog/</url>
    <content><![CDATA[吃掉那只青蛙：博恩·崔西的高效时间管理法则（原书第3版）
博恩·崔西

1）人生一定要有梦想，因为它一定会实现。梦想再大也不嫌大，追梦的人再小也不嫌小，每年年初给自己做一个梦想板，把今年的梦想或目标可视化，激励自己每天向它靠近。（2）人生不在于做多少事，而在于把重要的事做到极致。事情是永远做不完的，我们只能有选择地做最重要的事。每天挑出最重要的3件事优先完成，每天花80%的时间和精力吃掉3只青蛙，然后花20%的时间和精力处理杂事，这就是能让我们人生快速出成果的二八法则。（3）没有愿景，一切都是空想；没有行动，一切都是噩梦。行动力是我们获得成功的关键：烂开始、好开展、好结果。把一个巨大的目标分解成可以马上行动的一个个小步骤，一步一步地迈进，最终就能走到你想到达的地方。（4）精力管理是时间管理的基础，身体健康才能保证做事高效，所以为了确保自己每天都有充足的精力应对挑战，我倡导大家一定要养成“3+1”的人生基础习惯：早睡早起、健康饮食、运动健身+正念·冥想。
前言你永远不可能完成所有事情，也永远无法完成你要做的所有任务。对你来说，完成所有任务，然后全身心地放松、享受休闲时光，似乎是一个遥不可及的梦。
你只有学会放弃，把时间和精力放在那些能够改变你生活的重要事情上，才能有效地安排你所要面对的那些事情。
集中精力去完成最重要的事情，彻底地完成它们，并把它们做好，这是人一生取得巨大的成功、成就，赢得受人尊重的社会地位，获取幸福感的关键所在。
成功的关键在于行动，这些原理可以帮助你快速地实现个人绩效的增长，完成可预测的结果，你越快掌握这些技巧和原理，并把它们运用在实际的工作和生活中，你在职业道路上就会进步得越快，比别人更早地突破职业天花板
引言曾经有一句谚语说的是，如果你每天早上醒来做的第一件事情是吃掉一只活的青蛙，你就会欣喜地发现，在这一天接下来的时间里，将没有什么比这个更糟糕的事情了。这只“青蛙”就意味着你最艰巨、最重要的任务。如果你不对最艰巨的任务立刻采取行动的话，很可能你会因为它耽误很多时间。吃掉你的“青蛙”也可能会对你目前的生活产生最大的积极影响。
为了养成专注的习惯，你需要具备3种品质：决定（decision）、自律（discipline）和决心（determination）
首先，下定决心养成做事有始有终的习惯。其次，约束自己反复练习那些想要学习的原则，直至完全掌握为止。最后，无论做什么事情，都要坚定不移，直至养成这种习惯，并使之成为你性格中不可分割的一部分。
要想更快成为你理想中的高效能人士，这里有一种特殊的方法。你可以不断地在大脑中想象：你已经是一个踌躇满志、马上行动、处事果断、专注的人，你的回报和收益将会如何。你要经常把自己想象成为一个挑大梁的人，而且总是能够迅速而又圆满地完成你的各项工作。在大脑中为自己勾画的蓝图，会对自己的行为产生至关重要的作用。因此，一定要把自己想象成为你理想中的人。你在内心为自己刻画的形象，以及你对自己的评价，在很大程度上决定着你的外在表现如何。你能看到什么样的人，你就会成为什么样的人。事实上，每个人学习新技能、培养新习惯、挖掘新能力的潜力都是无穷的。如果能通过反复练习，培养自己克服拖延、迅速完成最重要任务的习惯，你就将进入工作和生活的快车道，踏上成功的加速器。
书面目标的魔力一个人对自己的目标越明确，对实现目标的步骤越清晰，就越容易克服拖延的弊病，
茫然、思维混乱、态度模糊……比如一个人不知道自己应该做什么、应该先做什么后做什么、为什么做这些事情，都是造成他拖延和缺乏积极态度的主要因素。只有积极地寻找更明确的目标和任务，才能克服这些常见的问题。如果一个人对自己想要什么非常明确，他会更清楚地知道如何才能实现自己的目标，会更容易克服拖延的弊病，实现目标。
把目标写在纸上。
研究表明：大约只有3%的成年人拥有明确的目标，并把目标用书面化的方式记录下来。但在受教育程度和能力相等的条件下，那些写下自己目标的人，比没有写下自己目标的人的成就高出5～10倍。
有一个方法对设定并实现自己的目标非常有效，你也可以在自己的生活中运用这一方法。该方法包括7个简单的步骤。
第一步：明确你究竟想要什么。你可以自己决定自己究竟想要什么，也可以和你的老板坐下来，就你为自己设定的目标进行讨论，直到你彻底弄清楚自己应该做些什么，应该按照什么顺序来做这些事情为止。
最糟糕的利用时间的情形之一，是把根本不需要做的事情做得很完美。
第二步：把你的目标写下来。也就是说，将你的想法付诸笔端。一方面，当你把目标写在纸上以后，你为自己制定的目标就清晰化、具体化了。你为自己创造了一个能看得见、摸得着的东西。
第三步：为你的目标设定一个完成的最后期限；在必要的情况下，设定出子目标的期限。一个目标或者决定如果没有应该完成的最后期限，就没有紧迫性，没有真正的起点和终点。如果没有一个最后期限，以及相应的应该完成的任务，你做起事情来就会不由自主地拖延，
第四步：为了实现目标，把你所能想到的、所有要完成的事项都列在一个清单上。只要你一想起新的活动，就添加到清单上。然后不断地完善你的清单，直到把所有事项罗列完整为止。这样的一份清单能够将你的目标和任务具象化。
第五步：进一步梳理整个清单，使之成为一份计划。根据优先级顺序来整理计划。请你花一点时间，决定什么事情要放在其他事情之前做，什么事情应该先做，什么事情可以往后放。这里还有一个更有效的方法：你需要在一张单页纸上，把计划中的任务用一系列具象的方框或圆形的流程符号表示出来，然后用直线和箭头把每个任务连接起来，标明相互之间的关系。
第六步：根据计划马上采取行动。你应该马上做点什么事情，做什么都行。即使这个计划平淡无奇，只要你充满激情地按照计划执行，就好过制订一份出色的计划，却无任何行动。
第七步：每天解决一部分问题，向前推进主要目标的实现。你需要在每日行动表中列出一天的活动。
明确的书面目标对你的思想有不可思议的影响力。它能激励你不断地采取行动，它能像其他要素那样，激发你的创造力，释放你的能量，帮助你克服拖延症。
现在就拿出一张纸来，列出你明年最想实现的10个目标。在写下这些目标的时候，设想着明年已经过去，这些目标已经实现。
然后，检查你前面列出的10个目标，并从中挑出一个，设想一下如果这个目标实现了，就会对你的生活产生最大程度的积极影响。无论这个目标是什么，都把它写在另外一张纸上，给这个目标设定一个实现的最后期限，然后制订一份计划，并针对计划采取相应的行动，而且坚持每天都做一些有助于你实现这一计划的事情。坚持去做，这项练习会改变你的生活。
提高回报率你在脑海中思考如何行动，制订出计划并做出决定，是你克服拖延症、提高生产力的最有效的手段。这些行动可能包括明确目标、制订计划、采取行动，所有这一切会决定你的生活轨迹。对如何行动进行思考，并进行周密计划的过程会释放你心智中的潜能，激发你的创造力，增强你精神和身体的力量。
计划制订得越周密，你就越容易克服拖延症、迅速行动、吃掉青蛙，并能不间断地保持行动的状态
据观察，每拿出一分钟制订计划，在行动时将会节省出相当于制订计划10倍的时间。所以，每天你只要拿出10～12分钟来制订计划，就能节省出将近两小时的时间（约为100～120分钟）。
不管你是借助最先进的掌上电脑、最复杂的电脑程序，还是借助时间管理器来工作，原理都是一样的：在开始工作之前先坐下来，把你要做的每一件事情都逐条写出来。
无论你准备做什么，都应该先列出一份清单。每次想到什么新的事项，在开始做之前都先把它加在清单上。如果你一直坚持先列出清单再开始工作，那么，从一开始你的生产力就能提高25%，相当于每天节省出两小时。当前一天的工作结束以后，要开始制订第二天的计划。把尚未完成的事项、需要在第二天完成的事项，都写在第二天的计划上。当你在前一天晚上制订了计划之后，即使你入睡了，你的潜意识也会围绕这个计划转。通常情况下，当你第二天早上醒来时，你的脑海中就会涌现出灵感，从而使你能更快、更好地完成工作。在制订必须完成的工作计划上，你提前花费的时间越多，你的工作效率、工作的有效性就越高。
你需要针对不同的目标制订不同的计划。首先，你必须拟订一份总计划，在这份计划上，你把能想到的、未来能做的每一件事情都写下来。在这份总计划上，你要写下脑海中想到的所有任务以及相应的职责。之后你可以对计划中的事项做进一步整理。其次，你应该在每个月月末，为下一个月要做的工作制订一份每月计划。其中的某些事项可以是从总计划上分解到这里的。再次，在每周工作开始前，你要提前制订一份每周计划，来计划一周的工作。每周计划是基于你对整周工作的统筹而制订的。
不论你要完成什么项目，都应该在行动之前先制订一份计划，在这份计划上把你要完成的工作、所需要执行的每一步工作都写下来，然后根据它们的重要程度安排先后顺序。
个人高效能工作的最重要的法则之一是10/90法则，即整个工作的前10%的时间用于制订计划、组织工作，那么在实际完成工作的过程中将节约90%的时间。

从今天开始，你要对每个月、每一周、每一天的工作提前制订计划。请拿出一个记事本或一张白纸（也可以用你的电子助手或手机上的软件），把未来24小时内要做的所有事情都列在上面。当你随时想起需要添加的事项时，就把它们写进去。把所有关系到你未来的重大项目写下来，放在一个单独的清单里。2. 把每一项主要目标和任务都写在计划上，然后根据优先级和时间顺序，把最重要的和需要最早完成的排在前面。然后安排次重要的，并以此类推。最后以计划的终点倒推工作的起点。

任务的数量vs任务的重要性80/20法则是时间管理与生活管理方面最有用的概念之一。
通常来讲，如果在一张项目计划上列出10项任务，其中一项你必须完成的任务远比其他9个剩下的任务更有价值。那么这项任务就是你应当最先吃掉的青蛙
很多人的拖延清单中最多的就是能产生最大价值的最重要的10%～20%的项目，这些项目是“极重要的少数”。人们忙碌于那些不重要的80%的项目部分，在对回报没有太大影响的“不重要的多数”工作上花了很长时间。
你常常能够看到有的人终日忙忙碌碌，但几乎看不到工作的结果。这几乎可以全部归因于：他们忙碌的是一些低价值的任务，但对某项重要的活动却一再拖延。如果他们能又快又好地完成这些重要的活动，无论对公司还是他们个人的事业都会产生实质性的、重大的影响。每天你能完成的最重要的任务通常是最艰难、最复杂的任务，但是，圆满地完成这些任务所带给你的回报和奖励也是巨大的。鉴于此，如果你还有最重要的20%的工作没有完成，你必须坚定地拒绝做重要性很低的那80%的工作。
抵制诱惑，不被小事所引诱。你要记住，不管你选择先完成什么任务，久而久之都会形成一种固化的习惯。如果你选择每天先做低价值的任务，你将很快养成先做低价值任务的习惯。这一定不是你希望养成或保持的习惯。你要在一开始就处理重要的任务中最难的部分。一旦你开始处理最有价值的任务，你才会很自然地有兴趣继续往下做。如果你在思想上愿意为了有意义的任务来忙前忙后地工作的话，那么你会看到完全不同的结果。然后你要通过不断地以这种思维工作，进一步强化头脑中的这种意识
如果你在脑海中设想一下，开始完成重要的任务以及完成了重要的任务的场景，你就能以此激励自己，战胜拖延症。事实上，完成一项重要的工作所需要的时间与完成一项不重要的工作所需的时间通常是一样的。区别是你完成重要的、有意义的工作能获得极大的自豪感和满足感。然而，当你完成一项低价值的工作时，即使耗费了同样多的时间和精力，你也只能得到很少的满足感，甚至一点满足感也得不到。

制订一份计划，在上面列出今天你所有关键的目标、活动、项目、生活上的责任。有没有可能在这些任务中，最重要的10%～20%代表了或可能代表了你80%～90%的结果？2. 今天就来解决这个问题：对于可以改变你的人生和事业的少数活动，你应该花费越来越多的时间；对于不会影响你的人生和事业的低价值的大量活动，你花费的时间应该越来越少

对时间的配置做出更好的安排成功基于个人对于时间的态度，不论是工作还是生活，成功人士在做每天、每周、每月的活动规划时，都会用长期的观点去考量。
你对时间的处理态度、你的“投资回报期”会对你的行为和选择产生重大的影响。与没有长期时间观念的人相比，能够运用长期时间观念规划生活和职业前途的人似乎能对自己的时间和活动做出更好的决定。
成功人士是那些懂得延迟满足感，愿意做出短期牺牲来追求长期高回报的人。
不断地鼓舞自己，激励自己。如果一项活动或行为会对你的生活产生重大的、积极的影响，那么一旦你清晰地锁定目标，你会不断地被激励，从而有动力克服拖延症，并迅速把它做好。然后，持续地启动、完成那些能对你的公司和未来产生重大影响的任务，你会集中精力、勇往直前。
经常思考你做出的选择、决定和行为是否能产生积极的发展前景及对未来的影响，这是确定你的工作和个人生活中的优先级顺序的最好方法之一。
强迫效率法则的详细解释是：“时间有限，任何人都无法做完所有的事情。但只做那些以后能获得正面效果的工作，做与完成最大目标有关的工作，你的时间是足够的。”换句话说，你无法吃掉池塘里的所有蝌蚪和青蛙，但是在当下，你能吃掉最大、最丑陋的那只就够了。
一个人如果在最后期限的压力下工作，通常他会不由自主地拖延，也会承受更大的压力、犯更多的错误，比无压力状态下的返工率更高。
如果你想专注地完成计划上最重要的任务，每次要问自己3个固定的问题。第一个问题是，“我的最高价值的工作是什么？
第二个问题：“我只有把哪件事情做好了才会产生非凡的影响？
第三个问题是：“在此时此刻，对我来说最有价值的事情是什么
第三个问题是时间管理的核心问题。能否正确地回答这个问题，是一个人克服拖延症、成为一个高效率的人的关键。每一天中的每个小时，你当时完成的任务，代表着你利用那段时间的最大价值。你要反复问自己第三个问题，要不厌其烦地一次次地重复问自己，不管答案是什么，都要不断地着手处理它。

回顾一下你的相关任务、活动、项目。不断重复地问自己：“在工作或个人生活中，我出色又及时地完成哪一项项目/活动，会给我带来极大的正向回报呢？”2. 每天的每个小时，你要决定这个时间单元最重要的事情是什么，然后约束自己不断地将时间用在最有价值的工作上。思考下一步最重要的事情又是什么，如此循环。不管接下来要做的工作是什么，都把它设定为一个目标，为此制订一项计划，并立刻行动去完成这项计划。记住歌德的那句名言：“只有找到能够吸引你、让你燃起内心激情的部分，并马上投入其中，你才能完成你的工作。”

优先级高低之分每天都抽出时间推进那些艰巨任务的实施。提前计划好一天的工作量，用最高效的时间完成最重要的工作。每天早晨先挑选出一些最紧迫的简单工作，继而直接开始完成大任务，专注地去做，一直到完成为止。
事实上，每个人都不可能做完所有的事情。你必须有选择地去延迟完成一些事情，一些简单任务不立刻去完成，而是实行创造性拖延。也就是说，有些事情必须向后拖延。选出一些较小、不太丑的“青蛙”，向后推迟一段时间再吃。把那些最大、最丑的“青蛙”安排在第一时间吃掉。先处理最艰难、最复杂的任务
当你不再去做那些低优先级的工作时，你的时间和生活才能完全掌握在自己手中。
大多数人都会无意识地拖延，人们的拖延往往是没有经过周密考虑的结果。这会导致人们拖延工作量浩大的、高价值的、重要的任务，从长期来看，这些任务将对他们的事业和生活产生重大的影响。因此，你必须想尽一切办法，避免这些跟别人趋同的规律发生在你身上。你的任务就是，对那些优先级低的任务进行拖延，从而可以腾出更多的时间来做那些改变你的工作和生活的任务。

在生活的各个方面，你都可以应用归零思考法（zero-based thinking）来思考问题。不断地问自己：“如果我还没有开始做这件事情，而且我已经知道做完的后果，今天我还会如此这般再做一次吗？”如果答案是否定的，那么这件事就应该创造性拖延或取消。2. 根据你目前的状况，重新审视、评估你工作和生活中的活动，挑出其中至少一项，立刻放弃，或者创造性拖延，直到你完成那些更重要的事情为止。一边思考，一边把你思考的结果写在纸上

成功的第一定律是专注，是把所有精力聚焦在一点上，然后向着这一点的目标努力推进，不要瞻前顾后。
在开始处理一项工作之前，你在制订计划、设定优先顺序方面投入得越多，你所做的事情就越重要，一旦开始工作，你的效率就越高。你所从事的工作越重要、越有价值，你克服拖延症、全力投入该工作的劲头也就越足。

现在，回顾你的工作计划，然后在每一项任务或工作之前标上A、B、C、D或E。选择标记为A-1的工作或任务，然后立即动手处理，切记必须在完成这项工作之后再开始做其他工作。2. 在接下来的一个月，每天都练习使用ABCDE法来处理每一项工作。这样坚持一个月以后，你就会养成先处理优先级最高的任务的习惯，你的未来就会尽在掌握之中！

管理和销售工作中的7大要素关键结果领域是你工作成功所必须取得的结果。它是完全由你负责的工作领域。如果你不把它做好，那么没有人代替你完成。关键结果领域是在你控制下的活动。它是你工作的产出，同时也会成为别人工作的输入或有用的因素。
管理的关键结果领域是计划、组织、配备人员、授权、监督、检查和报告。
无论从事什么工作，你都必须掌握完成工作所必需的知识和技能。对知识和技能的要求是不断变化的。你只有提高核心竞争力，才能很好地完成你的工作。但是，关键结果领域永远是你工作的中心并决定你工作的成败。
提高生产力的起点是，首先搞清楚你工作的关键结果领域。你可以同领导讨论这些关键结果领域。列出你的产出责任并确保你的领导、同级和下级都同意你所列出的产出责任清单。

找出工作中的关键结果领域。这些职责是什么？把它们写下来。找出自己在每个环节内的优劣势。然后，确定一种技能，如果你在这方面优势突出的话，那么它将对你的工作有极大的帮助。2. 带着这张清单去拜访你的领导，并与他讨论清单上列出的工作。请他做诚实而中肯的评价。只有虚心听取他人提出的建设性意见，才能不断地完善自己并取得进步。此外，还要与你的同事、爱人进行探讨、交流。在你以后的职业生涯中，应该养成定期进行分析的习惯。不断强化这种习惯，这个决定本身就能改变你的生活。

每天只做一项工作请你在30秒之内，把生活中最重要的3个目标写下来。”通过这个练习我们发现，如果只给人们30秒钟让他们写下3个最重要的目标，他们的答案非常准确，结果跟经过30分钟或3小时思考的一样。
80%的人的3个目标是一样的：第1个目标是经济和事业方面的；第2个是家庭或人际关系方面的；第3个是健康或身体方面的。
学习时间管理技巧的一个主要目的是，从现在开始，你可以去做那些真正重要的工作，并腾出更多的时间去做那些生活中能给你带来最大的幸福感和满足感的事情。
生活中有85%的幸福感来自与他人的和谐的关系，尤其是与那些和你关系最密切的人，以及家人的关系。决定你人际关系质量的关键因素是，你与爱人相处时间的长短。学习时间管理的目的在于提高效率，这样你会有更多的时间去陪自己爱的人，有更多的时间去做那些能最大限度地给自己带来快乐的事情。

找出工作中最重要的1项任务。你可以问自己：“如果我每天只能完成1项任务，哪项任务对我的工作贡献最大？”然后重复两遍同样的问题。按照这种方法找到工作中最重要的3项任务之后，每天把所有的精力全部放在这3项任务上。2. 确定生活中最重要的3个目标，然后根据优先级别进行排序。针对这些目标制订相应的计划，然后全力以赴去实现。持续几个月至若干年之后，你会为自己取得的成就感到惊讶。

创造舒适的工作空间不管与生俱来的能力是高是低，你的潜力永远大于你一生所表现出来的能力
克服拖延、提高工作效率最好的方法之一，就是在开始工作之前做好充分准备。如果你的准备工作做得很充分，那么开始工作的时候你就会像满弓上的箭一样，蓄势待发，只需要一点点动力，就能着手处理最重要的工作了
将所有与完成工作有关的信息、报告、详图、文件等资料收集在一起，全部放在手边，当你需要的时候，不需要起身或离开座位去找它们。确保你收集齐了所有的书面资料，包括登录信息、密码、邮箱地址，以及从工作开始到完成所需的都已经准备妥当。

认真地检查你家中和公司的办公桌，然后问自己：“哪个类型的人会在这种环境中工作？”你的工作环境越干净、整洁，你就会越积极、高效、自信地投入工作。2. 下定决心，今天就把办公桌和办公室收拾得干干净净、整整齐齐，这样你会感觉每次都能高效地开始工作。

穿越撒哈拉沙漠
任意选择一个曾经被你拖延的目标、任务或项目，从现在就开始迈出第一步。有时候，要开始一件事情并不难，你只需坐下来，把所有必要的步骤都列出来就足够了。2. 接下来，马上从第一步开始，一步一步、循序渐进地去做这件事情。最终你会惊讶地发现自己取得的成就非凡。

学无止境所有成功都有共通的意义，无论你的任务是什么，坚持更多、更好地付出，都是确保你获得成功的不二法门。
成为大师的3个步骤
首先，每天至少阅读1小时，以了解行业最新动态。每天早晨尽量早一点起床，阅读30～60分钟的图书或杂志，其中应包含有助于你提高生产力和工作效率的信息。
其次，参加有助于你提高工作技能的每一堂课程和讲座。参加行业内的研讨会和专业会议。更不要错过任何高水平的培训和讲习。坐在前排认真做笔记，并购买活动的音像和影像资料。下决心把自己培养成业内知识最渊博、最有竞争力的人。最后，一边开车一边收听你购买的音像资料。

找出能够帮助你更快更好地实现目标的、最有效的关键技能。决定你必须具备哪些核心竞争力，这些核心竞争力能够在未来让你在专业领域脱颖而出。不管这些能力是什么，你都要设定目标、制订计划、开始构建和提升该领域的能力。在自己能力所及的范围内做到最好。2. 为了出色地完成最重要的任务，你应该制订一项个人计划，让自己充分地做好准备。专注于那些你具有特殊天分，并且非常感兴趣的领域。这是打开个人潜能的钥匙。找出限制因素

现在就确定你生活中最重要的目标。这个目标是什么？一旦实现这个目标，是否会对你的生活产生极大的积极影响？你工作中的哪项成就会对你的职业生涯产生非常积极的影响？2. 一旦明确了自己最重要的目标，你可以问自己这些问题：“是什么制约了我实现这个目标？为什么我还没有实现自己的目标？是什么制约着我的进步？”找到答案后，立刻行动起来解决这些问题。你想做什么都可以，但必须要行动起来。


成为业内的领军者成功的第一要素是：必须全身心地做一件事情，决不能有任何懈怠。
只有约2%的人能在完全没有监督的情况下工作，这样的人可以说寥若晨星。我们称这些人为“领导”。只要你愿意，并且下定决心做一个能自我监督的人，那么你一定能成功。
有一个最好的办法能帮助你克服拖延症：假设距离完成最重要的工作的最后期限只有一天。

为自己的每一项任务和活动设定最后期限和各个阶段的最后期限。自己制定一个“强制系统”。不断提醒自己设定的最后期限，不让自己有丝毫的松懈。一旦设定最后期限，就严格执行，力争提前完成工作。2. 在开始最重要的工作前，把你的每一个步骤都写下来，然后确定每一步需要用多长时间。在你一丝不苟地完成这些工作的过程中，让自己不断与时间赛跑，并尽量提前完成工作。可以把这个当作一项游戏，让自己胜出。

控制你跟心灵的对话你对自己的评价、自爱、自尊的程度，在很大程度上决定你工作时自我激励的程度，及能否坚持不懈地工作
维克多·弗兰克尔（Viktor Frankl）在畅销书《活出意义来》（Man’s Search for Meaning）中所写的那样：“人类的终极自由是在现有的任何一种环境中选择做自己的态度
“乐观”的性格是事业成功、生活幸福的最重要的品质。几乎在生活中的方方面面，乐观的人的做事效率都更高。
乐观主义者有4个显著的特征，而这些特征都是通过反复实践学来的。第一个特征，乐观主义者在任何情况下都会去看事情好的一面。无论出现什么状况，他们都会努力寻求有益的一面。第二个特征，乐观主义者总是能从挫折和苦难中总结经验，吸取教训。他们相信，“困难的出现不是为了挡住去路，而是为了指明出路”。他们相信，每一个挫折和障碍中都蕴含着有用的教训，他们会从中吸取教训。第三个特征，乐观主义者总是极力找出问题的解决方法。出现问题的时候，他们不是指责他人或不停地发牢骚，相反，他们总是尽自己的最大努力去寻求解决问题的办法。他们提出的问题是：“解决这个问题的方法是什么？我们现在应该怎么做？下一步应该怎么做？”第四个特征，性格积极、乐观的人会不断地思考和谈论他们的目标。他们总是在思考自己究竟想得到什么，如何得到他们想要的。他们所想所说的是未来，是他们想要实现什么样的目标，而不是过去曾经得到过什么。他们总是向前看，而不是向后看。

控制自己的思想，让自己总是保持积极的态度。记住，你会成为你想成为的那个人，所以，只说你想说的，只做你想做的。2. 勇于面对现实、承担责任，使自己保持积极的心态。无论遇到什么事情，都不要去批评、埋怨、指责别人。去改善，而不是责怪。集中思想和精力向前看，不要理会其他。

你要有所选择“每天我会定时查看两次邮件。当我看到您的消息后，会尽快回复。如有紧急事宜，请致电我的手机。”

在日常生活中，给自己留出一部分独处的时间。每天上午和下午各安排一个小时，在这段时间里，把所有的通信设备都关掉。你会惊讶地发现，没有什么区别！2. 每周都给自己安排一整天时间。在这一天里，不开电脑，不用手机，也不使用任何方式与外界联系。到一天结束的时候，你会发现自己的心灵异常平静，思路格外清晰。当你腾出时间重塑精神能量之后，你吃青蛙会更有效率。

掌控你的通信
今天就痛下决心，推掉所有的通告，只给自己留下一个处理紧急情况的渠道。为你最重要的任务创造一个数字化生活的特定空间。2. 下决心研究、安装一个软件或App，让它帮你变得更加高效和专注。上瘾

生命完全是一场专注力的修行，你专注于哪里，你的生命就在哪里。
处理完网络上的一个突发事件后，人们通常需要花费7分钟才能完全将注意力从前一件事情上转回到原来的任务中，然后继续工作。
已经被各行业的高效能人士广泛采用。第一，清晨不要检查邮件，这样才会避免新邮件刺激大脑，释放出全天的多巴胺，分散注意力。让你的设备仍处于关闭的状态。第二，如果由于特殊原因，你需要查看邮件，那么你需要尽快切换到邮件处理状态，然后迅速地结束。关掉电脑的声音提示音，让你的手机处于“震动”状态。停止刺激和触发多巴胺的释放，停止其他不断引发注意力中断的刺激。第三，下定决心每天查看两次邮件，把时间定在上午11点和下午3点半，处理完之后就关闭邮箱。给他人提供一个在紧急情况下可以找到你的电话号码。不论你是跟别人一对一开会，还是给更多人开会，都采用上述的协议。把电子设备关掉。不要打断别人与你的在线合作，或者中途接听第三人的来电，因为这些举动对对方而言都是不礼貌的。一定要为对方100%地专注。这一条协议也适用于在家里发生的情况。
第一，每天提前制订一整天的计划，选择出你最重要的任务，然后开始完成该任务，直到全部结束为止，在彻底完成该任务之后，再开始做其他的工作。第二，持续不间断地连续工作90分钟，期间不要有任何的干扰和注意力的分散，然后让自己休息15分钟。第三，投入全部精力再次开始下一个90分钟的工作。第四，完成了为期三小时的工作后，你终于可以奖励自己查看邮件，刺激多巴胺冲击你的大脑了。当你建立了这一习惯，在每天上午首先抽出连续3小时完成重要工作后，你将让你的生产力提升到两倍，并能够克服全天不定期查看邮箱的陋习。你将会全面掌控自己的生活。

在大脑中保持对成功目标和高效生产力的追求。在你开始做任何事情之前，都要先问问自己，“这会帮助我达成最重要的目标吗，还是仅仅是一个干扰而已？”2. 拒绝成为各种警报声和提示音的奴隶，这些只会使你从即将真正改变人生的任务中分心。让你的通信设备处于关闭的状态。

设定强制关闭机制吃掉那只青蛙1. 立刻将这些技巧付诸实践。选择一项你拖延的复杂而艰巨的任务，无论是用“香肠工作法”还是“奶酪工作法”，都去立即着手处理这项任务。2. 把自己变身为“行动派”。高效能人士有一个共同点，每当他们听到一个好点子，就会立刻行动。所以他们学得更多，学得更快，并能得到更好的结果。不要迟疑。今天就试试这种方法！
为整块时间制订时间表如果你把全部精力集中于一组有限的目标上，那么你的未来将不可限量。
许多重要任务都要花费大块的时间不间断地完成。你能否找到大块的、可利用的时间，关系到你能否在工作、生活中取得大的成就。
许多人把每天晚上睡觉之前的15分钟用来阅读精品图书。
很多高效能人士都是这样做的，他们总是提前安排每一天的工作，安排特定的时间段来处理特定的事情。他们的目标是一次完成一项重要工作，并根据这一原则来规划自己的职业生涯。
在这段工作时间之内，你关闭手机，不受任何来自外界的干扰，不间断地进行工作。最好的工作习惯之一就是每天早早起床，然后在家里工作几个小时。在这段时间里，没有人打搅你的工作。而在忙碌的办公室里，你的周围可能人满为患，电话也狂轰滥炸地响个没完没了。相比之下，你在家里可以完成3倍的工作量。

多思考和尝试用各种不同的办法来节约、安排或创造大块的时间。用这些时间去处理那些重要的、长期能产生重大影响的任务。2. 充分发挥每一分钟的价值。提前计划并做好准备，从而能够持续不断地、不受干扰地进行工作。最重要的是，把精力集中在你负责的最重要的工作上。

进入最佳状态不要盲目地等待，时机永远不会“恰到好处”地到来。从你现在的位置开始工作，运用你需要的、能找到的任何工具。在前进的过程中，你还会找到更好的工具。
生产力高的人愿意花费时间去思考、制订计划、确定事件的优先级。然后，他们就行动迅速、意志坚定地投入工作，朝着自己的理想和目标前进。他们从容不迫地、循序渐进地工作，在一般人盲目地社交，浪费时间，从事那些无谓的、低价值回报的工作的时候，他们却完成了不计其数的工作。
当你精力充沛、活力四射地投入自己的工作的时候，你会觉得自己的大脑进入了一种充满激情的状态。几乎每个人都有过这样的经历。而真正的成功人士，体验到这种状态的频率要比普通人高得多。这种状态是一个人在工作生产力和效能方面所表现出来的最佳状态。在这种状态下，你的思想和情感通常会发生一些近乎奇迹的事情。在这种状态下，你会感到自己头脑清醒，工作热情高涨，无论做什么事情都既有效又精准。你会觉得自己兴高采烈、充满活力。你会觉得自己做事有条不紊，工作效率非常高。
好的结果是，你行动的速度越快，你的能量就越大；你行动的速度越快，你完成的工作就越多，你的工作效率就越高；你行动的速度越快，你积累的经验就越多，学到的知识也越多；你行动的速度越快，你的工作能力就越强，才能就越出众。

从现在开始，无论做什么事情都要培养一种紧迫感。选择一个自己可能会拖延的领域，决定在这个领域内养成马上行动、决不拖泥带水的习惯。2. 当你看到一个机会或者发现一个问题时，应当立刻采取行动。当你接受了一项任务或承担了某个责任时，应当迅速完成并及时向领导汇报结果。你应当在生活的重要领域快速地行动。当这一切成为习惯之后，你的感觉会更好。

一旦开始，全力以赴力量的真正秘密在于此。学习如何使用资源，然后在特定的时刻把它集中使用在特定的事情上。这一习惯要通过反复实践才能形成。
全力以赴地投入一项工作的要求是，一旦开始做这件事情，就全身心地投入进来，不受外界干扰，不转移注意力，直到100%地完成工作。每当你想停下来，或想要做其他事情的时候，你要不断对自己重复“继续工作”这句话，然后敦促自己不断前进。只要你能全身心地投入对你最重要的事情，就能把完成工作所需要的时间缩短50%甚至更多。
在应该做某件事情的时候，约束自己去做那件事情，无论自己当时想做还是不想做”。归根结底，在任何一个领域内，要想获得成功，都需要极强的自律能力。自律、自制是一个人性格塑造和高效能的基石。

立刻行动！现在就确定对你来说最重要的工作和任务，然后立刻全身心地投入这项工作。2. 一旦开始工作，就约束自己在工作过程中心无旁骛，不受外界干扰，也决不分散自己的注意力，直到工作100%完成，把这个当作一项测试，看自己是否能做出决定并完成。一旦开始工作，就坚持到底，直到全部完成为止。

后记
明确目标：确定自己究竟想要什么。目标清晰至关重要。在每天开始工作之前，把你的目标全部写下来。
每天提前做计划：一边思考，一边把你的想法写在纸上。你花费在准备工作上的每一分钟，都将使你在工作过程中节约5～10分钟。
将80/20法则用于你的所有任务：你的所有任务中，其中有20%的任务能产生80%的结果。因此，尽量把你的精力集中在那20%的任务上。
考虑效果：你最重要的、优先级最高的事情是那些将对你以后的生活或工作产生最重要影响的事情，无论其影响是正面的还是负面的。你应当最优先处理这些事情。5.“创造性拖延”练习：既然你没有时间去安排所有的事情，你就必须学会推迟处理那些没有什么意义的工作，从而腾出时间来处理那些少数的、重要的工作。
持续不断地练习使用ABCDE法：根据自己列出的任务计划，在开始工作之前，先抽出一点时间，根据优先级对这些事情进行安排，从而确保你先处理最重要、最有价值的事情。7. 聚焦关键结果领域：要想圆满地完成自己的工作，你必须具备哪些能力和技能？找出答案，然后日益精进，解决上述问题。
遵守“3个”定律：找出你的工作中的最重要的3件事情，你对公司90%的贡献都来自这3件事情。无论如何，都先把这些事情做好，然后，你才能腾出更多的时间来安排个人的家庭和生活。
做好充分准备再行动：开始工作前，先把一切都准备就绪，包括所有的资料、信息、工具、材料，以及你需要的数据，然后，你就可以全身心地工作了。
每次到达下一个油桶：如果你每次能阶段性地推进下一步工作，那么你就能完成最艰巨、最复杂的工作。
升级核心技能：你在自己的关键领域内知识越全面，技能越娴熟，你动手就越快，任务完成得就越早。
找到最关键的限制因素：确定影响你实现目标的瓶颈和主要障碍，无论是来自外部还是内部，然后集中精力消除这些障碍。
自我设定压力目标：假设你即将离开所在的城市，外出一个月，离开之前必须把所有重要的工作都处理完。
激励自己将理想转化成行动：做你自己的啦啦队队长。在任何情况下，都寻求事情积极的一面。把精力集中在如何解决问题上，而不是问题本身。要保持乐观向上的态度。
技术是一个可怕的主人：把你的时间收回，不要让各种技术分散你的注意力，停止做技术的奴隶。学着经常把手机设备关机，并放在一边。
技术是一个非常优秀的仆人：用技术工具帮你自己处理最重要的工作，把自己从最不重要的工作中解放出来。
集中注意力：停止不断地打扰和分心，影响你正在完成的最重要的工作。
奶酪和香肠工作法：把复杂而又艰巨的大任务分割开来，变成许多部分，每次只处理一小部分。
创造整块的时间：为自己安排一份日程表，然后留出大块的时间来处理对你来说最重要的事情。
保持紧迫感：养成迅速处理关键任务的习惯。把自己培养成一个能迅速、圆满完成工作的人。
单独处理每一项任务：根据事情的优先级安排优先处理哪些事情，然后立即着手处理最重要的、必须优先处理的事情，全心全意地去做这件事情，决不中途停止，直到100%完成为止。这是工作高效、个人生产力最大化的关键所在。

评论这是一本值得常读常看的书籍
]]></content>
      <categories>
        <category>读书</category>
      </categories>
      <tags>
        <tag>读书</tag>
        <tag>阅读</tag>
        <tag>时间管理</tag>
        <tag>自我管理</tag>
        <tag>个人管理</tag>
        <tag>效率管理</tag>
        <tag>方法工具</tag>
        <tag>方法论</tag>
      </tags>
  </entry>
  <entry>
    <title>幸福了吗？</title>
    <url>/2013/08/24/book-have-u-happy/</url>
    <content><![CDATA[幸福了吗？白岩松
一个人需要隐藏多少秘密才能巧妙地度过一生这佛光闪闪的高原三步两步便是天堂却仍有那么多人因心事过重而走不动——六世达赖喇嘛仓央嘉措
梁漱溟先生有关的一本书《这个世界会好吗》，翻到后记，梁先生的一段话，突然让我心动。梁老认为，人类面临有三大问题，顺序错不得。先要解决人和物之间的问题，接下来要解决人和人之间的问题，最后一定要解决人和自己内心之间的问题。
青春应当浪漫一些，不那么功利与现实，可现今的年轻人却不敢也不能。房价不断上涨，甚至让人产生错觉：“总理说了不算，总经理说了才算。”后来总经理们太过分，总理急了，这房价才稍稍停下急匆匆的脚步。房价已不是经济问题，而是社会问题政治问题。
一群人急匆匆地赶路，突然，一个人停了下来。旁边的人很奇怪：为什么不走了？停下的人一笑：走得太快，灵魂落在了后面，我要等等它。是啊，我们都走得太快。然而，谁又打算停下来等一等呢？如果走得太远，会不会忘了当初为什么出发？
03 让敏感的不再敏感
有些人不喜欢中国，更多的人开始喜欢中国人民，但绝对所有的人都喜欢中国人民币。

注: 精辟

09 三进台湾
所有的生离死别，都发生在一个码头，上了船，就是一生。让你看见我们的父母，一整代人隐忍不言的伤。这是一本你从来没认识过的一九四九。

注: 大江大海

10 靖国神社与垃圾分类
日本大城市中，人们的交通主要依靠地铁。高峰时，车厢里的椅子都能收起来，大家都站着，为了节省空间，到了非高峰期，椅子才放下；而在车厢里，很少有少有人跷二郎腿，打电话也被视为不礼貌的行为；无论购物还是吃饭，都是有秩序地排队，无人加塞儿。

注: 这个没有注意

12 感动，有没有用？
做《感动中国》的主持人，是一件既幸福又痛苦的事情。幸福在于，你可以离感动如此之近；而痛苦在于，当你被感动时，你必须克制，不能放纵泪水一次又一次地滑落。这种痛苦，只有身在其中，才能强烈地感受

注: 感动中国的幸福与痛苦

14 成长的营养：好听的好看的
生命如同一条河流，出发时，还只是清澈的涓涓细流，一路奔腾，慢慢加速，陆续开始有人或事，书或者光影，为这条河流填注力量，增加水流甚至影响方向，每个人都不例外。

注: 生命

15 谁，影响并改变着我？
高中同学与大学同学不一样，后者因学的是同一个专业，即便毕业后天南海北，可行业的关系，还是让大学同学更方便时常见面。而高中的同学，由于上的大学与专业千差万别，聚会的难度就加大了，只能回家
如果有一天，你感觉内心沉静，世事浮沉暂时抽离，而窗外又风和日丽，你试着再听听莫扎特，用你最简单和纯真的心，这时候我相信，真正的莫扎特会在上帝的指使下再度归来。
]]></content>
      <categories>
        <category>读书</category>
      </categories>
      <tags>
        <tag>读书</tag>
      </tags>
  </entry>
  <entry>
    <title>如何阅读一本书? -- 范多伦,艾德勒</title>
    <url>/2012/12/16/book-how-to-read-a-book/</url>
    <content><![CDATA[如何阅读一本书? – 范多伦,艾德勒法国学者巴斯卡(Pascal)在三百年前就说过：“读得太快或太慢，都一无所获。”注：读书不能太快或太慢！要有所把握
介绍四种不同层次的阅读—基础阅读(elementary reading)、检视阅读(inspectional reading)、分析阅读、主题阅读(syntopical reading)。
注：四种层次的阅读
阅读越主动，效果越好。这个读者比另一个读者更主动一些，他在阅读世界里面的探索能力就更强一些，收获更多一些，因而也更高明一些。读者对他自己，以及自己面前的书籍，要求的越多，获得的就越多。
注：主动阅读
阅读的目标：为获得资讯而读，以及为求得理解
注：阅读的目标
运用阅读以增加资讯与洞察力，与运用阅读增长理解力
注：阅读的目标
要避免这样的错误—以为读得多就是读得好的错误—我们必须要区分出各种不同的阅读形态。这种区分对阅读的本身，以及阅读与一般教育的关系都有很重大的影响。
注：读的多并不一定是读的好
敏锐的观察、灵敏可靠的记忆、想像的空间，再者当然就是训练有素的分析、省思能力。这么说的理由在于：阅读也就是一种发现—虽然那是经过帮助，而不是未经帮助的一个过
注：阅读的技巧
二个层次的阅读我们称之为检视阅读(inspectional reading)。特点在强调时间。在这个阅读层次，学生必须在规定的时间内完成一项阅读的功课
注：第二个层次
分析阅读就是全盘的阅读、完整的阅读，或是说优质的阅读—你能做到的最好的阅读方式。如果说检视阅读是在有限的时间内，最好也最完整的阅读，那么分析阅读就是在无限的时间里，最好也最完整的阅读
注：第三个层次，分析阅读
如比较阅读(comparative reading)。在做主题阅读时，阅读者会读很多书，而不是一本书，并列举出这些书之间相关之处，提出一个所有的书都谈到的主题。但只是书本字里行间的比较还不够。主题阅读涉及的远不止此。借助他所阅读的书籍，主题阅读者要能够架构出一个可能在哪一本书里都没提过的主题分析。因此，很显然的，主题阅读是最主动、也最花力气的一种阅读。
注：最复杂的主题阅读
层次所可能碰到的各种紧急状况与问题的程度就会明白了。然而，除非我们在所有的阅读层次都投下努力，否则我们社会里有关阅读的整体。特别就一本教人如何阅读的书来说，它的读者必须有某种程度的阅读能力才行。
?(1)先看书名页
注：略读的方法1
2)研究目录页，对这本书的基本架构做
注：略读的方法2
3)如果书中附有索引，也要检阅一下—大多数论说类的书籍都会有索引
注：略读的方法3索引
4）如果那是本包着书衣的新书，不妨读一下出版者的介绍
注：略读的方法4出版商说明
(5)从你对一本书的目录很概略，甚至有点模糊的印象当中，开始挑几个看来跟主题息息相关的篇章来看。如果这些篇章在开头或结尾有摘要说明（很多会有），就要仔细地阅读这些说明
注：略读的方法5随便挑几章看看
6)最后一步，把书打开来，东翻翻西翻翻，念个一两段．有时候连续读几页，但不要太多。就用这样的方法把全书翻过一遍，随时寻找主要论点的讯号，留意主题的基本脉动。最重要的是，不要忽略最后的两三页。就算最后有后记，一本书最后结尾的两三页也还是不可忽视的
注：略读的方法6主动寻找资讯
头一次面对一本难读的书的时候，从头到尾先读完一遍，碰到不懂的地方不要停下来查询或思索。
只注意你能理解的部分，不要为一些没法立即了解的东西而停顿。继续读下去，略过那些不懂的部分，很快你会读到你看得懂的地方。集中精神在这个部分。继续这样读下去。将全书读完，不要被一个看不懂的章节、注解、评论或参考资料阻挠或泄气。如果你让自己被困住了，如果你容许自己被某个顽固的段落绑住了，你就是被打败了。在大多数情况里，你一旦和它纠缠，就很难脱困而出。在读第二遍的时候，你对那个地方的了解可能会多一些，但是在那之前，你必须至少将这本书先从头到尾读一遍才行。
注：读书对的方向！不能因为某个章节不懂而停滞不前，至少完整读下来，多注意那些理解的章节
亚当·斯密(Adam Smith)的经典作品《国富论》(The Wealth of Nations
注：国富论
每一本书，不论是多么难读的书，在无关紧要的间隙部分就可以读快一点。而一本好书，总会包含一些比较困难，应该慢慢阅读的内容
注：快慢的把握
要矫正眼睛逗留于一点的工具有很多种，有些很复杂又很昂贵。无论如何，任何复杂的工具其实都比不上你的一双手来得有用，你可以利用双手训练自己的眼睛，跟着章节段落移动得越来越快。你可以自己做这样的训练：将大拇指与食指、中指合并在一起，用这个“指针”顺着一行一行的字移动下去，速度要比你眼睛感觉的还要快一点。强迫自己的眼睛跟着手部的动作移动。一旦你的眼睛能跟着手移动时，你就能读到那些字句了。继续练习下去，继续增快手的动作，等到你发觉以前，你的速度已经可以比以前快两三倍了
注：矫正眼睛经常逗留，跟不上脑袋的速度，用手做工具
在阅读一本书的时候，慢不该慢到不值得，快不该快到有损于满足与理解。不论怎么说，阅读的速度，不论是快还是慢，只不过是阅读问题一个微小的部分而
注：阅读时的速度把握
最后，在第一次阅读一本难读的书时，不要企图了解每一个字句。这是最最重要的一个规则。这也是检视阅读的基本概念。不要害怕，或是担忧自己似乎读得很肤浅。就算是最难读的书也快快地读一遍。当你再读第二次时，你就已经准备好要读这本书了。
注：对难懂的书先速读一遍，然后? 再研究第二遍
在阅读的时候想要保持清醒，或昏昏入睡，主要看你的阅读目标是什么。如果你的阅读目标是获得利益—不论是心灵或精神上的成长—你就得保持清醒。这也意味着在阅读时要尽可能地保持主动，同时还要做一番努力—而这番努力是会有回馈的。
注：阅读的时候保持清醒
关于一本书，你一定要提出四个主要的问题。
(1)整体来说，这本书到底在谈些什么？你一定要想办法找出这本书的主题，作者如何依次发展这个主题，如何逐步从核心主题分解出从属的关键议题来。
(2)作者细部说了什么，怎么说的？你一定要想办法找出主要的想法、声明与论点。这些组合成作者想要传达的特殊讯息。
(3)这本书说得有道理吗？是全部有道理，还是部分有道理？除非你能回答前两个问题，否则你没法回答这个问题。在你判断这本书是否有道理之前，你必须先了解整本书在说些什么才行。然而，等你了解了一本书，如果你又读得很认真的话，你会觉得有责任为这本书做个自己的判断。光是知道作者的想法是不够的。
(4)这本书跟你有什么关系？如果这本书给了你一些资讯，你一定要问问这些资讯有什么意义。为什么这位作者会认为知道这件事很重要？你真的有必要去了解吗？如果这本书不只提供了资讯，还启发了你，就更有必要找出其他相关的、更深的含意或建议，以获得更多的启示。
注：读书时要提出的四个问题
如何让一本书真正属于你自己
如果你有读书时提出问题的习惯，那就要比没有这种习惯更能成为一个好的阅读者。但是，就像我们所强调的，仅仅提出问题还不够。你还要试着去回答问题。理论上来说，这样的过程可以在你脑海中完成，但如果你手中有一枝笔会更容易做到。在你阅读时，这枝笔会变成提醒你的一个讯号。
注：如何让一本书属于你
俗话说：“你必须读出言外之意，才会有更大的收获。”而所谓阅读的规则，就是用一种比较正式的说法来说明这件事而已。此外，我们也鼓励你“写出言外之意”。不这么做，就难以达到最有效的阅读的境界。
你买了一本书，就像是买了一项资产，和你付钱买衣服或家具是一样的。但是就一本书来说，付钱购买的动作却不过是真正拥有这本书的前奏而已。要真正完全拥有一本书，必须把这本书变成你自己的一部分才行，而要让你成为书的一部分最好的方法—书成为你的一部分和你成为书的一部分是同一件事—就是要去写下来。
为什么对阅读来说，在书上做笔记是不可或缺的事？第一，那会让你保持清醒—不只是不昏睡，还是非常清醒。其次，阅读，如果是主动的，就是一种思考，而思考倾向于用语言表达出来—不管是用讲的还是写的。一个人如果说他知道他在想些什么，却说不出来，通常是他其实
注：让书成为自己的
知道自己在想些什么。第三，将你的感想写下来，能帮助你记住作者的思想
做笔记有各式各样，多彩多姿的方法。以下是几个可以采用的方
注：做笔记的方法
※ 三种做笔记的方
注：三种做笔记的方法
※ 培养阅读的习惯
所谓艺术或技巧，只属于那个能养成习惯，而且能依照规则来运作的人。这也是艺术家或任何领域的工匠与众不同之处。要养成习惯，除了不断地运作练习之外，别无他法。这也就是我们通常所说的，从实际去做中学习到如何去做的道
注：培养阅读的习惯
第七章 透视一本书
每一本书的封面之下都有一套自己的骨架。作为一个分析阅读的读者，你的责任就是要找出这个骨
注：透视一本书的骨架
一本好书，就像一栋好房子，每个部分都要很有秩序地排列起来。每个重要部分都要有一定的独立
注：好书像一个好房子
分析阅读的第一阶段，或，找出一本书在谈些什么的四个规则：
注：找出一本书在说什么的方法
一般来说，阅读的过程与商业上的过程正好相反。商人通常是在找出提案是什么后，才会达成共识。但是读者却要先与作者达成共识，才能明白作者的主旨是什么，以及他所声明的是什么样的判断
注：判断作者的主旨
?(5)诠释作者使用的关键字，与作者达成共识。
(6)从最重要的句子中抓出作者的重要主旨。
(7)找出作者的论述，重新架构这些论述的前因后果，以明白作者的主张。
(8)确定作者已经解决了哪些问题，还有哪些是未解决的。在未解决的问题中，确定哪些是作者认为自己无法解决的问题。
注：分析阅读的第二个阶段
我们的建议尤其适用于所谓巨著。一般人总是抱着热忱想要阅读巨著，但是当他绝望地感觉到自己无法理解这本书时，热忱很快便消退了。其中一个原因，当然是因为一般人根本不知道要如何好好地阅读一本书。但还不只如此，还有另一个原因：他们认为自己应该能够读懂自己所挑选的第一本书，用不着再读其他相关的著作。
注：巨著读法
许多伟大的作品不只是互相有关联，而且在写作时还有特定的先后顺序，这都是不该忽略的事。后人的作品总是受到前人的影响。如果你先读前一位的作品，他可能会帮助你了解后人的作品。阅读彼此相关的书籍‘，依照写作的时间顺序来读，对你了解最后写的作品有很大帮助。这就是外在辅助阅读的基本常识与规则。
注：读巨著前先读一些基础著作
读一本好书，却会让你的努力有所回报。最好的书对你的回馈也最多。当然，这样的回馈分成两种：第一，当你成功地阅读了一本难读的好书之后，你的阅读技巧必然增进了。第二—长期来说这一点更重要—一本好书能教你了解这个世界以及你自己。你不只更懂得如何读得更好，还更懂得生命。你变得更有智慧，而不只是更有知识—像只提供讯息的书所形成的那样。你会成为一位智者，对人类生命中永恒的真理有更深刻的体认。
注：读一本好书的好处
好的阅读，也就是主动的阅读，不只是对阅读本身有用，也不只是对我们的工作或事业有帮助，更能帮助我们的心智保持活力与
]]></content>
      <categories>
        <category>读书</category>
      </categories>
      <tags>
        <tag>读书</tag>
        <tag>阅读</tag>
      </tags>
  </entry>
  <entry>
    <title>跑步，该怎么跑</title>
    <url>/2015/03/23/book-how-to-run/</url>
    <content><![CDATA[跑步，该怎么跑

如果你想要健康 – 跑吧。
如果你想要俊美 – 跑吧。
如果你想要聪慧 – 跑吧。

练就完美跑步技术的关键在于：尽可能利用重力。
完美的跑者，融合自然的不掉，用你的双脚轻柔、敏捷地踩踏过路面。
厉害的赛跑者总是以优雅的节奏，流畅地跑着。

膝盖与胯关节不要太高或往前
绝对不要把腿伸直
不要摆动手臂让身体前进

主要是纠正了跑步的动作~
]]></content>
      <categories>
        <category>读书</category>
        <category>健身</category>
      </categories>
      <tags>
        <tag>读书</tag>
        <tag>健身</tag>
        <tag>跑步</tag>
      </tags>
  </entry>
  <entry>
    <title>每天最终好的3件事</title>
    <url>/2020/02/02/book-import-3-things-in-one-day/</url>
    <content><![CDATA[每天最重要的3件事   – 张永锡 李瑞文“Just do it”是幸福行动家们在实践相关内容时的真实案例和经验。
第一个习惯是“先吃掉那只青蛙”，第二个习惯是“清空收件夹”，第三个习惯是“每日重开机”
第一部分 先吃掉那只青蛙时间管理不是让人变得一味忙碌，而是让人变得轻松，有时间享受生活。
如果每天早晨你先做最有挑战性的事情，一天中其他的事情都会显得无比轻松。
高效的人并不是每天做很多小事，而是把时间花在最重要的几件事情上
A代表“Action List”，英文中的行动清单。把今天要做的事情列成清单，之后就专注地一项一项做完。每天早上花点儿时间，列出包含13只青蛙、57只蝌蚪的每日行动计划。青蛙之后的其他任务就是“蝌蚪”，就是我们所说的琐事或小任务，相对来说不是非常重要的事。蝌蚪意味着如果今天做不完可以适当舍弃。这份清单除了自己使用，还可以和团队共享，让队员互相了解彼此的进度。
S是“Slice”的缩写，代表切成小片。有些青蛙，不是一口能吃完的，需要分成几天甚至几周才能吃完，那么就需要切成小片。第二章 F吃青蛙：要事为先的三个关键
进入心流状态四步法：

Step1：热身时间先做一些容易的工作，轮替一下不同的小事，这就好像典礼开始时的暖场。
Step2：专注青蛙进入每天最重要的事（吃青蛙）本身。别忘了一口一口吃的技巧，心如止水，顺流而下。
Step3：适时休息记得要在疲倦之前就休息。我在后面的章节会讲到番茄工作法，番茄工作法使我们每25分钟就有一次休息的时间。
Step4：每日检视我会在第二天早晨写日记检视，从检视中找出哪些做法可以改善，下次要吃类似的青蛙时，可以有更好的方法。

挑战最难的事情，正是生活中最有趣的部分。
我会回顾昨天在笔记上记录下来的事情。把需要执行的部分移到行动清单中，剩下的保存在笔记资料库中。
一封信一封信地依次检视，每看完一封信，你可以选择存档、立刻回信、授权他人处理，或者转寄到行动清单作为下一步行动。
我写晨间日记的习惯已经坚持了将近十年，每天记录前一天发生的事情或心情，对于了解自己有莫大帮助。
推荐四个数字化清单应用除了把清单写在笔记本上，现代人应该懂得善用“数字化清单”工具，这里我先做一个简单推荐。OmniFocus是老牌又专业的清单工具，效率非常高，美中不足的是只能在Mac和iOS系统下使用，没有PC版。Wunderlist，又称奇妙清单，有很漂亮的界面与亲切的使用流程，目前属于微软旗下的服务。滴答清单，基础功能免费，比较符合大陆用户的使用习惯，可以语音输入，还可以把微信的内容直接复制到清单里。第五章 T训练自己的时间感知能力
番茄工作法的基本原则是最高强度地专注于一件事情上25分钟，例如看书、背诵、写作、思考或进行各种工作任务，然后让自己精神放松5分钟，例如站起来走走、刷网页、聊聊天。只要一直重复这个循环过程，可以让自己掌控时间并维持最佳专注力
所以，通常我会利用上午的时间来吃青蛙，这是我一天中工作效率最高的时段。到了下午，我的精神已经疲惫，不适合吃青蛙，就处理一些比较轻松的工作，这样才能劳逸平衡
番茄土豆：结合任务清单与番茄钟，有各平台的APP与网页版，是很适合吃青蛙的番茄钟工具。Focus：有Mac和iOS版，好处是可以列出待办事项。Focus Booster：有Windows与Mac版本，可以在桌面上使用的番茄钟计时工具。
我们需要顺应身体的节律，集中注意力、休息放松，保持规律的生活、充足的睡眠。保持节律，只靠大脑是不够的，我们还需要一个闹钟。现代人习惯用手机、电脑、实体倒计时器作为闹钟。这些形态的闹钟都可以使用，更重要的是如何有效地用好它们。
电脑上的计时软件我是用Due做电脑上的计时软件。Due是一个专业的闹钟APP，可以快速输入几个自己需要的闹钟，或设定倒计时，整个过程行云流水，更棒的是可以同步到iOS设备，就算离开电脑也能够提醒自己。
FAST原则除了可以帮你个人完成一天的重要任务，其实也可以管理一个团队的工作流程。F，就是找出团队专案里最重要的事情有哪些。A，就是列出整个团队专案的进度清单。S，就是分配任务、切割任务，根据每个团队成员的能力去分配工作。T，就是分配专案时间，让每个团队成员有时间去完成任务。第八章 清空收件夹：将杂事加工成行动
这个世界上的信息固然非常多，但终会被信息组成者宰制，这些人能在对的时间点，归纳整合正确的信息，批判性地思考，明智地做出重要决定。—— 哈佛大学教授 爱德华·奥斯本·威尔森（Edward Osborne Wilson）
清空收件夹清空收件夹分三步：收集杂事、将杂事加工成行动、贯通收件夹与行动提示系统。
学习好“清空收件夹”的三个流程，就是练习三个基本功：首先，管理好杂事收件夹系统；其次，架构好行动提示系统；最后，清空收件夹，贯通从杂事到行动的高速铁路。让杂事有明确可以放置的地方，有明确的流程让杂事变成行动，最后做事的速度与质量因为有良好的行动提示系统而得到提升，这就是清空收件夹的目的。
人生中一半的麻烦源于答应得太快，拒绝得太慢。——格雷戈·麦吉沃恩（Greg Mckeown）
重新开机重开机（Reboot）：使用时间管理系统帮助我们推进任务，久而久之，系统会产生一些“阻力”，需要定期重开机，清空CPU及RAM内存，让时间管理系统恢复应有的速度。
Schedule，日程表我每天早上检查日程表，确认自己一天的行程。每周在做检视时，也会确认自己上一周与下一周的各项任务，并列出任务清单，安排执行任务的时间，并设定闹钟自动提醒。Task，任务现代知识工作者会同时进行许多任务，有的耗时短，几天可以完成，有的耗时长，需要数周或数月才能完成。任务分个人及组织的任务，有的是独立完成，有的要和团队成员协作才能完成。要对任务做好适当的规划，借此了解整个任务的全貌，这样执行时才能够持续推动，减少边想边做出现的状况。
若是能管控好下周要推动的任务清单及下一步行动，这样时间管理的功力就很不错了。Action，行动每天都需要推动许多行动，有些是单独的行动，有些则是和某个任务相关的行动。行动不容易推动有两方面原因，一方面是没能做好任务规划工作，一直找不到关键行动；另一方面就是今天有太多可以做的行动，需要花时间厘清先后次序。
因此每天要先列出三只青蛙，几只蝌蚪，努力推动，当有杂事进入收件夹，迅速加工确认是否必须今天做。可能的话尽量不要安排在今天，而是安排特定日期来做该行动。这样才能顺利推动今天的青蛙，吃完青蛙和蝌蚪，拥有高效的一天。Reference，参考资料库为了持续做好时间管理，需要建立参考资料库，例如之前提过的晨间日记，爱画画及拍照的人会建立图片资料库，讲师会有幻灯片资料库，上班族则有Office文件管理。这些资料可以帮助我们将任务执行得更好。第十九章 晨间日记：为检视自己而写
每天清晨，我会打开印象笔记，开始写晨间日记，在窗帘透进来的曙光中，只聆听键盘敲击及内心对话这两种声音。而每周每年的坚持检视，帮助我归纳整合信息，做批判性的思考，不断升级自己的人生操作系统。每一次阅读日记，都会觉得好像面对一个不太熟悉的自己。有时发现，自己生命中的每一天都是如此认真地活，这些体验是如此地真实生动。有些时候，也会有点懊恼，为何当初没有好好对待那件事情。日积月累，人生变得更加丰润成熟
一年一次的深度检视，仿佛在一条长路中，停下来歇歇脚。回看之前的轨道，依稀看出形成一条直线，再一转头，望向未来的目标，就知道如何修订生活与工作的角度，向目标继续前进，拥有一个值得拥有的人生
1．选一个早晨自己可以接受的起床时间。2．选一件没有压力，但是可以让自己振奋精神的事，当成早晨起床的第一个动力。3．不急着行动，从晨间日记的每日检视开始。4．选一件对自己具有“高价值”的工作开始做，让自己在早晨就感受到强大回馈。第二十章 每周检视：提升时间管理高度
每周检视的一小时，是一周168小时中最珍贵的一小时。这一小时让我得以从高空俯瞰生活的全局，这样充分地检视后，我的头脑才能获得真正的宁静。
如果你已经下定决心做好每周检视，可以按照如下流程进行：先清空收件夹检视晨间日记本下周日程表思考下周任务检视年度计划
1．设定每周某一固定时段进行每周检视。2．练习快速完成检视。3．每周检视的目的先从找到下周目标开始。4．执行几次后，在每周检视中找到未来计划。
点评★★★☆☆重要的事，琐事如何排序 还有定时日记，自己重开机都是很好的习惯！
]]></content>
      <categories>
        <category>读书</category>
      </categories>
      <tags>
        <tag>读书</tag>
        <tag>阅读</tag>
      </tags>
  </entry>
  <entry>
    <title>不做乔布斯，做最好的自己</title>
    <url>/2015/04/05/book-no-jobs-just-yourself/</url>
    <content><![CDATA[不做乔布斯，做最好的自己要把重要的决定权交给直觉，你就必须放弃规划人生未来的想法。
作为一个高科技公司，苹果公司只有坚持不断创新，才能做到尽量完美。对于操作系统，微软的理念是要让它的使用变得简单，而苹果则希望让它像艺术品一样完美。在库克看来，创新永远是苹果公司致胜的有力武器，只要能保持不断的创新，苹果公司就可以在业界保持领先的地位
]]></content>
      <categories>
        <category>读书</category>
      </categories>
      <tags>
        <tag>读书</tag>
        <tag>乔布斯</tag>
        <tag>库克</tag>
        <tag>苹果</tag>
      </tags>
  </entry>
  <entry>
    <title>不做乔布斯，做最好的自己</title>
    <url>/2014/01/24/book-no-tools-fitness/</url>
    <content><![CDATA[无器械健身总结起来也就六个字：
** 结实 强壮 自信 **
即练出结实的肌肉、锻炼强壮的躯体，培养自信的自己。
Plus:成功健身必须遵循的6个原则

坚持
恢复
规律
变化
进步
超负荷

]]></content>
      <categories>
        <category>读书</category>
      </categories>
      <tags>
        <tag>读书</tag>
        <tag>无器械健身</tag>
      </tags>
  </entry>
  <entry>
    <title>用小刀划开</title>
    <url>/2015/03/22/book-open-with-knife/</url>
    <content><![CDATA[用小刀划开我们总是饿着肚子眼含泪手、不断呜咽幻想着天上会不会掉下什么看看上面、看看下面但 绝不乞求
有多喜爱、就要多厌恶虽然离不开这座城市但总是眼望远方

那时我还很小什么都不懂现在也依然不懂如果有一天我懂了眼前的生活或许也可接受这被压抑被漠视的每一天即使所有人 都可以接受这样的生活也不会所有人 生来就认为 生活就该是这个样子
]]></content>
      <categories>
        <category>读书</category>
      </categories>
      <tags>
        <tag>人生</tag>
        <tag>读书</tag>
        <tag>思考</tag>
        <tag>会话</tag>
      </tags>
  </entry>
  <entry>
    <title>超级时间整理术</title>
    <url>/2015/03/13/book-super-time-collection/</url>
    <content><![CDATA[超级时间整理术
严格执行事先制定好的工作计划，并且一定要完成；
不把时间浪费在找东西上；
争取安排出工作以外的自由时间；

整理的目的是为了提高工作效率，而不仅仅是为了整理干净。 不会整理的人，其工作效率往往比较底下。
整理可以使环境更整洁、思路更清晰。
所谓整理，就是要达到“你想要的东西就能拿到并方便使用”。
人的脑力有限，花脑力去记那些没必要记的东西也是一种浪费。
及时丢弃不必要的东西。
用后就还原位置。
尽量不打印纸质文件。
周五是整理日。
]]></content>
      <categories>
        <category>读书</category>
      </categories>
      <tags>
        <tag>时间</tag>
        <tag>读书</tag>
      </tags>
  </entry>
  <entry>
    <title>黑洞里面有什么</title>
    <url>/2007/04/05/book-what-inside-black-hole/</url>
    <content><![CDATA[黑洞里面有什么天上的星星并不是均匀分布的，而是分成群落、组成图案。
星星为什么闪烁？实际上大多数星星只会发出稳定的光线。之所以发生闪烁是因为大气层—覆盖在地球表面的空气层的变化。大气层的某些部分是不断运动的，而且某些地方的空气比其他地方密度高，空气的这些差异对来自星星的光线产生了影响，使它们看起来摇曳不定。
天文学家将天空划分为88个不同的星座，在赤道上可以看到全部星座。
看见过去当遥望群星时，我们其实是在做一件非常奇特的事情—我们正在时间中回望，星星，例如作为猎户座一部分的参宿⑦，距离地球大约900光年，当我们在天空中看到参宿⑦时，我们看见的光已经离开那颗星星900年了。
恒星的寿命一颗超巨星将在几百万年内燃尽自己的燃料。而作为黄矮星的太阳，能够维持50-100亿年，而一颗红矮星可以闪耀1000亿年。
超巨星在超新星爆发中死去，爆炸只留下一个体积微小而又重的不可思议的中子星，一颗中子星的直径大约只有10km长，但是其质量比太阳还大。
##脉冲星
旋转的中子星
黑洞大质量恒星爆炸时，星体的中央塌缩为一个微小的物质点，但是这个物质点比太阳还重，即黑洞。
地球太阳和地球是一个被称为银河的巨大星系的一部分，这个星系的直径约为10万光年，容纳着1000亿颗左右的恒星。
在我们星系的中央，存在一个重量相当于350万个太阳的大质量黑洞，它的事件视界大约为22万千米，在1974年首次发现。
类星体类似于恒星的天体，指某种看起来像恒星又不像恒星的天体，特点是比任何其他物体都亮。
天文学家认为类星体是一些中央存在大质量黑洞的星系。
来自类星体的光比来自恒星的光更红。（红移）
红移是由于多普勒效应导致的，这意味着星系离我们正远去。离我们越远的星系移动得越快，不过在类星体中，红移比在其他任何星系都强。
多普勒效应：

向你移动：蓝光
离你远去：红光

事件视界黑洞并非把它周围的任何物体都吸进去，只有在事件视界之内的物体才会被吸进去。事件视界是一个与黑洞质量有关的量。
黑洞的影响一颗行星例如地球对时空的影响只造成一点弯曲；
一颗恒星造成的弯曲会多一些；
而一颗黑洞会在时空上留下一个窟窿；
走进洞内当我们从地球、太阳进入黑洞时，由于受到引力的增大，运动的速度也越来越快，直到黑洞把我们撕碎。
洞外观察与我们自身相反，观察者会发现我们进入黑洞后，速度越来越慢，主要是由于光进入黑洞后由于引力而变慢，要花更多的时间才能到达看你的人。
宇宙大爆炸大约150亿年前
背景辐射早在恒星和星系形成以前，空间中熊熊燃烧的炽热白光所留下的微弱的回声。
暗物质
天文学家：不能发光的普通大质量物体，例如大行星、棕矮星；
物理学家：由比原子更小的微小粒子组成的，微小粒子可能是WIMP（弱相互作用大质量粒子）和中微子。

]]></content>
      <categories>
        <category>读书</category>
      </categories>
      <tags>
        <tag>读书</tag>
        <tag>中子星</tag>
        <tag>中微子</tag>
        <tag>暗物质</tag>
        <tag>类星体</tag>
        <tag>红移</tag>
        <tag>背景辐射</tag>
        <tag>脉冲星</tag>
        <tag>蓝移</tag>
        <tag>黑洞</tag>
        <tag>黑洞里面有什么</tag>
      </tags>
  </entry>
  <entry>
    <title>超级时间整理术</title>
    <url>/2015/03/13/book-youth/</url>
    <content><![CDATA[YOUTH
Samuel Ullman

　　Youth is not a time of life; it is a state of mind; it is not a matter of rosy cheeks, red lips and supple knees; it is a matter of the will, a quality of the imagination, a vigor of the emotions; it is the freshness of the deep springs of life.　　Youth means a temperamental predominance of courage over timidity, of the appetite for adventure over the love of ease. This often exists in a man of 60 more than a boy of 20.　Nobody grows old merely by a number of years.　We grow old by deserting our ideals.　　Years may wrinkle the skin, but to give up enthusiasm wrinkles the soul. Worry, fear, self-distrust bows the heart and turns the spirit back to dust.　　Whether 60 or 16, there is in every human being’s heart the lure of wonder,the unfailing childlike appetite for what’s next and the joy of the game of living.　In the center of your heart and my heart there is a wireless station: so long as it receives messages of beauty, hope, cheer, courage and power from men and from the Infinite, so long as you are young.　　When the aerials are down, and your spirit is covered with snows of cynicism and the ice of pessimism, then you are grown old, even at 20, but as long as your aerials are up, to catch waves of optimism, there is hope you may die young at 80.


中文版
　　青春 王佐良译
　　青春不是年华，而是心境；青春不是桃面、丹唇、柔膝，而是深沉的意志，恢宏的想 象，炙热的恋情；青春是生命的深泉在涌流。 青春气贯长虹，勇锐盖过怯弱，进取压倒苟安。如此锐气，二十后生而有之，六旬男子则更多见。年岁有加，并非垂老，理想丢弃，方堕暮年。 岁月悠悠，衰微只及肌肤；热忱抛却，颓废必致灵魂。忧烦，惶恐，丧失自信，定使心灵扭曲，意气如灰。　　无论年届花甲，拟或二八芳龄，心中皆有生命之欢乐，奇迹之诱惑，孩童般天真久盛不衰。人人心中皆有一台天线，只要你从天上人间接受美好、希望、欢乐、勇气和力量的信号，你就青春永驻，风华常存。　　一旦天线下降，锐气便被冰雪覆盖，玩世不恭、自暴自弃油然而生，即使年方二十，实已垂垂老矣；然则只要树起天线，捕捉乐观信号，你就有望在八十高龄告别尘寰时仍觉年轻。
]]></content>
      <categories>
        <category>读书</category>
      </categories>
      <tags>
        <tag>时间</tag>
        <tag>读书</tag>
      </tags>
  </entry>
  <entry>
    <title>二十几岁比别人幸运，就靠这9个好习惯</title>
    <url>/2013/12/21/book-9-good-habits/</url>
    <content><![CDATA[二十几岁比别人幸运，就靠这9个好习惯习惯一旦养成，就会成为支配人生的一种行为力量，它可以主宰人的一生。

播下一种行为，收获一种习惯；
播下一种习惯，收获一种性格；
播下一种性格，收获一种命运；


树立目标并做好规划，目标要打，并专心致志，制定一个完成目标的可行性计划，并开始行动；
塑造一种可以战胜一切的品质，品格是人生的王冠和荣耀，记住有志者，事竟成，对别人的宽容就是对自己的宽容，要有责任感，成功源于细节；
了解各种为人处世的细节，敢于怀疑才会有进步，感恩的心会使人变得愉悦和健康，消除嫉妒心，把幸福分给别人，幸福才会更多，你付出什么，就会得到什么，换位思考，学会理解，尊重他人才能包容一切
调节好情绪与心态，控制好你自己的情绪，记住，情绪成就一切，你的心态决定生活状态，保持开朗，打开心灵之窗,,正确对待人生的各种得失,学会冷静，会调节与释放压力，心有多大，舞台就有多大
学会高效工作，学会规划自己的时间，确定工作的优先次序，切忌三心二意，有了计划要马上付诸行动，好的习惯是提高效率的关键
正确支配自己的财富
开发自己的创造力，留住刹那间的思维火花，
捕捉每一个属于自己的机会，，机遇只垂青有准备的人
努力找寻人生的真谛，学会从不同的角度看问题，生活的不如意大多源自于比较，平静是一种难得的幸福，时常与自己的心灵说说话，推荐打坐，嘿嘿

]]></content>
      <categories>
        <category>读书</category>
      </categories>
      <tags>
        <tag>人生</tag>
        <tag>励志</tag>
        <tag>心态</tag>
        <tag>时间</tag>
        <tag>目标</tag>
        <tag>工作</tag>
        <tag>机会</tag>
      </tags>
  </entry>
  <entry>
    <title>不做乔布斯，做最好的自己</title>
    <url>/2015/04/05/book-%E4%B8%8D%E5%81%9A%E4%B9%94%E5%B8%83%E6%96%AF%EF%BC%8C%E5%81%9A%E6%9C%80%E5%A5%BD%E7%9A%84%E8%87%AA%E5%B7%B1/</url>
    <content><![CDATA[不做乔布斯，做最好的自己要把重要的决定权交给直觉，你就必须放弃规划人生未来的想法。
作为一个高科技公司，苹果公司只有坚持不断创新，才能做到尽量完美。对于操作系统，微软的理念是要让它的使用变得简单，而苹果则希望让它像艺术品一样完美。在库克看来，创新永远是苹果公司致胜的有力武器，只要能保持不断的创新，苹果公司就可以在业界保持领先的地位
]]></content>
      <categories>
        <category>读书</category>
      </categories>
      <tags>
        <tag>读书</tag>
        <tag>乔布斯</tag>
        <tag>库克</tag>
        <tag>苹果</tag>
      </tags>
  </entry>
  <entry>
    <title>二十几岁比别人幸运，就靠这9个好习惯</title>
    <url>/2013/12/21/book-%E4%BA%8C%E5%8D%81%E5%87%A0%E5%B2%81%E6%AF%94%E5%88%AB%E4%BA%BA%E5%B9%B8%E8%BF%90%EF%BC%8C%E5%B0%B1%E9%9D%A0%E8%BF%999%E4%B8%AA%E5%A5%BD%E4%B9%A0%E6%83%AF/</url>
    <content><![CDATA[二十几岁比别人幸运，就靠这9个好习惯习惯一旦养成，就会成为支配人生的一种行为力量，它可以主宰人的一生。

播下一种行为，收获一种习惯；
播下一种习惯，收获一种性格；
播下一种性格，收获一种命运；


树立目标并做好规划，目标要打，并专心致志，制定一个完成目标的可行性计划，并开始行动；
塑造一种可以战胜一切的品质，品格是人生的王冠和荣耀，记住有志者，事竟成，对别人的宽容就是对自己的宽容，要有责任感，成功源于细节；
了解各种为人处世的细节，敢于怀疑才会有进步，感恩的心会使人变得愉悦和健康，消除嫉妒心，把幸福分给别人，幸福才会更多，你付出什么，就会得到什么，换位思考，学会理解，尊重他人才能包容一切
调节好情绪与心态，控制好你自己的情绪，记住，情绪成就一切，你的心态决定生活状态，保持开朗，打开心灵之窗,,正确对待人生的各种得失,学会冷静，会调节与释放压力，心有多大，舞台就有多大
学会高效工作，学会规划自己的时间，确定工作的优先次序，切忌三心二意，有了计划要马上付诸行动，好的习惯是提高效率的关键
正确支配自己的财富
开发自己的创造力，留住刹那间的思维火花，
捕捉每一个属于自己的机会，，机遇只垂青有准备的人
努力找寻人生的真谛，学会从不同的角度看问题，生活的不如意大多源自于比较，平静是一种难得的幸福，时常与自己的心灵说说话，推荐打坐，嘿嘿

]]></content>
      <categories>
        <category>读书</category>
      </categories>
      <tags>
        <tag>人生</tag>
        <tag>励志</tag>
        <tag>心态</tag>
        <tag>时间</tag>
        <tag>目标</tag>
        <tag>工作</tag>
        <tag>机会</tag>
      </tags>
  </entry>
  <entry>
    <title>人间值得</title>
    <url>/2019/03/13/book-%E4%BA%BA%E9%97%B4%E5%80%BC%E5%BE%97/</url>
    <content><![CDATA[人间值得
中村恒子 奥田弘美

人生，只要能照亮某个角落就够了
我觉得解决的关键在于，在现实和自己的心情之间找到平衡点。简单来说，就是如何把人生过得值得，过得欢喜。
别人可能会给你各种各样的建议，其实到最后还是要靠自己。归根结底，不过是要弄清楚自己想如何生活，想做什么。
恒子老师的生活方式，用一句话来说就是“平平淡淡地过好每一天”。她既不潇洒，也不高效，但无论什么时候，都会做好眼前的事。在她的身上，看不到任何执念。
第1章：工作是为了什么
当自己能够自食其力，凭借自身的能力在社会上立足，就会开始被周围人认可，觉得你“可以独当一面的大人”。
当你面对“为了什么而工作”感到迷茫时，你就干脆而果断地告诉自己“工作只是为了赚钱养活自己而已”。这就是人为何要工作的根本。
至于“人生价值”“自我成长”之类，是要等自己立足安稳后，在闲暇之余慢慢思考的问题。人生很长，慢慢思考就好了。
02 在思考“这份工作不适合我”之前，先试着挑战一下。不那样的话，人就会止步不前
这份工作不适合我”之前，先试着挑战一下。不那样的话，人就会止步不前
如果被权力、地位、名誉之类的东西紧紧束缚住，在工作中一味地在意别人的眼光，很快就会疲于应对。要是这般勉强度过几十年，迟早会被工作击垮。其实，每个人都没有必要对工作期待过高。新员工也好，老员工也好，对于上司安排给你的工作，不要想太多，先试着去做
当人活到七老八十的时候，“胜利”与“失败”都毫无意义。
不要把自我价值全部建立在工作上，带着“为身边的人略尽绵力”的想法去工作，或许会更好。饮食足以温饱，有工作需要自己，其实这样的生活刚刚好。
03 即使你不喜欢工作，也没有关系，尽可能去做总比瞎想强
过多的“空闲”，有时会带来负面影响，“适当忙碌”的状态反而更好
04 工作的去留自己决定，别人无从干涉
如果工作让你一直做出巨大的牺牲，那一定要果断离开，毫不犹豫。
06 不强求改变别人，不如把心力放在“自己如何才能快乐生活”
不要试图通过改变他人来获得快乐，而是想“自己如何做才会快乐”或“怎么努力让自己在这里心情愉快地度过”，我觉得这才是应该考虑的关键。
07 即便是家人也要分清彼此，强迫他人，自己和对方都很痛苦
来则欢喜，去则放手”，这对彼此来说是最轻松的。
08 不要认为别人的给予理所当然，感谢你所得到的，并且不再奢求更多
无论在职场还是家庭，“只要是别人给予的东西，自己就应该感谢对方”。如果以这样的心态和别人相处，人际关系就不可能出现大的问题。
09 尊重别人，别人也会尊重你
如果你想让对方尊重自己，自己当然先要尊重对方。道理虽然简单，但我觉得这是非常重要的事情。
10 机会源于偶然，如果有人助力，就顺势而为
总想着得失，那么就会觉得勉强自己，甚至产生心结。与其如此，还不如率性而为，跟随心的决定。
第3章：恰到好处的人际关系
心灵的沟通，其实就是把自己放到与对方平等的位置上，倾听对方的内心世界。
12 不要小气，接受小小的请求，让微小的善意流转
人和人之间就是互相帮助的关系。如果你是一个容易接受拜托的人，那你在人际关系中的摩擦就会很少。
13 争执之后先道歉才是胜者，如果一遇事就发飙，你将无法立足
我会尽量抛弃“我才了不起”的想法，这样的话自己感到轻松，周围人也轻松。
14 交朋友要根据自己的喜好来选择，通过权衡得失来交往是不可取的
当你想要“遵从内心而活”，你就会发现自己不会被外在多余事情所困扰
15 和那个人该交往还是远离，不要急于寻找答案，调整心理的距离感就够了
生老病死另当别论，人生的一切选择，最终都是以为自己负责的态度来决定
16 就算一个人设计好自己的生活方式，也不会照着做，因此，人生没必要详细计划
只要自己存在，就要带着一种包容力让别人平和下来。让自己成为别人愿意自然而然打开心扉，找你倾诉烦恼的精神科医生。
第4章：让心归于平静
不要忽视你面前的事情，这是最重要的事情。自己的工作也好，孩子也好，家务也好，不管怎样都不能让眼前的生活过得凌乱落魄。
18 痛苦会成为今后重要的经验，所以一次也不要浪费
人生总会遇到不愉快的事。有些事能靠自己解决，而有些事我们无能为力。
人毕竟是伟大的，无论遇到什么样的环境，都有可能坚定地认为“这就是自己的人生”，然后顺其自然地走下去。
大多数事情都会得到解决，人生只能笑着走下去。
即使遇到困难，只要该吃就吃，该睡就睡，保持身体健康，坚持努力，很多问题就会迎刃而解。所有的经历都是有意义的，如果你有这种真切的感受，在关键时刻就会更努力工作。
19 接连发生不顺的时候，也不要停下脚步，停下来就无法前进
如果总也不顺利，那么你就要意识到，“人生本来就是这样”。“不顺”不只会光顾你的人生，我接触过各种各样的人，不管什么样的人都会经历不顺。这时，我们不妨学着练习“逆境中的生存之道”。
20 晚上好好睡觉，确有急事时快速处理，其他一概不管
保持心平气和的另一个有效方法，就是“工作时间以外，不考虑工作上的事”。
在非工作时间，尽量不要考虑工作上的事。
21 “没有自信”并非坏事，盲目自信才是最危险的
所谓自信，是原本做不好的事一点点取得进步。
面对没有自信的事情，一定要真诚坦率。这对于获得平静的生活是很重要的事情。
22 从悲伤或打击中走出来，要依靠“日药”而非建议
痛苦与伤心，其实也是与生俱来的东西。人活着，肯定会经历苦难。
23 人很难不与他人比较，即便健康有活力的人，未必没有烦恼
和别人比较让自己陷入失落、嫉妒中，实在毫无意义，这只会消耗你的精力。
24 不得不努力的时刻，一定会到来。所以，如果不是这样的时候，就无须太过努力
不要事事都想咬紧牙关挺过去，只要抱着“今天这样做基本就可以了”的态度，日复一日地坚持积累。
第5章：生活和工作的平衡之道
在我看来，与其追求完美而挫折不断，不如以笨拙的方式坚持下去。
26 家庭和睦比什么都重要，只要守护它，其他都会慢慢变好
父母的心情会扰乱孩子的内心，孩子的波动反过来又会反弹给父母。
无论是孩子还是家庭，不要试图追求完美，保持一种细水长流的态度，结果会更好。
27 人生常常需要忍耐，思考可以轻松忍耐的方法
生活如果没有目标，就会变得懒散。一旦决定“今天这样做”，生活一下子就会张弛有度。
28 所谓育儿，其实也是成长
提醒别人的事情，自己如果做不到，更加不好。即使是孩子，也会看穿大人的一言一行。因此，要想改变孩子，首先得改变自己。这样，通过育儿，也会注意到自己一些为人处事的方式。
育儿过程，就是让自己越发优秀的成长过程。养育孩子，也是成长。
29 对于养育孩子，比起技巧，更重要的是行动
即使你工作很忙，也要尽可能以某种形式，让孩子感受到“我一直在关心你”。如果你这样做了，孩子一定会感受到父母的用心。
即使你不心灵手巧，也没有奇思妙想，但如果有时间，就尽量亲自动手做饭；尽量多陪在孩子身边，当他们想找你聊天的时候，认真倾听；不要把孩子只当作小孩子对待，多尝试和他们一起思考，时不时问他们“你会怎么做？你是怎么想的”之类的问题。父母对孩子的爱就是这样日积月累的。令人不可思议的是，孩子能够感受到父母是真的为自己着想，而不是只停留在形式上的关爱。
30 不要阻碍别人自立，如果全面掌控，成长就会停止
对于孩子，父母该管教的时候，应该全身心地投入，孩子才会安心成长，直至独立生活。
不管怎么样，孩子既然开启了自己的人生，父母就不要贸然闯入。
31 孤独地死去非常好，担心死亡的方式毫无意义
死亡后，无论你是被称赞，还是被评论，都与死人无关，因为听不见他们在说什么。
任何事情有开始就会有结束。人只要出生，就会面对死亡。
死亡后，无论你是被称赞，还是被评论，都与死人无关，因为听不见他们在说什么。
第6章：简单生活每一天
“总之，只要活着，人生总会有办法的。能吃饱，能睡好，有一份维持最低限度生活的工作，一定没问题。即使有什么不顺心，也不要太在意。”
33 他人有他人的人生，自己有自己的人生，界限分明，冲突、压力就会减少
每天努力地生活，拼命做好眼前的工作。至于出人头地、享受奢侈人生之类的，完全没有时间考虑
在追求的过程中，一定要分清自己是自己，他人在实践他人的人生，我们不需要追寻别人的脚步。
34 人际关系的秘密在于“距离感”，不可逾越的界限，一定要保持住
越是对别人讨厌、反感，这些情绪就越容易在自己的表情和态度上反映出来，进而传达给对方。
36 事情不会马上有结果，焦虑的时候心里不要七上八下，也不要思考过去和未来，而是珍惜当下
人生的结果，不会马上显现。但是在每个瞬间，都有必须珍惜的事情。
37 不求功成名就，只要能照亮某个角落就够了
不求功成名就，只要能照亮某个角落就够了
其实，每个人都有不同的人生轨迹，没有必要和他人比较。
人做事往往凭借自己的感觉，到底“应该这样生活”还是“应该那样生活”，常常会做出片面的决定。有的人认为赚很多钱就是厉害，有的人觉得实现梦想才是伟大的。
点评
最触动的一句话 人生只要能照亮某个角落就够了！
]]></content>
      <categories>
        <category>读书</category>
      </categories>
      <tags>
        <tag>人生</tag>
        <tag>读书</tag>
        <tag>温情</tag>
      </tags>
  </entry>
  <entry>
    <title>其他星球上有生命吗</title>
    <url>/2007/04/18/book-%E5%85%B6%E4%BB%96%E6%98%9F%E7%90%83%E4%B8%8A%E6%9C%89%E7%94%9F%E5%91%BD%E5%90%97/</url>
    <content><![CDATA[其他星球上有生命吗太阳是太阳系的中心，是距离我们最近的恒星。
9颗大行星围绕太阳旋转，有160多颗卫星分别围绕行星旋转。
行星行星通常指自身不发光，环绕着恒星的天体。其公转方向常与所绕恒星的自转方向相同。一般来说行星需具有一定质量，行星的质量要足够的大且近似于圆球状，自身不能像恒星那样发生核聚变反应。
“行星”的新定义，这一定义包括以下三点：

必须是围绕恒星运转的天体；
质量必须足够大，来克服固体应力以达到流体静力平衡的形状（近于球体）；
必须清除轨道附近区域，公转轨道范围内不能有比它更大的天体

一般来说，行星的直径必须在800公里以上，质量必须在5亿亿吨以上。
按照这一定义，目前太阳系内有8颗行星，分别是：水星Mercury、金星Venus、地球Earth、火星Mars、木星Jupiter、土星Saturn、天王星Uranus、海王星Neptune。
分类类地行星水星、金星、地球、火星。
顾名思义，类地行星的许多特性与地球相接近，它们离太阳相对较近，质量和半径都较小，平均密度则较大。类地行星的表面都有一层硅酸盐类岩石组成的坚硬壳层，有着类似地球和月球的各种地貌特征。对于没有大气的星球（如水星），其外貌类似于月球，密布着环形山和沟纹；而对于像有浓密大气的金星，则其表面地形更像地球。
行星早在史前就已经被人类发现了，后来人类了解到，地球本身也是一颗行星。
巨行星和远日行星木星和土星是行星世界的巨人，称为巨行星。它们拥有浓密的大气层，在大气之下却并没有坚实的表面，而是一片沸腾着的氢组成的“汪洋大海”。所以它们实质上是液态行星。天王星，海王星这两颗遥远的行星称为远日行星，是在望远镜发明以后才被发现的。它们拥有主要由分子氢组成的大气，通常有一层非常厚的甲烷冰、氨冰之类的冰物质覆盖在其表面上，再以下就是坚硬的岩核。根据上述这一定义，冥王星失去行星地位。
]]></content>
      <categories>
        <category>读书</category>
      </categories>
      <tags>
        <tag>Uranus</tag>
        <tag>Venus</tag>
        <tag>Mars</tag>
        <tag>Jupiter</tag>
        <tag>Earth</tag>
        <tag>Mercury</tag>
        <tag>Neptune</tag>
        <tag>Saturn</tag>
      </tags>
  </entry>
  <entry>
    <title>吃掉那只青蛙</title>
    <url>/2020/02/06/book-%E5%90%83%E6%8E%89%E9%82%A3%E5%8F%AA%E9%9D%92%E8%9B%99/</url>
    <content><![CDATA[吃掉那只青蛙：博恩·崔西的高效时间管理法则（原书第3版）
博恩·崔西

1）人生一定要有梦想，因为它一定会实现。梦想再大也不嫌大，追梦的人再小也不嫌小，每年年初给自己做一个梦想板，把今年的梦想或目标可视化，激励自己每天向它靠近。（2）人生不在于做多少事，而在于把重要的事做到极致。事情是永远做不完的，我们只能有选择地做最重要的事。每天挑出最重要的3件事优先完成，每天花80%的时间和精力吃掉3只青蛙，然后花20%的时间和精力处理杂事，这就是能让我们人生快速出成果的二八法则。（3）没有愿景，一切都是空想；没有行动，一切都是噩梦。行动力是我们获得成功的关键：烂开始、好开展、好结果。把一个巨大的目标分解成可以马上行动的一个个小步骤，一步一步地迈进，最终就能走到你想到达的地方。（4）精力管理是时间管理的基础，身体健康才能保证做事高效，所以为了确保自己每天都有充足的精力应对挑战，我倡导大家一定要养成“3+1”的人生基础习惯：早睡早起、健康饮食、运动健身+正念·冥想。
前言你永远不可能完成所有事情，也永远无法完成你要做的所有任务。对你来说，完成所有任务，然后全身心地放松、享受休闲时光，似乎是一个遥不可及的梦。
你只有学会放弃，把时间和精力放在那些能够改变你生活的重要事情上，才能有效地安排你所要面对的那些事情。
集中精力去完成最重要的事情，彻底地完成它们，并把它们做好，这是人一生取得巨大的成功、成就，赢得受人尊重的社会地位，获取幸福感的关键所在。
成功的关键在于行动，这些原理可以帮助你快速地实现个人绩效的增长，完成可预测的结果，你越快掌握这些技巧和原理，并把它们运用在实际的工作和生活中，你在职业道路上就会进步得越快，比别人更早地突破职业天花板
引言曾经有一句谚语说的是，如果你每天早上醒来做的第一件事情是吃掉一只活的青蛙，你就会欣喜地发现，在这一天接下来的时间里，将没有什么比这个更糟糕的事情了。这只“青蛙”就意味着你最艰巨、最重要的任务。如果你不对最艰巨的任务立刻采取行动的话，很可能你会因为它耽误很多时间。吃掉你的“青蛙”也可能会对你目前的生活产生最大的积极影响。
为了养成专注的习惯，你需要具备3种品质：决定（decision）、自律（discipline）和决心（determination）
首先，下定决心养成做事有始有终的习惯。其次，约束自己反复练习那些想要学习的原则，直至完全掌握为止。最后，无论做什么事情，都要坚定不移，直至养成这种习惯，并使之成为你性格中不可分割的一部分。
要想更快成为你理想中的高效能人士，这里有一种特殊的方法。你可以不断地在大脑中想象：你已经是一个踌躇满志、马上行动、处事果断、专注的人，你的回报和收益将会如何。你要经常把自己想象成为一个挑大梁的人，而且总是能够迅速而又圆满地完成你的各项工作。在大脑中为自己勾画的蓝图，会对自己的行为产生至关重要的作用。因此，一定要把自己想象成为你理想中的人。你在内心为自己刻画的形象，以及你对自己的评价，在很大程度上决定着你的外在表现如何。你能看到什么样的人，你就会成为什么样的人。事实上，每个人学习新技能、培养新习惯、挖掘新能力的潜力都是无穷的。如果能通过反复练习，培养自己克服拖延、迅速完成最重要任务的习惯，你就将进入工作和生活的快车道，踏上成功的加速器。
书面目标的魔力一个人对自己的目标越明确，对实现目标的步骤越清晰，就越容易克服拖延的弊病，
茫然、思维混乱、态度模糊……比如一个人不知道自己应该做什么、应该先做什么后做什么、为什么做这些事情，都是造成他拖延和缺乏积极态度的主要因素。只有积极地寻找更明确的目标和任务，才能克服这些常见的问题。如果一个人对自己想要什么非常明确，他会更清楚地知道如何才能实现自己的目标，会更容易克服拖延的弊病，实现目标。
把目标写在纸上。
研究表明：大约只有3%的成年人拥有明确的目标，并把目标用书面化的方式记录下来。但在受教育程度和能力相等的条件下，那些写下自己目标的人，比没有写下自己目标的人的成就高出5～10倍。
有一个方法对设定并实现自己的目标非常有效，你也可以在自己的生活中运用这一方法。该方法包括7个简单的步骤。
第一步：明确你究竟想要什么。你可以自己决定自己究竟想要什么，也可以和你的老板坐下来，就你为自己设定的目标进行讨论，直到你彻底弄清楚自己应该做些什么，应该按照什么顺序来做这些事情为止。
最糟糕的利用时间的情形之一，是把根本不需要做的事情做得很完美。
第二步：把你的目标写下来。也就是说，将你的想法付诸笔端。一方面，当你把目标写在纸上以后，你为自己制定的目标就清晰化、具体化了。你为自己创造了一个能看得见、摸得着的东西。
第三步：为你的目标设定一个完成的最后期限；在必要的情况下，设定出子目标的期限。一个目标或者决定如果没有应该完成的最后期限，就没有紧迫性，没有真正的起点和终点。如果没有一个最后期限，以及相应的应该完成的任务，你做起事情来就会不由自主地拖延，
第四步：为了实现目标，把你所能想到的、所有要完成的事项都列在一个清单上。只要你一想起新的活动，就添加到清单上。然后不断地完善你的清单，直到把所有事项罗列完整为止。这样的一份清单能够将你的目标和任务具象化。
第五步：进一步梳理整个清单，使之成为一份计划。根据优先级顺序来整理计划。请你花一点时间，决定什么事情要放在其他事情之前做，什么事情应该先做，什么事情可以往后放。这里还有一个更有效的方法：你需要在一张单页纸上，把计划中的任务用一系列具象的方框或圆形的流程符号表示出来，然后用直线和箭头把每个任务连接起来，标明相互之间的关系。
第六步：根据计划马上采取行动。你应该马上做点什么事情，做什么都行。即使这个计划平淡无奇，只要你充满激情地按照计划执行，就好过制订一份出色的计划，却无任何行动。
第七步：每天解决一部分问题，向前推进主要目标的实现。你需要在每日行动表中列出一天的活动。
明确的书面目标对你的思想有不可思议的影响力。它能激励你不断地采取行动，它能像其他要素那样，激发你的创造力，释放你的能量，帮助你克服拖延症。
现在就拿出一张纸来，列出你明年最想实现的10个目标。在写下这些目标的时候，设想着明年已经过去，这些目标已经实现。
然后，检查你前面列出的10个目标，并从中挑出一个，设想一下如果这个目标实现了，就会对你的生活产生最大程度的积极影响。无论这个目标是什么，都把它写在另外一张纸上，给这个目标设定一个实现的最后期限，然后制订一份计划，并针对计划采取相应的行动，而且坚持每天都做一些有助于你实现这一计划的事情。坚持去做，这项练习会改变你的生活。
提高回报率你在脑海中思考如何行动，制订出计划并做出决定，是你克服拖延症、提高生产力的最有效的手段。这些行动可能包括明确目标、制订计划、采取行动，所有这一切会决定你的生活轨迹。对如何行动进行思考，并进行周密计划的过程会释放你心智中的潜能，激发你的创造力，增强你精神和身体的力量。
计划制订得越周密，你就越容易克服拖延症、迅速行动、吃掉青蛙，并能不间断地保持行动的状态
据观察，每拿出一分钟制订计划，在行动时将会节省出相当于制订计划10倍的时间。所以，每天你只要拿出10～12分钟来制订计划，就能节省出将近两小时的时间（约为100～120分钟）。
不管你是借助最先进的掌上电脑、最复杂的电脑程序，还是借助时间管理器来工作，原理都是一样的：在开始工作之前先坐下来，把你要做的每一件事情都逐条写出来。
无论你准备做什么，都应该先列出一份清单。每次想到什么新的事项，在开始做之前都先把它加在清单上。如果你一直坚持先列出清单再开始工作，那么，从一开始你的生产力就能提高25%，相当于每天节省出两小时。当前一天的工作结束以后，要开始制订第二天的计划。把尚未完成的事项、需要在第二天完成的事项，都写在第二天的计划上。当你在前一天晚上制订了计划之后，即使你入睡了，你的潜意识也会围绕这个计划转。通常情况下，当你第二天早上醒来时，你的脑海中就会涌现出灵感，从而使你能更快、更好地完成工作。在制订必须完成的工作计划上，你提前花费的时间越多，你的工作效率、工作的有效性就越高。
你需要针对不同的目标制订不同的计划。首先，你必须拟订一份总计划，在这份计划上，你把能想到的、未来能做的每一件事情都写下来。在这份总计划上，你要写下脑海中想到的所有任务以及相应的职责。之后你可以对计划中的事项做进一步整理。其次，你应该在每个月月末，为下一个月要做的工作制订一份每月计划。其中的某些事项可以是从总计划上分解到这里的。再次，在每周工作开始前，你要提前制订一份每周计划，来计划一周的工作。每周计划是基于你对整周工作的统筹而制订的。
不论你要完成什么项目，都应该在行动之前先制订一份计划，在这份计划上把你要完成的工作、所需要执行的每一步工作都写下来，然后根据它们的重要程度安排先后顺序。
个人高效能工作的最重要的法则之一是10/90法则，即整个工作的前10%的时间用于制订计划、组织工作，那么在实际完成工作的过程中将节约90%的时间。

从今天开始，你要对每个月、每一周、每一天的工作提前制订计划。请拿出一个记事本或一张白纸（也可以用你的电子助手或手机上的软件），把未来24小时内要做的所有事情都列在上面。当你随时想起需要添加的事项时，就把它们写进去。把所有关系到你未来的重大项目写下来，放在一个单独的清单里。2. 把每一项主要目标和任务都写在计划上，然后根据优先级和时间顺序，把最重要的和需要最早完成的排在前面。然后安排次重要的，并以此类推。最后以计划的终点倒推工作的起点。

任务的数量vs任务的重要性80/20法则是时间管理与生活管理方面最有用的概念之一。
通常来讲，如果在一张项目计划上列出10项任务，其中一项你必须完成的任务远比其他9个剩下的任务更有价值。那么这项任务就是你应当最先吃掉的青蛙
很多人的拖延清单中最多的就是能产生最大价值的最重要的10%～20%的项目，这些项目是“极重要的少数”。人们忙碌于那些不重要的80%的项目部分，在对回报没有太大影响的“不重要的多数”工作上花了很长时间。
你常常能够看到有的人终日忙忙碌碌，但几乎看不到工作的结果。这几乎可以全部归因于：他们忙碌的是一些低价值的任务，但对某项重要的活动却一再拖延。如果他们能又快又好地完成这些重要的活动，无论对公司还是他们个人的事业都会产生实质性的、重大的影响。每天你能完成的最重要的任务通常是最艰难、最复杂的任务，但是，圆满地完成这些任务所带给你的回报和奖励也是巨大的。鉴于此，如果你还有最重要的20%的工作没有完成，你必须坚定地拒绝做重要性很低的那80%的工作。
抵制诱惑，不被小事所引诱。你要记住，不管你选择先完成什么任务，久而久之都会形成一种固化的习惯。如果你选择每天先做低价值的任务，你将很快养成先做低价值任务的习惯。这一定不是你希望养成或保持的习惯。你要在一开始就处理重要的任务中最难的部分。一旦你开始处理最有价值的任务，你才会很自然地有兴趣继续往下做。如果你在思想上愿意为了有意义的任务来忙前忙后地工作的话，那么你会看到完全不同的结果。然后你要通过不断地以这种思维工作，进一步强化头脑中的这种意识
如果你在脑海中设想一下，开始完成重要的任务以及完成了重要的任务的场景，你就能以此激励自己，战胜拖延症。事实上，完成一项重要的工作所需要的时间与完成一项不重要的工作所需的时间通常是一样的。区别是你完成重要的、有意义的工作能获得极大的自豪感和满足感。然而，当你完成一项低价值的工作时，即使耗费了同样多的时间和精力，你也只能得到很少的满足感，甚至一点满足感也得不到。

制订一份计划，在上面列出今天你所有关键的目标、活动、项目、生活上的责任。有没有可能在这些任务中，最重要的10%～20%代表了或可能代表了你80%～90%的结果？2. 今天就来解决这个问题：对于可以改变你的人生和事业的少数活动，你应该花费越来越多的时间；对于不会影响你的人生和事业的低价值的大量活动，你花费的时间应该越来越少

对时间的配置做出更好的安排成功基于个人对于时间的态度，不论是工作还是生活，成功人士在做每天、每周、每月的活动规划时，都会用长期的观点去考量。
你对时间的处理态度、你的“投资回报期”会对你的行为和选择产生重大的影响。与没有长期时间观念的人相比，能够运用长期时间观念规划生活和职业前途的人似乎能对自己的时间和活动做出更好的决定。
成功人士是那些懂得延迟满足感，愿意做出短期牺牲来追求长期高回报的人。
不断地鼓舞自己，激励自己。如果一项活动或行为会对你的生活产生重大的、积极的影响，那么一旦你清晰地锁定目标，你会不断地被激励，从而有动力克服拖延症，并迅速把它做好。然后，持续地启动、完成那些能对你的公司和未来产生重大影响的任务，你会集中精力、勇往直前。
经常思考你做出的选择、决定和行为是否能产生积极的发展前景及对未来的影响，这是确定你的工作和个人生活中的优先级顺序的最好方法之一。
强迫效率法则的详细解释是：“时间有限，任何人都无法做完所有的事情。但只做那些以后能获得正面效果的工作，做与完成最大目标有关的工作，你的时间是足够的。”换句话说，你无法吃掉池塘里的所有蝌蚪和青蛙，但是在当下，你能吃掉最大、最丑陋的那只就够了。
一个人如果在最后期限的压力下工作，通常他会不由自主地拖延，也会承受更大的压力、犯更多的错误，比无压力状态下的返工率更高。
如果你想专注地完成计划上最重要的任务，每次要问自己3个固定的问题。第一个问题是，“我的最高价值的工作是什么？
第二个问题：“我只有把哪件事情做好了才会产生非凡的影响？
第三个问题是：“在此时此刻，对我来说最有价值的事情是什么
第三个问题是时间管理的核心问题。能否正确地回答这个问题，是一个人克服拖延症、成为一个高效率的人的关键。每一天中的每个小时，你当时完成的任务，代表着你利用那段时间的最大价值。你要反复问自己第三个问题，要不厌其烦地一次次地重复问自己，不管答案是什么，都要不断地着手处理它。

回顾一下你的相关任务、活动、项目。不断重复地问自己：“在工作或个人生活中，我出色又及时地完成哪一项项目/活动，会给我带来极大的正向回报呢？”2. 每天的每个小时，你要决定这个时间单元最重要的事情是什么，然后约束自己不断地将时间用在最有价值的工作上。思考下一步最重要的事情又是什么，如此循环。不管接下来要做的工作是什么，都把它设定为一个目标，为此制订一项计划，并立刻行动去完成这项计划。记住歌德的那句名言：“只有找到能够吸引你、让你燃起内心激情的部分，并马上投入其中，你才能完成你的工作。”

优先级高低之分每天都抽出时间推进那些艰巨任务的实施。提前计划好一天的工作量，用最高效的时间完成最重要的工作。每天早晨先挑选出一些最紧迫的简单工作，继而直接开始完成大任务，专注地去做，一直到完成为止。
事实上，每个人都不可能做完所有的事情。你必须有选择地去延迟完成一些事情，一些简单任务不立刻去完成，而是实行创造性拖延。也就是说，有些事情必须向后拖延。选出一些较小、不太丑的“青蛙”，向后推迟一段时间再吃。把那些最大、最丑的“青蛙”安排在第一时间吃掉。先处理最艰难、最复杂的任务
当你不再去做那些低优先级的工作时，你的时间和生活才能完全掌握在自己手中。
大多数人都会无意识地拖延，人们的拖延往往是没有经过周密考虑的结果。这会导致人们拖延工作量浩大的、高价值的、重要的任务，从长期来看，这些任务将对他们的事业和生活产生重大的影响。因此，你必须想尽一切办法，避免这些跟别人趋同的规律发生在你身上。你的任务就是，对那些优先级低的任务进行拖延，从而可以腾出更多的时间来做那些改变你的工作和生活的任务。

在生活的各个方面，你都可以应用归零思考法（zero-based thinking）来思考问题。不断地问自己：“如果我还没有开始做这件事情，而且我已经知道做完的后果，今天我还会如此这般再做一次吗？”如果答案是否定的，那么这件事就应该创造性拖延或取消。2. 根据你目前的状况，重新审视、评估你工作和生活中的活动，挑出其中至少一项，立刻放弃，或者创造性拖延，直到你完成那些更重要的事情为止。一边思考，一边把你思考的结果写在纸上

成功的第一定律是专注，是把所有精力聚焦在一点上，然后向着这一点的目标努力推进，不要瞻前顾后。
在开始处理一项工作之前，你在制订计划、设定优先顺序方面投入得越多，你所做的事情就越重要，一旦开始工作，你的效率就越高。你所从事的工作越重要、越有价值，你克服拖延症、全力投入该工作的劲头也就越足。

现在，回顾你的工作计划，然后在每一项任务或工作之前标上A、B、C、D或E。选择标记为A-1的工作或任务，然后立即动手处理，切记必须在完成这项工作之后再开始做其他工作。2. 在接下来的一个月，每天都练习使用ABCDE法来处理每一项工作。这样坚持一个月以后，你就会养成先处理优先级最高的任务的习惯，你的未来就会尽在掌握之中！

管理和销售工作中的7大要素关键结果领域是你工作成功所必须取得的结果。它是完全由你负责的工作领域。如果你不把它做好，那么没有人代替你完成。关键结果领域是在你控制下的活动。它是你工作的产出，同时也会成为别人工作的输入或有用的因素。
管理的关键结果领域是计划、组织、配备人员、授权、监督、检查和报告。
无论从事什么工作，你都必须掌握完成工作所必需的知识和技能。对知识和技能的要求是不断变化的。你只有提高核心竞争力，才能很好地完成你的工作。但是，关键结果领域永远是你工作的中心并决定你工作的成败。
提高生产力的起点是，首先搞清楚你工作的关键结果领域。你可以同领导讨论这些关键结果领域。列出你的产出责任并确保你的领导、同级和下级都同意你所列出的产出责任清单。

找出工作中的关键结果领域。这些职责是什么？把它们写下来。找出自己在每个环节内的优劣势。然后，确定一种技能，如果你在这方面优势突出的话，那么它将对你的工作有极大的帮助。2. 带着这张清单去拜访你的领导，并与他讨论清单上列出的工作。请他做诚实而中肯的评价。只有虚心听取他人提出的建设性意见，才能不断地完善自己并取得进步。此外，还要与你的同事、爱人进行探讨、交流。在你以后的职业生涯中，应该养成定期进行分析的习惯。不断强化这种习惯，这个决定本身就能改变你的生活。

每天只做一项工作请你在30秒之内，把生活中最重要的3个目标写下来。”通过这个练习我们发现，如果只给人们30秒钟让他们写下3个最重要的目标，他们的答案非常准确，结果跟经过30分钟或3小时思考的一样。
80%的人的3个目标是一样的：第1个目标是经济和事业方面的；第2个是家庭或人际关系方面的；第3个是健康或身体方面的。
学习时间管理技巧的一个主要目的是，从现在开始，你可以去做那些真正重要的工作，并腾出更多的时间去做那些生活中能给你带来最大的幸福感和满足感的事情。
生活中有85%的幸福感来自与他人的和谐的关系，尤其是与那些和你关系最密切的人，以及家人的关系。决定你人际关系质量的关键因素是，你与爱人相处时间的长短。学习时间管理的目的在于提高效率，这样你会有更多的时间去陪自己爱的人，有更多的时间去做那些能最大限度地给自己带来快乐的事情。

找出工作中最重要的1项任务。你可以问自己：“如果我每天只能完成1项任务，哪项任务对我的工作贡献最大？”然后重复两遍同样的问题。按照这种方法找到工作中最重要的3项任务之后，每天把所有的精力全部放在这3项任务上。2. 确定生活中最重要的3个目标，然后根据优先级别进行排序。针对这些目标制订相应的计划，然后全力以赴去实现。持续几个月至若干年之后，你会为自己取得的成就感到惊讶。

创造舒适的工作空间不管与生俱来的能力是高是低，你的潜力永远大于你一生所表现出来的能力
克服拖延、提高工作效率最好的方法之一，就是在开始工作之前做好充分准备。如果你的准备工作做得很充分，那么开始工作的时候你就会像满弓上的箭一样，蓄势待发，只需要一点点动力，就能着手处理最重要的工作了
将所有与完成工作有关的信息、报告、详图、文件等资料收集在一起，全部放在手边，当你需要的时候，不需要起身或离开座位去找它们。确保你收集齐了所有的书面资料，包括登录信息、密码、邮箱地址，以及从工作开始到完成所需的都已经准备妥当。

认真地检查你家中和公司的办公桌，然后问自己：“哪个类型的人会在这种环境中工作？”你的工作环境越干净、整洁，你就会越积极、高效、自信地投入工作。2. 下定决心，今天就把办公桌和办公室收拾得干干净净、整整齐齐，这样你会感觉每次都能高效地开始工作。

穿越撒哈拉沙漠
任意选择一个曾经被你拖延的目标、任务或项目，从现在就开始迈出第一步。有时候，要开始一件事情并不难，你只需坐下来，把所有必要的步骤都列出来就足够了。2. 接下来，马上从第一步开始，一步一步、循序渐进地去做这件事情。最终你会惊讶地发现自己取得的成就非凡。

学无止境所有成功都有共通的意义，无论你的任务是什么，坚持更多、更好地付出，都是确保你获得成功的不二法门。
成为大师的3个步骤
首先，每天至少阅读1小时，以了解行业最新动态。每天早晨尽量早一点起床，阅读30～60分钟的图书或杂志，其中应包含有助于你提高生产力和工作效率的信息。
其次，参加有助于你提高工作技能的每一堂课程和讲座。参加行业内的研讨会和专业会议。更不要错过任何高水平的培训和讲习。坐在前排认真做笔记，并购买活动的音像和影像资料。下决心把自己培养成业内知识最渊博、最有竞争力的人。最后，一边开车一边收听你购买的音像资料。

找出能够帮助你更快更好地实现目标的、最有效的关键技能。决定你必须具备哪些核心竞争力，这些核心竞争力能够在未来让你在专业领域脱颖而出。不管这些能力是什么，你都要设定目标、制订计划、开始构建和提升该领域的能力。在自己能力所及的范围内做到最好。2. 为了出色地完成最重要的任务，你应该制订一项个人计划，让自己充分地做好准备。专注于那些你具有特殊天分，并且非常感兴趣的领域。这是打开个人潜能的钥匙。找出限制因素

现在就确定你生活中最重要的目标。这个目标是什么？一旦实现这个目标，是否会对你的生活产生极大的积极影响？你工作中的哪项成就会对你的职业生涯产生非常积极的影响？2. 一旦明确了自己最重要的目标，你可以问自己这些问题：“是什么制约了我实现这个目标？为什么我还没有实现自己的目标？是什么制约着我的进步？”找到答案后，立刻行动起来解决这些问题。你想做什么都可以，但必须要行动起来。


成为业内的领军者成功的第一要素是：必须全身心地做一件事情，决不能有任何懈怠。
只有约2%的人能在完全没有监督的情况下工作，这样的人可以说寥若晨星。我们称这些人为“领导”。只要你愿意，并且下定决心做一个能自我监督的人，那么你一定能成功。
有一个最好的办法能帮助你克服拖延症：假设距离完成最重要的工作的最后期限只有一天。

为自己的每一项任务和活动设定最后期限和各个阶段的最后期限。自己制定一个“强制系统”。不断提醒自己设定的最后期限，不让自己有丝毫的松懈。一旦设定最后期限，就严格执行，力争提前完成工作。2. 在开始最重要的工作前，把你的每一个步骤都写下来，然后确定每一步需要用多长时间。在你一丝不苟地完成这些工作的过程中，让自己不断与时间赛跑，并尽量提前完成工作。可以把这个当作一项游戏，让自己胜出。

控制你跟心灵的对话你对自己的评价、自爱、自尊的程度，在很大程度上决定你工作时自我激励的程度，及能否坚持不懈地工作
维克多·弗兰克尔（Viktor Frankl）在畅销书《活出意义来》（Man’s Search for Meaning）中所写的那样：“人类的终极自由是在现有的任何一种环境中选择做自己的态度
“乐观”的性格是事业成功、生活幸福的最重要的品质。几乎在生活中的方方面面，乐观的人的做事效率都更高。
乐观主义者有4个显著的特征，而这些特征都是通过反复实践学来的。第一个特征，乐观主义者在任何情况下都会去看事情好的一面。无论出现什么状况，他们都会努力寻求有益的一面。第二个特征，乐观主义者总是能从挫折和苦难中总结经验，吸取教训。他们相信，“困难的出现不是为了挡住去路，而是为了指明出路”。他们相信，每一个挫折和障碍中都蕴含着有用的教训，他们会从中吸取教训。第三个特征，乐观主义者总是极力找出问题的解决方法。出现问题的时候，他们不是指责他人或不停地发牢骚，相反，他们总是尽自己的最大努力去寻求解决问题的办法。他们提出的问题是：“解决这个问题的方法是什么？我们现在应该怎么做？下一步应该怎么做？”第四个特征，性格积极、乐观的人会不断地思考和谈论他们的目标。他们总是在思考自己究竟想得到什么，如何得到他们想要的。他们所想所说的是未来，是他们想要实现什么样的目标，而不是过去曾经得到过什么。他们总是向前看，而不是向后看。

控制自己的思想，让自己总是保持积极的态度。记住，你会成为你想成为的那个人，所以，只说你想说的，只做你想做的。2. 勇于面对现实、承担责任，使自己保持积极的心态。无论遇到什么事情，都不要去批评、埋怨、指责别人。去改善，而不是责怪。集中思想和精力向前看，不要理会其他。

你要有所选择“每天我会定时查看两次邮件。当我看到您的消息后，会尽快回复。如有紧急事宜，请致电我的手机。”

在日常生活中，给自己留出一部分独处的时间。每天上午和下午各安排一个小时，在这段时间里，把所有的通信设备都关掉。你会惊讶地发现，没有什么区别！2. 每周都给自己安排一整天时间。在这一天里，不开电脑，不用手机，也不使用任何方式与外界联系。到一天结束的时候，你会发现自己的心灵异常平静，思路格外清晰。当你腾出时间重塑精神能量之后，你吃青蛙会更有效率。

掌控你的通信
今天就痛下决心，推掉所有的通告，只给自己留下一个处理紧急情况的渠道。为你最重要的任务创造一个数字化生活的特定空间。2. 下决心研究、安装一个软件或App，让它帮你变得更加高效和专注。上瘾

生命完全是一场专注力的修行，你专注于哪里，你的生命就在哪里。
处理完网络上的一个突发事件后，人们通常需要花费7分钟才能完全将注意力从前一件事情上转回到原来的任务中，然后继续工作。
已经被各行业的高效能人士广泛采用。第一，清晨不要检查邮件，这样才会避免新邮件刺激大脑，释放出全天的多巴胺，分散注意力。让你的设备仍处于关闭的状态。第二，如果由于特殊原因，你需要查看邮件，那么你需要尽快切换到邮件处理状态，然后迅速地结束。关掉电脑的声音提示音，让你的手机处于“震动”状态。停止刺激和触发多巴胺的释放，停止其他不断引发注意力中断的刺激。第三，下定决心每天查看两次邮件，把时间定在上午11点和下午3点半，处理完之后就关闭邮箱。给他人提供一个在紧急情况下可以找到你的电话号码。不论你是跟别人一对一开会，还是给更多人开会，都采用上述的协议。把电子设备关掉。不要打断别人与你的在线合作，或者中途接听第三人的来电，因为这些举动对对方而言都是不礼貌的。一定要为对方100%地专注。这一条协议也适用于在家里发生的情况。
第一，每天提前制订一整天的计划，选择出你最重要的任务，然后开始完成该任务，直到全部结束为止，在彻底完成该任务之后，再开始做其他的工作。第二，持续不间断地连续工作90分钟，期间不要有任何的干扰和注意力的分散，然后让自己休息15分钟。第三，投入全部精力再次开始下一个90分钟的工作。第四，完成了为期三小时的工作后，你终于可以奖励自己查看邮件，刺激多巴胺冲击你的大脑了。当你建立了这一习惯，在每天上午首先抽出连续3小时完成重要工作后，你将让你的生产力提升到两倍，并能够克服全天不定期查看邮箱的陋习。你将会全面掌控自己的生活。

在大脑中保持对成功目标和高效生产力的追求。在你开始做任何事情之前，都要先问问自己，“这会帮助我达成最重要的目标吗，还是仅仅是一个干扰而已？”2. 拒绝成为各种警报声和提示音的奴隶，这些只会使你从即将真正改变人生的任务中分心。让你的通信设备处于关闭的状态。

设定强制关闭机制吃掉那只青蛙1. 立刻将这些技巧付诸实践。选择一项你拖延的复杂而艰巨的任务，无论是用“香肠工作法”还是“奶酪工作法”，都去立即着手处理这项任务。2. 把自己变身为“行动派”。高效能人士有一个共同点，每当他们听到一个好点子，就会立刻行动。所以他们学得更多，学得更快，并能得到更好的结果。不要迟疑。今天就试试这种方法！
为整块时间制订时间表如果你把全部精力集中于一组有限的目标上，那么你的未来将不可限量。
许多重要任务都要花费大块的时间不间断地完成。你能否找到大块的、可利用的时间，关系到你能否在工作、生活中取得大的成就。
许多人把每天晚上睡觉之前的15分钟用来阅读精品图书。
很多高效能人士都是这样做的，他们总是提前安排每一天的工作，安排特定的时间段来处理特定的事情。他们的目标是一次完成一项重要工作，并根据这一原则来规划自己的职业生涯。
在这段工作时间之内，你关闭手机，不受任何来自外界的干扰，不间断地进行工作。最好的工作习惯之一就是每天早早起床，然后在家里工作几个小时。在这段时间里，没有人打搅你的工作。而在忙碌的办公室里，你的周围可能人满为患，电话也狂轰滥炸地响个没完没了。相比之下，你在家里可以完成3倍的工作量。

多思考和尝试用各种不同的办法来节约、安排或创造大块的时间。用这些时间去处理那些重要的、长期能产生重大影响的任务。2. 充分发挥每一分钟的价值。提前计划并做好准备，从而能够持续不断地、不受干扰地进行工作。最重要的是，把精力集中在你负责的最重要的工作上。

进入最佳状态不要盲目地等待，时机永远不会“恰到好处”地到来。从你现在的位置开始工作，运用你需要的、能找到的任何工具。在前进的过程中，你还会找到更好的工具。
生产力高的人愿意花费时间去思考、制订计划、确定事件的优先级。然后，他们就行动迅速、意志坚定地投入工作，朝着自己的理想和目标前进。他们从容不迫地、循序渐进地工作，在一般人盲目地社交，浪费时间，从事那些无谓的、低价值回报的工作的时候，他们却完成了不计其数的工作。
当你精力充沛、活力四射地投入自己的工作的时候，你会觉得自己的大脑进入了一种充满激情的状态。几乎每个人都有过这样的经历。而真正的成功人士，体验到这种状态的频率要比普通人高得多。这种状态是一个人在工作生产力和效能方面所表现出来的最佳状态。在这种状态下，你的思想和情感通常会发生一些近乎奇迹的事情。在这种状态下，你会感到自己头脑清醒，工作热情高涨，无论做什么事情都既有效又精准。你会觉得自己兴高采烈、充满活力。你会觉得自己做事有条不紊，工作效率非常高。
好的结果是，你行动的速度越快，你的能量就越大；你行动的速度越快，你完成的工作就越多，你的工作效率就越高；你行动的速度越快，你积累的经验就越多，学到的知识也越多；你行动的速度越快，你的工作能力就越强，才能就越出众。

从现在开始，无论做什么事情都要培养一种紧迫感。选择一个自己可能会拖延的领域，决定在这个领域内养成马上行动、决不拖泥带水的习惯。2. 当你看到一个机会或者发现一个问题时，应当立刻采取行动。当你接受了一项任务或承担了某个责任时，应当迅速完成并及时向领导汇报结果。你应当在生活的重要领域快速地行动。当这一切成为习惯之后，你的感觉会更好。

一旦开始，全力以赴力量的真正秘密在于此。学习如何使用资源，然后在特定的时刻把它集中使用在特定的事情上。这一习惯要通过反复实践才能形成。
全力以赴地投入一项工作的要求是，一旦开始做这件事情，就全身心地投入进来，不受外界干扰，不转移注意力，直到100%地完成工作。每当你想停下来，或想要做其他事情的时候，你要不断对自己重复“继续工作”这句话，然后敦促自己不断前进。只要你能全身心地投入对你最重要的事情，就能把完成工作所需要的时间缩短50%甚至更多。
在应该做某件事情的时候，约束自己去做那件事情，无论自己当时想做还是不想做”。归根结底，在任何一个领域内，要想获得成功，都需要极强的自律能力。自律、自制是一个人性格塑造和高效能的基石。

立刻行动！现在就确定对你来说最重要的工作和任务，然后立刻全身心地投入这项工作。2. 一旦开始工作，就约束自己在工作过程中心无旁骛，不受外界干扰，也决不分散自己的注意力，直到工作100%完成，把这个当作一项测试，看自己是否能做出决定并完成。一旦开始工作，就坚持到底，直到全部完成为止。

后记
明确目标：确定自己究竟想要什么。目标清晰至关重要。在每天开始工作之前，把你的目标全部写下来。
每天提前做计划：一边思考，一边把你的想法写在纸上。你花费在准备工作上的每一分钟，都将使你在工作过程中节约5～10分钟。
将80/20法则用于你的所有任务：你的所有任务中，其中有20%的任务能产生80%的结果。因此，尽量把你的精力集中在那20%的任务上。
考虑效果：你最重要的、优先级最高的事情是那些将对你以后的生活或工作产生最重要影响的事情，无论其影响是正面的还是负面的。你应当最优先处理这些事情。5.“创造性拖延”练习：既然你没有时间去安排所有的事情，你就必须学会推迟处理那些没有什么意义的工作，从而腾出时间来处理那些少数的、重要的工作。
持续不断地练习使用ABCDE法：根据自己列出的任务计划，在开始工作之前，先抽出一点时间，根据优先级对这些事情进行安排，从而确保你先处理最重要、最有价值的事情。7. 聚焦关键结果领域：要想圆满地完成自己的工作，你必须具备哪些能力和技能？找出答案，然后日益精进，解决上述问题。
遵守“3个”定律：找出你的工作中的最重要的3件事情，你对公司90%的贡献都来自这3件事情。无论如何，都先把这些事情做好，然后，你才能腾出更多的时间来安排个人的家庭和生活。
做好充分准备再行动：开始工作前，先把一切都准备就绪，包括所有的资料、信息、工具、材料，以及你需要的数据，然后，你就可以全身心地工作了。
每次到达下一个油桶：如果你每次能阶段性地推进下一步工作，那么你就能完成最艰巨、最复杂的工作。
升级核心技能：你在自己的关键领域内知识越全面，技能越娴熟，你动手就越快，任务完成得就越早。
找到最关键的限制因素：确定影响你实现目标的瓶颈和主要障碍，无论是来自外部还是内部，然后集中精力消除这些障碍。
自我设定压力目标：假设你即将离开所在的城市，外出一个月，离开之前必须把所有重要的工作都处理完。
激励自己将理想转化成行动：做你自己的啦啦队队长。在任何情况下，都寻求事情积极的一面。把精力集中在如何解决问题上，而不是问题本身。要保持乐观向上的态度。
技术是一个可怕的主人：把你的时间收回，不要让各种技术分散你的注意力，停止做技术的奴隶。学着经常把手机设备关机，并放在一边。
技术是一个非常优秀的仆人：用技术工具帮你自己处理最重要的工作，把自己从最不重要的工作中解放出来。
集中注意力：停止不断地打扰和分心，影响你正在完成的最重要的工作。
奶酪和香肠工作法：把复杂而又艰巨的大任务分割开来，变成许多部分，每次只处理一小部分。
创造整块的时间：为自己安排一份日程表，然后留出大块的时间来处理对你来说最重要的事情。
保持紧迫感：养成迅速处理关键任务的习惯。把自己培养成一个能迅速、圆满完成工作的人。
单独处理每一项任务：根据事情的优先级安排优先处理哪些事情，然后立即着手处理最重要的、必须优先处理的事情，全心全意地去做这件事情，决不中途停止，直到100%完成为止。这是工作高效、个人生产力最大化的关键所在。

评论这是一本值得常读常看的书籍
]]></content>
      <categories>
        <category>读书</category>
      </categories>
      <tags>
        <tag>读书</tag>
        <tag>阅读</tag>
        <tag>时间管理</tag>
        <tag>自我管理</tag>
        <tag>个人管理</tag>
        <tag>效率管理</tag>
        <tag>方法工具</tag>
        <tag>方法论</tag>
      </tags>
  </entry>
  <entry>
    <title>如何阅读一本书? -- 范多伦,艾德勒</title>
    <url>/2012/12/16/book-%E5%A6%82%E4%BD%95%E9%98%85%E8%AF%BB%E4%B8%80%E6%9C%AC%E4%B9%A6/</url>
    <content><![CDATA[如何阅读一本书? – 范多伦,艾德勒法国学者巴斯卡(Pascal)在三百年前就说过：“读得太快或太慢，都一无所获。”注：读书不能太快或太慢！要有所把握
介绍四种不同层次的阅读—基础阅读(elementary reading)、检视阅读(inspectional reading)、分析阅读、主题阅读(syntopical reading)。
注：四种层次的阅读
阅读越主动，效果越好。这个读者比另一个读者更主动一些，他在阅读世界里面的探索能力就更强一些，收获更多一些，因而也更高明一些。读者对他自己，以及自己面前的书籍，要求的越多，获得的就越多。
注：主动阅读
阅读的目标：为获得资讯而读，以及为求得理解
注：阅读的目标
运用阅读以增加资讯与洞察力，与运用阅读增长理解力
注：阅读的目标
要避免这样的错误—以为读得多就是读得好的错误—我们必须要区分出各种不同的阅读形态。这种区分对阅读的本身，以及阅读与一般教育的关系都有很重大的影响。
注：读的多并不一定是读的好
敏锐的观察、灵敏可靠的记忆、想像的空间，再者当然就是训练有素的分析、省思能力。这么说的理由在于：阅读也就是一种发现—虽然那是经过帮助，而不是未经帮助的一个过
注：阅读的技巧
二个层次的阅读我们称之为检视阅读(inspectional reading)。特点在强调时间。在这个阅读层次，学生必须在规定的时间内完成一项阅读的功课
注：第二个层次
分析阅读就是全盘的阅读、完整的阅读，或是说优质的阅读—你能做到的最好的阅读方式。如果说检视阅读是在有限的时间内，最好也最完整的阅读，那么分析阅读就是在无限的时间里，最好也最完整的阅读
注：第三个层次，分析阅读
如比较阅读(comparative reading)。在做主题阅读时，阅读者会读很多书，而不是一本书，并列举出这些书之间相关之处，提出一个所有的书都谈到的主题。但只是书本字里行间的比较还不够。主题阅读涉及的远不止此。借助他所阅读的书籍，主题阅读者要能够架构出一个可能在哪一本书里都没提过的主题分析。因此，很显然的，主题阅读是最主动、也最花力气的一种阅读。
注：最复杂的主题阅读
层次所可能碰到的各种紧急状况与问题的程度就会明白了。然而，除非我们在所有的阅读层次都投下努力，否则我们社会里有关阅读的整体。特别就一本教人如何阅读的书来说，它的读者必须有某种程度的阅读能力才行。
?(1)先看书名页
注：略读的方法1
2)研究目录页，对这本书的基本架构做
注：略读的方法2
3)如果书中附有索引，也要检阅一下—大多数论说类的书籍都会有索引
注：略读的方法3索引
4）如果那是本包着书衣的新书，不妨读一下出版者的介绍
注：略读的方法4出版商说明
(5)从你对一本书的目录很概略，甚至有点模糊的印象当中，开始挑几个看来跟主题息息相关的篇章来看。如果这些篇章在开头或结尾有摘要说明（很多会有），就要仔细地阅读这些说明
注：略读的方法5随便挑几章看看
6)最后一步，把书打开来，东翻翻西翻翻，念个一两段．有时候连续读几页，但不要太多。就用这样的方法把全书翻过一遍，随时寻找主要论点的讯号，留意主题的基本脉动。最重要的是，不要忽略最后的两三页。就算最后有后记，一本书最后结尾的两三页也还是不可忽视的
注：略读的方法6主动寻找资讯
头一次面对一本难读的书的时候，从头到尾先读完一遍，碰到不懂的地方不要停下来查询或思索。
只注意你能理解的部分，不要为一些没法立即了解的东西而停顿。继续读下去，略过那些不懂的部分，很快你会读到你看得懂的地方。集中精神在这个部分。继续这样读下去。将全书读完，不要被一个看不懂的章节、注解、评论或参考资料阻挠或泄气。如果你让自己被困住了，如果你容许自己被某个顽固的段落绑住了，你就是被打败了。在大多数情况里，你一旦和它纠缠，就很难脱困而出。在读第二遍的时候，你对那个地方的了解可能会多一些，但是在那之前，你必须至少将这本书先从头到尾读一遍才行。
注：读书对的方向！不能因为某个章节不懂而停滞不前，至少完整读下来，多注意那些理解的章节
亚当·斯密(Adam Smith)的经典作品《国富论》(The Wealth of Nations
注：国富论
每一本书，不论是多么难读的书，在无关紧要的间隙部分就可以读快一点。而一本好书，总会包含一些比较困难，应该慢慢阅读的内容
注：快慢的把握
要矫正眼睛逗留于一点的工具有很多种，有些很复杂又很昂贵。无论如何，任何复杂的工具其实都比不上你的一双手来得有用，你可以利用双手训练自己的眼睛，跟着章节段落移动得越来越快。你可以自己做这样的训练：将大拇指与食指、中指合并在一起，用这个“指针”顺着一行一行的字移动下去，速度要比你眼睛感觉的还要快一点。强迫自己的眼睛跟着手部的动作移动。一旦你的眼睛能跟着手移动时，你就能读到那些字句了。继续练习下去，继续增快手的动作，等到你发觉以前，你的速度已经可以比以前快两三倍了
注：矫正眼睛经常逗留，跟不上脑袋的速度，用手做工具
在阅读一本书的时候，慢不该慢到不值得，快不该快到有损于满足与理解。不论怎么说，阅读的速度，不论是快还是慢，只不过是阅读问题一个微小的部分而
注：阅读时的速度把握
最后，在第一次阅读一本难读的书时，不要企图了解每一个字句。这是最最重要的一个规则。这也是检视阅读的基本概念。不要害怕，或是担忧自己似乎读得很肤浅。就算是最难读的书也快快地读一遍。当你再读第二次时，你就已经准备好要读这本书了。
注：对难懂的书先速读一遍，然后? 再研究第二遍
在阅读的时候想要保持清醒，或昏昏入睡，主要看你的阅读目标是什么。如果你的阅读目标是获得利益—不论是心灵或精神上的成长—你就得保持清醒。这也意味着在阅读时要尽可能地保持主动，同时还要做一番努力—而这番努力是会有回馈的。
注：阅读的时候保持清醒
关于一本书，你一定要提出四个主要的问题。
(1)整体来说，这本书到底在谈些什么？你一定要想办法找出这本书的主题，作者如何依次发展这个主题，如何逐步从核心主题分解出从属的关键议题来。
(2)作者细部说了什么，怎么说的？你一定要想办法找出主要的想法、声明与论点。这些组合成作者想要传达的特殊讯息。
(3)这本书说得有道理吗？是全部有道理，还是部分有道理？除非你能回答前两个问题，否则你没法回答这个问题。在你判断这本书是否有道理之前，你必须先了解整本书在说些什么才行。然而，等你了解了一本书，如果你又读得很认真的话，你会觉得有责任为这本书做个自己的判断。光是知道作者的想法是不够的。
(4)这本书跟你有什么关系？如果这本书给了你一些资讯，你一定要问问这些资讯有什么意义。为什么这位作者会认为知道这件事很重要？你真的有必要去了解吗？如果这本书不只提供了资讯，还启发了你，就更有必要找出其他相关的、更深的含意或建议，以获得更多的启示。
注：读书时要提出的四个问题
如何让一本书真正属于你自己
如果你有读书时提出问题的习惯，那就要比没有这种习惯更能成为一个好的阅读者。但是，就像我们所强调的，仅仅提出问题还不够。你还要试着去回答问题。理论上来说，这样的过程可以在你脑海中完成，但如果你手中有一枝笔会更容易做到。在你阅读时，这枝笔会变成提醒你的一个讯号。
注：如何让一本书属于你
俗话说：“你必须读出言外之意，才会有更大的收获。”而所谓阅读的规则，就是用一种比较正式的说法来说明这件事而已。此外，我们也鼓励你“写出言外之意”。不这么做，就难以达到最有效的阅读的境界。
你买了一本书，就像是买了一项资产，和你付钱买衣服或家具是一样的。但是就一本书来说，付钱购买的动作却不过是真正拥有这本书的前奏而已。要真正完全拥有一本书，必须把这本书变成你自己的一部分才行，而要让你成为书的一部分最好的方法—书成为你的一部分和你成为书的一部分是同一件事—就是要去写下来。
为什么对阅读来说，在书上做笔记是不可或缺的事？第一，那会让你保持清醒—不只是不昏睡，还是非常清醒。其次，阅读，如果是主动的，就是一种思考，而思考倾向于用语言表达出来—不管是用讲的还是写的。一个人如果说他知道他在想些什么，却说不出来，通常是他其实
注：让书成为自己的
知道自己在想些什么。第三，将你的感想写下来，能帮助你记住作者的思想
做笔记有各式各样，多彩多姿的方法。以下是几个可以采用的方
注：做笔记的方法
※ 三种做笔记的方
注：三种做笔记的方法
※ 培养阅读的习惯
所谓艺术或技巧，只属于那个能养成习惯，而且能依照规则来运作的人。这也是艺术家或任何领域的工匠与众不同之处。要养成习惯，除了不断地运作练习之外，别无他法。这也就是我们通常所说的，从实际去做中学习到如何去做的道
注：培养阅读的习惯
第七章 透视一本书
每一本书的封面之下都有一套自己的骨架。作为一个分析阅读的读者，你的责任就是要找出这个骨
注：透视一本书的骨架
一本好书，就像一栋好房子，每个部分都要很有秩序地排列起来。每个重要部分都要有一定的独立
注：好书像一个好房子
分析阅读的第一阶段，或，找出一本书在谈些什么的四个规则：
注：找出一本书在说什么的方法
一般来说，阅读的过程与商业上的过程正好相反。商人通常是在找出提案是什么后，才会达成共识。但是读者却要先与作者达成共识，才能明白作者的主旨是什么，以及他所声明的是什么样的判断
注：判断作者的主旨
?(5)诠释作者使用的关键字，与作者达成共识。
(6)从最重要的句子中抓出作者的重要主旨。
(7)找出作者的论述，重新架构这些论述的前因后果，以明白作者的主张。
(8)确定作者已经解决了哪些问题，还有哪些是未解决的。在未解决的问题中，确定哪些是作者认为自己无法解决的问题。
注：分析阅读的第二个阶段
我们的建议尤其适用于所谓巨著。一般人总是抱着热忱想要阅读巨著，但是当他绝望地感觉到自己无法理解这本书时，热忱很快便消退了。其中一个原因，当然是因为一般人根本不知道要如何好好地阅读一本书。但还不只如此，还有另一个原因：他们认为自己应该能够读懂自己所挑选的第一本书，用不着再读其他相关的著作。
注：巨著读法
许多伟大的作品不只是互相有关联，而且在写作时还有特定的先后顺序，这都是不该忽略的事。后人的作品总是受到前人的影响。如果你先读前一位的作品，他可能会帮助你了解后人的作品。阅读彼此相关的书籍‘，依照写作的时间顺序来读，对你了解最后写的作品有很大帮助。这就是外在辅助阅读的基本常识与规则。
注：读巨著前先读一些基础著作
读一本好书，却会让你的努力有所回报。最好的书对你的回馈也最多。当然，这样的回馈分成两种：第一，当你成功地阅读了一本难读的好书之后，你的阅读技巧必然增进了。第二—长期来说这一点更重要—一本好书能教你了解这个世界以及你自己。你不只更懂得如何读得更好，还更懂得生命。你变得更有智慧，而不只是更有知识—像只提供讯息的书所形成的那样。你会成为一位智者，对人类生命中永恒的真理有更深刻的体认。
注：读一本好书的好处
好的阅读，也就是主动的阅读，不只是对阅读本身有用，也不只是对我们的工作或事业有帮助，更能帮助我们的心智保持活力与
]]></content>
      <categories>
        <category>读书</category>
      </categories>
      <tags>
        <tag>读书</tag>
        <tag>阅读</tag>
      </tags>
  </entry>
  <entry>
    <title>小行星会撞地球吗</title>
    <url>/2007/04/07/book-%E5%B0%8F%E8%A1%8C%E6%98%9F%E4%BC%9A%E6%92%9E%E5%9C%B0%E7%90%83%E5%90%97/</url>
    <content><![CDATA[小行星会撞地球吗小行星小行星（asteroid）是太阳系内类似行星环绕太阳运动，但体积和质量比行星小得多的天体。太阳系中大部分小行星的运行轨道在火星和木星之间，称为小行星带。另外在海王星以外也分布有小行星，这片地带称为柯伊伯带（Kuiper Belt）。
主要成分为岩石、金属、碳以及冰块。
多数小行星的个头很小，只有小石块那么大，小行星带中最大的小行星为谷神星，直径933km。
由于在太阳系中的位置不同，小行星被分为四个不同的组别：

主带小行星：约90%已知的小行星的轨道位于小行星带中。小行星带是一个相当宽的位于火星和木星之间的地带。谷神星、智神星等首先被发现的小行星都是小行星带内的小行星；

特洛伊型小行星：在其它行星轨道的拉格朗日点上运行的小行星被称为特洛伊小行星。最早被发现的特洛伊小行星是在木星轨道上的小行星，它们中有些在木星前，有些在木星后运行。有代表性的木星特洛伊小行星有小行星588和小行星1172。1990年第一颗火星特洛伊小行星小行星5261被发现，此后还有其它四颗火星特洛伊小行星被发现。

半人马天体：土星和天王星之间的小行星有一群被称为半人马小行星群的小行星，它们的偏心率都相当大。最早被发现的半人马小行星群的小行星是小行星2060。估计这些小行星是从柯伊伯带中受到其它大行星的引力干扰而落入一个不稳定的轨道中的。

近地小行星：运行的轨道使其与地球的轨道特别靠近，甚至有机会撞向地球：

阿莫尔型小行星群：这一类小行星穿越火星轨道并来到地球轨道附近。其代表性的小行星是1898年发现的小行星433，这颗小行星可以到达离地球0.15天文单位的距离。1900年和1931年小行星433来到地球附近时天文学家用这个机会来确定太阳系的大小。1911年发现的小行星719后来又失踪了，一直到2000年它才重新被发现。这个小行星组的命名星小行星1221阿莫尔的轨道位于离太阳1.08到2.76天文单位，这是这个群相当典型的一个轨道。

阿波罗小行星群：这个小行星群的小行星的轨道位于火星和地球之间。这个组中一些小行星的轨道的偏心率非常高，它们的近日点一直到达金星轨道内。这个群典型的小行星轨道有1932年发现的小行星1862阿波罗，它的轨道在0.65到2.29天文单位之间。小行星69230在仅1.5月球距离处飞略地球。

阿登型小行星群：这个群的小行星的轨道一般在地球轨道以内。其命名星是1976年发现的小行星2062阿登。有些这个组的小行星的偏心率比较高，它们可能从地球轨道内与地球轨道相交




通过光谱分析所得到的数据可以证明小行星的表面组成很不一样，按照光谱的特性小行星可以分为：

C-小行星：这种小行星占所有小行星的75%，因此是数量最多的小行星。C-小行星的表面含碳，反照率非常低，只有0.05左右。一般认为C-小行星的构成与碳质球粒陨石（一种石陨石）的构成一样。一般C-小行星多分布于小行星带的外层。
S-小行星：这种小行星占所有小行星的17%，是数量第二多的小行星。S-小行星一般分布于小行星带的内层。S-小行星的反照率比较高，在0.15到0.25之间。它们的构成与普通球粒陨石类似。这类陨石一般由硅化物组成。
M-小行星：剩下的小行星中大多数属于这一类。这些小行星可能是过去比较大的小行星的金属核。它们的反照率与S-小行星的类似。它们的构成可能与镍–铁陨石类似。
E-小行星：这类小行星的表面主要由顽火辉石构成，它们的反照率比较高，一般在0.4以上。它们的构成可能与顽火辉石球粒陨石（另一类石陨石）相似。
V-小行星：这类非常稀有的小行星的组成与S-小行星差不多，唯一的不同是它们含有比较多的辉石。天文学家怀疑这类小行星是从灶神星的上层硅化物中分离出来的。灶神星的表面有一个非常大的环形山，可能在它形成的过程中V-小行星诞生了。
地球上偶尔会找到一种十分罕见的石陨石，HED-非球粒陨石，它们的组成可能与V-小行星相似，它们可能也来自灶神星。
G-小行星：它们可以被看做是C-小行星的一种。它们的光谱非常类似，但在紫外线部分G-小行星有不同的吸收线。
B-小行星：它们与C-小行星和G-小行星相似，但紫外线的光谱不同。
F-小行星：也是C-小行星的一种。它们在紫外线部分的光谱不同，而且缺乏水的吸收线。
P-小行星：这类小行星的反照率非常低，而且其光谱主要在红色部分。它们可能是由含碳的硅化物组成的。它们一般分布在小行星带的极外层。
D-小行星：这类小行星与P-小行星类似，反照率非常低，光谱偏红。
R-小行星：这类小行星与V-小行星类似，它们的光谱说明它们含较多的辉石和橄榄石。
A-小行星：这类小行星含很多橄榄石，它们，主要分布在小行星带的内层。
T-小行星：这类小行星也分布在小行星带的内层。它们的光谱比较红暗，但与P-小行星和R-小行星不同。

冥王星冥王星，或被称为134340号小行星，于1930年1月由克莱德·汤博根据美国天文学家洛韦尔的计算发现，并以罗马神话中的冥王普路托（Pluto）命名。它曾经是太阳系九大行星之一，但后来被降格为矮行星。与太阳平均距离59亿千米。直径2300千米，平均密度2.0克左右/立方厘米，质量1.290×10^22 千克。公转周期约248年，自转周期6.387天。表面温度在-220°c以下，表面可能有一层固态甲烷冰。
2006年8月24日，该行星经在布拉格举行的国际天文联合会(IAU)的讨论，从九大行星行列中排除，正式降格为矮行星，因为最近在太阳系边缘发现了小行星带，那里许多小行星都比冥王星大，而且主要是当时汤博计算其质量错误。
矮行星：或称“侏儒行星”，体积介于行星和小行星之间，围绕太阳运转，质量足以克服固体应力以达到流体静力平衡（近于圆球）形状，没有清空所在轨道上的其他天体，同时不是卫星。矮行星是一个新的分类。定义的标准尚不明确。
行星

一是必须围绕太阳运转的天体；
二是质量足够大，能依靠自身引力使天体呈圆球状；
三是其轨道附近应该没有其他物体。


Mark：其中冥王星不满足第三条，因为其轨道与海王星有交集。

科学家证实，大到足以影响整个地球的撞击一般10万年才能发生一次。
彗星当靠近太阳时能够较长时间大量挥发气体和尘埃的一种小天体。由冰冻物质和尘埃组成。当它靠近太阳时即为可见。太阳的热使彗星物质蒸发，在冰核周围形成朦胧的彗发和一条稀薄物质流构成的彗尾。由于太阳风的压力，彗尾总是指向背离太阳的方向。
彗星的轨道有椭圆、抛物线、双曲线三种。
由于每次接近一次太阳，彗星便损失一些气体和尘埃，所以最终可能消失。
彗星上的水：当数十年太阳刚形成时，行星都非常热，水和大气都消失在了太空中，即使地球上也没有空气和水，在形成之后很短的时间里，行星受到了来自小行星及彗星的撞击，彗星中含的水和气体在撞击中被释放出来。
彗星与流星的区别★ 彗星(Comet)彗星的本体主要是由冰冻的气体和微尘所组成，也因此有「脏雪球」的称号，它的直径通常只有数公里左右，10公里以上的就算非常巨大了，而它的轨道多为扁长的椭圆形或是抛物线，前者绕行太阳一圈的时间从几年到几万年以上都有，后者则在造访太阳一次之后就永远都不会回来了；平时的彗星因为距离太阳较远，因此都处於冰冻的状态，且光度极为黯淡，但只要一进入到地球的轨道附近，与太阳的距离缩短之后，就会开始活泼起来，同时释出许多的微尘形成彗发和彗尾，体积非常巨大，最大的甚至可以和太阳相较，但其密度却稀薄的比地球上所能制造的「真空」还要小。
肉眼即可见到的大彗星不会太常出现，但能用望远镜或摄影观测的彗星每年都会有一、二十个以上，若偶尔出现壮观明亮的大彗星时，就会引起广大的天文热潮，如前几年的百武彗星和海尔‧波普彗星即是，不过除了周期76年的哈雷彗星之外，能够引起大众注意的几乎全是非周期彗星(指周期大於200年或不会回归的彗星)了；2004年5月时预计将有2颗亮度达到1等以上的大彗星，在日落后将同时出现於西方天空，此一难得的天文奇观值得期待。
★ 流星(Meteor)流星的本体主要是一些漫游在太空中的灰尘微粒，体积非常的小，有些甚至小到连肉眼都看不见，它们因受到地球引力的吸引而掉落到地球上，通常以秒速1171公里的速度进入地球的大气层，和大气摩擦产生的高热便足以将它们本身汽化消失，并因为电子遭到激发而散发光芒，发光的高度约在80120公里左右，且只要几公厘的大小就可以很明亮了；而质量较大的流星体，或亮度在-2等以上的大流星我们通常称为「火球」或「火流星」，其中有些会在中途因爆炸而大量增光，有时甚至还能听到声音，有些明亮的流星在划过后会留下淡淡的流星痕，规模较大的还可以持续数分钟之久，而后将随著高空的强风而慢慢的散开消失。
平常的夜晚我们常常能看到几颗散落的流星飞过孤寂的夜晚，但除了这些随机出现的流星外，有时候在短时间之内会出现大量的流星(每小时数十颗以上)，并且都自同一个辐射点向外飞出，这就是我们所谓的「流星雨」；流星雨是在地球穿过一群彗星经过后而遗留下来的微尘时所发生的，能造成流星雨的彗星必须轨道和地球相交，因此我们常说彗星就是流星的母亲；每年地球都会定期的穿过某些流星群而形成流星雨(Meteor Shower)，
其中较为著名的有象限仪座(天龙座ι)流星雨、英仙座流星雨、狮子座流星雨和双子座流星…等，流星雨的命名方式通常以辐射点的位置而定，其每小时的流星数(ZHR)通常在几颗到上百颗不等，有时候还会出现罕见的「流星暴」现象，每小时的流星数可以到达1000颗甚至数十万颗以上，非常壮观；而其中最为著名的狮子座流星雨每隔33年就会有一次持续几年的极大期，在极大时就很有可能出现流星暴的盛况。
]]></content>
      <categories>
        <category>读书</category>
      </categories>
      <tags>
        <tag>Comet</tag>
        <tag>Meteor</tag>
        <tag>asteroid</tag>
        <tag>冥王星</tag>
        <tag>小行星</tag>
        <tag>彗星</tag>
        <tag>流星</tag>
        <tag>行星</tag>
        <tag>Book</tag>
      </tags>
  </entry>
  <entry>
    <title>幸福了吗？</title>
    <url>/2013/08/24/book-%E5%B9%B8%E7%A6%8F%E4%BA%86%E5%90%97%EF%BC%9F/</url>
    <content><![CDATA[幸福了吗？白岩松
一个人需要隐藏多少秘密才能巧妙地度过一生这佛光闪闪的高原三步两步便是天堂却仍有那么多人因心事过重而走不动——六世达赖喇嘛仓央嘉措
梁漱溟先生有关的一本书《这个世界会好吗》，翻到后记，梁先生的一段话，突然让我心动。梁老认为，人类面临有三大问题，顺序错不得。先要解决人和物之间的问题，接下来要解决人和人之间的问题，最后一定要解决人和自己内心之间的问题。
青春应当浪漫一些，不那么功利与现实，可现今的年轻人却不敢也不能。房价不断上涨，甚至让人产生错觉：“总理说了不算，总经理说了才算。”后来总经理们太过分，总理急了，这房价才稍稍停下急匆匆的脚步。房价已不是经济问题，而是社会问题政治问题。
一群人急匆匆地赶路，突然，一个人停了下来。旁边的人很奇怪：为什么不走了？停下的人一笑：走得太快，灵魂落在了后面，我要等等它。是啊，我们都走得太快。然而，谁又打算停下来等一等呢？如果走得太远，会不会忘了当初为什么出发？
03 让敏感的不再敏感
有些人不喜欢中国，更多的人开始喜欢中国人民，但绝对所有的人都喜欢中国人民币。

注: 精辟

09 三进台湾
所有的生离死别，都发生在一个码头，上了船，就是一生。让你看见我们的父母，一整代人隐忍不言的伤。这是一本你从来没认识过的一九四九。

注: 大江大海

10 靖国神社与垃圾分类
日本大城市中，人们的交通主要依靠地铁。高峰时，车厢里的椅子都能收起来，大家都站着，为了节省空间，到了非高峰期，椅子才放下；而在车厢里，很少有少有人跷二郎腿，打电话也被视为不礼貌的行为；无论购物还是吃饭，都是有秩序地排队，无人加塞儿。

注: 这个没有注意

12 感动，有没有用？
做《感动中国》的主持人，是一件既幸福又痛苦的事情。幸福在于，你可以离感动如此之近；而痛苦在于，当你被感动时，你必须克制，不能放纵泪水一次又一次地滑落。这种痛苦，只有身在其中，才能强烈地感受

注: 感动中国的幸福与痛苦

14 成长的营养：好听的好看的
生命如同一条河流，出发时，还只是清澈的涓涓细流，一路奔腾，慢慢加速，陆续开始有人或事，书或者光影，为这条河流填注力量，增加水流甚至影响方向，每个人都不例外。

注: 生命

15 谁，影响并改变着我？
高中同学与大学同学不一样，后者因学的是同一个专业，即便毕业后天南海北，可行业的关系，还是让大学同学更方便时常见面。而高中的同学，由于上的大学与专业千差万别，聚会的难度就加大了，只能回家
如果有一天，你感觉内心沉静，世事浮沉暂时抽离，而窗外又风和日丽，你试着再听听莫扎特，用你最简单和纯真的心，这时候我相信，真正的莫扎特会在上帝的指使下再度归来。
]]></content>
      <categories>
        <category>读书</category>
      </categories>
      <tags>
        <tag>读书</tag>
      </tags>
  </entry>
  <entry>
    <title>改变世界是一种信仰：乔布斯和他的苹果神话</title>
    <url>/2015/04/10/book-%E6%94%B9%E5%8F%98%E4%B8%96%E7%95%8C%E6%98%AF%E4%B8%80%E7%A7%8D%E4%BF%A1%E4%BB%B0%EF%BC%9A%E4%B9%94%E5%B8%83%E6%96%AF%E5%92%8C%E4%BB%96%E7%9A%84%E8%8B%B9%E6%9E%9C%E7%A5%9E%E8%AF%9D/</url>
    <content><![CDATA[改变世界是一种信仰：乔布斯和他的苹果神话人类的文明史记录了三个关于苹果的重要故事：

亚当夏娃头吃苹果，人类因此有了智慧 –神话
苹果砸到牛顿，有了万有引力 –传说
史蒂夫乔布斯缔造苹果电脑  –真实故事


这辈子没法做太多事情，所以每一件都要做到精彩绝伦。


我们的目标并不在于制造出市场上最廉价的产品，而是制造出最优秀的产品。

苹果能制造出像iPod这样的产品，就是因为我们一直试图站在人文艺术和科学技术的交汇处，博采众长。
所有的产品一定会离开苹果商店但不能离开苹果系统，我们要帮助客户持续使用苹果产品，知道寿终正寝。
苹果不仅贩卖产品，更在贩卖一种文化。
细节的准确、生动可以成就一件伟大的作品。
创新不是创新者创出来的东西，而是消费者实际采纳的东西。
苹果创新的核心：简约。iPod放弃了屏幕，iPhone放弃了手写笔，iPad放弃了鼠标，iMac放弃了软盘，MacBook Air放弃了光驱。
有时生活会当头给你一棒，但不要灰心，我坚信让我一往无前的唯一力量就是我热爱我所做的一切。
让自己真正满意的唯一办法，是做自己认为有意义的工作；做有意义的工作的唯一办法，是热爱自己的工作。如果你还没有发现自己喜欢什么，那就不断地去寻找，不要急于做出决定。就像一切要凭着感觉去做的事情一样，一旦找到了自己喜欢的事情，感觉就会告诉你。
记住自己随时都会死掉，是防止你陷入畏首畏尾陷阱的最好方法。。。你已经一无所有了，没有理由不去追随你的心。
活着就是为了改变世界。
内心的喜好是推动事业进步的最大动力，它能帮你克服困难，坚持到底。如果你喜欢的事情有很多，要挑选自己最擅长做的事情，这样就能在感受快乐的同时取得超乎常人的成就。

如果你把每一天当做生命的最后一天过，总有一天你的假设会成为现实。

]]></content>
      <categories>
        <category>读书</category>
      </categories>
      <tags>
        <tag>读书</tag>
        <tag>MacOSX</tag>
        <tag>乔布斯</tag>
        <tag>库克</tag>
        <tag>苹果</tag>
        <tag>iMac</tag>
        <tag>iPad</tag>
        <tag>iPhone</tag>
      </tags>
  </entry>
  <entry>
    <title>无器械健身</title>
    <url>/2014/01/24/book-%E6%97%A0%E5%99%A8%E6%A2%B0%E5%81%A5%E8%BA%AB/</url>
    <content><![CDATA[无器械健身总结起来也就六个字：
** 结实 强壮 自信 **
即练出结实的肌肉、锻炼强壮的躯体，培养自信的自己。
Plus:成功健身必须遵循的6个原则

坚持
恢复
规律
变化
进步
超负荷

]]></content>
      <categories>
        <category>读书</category>
      </categories>
      <tags>
        <tag>读书</tag>
        <tag>无器械健身</tag>
      </tags>
  </entry>
  <entry>
    <title>每天最重要的3件事</title>
    <url>/2020/02/02/book-%E6%AF%8F%E5%A4%A9%E6%9C%80%E9%87%8D%E8%A6%81%E7%9A%843%E4%BB%B6%E4%BA%8B/</url>
    <content><![CDATA[每天最重要的3件事   – 张永锡 李瑞文“Just do it”是幸福行动家们在实践相关内容时的真实案例和经验。
第一个习惯是“先吃掉那只青蛙”，第二个习惯是“清空收件夹”，第三个习惯是“每日重开机”
第一部分 先吃掉那只青蛙时间管理不是让人变得一味忙碌，而是让人变得轻松，有时间享受生活。
如果每天早晨你先做最有挑战性的事情，一天中其他的事情都会显得无比轻松。
高效的人并不是每天做很多小事，而是把时间花在最重要的几件事情上
A代表“Action List”，英文中的行动清单。把今天要做的事情列成清单，之后就专注地一项一项做完。每天早上花点儿时间，列出包含13只青蛙、57只蝌蚪的每日行动计划。青蛙之后的其他任务就是“蝌蚪”，就是我们所说的琐事或小任务，相对来说不是非常重要的事。蝌蚪意味着如果今天做不完可以适当舍弃。这份清单除了自己使用，还可以和团队共享，让队员互相了解彼此的进度。
S是“Slice”的缩写，代表切成小片。有些青蛙，不是一口能吃完的，需要分成几天甚至几周才能吃完，那么就需要切成小片。第二章 F吃青蛙：要事为先的三个关键
进入心流状态四步法：

Step1：热身时间先做一些容易的工作，轮替一下不同的小事，这就好像典礼开始时的暖场。
Step2：专注青蛙进入每天最重要的事（吃青蛙）本身。别忘了一口一口吃的技巧，心如止水，顺流而下。
Step3：适时休息记得要在疲倦之前就休息。我在后面的章节会讲到番茄工作法，番茄工作法使我们每25分钟就有一次休息的时间。
Step4：每日检视我会在第二天早晨写日记检视，从检视中找出哪些做法可以改善，下次要吃类似的青蛙时，可以有更好的方法。

挑战最难的事情，正是生活中最有趣的部分。
我会回顾昨天在笔记上记录下来的事情。把需要执行的部分移到行动清单中，剩下的保存在笔记资料库中。
一封信一封信地依次检视，每看完一封信，你可以选择存档、立刻回信、授权他人处理，或者转寄到行动清单作为下一步行动。
我写晨间日记的习惯已经坚持了将近十年，每天记录前一天发生的事情或心情，对于了解自己有莫大帮助。
推荐四个数字化清单应用除了把清单写在笔记本上，现代人应该懂得善用“数字化清单”工具，这里我先做一个简单推荐。OmniFocus是老牌又专业的清单工具，效率非常高，美中不足的是只能在Mac和iOS系统下使用，没有PC版。Wunderlist，又称奇妙清单，有很漂亮的界面与亲切的使用流程，目前属于微软旗下的服务。滴答清单，基础功能免费，比较符合大陆用户的使用习惯，可以语音输入，还可以把微信的内容直接复制到清单里。第五章 T训练自己的时间感知能力
番茄工作法的基本原则是最高强度地专注于一件事情上25分钟，例如看书、背诵、写作、思考或进行各种工作任务，然后让自己精神放松5分钟，例如站起来走走、刷网页、聊聊天。只要一直重复这个循环过程，可以让自己掌控时间并维持最佳专注力
所以，通常我会利用上午的时间来吃青蛙，这是我一天中工作效率最高的时段。到了下午，我的精神已经疲惫，不适合吃青蛙，就处理一些比较轻松的工作，这样才能劳逸平衡
番茄土豆：结合任务清单与番茄钟，有各平台的APP与网页版，是很适合吃青蛙的番茄钟工具。Focus：有Mac和iOS版，好处是可以列出待办事项。Focus Booster：有Windows与Mac版本，可以在桌面上使用的番茄钟计时工具。
我们需要顺应身体的节律，集中注意力、休息放松，保持规律的生活、充足的睡眠。保持节律，只靠大脑是不够的，我们还需要一个闹钟。现代人习惯用手机、电脑、实体倒计时器作为闹钟。这些形态的闹钟都可以使用，更重要的是如何有效地用好它们。
电脑上的计时软件我是用Due做电脑上的计时软件。Due是一个专业的闹钟APP，可以快速输入几个自己需要的闹钟，或设定倒计时，整个过程行云流水，更棒的是可以同步到iOS设备，就算离开电脑也能够提醒自己。
FAST原则除了可以帮你个人完成一天的重要任务，其实也可以管理一个团队的工作流程。F，就是找出团队专案里最重要的事情有哪些。A，就是列出整个团队专案的进度清单。S，就是分配任务、切割任务，根据每个团队成员的能力去分配工作。T，就是分配专案时间，让每个团队成员有时间去完成任务。第八章 清空收件夹：将杂事加工成行动
这个世界上的信息固然非常多，但终会被信息组成者宰制，这些人能在对的时间点，归纳整合正确的信息，批判性地思考，明智地做出重要决定。—— 哈佛大学教授 爱德华·奥斯本·威尔森（Edward Osborne Wilson）
清空收件夹清空收件夹分三步：收集杂事、将杂事加工成行动、贯通收件夹与行动提示系统。
学习好“清空收件夹”的三个流程，就是练习三个基本功：首先，管理好杂事收件夹系统；其次，架构好行动提示系统；最后，清空收件夹，贯通从杂事到行动的高速铁路。让杂事有明确可以放置的地方，有明确的流程让杂事变成行动，最后做事的速度与质量因为有良好的行动提示系统而得到提升，这就是清空收件夹的目的。
人生中一半的麻烦源于答应得太快，拒绝得太慢。——格雷戈·麦吉沃恩（Greg Mckeown）
重新开机重开机（Reboot）：使用时间管理系统帮助我们推进任务，久而久之，系统会产生一些“阻力”，需要定期重开机，清空CPU及RAM内存，让时间管理系统恢复应有的速度。
Schedule，日程表我每天早上检查日程表，确认自己一天的行程。每周在做检视时，也会确认自己上一周与下一周的各项任务，并列出任务清单，安排执行任务的时间，并设定闹钟自动提醒。Task，任务现代知识工作者会同时进行许多任务，有的耗时短，几天可以完成，有的耗时长，需要数周或数月才能完成。任务分个人及组织的任务，有的是独立完成，有的要和团队成员协作才能完成。要对任务做好适当的规划，借此了解整个任务的全貌，这样执行时才能够持续推动，减少边想边做出现的状况。
若是能管控好下周要推动的任务清单及下一步行动，这样时间管理的功力就很不错了。Action，行动每天都需要推动许多行动，有些是单独的行动，有些则是和某个任务相关的行动。行动不容易推动有两方面原因，一方面是没能做好任务规划工作，一直找不到关键行动；另一方面就是今天有太多可以做的行动，需要花时间厘清先后次序。
因此每天要先列出三只青蛙，几只蝌蚪，努力推动，当有杂事进入收件夹，迅速加工确认是否必须今天做。可能的话尽量不要安排在今天，而是安排特定日期来做该行动。这样才能顺利推动今天的青蛙，吃完青蛙和蝌蚪，拥有高效的一天。Reference，参考资料库为了持续做好时间管理，需要建立参考资料库，例如之前提过的晨间日记，爱画画及拍照的人会建立图片资料库，讲师会有幻灯片资料库，上班族则有Office文件管理。这些资料可以帮助我们将任务执行得更好。第十九章 晨间日记：为检视自己而写
每天清晨，我会打开印象笔记，开始写晨间日记，在窗帘透进来的曙光中，只聆听键盘敲击及内心对话这两种声音。而每周每年的坚持检视，帮助我归纳整合信息，做批判性的思考，不断升级自己的人生操作系统。每一次阅读日记，都会觉得好像面对一个不太熟悉的自己。有时发现，自己生命中的每一天都是如此认真地活，这些体验是如此地真实生动。有些时候，也会有点懊恼，为何当初没有好好对待那件事情。日积月累，人生变得更加丰润成熟
一年一次的深度检视，仿佛在一条长路中，停下来歇歇脚。回看之前的轨道，依稀看出形成一条直线，再一转头，望向未来的目标，就知道如何修订生活与工作的角度，向目标继续前进，拥有一个值得拥有的人生
1．选一个早晨自己可以接受的起床时间。2．选一件没有压力，但是可以让自己振奋精神的事，当成早晨起床的第一个动力。3．不急着行动，从晨间日记的每日检视开始。4．选一件对自己具有“高价值”的工作开始做，让自己在早晨就感受到强大回馈。第二十章 每周检视：提升时间管理高度
每周检视的一小时，是一周168小时中最珍贵的一小时。这一小时让我得以从高空俯瞰生活的全局，这样充分地检视后，我的头脑才能获得真正的宁静。
如果你已经下定决心做好每周检视，可以按照如下流程进行：先清空收件夹检视晨间日记本下周日程表思考下周任务检视年度计划
1．设定每周某一固定时段进行每周检视。2．练习快速完成检视。3．每周检视的目的先从找到下周目标开始。4．执行几次后，在每周检视中找到未来计划。
点评★★★☆☆重要的事，琐事如何排序 还有定时日记，自己重开机都是很好的习惯！
]]></content>
      <categories>
        <category>读书</category>
      </categories>
      <tags>
        <tag>读书</tag>
        <tag>阅读</tag>
      </tags>
  </entry>
  <entry>
    <title>用小刀划开</title>
    <url>/2015/03/22/book-%E7%94%A8%E5%B0%8F%E5%88%80%E5%88%92%E5%BC%80/</url>
    <content><![CDATA[用小刀划开我们总是饿着肚子眼含泪手、不断呜咽幻想着天上会不会掉下什么看看上面、看看下面但 绝不乞求
有多喜爱、就要多厌恶虽然离不开这座城市但总是眼望远方

那时我还很小什么都不懂现在也依然不懂如果有一天我懂了眼前的生活或许也可接受这被压抑被漠视的每一天即使所有人 都可以接受这样的生活也不会所有人 生来就认为 生活就该是这个样子
]]></content>
      <categories>
        <category>读书</category>
      </categories>
      <tags>
        <tag>人生</tag>
        <tag>读书</tag>
        <tag>思考</tag>
        <tag>会话</tag>
      </tags>
  </entry>
  <entry>
    <title>让掌声响起来-PPT制作达人速成</title>
    <url>/2015/03/24/book-%E8%AE%A9%E6%8E%8C%E5%A3%B0%E5%93%8D%E8%B5%B7%E6%9D%A5-PPT%E5%88%B6%E4%BD%9C%E8%BE%BE%E4%BA%BA%E9%80%9F%E6%88%90/</url>
    <content><![CDATA[让掌声响起来-PPT制作达人速成真正的PPT模板，都是通过母版制作来实现的。
所以，其实对于PPT而言重要的在于母版的制作。
]]></content>
      <categories>
        <category>读书</category>
      </categories>
      <tags>
        <tag>PPT</tag>
      </tags>
  </entry>
  <entry>
    <title>超级时间整理术</title>
    <url>/2015/03/13/book-%E8%B6%85%E7%BA%A7%E6%97%B6%E9%97%B4%E6%95%B4%E7%90%86%E6%9C%AF/</url>
    <content><![CDATA[超级时间整理术
严格执行事先制定好的工作计划，并且一定要完成；
不把时间浪费在找东西上；
争取安排出工作以外的自由时间；

整理的目的是为了提高工作效率，而不仅仅是为了整理干净。 不会整理的人，其工作效率往往比较底下。
整理可以使环境更整洁、思路更清晰。
所谓整理，就是要达到“你想要的东西就能拿到并方便使用”。
人的脑力有限，花脑力去记那些没必要记的东西也是一种浪费。
及时丢弃不必要的东西。
用后就还原位置。
尽量不打印纸质文件。
周五是整理日。
]]></content>
      <categories>
        <category>读书</category>
      </categories>
      <tags>
        <tag>时间</tag>
        <tag>读书</tag>
      </tags>
  </entry>
  <entry>
    <title>跑步，该怎么跑</title>
    <url>/2015/03/23/book-%E8%B7%91%E6%AD%A5%EF%BC%8C%E8%AF%A5%E6%80%8E%E4%B9%88%E8%B7%91/</url>
    <content><![CDATA[跑步，该怎么跑

如果你想要健康 – 跑吧。
如果你想要俊美 – 跑吧。
如果你想要聪慧 – 跑吧。

练就完美跑步技术的关键在于：尽可能利用重力。
完美的跑者，融合自然的不掉，用你的双脚轻柔、敏捷地踩踏过路面。
厉害的赛跑者总是以优雅的节奏，流畅地跑着。

膝盖与胯关节不要太高或往前
绝对不要把腿伸直
不要摆动手臂让身体前进

主要是纠正了跑步的动作~
]]></content>
      <categories>
        <category>读书</category>
      </categories>
      <tags>
        <tag>读书</tag>
        <tag>健身</tag>
        <tag>跑步</tag>
      </tags>
  </entry>
  <entry>
    <title>黑洞里面有什么</title>
    <url>/2007/04/05/book-%E9%BB%91%E6%B4%9E%E9%87%8C%E9%9D%A2%E6%9C%89%E4%BB%80%E4%B9%88/</url>
    <content><![CDATA[黑洞里面有什么天上的星星并不是均匀分布的，而是分成群落、组成图案。
星星为什么闪烁？实际上大多数星星只会发出稳定的光线。之所以发生闪烁是因为大气层—覆盖在地球表面的空气层的变化。大气层的某些部分是不断运动的，而且某些地方的空气比其他地方密度高，空气的这些差异对来自星星的光线产生了影响，使它们看起来摇曳不定。
天文学家将天空划分为88个不同的星座，在赤道上可以看到全部星座。
看见过去当遥望群星时，我们其实是在做一件非常奇特的事情—我们正在时间中回望，星星，例如作为猎户座一部分的参宿⑦，距离地球大约900光年，当我们在天空中看到参宿⑦时，我们看见的光已经离开那颗星星900年了。
恒星的寿命一颗超巨星将在几百万年内燃尽自己的燃料。而作为黄矮星的太阳，能够维持50-100亿年，而一颗红矮星可以闪耀1000亿年。
超巨星在超新星爆发中死去，爆炸只留下一个体积微小而又重的不可思议的中子星，一颗中子星的直径大约只有10km长，但是其质量比太阳还大。
##脉冲星
旋转的中子星
黑洞大质量恒星爆炸时，星体的中央塌缩为一个微小的物质点，但是这个物质点比太阳还重，即黑洞。
地球太阳和地球是一个被称为银河的巨大星系的一部分，这个星系的直径约为10万光年，容纳着1000亿颗左右的恒星。
在我们星系的中央，存在一个重量相当于350万个太阳的大质量黑洞，它的事件视界大约为22万千米，在1974年首次发现。
类星体类似于恒星的天体，指某种看起来像恒星又不像恒星的天体，特点是比任何其他物体都亮。
天文学家认为类星体是一些中央存在大质量黑洞的星系。
来自类星体的光比来自恒星的光更红。（红移）
红移是由于多普勒效应导致的，这意味着星系离我们正远去。离我们越远的星系移动得越快，不过在类星体中，红移比在其他任何星系都强。
多普勒效应：

向你移动：蓝光
离你远去：红光

事件视界黑洞并非把它周围的任何物体都吸进去，只有在事件视界之内的物体才会被吸进去。事件视界是一个与黑洞质量有关的量。
黑洞的影响一颗行星例如地球对时空的影响只造成一点弯曲；
一颗恒星造成的弯曲会多一些；
而一颗黑洞会在时空上留下一个窟窿；
走进洞内当我们从地球、太阳进入黑洞时，由于受到引力的增大，运动的速度也越来越快，直到黑洞把我们撕碎。
洞外观察与我们自身相反，观察者会发现我们进入黑洞后，速度越来越慢，主要是由于光进入黑洞后由于引力而变慢，要花更多的时间才能到达看你的人。
宇宙大爆炸大约150亿年前
背景辐射早在恒星和星系形成以前，空间中熊熊燃烧的炽热白光所留下的微弱的回声。
暗物质
天文学家：不能发光的普通大质量物体，例如大行星、棕矮星；
物理学家：由比原子更小的微小粒子组成的，微小粒子可能是WIMP（弱相互作用大质量粒子）和中微子。

]]></content>
      <categories>
        <category>读书</category>
      </categories>
      <tags>
        <tag>读书</tag>
        <tag>中子星</tag>
        <tag>中微子</tag>
        <tag>暗物质</tag>
        <tag>类星体</tag>
        <tag>红移</tag>
        <tag>背景辐射</tag>
        <tag>脉冲星</tag>
        <tag>蓝移</tag>
        <tag>黑洞</tag>
        <tag>黑洞里面有什么</tag>
      </tags>
  </entry>
  <entry>
    <title>C语言 abort函数</title>
    <url>/2011/02/03/c-advance-abort/</url>
    <content><![CDATA[abort函数函数abort，需要头文件：#include &lt;stdlib.h&gt;，异常终止一个进程。中止当前进程，返回一个错误代码。错误代码的缺省值是3。
该函数产生SIGABRT信号并发送给自己。
]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>c++</tag>
        <tag>abort</tag>
        <tag>SIGABRT</tag>
        <tag>c-advance</tag>
        <tag>C语言从入门到进阶</tag>
      </tags>
  </entry>
  <entry>
    <title>C语言 assert的使用</title>
    <url>/2013/01/03/c-advance-assert/</url>
    <content><![CDATA[关于断言assert的使用assert宏的原型定义在&lt;assert.h&gt;中，其作用是如果它的条件返回错误，则终止程序执行，原型定义：
#include &lt;assert.h&gt;void assert( int expression );

assert的作用是先计算表达式 expression ，如果其值为假（即为0），那么它先向stderr打印一条出错信息，然后通过调用 abort 来终止程序运行。
但是使用assert()的缺点是，频繁的调用会极大的影响程序的性能，增加额外的开销。在调试结束后，可以通过在包含#include &lt;assert.h&gt;的语句之前插入 #define NDEBUG` 来禁用assert调用。
我比较常用的比如断言分母不能是0等等。
]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>c++</tag>
        <tag>c-advance</tag>
        <tag>C语言从入门到进阶</tag>
        <tag>assert</tag>
        <tag>define</tag>
        <tag>NDEBUG</tag>
      </tags>
  </entry>
  <entry>
    <title>C语言 程序编译</title>
    <url>/2013/01/03/c-advance-compiler/</url>
    <content><![CDATA[程序编译的过程一个程序的编译，需要完成词法分析、语法分析、中间代码生成、代码优化、目标代码生成。而编译的过程包括预处理preprocessing、编译compilation、汇编assembly和链接linking。

词法分析。词法分析指的是对由字符组成的单词进行处理，从左至右逐个字符地对源程序进行扫描，产生一个个单词符号，然后把字符串的源程序改造成单词符号串的中间程序。在编译程序时，这一过程是自动完成的。编译程序会对代码的每个单词进行检查，如果单词发生错误，编译过程就会停止并显示错误，这时需要对程序中的错误进行修改。
语法分析。语法分析器以单词符号作为输入，分析单词符号串是否形成符合语法规则的语句。例如，需要检查表达式、赋值、循环等结构是否完整和符合使用规则。在语法分析时，会分析出程序中错误的语句，并显示出结果。如果语法发生错误，编译任务是不能完成的。
中间代码生成。中间代码是源程序的一种内部表示，或称中间语言。程序进行词法分析和语法分析以后，将程序转换成中间代码，这一转换的作用是使程序的结构更加简单和规范。中间代码生成操作是一个中间过程，与用户无关。
代码优化。代码优化是指对程序进行多种等价变换，使得变换后的程序能生成更有效的目标代码。用户可以在编译程序时设置代码优化的参数，可以针对不同的环境和设置进行优化。
目标代码生成。目标代码生成指的是产生可以执行的应用程序，这是编译的最后一个步骤。生成的程序是二进制形式的机器语言，用户只能运行这个程序，而不能打开这个文件查看程序的代码。

]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>c++</tag>
        <tag>c-advance</tag>
        <tag>C语言从入门到进阶</tag>
        <tag>compiler</tag>
      </tags>
  </entry>
  <entry>
    <title>C语言 基本输入和输出操作</title>
    <url>/2012/02/04/c-advance-io/</url>
    <content><![CDATA[基本输入和输出操作与大多数现代编程语言一样，C语言也没有输入输出的能力，所有这类操作都由标准库中的函数提供。
stderr流只是将来自C库的错误信息传送出去，也可以将自己的错误信息传送给stderr。
stderr和stdout之间的主要差别是，输出到stdout的流在内存上缓存，所以写入stdout的数据不会马上送到设备上，而stderr不缓存，所以写入到stderr的数据会立刻传送到设备上。对于缓存的流，程序会在内存中传入或传出缓存区域的数据，在物理设备上传入或传出数据可以异步进行。这使输入输出比较高效，而为错误信息使用不缓存的流，其优点是可以确保错误信息显示出来，但输出操作是低效的。缓存的流比较高效，但是如果程序因某种原因失败，缓存的流就不会刷新，所以输出可能永远不会显示出来。
scanf会忽略空白字符scanf和printf中有个格式控制符%n：表示输出有效字符的数量。
N多的scanf参数也可以保证，你可以用许多方式得到自己希望得到的数据。
但是有一点需要注意，就是scanf对输入格式很挑剔，稍微错一点就会导致整个读取输入出错。
scanf的格式控制符%s只能读取不含空格的字符串，但是%[]可以读取包含空格的字符串，比如I love you，就可以全部读取。
scanf的陷阱
变元必须是指针，最常犯的错误是将变量指定为scanf的变元时，忘记在变量名的前面加上&amp;符号，不过使用printf时不需要这个&amp;字符，此外，如果变元时数组名或指针变量，也不需要&amp;符号；
在读字符串时，要确保有足够的空间存放读入的字符串，这个字符串需包含终止字符’\0’，否则，会覆盖内存中的饿数据，甚至是程序代码。

对于字符串输入，使用gets或fgets通常是首选方式，除非要控制字符串的内容。
]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>c++</tag>
        <tag>c-advance</tag>
        <tag>C语言从入门到进阶</tag>
      </tags>
  </entry>
  <entry>
    <title>C语言 库函数和系统调用的区别</title>
    <url>/2013/04/14/c-advance-library-function-and-system-call/</url>
    <content><![CDATA[库函数和系统调用的区别库函数是更高级别的，完全在用户空间里运行，并为程序员提供了更方便的做实际工作的函数接口。Higher level，run in user space，more convenient。
系统调用代表用户以内核模式工作，由操作系统本身的内核提供。In kernel mode。
库函数printf看上去类似于一般输出函数，但是它实际上只是格式化你提供给字符串的数据，并用低级系统调用write编写字符串数据，然后将数据发送到一个与终端的标准输出关联的文件中。
]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>c++</tag>
        <tag>c-advance</tag>
        <tag>C语言从入门到进阶</tag>
        <tag>kernel</tag>
        <tag>library function</tag>
        <tag>printf</tag>
      </tags>
  </entry>
  <entry>
    <title>C语言 空指针</title>
    <url>/2012/03/08/c-advance-null-pointer/</url>
    <content><![CDATA[空指针
所谓的空指针就是表示“未分配”或者“尚未指向任何地方”的“特殊”指针；
在源码中用来表示空指针的空指针常量使用整数0，且在很多机器上都在内部采用所有位都是0的字来表示空指针，但C语言不保证第二点；
空指针在概念上不同于未初始化的指针。空指针可以确保不指向任何对象或函数，而未初始化的指针则可能指向任何地方；
根据语言定义，在指针上下文中的“值为0的整型常量表达式”会在编译时转换为空指针，但是，传入函数的参数不一定被当做指针上下文。所以，在函数调用时对所有的空指针进行类型转换可能是防止可变参数和无原型函数出问题的最安全的方法；
为了让程序中的空指针使用更加明确，特意定义了一个标准预处理宏NULL，其值为空指针常量；
在有些编译器头文件中定义NULL为0L，是因为在有些机器上指针比整型大，比如large模式的PC兼容机上；
关于空指针，有两条规则必须遵循：
当在源码中需要空指针常量时，用“0”或“NULL”；

如果在函数调用中“0”或“NULL”用作参数，把它转换成被调函数需要的指针类型即可；
]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>c++</tag>
        <tag>c-advance</tag>
        <tag>C语言从入门到进阶</tag>
        <tag>pointer</tag>
      </tags>
  </entry>
  <entry>
    <title>C语言 按位运算符</title>
    <url>/2012/01/31/c-advance-operator-step1/</url>
    <content><![CDATA[C语言的按位运算符​	按位运算符，在实际的程序中用的不是很多，主要的应用是底层系统操作，比如嵌入式、驱动等，它的作用就是对位进行操作，这个就要比较熟悉各种进制的转换了。
​	几个按位运算符的含义如下：



按位运算符
含义



&amp;
按位与


|
按位或


^
按位异或


~
按位取反


&lt;&lt;
按位左移


&gt;&gt;
按位右移


举个例子来show一下：
/*advance/operator/operator1.c*/#include &lt;stdio.h&gt;int main(){    int a = 5; //0b101    int b = 3; //0b011    printf("%d &amp; %d : %d\n", a, b, (a &amp; b));    printf("%d | %d : %d\n", a, b, (a | b));    printf("%d ^ %d : %d\n", a, b, (a ^ b));    printf("~%d    : %d\n", a, ~a);    printf("%d&lt;&lt;1  : %d\n", a, a &lt;&lt; 1);    printf("%d&gt;&gt;1  : %d\n", b, b &gt;&gt; 1);    return 0;}

相应地Makefile如下所示：
#advance/operator/MakefileALL : operator1operator1: operator1.c	gcc -o operator1 operator1.c.PHONY : cleanclean:	rm -f operator1


我们可以看到，这一次的Makefile我们多了一个.PHONY行，这是一个伪目标，主要作用是防止Makefile定义的可执行命令的目标跟工作目录里面的文件重名而出现无法运行的问题，在这也提高了执行时的效率，建议每个Makefile都要包含。

输入make，然后./operator1输出为：
5 &amp; 3 : 15 | 3 : 75 ^ 3 : 6~5    : -65&lt;&lt;1  : 103&gt;&gt;1  : 1


可以看到结果就是对每一位进行的操作

]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>c-advance</tag>
        <tag>C语言从入门到进阶</tag>
        <tag>operator</tag>
      </tags>
  </entry>
  <entry>
    <title>C语言 赋值运算符</title>
    <url>/2012/01/31/c-advance-operator-step2/</url>
    <content><![CDATA[C语言的赋值运算符​	赋值运算符就是把表达式或者值赋给变量，比如极易混淆的=为赋值，等于是==。
​	其实赋值运算符可以和很多前面说的算术运算符、逻辑运算符和按位运算符合并使用。
​	如下如下：



赋值运算符
含义



=
赋值，等于


+=
加后赋值


-=
减后赋值


*=
乘后赋值


/=
除后赋值


%=
取模后赋值


&amp;=
按位与后赋值


|=
按位或后赋值


^=
按位异或后赋值


&lt;&lt;=
按位左移后赋值


&gt;&gt;=
按位右移后赋值


举个例子来show一下：
/*advance/operator/operator2.c*/#include &lt;stdio.h&gt;int main(){    int a;    printf("a is %d\n", a);    a = 5; //0b101    printf("a is %d\n", a);    printf("%d += 2 -&gt; %d \n", a, a += 2);    a = 5; //0b101    printf("%d -= 2 -&gt; %d \n", a, a -= 2);    a = 5; //0b101    printf("%d *= 2 -&gt; %d \n", a, a *= 2);    a = 5; //0b101    printf("%d /= 2 -&gt; %d \n", a, a /= 2);    a = 5; //0b101    printf("%d %%= 2 -&gt; %d \n", a, a %= 2);    a = 5; //0b101    printf("%d &amp;= 2 -&gt; %d \n", a, a &amp;= 2);    a = 5; //0b101    printf("%d |= 2 -&gt; %d \n", a, a |= 2);    a = 5; //0b101    printf("%d ^= 2 -&gt; %d \n", a, a ^= 2);    a = 5; //0b101    printf("%d &lt;&lt;= 2 -&gt; %d \n", a, a &lt;&lt;= 2);    a = 5; //0b101    printf("%d &gt;&gt;= 2 -&gt; %d \n", a, a &gt;&gt;= 2);    return 0;}

相应地Makefile如下所示：
#advance/operator/MakefileALL : operator1  operator2operator1: operator1.c	gcc -o operator1 operator1.coperator2: operator2.c	gcc -o operator2 operator2.c.PHONY : cleanclean:	rm -f operator1 operator2

输入make，然后./operator2输出为：
a is 107106770a is 55 += 2 -&gt; 75 -= 2 -&gt; 35 *= 2 -&gt; 105 /= 2 -&gt; 25 %= 2 -&gt; 15 &amp;= 2 -&gt; 05 |= 2 -&gt; 75 ^= 2 -&gt; 75 &lt;&lt;= 2 -&gt; 205 &gt;&gt;= 2 -&gt; 1


可以看到结果就是对每一位进行的操作

那么问题来了，你知道为什么a刚开始的值是107106770吗，为什么每次都给a赋值吗？
]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>c-advance</tag>
        <tag>C语言从入门到进阶</tag>
        <tag>operator</tag>
      </tags>
  </entry>
  <entry>
    <title>C语言 数据运算符</title>
    <url>/2012/02/02/c-advance-operator-step3/</url>
    <content><![CDATA[C语言的数据运算符这一节接触的都是新东西，hold住。
数据运算符顾名思义就是对数据进行操作的运算符，这里设计到几个新概念，如果刚开始不了解，也没有关系，毕竟是进阶的东西，先大概看一下有个基础概念，因为这一次我们接触到了C语言中最难懂也是最优雅的指针，此处有掌声。
​	数据运算符有下面几个：



数据运算符
含义



sizeof()
获取xx的大小，返回字节长度


[]
数组


&amp;
取地址


*
定义指针或者解指针


-&gt;
结构体解应用


.
结构体应用


详细说说这几个的具体含义：

sizeof(xx)：这个比较简单，就是计算xx的字节长度；
[]：数组的定义方式，比如int a[10]就是定义了一个一维的整数数组，这个数组长度为10，但是有个问题要注意了，数组的长度从0开始，所以如果访问数组a，只能是a[0]到a[9]，如果下标是10就越界报错了，其实ANSI也曾尝试着把这个下标从1开始矫正过来，但是几十年的传统还有兼容性，此事只能作罢；
&amp;：取地址是取一个变量的地址，比如int a=0；我们顶一个了一个整数a，它的值是0，那么它位于哪里呢，这个就类似于你叫张三，你家的地址在桃花坞里桃花庵，桃花庵里第一间，另注意这个符号在C++里面是引用的含义，不要混淆；
*：这个星号就大有来头了，前后左右的含义不一样，古往今来也很很多人栽进去了，就是因为这个隐晦又高效的指针，所以有了一本书叫做《C和指针》，专门来讲讲这个东西，后面我们也会 有系列小篇，争取能让大家越过这个坎，那就算是C语言里面的高手了；
-&gt;和.：这两个的区别主要在于结构体，如果定义的结构体是指针用-&gt;，如果不是用.，这个我也迷惑过。

看个例子来show一下：
这个例子又新增了一些东西，除了上面描述的运算符，我们增加了一个头文件string.h，这个用来后面调用strcpy函数，另外还使用了结构体，下一节来聊聊必须要使用的结构体。
/*advance/operator/operator3.c*/#include &lt;stdio.h&gt;#include &lt;string.h&gt;int main(){    int a;    printf("sizeof(a) is %d \n", sizeof(a));    int arr[100];    arr[0] = 0;    arr[2] = 2;    printf("The value of arr[0] is %d\n", arr[0]);    printf("The value of arr[1] is %d\n", arr[1]);    printf("The value of arr[2] is %d\n", arr[2]);    printf("The address of a   is %X\n", &amp;a);    printf("The address of arr is %X\n", arr);    int *pa = &amp;a;    printf("The address of a   is %X\n", pa);    int *parr = arr;    printf("The address of arr is %X\n", parr);    struct person    {        char name[20];        int age;    };    struct person lilei = {"Li Lei", 18};    printf("Person 1 : Name: %s\t Age : %d\n", lilei.name, lilei.age);    struct person hanmeimei;    struct person *phanmeimei = NULL;    phanmeimei = &amp;hanmeimei;    strcpy(phanmeimei-&gt;name, "Han Meimei");    phanmeimei-&gt;age = 16;    printf("Person 2 : Name: %s\t Age : %d\n", phanmeimei-&gt;name, phanmeimei-&gt;age);    return 0;}

相应地Makefile如下所示：
#advance/operator/MakefileALL : operator1  operator2 operator3operator1: operator1.c	gcc -o operator1 operator1.coperator2: operator2.c	gcc -o operator2 operator2.coperator3: operator3.c	gcc -o operator3 operator3.c.PHONY : cleanclean:	rm -f operator1 operator2 operator3

输入make，然后./operator3输出为：
sizeof(a) is 4The value of arr[0] is 0The value of arr[1] is 0The value of arr[2] is 2The address of a   is EDFAD6D8The address of arr is EDFAD710The address of a   is EDFAD6D8The address of arr is EDFAD710Person 1 : Name: Li Lei        Age : 18Person 2 : Name: Han Meimei    Age : 16




Q&amp;A ：上上节的答案，为什么a没有赋值却有这么大的值，这个涉及到后面会说到的全局变量和局部变量的区别，局部变量在未初始化之前，有可能是任何值，所以为防意外，变量定义最好都要初始化。

]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>c-advance</tag>
        <tag>C语言从入门到进阶</tag>
        <tag>operator</tag>
      </tags>
  </entry>
  <entry>
    <title>C语言 static的作用</title>
    <url>/2014/02/15/c-advance-static/</url>
    <content><![CDATA[C语言中static的作用隐藏当我们同时编译多个文件时，所有未加 static 前缀的全局变量和函数都具有全局可见性。为理解这句话，我举例来说明。我们要同时编译两个源文件，一个是 sub.c，另一个是 main.c。
下面是 sub.c 的内容：
sub.c 文件代码
char a = 'A'; // global variablevoid msg(){    printf("Hello World\n");}

下面是 main.c 的内容：
main.c 文件代码
int main(void){        extern char a;    // extern variable must be declared before use    printf("%c ", a);    (void)msg();    return 0;}

程序的运行结果是：
A Hello World

在 sub.c 中定义的全局变量 a 和函数 msg 能在 main.c 中使用是因为所有未加 static 前缀的全局变量和函数都具有全局可见性，其它的源文件也能访问。如果加了 static，就会对其它源文件隐藏。例如在 a 和 msg 的定义前加上 static，main.c 就看不到它们了。利用这一特性可以在不同的文件中定义同名函数和同名变量，而不必担心命名冲突。
static 可以用作函数和变量的前缀，对于函数来讲，static 的作用仅限于隐藏，而对于变量，static 还有下面两个作用。
static 的第二个作用是保持变量内容的持久。存储在静态数据区的变量会在程序刚开始运行时就完成初始化，也是唯一的一次初始化。共有两种变量存储在静态存储区：全局变量和 static 变量，只不过和全局变量比起来，static 可以控制变量的可见范围，说到底 static 还是用来隐藏的。虽然这种用法不常见，但我还是举一个例子。
#include &lt;stdio.h&gt;int fun(void){    static int count = 10;    // 事实上此赋值语句从来没有执行过    return count--;}int count = 1;int main(void){        printf("global\t\tlocal static\n");    for(; count &lt;= 10; ++count)        printf("%d\t\t%d\n", count, fun());        return 0;}

程序的运行结果是：
global          local static1               102               93               84               75               66               57               48               39               210              1

static 的第三个作用是默认初始化为 0其实全局变量也具备这一属性，因为全局变量也存储在静态数据区。在静态数据区，内存中所有的字节默认值都是 0x00，某些时候这一特点可以减少程序员的工作量。比如初始化一个稀疏矩阵，我们可以一个一个地把所有元素都置 0，然后把不是 0 的几个元素赋值。如果定义成静态的，就省去了一开始置 0 的操作。再比如要把一个字符数组当字符串来用，但又觉得每次在字符数组末尾加 \0 太麻烦。如果把字符串定义成静态的，就省去了这个麻烦，因为那里本来就是 \0 。
不妨做个小实验验证一下。
#include &lt;stdio.h&gt;int a;int main(void){    int i;    static char str[10];    printf("integer: %d;  string: (begin)%s(end)", a, str);    return 0;}

程序的运行结果如下:
integer: 0; string: (begin)(end)

最后对 static 的三条作用做一句话总结。首先 static 的最主要功能是隐藏，其次因为 static 变量存放在静态存储区，所以它具备持久性和默认值0。
]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>c-advance</tag>
        <tag>C语言从入门到进阶</tag>
        <tag>static</tag>
      </tags>
  </entry>
  <entry>
    <title>C语言 字符与字符串处理</title>
    <url>/2012/02/15/c-advance-string/</url>
    <content><![CDATA[C语言的字符串
字符测试函数，介绍C语言中各种字符检测函数的使用。
字符串转换，介绍将各种数值转换成字符串的函数。
字符串比较，介绍3种字符串比较函数的使用。
字符串复制，介绍各种不同的字符串复制函数的使用。
字符串清理与填充，介绍常用的字符串清理与填充函数的使用。
字符串查找，介绍字符串查找函数的使用。
字符串的连接与分割，介绍字符串连接函数与分割函数的使用。
其他字符串函数，介绍得到字符串长度、允许出现字符和不允许出现字符查找函数的使用。

字符测试 如果需要对某个字符进行类型测试，则需要用到字符测试函数。
 字符测试函数主要有isalnum()、isalpha()、isascii()、iscntrl()、isdigit()、isgraph()、islower()、isprint()等。这些函数的作用都是对一个字符进行类型测试，返回结果都是表示真假的1或0。
字符串转换字符串转换，主要是字符串到整型、浮点型、长整型的转换，整型、浮点型、长整型到字符串的转换。
常用的函数有atof()、atoi()、atol()、gcvt()、strtod()、strtol()、strtoul()、toascii()、tolower()等。在使用这些函数时，需要注意函数的参数和函数对各种参数的处理机制。
字符串处理字符串连接、分割、复制、查找、比较等字符串操作.
主要的函数有bcopy()、bzero()、index()、strcat()、strchr()、strncat()、strncpy()、strrchr()、strtok()等。
]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>c-advance</tag>
        <tag>C语言从入门到进阶</tag>
        <tag>string</tag>
      </tags>
  </entry>
  <entry>
    <title>C语言 atan函数与atan2函数的一点区别</title>
    <url>/2013/11/24/c-atan/</url>
    <content><![CDATA[atan函数与atan2函数的一点区别atan 和 atan2 都是求反正切函数，如：有两个点 point(x1,y1), 和 point(x2,y2);
那么这两个点形成的斜率的角度计算方法分别是：
float angle = atan( (y2-y1)/(x2-x1) );

或
float angle = atan2( y2-y1, x2-x1 );

atan 和 atan2 区别：
1：参数的填写方式不同；
2：atan2 的优点在于 如果 x2-x1等于0 依然可以计算，但是atan函数就会导致程序出错；
结论： atan 和 atan2函数，建议用 atan2函数.
]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>atan</tag>
        <tag>atan2</tag>
      </tags>
  </entry>
  <entry>
    <title>C语言 assert的使用</title>
    <url>/2013/03/08/c-autoacceleration/</url>
    <content><![CDATA[i++和++i的区别i++:对i增加1，但返回的是原来的未增加的值；
++i:在i存储的值上增加1并向使用它的表达式“返回”新的、增加后的值；

Mark：在c++中应该优先使用++i。

]]></content>
      <categories>
        <category>C</category>
        <category>C++</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>c++</tag>
        <tag>autoacceleration</tag>
      </tags>
  </entry>
  <entry>
    <title>C语言 argc和argv</title>
    <url>/2011/02/10/c-beginner-argc-argv/</url>
    <content><![CDATA[C语言 argc和argvargc和argv是最熟悉的陌生人。
为什么说他们熟悉，是因为如果你用的IDE比较多，大部分的main函数的样子是这样子的int main(int argc, char *argv[])；
说它们陌生是因为，你可能写了半年的程序也没有实际用过这两个参数，不明所以。
好的，先来说说它们的叫法，或许也不对：

argc：argument counter，读作arg - C，是一个整型
argv：argument vector，读作 arg-V，是一个二维字符数组

具体什么意思呢，还记不记得前面说的scanf，可以采集键盘输入，恩，运行程序，然后等待我们输入，这两个参数的含义是在运行程序的时候就直接输入，比如，有两个程序bigger和smaller，我想后面直接跟两个参数来输入较大值 或者较小值，用法如下：
$ ./bigger 5 4$ ./smaller 15 23

这个时候就需要argc和argv了。
比如下面这个例子：
/*beginner/argcargv/argcargv1.c*/#include &lt;stdio.h&gt;int main(int argc, char *argv[]){    printf("argc  = %d\n", argc);    return 0;}

编译运行：
$ ./argcargv1 argc  = 1$ ./argcargv1 1 argc  = 2$ ./argcargv1 1 2argc  = 3$ ./argcargv1 1 2 3argc  = 4$ ./argcargv1 1 2 3 4argc  = 5$ ./argcargv1 1 2 3 4 1234argc  = 6

哇，amazing，argc的值根据你的输入参数在自动修改，这就是argc的意思，就是命令行的个数统计。
下面看看argv的用法，代码如下：
/*beginner/argcargv/argcargv2.c*/#include &lt;stdio.h&gt;int main(int argc, char *argv[]){    printf("argv are :\n");    int i;    for (i = 0; i &lt; argc; i++)        printf("argv[%d] = %s\n", i, argv[i]);    return 0;}


这里有个需要留意的地方，就是我们在使用argv的时候需要配合argc，因为这就涉及到数组溢出的issue了。

结果如下：
$ ./argcargv2 1argv are :argv[0] = ./argcargv2argv[1] = 1$ ./argcargv2 1 2argv are :argv[0] = ./argcargv2argv[1] = 1argv[2] = 2$ ./argcargv2 1 2 34argv are :argv[0] = ./argcargv2argv[1] = 1argv[2] = 2argv[3] = 34



综上，我们就可以写个bigger的demo程序了，先自己想想如何写。

代码如下：
/*beginner/argcargv/argcargv3.c*/#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;int main(int argc, char *argv[]){    if (argc != 3)    {        printf("Usage :\n");        printf("       ./argcargv3 num1 num2\n");        exit(0);    }    if (atoi(argv[1]) &gt; atoi(argv[2]))        printf("Bigger is %d\n", atoi(argv[1]));    else        printf("Bigger is %d\n", atoi(argv[2]));    return 0;}

测试如下：
$ ./argcargv3Usage :       ./argcargv3 num1 num2$ ./argcargv3 3 6Bigger is 6$ ./argcargv3 9 6Bigger is 9


 哇哦，又来了一点新东西，首先头文件加了stdlib，这个主要是因为使用了函数atoi，这个函数的含义就是把字符转换为数字，因为命令行参数的类型是char *的，所以在进行比较的时候要转换为整数。

编译运行直接输入make就可以了。
#beginner/argcargv/MakefileALL : argcargv1 argcargv2 argcargv3 argcargv1: argcargv1.c	gcc -o argcargv1 argcargv1.cargcargv2: argcargv2.c	gcc -o argcargv2 argcargv2.cargcargv3: argcargv3.c	gcc -o argcargv3 argcargv3.c.PHONY : cleanclean:	rm -f argcargv1 argcargv2 argcargv3 
]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>argc</tag>
        <tag>argv</tag>
        <tag>c-beginner</tag>
        <tag>C语言从小白到入门</tag>
      </tags>
  </entry>
  <entry>
    <title>C语言 存储相同类型的数组</title>
    <url>/2011/02/14/c-beginner-array/</url>
    <content><![CDATA[C语言的数组先说了结构体，可以存储不同的类型，比如描述一个学生，有学号、姓名、成绩等。
那么我们现在只想了解某个班级的平均分数，这是就是同一类型的组合了，当然也可以使用结构体搞定，不过就大材小用了，我们这次就看看能存储相同类型的数组。
先看看数组的定义方式：
type array_name [array_size];

其中：

type为数组的类型，可以是我们前面说过的各种类型，比如int，float，double等
array_name为数组的名字
array_size为数组的元素数量

下面来看看如何用，比如我们希望初始化5个学生的成绩，首先需要定义一个含有5个元素的数组:
float score[5];

初始化以后需要赋值，如下所示：
score[0] = 76.0;score[1] = 77.0;score[2] = 89.0;score[3] = 98.0;score[4] = 99.0;

不知你有没有注意到，数组的下标是从0开始的，所以下标的范围为0~array_size-1。
这种初始化方式有点繁琐，还有一种声明初始化一起的语句为：
float score[size] = {76.0, 77.0, 89.0, 98.0, 99.0};

上面的两个方法效果是一样的。
好的，开始算算这5个学生的平均成绩吧。
/*beginner/array/array1.c*/#include &lt;stdio.h&gt;int main(){    const int size = 5;    float score[size] = {76.0, 77.0, 89.0, 98.0, 99.0};    float average_score;    float sum = 0;    int i;    for (i = 0; i &lt; size; i++)        sum += score[i];    average_score = sum / size;    printf("The average score is %f\n", average_score);    return 0;}

编译运行直接输入make就可以了。
#beginner/array/MakefileALL : array1 struct1: array1.c	gcc -o array1 array1.c.PHONY : cleanclean:	rm -f array1

运行输出如下：$ ./array1The average score is 87.800003

]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>c-beginner</tag>
        <tag>C语言从小白到入门</tag>
        <tag>array</tag>
      </tags>
  </entry>
  <entry>
    <title>C语言 存储类型关键字auto/register和static</title>
    <url>/2011/02/22/c-beginner-auto-register-static/</url>
    <content><![CDATA[C语言的存储类型关键字存储类型定义了C程序中变量与函数的可见范围和生命周期。
这些关键字位于修饰的函数或变量之前，主要说说下面几个：

auto
register
static
extern （后面再说）

auto 存储类型auto 存储类是所有局部变量默认的存储类型，不管写不写，默认是auto类型的，比如：
/*beginner/auto/auto1.c*/#include &lt;stdio.h&gt;int main(){    int year = 2011;    auto int month = 2;    printf("Year : %d\n", year);    printf("Month: %d\n", month);    return 0;}

上面的实例定义了两个带有相同存储类的变量。

auto 只能用在函数内，即 auto 只能修饰局部变量。

register 存储类型register 存储类型用于定义存储在寄存器中而不是 RAM 中的局部变量。这意味着变量的最大尺寸等于寄存器的大小（通常是一个词），且不能对它应用一元的 &amp; 运算符（因为它没有内存位置）。
/*beginner/register/register2.c*/#include &lt;stdio.h&gt;int main(){    register int sum = 0;    int i = 0;    for (i = 0; i &lt;= 100; i++)    {        sum += i;        printf("Sum : %d\n", sum);    }    return 0;}

寄存器主要用于快速访问及变化的变量，比如计数器。不过，定义 register 并不意味着变量将被存储在寄存器中，它意味着变量可能存储在寄存器中，只是可能，这取决于硬件和实现的限制，所以这个一般不太实用，除非对系统很精通，确认是寄存器使用，才能起到加速的效果。
static 存储类型static有多重用法，这里先说一下作为存储类型的用法，这个功能对于需要在某个函数进行初始化且需要保持状态作用大大滴。

static 存储类型指示编译器在程序的生命周期内保持局部变量的存在，而不需要在每次它进入和离开作用域时进行创建和销毁。因此，使用 static 修饰局部变量可以在函数调用之间保持局部变量的值。

static 修饰符也可以应用于全局变量。当 static 修饰全局变量时，会使变量的作用域限制在声明它的文件内，还未说到多个文件，后续再介绍

全局声明的一个 static 变量或方法可以被任何函数或方法调用，只要这些方法出现在跟 static 变量或方法同一个文件中。


以下实例演示了 static 修饰全局变量和局部变量的应用：
/*beginner/static/static3.c*/#include &lt;stdio.h&gt;void localfunc(void);static int global = 10;int main(){    while (global--)    {        localfunc();    }    return 0;}void localfunc(void){    static int local = 5;    local++;    printf(" local : %d , global : %d\n", local, global);}

可以看到运行的结果为：
$ ./storage3 local : 6 , global : 9 local : 7 , global : 8 local : 8 , global : 7 local : 9 , global : 6 local : 10 , global : 5 local : 11 , global : 4 local : 12 , global : 3 local : 13 , global : 2 local : 14 , global : 1 local : 15 , global : 0
]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>static</tag>
        <tag>c-beginner</tag>
        <tag>C语言从小白到入门</tag>
        <tag>auto</tag>
        <tag>register</tag>
        <tag>extern</tag>
      </tags>
  </entry>
  <entry>
    <title>C语言 main函数</title>
    <url>/2011/02/11/c-beginner-calloc/</url>
    <content><![CDATA[聊聊main函数main字面的意思就是主要的意思，在程序里面也是，并且更重要了，是主函数，何为主函数，就是程序运行会执行的第一个程序，意即程序的入口，如果说眼睛是心灵的窗户，那么main就是程序的大门。
在C99标准之前，main函数可以没有返回类型或者使用void，如下所示：
/*beginner/main/main1.c*/main(){}

或者
/*beginner/main/main2.c*/void main(){}



这两个可以称为最短小精悍的程序了，不会出错，因为没有语句。
如果使用C99标准编译，就可以看到如下的警告信息：
main1.c:3:1: warning: type specifier missing, defaults to 'int' [-Wimplicit-int]main()^1 warning generated.gcc -o main2 main2.cmain2.c:3:1: warning: return type of 'main' is not 'int' [-Wmain-return-type]void main()^main2.c:3:1: note: change return type to 'int'void main()^~~~int1 warning generated.

警告的含义就是我们的mian函数是有血有肉的，是有正儿八经的返回值的，这个返回值的类型就是int，所以这个程序：
/*beginner/main/main3.c*/int main(){}

OK，完美编译，没有任何报错信息，不过终归看着少了点什么，是的，如果定义了返回类型，就需要有相应的返回，所以第一个标准的简单C语言函数如下所示：
/*beginner/main/main4.c*/int main(){    return 0;}

main函数的形式恩，既然写出了main函数的标准形式，这里就需要讨论一个问题，为什么有时候看到int main()，有时候又看到int main(int argc, char *argv[])呢，具体的形式如下所示：
无参数的main函数/*beginner/main/main5.c*/int main(){    printf("Hello World\n");    return 0;}

可以看到上面这个例子，只是打印了hello world，并没有其他语句。
而下面的例子，我们看到使用到了argc和argv，所谓的形参，所以在有需要的时候才会出现这种形式，就好像是黄蓉给郭靖的几个锦囊^_^。
有参数的main函数/*beginner/main/main6.c*/int main(int argc, char *argv[]){    printf("The are %d arguments.\n", argc);    int i;    for (i = 0; i &lt; argc; i++)        printf("%s ", argv[i]);    printf("\n");    return 0;}



编译运行直接输入make就可以了。
#beginner/main/MakefileALL : main1 main2 main3 main4 main5 main6main1: main1.c	gcc -o main1 main1.cmain2: main2.c	gcc -o main2 main2.cmain3: main3.c	gcc -o main3 main3.cmain4: main4.c	gcc -o main4 main4.cmain5: main5.c	gcc -o main5 main5.cmain6: main6.c	gcc -o main6 main6.c.PHONY : cleanclean:	rm -f main1 main2 main3 main4 main5 main6

MALLOC(3)                                                                          Linux Programmer’s Manual                                                                         MALLOC(3)
NAME       malloc, free, calloc, realloc - allocate and free dynamic memory
SYNOPSIS       #include &lt;stdlib.h&gt;
   void *malloc(size_t size);
   void free(void *ptr);
   void *calloc(size_t nmemb, size_t size);
   void *realloc(void *ptr, size_t size);
   void *reallocarray(void *ptr, size_t nmemb, size_t size);

   Feature Test Macro Requirements for glibc (see feature_test_macros(7)):
   reallocarray():
       Since glibc 2.29:
           _DEFAULT_SOURCE
       Glibc 2.28 and earlier:
           _GNU_SOURCE

DESCRIPTION       The malloc() function allocates size bytes and returns a pointer to the allocated memory.  The memory is not initialized.  If size is 0, then malloc() returns either NULL, or a unique       pointer value that can later be successfully passed to free().
   The free() function frees the memory space pointed to by ptr, which must have been returned by a previous call to malloc(), calloc(), or realloc().  Otherwise, or if free(ptr) has al‐
   ready been called before, undefined behavior occurs.  If ptr is NULL, no operation is performed.

   The  calloc()  function allocates memory for an array of nmemb elements of size bytes each and returns a pointer to the allocated memory.  The memory is set to zero.  If nmemb or size
   is 0, then calloc() returns either NULL, or a unique pointer value that can later be successfully passed to free().  If the multiplication of nmemb and size would  result  in  integer
   overflow, then calloc() returns an error.  By contrast, an integer overflow would not be detected in the following call to malloc(), with the result that an incorrectly sized block of
   memory would be allocated:

       malloc(nmemb * size);

   The realloc() function changes the size of the memory block pointed to by ptr to size bytes.  The contents will be unchanged in the range from the start of the region up to the  mini‐
   mum of the old and new sizes.  If the new size is larger than the old size, the added memory will not be initialized.  If ptr is NULL, then the call is equivalent to malloc(size), for
   all values of size; if size is equal to zero, and ptr is not NULL, then the call is equivalent to free(ptr).  Unless ptr is NULL, it must have been returned by an earlier call to mal‐
   loc(), calloc(), or realloc().  If the area pointed to was moved, a free(ptr) is done.

   The reallocarray() function changes the size of the memory block pointed to by ptr to be large enough for an array of nmemb elements, each of which is size bytes.  It is equivalent to
   the call

           realloc(ptr, nmemb * size);

   However, unlike that realloc() call, reallocarray() fails safely in the case where the multiplication would overflow.  If such an overflow occurs, reallocarray()  returns  NULL,  sets
   errno to ENOMEM, and leaves the original block of memory unchanged.

RETURN VALUE       The  malloc()  and calloc() functions return a pointer to the allocated memory, which is suitably aligned for any built-in type.  On error, these functions return NULL.  NULL may also       be returned by a successful call to malloc() with a size of zero, or by a successful call to calloc() with nmemb or size equal to zero.
   The free() function returns no value.

   The realloc() function returns a pointer to the newly allocated memory, which is suitably aligned for any built-in type, or NULL if the request failed.  The returned  pointer  may  be
   the  same as ptr if the allocation was not moved (e.g., there was room to expand the allocation in-place), or different from ptr if the allocation was moved to a new address.  If size
   was equal to 0, either NULL or a pointer suitable to be passed to free() is returned.  If realloc() fails, the original block is left untouched; it is not freed or moved.

   On success, the reallocarray() function returns a pointer to the newly allocated memory.  On failure, it returns NULL and the original block of memory is left untouched.

ERRORS       calloc(), malloc(), realloc(), and reallocarray() can fail with the following error:
   ENOMEM Out of memory.  Possibly, the application hit the RLIMIT_AS or RLIMIT_DATA limit described in getrlimit(2).

ATTRIBUTES       For an explanation of the terms used in this section, see attributes(7).
   ┌─────────────────────┬───────────────┬─────────┐
   │Interface            │ Attribute     │ Value   │
   ├─────────────────────┼───────────────┼─────────┤
   │malloc(), free(),    │ Thread safety │ MT-Safe │
   │calloc(), realloc()  │               │         │
   └─────────────────────┴───────────────┴─────────┘

CONFORMING TO       malloc(), free(), calloc(), realloc(): POSIX.1-2001, POSIX.1-2008, C89, C99.
   reallocarray() is a nonstandard extension that first appeared in OpenBSD 5.6 and FreeBSD 11.0.

NOTES       By default, Linux follows an optimistic memory allocation strategy.  This means that when malloc() returns non-NULL there is no guarantee that the memory really is available.  In case       it turns out that the system is out of memory, one or more processes will be killed by the OOM killer.  For more information, see the description of /proc/sys/vm/overcommit_memory and       /proc/sys/vm/oom_adj in proc(5), and the Linux kernel source file Documentation/vm/overcommit-accounting.rst.
   Normally, malloc() allocates memory from the heap, and adjusts the size of the heap as required, using sbrk(2).  When allocating blocks of memory larger than MMAP_THRESHOLD bytes, the
   glibc  malloc()  implementation  allocates the memory as a private anonymous mapping using mmap(2).  MMAP_THRESHOLD is 128 kB by default, but is adjustable using mallopt(3).  Prior to
   Linux 4.7 allocations performed using mmap(2) were unaffected by the RLIMIT_DATA resource limit; since Linux 4.7, this limit is also enforced for allocations performed using mmap(2).

   To avoid corruption in multithreaded applications, mutexes are used internally to protect the memory-management data structures employed by these functions.  In a multithreaded appli‐
   cation  in  which  threads  simultaneously  allocate and free memory, there could be contention for these mutexes.  To scalably handle memory allocation in multithreaded applications,
   glibc creates additional memory allocation arenas if mutex contention is detected.  Each arena is a large region of memory that is internally allocated by the system (using brk(2)  or
   mmap(2)), and managed with its own mutexes.

   SUSv2 requires malloc(), calloc(), and realloc() to set errno to ENOMEM upon failure.  Glibc assumes that this is done (and the glibc versions of these routines do this); if you use a
   private malloc implementation that does not set errno, then certain library routines may fail without having a reason in errno.

   Crashes in malloc(), calloc(), realloc(), or free() are almost always related to heap corruption, such as overflowing an allocated chunk or freeing the same pointer twice.

   The malloc() implementation is tunable via environment variables; see mallopt(3) for details.

SEE ALSO       valgrind(1), brk(2), mmap(2), alloca(3), malloc_get_state(3), malloc_info(3), malloc_trim(3), malloc_usable_size(3), mallopt(3), mcheck(3), mtrace(3), posix_memalign(3)
   For details of the GNU C library implementation, see ⟨https://sourceware.org/glibc/wiki/MallocInternals⟩.

COLOPHON       This page is part of release 5.05 of the Linux man-pages project.  A description of the project, information about reporting bugs, and the latest version of this page, can be found at       https://www.kernel.org/doc/man-pages/.
GNU                                                                                       2020-02-09                                                                                 MALLOC(3)
]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>argc</tag>
        <tag>argv</tag>
        <tag>c-beginner</tag>
        <tag>C语言从小白到入门</tag>
      </tags>
  </entry>
  <entry>
    <title>C语言 常量</title>
    <url>/2011/02/15/c-beginner-constant/</url>
    <content><![CDATA[C语言中的常量在C语言里面，一般有2个常量的使用，一个是说过的define另外一个就是前两次用到的const，下面就分别来说说。
constconst是C/C++中的一个关键字(修饰符), const一般用来定义一个常量, 既然叫做常量, 即就意味着这个值后面就不能修改了。
举个简单的计算面积的例子：
/*beginner/constant/constant1.c*/#include &lt;stdio.h&gt;int main(){    const int LENGTH = 5;    const int WIDTH = 4;    printf("The area is %d\n", LENGTH * WIDTH);    return 0;}



下面在看看define这个常量定义。
#define而define，其实正常的称呼应该叫做宏定义，是一条预编译指令， 编译器在编译阶段会将所有使用到宏的地方简单地进行替换。如下图所示 :
比较所以const 和 define 都能定义一个常量，都能实现修改值修改一次, 则所有用上该常量的地方都同步改值，一句代码都不用改。
这样就可以得到下面的优点：

使代码更易维护
提高代码的效率

不过除了这些相同点，还是区别的，听我慢慢道来。

下面的有点小超纲，看不懂也没有关系的，🆙。

const定义常量是汇编的角度来看，只是给出了对应的内存地址，而不是象#define一样给出的是立即数，所以，const定义的常量在程序运行过程中只有一份拷贝，而#define定义的常量在内存中有若干个拷贝
编译器通常不为普通const常量分配存储空间，而是将它们保存在符号表中，这使得它成为一个编译期间的常量，没有了存储与读内存的操作，使得它的效率比宏定义要高。既然宏定义能做的事const都能做, 那宏还有什么存在的必要么?
存在即合理, 既然宏定义还没被淘汰, 那必然有它存在的道理.
宏能做到const不能办到的事.

宏能定义函数
宏还能根据传入的参数生成字符串

/*beginner/constant/constant3.c*/#include &lt;stdio.h&gt;#define STRINGCAT(x,y)  #x#y#define TOSTRING(x) #xint main(){    printf("%s\n", STRINGCAT(Hello, WORLD));    printf("%s\n", TOSTRING(1234));    return 0;}

这个功能相当的赞，可以替换很多string的函数了。
编译运行直接输入make就可以了。
#beginner/constant/MakefileALL : constant1 constant2 constant3 constant1: constant1.c	gcc -o constant1 constant1.cconstant2: constant2.c	gcc -o constant2 constant2.cconstant3: constant3.c	gcc -o constant3 constant3.c.PHONY : cleanclean:	rm -f constant1 constant2 constant3 

运行输出如下：$ ./constant1The area is 20$ ./constant2The area is 20$ ./constant3HelloWORLD1234
]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>define</tag>
        <tag>c-beginner</tag>
        <tag>C语言从小白到入门</tag>
        <tag>const</tag>
      </tags>
  </entry>
  <entry>
    <title>C语言 源码、反码和补码</title>
    <url>/2011/02/09/c-beginner-data-type/</url>
    <content><![CDATA[C语言的原码、反码和补码经典著作《C和指针》说过，对于C语言而言，只有四种类型：

整形
浮点型
指针型
聚合型（比如数组、结构体等）

有人就说了，明显的有char类型吗，不过你可以看看char的范围，就能理解这个char是一个微型的正数，范围在-128~127或者0-255之间，为什么会是两个范围呢，仔细想想signed和unsigned的区别。

建议阅读这个经典著作，对指针的理解会上升一个层次

其中整数在计算机内部基本使用补码来表示，这里就说下原码、反码和补码。
先抛出他们的定义：

原码：原码就是符号位加上真值的绝对值, 即用第一位表示符号, 其余位表示值

反码：正数的反码是其本身，负数的反码是在其原码的基础上, 符号位不变，其余各个位取反.

补码：正数的补码就是其本身，负数的补码是在其原码的基础上, 符号位不变, 其余各位取反, 最后+1(也可以认为是在反码的基础上+1)


举个例子说明一下：



类别
正数
负数
备注（十进制）



原码
0b00011011
0b10011011
27/-27


反码
0b00011011
0b11100100
27/-100


补码
0b00011011
0b11100101
27/-101


对于计算机而言，能理解的只有二进制，也就是电路里面的高低或者叫开关。





]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>c-beginner</tag>
        <tag>C语言从小白到入门</tag>
      </tags>
  </entry>
  <entry>
    <title>C语言 最适合学习C语言的编辑器</title>
    <url>/2011/01/26/c-beginner-editors/</url>
    <content><![CDATA[最适合学习C语言的编辑器你说那个是最好的编辑器，vim吗，emacs呀，然后两个阵营的人就开始互殴了，但凡在命令行界面开发的人，估计使用这个2个编辑器的人占到了99.9%。
以前看过一些文章说Vim是编辑器之神，Emacs是神的编辑器。
因为最开始接触的vim，所以钟爱vim。
不过这个跟开始学C语言的没什么关系，虽然经过半年的使用熏陶，先入为主，我已经爱上了Vim，哈哈。
gedit在开始学习C语言的时候，不要在这些无所谓的事情上浪费太多的精力，如果是在Linux的Gnome环境下，就使用Gedit就可以了，如果是Windows使用记事本或者Notepad++，不过你怎么不听劝，还没有切换到Linux环境吗，😳。
Notepad++(Windows)Notepad++ 是很多Windows用户寻找的比记事本更优秀的文本编辑器。它拥有很多丰富先进的特性，例如语法高亮显示，代码折叠和宏，但不同于大多数其他的基于GUI的文本编辑器功能，Notepad++是完全自由而且开放源代码。它和其他的编辑器相比可能并非性感如起飞的蝙蝠。但它完全定制，因此只受限于您的时间和想象力。作为一个编辑器，它的强大是不言而喻的。

官方网址：http://notepad-plus.sourceforge.net/uk/site.htm

Emacs (适合所有平台)高级程序员的主要文本编辑器。在Emacs（编辑宏）最受欢迎的是内置宏和清大的键盘命令，使编辑的文本文件，尤其是代码很好高兴。常说：您可能不会完全明白Emacs的，直到您话一些时间去了解它。该程序已经被移植到几乎所有的平台，并有多个发行版，其中最流行的可能是GNU Emacs和XEmacs，它们都是免费、跨平台和开放源码。

Emacs的入门比较难，过程比较酸，掌握后会比较爽。

Vim(所有平台)类似于Emacs，Vim（一个六岁的孩童），是因为它的键盘宏而广受欢迎，是高级程序员的一个强大工具。也类似于Emacs，Vim也有不同的口味，除了原来的，还有Windows平台的gVim 和 gVim Portable，Mac平台的MacVim，如果你认为你可能的兴趣在Vim中已经提供，但尚未准备好一步一步深入这款功能强大而又有点不易用的编辑器，
Pspad（windows）PSPad功能非常强大，UltraEdit、Editplus、EmEditor能做的（比如多文件编辑、支持“工程”、语法高亮、HEX编辑，内置FTP功能），PSPad也能做到，甚至做得更好！PSPad里集成了许多非常实用的工具


接下啦是一些收费软件。

EditPlusEditPlus(文字编辑器)汉化版一套功能强大，可取代记事本的文字编辑器，EditPlus拥有无限制的撤消与重做、英文拼字检查、自动换行、列数标记、搜寻取代、同时编辑多文件、全屏幕浏览功能。而它还有一个好用的功能，就是它有监视剪贴板的功能，能够同步于剪贴板自动将文字粘贴进 EditPlus 的编辑窗口中，让你省去粘贴的步骤。另外它也是一个非常好用的HTML编辑器，它除了支持颜色标记、HTML 标记，同时支持C、C++、Perl、Java，另外，它还内建完整的HTML &amp; CSS1 指令功能，对于习惯用记事本编辑网页的朋友，它可帮你节省一半以上的网页制作时间，若你有安装IE3.0 以上版本，它还会结合IE浏览器于 EditPlus 窗口中，让你可以直接预览编辑好的网页(若没安装IE，也可指定浏览器路径)。因此，它是一个相当棒又多用途多状态的编辑软件。
UltraEdit (Windows)共享软件UltraEdit（$49.95）用户感觉很友好的编辑器，只吃语法高亮显示，代码折叠宏和和同类软件相比拥有大量的可用功能。UltraEdit是一个很好的WEB开发平台，提供很多高级特性用来构建HTML,PHP，JavaScript和更多其它的网络编程语言。
TextMate (Mac OS X)强大而且更具吸引力，TextMate ($63)出现在视野中仅仅几年时间而且因有吸引力的界面、功能强大的宏、以及可下载和可编辑的束，迅速的获得了狂热的追捧。Windows用户要是喜欢TextMate可以试一下E Text Editor（一个类似于TextMate且支持TextMate宏束的文本编辑器）。
]]></content>
      <categories>
        <category>C</category>
        <category>Vim</category>
        <category>Emacs</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>c-beginner</tag>
        <tag>C语言从小白到入门</tag>
        <tag>linux</tag>
        <tag>editor</tag>
        <tag>gedit</tag>
        <tag>emacs</tag>
        <tag>ultraedit</tag>
        <tag>textmate</tag>
        <tag>vim</tag>
        <tag>pspad</tag>
        <tag>editplus</tag>
      </tags>
  </entry>
  <entry>
    <title>C语言 枚举类型</title>
    <url>/2011/02/16/c-beginner-enum/</url>
    <content><![CDATA[C语言的枚举枚举这个类型，其实不是很常见，因为使用define基本都可以搞定，不过存在即是合理，枚举可以让某些数据组合更加简洁、易读、规范。
举个用的最多的例子，如果我们定义一个星期，可以使用define，如下所示：
#define MONDAY 1#define TUESDAY 2#define WEDNESDAY 3#define THURSDAY 4#define FRIDAY 5#define SATURDAY 6#defind SUNDAY 7

看着还是很不错的表达方式，然后我们在看看枚举变量，表达如下：
enum DAY{    MONDAY = 1, TUESDAY, WEDNESDAY, THURSDAY, FRIDAY, SATURDAY, SUNDAY };

看起来貌似更加简洁，明了。
OK，现在来看看枚举的定义方式：
enum enum_name {enum_element1, enum_element2, enum_element3...enum_elementN};

其中：

enum_name为枚举的名字
enum_element为枚举的元素


NOTE : 枚举的元素，默认第一个为0，如果需要改变，需要显式初始。

看一下enum的使用吧：
/*beginner/enum/enum1.c*/#include &lt;stdio.h&gt;int main(){    int i;    enum DAY    {        MONDAY,        TUESDAY,        WEDNESDAY,        THURSDAY,        FRIDAY,        SATURDAY,        SUNDAY    };    for (i = MONDAY; i &lt;= SUNDAY; i++)        printf("TODAY is %d\n", i);    return 0;}

可以看到默认MONDAY为0，与我们的习惯不同，我们显式初始化为1：
/*beginner/enum/enum2.c*/#include &lt;stdio.h&gt;int main(){    int i;    enum DAY    {        MONDAY = 1,        TUESDAY,        WEDNESDAY,        THURSDAY,        FRIDAY,        SATURDAY,        SUNDAY    };    for (i = MONDAY; i &lt;= SUNDAY; i++)        printf("TODAY is %d\n", i);    return 0;}



看看enum和switch的配合使用：
/*beginner/enum/enum3.c*/#include &lt;stdio.h&gt;int main(){    int i;    enum DAY    {        MONDAY = 1,        TUESDAY,        WEDNESDAY,        THURSDAY,        FRIDAY,        SATURDAY,        SUNDAY    };    enum DAY which_day;    printf("Which day is today?[1-7]: ");    scanf("%d", &amp;which_day);    switch (which_day)    {    case MONDAY:    case TUESDAY:    case WEDNESDAY:    case THURSDAY:    case FRIDAY:        printf("OMG, Working day\n");        break;    case SATURDAY:    case SUNDAY:        printf("Oh, yeah, weekend\n");        break;    default:        printf("range (1-7)");        break;    }    return 0;}



编译运行直接输入make就可以了。
#beginner/enum/MakefileALL : enum1 enum2 enum3 enum1: enum1.c	gcc -o enum1 enum1.cenum2: enum2.c	gcc -o enum2 enum2.cenum3: enum3.c	gcc -o enum3 enum3.c.PHONY : cleanclean:	rm -f enum1 enum2 enum3 

运行输出如下：$./enum1TODAY is 0TODAY is 1TODAY is 2TODAY is 3TODAY is 4TODAY is 5TODAY is 6$ ./enum2TODAY is 1TODAY is 2TODAY is 3TODAY is 4TODAY is 5TODAY is 6TODAY is 7$ ./enum3Which day is today?[1-7]: 3OMG, Working day$ ./enum3Which day is today?[1-7]: 6Oh, yeah, weekend

]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>c-beginner</tag>
        <tag>C语言从小白到入门</tag>
        <tag>enum</tag>
      </tags>
  </entry>
  <entry>
    <title>C语言 存储类型关键字extern</title>
    <url>/2011/02/22/c-beginner-extern/</url>
    <content><![CDATA[C语言的存储类型关键字前面说了auto、register和static存储类型，这次说一下extern存储类型。
在使用这个关键字之前，需要了解多个函数的编译，什么意思呢，就是文件a.c会使用b.c或者c.c的变量、函数等，在编译的时候也需要提供所有的文件。
下面来看看extern的概念吧。
extern 存储类用于提供一个全局变量的引用，全局变量对所有的程序文件都是可见的。当您使用 extern 时，对于无法初始化的变量，会把变量名指向一个之前定义过的存储位置。
当您有多个文件且定义了一个可以在其他文件中使用的全局变量或函数时，可以在其他文件中使用 extern 来得到已定义的变量或函数的引用。可以这么理解，extern 是用来在另一个文件中声明一个全局变量或函数。
extern 修饰符通常用于当有两个或多个文件共享相同的全局变量或函数的时候，如下所示：
第一个文件：
/*beginner/extern/extern1.c*/#include &lt;stdio.h&gt;int number;extern void test();int main(){    number = 10;    test();    return 0;}

第二个文件：
/*beginner/extern/test.c*/#include &lt;stdio.h&gt;extern int number;void test(){    int i;    for (i = 0; i &lt; 10; i++)    {        number -= 1;        printf("number is %d\n", number);    }}

可以看到两个文件互为extern，extern1.c调用test.c的test函数，test.c调用extern1.c的number变量。
编译也有所不同，方法为：
$ gcc -o extern1 extern1.c test.c

这会产生可执行程序，当程序被执行时，它会产生下列结果：
$ ./extern1number is 9number is 8number is 7number is 6number is 5number is 4number is 3number is 2number is 1number is 0
]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>static</tag>
        <tag>c-beginner</tag>
        <tag>C语言从小白到入门</tag>
        <tag>auto</tag>
        <tag>register</tag>
        <tag>extern</tag>
      </tags>
  </entry>
  <entry>
    <title>C语言 历史</title>
    <url>/2011/01/01/c-beginner-features/</url>
    <content><![CDATA[C语言的优缺点特点
底层语言：速度快，权限高，如果编写嵌入式底层，这个是必须的
小型语言：看看关键字，看看圣经，然后再看看众多的Libraries
开放性语言：给了程序员最大的自由，比如指针完全有程序员自己决定时候释放，而其他语言可能自由回收

优点
高效
可移植
灵活

缺点
错误不易发觉
可以编写混乱代码
代码到达一定量级，可能比较难维护

]]></content>
      <categories>
        <category>C</category>
        <category>Program</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>c-beginner</tag>
        <tag>C语言从小白到入门</tag>
      </tags>
  </entry>
  <entry>
    <title>C语言 for循环语句</title>
    <url>/2011/02/06/c-beginner-for-sentence/</url>
    <content><![CDATA[C语言的for循环语句​	C语言的for循环语句用的那是相当的多，等等，这话我好像说了好几次了，哈哈。
​	在小时候爸爸妈妈为我，从1加到100，最后值是多少呢，然后从早到晚就算起来了；再后来知道的神通高斯；再后来知道了C语言的for语句，😁。
​	for循环的结构比较简单，如下所示：
for (表达式1；表达式2；表达式3){    //do something}

它的执行过程如下所示：

先求解表达式1;
求解表达式2，若其值为真（非0），则执行循环体，否则结束循环;
执行完循环体，再求解表达式3。
重复执行步骤 2) 和 3)，直到循环结束。

按照上面的例子，简单举几个例子如下：
/*beginner/for/for1.c*/#include &lt;stdio.h&gt;int main(){    int i;    int sum = 0;    for (i = 0; i &lt; 101; i++)        sum += i;    printf("1 + ... + 100 = %d\n", sum);    return 0;}



相应地Makefile如下所示：
#beginner/for/MakefileALL : for1 for1 : for1.c	gcc -o for1 for1.cclean:	rm -f for1 

输入make，然后./operator4输出为：
$ ./for11 + ... + 100 = 5050

]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>c-beginner</tag>
        <tag>C语言从小白到入门</tag>
        <tag>for</tag>
      </tags>
  </entry>
  <entry>
    <title>C语言 文本文件读写</title>
    <url>/2011/03/02/c-beginner-file/</url>
    <content><![CDATA[C语言 文本文件读写基础储备知识基本结束了，今天看一下稍微高级点的文件读写，这个主要针对的对象是什么呢，比如要统计学生的分数，一般我们都会有一个文件保存所有的学生的成绩，这个时候如果我们能读取这些信息就会少了很多人工输入的工作，在前面，我们的解决方案可能是输入每一个学生的成绩，这次我们通过读取文件来搞定。
而文件的读写又分为两种：

文本文件：可以读懂的文件
二进制文件：读不懂的天数


这个跟程序员的世界很像，因为程序员的世界也是有0和1这两个元素组成的。

先说说直观上比较容易理解的文本文件。
对于文件的读写，一般的步骤为：

打开文件
读写文件
关闭文件

对应的函数为：

fopen
fread/fwrite
fclose

下面详细说说这几个函数.
]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>c-beginner</tag>
        <tag>C语言从小白到入门</tag>
        <tag>io</tag>
        <tag>fopen</tag>
        <tag>fclose</tag>
      </tags>
  </entry>
  <entry>
    <title>C语言 函数指针</title>
    <url>/2011/02/28/c-beginner-function-pointer/</url>
    <content><![CDATA[C语言 函数指针指针不仅仅能指向变量，也可以指向函数，这个功能主要用在方便快捷地调用函数上。
比如我们结合前面说的三元描述符、子函数来看看如何用函数指针。
看一个例子如下，我们已经写好了如何选择最大值，如下所示：
/*beginner/pointer/pointer2.c*/#include &lt;stdio.h&gt;int max(a, b){    return (a &gt; b ? a : b);}int main(){    int a = 6;    int b = 8;    printf("max is %d\n", max(a, b));    return 0;}

上面的是比较2个值的大小，如果想比较3个值呢，用上面的代码，新增如下：
/*beginner/pointer/pointer3.c*/#include &lt;stdio.h&gt;int max(a, b){    return (a &gt; b ? a : b);}int main(){    int a = 6;    int b = 8;    int c = 12;    int t = max(a,b);    printf("max is %d\n", max(t, c));    return 0;}

在增加一个，4个值呢，
/*beginner/pointer/pointer4.c*/#include &lt;stdio.h&gt;int max(a, b){    return (a &gt; b ? a : b);}int main(){    int a = 6;    int b = 8;    int c = 12;    int d = 9;    int t = max(a,b);    int tt = max(t,c);    printf("max is %d\n", max(tt, d));    return 0;}

所以看出来，每次新增一个值，就需要多调用一次max函数。
如果使用函数指针就可以很好地解决这个问题，如下所示：
/*beginner/pointer/pointer5.c*/#include &lt;stdio.h&gt;int max(a, b){    return (a &gt; b ? a : b);}int main(){    int (*p)(int, int) = &amp; max;    int a = 6;    int b = 8;    int c = 12;    int d = 9;    int t = p(a,b);    int tt = p(t,c);    printf("max is %d\n", p(tt, d));    return 0;}

从这里例子也可以看出来，函数的指针的格式如下所示：

返回值与原函数一致；
定义的参数与原函数类型一致；

不过好像也没有简便很多，不过如果碰到函数名巨长无比的，还是有些作用的，另外我们可以使用内嵌的方法，如下：
/*beginner/pointer/pointer6.c*/#include &lt;stdio.h&gt;int max(a, b){    return (a &gt; b ? a : b);}int main(){    int (*p)(int, int) = &amp;max;    int a = 6;    int b = 8;    int c = 12;    int d = 9;    printf("max is %d\n", p(p(p(a, b), c), d));    return 0;}
]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>c-beginner</tag>
        <tag>C语言从小白到入门</tag>
        <tag>point</tag>
      </tags>
  </entry>
  <entry>
    <title>C语言 函数</title>
    <url>/2011/01/26/c-beginner-function/</url>
    <content><![CDATA[C语言 函数C语言的main其实也是一个函数，不过是个主函数，随着程序规模的增大，就要考虑
基础储备知识基本结束了，今天看一下稍微高级点的文件读写，这个主要针对的对象是什么呢，比如要统计学生的分数，一般我们都会有一个文件保存所有的学生的成绩，这个时候如果我们能读取这些信息就会少了很多人工输入的工作，在前面，我们的解决方案可能是输入每一个学生的成绩，这次我们通过读取文件来搞定。
而文件的读写又分为两种：

文本文件：可以读懂的文件
二进制文件：读不懂的天数


这个跟程序员的世界很像，因为程序员的世界也是有0和1这两个元素组成的。

先说说直观上比较容易理解的文本文件。
对于文件的读写，一般的步骤为：

打开文件
读写文件
关闭文件

对应的函数为：

fopen
TODO

最简单的自定义函数#include &lt;stdio.h&gt;void newline(void){	printf("\n");}int main(void){    printf("First Line.\n");    newline();    printf("Second Line.\n");    return 0;}

]]></content>
      <categories>
        <category>C</category>
        <category>C语言入门</category>
      </categories>
      <tags>
        <tag>c-beginner</tag>
        <tag>C语言从小白到入门</tag>
        <tag>function</tag>
        <tag>bigger</tag>
      </tags>
  </entry>
  <entry>
    <title>C语言 自定义函数</title>
    <url>/2011/02/12/c-beginner-functions/</url>
    <content><![CDATA[自定义函数是写大程序的前提最开始写程序的时候，我们都会全部一股脑地写在main函数中，导致有的main函数有成千上万行，要调试起来，这就尴尬了。
这就引出了我们需要定义一些自定义函数，只需要将这些函数写在主函数就可以了。
是个什么意思呢，就是你秀给客户或者测试人员的main函数，是这个样子的（看一下百万量级规模的内核启动函数）：
int main(void){	printf("Linux/AXP bootloader for Linux \n");	pal_init();    openboot();    printf("Loading vmlinux ...");	load(dev, START_ADDR, KERNEL_SIZE);	close(dev);    callback_getenv(ENV_BOOTED_OSFLAGS, envval, sizeof(envval));    runkernel();    //__halt();}

虽然有些东西看不懂什么意思（因为我精简和修改了部分代码），没有问题，我们需要理解的就是Linux内核有百万行量级，而它的主函数也就短短的十几行，其他的就放在了自定义函数里实现，也就上面的openboot，runkernel等。

OK，任务来了，我想让你写个程序，计算出摄氏度和华氏度的转换，
两个的转换关系如下：

华氏度 = 32°F+ 摄氏度 × 1.8
摄氏度 = (华氏度 - 32°F) ÷ 1.8

这个简单呀，前面就写过（刷刷刷，码出如下代码）：
/*beginner/function/function1.c*/# include &lt;stdio.h&gt;int main(){    float f; // Fahrenheit temperature    float c; // Celsius temperature    f = 80.0;    c = 27.0;    float ff;    float cc;    printf ("Fahrenheit  &lt;=&gt; Celsius\n");    ff = 32 + c * 1.8;    cc = (f - 32) / 1.8;    printf("%f   &lt;=&gt; %f\n",f, cc);    printf("%f   &lt;=&gt; %f\n",ff, c);    return 0;}

不错，孺子可教也，在加深一步，又来了一组数据，也是求两者的转换关系，代码继续累加，如下：
/*beginner/function/function2.c*/# include &lt;stdio.h&gt;int main(){    float f; // Fahrenheit temperature    float f1;    float c; // Celsius temperature    float c1;    f = 80.0;    f1 = 90.0;    c = 27.0;    c1 = 36.0;    float ff;    float ff1;    float cc;    float cc1;    printf ("Fahrenheit  &lt;=&gt; Celsius\n");    ff = 32 + c * 1.8;    cc = (f - 32) / 1.8;    printf("%f   &lt;=&gt; %f\n",f, cc);    printf("%f   &lt;=&gt; %f\n",ff, c);    ff1 = 32 + c1 * 1.8;    cc1 = (f1 - 32) / 1.8;    printf("%f   &lt;=&gt; %f\n",f1, cc1);    printf("%f   &lt;=&gt; %f\n",ff1, c1);    return 0;}

如果我在来一组数据，是不是同样还需要在原来的代码基础上累加，我们就会发现：main函数越来越庞大，但是有效的代码就那么几行，其余的工作都是在重复叠加，这就引出一个问题，我们的华氏转摄氏度是比较简单的公示，如果算个麦克斯韦方程：
$\oiint_{\partial V}\mathrm{E}\cdot d \mathrm{a} = \frac{Q_V}{\epsilon_0}\ \oiint_{\partial S}\mathrm{E}\cdot d \mathrm{l} = \frac{d}{dt} \int_S \mathrm{B} \cdot d\mathrm{a}\ \oiint_{\partial V}\mathrm{B}\cdot d \mathrm{a} = 0 \ \oiint_{\partial S}\mathrm{B}\cdot d \mathrm{l} = \mu_0\epsilon_0\frac{d}{dt} \int_S \mathrm{E}  \cdot d\mathrm{a}  $$

其中$\oiint$为环路积分的符号

那么每一次计算都要重复这些操作，有没有一种方法可以简化呢，妥妥滴，这就带来了自定义函数。
我们以华氏度和摄氏度的转换为例，可以定义两个函数：
float c2f(float c); // Celsius to Fahrenheitfloat f2c(float f); // Fahrenheit to Celsius

两个函数的含义为c2f就是将摄氏度c转换为华氏度返回，相反f2c为将华氏度f转换为摄氏度返回。
具体的代码如下：
float c2f(float c){    return 32 + c * 1.8;}float f2c(float f){    return (f - 32) / 1.8;}

我们把这两个代码片段加到程序中，最后的效果如下：
/*beginner/function/function2.c*/# include &lt;stdio.h&gt;float c2f(float c); // Celsius to Fahrenheitfloat f2c(float f); // Fahrenheit to Celsiusint main(){    float f; // Fahrenheit temperature    float f1;    float c; // Celsius temperature    float c1;    f = 80.0;    f1 = 90.0;    c = 27.0;    c1 = 36.0;    float ff;    float ff1;    float cc;    float cc1;    printf ("Fahrenheit  &lt;=&gt; Celsius\n");    cc = f2c(f);    ff = c2f(c);    printf("%f   &lt;=&gt; %f\n",f, cc);    printf("%f   &lt;=&gt; %f\n",ff, c);    cc1 = f2c(f1);    ff1 = c2f(c1);    printf("%f   &lt;=&gt; %f\n",f1, cc1);    printf("%f   &lt;=&gt; %f\n",ff1, c1);    return 0;}float c2f(float c){    return 32 + c * 1.8;}float f2c(float f){    return (f - 32) / 1.8;}

这个程序新加的东西有点多，不过可以清晰的看到，主函数通过使用自定义的函数已经将重复的东西结构化了，这是编写大程序的基础，希望你能掌握。
编译运行直接输入make就可以了。
#beginner/function/MakefileALL : function1 function2 function3 function1: function1.c	gcc -o function1 function1.cfunction2: function2.c	gcc -o function2 function2.cfunction3: function3.c	gcc -o function3 function3.c.PHONY : cleanclean:	rm -f function1 function2 function3 

运行输出如下：$ ./function1Fahrenheit  &lt;=&gt; Celsius80.000000   &lt;=&gt; 26.66666680.599998   &lt;=&gt; 27.000000$ ./function2Fahrenheit  &lt;=&gt; Celsius80.000000   &lt;=&gt; 26.66666680.599998   &lt;=&gt; 27.00000090.000000   &lt;=&gt; 32.22222196.800003   &lt;=&gt; 36.000000$ ./function3Fahrenheit  &lt;=&gt; Celsius80.000000   &lt;=&gt; 26.66666680.599998   &lt;=&gt; 27.00000090.000000   &lt;=&gt; 32.22222196.800003   &lt;=&gt; 36.000000

]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>c-beginner</tag>
        <tag>C语言从小白到入门</tag>
        <tag>function</tag>
      </tags>
  </entry>
  <entry>
    <title>C语言 Hello World</title>
    <url>/2011/01/04/c-beginner-helloworld/</url>
    <content><![CDATA[C语言第一个程序 - Hello WorldC语言作为编译型程序，相比较于解释型语言多了编译这一步，不像python编写了代码就直接可以运行了，这基本上也是上手有难度的原因了。
这里从一个最简单的程序Hello World入手，讲解一下如何编写，编译及运行，这也是后面基本所有程序的步骤了。
程序代码在前面说的编辑器中输入如下代码，gedit会自动上色，比如关键字等，这样也便于编写的过程中发现语法错误。
/*beginner/helloworld/main1.c*/#include &lt;stdio.h&gt;int main(){   printf("Hello, World! \n");     return 0;}
简单的几行，完成了打印Hello World的功能。
代码的含义程序的第一行 #include &lt;stdio.h&gt; 是预处理器指令，告诉 C 编译器在实际编译之前要包含 stdio.h 文件。
下一行 int main() 是主函数，程序从这里开始执行。
下一行 printf(...) 是 C 中另一个可用的函数，会在屏幕上显示消息 "Hello, World!"。
下一行 return 0; 终止 main() 函数，并返回值 0。
编译 &amp; 执行 C 程序$ gcc main.c -o helloworld

执行上述命令后就会生成一个可执行文件helloworld，然后输入
$ ./helloworldHello World!
]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title>C语言 历史</title>
    <url>/2011/01/01/c-beginner-history/</url>
    <content><![CDATA[C语言的历史起源C语言是由Bell实验室的Ken Thompson、Dennis Ritchie等人开发的，刚开始Thompson开发了一个小型的B语言，后来Dennis加入进来，开始着手完善升级B语言，并称为NB语言（果然够N-B），其实是New-B的意思，不过Dennis写着写着，犹如神助，功能越发完善，已经不是NB可以承载的了，所以更名为C语言。
圣经C语言的学习有一本圣经，就是C语言的创建者合写的《The C Programming Language》，虽然现在看起来在C语言标准化以后有些章节有些过时，但是由此引发了一系列的跟随者，比如The C++/C#/XXX Programming Language。
后继者如果评判一件事物是否够千秋万业，只要看看是否可以”前无古人后无来者”即可，或者”前无古人后有继承者”亦可。C语言是后一种，作为一种超级现在的编程语言，C语言影响了后来的很多编程语言，比如C++、Java、C#、Perl等。 
]]></content>
      <categories>
        <category>C</category>
        <category>Program</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>c-beginner</tag>
        <tag>C语言从小白到入门</tag>
      </tags>
  </entry>
  <entry>
    <title>C语言 i++和++i</title>
    <url>/2011/02/04/c-beginner-i++-++i/</url>
    <content><![CDATA[C语言++i和i++的区别​	对于一个如此细节的问题，其实没有很大的必要来讨论，毕竟正儿八经的程序里面，按照前面说的，形成了自己的风格，基本上已经不用太多估计i++和++i的区别了。
​	但是既然聊起这个问题，最简单的区别方法相信很多人已经了然于胸了，那就是：

i++：先用i的值然后再加1      所以a=++i等价于：i=i+1;a=i;
++i：i先加1，然后在用i的值 所以a=i++等价于：a=i;i=i+1;

比如下面的代码：
   int a, b;   int i = 10;int j = 10;   a = i++;   b = ++j;

毋庸置疑，最后的结果是a=10，b=11。这个没有问题，那么下面的这个问题呢：
int i = 10;int j = 10;a = (i++) + (i++) + (i++);b = (++j) + (++j) + (++j);

你是不是也可以立即给出答案呢，但是你确定结果是这样的吗，或许你实际执行了一下，结果在不同的平台竟然不一样，比如：Linux下面得到的结果是a=30,b=37，而MacOSX编译后的结果竟然是：a=33,b=36，同一个代码，竟然有不同的结果，甚至同一个平台不同的编辑器也会有不同的结果，引起这个的原因就是C语言里的副作用，所谓的副作用（side effect）是指对数据对象或文件的修改，而这个修改可能不同的编辑器有不同的顺序，详情且听下回分解。

建议如下，对于这两个的区别，实在是如果能不用到多个++i/i++就不要用，或者等你去参加面试高速面试官这个有多个结果，分别是为何为何，亦或者是你面试别人，出个考题，保证只有一个答案的新手们，妥妥被教育，暂无他用。

举个例子源码如下：
/*beginner/operator/operator4.c*/#include &lt;stdio.h&gt;int main(){    int a, b;    int i = 10, j = 10;    a = i++;    b = ++j;    printf("a : %d\n", a);    printf("b : %d\n", b);    i = 10;    j = 10;    a = (i++) + (i++) + (i++);    b = (++j) + (++j) + (++j);    printf("a : %d\n", a);    printf("b : %d\n", b);    return 0;}

相应地Makefile如下所示：
#beginner/operator/MakefileALL : operator1 operator2 operator3 operator4operator1: operator1.c	gcc -o operator1 operator1.coperator2: operator2.c	gcc -o operator2 operator2.coperator3: operator3.c	gcc -o operator3 operator3.coperator4: operator4.c	gcc -o operator4 operator4.c.PHONY : cleanclean:	rm -f operator1 operator2 operator3 operator4

输入make，然后./operator4输出为：
a : 10b : 11a : xxb : xx
第二个结果给的是xx，因为我目前有多个答案，随你去实验吧，等下次来讲讲为何会有这几个答案。
]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>operator</tag>
        <tag>c-beginner</tag>
        <tag>C语言从小白到入门</tag>
      </tags>
  </entry>
  <entry>
    <title>C语言 if语句</title>
    <url>/2011/02/05/c-beginner-if-sentence/</url>
    <content><![CDATA[C语言的if语句​	C语言里面有一个问题，就是虽然对于逻辑运算符而言，存在真假，不过C语言里面是没有这个概念的，不想Python里面有True和False，对于C而言，非假即为真，也就是如果值不是0，那么就认为是真的。

此处为何非假即为真，而不是非真即为假呢，因为只有0为假，其他均为真

那么什么时候会用到if语句呢，答案是很多时候，但凡开始结构化语句判断就会涉及到，比如：

判断是正数   如示例if1.c

判断成绩：不及格或及格  如示例if2.c

判断年龄段：婴儿、儿童、青少年、成人等， 如示例if3.c


这三种情况从简单到复杂覆盖了if语句的情况。

最简单的就是判断是否真假：

if (true){    //do something}


这里假定定义了true为真，比如#define true 1


第二种情况为判断真假

if (true){    // do something}else{    // do something else}


第三种情况为判断各种情况的真假

if (a){    // a do something}else if (b){    // b do something}else if (c){    // c do something}else{    // do something else}



按照上面的例子，简单举几个例子如下：
/*beginner/if/if1.c*/#include &lt;stdio.h&gt;int main(){    int value = 5;    if (value &gt; 0)        printf("Yes, positive number\n");    return 0;}





/*beginner/if/if2.c*/#include &lt;stdio.h&gt;int main(){    int score = 75;    if (score &lt; 60)        printf("Not passed\n");    else        printf("Passed\n");    return 0;}



/*beginner/if/if3.c*/#include &lt;stdio.h&gt;int main(){    int age = 16;    if (age &lt; 3)        printf("Baby\n");    else if (age &lt; 5)        printf("preschooler\n");    else if (age &lt; 10)        printf("schoolchild\n");    else if (age &lt; 12)        printf("preteen\n");    else if (age &lt; 18)        printf("teenager\n");    else        printf("adult\n");    return 0;}



相应地Makefile如下所示：
#beginner/if/MakefileALL : if1 if2 if3if1 : if1.c	gcc -o if1 if1.cif2 : if2.c	gcc -o if2 if2.cif3 : if3.c	gcc -o if3 if3.c.PHONY : cleanclean:	rm -f if1 if2 if3

输入make，然后./operator4输出为：
$ ./if1Yes, positive number$ ./if2Passed$ ./if3teenager
]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>c-beginner</tag>
        <tag>C语言从小白到入门</tag>
        <tag>if</tag>
      </tags>
  </entry>
  <entry>
    <title>C语言 输入和输出续</title>
    <url>/2011/03/01/c-beginner-io-more/</url>
    <content><![CDATA[C语言 输入和输出续其实在刚开始学习输入输出的时候，第一个接触的可能不一定是printf和scanf函数，还有两个关于字符和字符串的输入输出函数。
下面分别来是说说：
getchar &amp;&amp; putchar从字面意思来看，很容易理解，就是对字符的获取和输出，所以这两个函数你只能输入一个字符，这是限制。
/*beginner/io/io3.c*/#include &lt;stdio.h&gt;int main(){    int c;    printf("Enter a character:");    c = getchar();    printf("You enter :");    putchar(c);    printf("\n");    return 0;}



gets &amp;&amp; puts这两个函数就比较灵活，处理的为字符串，会等待输入的一行文本，只有在输入回车键或者遇到终止符时，才认为是结束了。
/*beginner/io/io4.c*/#include &lt;stdio.h&gt;int main(){    char s[1024];    printf("Enter a string:");    gets(s);    printf("You enter :");    puts(s);    printf("\n");    return 0;}
NB：不过，对于C语言而言，这两个函数能实现的，printf和scanf都可以实现，并且bug少一些，建议尽量少使用今天提到的4个函数，了解即可。
]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>printf</tag>
        <tag>c-beginner</tag>
        <tag>C语言从小白到入门</tag>
        <tag>io</tag>
        <tag>scanf</tag>
        <tag>getchar</tag>
        <tag>putchar</tag>
        <tag>gets</tag>
        <tag>puts</tag>
      </tags>
  </entry>
  <entry>
    <title>C语言 输入和输出</title>
    <url>/2011/03/01/c-beginner-io/</url>
    <content><![CDATA[C语言 输入和输出这次说说C语言的输入和输出，其实从开始的第一个程序，我们已经和C语言的输出打上交道了，对的，就是printf函数，而输入也有提及，就是scanf函数。
而对于用户或者开发者而言，最直观的程序运行的概念就是你输入给程序信息，程序打印输出给你看到。
BINGO，程序正常运行。
这次来详细说说，在C语言或者Linux的世界里面，所有的设备都是文件，所以访问设备就是访问文件，你可以注意到在Linux系统的根目录有一个dev目录，就是设备的交户口所在地。
如何才能交互呢，在C语言里面，在你运行程序的时候，下面的三个默认文件已经同步打开了，这就方便了我们访问键盘，进行输入或者通过屏幕输出信息：



文件
文件指针
对应设备



标准输入
stdin
键盘


标准输出
stdout
屏幕


标准错误
stderr
屏幕


这里在重温一下C语言中用的最广的printf函数和scanf函数：

printf：发送格式化输出到stdout屏幕
scanf：从标准输入stdin读取并格式化转交给程序

参考示例：
/*beginner/io/io1.c*/#include &lt;stdio.h&gt;int main(){    printf("Hello, let's programming using C!!\n");    return 0;}

示例1展示了最简单的输出一句。
/*beginner/io/io2.c*/#include &lt;stdio.h&gt;int main(){    int all_tips = 100;    printf("Enter how many tips you've learned:");    int learned_tips;    scanf("%d", &amp;learned_tips);    printf("Percents %.2f%%\n", 100.0 * learned_tips / all_tips);    return 0;}
示例2展示了输入参数，可以看到我们已经学习了47个tips，如果100个可以完成对C语言的入门，那么恭喜，你已经完成一半了。
]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>printf</tag>
        <tag>c-beginner</tag>
        <tag>C语言从小白到入门</tag>
        <tag>io</tag>
        <tag>scanf</tag>
        <tag>getchar</tag>
        <tag>putchar</tag>
        <tag>gets</tag>
        <tag>puts</tag>
      </tags>
  </entry>
  <entry>
    <title>C语言 关键字</title>
    <url>/2011/02/18/c-beginner-keywords/</url>
    <content><![CDATA[C语言的关键字大全C语言的短小精悍从它的关键字就能够看出来，作为C语言的关键字、保留字，是不能作为变量名、常量名或者其他标识符的，他们有自己独特的含义。
前面的章节中其实多多少少已经进行了讲解，先总结如下：



关键字
说明



auto
声明自动变量


break
跳出当前循环


case
开关语句分支


char
声明字符型变量或函数返回值类型


const
声明只读变量


continue
结束当前循环，开始下一轮循环


default
开关语句中的”其它”分支


do
循环语句的循环体


double
声明双精度浮点型变量或函数返回值类型


else
条件语句否定分支（与 if 连用）


enum
声明枚举类型


extern
声明变量或函数是在其它文件或本文件的其他位置定义


float
声明浮点型变量或函数返回值类型


for
循环语句


goto
无条件跳转语句


if
条件语句


int
声明整型变量或函数


long
声明长整型变量或函数返回值类型


register
声明寄存器变量


return
子程序返回语句（可以带参数，也可不带参数）


short
声明短整型变量或函数


signed
声明有符号类型变量或函数


sizeof
计算数据类型或变量长度（即所占字节数）


static
声明静态变量


struct
声明结构体类型


switch
用于开关语句


typedef
用以给数据类型取别名


unsigned
声明无符号类型变量或函数


union
声明共用体类型


void
声明函数无返回值或无参数，声明无类型指针


volatile
说明变量在程序执行中可被隐含地改变


while
循环语句的循环条件


C99 新增关键字


_Bool
_Complex
_Imaginary
inline
restrict










C11 新增关键字


_Alignas
_Alignof
_Atomic
_Generic
_Noreturn



_Static_assert
_Thread_local





共用体是一种特殊的数据类型，允许您在相同的内存位置存储不同的数据类型。
什么意思呢，就是在同一块内存存储可以定义多个数据类型，但是在使用的时候，只有一个变量有效。
这里就有一个问题，变量有大有小呀，对的，所以这个时候共用体的空间为内部变量最大占用空间的值。
如此这般，共用体就可以通过共享存储空间，来避免当前没有被使用的变量所造成的存储空间的浪费。
共用体的成员可以使用任何数据类型，但是一个共用体所占用的存储空间的字节总数，必须保证至少足以能够容纳其占用空间字节数最大的成员。并且共用体每次只允许访问一个成员，也就是一种数据类型，确保按照正确的数据类型来访问共用体中的数据，就是你的责任了。
先看看union的格式：
union [tag]{   member definition;   member definition;   ...   member definition;} [variables];

其中：

union为类型变量；
tag为共用体的标记；
member definition为变量的定义；

举个例子：
union test{   int i;   float f;   double d;   char  str[20];} data;

通过这个例子可以看到，这个结构体的大小是多少呢？可以通过程序来确认一下。
OK，这次我们来聊聊结构体。
任务来了，我想让你给学生建立一个数据库，该怎么来做。
这个学生包含的信息如下：

ID：也就是学号，唯一区别码，用整型表示
Name：姓名，用字符串表示
Age：年龄，用整型表示
Sex：性别，用字符串表示

按照目前学过的知识我们的代码如下，比如先来一个李雷同学的吧：
#include &lt;stdio.h&gt;#include &lt;string.h&gt; union test{   int i;   float f;   double d;   char  str[20];}; int main( ){   union test data;            printf( "data size : %d\n", sizeof(data));    return 0;}
]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>static</tag>
        <tag>c-beginner</tag>
        <tag>C语言从小白到入门</tag>
        <tag>auto</tag>
        <tag>register</tag>
        <tag>extern</tag>
        <tag>const</tag>
        <tag>enum</tag>
        <tag>for</tag>
        <tag>if</tag>
        <tag>keyword</tag>
        <tag>break</tag>
        <tag>case</tag>
        <tag>char</tag>
        <tag>continue</tag>
        <tag>default</tag>
        <tag>do</tag>
        <tag>double</tag>
        <tag>else</tag>
        <tag>float</tag>
        <tag>goto</tag>
        <tag>int</tag>
        <tag>long</tag>
        <tag>return</tag>
        <tag>short</tag>
        <tag>signed</tag>
        <tag>sizeof</tag>
        <tag>struct</tag>
        <tag>switch</tag>
        <tag>typedef</tag>
        <tag>unsigned</tag>
        <tag>union</tag>
        <tag>void</tag>
        <tag>volatile</tag>
        <tag>while</tag>
      </tags>
  </entry>
  <entry>
    <title>C语言 main函数</title>
    <url>/2011/02/11/c-beginner-main/</url>
    <content><![CDATA[聊聊main函数main字面的意思就是主要的意思，在程序里面也是，并且更重要了，是主函数，何为主函数，就是程序运行会执行的第一个程序，意即程序的入口，如果说眼睛是心灵的窗户，那么main就是程序的大门。
在C99标准之前，main函数可以没有返回类型或者使用void，如下所示：
/*beginner/main/main1.c*/main(){}

或者
/*beginner/main/main2.c*/void main(){}



这两个可以称为最短小精悍的程序了，不会出错，因为没有语句。
如果使用C99标准编译，就可以看到如下的警告信息：
main1.c:3:1: warning: type specifier missing, defaults to 'int' [-Wimplicit-int]main()^1 warning generated.gcc -o main2 main2.cmain2.c:3:1: warning: return type of 'main' is not 'int' [-Wmain-return-type]void main()^main2.c:3:1: note: change return type to 'int'void main()^~~~int1 warning generated.

警告的含义就是我们的mian函数是有血有肉的，是有正儿八经的返回值的，这个返回值的类型就是int，所以这个程序：
/*beginner/main/main3.c*/int main(){}

OK，完美编译，没有任何报错信息，不过终归看着少了点什么，是的，如果定义了返回类型，就需要有相应的返回，所以第一个标准的简单C语言函数如下所示：
/*beginner/main/main4.c*/int main(){    return 0;}

main函数的形式恩，既然写出了main函数的标准形式，这里就需要讨论一个问题，为什么有时候看到int main()，有时候又看到int main(int argc, char *argv[])呢，具体的形式如下所示：
无参数的main函数/*beginner/main/main5.c*/int main(){    printf("Hello World\n");    return 0;}

可以看到上面这个例子，只是打印了hello world，并没有其他语句。
而下面的例子，我们看到使用到了argc和argv，所谓的形参，所以在有需要的时候才会出现这种形式，就好像是黄蓉给郭靖的几个锦囊^_^。
有参数的main函数/*beginner/main/main6.c*/int main(int argc, char *argv[]){    printf("The are %d arguments.\n", argc);    int i;    for (i = 0; i &lt; argc; i++)        printf("%s ", argv[i]);    printf("\n");    return 0;}



编译运行直接输入make就可以了。
#beginner/main/MakefileALL : main1 main2 main3 main4 main5 main6main1: main1.c	gcc -o main1 main1.cmain2: main2.c	gcc -o main2 main2.cmain3: main3.c	gcc -o main3 main3.cmain4: main4.c	gcc -o main4 main4.cmain5: main5.c	gcc -o main5 main5.cmain6: main6.c	gcc -o main6 main6.c.PHONY : cleanclean:	rm -f main1 main2 main3 main4 main5 main6

]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>argc</tag>
        <tag>argv</tag>
        <tag>c-beginner</tag>
        <tag>C语言从小白到入门</tag>
      </tags>
  </entry>
  <entry>
    <title>C语言 测试等值运算符</title>
    <url>/2011/01/30/c-beginner-operator-step2/</url>
    <content><![CDATA[C语言的等值运算符​	其实对于大概有40个运算符的C语言而言，记住这些不是很难得的事情，如果觉得比较困难倒是可以考虑在使用中来记忆，不需要先搞清楚到底什么意思，先用起来，再来八一八具体含义。
​	比如用来测试等值的运算符，用着用着就会了，如下：

==运算符，表示等于
!=运算符，表示不等于
&gt;运算符，表示大于
&lt;运算符，表示小于
&gt;=运算符，表示大于等于
&lt;=运算符，表示小于等于

需要注意的是：

C语言中的等于不是=，而是==
C语言中的等于不是=，而是==
C语言中的等于不是=，而是==


重要的事情说三遍

含义比较简单，如果满足条件就会返回真，在C语言里面就是非零的值。
举个例子源码如下：
/*beginner/operator/operator2.c*/#include &lt;stdio.h&gt;int main(){    int a = 5;    int b = 3;    printf("%d == %d : %d\n", a, b, (a == b));    printf("%d != %d : %d\n", a, b, (a != b));    printf("%d &gt;  %d : %d\n", a, b, (a &gt; b));    printf("%d &lt;  %d : %d\n", a, b, (a &lt; b));    printf("%d &gt;= %d : %d\n", a, b, (a &gt;= b));    printf("%d &lt;= %d : %d\n", a, b, (a &lt;= b));    return 0;}



输出为：
5 == 3 : 05 != 3 : 15 &gt;  3 : 15 &lt;  3 : 05 &gt;= 3 : 15 &lt;= 3 : 0
结果看到5 &gt; 3的结果为1，也就是真。其余类推
]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>operator</tag>
        <tag>c-beginner</tag>
        <tag>C语言从小白到入门</tag>
      </tags>
  </entry>
  <entry>
    <title>C语言 加减乘除运算符</title>
    <url>/2011/01/29/c-beginner-operator-step1/</url>
    <content><![CDATA[C语言的加减乘除运算符​	知道了如何定义变量，下一步就要做的就是计算了，相信学习C语言变量后，接下来就是要研究一下如何把C语言当做计算器了，虽然Linux下面是有很多计算器的，不过如果自己能写一个，岂不更好。
​	与数学里面的一样，程序语言是为了解决这些实际问题而产生的，所以肯定是具有这些功能的。比如这次说的7个运算符：

+运算符，表示加
-运算符，表示减
*运算符，表示乘
/运算符，表示除
%运算符，表示取余
++运算符，表示自加
--运算符，表示自减

需要注意的是：
4的除，如果是整数相除，那么结果还是整数，也就是只有整数位，小数位直接省略，比如5/3=1.666667，结果即为1；
5的取余，表示两者相除后余量，比如5%3，那么取余结果就是2；
6和7的自加与自减比较有趣，后面会有专门的一节来说道说道，可以理解为a++的含义就是a=a+1，即把a+1的值再赋值给a，完成自加操作，自减类似。
举个例子源码如下：
/*beginner/operator/operator.c*/#include &lt;stdio.h&gt;int main(){    int a = 5;    int b = 3;    printf("%d + %d = %d\n", a, b, (a + b));    printf("%d - %d = %d\n", a, b, (a - b));    printf("%d * %d = %d\n", a, b, (a * b));    printf("%d / %d = %d\n", a, b, (a / b));    printf("%d %% %d = %d\n", a, b, (a % b));    printf("a  = %d\n", a);    printf("a++= %d\n", (a++));    printf("a  = %d\n", a);    printf("b  = %d\n", b);    printf("b--= %d\n", (b--));    printf("b  = %d\n", b);    return 0;}



输出为：
5 + 3 = 85 - 3 = 25 * 3 = 155 / 3 = 15 % 3 = 2a  = 5a++= 5a  = 6b  = 3b--= 3b  = 2
]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>operator</tag>
        <tag>c-beginner</tag>
        <tag>C语言从小白到入门</tag>
      </tags>
  </entry>
  <entry>
    <title>C语言 逻辑运算符</title>
    <url>/2011/01/31/c-beginner-operator-step3/</url>
    <content><![CDATA[C语言的逻辑运算符​	对于逻辑运算符而言，含义比较清楚，就是用来逻辑测试的，比较特殊难懂的三元运算符，英文叫做logical ternary，也成为条件运算符，可以定义一些宏来完成简单且强大的功能，这个需要在进阶篇里面看到详细的含义，简单的理解就是：a?b:c，如果a为真就返回b，如果a为假就返回c。
​	几个逻辑运算符的含义如下：



逻辑运算符
含义



&amp;&amp;
逻辑与


||
逻辑或


!
逻辑非


?=
条件运算符


逻辑运算符的返回非真即假，也就是不是返回0就是返回1了，示例如下：
举个例子源码如下：
/*beginner/operator/operator3.c*/#include &lt;stdio.h&gt;int main(){    int a = 5; //0x101    int b = 3; //0x011    printf("%d &amp;&amp; %d : %d\n", a, b, (a &amp;&amp; b));    printf("%d || %d : %d\n", a, b, (a || b));    printf("!%d     : %d\n", a, !a);    printf("%d and %d: %d is bigger\n",a,b,(a&gt;b?a:b));    return 0;}

相应地Makefile如下所示：
#beginner/operator/MakefileALL : operator1 operator2 operator3operator1: operator1.c	gcc -o operator1 operator1.coperator2: operator2.c	gcc -o operator2 operator2.coperator3: operator3.c	gcc -o operator3 operator3.c.PHONY : cleanclean:	rm -f operator1 operator2 operator3


我们可以看到，这一次的Makefile我们多了一个.PHONY行，这是一个伪目标，主要作用是防止Makefile定义的可执行命令的目标跟工作目录里面的文件重名而出现无法运行的问题，在这也提高了执行时的效率，建议每个Makefile都要包含。

输入make，然后./operator3输出为：
5 &amp;&amp; 3 : 15 || 3 : 1!5     : 05 and 3: 5 is bigger
结果看到5 &gt; 3的结果为1，也就是真。其余类推
]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>operator</tag>
        <tag>c-beginner</tag>
        <tag>C语言从小白到入门</tag>
      </tags>
  </entry>
  <entry>
    <title>C语言 最适合学习C语言的开发环境</title>
    <url>/2011/01/24/c-beginner-prepare-work/</url>
    <content><![CDATA[最适合学习C语言的开发环境感觉编程从一开始走的路子就不对。大学的时候老师醉心于调bug，Windows上用着Borland公司的Turbo C，无法自拔，经常自言自语，留下一脸懵逼的学生们。这个时候Linux已经发展的如火如荼并发布了稳定版的2.6版本的内核，Ubuntu横空出世。
研究生的时候老师醉心于编写界面，拿着Visual C++动辄自动生成的上万行代码来一步一步的来查找bug，编写界面。
正式工作后工作环境完全转移到Linux，正式开始真正意义上的编程。
如何开始编程，最简单的开始就是搭建开发环境了，这里一定要指出，一定使用类Unix系统，一定使用类Unix系统，一定使用类Unix系统，重要的话说3遍。
当然Windows系统可以使用Oracle公司的开源虚拟机VirtualBox来搞定或者使用Cygwin来搞定。
我的开发环境是Fedora 6，给个界面看看

如果使用其他的系统，开发环境可以通过下面的命令来准备
LinuxDebian系Debain系列为基于Debian开发的发行版，比如著名的Ubuntu，只需要打开终端输入下列命令即可：
$ sudo apt-get install build-essential

此时输入Y同意，即可安装相关的环境。
流行度很广的Ubuntu10.04系统

Redhat系Redhat系列为基于Redhat开发的发行版，比如著名的CentOS和Fedora，只需要打开终端输入下列命令即可：
$ sudo yum groupinstall "Development Tools"



MacOSXMacOSX号称最好用最稳定的系统，俺还没有这个平台，不过据说只要安装上Xcode，基本上就具备开发环境了。土豪们可以试一试了。
{width=30%}
WindowsCygwin是一个在windows平台上运行的类UNIX模拟环境，是cygnus solutions公司开发的自由软件，只要下载一下安装包，然后安装选定需要的开发环境即可，搜索一下就有很多的教程，此处不在阐述，这里还是推荐，在机器性能比较好的情况下，还是使用VirtualBox来个全功能版本的Linux吧。
]]></content>
      <categories>
        <category>C</category>
        <category>Program</category>
        <category>Linux</category>
        <category>Windows</category>
        <category>MacOSX</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>c-beginner</tag>
        <tag>C语言从小白到入门</tag>
        <tag>linux</tag>
        <tag>editor</tag>
      </tags>
  </entry>
  <entry>
    <title>C语言 指针初探</title>
    <url>/2011/02/27/c-beginner-pointer/</url>
    <content><![CDATA[C语言 指针初探指针是C语言中最有趣的概念，简洁、优美、快速、复杂、难懂，所以有一本书叫做《C和指针》，足见其强悍之处。
C语言指针一般设计到动态内存分配等高级概念，要想成为一个高手，必须要掌握指针，本节，只需要了解一个概念即可。
即指针是一个变量，指针的值是另外一个变量的地址，可以认为指针指向你这个值的时候，代表的是你家的地址。
看一个例子如下：
/*beginner/pointer/pointer1.c*/#include &lt;stdio.h&gt;int main(){    char a = 'a';    int b = 1;    float c = 3.1415926;    double d = 3.1415926;    printf("The address of a is %p\n", &amp;a);    printf("The address of b is %p\n", &amp;b);    printf("The address of c is %p\n", &amp;c);    printf("The address of d is %p\n", &amp;d);    return 0;}



$ ./pointer1The address of a is 0x7ffee3e5272bThe address of b is 0x7ffee3e52724The address of c is 0x7ffee3e52720The address of d is 0x7ffee3e52718

可以看到变量没有规则，但是出来的地址是有顺序的，按照一定的规则增加或减少。
指针规则看一下如何使用指针，规则如下：
type * var-name;


type：是指针的基本类型
var-name：为指针的名字

其中type可以是我们前面说过的所有变量类型，比如int、double、float、char等。
比如：
int *pi;float *pf;double *pd;char *pc;

]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>c-beginner</tag>
        <tag>C语言从小白到入门</tag>
        <tag>point</tag>
      </tags>
  </entry>
  <entry>
    <title>C语言 赏心悦目的输出</title>
    <url>/2011/01/28/c-beginner-print/</url>
    <content><![CDATA[赏心悦目的C语言输出C语言的输出功能，超出你的想象，你能想到的，她基本也能做到。
刚开始还只是照抄printf语句，老是出现下面的情况：
Hello World% $



后面才晓得printf函数是有特殊规定字符的，比如换行的\n，换页的\f，回车的\r，以及制表符\t等。
这次就说说是个什么意思以及如何使用。
本节尽量只使用printf函数，除非 有必要，尽量简洁，然后举几个用的最广的例子。
换行显示文本printf要完成的功能就是显示文本，比如最简单的：
/*beginner/print/print1.c*/#include &lt;stdio.h&gt;int main(){    printf("Hello World\n");    return 0;}

比如我们想打印一首诗，原文是
Hickory, dickory, dock,The mouse ran up the clock.The clock struck one,The mouse ran down,Hickory, dickory, dock.

这个简单呀，直接输入下面的代码
/*beginner/print/print2.c*/#include &lt;stdio.h&gt;int main(){    printf("Hickory, dickory, dock,");    printf("The mouse ran up the clock.");    printf("The clock struck one,");    printf("The mouse ran down,");    printf("Hickory, dickory, dock.");    return 0;}



输出是什么的
Hickory, dickory, dock,The mouse ran up the clock.The clock struck one,The mouse ran down,Hickory, dickory, dock.%  

😳，这就是没有添加换行符的原因，加上以后如下所示：
/*beginner/print/print3.c*/#include &lt;stdio.h&gt;int main(){    printf("Hickory, dickory, dock,\n");    printf("The mouse ran up the clock.\n");    printf("The clock struck one,\n");    printf("The mouse ran down,\n");    printf("Hickory, dickory, dock.\n");    return 0;}

优雅的输出如下所示：
Hickory, dickory, dock,The mouse ran up the clock.The clock struck one,The mouse ran down,Hickory, dickory, dock.

回车显示进度条效果其实回车的意思并不是通俗意义上的回车，你敲下键盘，叫做Enter，是另外一种回车。
这里的回车是不换行从头开始的意思，是ASCII码为13的特殊字符，换行是ASCII码为10的特殊字符。
这个示例只能通过自己编译来使用了，代码简单，如下，就能看到进度条的效果了
/*beginner/print/print4.c*/#include &lt;stdio.h&gt;#include &lt;unistd.h&gt;int main(){    printf("*          \r");    fflush(stdout);    sleep(1);    printf("*****        \r");    fflush(stdout);    sleep(1);    printf("*******       \r");    fflush(stdout);    sleep(1);    printf("*********      \r");    fflush(stdout);    sleep(1);    printf("*************    \r");    fflush(stdout);    sleep(1);    printf("*****************  \r");    fflush(stdout);    sleep(1);    printf("*********************\r");    fflush(stdout);    sleep(1);    printf("\n\n");    return 0;}

运行的时候，可以看到光标在移动，这个用法我是学了2个多月才知道，悲哉！

说明：fflush是用来强行刷新的，因为如果不刷新，有的时候无法显示，另外sleep是为了演示移动效果，不然毫秒级显示完成，就看不到效果了。

优雅的对齐特性其实想对齐，是比较简单的一件事情，直接空格多敲一些就行了，如下所示：
/*beginner/print/print5.c*/#include &lt;stdio.h&gt;#include &lt;unistd.h&gt;int main(){    printf("Name      Age ID\n");    printf("Zhang San 16  1\n");    printf("Li Si     17  2\n");    printf("Wang Wu   18  3\n");    return 0;}

输入为：
Name      Age IDZhang San 16  1Li Si     17  2Wang Wu   18  3

但是，如果在我们不知道数字是多少，字符串是多少的时候怎么来做呢，就是制表符的效果了。
很简单，只要在需要分割的地方加上就可以了：
/*beginner/print/print6.c*/#include &lt;stdio.h&gt;#include &lt;unistd.h&gt;int main(){    printf("Name     \tAge\tID\n");    printf("Zhang San\t16\t1\n");    printf("Li Si    \t17\t2\n");    printf("Wang Wu  \t18\t3\n");    return 0;}

输入为：
Name     	Age	IDZhang San	16	1Li Si    	17	2Wang Wu  	18	3





集大成这里三个都演示下，可以通过./print_all来查看效果。
###################The demo of \n###################          *                  *****               *******                 *                  *****               *******             *********                *                  *****               *******             *********          *************      *****************  *********************        *****                *****                *****                *****                *****                *****        ******************************************###################The demo of \r###################*********************###################The demo of \t###################Name     	Age	IDZhang San	16	1Li Si    	17	2Wang Wu  	18	3



编译运行还是跟前面的hello world 一致，这次还是包含两类文件，一个是源码文件print.c，另外一个就是Makefile了。
Makefile如下所示，比上一个稍微复杂了些，其实不难理解，可以搜索Makefile帮助查看信息。
#beginner/print/MakefileALL : print1 print2 print3 print4 print5 print6 print_allprint1: print1.c	gcc -o print1 print1.cprint2: print2.c	gcc -o print2 print2.cprint3: print3.c	gcc -o print3 print3.cprint4: print4.c	gcc -o print4 print4.cprint5: print5.c	gcc -o print5 print5.cprint6: print6.c	gcc -o print6 print6.cprint_all: print_all.c	gcc -o print_all print_all.c
运行只需要输入make，然后./print就可以看到相关的输出了。
备注1．转换说明符



转换
说明



%a(%A)
浮点数、十六进制数字和p-(P-)记数法(C99)


%c
字符


%d
有符号十进制整数


%f
浮点数(包括float和doulbe)


%e(%E)
浮点数指数输出[e-(E-)记数法]


%g(%G)
浮点数不显无意义的零”0”


%i
有符号十进制整数(与%d相同)


%u
无符号十进制整数


%o
八进制整数  e.g.   0123


%x(%X)
十六进制整数   e.g.  0x1234


%p
指针


%s
字符串


%%
“%”


​        
2．标志   左对齐：”-“  e.g.  “%-20s”   右对齐：”+” e.g.  “%+20s”   空格：若符号为正，则显示空格，负则显示”-“  e.g.  “% “   #：对c,s,d,u类无影响；对o类，在输出时加前缀o；对x类，在输出时加前缀0x；      对e,g,f 类当结果有小数时才给出小数点。
3．格式字符串（格式）   ［标志］［输出最少宽度］［．精度］［长度］类型   “％-md” ：左对齐，若m比实际少时，按实际输出。   “%m.ns”：输出m位，取字符串(左起)n位，左补空格，当n&gt;m or m省略时m=n           e.g.  “%7.2s”  输入CHINA                 　      输出”   CH”   “%m.nf”：输出浮点数，m为宽度，n为小数点右边数位           e.g.  “%”  输入3852.99                        输出3853.0   长度：为ｈ短整形量,ｌ为长整形量
printf的格式控制的完整格式：% - .n l或h 格式字符下面对组成格式说明的各项加以说明：①%：表示格式说明的起始符号，不可缺少。②-：有-表示左对齐输出，如省略表示右对齐输出。③0：有0表示指定空位填0,如省略表示指定空位不填。④m.n：m指域宽，即对应的输出项在输出设备上所占的字符数。N指精度。用于说明输出的实型数的小数位数。为指定n时，隐含的精度为n=6位。⑤l或h:l对整型指long型，对实型指double型。h用于将整型的格式字符修正为short型。
一个h表示short，即short int两个h表示short short，即 char。%hhx用于输出char%hx用于输出short int.





－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－格式字符格式字符用以指定输出项的数据类型和输出格式。①d格式：用来输出十进制整数。有以下几种用法：%d：按整型数据的实际长度输出。%md：m为指定的输出字段的宽度。如果数据的位数小于m，则左端补以空格，若大于m，则按实际位数输出。%ld：输出长整型数据。②o格式：以无符号八进制形式输出整数。对长整型可以用”%lo”格式输出。同样也可以指定字段宽度用“%mo”格式输出。例：  main()  { int a = -1;   printf(“%d, %o”, a, a);  }运行结果：-1,177777程序解析：-1在内存单元中（以补码形式存放）为(1111111111111111)2，转换为八进制数为(177777)8。③x格式：以无符号十六进制形式输出整数。对长整型可以用”%lx”格式输出。同样也可以指定字段宽度用”%mx”格式输出。④u格式：以无符号十进制形式输出整数。对长整型可以用”%lu”格式输出。同样也可以指定字段宽度用“%mu”格式输出。⑤c格式：输出一个字符。⑥s格式：用来输出一个串。有几中用法%s：例如:printf(“%s”, “CHINA”)输出”CHINA”字符串（不包括双引号）。%ms：输出的字符串占m列，如字符串本身长度大于m，则突破获m的限制,将字符串全部输出。若串长小于m，则左补空格。%-ms：如果串长小于m，则在m列范围内，字符串向左靠，右补空格。%m.ns：输出占m列，但只取字符串中左端n个字符。这n个字符输出在m列的右侧，左补空格。%-m.ns：其中m、n含义同上，n个字符输出在m列范围的左侧，右补空格。如果n&gt;m，则自动取n值，即保证n个字符正常输出。⑦f格式：用来输出实数（包括单、双精度），以小数形式输出。有以下几种用法：%f：不指定宽度，整数部分全部输出并输出6位小数。%m.nf：输出共占m列，其中有n位小数，如数值宽度小于m左端补空格。%-m.nf：输出共占n列，其中有n位小数，如数值宽度小于m右端补空格。⑧e格式：以指数形式输出实数。可用以下形式：%e：数字部分（又称尾数）输出6位小数，指数部分占5位或4位。%m.ne和%-m.ne：m、n和”-”字符含义与前相同。此处n指数据的数字部分的小数位数，m表示整个输出数据所占的宽度。⑨g格式：自动选f格式或e格式中较短的一种输出，且不输出无意义的零。
－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－关于printf函数的进一步说明：如果想输出字符”%”,则应该在“格式控制”字符串中用连续两个%表示，如:printf(“%f%%”, 1.0/3);输出0.333333%。
－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－对于单精度数，使用%f格式符输出时，仅前7位是有效数字，小数6位．对于双精度数，使用%lf格式符输出时，前16位是有效数字，小数6位．
######################################拾遗 ########################################由高手指点对于m.n的格式还可以用如下方法表示（例）char ch[20];printf(“%*.s\n”,m,n,ch);前边的定义的是总的宽度，后边的定义的是输出的个数。分别对应外面的参数m和n 。我想这种方法的好处是可以在语句之外对参数m和n赋值，从而控制输出格式。-——————————————————————————-今天()又看到一种输出格式 %n 可以将所输出字符串的长度值赋绐一个变量, 见下例:
int slen;
printf(“hello world%n”, &amp;slen);
执行后变量被赋值为11
另外：
1、格式输出函数的一般形式
   函数原型： int printf(char * format[,argument,…]);
   函数功能：按规定格式向输出设备（一般为显示器）输出数据，并返回实际输出的字符数，若出错，则返回负数。
   它使用的一般形式为：
​        printf(“格式控制字符串”,输出项列表);
   语句中“输出项列表”列出要输出的表达式（如常量、变量、运算符表达式、函数返回值等），它可以是0个、一个或多个，每个输出项之间用逗号（,）分隔。输出的数据可以是整数、实数、字符和字符串。
   “格式控制字符串”必须用英文的双引号括起来，它的作用是 控制输出项的格式和输出一些提示信息，例如
​          int i=97; printf(“i=%d,%c\n”,i,i);
​        输出结果为：i=97,a
​    语句“printf(“i=%d,%c\n”,i,i);”中的两个输出项都是变量i，但却以不同的格式输出，一个输出整型数97，另一个输出的却是字符a，其格式分别由“%d”与“%c”来控制。
​    语句“printf(“i=%d,%c\n”,i,i);”的格式控制字符串中“i=”是普通字符，他将照原样输出；“%d”与“%c”是格式控制符；”\n”是转义字符，它的作用是换行。
2、格式控制
   格式控制由格式控制字符串实现。格式控制字符串由3部分组成：普通字符、转义字符、输出项格式说明。
   （1）普通字符。普通字符在输出时，按原样输出，主要用于输出提示信息。
   （2）转义字符。转义字符指明特定的操作，如”\n”表示换行，”\t”表示水平制表等。
   （3）格式说明部分由“%”和“格式字符串”组成，他表示按规定的格式输出数据。
​     格式说明的形式为：****
​        %[flags][width][.prec][F|N|h|I][type]
​     各部分说明如下：

“[]”表示该项为可选项，即可有可无，如 printf(“%d”,100);
flags为可选择的标志字符，常用的标志字符有：
-  ——左对齐输出，默认为右对齐输出；
+  ——正数输出加号(+)，负数输出减号(-);
空格 ——正数输出空格代替加号(+)，负数输出减号(-)。


width为可选择的宽度指示符。
用十进制正整数表示设置输出值得最少字符个数。不足则补空格，多出则按实际输出，默认按实际输出，例如：
printf(“%8d\n”,100);    printf(“%6d\n”,100);    printf(“%-8d\n”,100);    printf(“%+8\n”,100);
输出结果为：└┘└┘└┘└┘└┘100└┘└┘└┘100     100└┘└┘└┘└┘└┘   └┘└┘└┘└┘+100


[.prec]为可选的精度指示符
用“小数点”加“十进制正整数”表示，对“整数”、“实数”和“字符串”的输出有如下功能：对“整数”，表示至少要输出的数字个数，不足补数字0，多则原样输出；对“实数”，表示小数点后至多输出的数字个数，不足则补数字0，多则做舍入处理；对“字符串”，表示最多输出的字符个数，不足补空格，多则丢弃。
例如：printf(“%8.2f\n”,3.14159);printf(“%8.5f\n”,3.14159);
输出结果为：└┘└┘└┘└┘3.14└┘3.14159


[F|N|h|I]为可选的输出长度修饰符，其功能如下：
F ——输出远指针存放的地址；
N——输出近指针存放的地址；
h——输出短整型数据的值；
l——输出长整型或双精度型数据的值。
例如：long n=40000;
​      printf(“%8ld\n”,n);/因为200200是长整型数据*/


type为可选的格式字符，用来进行格式转换。

]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>printf</tag>
        <tag>c-beginner</tag>
        <tag>C语言从小白到入门</tag>
      </tags>
  </entry>
  <entry>
    <title>C语言编程开发步骤</title>
    <url>/2003/09/22/c-beginner-program-steps/</url>
    <content><![CDATA[C语言编程C语言是一种很强悍和紧凑的语言，你写程序，让计算机执行即可。
创建C程序创建C程序一共有4步：

编辑；使用vi、emacs或者IDE，Linux下面新手首推gedit，高手首推Vim
编译链接  ​     gcc –o app myprogram.c
执行./app

]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>c-beginner</tag>
        <tag>C语言从小白到入门</tag>
      </tags>
  </entry>
  <entry>
    <title>C语言 终端输入scanf函数</title>
    <url>/2011/02/09/c-beginner-scanf/</url>
    <content><![CDATA[C语言键盘输入采集scanf函数前面说过C语言的额printf函数，那么这一次说说scanf函数。
这两个函数像两兄弟，比如在C++里面经常遇到set和get，就差不到就是scanf和printf的意思，printf用来通过终端输出一些内容，scanf用来通过终端输入一些内容。
先看看这个函数的原型：
# include &lt;stdio.h&gt;int scanf(const char *format, ...);

哇哦，这么多没有见过的，貌似不懂什么意思，没问题，一步一步来理解。
先来个好理解的，这个函数的意思就是：
scanf("输入控制符", 输入参数);

就是将键盘输入的参数转换为输入控制符规定格式的数据，然后保存到输入参数地址所表示的变量里面。
举个简单的例子：
int i;scanf("%d", &amp;i);

这个小段的意思就是输入一个数字，把这个数字作为传入参数赋值给变量i。

这个有个问题需要特别注意，就是&amp;i的使用，很多人刚开始都会只输入i，实际需要传入的是一个地址，特别留意。

来个简单的小例子：
/*beginner/scanf/scanf1.c*/#include &lt;stdio.h&gt;int main(void){    int i;    i = 1314;    printf("i = %d\n", i);    return 0;}

这个我们最开始编写的程序，如果需要打印一个我们需要的，就要每次修改源码，然后再编译运行，比如刚开始我们要一生一世1314，后来一想不对呀，要生生世世3344方显诚心吗，改过来，如此这般。
但是如果碰到一个变化不断的数字怎么办，比如让你说如N个学生的成绩，用来判断是否达到老师的期望，这个时候再改源码就不合适了，怎么办呢，就需要使用scanf函数了，如下所示：
/*beginner/scanf/scanf2.c*/#include &lt;stdio.h&gt;int main(void){    int i;    scanf("%d", &amp;i);    printf("i = %d\n", i);    return 0;}

不错，已经每次可以通过终端输入打印出来不同的值了。
但是最后有个提示对不对，好的，大部分人会这么写，但是就会出现各种各样的问题：
/*beginner/scanf/scanf3.c*/#include &lt;stdio.h&gt;int main(void){    int i;    scanf("please input i %d", &amp;i);    printf("i = %d\n", i);    return 0;}

正确的写法是怎么样的呢，如下：
/*beginner/scanf/scanf4.c*/#include &lt;stdio.h&gt;int main(void){    int i;    printf("please input i :");    scanf("%d", &amp;i);    printf("i = %d\n", i);    return 0;}

看到区别了吗，区别就是把要显示的东西还是使用printf来，只有最简单的输入用scanf来，其实用scanf也是可以的，如果按照scanf3的代码来，你需要在终端中输入的语句是：please input i 1314，这样才能满足你的需求，但显然这不符合你的初衷，对吧。
所以这也说明了另一个问题，那就是scanf的格式与输入需要保持严格一致。
编译运行直接输入make就可以了。
#beginner/scanf/MakefileALL : scanf1 scanf2scanf1: scanf1.c	gcc -o scanf1 scanf1.cscanf2: scanf2.c	gcc -o scanf2 scanf2.cscanf3: scanf3.c	gcc -o scanf3 scanf3.cscanf4: scanf4.c	gcc -o scanf4 scanf4.c.PHONY : cleanclean:	rm -f scanf1 scanf2 scanf3 scanf4
运行自行琢磨。
]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>c-beginner</tag>
        <tag>C语言从小白到入门</tag>
        <tag>scanf</tag>
      </tags>
  </entry>
  <entry>
    <title>C语言 作用域</title>
    <url>/2011/02/23/c-beginner-scope/</url>
    <content><![CDATA[C语言的作用域任何一种编程语言，都会存在作用域的概念，比如C++中的private、public等，在C语言里面，主要根据变量所在的位置来区分，主要有：

局部变量
全局变量

局部变量所谓的局部变量就是只能被局部访问，一般定义在函数内部或者某个块，在函数的外部是不可知且不能被访问的，比如下面的变量：
/*beginner/scope/scope1.c*/#include &lt;stdio.h&gt;int main(){    int a = 1;    int b = 3;    int c = 5;    printf("a is %d\n", a);    printf("b is %d\n", b);    printf("c is %d\n", c);    return 0;}

其中的变量a、b、c，也就是1、3、5就是main函数的局部变量。
全局变量全局变量按照字母意思就是在整个程序的声明周期都存在，也就是说所有的函数都可以访问到，一般而言，都会位于函数的外面，通常在程序的顶部，比如：
/*beginner/scope/scope2.c*/#include &lt;stdio.h&gt;int g = 7;int main(){    int a = 1;    int b = 3;    int c = 5;    printf("a is %d\n", a);    printf("b is %d\n", b);    printf("c is %d\n", c);    printf("g is %d\n", g);    g = 9;    printf("g is %d\n", g);    return 0;}

访问顺序那么问题就来了，万一全部变量和局部变量定义了相同给的名字，该访问使用哪一个呢，这个记住即可，如果两个名字相同，会使用局部变量，临近原则吧。
/*beginner/scope/scope3.c*/#include &lt;stdio.h&gt;int g = 7;int main(){    int a = 1;    int b = 3;    int c = 5;    printf("a is %d\n", a);    printf("b is %d\n", b);    printf("c is %d\n", c);    printf("g is %d\n", g);    int g = 3;    printf("g is %d\n", g);    return 0;}



编译编译也有所不同，方法为：
#beginner/scope/MakefileALL : scope1  scope2 scope3scope1: scope1.c	gcc -o scope1 scope1.cscope2: scope2.c	gcc -o scope2 scope2.cscope3: scope3.c	gcc -o scope3 scope3.c.PHONY : cleanclean:	rm -f scope1 scope2 scope3

这会产生可执行程序，当程序被执行时，它会产生下列结果：
$ ./scope1a is 1b is 3c is 5$ ./scope2a is 1b is 3c is 5g is 7g is 9$ ./scope3a is 1b is 3c is 5g is 7g is 3

]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>c-beginner</tag>
        <tag>C语言从小白到入门</tag>
        <tag>local</tag>
        <tag>global</tag>
      </tags>
  </entry>
  <entry>
    <title>C语言 &quot;Hello&quot;和 &#39;H&#39;,&#39;e&#39;,&#39;l&#39;,&#39;l&#39;,&#39;o&#39;的区别</title>
    <url>/2011/02/15/c-beginner-string/</url>
    <content><![CDATA[C语言的字符串何为字符串，就是将字符串起来，哈哈，跟羊肉串一样。
这次说说早就应该介绍的字符串，其实字符串主要坑比较多，刚开始用还没啥，越用越心虚。
那咱们就从不心虚的地方说起吧。
来个官方定义：

字符串实际上是使用 null 字符 ‘\0’ 终止的一维字符数组。所以一个以 null 结尾的字符串，包含了组成该字符串的字符。

是个什么意思呢，来看个实例了解下。
比如我们声明和初始化创建了一个 “Hello” 字符串。
char greeting[6] = {'H', 'e', 'l', 'l', 'o', '\0'};

这里就有疑问了，本着勤俭节约的精神，吃饭不要铺张浪费，吃饱吃好就行，不耍排场。这里也应该这样呀，你的Hello只有5个字符，为什么要用6个字符数组？？？
这是字符串的第一个坑，建议的解决方法是尽可能比你需要的大一些字符，在目前内存与房价齐飞的阶段，不多你几个字符，原因如下：

由于在数组的末尾存储了空字符，所以字符数组的大小比单词 “Hello” 的字符数多一个。

还有一个疑问就是，这样写字符串也太-太-太啰嗦了吧，是的，所以另外一种的使用方法为：
char greeting[] = "Hello";

整齐划一有内涵。
这两个值倒是在内存里面如何存储呢，我们来个表格看看：



下标
0
1
2
3
4
5



变量
H
e
l
l
o
\0


看到没有，最后一位就是null，即\0。
看个简单的代码：
/*beginner/string/string1.c*/#include &lt;stdio.h&gt;int main(){    char s1[6] = "Hello";    char s2[6] = {'H', 'e', 'l', 'l', 'o'};    printf("s1 is %s\n", s1);    printf("s2 is %s\n", s2);    return 0;}



编译运行直接输入make就可以了。
#beginner/string/MakefileALL : string1 string1: string1.c	gcc -o string1 string1.c.PHONY : cleanclean:	rm -f string1 

运行输出如下：$ ./string1s1 is Hellos2 is Hello
]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>string</tag>
        <tag>c-beginner</tag>
        <tag>C语言从小白到入门</tag>
      </tags>
  </entry>
  <entry>
    <title>C语言 访问struct的方式</title>
    <url>/2011/02/15/c-beginner-struct-access/</url>
    <content><![CDATA[C语言的结构体访问方式本学期来了一个新学生，名字叫魏华，在上一个程序的基础上，我们使用指向结构的指针来访问试试看。
先看代码：
/*beginner/struct/struct4.c*/#include &lt;stdio.h&gt;int main(){    struct Student    {        int id;        char name[15];        int age;        char sex[10];    };    struct Student lilei = {1, "Li Lei", 18, "male"};    struct Student hanmeimei = {2, "Han Meimei", 17, "female"};    struct Student weihua1 = {3, "Wei Hua", 18, "male"};    struct Student *weihua = &amp;weihua1;     printf("The student information :\n");    printf("ID \t | Name \t| Age\t| Sex \n");    printf("%d \t | %s \t| %d \t| %s \n", lilei.id, lilei.name, lilei.age, lilei.sex);    printf("%d \t | %s \t| %d \t| %s \n", hanmeimei.id, hanmeimei.name, hanmeimei.age, hanmeimei.sex);    printf("%d \t | %s \t| %d \t| %s \n", weihua-&gt;id, weihua-&gt;name, weihua-&gt;age, weihua-&gt;sex);    return 0;}

可以看到与上一个程序的区别就是如下的代码段：
struct Student weihua1 = {3, "Wei Hua", 18, "male"};struct Student *weihua = &amp;weihua1; printf("%d \t | %s \t| %d \t| %s \n", weihua-&gt;id, weihua-&gt;name, weihua-&gt;age, weihua-&gt;sex);

这里说一下另立独行，希望引起注意的魏华同学，先定义了weihua1这个结构体，然后定义了一个执行该结构的指针，你应该还记得&amp;是什么意思，对的，是取指针地址的意思。
另外需要注意的是，在原来定义结构体变量的时候，访问方式为.，但是在更改为指针后，访问方式为-&gt;。
这个记住就好了，如果不记得，在编译的时候看一下报错信息。
编译运行直接输入make就可以了。
#beginner/struct/MakefileALL : struct1 struct2 struct3 struct4struct1: struct1.c	gcc -o struct1 struct1.cstruct2: struct2.c	gcc -o struct2 struct2.cstruct3: struct3.c	gcc -o struct3 struct3.cstruct4: struct4.c	gcc -o struct4 struct4.c.PHONY : cleanclean:	rm -f struct1 struct2 struct3  struct4

运行输出如下：$ ./struct4The student information :ID       | Name         | Age   | Sex1        | Li Lei       | 18    | male2        | Han Meimei   | 17    | female3        | Wei Hua      | 18    | male

]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>c-beginner</tag>
        <tag>C语言从小白到入门</tag>
        <tag>struct</tag>
      </tags>
  </entry>
  <entry>
    <title>C语言 struct的位域</title>
    <url>/2011/02/19/c-beginner-struct-bitfield/</url>
    <content><![CDATA[C语言的结构体位域前面可以看到，使用unoin共用体可以节省数据的存储空间。
同样，在结构体或者共用体中，使用位域也可以达到这个效果。
先看看什么时候可以使用位域，这个特点大多数人都不会用到，用到的大部分人都基本跟底层打交道，比如驱动开发、单片机开发等。
先看一个最简单的例子，比如我们的红绿灯系统，先定义一个结构体：
typedef struct{    unsigned int red;    unsigned int green;    unsigned int yellow;} TrafficLight;

此时如果看一下TrafficLight结构体的大小，应该是12个字节

但是我们知道对于这几种灯而言，只有2中状态，开和关，也就是1和0，也就是1个bit其实就能表达，所以针对这种情况，有了位域的概念，先看一下位域的声明：
typedef struct {    type name : width;}


type：整数类型
name：为位域的名称
width：为位域中位的数量，其值需要小于等于type指定的类型大小

所以交通灯的结构体使用位域的概念就如下所示：
typedef struct{    unsigned int red : 1;    unsigned int green : 1;    unsigned int yellow : 1;} TrafficLight1;
三色红绿灯加起来一共需要3个bit，所以一个无符号整型就可以容纳这些值了，此时看一下这个结构体的长度，应该为4。
总结一下：
当结构体或共用体中有无符号整型或有符号整型成员时，C语言允许用户指定这些成员所占用的存储位数，即位域。通过将数据存储在它们所需的最小数目的存储位内，位域能够有效地提供存储空间的利用率，但是，要注意，位域成员必须被声明为有符号整型或无符号整型。
代码如下：
/*beginner/struct/struct6.c*/#include &lt;stdio.h&gt;int main(){    typedef struct    {        unsigned int red;        unsigned int green;        unsigned int yellow;    } TrafficLight;    TrafficLight trafficlight;    printf("The size of TrafficLight %d\n", sizeof(trafficlight));    typedef struct    {        unsigned int red : 1;        unsigned int green : 1;        unsigned int yellow : 1;    } TrafficLight1;    TrafficLight1 trafficlight1;    printf("The size of TrafficLight1 %d\n", sizeof(trafficlight1));    return 0;}

编译运行直接输入make就可以了。
#beginner/struct/Makefilestruct6: struct6.c	gcc -o struct6 struct6.c

运行输出如下：$ ./struct6The size of TrafficLight 12The size of TrafficLight1 4

扩展既然位域指定了长度位，所以就涉及到万一赋值超过了会发生什么情况，可以通过给红绿灯赋一个大值看看。
比如复制一个2，那么会得到如下警告：
warning: implicit truncation from 'int' to bit-field changes value from 2 to 0 [-Wbitfield-constant-conversion]
编译有警告，不过还是生成了可执行文件，运行下看看结果吧。
]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>c-beginner</tag>
        <tag>C语言从小白到入门</tag>
        <tag>struct</tag>
        <tag>bit field</tag>
      </tags>
  </entry>
  <entry>
    <title>C语言 简化struct的使用</title>
    <url>/2011/02/17/c-beginner-struct-typedef/</url>
    <content><![CDATA[C语言的结构体前面说到了结构体的使用方法和访问方法。
这一次讲点高级的结构体用法。
从前面的说法可以看到每次初始的方法为：
struct Student{    int id;    char name[15];    int age;    char sex[10];};struct Student lilei = {1, "Li Lei", 18, "male"};

是不是感觉很啰嗦，是的，每次都要使用struct关键字来新定义一个变量，程序员最有名的特点就是懒，所以这问题必须解决，这就是关键字typedef的妙用了。
typedef的作用就是用来创建新类型，看看用法：
typedef struct {    int id;    char name[15];    int age;    char sex[10];}Student;Student lilei = {1, "Li Lei", 18, "male"};

是的，只需要在struct前面加上typedef这个关键字，把tag移到结构体的最后，以后初始化的时候，只需要把Student当做一个变量类型就可以了。
/*beginner/struct/struct5.c*/#include &lt;stdio.h&gt;int main(){    typedef struct    {        int id;        char name[15];        int age;        char sex[10];    } Student;    Student lilei = {1, "Li Lei", 18, "male"};    Student hanmeimei = {2, "Han Meimei", 17, "female"};    Student weihua1 = {3, "Wei Hua", 18, "male"};    Student *weihua = &amp;weihua1;    printf("The student information :\n");    printf("ID \t | Name \t| Age\t| Sex \n");    printf("%d \t | %s \t| %d \t| %s \n", lilei.id, lilei.name, lilei.age, lilei.sex);    printf("%d \t | %s \t| %d \t| %s \n", hanmeimei.id, hanmeimei.name, hanmeimei.age, hanmeimei.sex);    printf("%d \t | %s \t| %d \t| %s \n", weihua-&gt;id, weihua-&gt;name, weihua-&gt;age, weihua-&gt;sex);    return 0;}

编译运行直接输入make就可以了。
gcc -o struct5 struct5.c

运行输出如下：$  ./struct5The student information :ID       | Name         | Age   | Sex1        | Li Lei       | 18    | male2        | Han Meimei   | 17    | female3        | Wei Hua      | 18    | male

]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>c-beginner</tag>
        <tag>C语言从小白到入门</tag>
        <tag>struct</tag>
        <tag>typedef</tag>
      </tags>
  </entry>
  <entry>
    <title>C语言 使用struct描述一个学生</title>
    <url>/2011/02/14/c-beginner-struct/</url>
    <content><![CDATA[C语言的结构体OK，这次我们来聊聊结构体。
任务来了，我想让你给学生建立一个数据库，该怎么来做。
这个学生包含的信息如下：

ID：也就是学号，唯一区别码，用整型表示
Name：姓名，用字符串表示
Age：年龄，用整型表示
Sex：性别，用字符串表示

按照目前学过的知识我们的代码如下，比如先来一个李雷同学的吧：
/*beginner/struct/struct1.c*/#include &lt;stdio.h&gt;int main(){    int lilei_id = 1;    char lilei_name[15] = "Li Lei";    int lilei_age = 18;    char lilei_sex[10] = "male";    printf("The student information :\n");    printf("ID \t | Name \t| Age\t| Sex \n");    printf("%d \t | %s \t| %d \t| %s \n", lilei_id, lilei_name, lilei_age, lilei_sex);    return 0;}

好，刚开学没几天，来了另外一个同学，韩梅梅，从此浪漫的爱情，不，英语学习开始，我们把数据库更新一下：
/*beginner/struct/struct2.c*/#include &lt;stdio.h&gt;int main(){    int lilei_id = 1;    char lilei_name[15] = "Li Lei";    int lilei_age = 18;    char lilei_sex[10] = "male";    int hanmeimei_id = 2;    char hanmeimei_name[15] = "Han Meimei";    int hanmeimei_age = 17;    char hanmeimei_sex[10] = "female";    printf("The student information :\n");    printf("ID \t | Name \t| Age\t| Sex \n");    printf("%d \t | %s \t| %d \t| %s \n", lilei_id, lilei_name, lilei_age, lilei_sex);    printf("%d \t | %s \t| %d \t| %s \n", hanmeimei_id, hanmeimei_name, hanmeimei_age, hanmeimei_sex);    return 0;}

发现了什么问题，是不是跟自定义函数类似，代码是简单，不过大部分都是重复的工作，没有显示度，没有创新。
如何办，C语言提供了一个结构体，允许用户自己建立由不同类型数据组成的组合型的数据结构，注意是不同类型，不同类型。

重要的事情说三遍。

先看一下结构体的声明吧，看看是何方神圣：
struct tag {     member1    member2     member3      ...} list ;

具体是个什么含义：

struct：是结构体的声明类型
tag：是这个结构体的标记；
member：就是结构体的内容
list：是变量的列表

来个实例化吧，比如学生的定义就可以写成如下：
struct Student{    int id;    char name[10];    int age;    char sex[10];}student;


从这个代码可以看出，结构体的tag首字母一般大写，结构体的内容类型不一样，结构体有个列表叫做student。

下面我们使用结构体来重构代码如下：
/*beginner/struct/struct3.c*/#include &lt;stdio.h&gt;int main(){    struct Student    {        int id;        char name[15];        int age;        char sex[10];    };    struct Student lilei = {1, "Li Lei", 18, "male"};    struct Student hanmeimei = {2, "Han Meimei", 17, "female"};    printf("The student information :\n");    printf("ID \t | Name \t| Age\t| Sex \n");    printf("%d \t | %s \t| %d \t| %s \n", lilei.id, lilei.name, lilei.age, lilei.sex);    printf("%d \t | %s \t| %d \t| %s \n", lilei.id, lilei.name, lilei.age, lilei.sex);    return 0;}

有没有感觉，神清气爽，两袖清风，原来8行的代码，2行搞定，也就多了一个结构体的定义，在学生数以万计的时候，代码量减少了四分之三，这是在只有4个参数的情况下，参数越多越给力。
有几点说明：

注意结构体的定义，有大括号，有分号
注意结构体的初始化，需要使用struct Student s1这样的表示方式；
注意结构体的初始化也是使用大括号，对应每个变量

编译运行直接输入make就可以了。
#beginner/struct/MakefileALL : struct1 struct2 struct3 struct1: struct1.c	gcc -o struct1 struct1.cstruct2: struct2.c	gcc -o struct2 struct2.cstruct3: struct3.c	gcc -o struct3 struct3.c.PHONY : cleanclean:	rm -f struct1 struct2 struct3 

运行输出如下：$ ./struct1The student information :ID 	 | Name 	| Age	| Sex 1 	 | Li Lei 	| 18 	| male $ ./struct2The student information :ID 	 | Name 	| Age	| Sex 1 	 | Li Lei 	| 18 	| male 2 	 | Han Meimei 	| 17 	| female $ ./struct3The student information :ID 	 | Name 	| Age	| Sex 1 	 | Li Lei 	| 18 	| male 2 	 | Han Meimei 	| 17 	| female 

]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>c-beginner</tag>
        <tag>C语言从小白到入门</tag>
        <tag>struct</tag>
      </tags>
  </entry>
  <entry>
    <title>C语言 switch分支选择语句</title>
    <url>/2011/02/08/c-beginner-switch-sentence/</url>
    <content><![CDATA[C语言的switch分支选择语句​	switch本身作为分支选择语句主要是为了多个分支选择，其实它的语句用前面提到的if..else if..else if...else也可以解决，不过总归会比较冗长，相比较而言，switch语句看起来短小精悍，容易理解。
​	最容易理解用来使用switch语句的为计算学生分数，比如输入A就证明分数在85~100分，输入B就证明分数在70-85，输入C勉强通过为60-70分，输入D，不好意思，还不到60分了。
swtich分支选择语句一般形式如下：
switch(表达式){    case 表达式1：语句1；    case 表达式2：语句2；        ...    case 表达式n-1：语句n-1；    case 表达式n：语句n；    default：语句n+1；            }

这个语句的具体含义为：

首先判断表达式；
如果表达式为表达式1，就执行语句1；
如果表达式为表达式2，就执行语句2；
以此类推
default语句为默认不满足任何语句的时候执行的语句


这里有一个特别需要注意的，就是每一个语句最后都要加上break，切记，不然执行的结果并不一定是你认为的那样，因为在每个表达式，它没有跳出来。

简单举几个例子如下：
/*beginner/switch/switch1.c*/#include &lt;stdio.h&gt;int main(){    int score;    score = 'A';    switch (score)    {    case 'A':        printf("Wow, Awesome!!\n");    case 'B':        printf("Yeah, Great!!\n");    case 'C':        printf("Ok, passed!!\n");    case 'D':        printf("Sorry, you lose it!!\n");    }    return 0;}

这个例子有一个最大的不足在于如果不满足上面说的四种情况，需要一个default语句来处理异常情况。
/*beginner/switch/switch2.c*/#include &lt;stdio.h&gt;int main(){    int score;    score = 'A';    switch (score)    {    case 'A':        printf("Wow, Awesome!!\n");    case 'B':        printf("Yeah, Great!!\n");    case 'C':        printf("Ok, passed!!\n");    case 'D':        printf("Sorry, you lose it!!\n");    default:        printf("BAD input\n");    }    return 0;}

这个例子的问题就在于每一个语句最后没有跟break语句，导致每个执行都会有输出。
/*beginner/switch/switch3.c*/#include &lt;stdio.h&gt;int main(){    int score;    score = 'A';    switch (score)    {    case 'A':        printf("Wow, Awesome!!\n");        break;    case 'B':        printf("Yeah, Great!!\n");        break;    case 'C':        printf("Ok, passed!!\n");        break;    case 'D':        printf("Sorry, you lose it!!\n");        break;    default:        printf("BAD input\n");        break;    }    return 0;}

完美的switch就应该是这个样子了，😁。
相应地Makefile如下所示：
#beginner/switch/MakefileALL : switch1 switch2 switch3switch1 : switch1.c	gcc -o switch1 switch1.cswitch2 : switch2.c	gcc -o switch2 switch2.cswitch3 : switch3.c	gcc -o switch3 switch3.c.PHONY : cleanclean:	rm -f switch1 switch2 switch3

输入make，然后执行各个程序输出如下：
$ ./switch1Wow, Awesome!!Yeah, Great!!Ok, passed!!Sorry, you lose it!!$ ./switch2Wow, Awesome!!Yeah, Great!!Ok, passed!!Sorry, you lose it!!BAD input$ ./switch3Wow, Awesome!!
]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>c-beginner</tag>
        <tag>C语言从小白到入门</tag>
        <tag>switch</tag>
      </tags>
  </entry>
  <entry>
    <title>C语言 符号常量</title>
    <url>/2011/02/09/c-beginner-symbol-const/</url>
    <content><![CDATA[C语言的符号常量​	前面已经看完了变量，正常情况下就要来聊聊常量了，从字面意义上看，变量与常量的概念比较容易理解：

变量：就是能改变的量
常量：就是不能改变的量

对于变量而言用的最多的也是见得做多的估计就是int i;这个语句的，而常量在什么时候用呢？
比如银行的利率，蔬菜的价格，电路的增益，线缆的损耗等等，可能会更改的值，更改不是原因，主要是在使用的时候一定要是多处使用到了，这样才能发挥它的作用。
先说一下符号变量的一般用法，如下所示：
#define 变量名 变量值

来个不用代码片段的，比如白菜的价格是2.5元一斤，张三、李四、王五，每个人来个三四五斤，需要多少钱，代码如下：
float zhangsan_price = 2.5 * 3;float lisi_prince = 2.5 * 4;float wangwu_prince = 2.5 * 5;

不错，代码看着简介明了，忽然章丘遇到天灾了，白菜统一涨价到5.5元一斤，OK，代码修改如下所示：
float zhangsan_price = 5.5 * 3;float lisi_prince = 5.5 * 4;float wangwu_prince = 5.5 * 5;

真是中国好邻居呀，干嘛都一起，这样也好操作，但是如果要统计一个村300多户都买几斤大白菜，那么需要修改的就是300多处，那样岂不是超级崩溃，OK，这时就需要符号常量了，我们略微修改，增加符号变量：
#define PRICE 2.5float zhangsan_price = PRICE * 3;float lisi_prince = PRICE * 4;float wangwu_prince = PRICE * 5;

涨价了怎么办呢，只需要需改第一句，把2.5更改为5.5即可，简单快捷粗暴：
#define PRICE 5.5float zhangsan_price = PRICE * 3;float lisi_prince = PRICE * 4;float wangwu_prince = PRICE * 5;

300多户，丝毫不惧，来个百八十万照旧一次修改，全部收益。
恩，符号变量的效果就是如此了，你是否已经了然于胸。
来个小例子：
/*beginner/define/define1.c*/#include &lt;stdio.h&gt;#define BONUS 0.1int main(){    int salary;    salary = 30;    printf("The salary this year is %.2fk\n", salary * (1 + BONUS));    return 0;}




每年浮动10%应该是常态，希望各位老板仁慈，对待优秀员工，把整个符号常量设大一点，哈哈，不用太多，0.5就可以了，😁。

相应地Makefile如下所示：
#beginner/define/MakefileALL : define1 define1 : define1.c	gcc -o define1 define1.c.PHONY : cleanclean:	rm -f define1 

输入make，然后执行各个程序输出如下：
$  ./define1The salary this year is 33.00k
]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>define</tag>
        <tag>c-beginner</tag>
        <tag>C语言从小白到入门</tag>
      </tags>
  </entry>
  <entry>
    <title>C语言 唯一的三元操作符</title>
    <url>/2011/02/23/c-beginner-ternary/</url>
    <content><![CDATA[C语言唯一的三元操作符如果有两个变量，我希望打印出最大的一个，怎么做呢，很简单一个if-else语句搞定，嗯嗯，👍。
/*beginner/ternary/ternary1.c*/#include &lt;stdio.h&gt;int main(){    int a = 5;    int b = 7;    if (a &gt; b)        printf("Bigger is %d\n", a);    else        printf("Bigger is %d\n", b);    return 0;}

今天来一个比较搞定的三元操作符，前面有提过什么事三元操作符，参考逻辑运算符原文，简单的理解就是：a?b:c，如果a为真就返回b，如果a为假就返回c。
所以rst = a?b:c用if-else来表达就是：
if (a)	rst = b;else	rst = c;

所以上面的程序可以简化为：
/*beginner/ternary/ternary2.c*/#include &lt;stdio.h&gt;int main(){    int a = 5;    int b = 7;        printf("Bigger is %d\n", a &gt; b ? a : b);    return 0;}


看到没有，奇迹就是用1行能写出4行的效果。
或许你会说用python可以1行写出c语言10行甚至100的功能，这个我承认，所以下一阶段开讲Python

或许你问了，有了if-else还要这个干吗，简单，我们可以做很多事情，比如在宏定义里面定义下面的一行
#define MAX(a,b) a&gt;b?a:b

后面直接调用MAX就可以得出最大值了，不过这个写法目前看来OK，如果严谨说起来是有bug的，且听下回分解。
另外一个比较有用的例子如下，我觉得很适合英语国家，在我们中国不存在这个问题，就是如果你有一个叔叔和几个叔叔的表达方式不一样：

中文：我有一个叔叔，我有N个叔叔（N&gt;1）
英文：我有一个uncle，我有N个uncles（N&gt;1）

看到没有，有好几个叔叔就要加个s，这个怎么来办呢，有了三元操作符，解决方案如下：
/*beginner/ternary/ternary3.c*/#include &lt;stdio.h&gt;int main(){    int n1 = 1;    int n3 = 3;    printf("I have %d uncle%s\n", n1, n1==1 ? "" : "s");    printf("I have %d uncle%s\n", n3, n3==1 ? "" : "s");    return 0;}



编译编译也有所不同，方法为：
#beginner/ternary/MakefileALL : ternary1  ternary2 ternary3ternary1: ternary1.c	gcc -o ternary1 ternary1.cternary2: ternary2.c	gcc -o ternary2 ternary2.cternary3: ternary3.c	gcc -o ternary3 ternary3.c.PHONY : cleanclean:	rm -f ternary1 ternary2 ternary3

这会产生可执行程序，当程序被执行时，它会产生下列结果：
$ ./ternary1Bigger is 7$ ./ternary2Bigger is 7$ ./ternary3I have 1 uncleI have 3 uncles

]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>c-beginner</tag>
        <tag>C语言从小白到入门</tag>
        <tag>ternary</tag>
      </tags>
  </entry>
  <entry>
    <title>C语言 共用体的成员访问</title>
    <url>/2011/02/19/c-beginner-union-access/</url>
    <content><![CDATA[C语言 共用体的访问共用体的访问与结构体类似，也是有2中类型，我们只看看成员访问运算符.。
所以按照通用的赋值方式，来看一下是否按照我们预定的方式运行。
/*beginner/union/union2.c*/#include &lt;stdio.h&gt;#include &lt;string.h&gt;union Data {    int i;    float f;    char str[20];};int main(){    union Data data;    data.i = 123;    data.f = 456.0;    strcpy(data.str, "Hello World");    printf("data.i : %d\n", data.i);    printf("data.f : %f\n", data.f);    printf("data.str : %s\n", data.str);    return 0;}


从结果上来看，what are you弄啥嘞，感觉什么跟什么呀，只有最后的字符串是正确的，这也就间接证明了共用体使用相同的存储空间，其他类型的赋值会破坏原先的赋值，正常情况下只有最后一次的赋值才会保证正确结果。

所以我们需要在每次赋值后直接查看结果，是可以保证结果正确的：
/*beginner/union/union3.c*/#include &lt;stdio.h&gt;#include &lt;string.h&gt;union Data {    int i;    float f;    char str[20];};int main(){    union Data data;    data.i = 123;    printf("data.i : %d\n", data.i);    data.f = 456.0;    printf("data.f : %f\n", data.f);    strcpy(data.str, "Hello World");    printf("data.str : %s\n", data.str);    return 0;}


再次运行，可以看到结果就按照预想的进行了。

编译运行#beginner/union/MakefileALL : union1 union2 union3union1: union1.c	gcc -o union1 union1.cunion2: union2.c	gcc -o union2 union2.cunion3: union3.c	gcc -o union3 union3.c.PHONY : cleanclean:	rm -f union1 union2 union3 



输出结果$ ./union2data.i : 1819043144data.f : 1143139122437582505939828736.000000data.str : Hello World$ ./union3data.i : 123data.f : 456.000000data.str : Hello World

]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>c-beginner</tag>
        <tag>C语言从小白到入门</tag>
        <tag>struct</tag>
      </tags>
  </entry>
  <entry>
    <title>C语言 解决存储的共用体</title>
    <url>/2011/02/18/c-beginner-union/</url>
    <content><![CDATA[C语言的共用体union共用体是一种特殊的数据类型，允许您在相同的内存位置存储不同的数据类型。
什么意思呢，就是在同一块内存存储可以定义多个数据类型，但是在使用的时候，只有一个变量有效。
这里就有一个问题，变量有大有小呀，对的，所以这个时候共用体的空间为内部变量最大占用空间的值。
如此这般，共用体就可以通过共享存储空间，来避免当前没有被使用的变量所造成的存储空间的浪费。
共用体的成员可以使用任何数据类型，但是一个共用体所占用的存储空间的字节总数，必须保证至少足以能够容纳其占用空间字节数最大的成员。并且共用体每次只允许访问一个成员，也就是一种数据类型，确保按照正确的数据类型来访问共用体中的数据，就是你的责任了。
先看看union的格式：
union [tag]{   member definition;   member definition;   ...   member definition;} [variables];

其中：

union为类型变量；
tag为共用体的标记；
member definition为变量的定义；

举个例子：
union test{   int i;   float f;   double d;   char  str[20];} data;

通过这个例子可以看到，这个结构体的大小是多少呢？可以通过程序来确认一下。
OK，这次我们来聊聊结构体。
任务来了，我想让你给学生建立一个数据库，该怎么来做。
这个学生包含的信息如下：

ID：也就是学号，唯一区别码，用整型表示
Name：姓名，用字符串表示
Age：年龄，用整型表示
Sex：性别，用字符串表示

按照目前学过的知识我们的代码如下，比如先来一个李雷同学的吧：
#include &lt;stdio.h&gt;#include &lt;string.h&gt; union test{   int i;   float f;   double d;   char  str[20];}; int main( ){   union test data;            printf( "data size : %d\n", sizeof(data));    return 0;}
]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>c-beginner</tag>
        <tag>C语言从小白到入门</tag>
        <tag>struct</tag>
      </tags>
  </entry>
  <entry>
    <title>C语言 优美的C语言命名方法</title>
    <url>/2011/01/27/c-beginner-variable-name/</url>
    <content><![CDATA[优美的C语言命名方法
Update : 20181107 增加多种命名方法的解释

武功的最高境界就是无招胜有招。
这在程序风格这里好像是说不通的，编程风格就忌讳的就是没有风格，或者太多风格。
对于C语言的变量命名而言，其实要做到太多风格其实是蛮困难的，因为C语言的变量必须是由数字、字母和下划线组成的，且数字不能开头的命名方式。这对于只有100多个键的键盘而言，可组合的真的是也是没有多少了。
可能刚开始写的时候会出现temporary这样的变量，C语言比较偏向于使用tmp来代替，这体现出来了C语言的简洁或者叫程序员的懒惰，能少敲1个是一个。
或者使用thenameofallthestudents，过了几天就会比较抓瞎，到底写的个啥，其实C语言提供了比较经典的两种方式：

驼峰法，上面的变量可以写为TheNameOfAllTheStudents
下划线法，上面的变量可以写为the_name_of_all_the_students

我比较倾向于第二种风格，暨下划线法，可能是因为对于大写的单词总归需要切换一下，😄。
当然还有其他一些诸如匈牙利命名法（微软用的比较多），PASCAL命名法（哦，Pascal），都是大同小异，有了自己的风格，坚持下去就可以了。
// no-stylechar thenameofallthestudents[1024]; 	// hump-style/PASCAL-stylechar TheNameOfAllTheStudents[1024]; 		// underscore-stylechar the_name_of_all_the_students[1024]; 	// Hungary-stylechar g_TheNameOfAllTheStudentsChar[1024];



驼峰命名法指混合使用大小写字母来构成变量和函数的名字，比如theNameOfAllTheStudents

注意：第一个单词首字母小写

匈牙利命名法在微软Windows环境中用的比较多，那是因为发明这个的人就是Microsoft的程序员，这种命名方式有点小复杂，规则如下：

变量名前面要加上一个小些字母做为前缀，来标示出变量的作用域和类型
后面就可以是中英文的各种含义了

比如，如果定义一个整型（int）的年龄（Age），那么命名方式为iAge，如果定义一个字符串名字，可以使用sName，而用0结尾的字符串，一般使用sz开头，比如szName。
而像上面的例子中，作用域可以使用g来表示全局变量global，l表示局部变量local。

不过，在当前的环境下，随便一个IDE都有智能提示，这个类型和作用域其实已经不是很有必要了。

帕斯卡PASCAL命名法Pascal曾经称霸多年。
与驼峰命名法类似，二者的区别在于：驼峰命名法是首字母小写，而帕斯卡命名法是首字母大写TheNameOfAllTheStudents，所以PASCAL命名法也被称为大驼峰命名法。
下划线命名法指混合使用小写字母与下划线来构成变量和函数的名字，比如the_name_of_all_the_students
程序的风格程序设计风格的原则根源于由实际经验中得到的常识，它不是随意的规则或者处方。代码应该是清楚的和简单的—具有直截了当的逻辑、自然的表达式、通行的语言使用方式、有意义的名字和有帮助作用的注释等，应该避免耍小聪明的花招，不使用非正规的结构。一致性是非常重要的东西，如果大家都坚持同样的风格，其他人就会发现你的代码很容易读，你也容易读懂其他人的。
]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>c-beginner</tag>
        <tag>C语言从小白到入门</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title>C语言 赏心悦目的输出</title>
    <url>/2011/01/28/c-beginner-variable-type/</url>
    <content><![CDATA[C语言的变量类型这一章讲讲变量的类型，编译型语言和解释性语言的一个区别就是编译型语言你得提前告诉我你是什么类型的，这就像现实与网络，现实中你得告诉我你说谁，我才和你聊，网络上无所谓了，其实也可能你在和一只哈士奇聊天，😄。
用之前先定义，记住这个就错不了了。
其实C语言里面的变量类型比较少，今天就说5个。

一个是整形integer，就是诸如1，2，3等的整数
浮点型float，就是123.45，有小数点的
浮点型double，这个是双精度的，相比较float，能表示的值更大
字符型char，只有一个字符的，比如A、B、C等
字符串char *，这个是包含多个字符的，比如“Hello World”

源码如下：
/*beginner/variable/variable.c*/#include &lt;stdio.h&gt;int main(){    int i = 5;    float f = 123.0;    double d = 456.0;    char c = 'A';    char cc[6] = "HELLO";    printf("Types \t Values\n");    printf("integer \t %d\n", i);    printf("float \t %f\n", f);    printf("double\t %f\n", d);    printf("char \t %c\n", c);    printf("string\t %s\n", cc);    return 0;}



输出为：
Types 	 ValuesInteger 	 5float 	 123.000000double	 456.000000char 	 Astring	 HELLO
是不是发现printf函数里面又多了一些内容，对的%d表示打印证书，%f代表打印浮点数，%c是字符，而%s是字符串。
]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>printf</tag>
        <tag>c-beginner</tag>
        <tag>C语言从小白到入门</tag>
      </tags>
  </entry>
  <entry>
    <title>C语言 选择哪种循环语句</title>
    <url>/2011/02/08/c-beginner-which-loop/</url>
    <content><![CDATA[如何选择C语言的循环语句对于C语言的三种语句而言，其实彼此基本可以实现功能，也就是说用for能解决的，用while也能解决，反之也是。
再看一下，两种循环结构：

for循环
while、do-while循环

那么是如何来进行选择呢，什么时候用哪种循环呢，这就要看具体情况，叫做it depends，^_^。
一般而言，_选用的原则_如下所示：

如果循环次数在执行循环体之前就已确定，一般用for语句。如果循环次数是由循环体的执行情况确定的，一般用 while语句或者do- while语句;
当循环体至少执行一次时，用do-while语句，反之，如果循环体可能一次也不执行，则选用while语句C++/C循环语句中，for语句使用频率最高，while语句其次，do语句很少用。

]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>c-beginner</tag>
        <tag>C语言从小白到入门</tag>
        <tag>for</tag>
        <tag>while</tag>
        <tag>do-while</tag>
      </tags>
  </entry>
  <entry>
    <title>C语言 while循环语句</title>
    <url>/2011/02/07/c-beginner-while-sentence/</url>
    <content><![CDATA[C语言的while循环语句​	C语言本身有3种程序结构，分别是：

顺序结构：语句一句一句执行，从头执行到结尾；
选择结构：可以理解为是分支结构，根据判断结构来选择向哪个方向进行，类似前面说的if、else语句；
循环结构：循环结构是这3个里面最复杂的，因为它自身有一个循环体，结构本身也是根据判断的结构，来决定循环体到底执行多少次，只要条件满足，循环体可以执行到天荒地老，此恨绵绵。主要的有上一次的for循环，还有今天说的while循环


while循环有两个，分别为while循环和do-while循环

while循环一般形式如下：
while(表达式){    语句；}



其中执行过程如下：

计算while后面括号里表达式的值，若其结果非0，则转入2，否则转3
执行循环体，转到1
退出循环，执行循环体下面的语句。

由于是先执行判断后执行循环体，所以循环体可能一次都不执行。
循环体可以为空语句;，不过这个基本没有什么卵用。
do-while循环与while循环类似，还有一个do-while循环，一般形式如下：
do{	语句；    }while(表达式);

执行过程如下所示：

执行循环体，转2
计算while后面括号里表达式的值，若其结果非0，则转入1，否则转3
退出循环，执行循环体下面的语句。


注意：do……while语句最后的分号（；）不可少，否则提示出错。

这里可以看到，两种循环的区别是do-while至少执行一次。
简单举几个例子如下：
/*beginner/while/while.c*/#include &lt;stdio.h&gt;int main(){    int i = 0;    int sum = 0;    while (i &lt; 101)    {        sum += i;        i++;    }    printf("1 + ... + 100 = %d\n", sum);    i = 0;    sum = 0;    do    {        sum += i;        i++;    } while (i &lt; 101);    printf("1 + ... + 100 = %d\n", sum);    return 0;}



相应地Makefile如下所示：
#beginner/for/MakefileALL : whilewhile : while.c	gcc -o while while.cclean:	rm -f while

输入make，然后./while输出如下：
$./while1 + ... + 100 = 50501 + ... + 100 = 5050

]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>c-beginner</tag>
        <tag>C语言从小白到入门</tag>
        <tag>while</tag>
      </tags>
  </entry>
  <entry>
    <title>C语言 关于break和continue</title>
    <url>/2013/01/24/c-break-continue/</url>
    <content><![CDATA[关于break和continue
break:用于即时地退出某个控制语句；
continue：用于跳过循环体中的剩余语句，开始下一轮；

]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>break</tag>
        <tag>continue</tag>
      </tags>
  </entry>
  <entry>
    <title>C语言 函数调用三种方式–传值调用–引用调用和传地址调用</title>
    <url>/2012/02/06/c-call/</url>
    <content><![CDATA[C语言函数调用三种方式–传值调用–引用调用和传地址调用三种调用方式
传值是把实参的值赋值给行参，那么对行参的修改，不会影响实参的值。从函数调用的角度理解：函数参数压栈的是参数的副本。任何的修改是在副本上作用，没有作用在原来的变量上。
传地址是传值的一种特殊方式，只是他传递的是地址，不是普通的如int，那么传地址以后，实参和行参都指向同一个对象。从函数调用的角度理解：压栈的是指针变量的副本。当你对指针解指针操作时，其值是指向原来的那个变量，所以对原来变量操作。
传引用—c中没有，C++中才有的真正的以地址的方式传递参数，传递以后，行参和实参都是同一个对象，只是他们名字不同而已，对行参的修改将影响实参的值.。从函数调用的角度理解：压栈的是引用的副本。由于引用是指向某个变量的，对引用的操作其实就是对他指向的变量的操作。
函数参数传递机制的基本理论函数参数传递机制问题在本质上是调用函数（过程）和被调用函数（过程）在调用发生时进行通信的方法问题。基本的参数传递机制有两种：值传递和引用传递。 以下讨论称调用其他函数的函数为主调函数，被调用的函数为被调函数。值传递（pass-by-value）过程中，被调函数的形式参数作为被调函数的局部变量处理，即在堆栈中开辟了内存空间以存放由主调函数放进来的实参的值，从而成为了实参的一个副本。值传递的特点是被调函数对形式参数的任何操作都是作为局部变量进行，不会影响主调函数的实参变量的值。
引用传递(pass-by-reference)过程中，被调函数的形式参数虽然也作为局部变量在堆栈中开辟了内存空间，但是这时存放的是由主调函数放进来的实参变量的地址。被调函数对形参的任何操作都被处理成间接寻址，即通过堆栈中存放的地址访问主调函数中的实参变量。正因为如此，被调函数对形参做的任何操作都影响了主调函数中的实参变量。
C语言中的函数参数传递机制在C语言中，值传递是唯一可用的参数传递机制。但是据笔者所知，由于受指针变量作为函数参数的影响，有许多朋友还认为这种情况是引用传递。这是错误的。请看下面的代码：
#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;void pass_by_value(int a,int b);void pass_by_address(int *pa,int *pb);//pass_by_reference(int &amp;ra,int &amp;rb);int main(void){    int a = 1;    int b = 2;    pass_by_value(a,b);    printf("%s:pass by value :a = %d, b = %d\n",__func__,a,b);    pass_by_address(&amp;a,&amp;b);    printf("%s:pass by address :a = %d, b = %d\n",__func__,a,b);//            pass_by_reference(a,b);//            printf("%s:pass by reference :a = %d, b = %d\n",__func__,a,b);    return 0;}void pass_by_value(int x,int y){    int tmp;    tmp = y;    y = x;    x = tmp;    printf("%s:pass by value: x = %d,y = %d\n",__func__,x,y);}void pass_by_address(int *px,int *py){    int tmp = *px;    *px = *py;    *py =  tmp;    printf("%s:pass by address: *px = %d,*py = %d\n",__func__,*px,*py);}#if 0pass_by_reference(int &amp;rx,int &amp;ry){    int tmp = rx;    rx = ry;    ry = tmp;    printf("%s:pass by reference: x = %d,y = %d\n",__func__,rx,ry);}#endif


pass_value(p1, p2)语句包含的意思是p1=a，p2=b；只是把a和b的值copy了一份给他们。
pass_address(*p1, *p2)语句包含的意思是p1=&amp;a，p2=&amp;b；是把a和b的地址值copy了一份给他们。

]]></content>
      <categories>
        <category>C</category>
        <category>C++</category>
      </categories>
      <tags>
        <tag>reference</tag>
      </tags>
  </entry>
  <entry>
    <title>C语言 const</title>
    <url>/2013/03/16/c-const/</url>
    <content><![CDATA[函数形参为const如果一个变量作为实参传递给一个函数，并且这个变量没有也不应该在这个函数体中被修改，那么应该将这个变量声明为const，以避免其被意外改写，比如:
extern char *strcpy(char dest[],const char *src);

这个函数我们可以保证src肯定不能被修改的。
const的含义
const char *p：p为指向字符常量的指针
char const *p：p为指向字符常量的指针
char * const p：声明一个指向字符的指针常量p

]]></content>
      <categories>
        <category>C</category>
        <category>C++</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>c++</tag>
        <tag>const</tag>
      </tags>
  </entry>
  <entry>
    <title>C语言 基于Doxygen的C/C++注释原则</title>
    <url>/2013/03/08/c-cpp-doxygen-comments/</url>
    <content><![CDATA[基于Doxygen的C/C++注释原则#define OST_TIMESTAMP                DATE “ “ TIME
## 1. 文件头的标注```c/******************************************************************************  The ATAS Library                                                          **  Copyright (C) 2010 Shaoguang Guo  sgguo@shao.ac.cn                        **                                                                            **                                                                            **  This program is free software; you can redistribute it and/or modify      **  it under the terms of the GNU General Public License version 3 as         **  published by the Free Software Foundation.                                **                                                                            **  You should have received a copy of the GNU General Public License         **  along with SHAO. If not, see &lt;http://www.gnu.org/licenses/&gt;.              **                                                                            **  Unless required by applicable law or agreed to in writing, software       **  distributed under the License is distributed on an "AS IS" BASIS,         **  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  **  See the License for the specific language governing permissions and       **  limitations under the License.                                            **                                                                            **  @file     Example.h                                                       **  @brief    brief introduction                                              **  Details.                                                                  **                                                                            **  @author   Shaoguang Guo                                                   **  @email    sgguo@shao.ac.cn                                                **  @version  0.1(version)                                                    **  @date     2010.07.16                                                      **  @license  GNU General Public License (GPL)                                **                                                                            **----------------------------------------------------------------------------**  Remark         : Description                                              **----------------------------------------------------------------------------**  Change History : &lt; can omit if using VCS &gt;                                **  &lt;Date&gt;     | &lt;Version&gt; | &lt;Author&gt;       | &lt;Description&gt;                   **----------------------------------------------------------------------------**  2010/07/16 |   0.1     | Shaoguang Guo  | Init the repo                   **----------------------------------------------------------------------------**                                                                            ******************************************************************************/

2.命名空间/*** @brief 命名空间的简单概述 \n(换行)* 命名空间的详细概述*/namespace OST{}

3. 类、结构、枚举标注/*** @brief 类的简单概述 \n(换行)* 类的详细概述*/class Example{};

枚举类型定义、结构体类型定义注释风格类似
/*** @brief 简要说明文字*/typedef struct 结构体名字{   成员1, /*!&lt; 简要说明文字 */ or ///&lt;说明， /**&lt;说明 */ 如果不加&lt;，则会认为是成员2的注释   成员2, /*!&lt; 简要说明文字 */ or ///&lt;说明， /**&lt;说明 */   成员3, /*!&lt; 简要说明文字 */ or ///&lt;说明， /**&lt;说明 */}结构体别名；

4. 函数注释原则/*** @brief 函数简要说明-测试函数* @param index    参数1* @param t            参数2 @see CTest** @return 返回说明*        -&lt;em&gt;false&lt;/em&gt; fail*        -&lt;em&gt;true&lt;/em&gt; succeed*/

bool Test(int index, const CTest&amp; t);

note：指定函数注意项事或重要的注解指令操作符
note格式如下：
        @note 简要说明

retval：指定函数返回值说明指令操作符。(注:更前面的return有点不同.这里是返回值说明)
retval格式如下：
        @retval 返回值 简要说明

pre：指定函数前置条件指令操作符
pre格式如下：
        @pre 简要说明

par：指定扩展性说明指令操作符讲。（它一般跟code、endcode一起使用 ）
par格式如下：
      @par 扩展名字

code、endcode：指定
code、endcode格式如下：
        @code
            简要说明(内容)
        @endcode

see：指定参考信息。
see格式如下：
        @see 简要参考内容

deprecated：指定函数过时指令操作符。
deprecated格式如下：
      @deprecated 简要说明　

　　调试Bug说明　　　　解决的bug说明，@bug　　警告说明 (warning)　　　　定义一些关于这个函数必须知道的事情，@warning　　备注说明 (remarks)　　　　定义一些关于这个函数的备注信息，@remarks　　将要完成的工作 (todo)　　　　说明哪些事情将在不久以后完成，@todo　　使用例子说明 (example)　　　　例子说明，@example example.cpp
5. 变量注释  /// 简述  /** 详细描述. */  或者  //! 简述  //! 详细描述  //! 从这里开始  int m_variable_1; ///&lt; 成员变量m_variable_1说明  int m_variable_2; ///&lt; 成员变量m_variable_1说明/*** @brief 成员变量m_c简要说明** 成员变量m_variable_3的详细说明，这里可以对变量进行* 详细的说明和描述，具体方法和函数的标注是一样的*/bool m_variable_3;


如果变量需要详细说明的可已按照m_varibale_3的写法写，注意，m_variable_2和m_variable_3之间一定需要空行，否则会导致m_variable_2的简述消失

6. 模块标注模块定义格式:
/*** @defgroup 模块名  页的标题名 (模块名只能英文,这个可以随便取.在一个源文件里不能相同)* @{ (跟c语言{一样起作用域功能)*/… 定义的内容 …/** @} */例：/*** @defgroup HenryWen Example.cpp* @{*/  … 定义的内容 …/** @} */

7. 分组标注分组定义格式：
/*** @name 分组说明文字* @{*/… 定义的内容 …/** @} */例：/*** @name PI常量* @{*/#define PI 3.1415926737/** @} *//*** @name 数组固定长度常量* @{*/const int g_ARRAY_MAX = 1024;/** @} */
]]></content>
      <categories>
        <category>C</category>
        <category>C++</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>c++</tag>
        <tag>doxygen</tag>
      </tags>
  </entry>
  <entry>
    <title>C语言 macro函数宏</title>
    <url>/2013/01/18/c-define/</url>
    <content><![CDATA[函数宏老的C语言程序员中有一种倾向，就是把很短的执行频繁的计算写成宏，而不是定义为函数。完成I / O的getchar，做字符测试的isdigit都是得到官方认可的例子。人们这样做最根本的理由就是执行效率：宏可以避免函数调用的开销。实际上，即使是在C语言刚诞生时(那时的机器非常慢，函数调用的开销也特别大)，这个论据也是很脆弱的，到今天它就更无足轻重了。有了新型的机器和编译程序，函数宏的缺点就远远超过它能带来的好处。
所以应该避免函数宏。在C++ 里，在线函数更削减了函数宏的用武之地，在Java里根本就没有宏这种东西。即使是在C语言里，它们带来的麻烦也比解决的问题更多。
函数宏最常见的一个严重问题是：如果一个参数在定义中出现多次，它就可能被多次求值。如果调用时的实际参数带有副作用，结果就会产生一个难以捉摸的错误。
]]></content>
      <categories>
        <category>C</category>
        <category>C++</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>c++</tag>
        <tag>define</tag>
      </tags>
  </entry>
  <entry>
    <title>C语言 GUI开发图形界面</title>
    <url>/2012/01/05/c-develop-gui/</url>
    <content><![CDATA[用C语言开发图形界面在浏览linuxquestions的时候，看到一篇关于Graphics Programming on linux using C的帖子，感觉不错，特来分享一下。
现在关于图形开发的VC，C#,java,QT等IDE大行其道。不过还是有一部分默默无闻的人偏爱着用pure代码来描绘着自己的世界。
我这里推荐几个，大家可以search一下相关的内容，下面即为keyword。

OpenGL
PGPLOT
GTK
KDE
GLUT
FLTK
ncurses
xlib
QT
SDL等

更多信息SDLSDL is a good library and used by game developers.
##OpenGL
You can also use OpenGL for 3d stuff, but be warned that performance will be poor unless X use 3d accelerated drivers. Otherwise it will use Mesa indirect.
svgalibsvgalib is easy to use, but people tend to overlook it because it doesn’t fit in well with the modern X graphics paradigm. I have a program (experix project in sourceforge) that plots graphs and writes text using a svgalib-based graphics server.
GTK+GTK+: can be a little overwelming but I was able to understand it a lot better than xlib. It is slower tho i will admit.
never tried svgalib before but thanks for the link ill have to check that out.
GTK+: will confuse you on all its diffrent versions as well and for larger apps it can get a little confusing on what does what or how this is related to that.
ncursesncurses: is cool but can be a freekin nightmare. i still dont understand columsand rows
QtQt: dont know anything about this think i made a program with it before i Knew anything about C
xlibxlib: Try if you dare you might find it more understandable then me. Never could get my hello world program to display.
]]></content>
      <categories>
        <category>C</category>
        <category>GUI</category>
      </categories>
      <tags>
        <tag>pgplot</tag>
        <tag>c</tag>
        <tag>gui</tag>
        <tag>opengl</tag>
        <tag>gtk</tag>
        <tag>kde</tag>
        <tag>glut</tag>
        <tag>fltk</tag>
        <tag>ncurses</tag>
        <tag>xlib</tag>
        <tag>qt</tag>
        <tag>sdl</tag>
      </tags>
  </entry>
  <entry>
    <title>C语言 动态内存分配</title>
    <url>/2012/03/01/c-dynamic-memory/</url>
    <content><![CDATA[动态内存分配为什么使用动态内存分配比如，我们计算年级学生的平均成绩，但是不知道有多少学生，可以定义一个很大的数组，确保学生个数不会超出数组定义范围，但是如果学生人数很少，就会造成巨大的浪费。所以会有如下缺点：

数组声明中引入了人为的限制，如果程序需要使用的元素数量超过了声明的长度，它就无法处理这种情况；
要避免上述情况，需要把数组声明的更大些，但这也导致如果元素数据比较少时，巨型数组的绝大部分内存空间都浪费了；
如果输入的数据超过了数组的容纳范围，程序必须以一种合理的方式作出响应，而不应该由于一个异常而失败，也不应该打印出看上去正确但实际上错误的结果。

malloc和freec函数库提供了两个函数，malloc和free，分别用于执行内存分配和释放。这些函数维护一个可用内存池。当一个程序另外需要一些内存时，它就调用malloc函数，malloc从内存池中提取一块合适的内存，并向该程序放回一个指向这块内存的指针。注意，现在这块内存并没有以任何方式进行初始化。
free的参数要么是NULL，要么是一个先前从malloc、calloc或realloc返回的值。向free传递一个NULL参数不会产生任何效果。
And我们知道malloc的返回值为void *，所以malloc可以指向任何类型的整数、浮点值、结构或者数组，这个需要我们自己定义。
calloc和reallocmalloc和calloc之间的主要区别是后者在返回指向内存的指针之前把它初始化为0。这个初始化常常能带来方便，但是如果你的程序只是想把一些值存储到数组中，那么这个初始化过程就纯属浪费时间；两者的另外一个较小的区别是它们请求内存数量的方式不同，calloc的参数包括所需元素的数量和每个元素的字节数。
realloc函数用于修改一个原先已经分配的内存块的大小。如果原先的内存块无法改变大小，realloc将分配另一块正确大小的内存，并把原先那块内存的内容复制到新的块上。
如果realloc函数的第一个参数是NULL，那么它的行为就和malloc一摸一样。
常见的动态内存错误使用动态内存常犯的错误就是忘记检查所请求的内存是否成功分配？第二大错误是操作内存时超出了分配内存的边界。
分配内存但在使用完毕后如果不释放将引起内存泄露memory leak。
内存分配实例动态内存分配一个常见的用途就是为那些长度在运行时才知的数组分配内存空间。
总结
当数组被声明时，必须在编译时知道它的长度。动态内存分配允许程序为一个长度在运行时才知道的数组分配内存空间；
动态内存分配时必须判断返回值是否为NULL；
动态内存分配有助于消除程序内部存在的限制；
使用sizeof计算数据类型的长度，可以提高程序的可移植性。

]]></content>
      <categories>
        <category>C</category>
        <category>C++</category>
      </categories>
      <tags>
        <tag>malloc</tag>
        <tag>free</tag>
        <tag>calloc</tag>
        <tag>realloc</tag>
      </tags>
  </entry>
  <entry>
    <title>C语言 extern用法解析</title>
    <url>/2013/03/15/c-endian/</url>
    <content><![CDATA[little-endian和big-endian区别endian一词源于小说格列佛游记，小说中，小人国为水煮蛋从大的一段big-end还是小的一端little-end剥开而争论（我习惯从大端打开clip_image001），争论的双方分别被称为big-endians和little-endians。
对于字节序的典型情况为整数在内存中的存放方式和网络传输的传输顺序。

小端序：LSByte在MSByte的前面，即LSB为低地址，MSB为高地址；
大端序：MSByte在LSByte的前面，即LSB为高地址，MSB为低地址；

对于单一的字节，大部分处理器以相同的顺序处理位元bit，因此单字节的存放方法和传输方式一般相同。
]]></content>
      <categories>
        <category>C</category>
        <category>C++</category>
      </categories>
      <tags>
        <tag>little-endian</tag>
        <tag>big-endian</tag>
      </tags>
  </entry>
  <entry>
    <title>c语言 file如何判断文件是否存在</title>
    <url>/2013/10/20/c-file-exist/</url>
    <content><![CDATA[c语言中如何判断文件是否存在 一般情况下，我们可以使用函数stat(), access() 和fopen()来检验文件是否存在，但是由于文件权限的问题，有时可能不像结果所言，可能不是因为文件不存在，而是没有打开的权限。
函数fopen通常情况下使用fopen主要用于读写文件，而我们就可以在这个上面做文章，通过以只读r的模式打开，如果失败，就是文件不存在咯。
FILE *fp;    fp=fopen(“file.txt” , “r”);    if ( fp == NULL )    printf(“file not exist!”);    else    fcolse(fp);

也可以写个子函数：
//存在返回0，不存在返回1    int file_exist(FILE *fo)    {    if(fopen(fp)==NULL)    return 1;    else    return 0;    }

函数access设计的子函数为：
int file_exists(char *filename){   return (access(filename, 0) == 0);}


access(filename, 0)0 表示判断文件是否存在finename 文件名称  ，mode 模式，共5种模式：     

0-检查文件是否存在        
1-检查文件是否可运行       
2-检查文件是否可写访问   
4-检查文件是否可读访问    
6-检查文件是否可读/写访问

注意，有的不适用数字表示，比如文件是否存在使用模式F_OK，类似的R_OK、W_OK和X_OK分别表示读写和可执行模式。
函数statstat函数可以获取文件的属性：
·表头文件:  #include &lt;sys/stat.h&gt;
·函数定义:  int stat(const char *file_name, struct stat *buf);
·函数说明:  通过文件名filename获取文件信息，并保存在buf所指的结构体stat中
·返回值: 执行成功则返回0，失败返回-1，错误代码存于errno（需要include &lt;errno.h&gt;）
因此如果文件存在，该函数将返回0，否则返回1。利用stat()函数来判断文件是否存在的代码如下：
int cfileexists(const char* filename){    struct stat buffer;    int exist = stat(filename,&amp;buffer);    if(exist == 0)        return 1;    else // -1        return 0;}

函数lstat与stat函数比较类似，除了在符号链接的时候有点小差别。
函数open对比与fopen，我们也可以使用open来判断文件的存在与否。
]]></content>
      <categories>
        <category>C</category>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>fopen</tag>
        <tag>access</tag>
        <tag>lstat</tag>
        <tag>stat</tag>
        <tag>open</tag>
      </tags>
  </entry>
  <entry>
    <title>C语言 gcc对文件扩展名的解释</title>
    <url>/2013/02/24/c-file-type/</url>
    <content><![CDATA[gcc对文件扩展名的解释
.c：c语言源代码
.cc：c++源代码
.i：预处理后的C源代码
.ii：预处理后的C++源代码
.S，.s：汇编语言源代码
.o：编译后的目标代码
.a，.so：编译后的库代码

]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>gcc</tag>
        <tag>cc</tag>
        <tag>i</tag>
        <tag>ii</tag>
        <tag>S</tag>
        <tag>o</tag>
        <tag>a</tag>
        <tag>so</tag>
      </tags>
  </entry>
  <entry>
    <title>c语言 使用FILE指针文件操作</title>
    <url>/2011/09/29/c-file/</url>
    <content><![CDATA[C使用FILE指针文件操作文件文件的基本概念所谓“文件”是指一组相关数据的有序集合。这个数据集有一个名称，叫做文件名。例如源程序文件、目标文件、可执行文件、库文件 (头文件)等。文件通常是驻留在外部介质(如磁盘等)上的，在使用时才调入内存中来。从不同的角度可对文件作不同的分类。
从用户的角度看，文件可分为普通文件和设备文件两种。
普通文件是指驻留在磁盘或其它外部介质上的一个有序数据集，可以是源文件、目标文件、可执行程序； 也可以是一组待输入处理的原始数据，或者是一组输出的结果。对于源文件、目标文件、可执行程序可以称作程序文件，对输入输出数据可称作数据文件。
设备文件是指与主机相联的各种外部设备，如显示器、打印机、键盘等。在操作系统中，把外部设备也看作是一个文件来进行管理，把它们的输入、输出等同于对磁盘文件的读和写。通常把显示器定义为标准输出文件，一般情况下在屏幕上显示有关信息就是向标准输出文件输出。如前面经常使用的printf, putchar 函数就是这类输出。键盘通常被指定标准的输入文件， 从键盘上输入就意味着从标准输入文件上输入数据。scanf, getchar函数就属于这类输入。
从文件编码的方式来看，文件可分为ASCII码文件和二进制码文件两种。
ASCII文件也称为文本文件，这种文件在磁盘中存放时每个字符对应一个字节，用于存放对应的ASCII码。例如，数5678的存储形式为：ASCII码： 　00110101 00110110 00110111 00111000                        ↓ 　　　　↓　　　　↓ 　　　↓十进制码：         5            6            7           8 共占用4个字节。ASCII码文件可在屏幕上按字符显示， 例如源程序文件就是ASCII文件，用DOS命令TYPE可显示文件的内容。 由于是按字符显示，因此能读懂文件内容。
二进制文件是按二进制的编码方式来存放文件的。 例如， 数5678的存储形式为： 00010110 00101110只占二个字节。二进制文件虽然也可在屏幕上显示，但其内容无法读懂。C系统在处理这些文件时，并不区分类型，都看成是字符流，按字节进行处理。输入输出字符流的开始和结束只由程序控制而不受物理符号(如回车符)的控制。 因此也把这种文件称作“流式文件”。
文件指针在Ｃ语言中用一个指针变量指向一个文件， 这个指针称为文件指针。通过文件指针就可对它所指的文件进行各种操作。定义说明文件指针的一般形式为： FILE* 指针变量标识符； 其中FILE应为大写，它实际上是由系统定义的一个结构，该结构中含有文件名、文件状态和文件当前位置等信息。 在编写源程序时不必关心FILE结构的细节。例如：FILE *fp；表示fp是指向FILE结构的指针变量，通过fp 即可找存放某个文件信息的结构变量，然后按结构变量提供的信息找到该文件，实施对文件的操作。习惯上也笼统地把fp称为指向一个文件的指针。文件在进行读写操作之前要先打开，使用完毕要关闭。所谓打开文件，实际上是建立文件的各种有关信息，并使文件指针指向该文件，以便进行其它操作。关闭文件则断开指针与文件之间的联系，也就禁止再对该文件进行操作。
在本章内将介绍主要的文件操作函数。
文件打开函数fopenfopen函数用来打开一个文件，其调用的一般形式为：文件指针名=fopen(文件名，使用文件方式) 其中，“文件指针名”必须是被说明为FILE 类型的指针变量，“文件名”是被打开文件的文件名。 “使用文件方式”是指文件的类型和操作要求。“文件名”是字符串常量或字符串数组。例如：
FILE *fp；fp=(“file a”,”r”);

其意义是在当前目录下打开文件file a， 只允许进行“读”操作，并使fp指向该文件。又如：
FILE *fphzkfphzk=(“c:test’,”rb”)

其意义是打开C驱动器磁盘的根目录下的文件test， 这是一个二进制文件，只允许按二进制方式进行读操作。两个反斜线“ ”中的第一个表示转义字符，第二个表示根目录。使用文件的方式共有12种，下面给出了它们的符号和意义。
文件使用方式的意义

“rt” ： 只读打开一个文本文件，只允许读数据
“wt” ：只写打开或建立一个文本文件，只允许写数据
“at” ：追加打开一个文本文件，并在文件末尾写数据
“rb” ：只读打开一个二进制文件，只允许读数据
“wb” ： 只写打开或建立一个二进制文件，只允许写数据
“ab” ：追加打开一个二进制文件，并在文件末尾写数据
“rt+” ： 读写打开一个文本文件，允许读和写
“wt+” ： 读写打开或建立一个文本文件，允许读写
“at+” ：读写打开一个文本文件，允许读，或在文件末追加数 据
“rb+” ： 读写打开一个二进制文件，允许读和写
“wb+” ：读写打开或建立一个二进制文件，允许读和写
“ab+” ：读写打开一个二进制文件，允许读，或在文件末追加数据

对于文件使用方式有以下几点说明：

文件使用方式由r,w,a,t,b，+六个字符拼成，各字符的含义是：


r(read): 读
w(write): 写
a(append): 追加
t(text): 文本文件，可省略不写
b(binary): 二进制文件
+: 读和写


凡用“r”打开一个文件时，该文件必须已经存在， 且只能从该文件读出。

用“w”打开的文件只能向该文件写入。 若打开的文件不存在，则以指定的文件名建立该文件，若打开的文件已经存在，则将该文件删去，重建一个新文件。

若要向一个已存在的文件追加新的信息，只能用“a ”方式打开文件。但此时该文件必须是存在的，否则将会出错。

在打开一个文件时，如果出错，fopen将返回一个空指针值NULL。在程序中可以用这一信息来判别是否完成打开文件的工作，并作相应的处理。因此常用以下程序段打开文件：


if((fp=fopen(“c:test”,”rb”)==NULL){      printf(“error on open c:test file!”);      getch();      exit(1);}

这段程序的意义是，如果返回的指针为空，表示不能打开C盘根目录下的test文件，则给出提示信息“error on open c: testfile!”，下一行getch()的功能是从键盘输入一个字符，但不在屏幕上显示。在这里，该行的作用是等待，只有当用户从键盘敲任一键时，程序才继续执行，因此用户可利用这个等待时间阅读出错提示。敲键后执行exit(1)退出程序。

把一个文本文件读入内存时，要将ASCII码转换成二进制码， 而把文件以文本方式写入磁盘时，也要把二进制码转换成ASCII码，因此文本文件的读写要花费较多的转换时间。对二进制文件的读写不存在这种转换。

标准输入文件(键盘)，标准输出文件(显示器 )，标准出错输出(出错信息)是由系统打开的，可直接使用。文件关闭函数fclose()文件一旦使用完毕，应用关闭文件函数把文件关闭，以避免文件的数据丢失等错误。


fclose函数调用的一般形式是： fclose(文件指针)； 例如：fclose(fp); 正常完成关闭文件操作时，fclose函数返回值为0。如返回非零值则表示有错误发生。文件的读写对文件的读和写是最常用的文件操作。
C语言中提供的多种文件读写的函数

·字符读写函数 ：fgetc和fputc
·字符串读写函数：fgets和fputs
·数据块读写函数：fread和fwrite
·格式化读写函数：fscanf和fprinf

.h。字符读写函数fgetc和fputc字符读写函数是以字符(字节)为单位的读写函数。 每次可从文件读出或向文件写入一个字符。
读字符函数FGETCfgetc函数的功能是从指定的文件中读一个字符，函数调用的形式为：字符变量=fgetc(文件指针)； 例如：ch=fgetc(fp);其意义是从打开的文件fp中读取一个字符并送入ch中。
　　对于fgetc函数的使用有以下几点说明：

在fgetc函数调用中，读取的文件必须是以读或读写方式打开的。

读取字符的结果也可以不向字符变量赋值，例如：fgetc(fp);但是读出的字符不能保存。

在文件内部有一个位置指针。用来指向文件的当前读写字节。在文件打开时，该指针总是指向文件的第一个字节。使用fgetc 函数后，该位置指针将向后移动一个字节。 因此可连续多次使用fgetc函数，读取多个字符。应注意文件指针和文件内部的位置指针不是一回事。文件指针是指向整个文件的，须在程序中定义说明，只要不重新赋值，文件指针的值是不变的。文件内部的位置指针用以指示文件内部的当前读写位置，每读写一次，该指针均向后移动，它不需在程序中定义说明，而是由系统自动设置的。


[例]读入文件test.c，在屏幕上输出。
#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;int main(){FILE *fp;char ch;if ((fp = fopen("test.c", "rt")) == NULL) {printf("Cannot open file strike any key exit!");getchar();exit(1);}ch = fgetc(fp);while (ch != EOF) {putchar(ch);ch = fgetc(fp);}fclose(fp);exit(0);}

本例程序的功能是从文件中逐个读取字符，在屏幕上显示。 程序定义了文件指针fp,以读文本文件方式打开文件“test.c”，并使fp指向该文件。如打开文件出错， 给出提示并退出程序。程序第12行先读出一个字符，然后进入循环，只要读出的字符不是文件结束标志(每个文件末有一结束标志EOF)就把该字符显示在屏幕上，再读入下一字符。每读一次，文件内部的位置指针向后移动一个字符，文件结束时，该指针指向EOF。执行本程序将显示整个文件。
写字符函数FPUTCfputc函数的功能是把一个字符写入指定的文件中，函数调用的 形式为： fputc(字符量，文件指针)； 其中，待写入的字符量可以是字符常量或变量，例如：fputc(‘a’,fp);其意义是把字符a写入fp所指向的文件中。
对于fputc函数的使用也要说明几点：

被写入的文件可以用、写、读写，追加方式打开，用写或读写方式打开一个已存在的文件时将清除原有的文件内容，写入字符从文件首开始。如需保留原有文件内容，希望写入的字符以文件末开始存放，必须以追加方式打开文件。被写入的文件若不存在，则创建该文件。

每写入一个字符，文件内部位置指针向后移动一个字节。

fputc函数有一个返回值，如写入成功则返回写入的字符， 否则返回一个EOF。可用此来判断写入是否成功。


[例]从键盘输入一行字符，写入一个文件， 再把该文件内容读出显示在屏幕上。
#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;int main(){FILE *fp;char ch;if((fp=fopen("string","wt+"))==NULL){printf("Cannot open file strike any key exit!");getchar();exit(1);}printf("input a string:");ch=getchar();while (ch!='n'){fputc(ch,fp);ch=getchar();}rewind(fp);ch=fgetc(fp);while(ch!=EOF){putchar(ch);ch=fgetc(fp);}printf("n");fclose(fp);}

　　程序中第6行以读写文本文件方式打开文件string。程序第13行从键盘读入一个字符后进入循环，当读入字符不为回车符时，则把该字符写入文件之中，然后继续从键盘读入下一字符。每输入一个字符，文件内部位置指针向后移动一个字节。写入完毕，该指针已指向文件末。如要把文件从头读出，须把指针移向文件头， 程序第19行rewind函数用于把fp所指文件的内部位置指针移到文件头。第20至25行用于读出文件中的一行内容。
[例]把命令行参数中的前一个文件名标识的文件， 复制到后一个文件名标识的文件中，如命令行中只有一个文件名则把该文件写到标准输出文件(显示器)中。
#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;int main(int argc,char *argv[]){FILE *fp1,*fp2;char ch;if(argc==1){printf("have not enter file name strike any key exit");getchar();exit(0);}if((fp1=fopen(argv[1],"rt"))==NULL){printf("Cannot open %s",argv[1]);getchar();exit(1);}if(argc==2)fp2=stdout;else if((fp2=fopen(argv[2],"wt+"))==NULL){printf("Cannot open %s",argv[1]);getchar();exit(1);}while((ch=fgetc(fp1))!=EOF)fputc(ch,fp2);fclose(fp1);fclose(fp2);}

本程序为带参的main函数。程序中定义了两个文件指针 fp1 和fp2，分别指向命令行参数中给出的文件。如命令行参数中没有给出文件名，则给出提示信息。程序第18行表示如果只给出一个文件名，则使fp2指向标准输出文件(即显示器)。程序第25行至28行用循环语句逐个读出文件1中的字符再送到文件2中。再次运行时，给出了一个文件名(由例10.2所建立的文件)，故输出给标准输出文件stdout，即在显示器上显示文件内容。第三次运行，给出了二个文件名，因此把string中的内容读出，写入到OK之中。可用 DOS命令type显示OK的内容。
字符串读写函数FGETS和FPUTS一、读字符串函数FGETS函数的功能是从指定的文件中读一个字符串到字符数组中，函数调用的形式为：fgets(字符数组名，n，文件指针)； 其中的n是一个正整数。表示从文件中读出的字符串不超过 n-1个字符。在读入的最后一个字符后加上串结束标志’ ‘。例如：fgets(str,n,fp);的意义是从fp所指的文件中读出n-1个字符送入字符数组str中。[例]从test.c文件中读入一个含10个字符的字符串。
#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;int main(){FILE *fp;char str[11];if ((fp = fopen("test.c", "rt")) == NULL) {printf("Cannot open file strike any key exit!");getchar();exit(1);}fgets(str, 11, fp);printf("%s", str);fclose(fp);exit(0);}

本例定义了一个字符数组str共11个字节，在以读文本文件方式打开文件e101.c后，从中读出10个字符送入str数组，在数组最后一个单元内将加上’ ‘，然后在屏幕上显示输出str数组。输出的十个字符正是例10.1程序的前十个字符。
对fgets函数有两点说明：

在读出n-1个字符之前，如遇到了换行符或EOF，则读出结束。
fgets函数也有返回值，其返回值是字符数组的首地址。

二、写字符串函数FPUTSfputs函数的功能是向指定的文件写入一个字符串，其调用形式为： fputs(字符串，文件指针) 其中字符串可以是字符串常量，也可以是字符数组名，或指针变量，例如：fputs(“abcd“，fp)；其意义是把字符串“abcd”写入fp所指的文件之中。
[例]在例10.2中建立的文件string中追加一个字符串。
#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;int main(){FILE *fp;char ch, st[20];if ((fp = fopen("string", "at+")) == NULL) {printf("Cannot open file strike any key exit!");getchar();exit(1);}printf("input a string:");scanf("%s", st);fputs(st, fp);rewind(fp);ch = fgetc(fp);while (ch != EOF) {putchar(ch);ch = fgetc(fp);}printf("");fclose(fp);exit(0);}

本例要求在string文件末加写字符串，因此，在程序第6行以追加读写文本文件的方式打开文件string 。 然后输入字符串，并用fputs函数把该串写入文件string。在程序15行用rewind函数把文件内部位置指针移到文件首。再进入循环逐个显示当前文件中的全部内容。
数据块读写函数FREAD和RWRITEＣ语言还提供了用于整块数据的读写函数。可用来读写一组数据，如一个数组元素，一个结构变量的值等。
读数据块函数调用的一般形式为：
fread(buffer,size,count,fp);
写数据块函数调用的一般形式为：
fwrite(buffer,size,count,fp);
其中buffer是一个指针，在fread函数中，它表示存放输入数据的首地址。在fwrite函数中，它表示存放输出数据的首地址。 size 表示数据块的字节数。count 表示要读写的数据块块数。fp 表示文件指针。例如：fread(fa,4,5,fp); 其意义是从fp所指的文件中，每次读4个字节(一个实数)送入实数组fa中，连续读5次，即读5个实数到fa中。[例]从键盘输入两个学生数据，写入一个文件中， 再读出这两个学生的数据显示在屏幕上。
#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;struct stu {char name[10];int num;int age;char addr[15];} boya[2], boyb[2], *pp, *qq;int main(){FILE *fp;char ch;int i;pp = boya;qq = boyb;if ((fp = fopen("stu_list", "wb+")) == NULL) {printf("Cannot open file strike any key exit!");getchar();exit(1);}printf("input data: name num age addressn");for (i = 0; i &lt; 2; i++, pp++)scanf("%s%d%d%s", pp-&gt;name, &amp;pp-&gt;num, &amp;pp-&gt;age, pp-&gt;addr);pp = boya;fwrite(pp, sizeof(struct stu), 2, fp);rewind(fp);fread(qq, sizeof(struct stu), 2, fp);printf("name number age addrn");for (i = 0; i &lt; 2; i++, qq++)printf("%s %5d %7d %sn", qq-&gt;name, qq-&gt;num, qq-&gt;age, qq-&gt;addr);fclose(fp);exit(0);}



本例程序定义了一个结构stu,说明了两个结构数组boya和 boyb以及两个结构指针变量pp和qq。pp指向boya,qq指向boyb。程序第16行以读写方式打开二进制文件“stu_list”，输入二个学生数据之后，写入该文件中， 然后把文件内部位置指针移到文件首，读出两块学生数据后，在屏幕上显示。
格式化读写函数FSCANF和FPRINTFfscanf函数，fprintf函数与前面使用的scanf和printf 函数的功能相似，都是格式化读写函数。 两者的区别在于 fscanf 函数和fprintf函数的读写对象不是键盘和显示器，而是磁盘文件。这两个函数的调用格式为：
fscanf(文件指针，格式字符串，输入表列)；
fprintf(文件指针，格式字符串，输出表列)；
例如：fscanf(fp,”%d%s”,&amp;i,s);fprintf(fp,”%d%c”,j,ch);
[例10.7]
#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;struct stu {char name[10];int num;int age;char addr[15];} boya[2], boyb[2], *pp, *qq;main(){FILE *fp;char ch;int i;pp = boya;qq = boyb;if ((fp = fopen("stu_list", "wb+")) == NULL) {printf("Cannot open file strike any key exit!");getchar();exit(1);}printf("input 2 groups datan");printf("nametnumtagetaddressn");for (i = 0; i &lt; 2; i++, pp++)scanf("%s%d%d%s", pp-&gt;name, &amp;pp-&gt;num, &amp;pp-&gt;age, pp-&gt;addr);pp = boya;for (i = 0; i &lt; 2; i++, pp++)fprintf(fp, "%s %d %d %s", pp-&gt;name, pp-&gt;num, pp-&gt;age,pp-&gt;addr);rewind(fp);for (i = 0; i &lt; 2; i++, qq++)fscanf(fp, "%s %d %d %s", qq-&gt;name, &amp;qq-&gt;num, &amp;qq-&gt;age,qq-&gt;addr);printf("name number age addrn");qq = boyb;for (i = 0; i &lt; 2; i++, qq++)printf("%s %5d %7d %sn", qq-&gt;name, qq-&gt;num, qq-&gt;age,qq-&gt;addr);fclose(fp);exit(0);}

本程序中fscanf和fprintf函数每次只能读写一个结构数组元素，因此采用了循环语句来读写全部数组元素。还要注意指针变量pp,qq由于循环改变了它们的值，因此在程序的25和32行分别对它们重新赋予了数组的首地址。
文件的随机读写前面介绍的对文件的读写方式都是顺序读写， 即读写文件只能从头开始，顺序读写各个数据。但在实际问题中常要求只读写文件中某一指定的部分。为了解决这个问题可移动文件内部的位置指针到需要读写的位置，再进行读写，这种读写称为随机读写。实现随机读写的关键是要按要求移动位置指针，这称为文件的定位。文件定位移动文件内部位置指针的函数主要有两个，即 rewind 函数和fseek函数。
rewind函数前面已多次使用过，其调用形式为：
rewind(文件指针)；
它的功能是把文件内部的位置指针移到文件首。
下面主要介绍fseek函数。
fseek函数用来移动文件内部位置指针，其调用形式为：
fseek(文件指针，位移量，起始点)；
其中：“文件指针”指向被移动的文件。 “位移量”表示移动的字节数，要求位移量是long型数据，以便在文件长度大于64KB 时不会出错。当用常量表示位移量时，要求加后缀“L”。“起始点”表示从何处开始计算位移量，规定的起始点有三种：文件首，当前位置和文件尾。其表示方法如表。
起始点 　　　表示符号 　　　数字表示──────────────────────────文件首 　　　SEEK—SET 0当前位置 　　SEEK—CUR 1文件末尾 　　SEEK—END 2例如：
fseek(fp,100L,0);其意义是把位置指针移到离文件首100个字节处。还要说明的是fseek函数一般用于二进制文件。在文本文件中由于要进行转换，故往往计算的位置会出现错误。文件的随机读写在移动位置指针之后，即可用前面介绍的任一种读写函数进行读写。由于一般是读写一个数据据块，因此常用fread和fwrite函数。下面用例题来说明文件的随机读写。
[例]在学生文件stu list中读出第二个学生的数据。
#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;struct stu {char name[10];int num;int age;char addr[15];} boy, *qq;main(){FILE *fp;char ch;int i = 1;qq = &amp;boy;if ((fp = fopen("stu_list", "rb")) == NULL) {printf("Cannot open file strike any key exit!");getchar();exit(1);}rewind(fp);fseek(fp, i * sizeof(struct stu), 0);fread(qq, sizeof(struct stu), 1, fp);printf("name number age addrn");printf("%s %5d %7d %s", qq-&gt;name, qq-&gt;num, qq-&gt;age, qq-&gt;addr);exit(0);}

本程序用随机读出的方法读出第二个学生的数据。程序中定义boy为stu类型变量，qq为指向boy 的指针。以读二进制文件方式打开文件，程序第22行移动文件位置指针。其中的i值为1，表示从文件头开始，移动一个stu类型的长度，然后再读出的数据即为第二个学生的数据。
文件检测函数C语言中常用的文件检测函数有以下几个一、文件结束检测函数feof函数调用格式： feof(文件指针)；功能：判断文件是否处于文件结束位置，如文件结束，则返回值为1，否则为0。
二、读写文件出错检测函数ferror函数调用格式： ferror(文件指针)；功能：检查文件在用各种输入输出函数进行读写时是否出错。 如ferror返回值为0表示未出错，否则表示有错。
三、文件出错标志和文件结束标志置0函数clearerr函数调用格式： clearerr(文件指针);功能：本函数用于清除出错标志和文件结束标志，使它们为0值。
]]></content>
      <categories>
        <category>C</category>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>fopen</tag>
        <tag>fclose</tag>
        <tag>fgetc</tag>
        <tag>fputc</tag>
        <tag>FILE</tag>
        <tag>fscanf</tag>
        <tag>fseek</tag>
      </tags>
  </entry>
  <entry>
    <title>c语言 file如何判断文件是否存在</title>
    <url>/2013/03/19/c-function/</url>
    <content><![CDATA[函数指针void func(int a,int b , int (*func2)(int x, int y));

函数指针function pointer通常应用于菜单驱动的系统中。系统提示用户从菜单中选择一种操作，每个选项的操作都是由不同过的函数来完成的。指向每个函数的指针就存储在一个指针数组中。用户的选择将作为数组的下标，并且数组中的指针被用于调用相应的函数。
#include &lt;stdio.h&gt;void function1(int a, int b);void function2(int a, int b);void function3(int a, int b);int main(void){       void (*f[3])(int ,int) = {function1,function2,function3};       int choice;       printf("Enter a number between 0 and 2, 3 to end:");       scanf("%d",&amp;choice);       while(choice &gt;= 0 &amp;&amp; choice &lt; 3)              {              (*f[choice])(choice);              printf("Enter a number between 0 and 2, 3 to end:");              scanf("%d",&amp;choice);       }       printf("Program execution completed.\n");       return 0;}void function1(int a, int b){       printf("You are now using function1");}void function2(int a, int b){       printf("You are now using function1");}void function3(int a, int b){       printf("You are now using function1");}
]]></content>
      <categories>
        <category>C</category>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>pointer</tag>
      </tags>
  </entry>
  <entry>
    <title>C  递归和迭代</title>
    <url>/2013/04/18/c-iteration/</url>
    <content><![CDATA[递归和迭代
迭代基于循环结构；
递归基于选择结构
迭代是显式地使用一个循环结构
递归通过重复地进行函数调用来实现循环
迭代总是不断地改变计数器变量直至它的值使得循环继续条件为假
递归总是不断地将问题的规模逐渐变小直至到达基线条件
递归有很多负面作用，递归需要不断地执行函数调用机制，因此，产生很大的函数调用开销，从而在处理器的时间和存储器的空间两方面导致很大的开销。由于每次递归调用都要创建函数的一个副本，这是很耗费存储器的。

迭代通常都是发生在一个函数内部，所以反复执行函数调用机构的开销和额外占用的存储器空间基本上可以忽略不计。
]]></content>
      <categories>
        <category>C</category>
        <category>C++</category>
      </categories>
      <tags>
        <tag>iteration</tag>
        <tag>recursion</tag>
      </tags>
  </entry>
  <entry>
    <title>c语言 漫谈C语言及如何学习C语言</title>
    <url>/2013/03/02/c-learn-methods/</url>
    <content><![CDATA[C语言学习方法参考 http://sunxiunan.com/?p=1661sunxiunan
C语言学习顺序：阅读参考书，阅读代码，编写调试实际程序，上网参与讨论，研究高级话题。
1，参考书籍
《The C Programming Language》 如果你只想买一本书学习C语言，只需要买这一本就够了。用三个词语来形容它就是：经典！经典！经典！这本薄薄的只有二百多页的小书涵盖了C语言的方方面面，前无古人而且后无来者，任何溢美之词都不足以形容它。
《C程序设计语言（第2版·新版）》这是K&amp;R的中文译本，可以先从中文译本看起，然后再读一遍英文原版，既可以学习英文，又可以体会原文那种简约优美的风格。
《C陷阱与缺陷》 《C专家编程》 这两本书也是学习及使用C语言的朋友必备的两本书，比如《C专家编程》，专门用两三个章节详细介绍C语言中数组与指针的不同之处，这两本书在某种程度上算是对K&amp;R略过的地方做了详细补充，强烈推荐。
《C语言参考手册》可以看作是C语言编程的《新华字典》，全面而权威。里面还涵盖了C99的内容，紧跟时代潮流。
《C和指针》 指针的重要性如何，学过C语言（或者C++）的朋友都知道，这本书更是把指针拔高到了与C语言平起平坐的地位，其实也是从头开始介绍，作为教学参考书也是可以的。
《C标准库》 这本书是专门介绍C语言的标准库如何实现的，比如malloc算法，用标准的C语言该如何写？strlen这个函数应该如何实现？尽管书中不少代码与真实的C标准库相差很多（由于标准库需要考虑性能优化，很多函数有一些特定的trick），但是绝对值得参考。
《你必须知道的495个C语言问题》 这本书其实就是C-FAQ的印刷版本，C-FAQ在各种编程语言的FAQ中可以称得上质量一流。如果你想应聘或者招聘C语言相关程序员，这本书一定要参考。
《Linux C编程一站式学习》 这本书是基于特定操作系统Linux来介绍C语言编程，可作为计算机相关专业的教科书或入门参考书，也是书单里面唯一一本国人原创的编程书籍，非常难得。书中几乎所有内容都在网上直接公开，针对读者的意见进行修改，这也是非常难得的一种开放态度。非常推荐大家买一本。

学习C语言，一定不能只读书，应该动手练习完成书里面的项目需求（比如编写一个目录浏览器）以及每章的练习题目。这就需要有可以实验的环境，下面针对不同操作系统简单做一下介绍。
2，开发环境Windows系统下推荐大家使用Code::blocks这个软件。这个软件最大优点是自带了基于mingw的GCC以及GDB，只要下载70M左右软件包，就可以完整支持C++、C语言编程了。各种功能（比如调试功能）也很强大，版本更新也比较快。注意下载选择名字有mingw的文件，比如最新版本是codeblocks-10.05mingw-setup.exe（版本也许有所不同）。
主页：http://www.codeblocks.org/
另外推荐codelite，相比codeblock，这个更新的更频繁一些。也支持各种比较有用的插件、调试特性、WX等等。
主页 http://codelite.org/
如果需要做Windows操作系统的开发，可以下载Visual C++ 2010 Express。
因为Code::Blocks不包含Windows编程头文件（实际是因为没有Windows SDK），无法编写Windows操作系统相关的界面应用程序或者服务类程序。而VC++Express自带了这些头文件以及编程库，虽然功能稍微简陋，但对于练习使用基本够用。
主页：http://www.microsoft.com/express/windows/
对于计算机专业的学生朋友，建议大家使用Linux操作系统，或者更详细一点是使用Xubuntu操作系统作为桌面，使用Netbeans和GCC这个组合（当然也可以选择Code::Blocks）。在Xubuntu下可以通过apt-get install build-essential这个命令安装gcc相关程序，已经可以在Terminal下编译C语言程序了，但为了使用方便，大家可以选择Netbeans的C++支持包，在Netbeans网站上就能下载。
主页：http://netbeans.org/features/cpp/index.html
如果使用苹果Mac系统，毫无疑问XCode就是编程的绝佳选择，XCode可以在苹果开发者网站上免费下载，在IPhone SDK中也包含了XCode。
主页：http://developer.apple.com/technologies/tools/xcode.html
如果手头没有合适的编程环境，还需要实验一些简单的代码，可以用http://codepad.org/提供的服务，在线编写运行代码。
另外建议大家申请一个github.com的账号，在gist.github.com可以保存自己的练习代码，就不需要随身带着U盘了。
C语言编程电子书及教程：
http://publications.gbdirect.co.uk/c_book/ 这一本写的非常详细，你可以把它看成是类似谭浩强版的教科书。
http://www.knosof.co.uk/cbook/cbook.html 这一本云风曾经推荐过，相当深入的介绍了C99标准，深入细节时候需要读读。
http://www.duckware.com/bugfreec/index.html 这本书在网上流传一个中文版本，《编写优化、高效、无错地代码》，另外也有英文影印版《编程精粹》。
http://wangcong.org/blog/?page_id=196 作者王聪，也是相当hard geek，从两个样章看，包含了相当多的内容。
《C语言深度解剖》这本可以在百度文库或google搜到，可以读读，有些参考性。
《C标准和实现》作者姚新颜，他的《深度探索C、C++》算是当年比较有深度的书籍，可惜已经绝版了。这本书也可以在百度文库搜到。这本书也比较值得读。
良葛格C语言学习笔记 http://caterpillar.onlyfun.net/Gossip/CGossip/CGossip.html
C与C++的兼容性问题 http://en.wikipedia.org/wiki/Compatibility_of_C_and_C%2B%2B
另一个文档关于C与C++标准兼容性问题：http://david.tribble.com/text/cdiffs.htm
《C Elements of Style》http://www.oualline.com/books.free/style/index.html
《Linux安全编程》http://www.dwheeler.com/secure-programs/
《C Craft》电子版 http://crypto.stanford.edu/~blynn/c/
《The function pointer tutorials》函数指针教程。http://www.newty.de/fpt/index.html
C语言编程及Unix系统调用，想用C在Unix或者Linux编程的朋友可以参考。http://www.cs.cf.ac.uk/Dave/C/
优化C、C++代码http://www.eventhelix.com/RealtimeMantra/Basics/OptimizingCAndCPPCode.htm
图文并茂介绍C语言的指针 http://boredzo.org/pointers/
另外一篇介绍C语言优化的文章 http://www.prism.uvsq.fr/~cedb/local_copies/lee.html
一个C语言教学ppt http://www.slideshare.net/petdance/just-enough-c-for-open-source-programmers
一些Unix下C语言编程相关的文章 http://users.actcom.co.il/~choo/lupg/tutorials/index.html
Unix下如何建立静态、动态C语言函数库 http://users.actcom.co.il/~choo/lupg/tutorials/libraries/unix-c-libraries.html
如何使用GDB http://users.actcom.co.il/~choo/lupg/tutorials/debugging/debugging-with-gdb.html
一些C语言编程技巧 http://users.bestweb.net/~ctips/
Advanced C programming，高级C语言编程，可以提高水平，非常有帮助http://www.mpi-inf.mpg.de/departments/rg1/teaching/advancedc-ws08/literature.html
C语言问答，这些题目也可用于面试 http://www.gowrikumar.com/c/

]]></content>
      <categories>
        <category>C</category>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>gcc</tag>
        <tag>codeblocks</tag>
        <tag>codelite</tag>
        <tag>gdb</tag>
        <tag>netbeans</tag>
      </tags>
  </entry>
  <entry>
    <title>C语言 Makefile</title>
    <url>/2011/01/27/c-makefile/</url>
    <content><![CDATA[强大且复杂的Makefile做为可以构建大型应用程序的Makefile，也是程序编译中无法迈过去的坎。
如果说源代码是一道菜，那么Makefile可以是一个菜谱，如何呈现给最后的用户，也是Makefile要做的工作。
我们的程序只有一个文件，OK，直接命令行就可以搞定了，不过如果有成千上万行的代码，那么该如何进行编译，如何先编译，如何后编译，包括那些文件需要编译，这些就可以交给Makefile了。
Linux下的程序员如果不会使用GNU make来构建程序和工程，应该不能算作一个合格的程序员，😄。
而对于Makefile而言，一个命令就可以完成构建一个极其复杂的工作，后续随着深入，同步更新Makefile，做为后续程序编译的工具。
上一篇使用gcc来完成编译，这里改为Makefile。
helloworld : helloworld.c	gcc -o helloworld helloworld.c

这个时候只要输入make就可以生成helloworld可执行程序了。
]]></content>
      <categories>
        <category>C</category>
        <category>Makefile</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>linux</tag>
        <tag>makefile</tag>
      </tags>
  </entry>
  <entry>
    <title>C语言 left value左值</title>
    <url>/2013/03/21/c-left-value/</url>
    <content><![CDATA[左值 左值并不完全表示“可以赋值的东西”，更好的定义为：（在内存中）有特定位置的东西。所以，如果没有+1，就要特别注意了。
]]></content>
      <categories>
        <category>C</category>
        <category>C++</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>c++</tag>
      </tags>
  </entry>
  <entry>
    <title>C语言 malloc的使用</title>
    <url>/2013/01/18/c-malloc/</url>
    <content><![CDATA[malloc的使用strlen求出的值没有计入串结尾的‘\ 0’字符，而strcpy却将复制它。所以这里分配的空间实际上是不够的，这将使strcpy的写入超过所分配空间的界限。习惯写法是：
p = malloc(strlen(buf) + 1);strcpy(p, buf);

所以，如果没有+1，就要特别注意了。
]]></content>
      <categories>
        <category>C</category>
        <category>C++</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>c++</tag>
        <tag>malloc</tag>
      </tags>
  </entry>
  <entry>
    <title>C语言 memcpy和strcpy比较</title>
    <url>/2013/03/22/c-memcpy/</url>
    <content><![CDATA[memcpy和strcpy比较函数memcpy比函数strcpy速度不会慢：

函数memcpy是按照机器的字长来拷贝的，现在主要是4字节；
strcpy是单个字节拷贝的；
memcpy函数被优化过；
strcpy有个限制就是遇到’\0’就结束


Mark：当涉及到的两个对象在内存中如果是相互重叠的，则函数memcpy的执行结果是没有意义的，此时应该使用函数memmove。

]]></content>
      <categories>
        <category>C</category>
        <category>C++</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>c++</tag>
        <tag>memcpy</tag>
        <tag>strcpy</tag>
        <tag>memmove</tag>
      </tags>
  </entry>
  <entry>
    <title>C语言 memory释放内存</title>
    <url>/2013/03/24/c-memory/</url>
    <content><![CDATA[释放内存Linux采取的是最快速操作，就算程序关闭掉，为了后面的可能会用的概率而保证这些数据可能还位于内存中，所以导致4G的内存，随便跑跑程序就到了3.6G了，只剩下几百兆，就算是很大的内存也是如此，我一个同事用的是24G的内存，跑网络程序，随便一跑就到了20多G，这里有个比较简单的释放内存的方法：
syncecho 3 &gt; /proc/sys/vm/drop-cache

这样就会释放出很大一部分的内存，但是可能对于网络数据的接收发送有影响，对于实时收发的程序，可以在程序中采取一定的策略。
]]></content>
      <categories>
        <category>C</category>
        <category>C++</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>c++</tag>
        <tag>memory</tag>
        <tag>sync</tag>
        <tag>echo</tag>
      </tags>
  </entry>
  <entry>
    <title>c语言 Linux下的off_t类型</title>
    <url>/2014/09/29/c-off_t/</url>
    <content><![CDATA[Linux下的off_t类型off_t类型用于指示文件的偏移量，常就是long类型，其默认为一个32位的整数，在gcc编译中会被编译为long int类型，在64位的Linux系统中则会被编译为long long int，这是一个64位的整数，其定义在unistd.h头文件中可以查看。
# ifndef __off_t_defined#  ifndef __USE_FILE_OFFSET64 typedef __off_t off_t; #  else typedef __off64_t off_t; #  endif #  define __off_t_defined # endif # if defined __USE_LARGEFILE64 &amp;&amp; !defined __off64_t_defined typedef __off64_t off64_t; #  define __off64_t_defined # endif



]]></content>
      <categories>
        <category>C</category>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>unistd</tag>
        <tag>off_t</tag>
      </tags>
  </entry>
  <entry>
    <title>C 集锦 一分钟看完C运算符</title>
    <url>/2012/02/03/c-operator-summary/</url>
    <content><![CDATA[C 集锦 一分钟看完C运算符发了6篇关于C运算符的小知识，总结一下，而且真的，关于运算符的几个总结，1分钟确实读完。
其实对于C语言而言，入门其实相对而言还是比较简单的，因为他的短小精悍，可有可无的坚决不增加，掌握了基础知识就可以说是入门了，但是做到精通就比较困难了，这就需要在学习之外的实战了。
对于所有程序里面的运算符而言，熟练掌握这些就没有问题了。

 C语言 按位运算符
 C语言 赋值运算符
 C语言 数据运算符
 C语言 加减乘除运算符
 C语言 测试等值运算符
 C语言 逻辑运算符

]]></content>
      <categories>
        <category>C</category>
        <category>集锦</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>operator</tag>
      </tags>
  </entry>
  <entry>
    <title>C语言 操作符和表达式</title>
    <url>/2012/02/21/c-operator/</url>
    <content><![CDATA[操作符和表达式C提供了所有你希望编程语言应该拥有的操作符，它甚至提供了一些你意想不到的操作符，比如三元操作符?:，正是因为它品种繁多的操作符，使得C语言很难精通。但是另一方面，C的许多操作符具有其他语言的操作符无法抗衡的价值。
移位操作符对于左移操作符都是添0来补齐的，但是对右移操作符而言，特别是对于有符号的数据而言，使用逻辑移位（左边的位用0来填充）或者算术移位（左边的位用符号位来填充）由编译器决定。
赋值对于表达式a=x=y+3；而言，说a等于x是不对的，比如如果x是int型的，而a是char型的，a就会把x截断。
复合赋值符比如+=、-=，增加这些的意义为：K&amp;R C设计者认为复合赋值符可以让程序员把代码写的更清楚一些。比如对于a[2*(y-6f(x))] = a[2(y-6f(x))] + 1，这样的式子可以写为a[2(y-6*f(x))] += 1，并且f的下标也只需访问一次，提高的速度。
单目操作符单目运算符sizeof对于变量可以不加括号，对于类似int这样的类型，必须加上括号。
注意，对于++和—这样的前置或后置增值运算符，操作的是复制了该变量的一份拷贝而已。
逻辑操作符这里比较帅的一个特性是短路求值short-circuited evaluation，工作原理如下，&amp;&amp;操作符的左操作数总是首先进行求值，如果它的结果为真，然后就紧接着对右操作符进行求值；但是，如果左操作数的值为假，那么右操作数便不再进行求值。对于||也是同理。注意这里不要把逻辑操作符和位操作符搞混淆。逻辑操作符用于测试零值和非零值，而位操作符用于比较它们的操作数中对应的位。
条件操作符expression1 ? expression2 : expression3：首先计算expression1，如果值为真，那么整个表达式的值就是expression2的值，expression3不会进行求值。但是如果expression1的值为假，那么整个语句的值就是expression3的值，expression2不会进行求值。条件操作符也可以长生简洁的代码，并且可以产生较小的目标代码。
逗号操作符逗号操作符将两个或多个表达式分割开来，这些表达式自左向右逐个进行求值，整个逗号表达式的值就是最后那个表达式的值。
下标引用、函数调用和结构成员.和-&gt;操作符用于访问一个结构的成员，如果s是个结构变量，那么s.a就访问s中名叫a的成员；当你拥有一个指向结构的指针而不是结构本身，切欲访问它的成员时，就需要使用-&gt;操作符而不是.。
布尔值C并不具备显式的布尔类型，所以使用整数来代替，其规则是：零是假，任何非零值均为真。但是，也并没有说1这个值比其他的非零值更真。所以对不是0的值最好不要进行比较哟。
左值和右值左值就是那些能够出现在赋值符号左边的东西，右值就是那些可以出现在赋值符号右边的东西。左值标示了一个可以存储结果值的地点；右值指定了一个值；所以，使用右值的地方可以使用左值，但是使用左值的地方不能使用右值。
*操作符：当它作为左值使用时，这个表达式就指定需要进行修改的位置，当它作为右值使用时，它就提取当前存储于这个位置的值。
表达式求值C的整型算术运算总是至少以缺省整型类型的精度来计算，所以对于char a，b，c；c=a+b；其中的a、b、c都是按照int来计算的。OMG， 这个我还真是第一次知道。
操作符的属性复杂表达式的求值顺序是由3个因素决定的：操作符的优先级、操作符的结合性以及操作符是否控制执行的顺序。
总结
有符号值的右移位操作是不可移植的；
在不同的用于表示布尔值的非零值之间不要比较；
不要编写结果依赖于求值顺序的表达式。

]]></content>
      <categories>
        <category>C</category>
        <category>C++</category>
      </categories>
      <tags>
        <tag>char</tag>
        <tag>sizeof</tag>
      </tags>
  </entry>
  <entry>
    <title>C语言 实参和形参</title>
    <url>/2012/02/06/c-parameter/</url>
    <content><![CDATA[实参和形参形参出现在函数定义中，在整个函数体内都可以使用，离开该函数则不能使用。
实参出现在主调函数中，进入被调函数后，实参变量也不能使用。
形参和实参的功能是作数据传送。发生函数调用时， 主调函数把实参的值传送给被调函数的形参从而实现主调函数向被调函数的数据传送。

形参变量只有在被调用时才分配内存单元，在调用结束时， 即刻释放所分配的内存单元。因此，形参只有在函数内部有效。 函数调用结束返回主调函数后则不能再使用该形参变量。
实参可以是常量、变量、表达式、函数等， 无论实参是何种类型的量，在进行函数调用时，它们都必须具有确定的值， 以便把这些值传送给形参。 因此应预先用赋值，输入等办法使实参获得确定值。
实参和形参在数量上，类型上，顺序上应严格一致， 否则会发生“类型不匹配”的错误。
函数调用中发生的数据传送是单向的。 即只能把实参的值传送给形参，而不能把形参的值反向地传送给实参。 因此在函数调用过程中，形参的值发生改变，而实参中的值不会变化。

]]></content>
      <categories>
        <category>C</category>
        <category>C++</category>
      </categories>
      <tags>
        <tag>real paramter</tag>
        <tag>实参</tag>
        <tag>形参</tag>
      </tags>
  </entry>
  <entry>
    <title>C语言 pseudocode 伪码</title>
    <url>/2013/01/24/c-pseudocode/</url>
    <content><![CDATA[pseudocode 伪码
伪码pseudocode是一种人工的、非正式的辅助人们尽心该算法设计的语言；
伪码与我们日常使用的英语极为类似，虽然伪码不是一种真正的计算机程序设计语言，但是它易学、易懂，书写方便；
伪码不能在计算机上执行，只是帮助我们在用计算机程序设计语言编写程序前“思考”程序应该如何设计；
伪码只包含字符，所以可以很方便地用一个文本编辑器来编辑伪码程序；
精心设计的伪码很容易转换为相应的C程序；
伪码程序只包含关于“行为语句”的语句—指那些当伪码转换为C程序后，在C程序中执行的那些操作。对于变量定义，它不是行为语句，只是程序员想传递给编译器的信息，可以不用出现在伪码中；
有些程序员会在伪码的开始处列出所有的变量，并简要说明其目的；

]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>pseudocode</tag>
      </tags>
  </entry>
  <entry>
    <title>C语言 read/write系统调用</title>
    <url>/2011/10/24/c-read/</url>
    <content><![CDATA[read系统调用用法：
#include &lt;unistd.h&gt; ssize_t read(int fd,void *buf,size_t nbyte) 
read函数是负责从fd中读取内容.成功时,read返回实际所读的字节数,如果返回的值是0,表示已经读到文件的结束了.小于0表示出现了错误.如果错误为EINTR说明读是由中断引起的, 如果是ECONNREST表示网络连接出了问题.
#include &lt;unistd.h&gt; ssize_t write(int fd,const void *buf,size_t nbytes) 



write函数将buf中的nbytes字节内容写入文件描述符fd.成功时返回写的字节数.失败时返回-1. 并设置errno变量. 在网络程序中,当我们向套接字文件描述符写时有俩种可能.1)write的返回值大于0,表示写了部分或者是全部的数据.2)返回的值小于0,此时出现了错误.我们要根据错误类型来处理.  如果错误为EINTR表示在写的时候出现了中断错误.如果为EPIPE表示网络连接出现了问题(对方已经关闭了连接).
]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>read</tag>
        <tag>write</tag>
      </tags>
  </entry>
  <entry>
    <title>C语言 recv/recvfrom/recvmsg系统调用</title>
    <url>/2013/10/24/c-recv/</url>
    <content><![CDATA[recv/recvfrom/recvmsg系统调用功能描述：
从套接字上接收一个消息。对于recvfrom 和 recvmsg，可同时应用于面向连接的和无连接的套接字。recv一般只用在面向连接的套接字，几乎等同于recvfrom，只要将recvfrom的第五个参数设置NULL。如果消息太大，无法完整存放在所提供的缓冲区，根据不同的套接字，多余的字节会丢弃。假如套接字上没有消息可以读取，除了套接字已被设置为非阻塞模式，否则接收调用会等待消息的到来。
用法：
#include &lt;sys/types.h&gt;#include &lt;sys/socket.h&gt;ssize_t recv(int sock, void *buf, size_t len, int flags);ssize_t recvfrom(int sock, void *buf, size_t len, int flags,     struct sockaddr *from, socklen_t *fromlen);ssize_t recvmsg(int sock, struct msghdr *msg, int flags);
参数：sock：索引将要从其接收数据的套接字。buf：存放消息接收后的缓冲区。len：buf所指缓冲区的容量。flags：是以下一个或者多个标志的组合体，可通过or操作连在一起MSG_DONTWAIT：操作不会被阻塞。MSG_ERRQUEUE： 指示应该从套接字的错误队列上接收错误值，依据不同的协议，错误值以某种辅佐性消息的方式传递进来， 使用者应该提供足够大的缓冲区。导致错误的原封包通过msg_iovec作为一般的数据来传递。导致错误的数据报原目标地址作为msg_name被提供。 错误以sock_extended_err结构形态被使用，定义如下
#define SO_EE_ORIGIN_NONE    0#define SO_EE_ORIGIN_LOCAL   1#define SO_EE_ORIGIN_ICMP    2#define SO_EE_ORIGIN_ICMP6   3struct sock_extended_err{    u_int32_t ee_errno;   /* error number */    u_int8_t ee_origin; /* where the error originated */    u_int8_t ee_type;    /* type */    u_int8_t ee_code;    /* code */    u_int8_t ee_pad;    u_int32_t ee_info;    /* additional information */    u_int32_t ee_data;    /* other data */    /* More data may follow */};
MSG_PEEK：指示数据接收后，在接收队列中保留原数据，不将其删除，随后的读操作还可以接收相同的数据。MSG_TRUNC：返回封包的实际长度，即使它比所提供的缓冲区更长， 只对packet套接字有效。MSG_WAITALL：要求阻塞操作，直到请求得到完整的满足。然而，如果捕捉到信号，错误或者连接断开发生，或者下次被接收的数据类型不同，仍会返回少于请求量的数据。MSG_EOR：指示记录的结束，返回的数据完成一个记录。MSG_TRUNC：指明数据报尾部数据已被丢弃，因为它比所提供的缓冲区需要更多的空间。MSG_CTRUNC：指明由于缓冲区空间不足，一些控制数据已被丢弃。MSG_OOB：指示接收到out-of-band数据(即需要优先处理的数据)。MSG_ERRQUEUE：指示除了来自套接字错误队列的错误外，没有接收到其它数据。from：指向存放对端地址的区域，如果为NULL，不储存对端地址。fromlen：作为入口参数，指向存放表示from最大容量的内存单元。作为出口参数，指向存放表示from实际长度的内存单元。msg：指向存放进入消息头的内存缓冲，结构形态如下
struct msghdr {    void         *msg_name;       /* optional address */    socklen_t     msg_namelen;    /* size of address */    struct iovec *msg_iov;        /* scatter/gather array */    size_t        msg_iovlen;     /* # elements in msg_iov */    void         *msg_control;    /* ancillary data, see below */    socklen_t     msg_controllen; /* ancillary data buffer len */    int           msg_flags;      /* flags on received message */};

可能用到的数据结构有
struct cmsghdr {    socklen_t cmsg_len;     /* data byte count, including hdr */    int       cmsg_level;   /* originating protocol */    int       cmsg_type;    /* protocol-specific type */    /* followed by    u_char    cmsg_data[]; */};

返回说明：成功执行时，返回接收到的字节数。另一端已关闭则返回0。失败返回-1，errno被设为以下的某个值EAGAIN：套接字已标记为非阻塞，而接收操作被阻塞或者接收超时EBADF：sock不是有效的描述词ECONNREFUSE：远程主机阻绝网络连接EFAULT：内存空间访问出错EINTR：操作被信号中断EINVAL：参数无效ENOMEM：内存不足ENOTCONN：与面向连接关联的套接字尚未被连接上ENOTSOCK：sock索引的不是套接字
]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>recv</tag>
        <tag>recvfrom</tag>
        <tag>recvmsg</tag>
        <tag>TCP</tag>
        <tag>UDP</tag>
      </tags>
  </entry>
  <entry>
    <title>C语言 怎样从函数返回多个值</title>
    <url>/2013/03/24/c-return-many-values/</url>
    <content><![CDATA[怎样从函数返回多个值有下面几种方法用于返回从函数返回多个值

传入多个指针指向不同的地址，让函数填入需要返回的值
让函数返回包含需要值的结构
结合指针和结构，让函数接收结构指针，然后再填入需要的数据
不得已的时候，可以使用全局变量，但是这个方法不推荐，GOD晓得有没有可能在多线程的其他程序中会修改全局变量，所以这是迫不得已时采用的方法。

]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>return</tag>
        <tag>struct</tag>
        <tag>functions</tag>
      </tags>
  </entry>
  <entry>
    <title>C语言 sizeof和strlen的区别</title>
    <url>/2013/03/08/c-sizeof-strlen/</url>
    <content><![CDATA[sizeof和strlen的区别sizeof函数返回的是变量声明后所占的内存数，不是实际长度；
sizeof是一个编译时执行的运算符，所以它不会导致额外的运行时开销。
strlen函数求的是字符串的实际长度;
]]></content>
      <categories>
        <category>C</category>
        <category>C++</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>c++</tag>
        <tag>sizeof</tag>
        <tag>strlen</tag>
      </tags>
  </entry>
  <entry>
    <title>C语言 segment fault</title>
    <url>/2013/04/16/c-segment-fault/</url>
    <content><![CDATA[no segmentation fault does not means program code is fine 分配页策略，no segmentation fault does not means program code is fine
​       The OS will not allocate partial pages to a program。So some illegal access may not cause some error info. The reason are：
​       操作系统不会将不完整的页分配给程序，例如，如果要运行的程序总共大约有10000字节，如果完全加载，会占用3个内存页（一个页占4096个字节），它不会仅占用2.5个页，因为页是虚拟内存系统能够操作的最小内存单元，这是调试时要着重了解的情况，这也导致了程序的一些错误内存访问不会触发段错误，换言之，在调试会话期间，没有引起段错误并不能直接说明代码是没有问题的。
]]></content>
      <categories>
        <category>C</category>
        <category>C++</category>
      </categories>
      <tags>
        <tag>segmenta fault</tag>
        <tag>page</tag>
      </tags>
  </entry>
  <entry>
    <title>C语言 标准函数库</title>
    <url>/2012/03/04/c-standard-library/</url>
    <content><![CDATA[标准函数库算术求商和余数的函数div。
字符串转换函数atoi和atol执行基数为10的转换；
而函数strtol和strtoul允许你在转化时指定基数，同时还允许访问字符串的剩余部分。
浮点表示形式函数modf把一个浮点值分成整数和小数两个部分。
非本地跳转setjmp和longjmp函数提供了一种类似goto语句的机制，但它并不局限于一个函数的作用域之内。这些函数常用于深层嵌套的函数调用链。
信号信号表示一种事件，它可能异步地发生，也就是并不予程序执行过程的任何时间同步。
信号处理函数由于信号可能在任何时候发生，所以由信号处理函数修改的变量的值可能会在任何时候发生改变。因此，我们不能指望这些变量在两条相邻的程序语句中肯定具有相同的值。volatile关键字告诉编译器这个事实，防止它以一种可能修改程序含义的方式“优化”程序。
通常情况下，上面的程序会认为第二个测试和第一个测试具有相同的结果
而如果把变量value声明为volatile类型的，就不会进行此类优化。有时，如果不用volatile修饰符，可能无法编写多线程程序，要么编译器失去大量优化的机会。
终止执行
abort函数用于不正常地终止一个正在执行的程序；
atexit函数可以把一些函数注册为退出函数exit function；
exit函数用于正常终止程序；

断言宏assert(test)用于检测test是否为真。用这种方法可以使调试变得更容易。并且我们可以在头文件assert.h被包含之前，添加#define NDEBUG皆可以禁用所有的断言。总结

frexp和ldexp函数在创建与机器无关的浮点数表示形式方面是很有用的。frexp函数用于计算一个给定值的表示形式；ldexp函数用于解释一个表示形式，恢复它的原先值；
qsort函数把一个数组中的值按照升序进行排序；
bsearch函数用于在一个已经排好序的数组中用二分法查找一个特定的值；
locale就是一组函数，根据世界各国的约定差异对C程序的行为进行调整；
使用setjmp和longjmp可能导致晦涩难懂的代码；
使用断言可以简化程序的调试；

]]></content>
      <categories>
        <category>C</category>
        <category>C++</category>
      </categories>
      <tags>
        <tag>exit</tag>
        <tag>abort</tag>
        <tag>assert</tag>
        <tag>NDEBUG</tag>
        <tag>volatile</tag>
        <tag>atexit</tag>
        <tag>atoi</tag>
        <tag>atol</tag>
        <tag>bsearch</tag>
        <tag>frexp</tag>
        <tag>ldexp</tag>
        <tag>locale</tag>
        <tag>longjmp</tag>
        <tag>modf</tag>
        <tag>qsort</tag>
        <tag>setjmp</tag>
        <tag>signal</tag>
        <tag>strtoul</tag>
        <tag>strtol</tag>
      </tags>
  </entry>
  <entry>
    <title>C语言的各种标准</title>
    <url>/2013/05/06/c-standard/</url>
    <content><![CDATA[C语言的标准（K&amp;R C，ANSI C，C89，C90，C99）历史
C语言：1973年由Dennis M. Ritchie设计和实现。

K&amp;R C：1978年由Kernighan和Ritchie合写的书《The C Programming Language》，形成了C语言的事实的标准，简称为K&amp;R C。

ANSI C（C89或C90）：1989年，美国国家标准局（ANSI）颁布了第一个官方的C语言标准（X3.159-1989），简称为ANSI C或C89；1990年，它被国际标准化组织（ISO）采纳国际标准（ISO/IEC9899:1990），简称为C90。这个标准是目前广泛使用并完全支持的。

C99：1999年，ISO/ANSI又推出了新的标准（ISO9899:1999），简称C99。这个标准目前支持的可能还不太全面。


C89/C90标准的指导原则是
相信程序员；
不妨碍程序员做需要完成的事情；
让语言保持短小简单；
只提供一种方法来执行一种操作；
使程序运行速度快，即使不能保证其可移植性。（不追求定义的抽象统一，更优先考虑运行效率）

C89/C90对K&amp;R C的改变有：
增加了函数原型（prototype），强调对函数的输入参数进行严格的类型检查；并补充定义了C语言的标准函数库
删除了关键字：entry（条目/入口）
增加了关键字：const（常型变量）、enum（枚举类型）、signed（有符号的，例如signed char）、void（空/无，可用于函数返回值和形参、通用指针类型）、volatile（易变变量，防止编译器错误的优化）
传递结构：允许将结构本身作为参数传递给函数（原来只允许传地址）
函数原型：增加了函数原型（便于编译器进行类型检查）
增加了预处理指令：#elif（else if）、#error（错误，强制编译停止）、#line（修改当前行号和源文件名）、#pragma（附注/编译指令，编译器定义的与实现有关的指令）
定义了固有宏：__LINE__（当前行号）、__FILE__（源文件名）、__DATE__（当前系统日期）、__TIME__（当前系统时间）、__STDC__（标准C版时为1）

C99的修订目标主要有三点：
支持国际化编程，引入了支持国际字符集Unicode的数据类型和库函数；
修正原有版本的明显缺点。如整数的移植方法，例如int8_t、int16_t、int32_t和int64_t等类型；
针对科学和工程的需要，改进计算的实用性。例如添加了复数类型和新数学函数。

C99标准的新特性C99是在C89（Ansi C）的基础上发展起来的,增加了基本数据类型,关键字 ,和一些系统函数等。目前完全支持的有这些：MinGW、Borland C++、dev-C++。
相对于c89的变化包括
增加restrict指针
inline（内联）关键字
新增数据类型 _Bool
对数组的增强: 可变长数组
可以单行注释
分散代码与声明
预处理程序的修改
复合赋值
柔性数组结构成员
指定的初始化符
printf()和scanf()函数系列的增强

C89中标准的头文件
&lt;assert.h&gt; 定义宏assert()
&lt;ctype.h&gt; 字符处理
&lt;errno.h&gt; 错误报告
&lt;float.h&gt; 定义与实现相关的浮点值勤
&lt;limits.h&gt; 定义与实现相关的各种极限值
&lt;locale.h&gt; 支持函数setlocale()
&lt;math.h&gt; 数学函数库使用的各种定义
&lt;setjmp.h&gt; 支持非局部跳转
&lt;signal.h&gt; 定义信号值
&lt;stdarg.h&gt; 支持可变长度的变元列表
&lt;stddef.h&gt; 定义常用常数
&lt;stdio.h&gt; 支持文件输入和输出
&lt;stdlib.h&gt; 其他各种声明
&lt;string.h&gt; 支持串函数
&lt;time.h&gt; 支持系统时间函数

C99新增的头文件和库
&lt;complex.h&gt; 支持复数算法
&lt;fenv.h&gt; 给出对浮点状态标记和浮点环境的其他方面的访问
&lt;inttypes.h&gt; 定义标准的、可移植的整型类型集合。也支持处理最大宽度整数的函数
&lt;iso646.h&gt; 首先在此1995年第一次修订时引进，用于定义对应各种运算符的宏
&lt;stdbool.h&gt; 支持布尔数据类型类型。定义宏bool，以便兼容于C++
&lt;stdint.h&gt; 定义标准的、可移植的整型类型集合。该文件包含在&lt;inttypes.h&gt;中
&lt;tgmath.h&gt; 定义一般类型的浮点宏
&lt;wchar.h&gt; 首先在1995年第一次修订时引进，用于支持多字节和宽字节函数
&lt;wctype.h&gt; 首先在1995年第一次修订时引进，用于支持多字节和宽字节分类函数




限制
C89标准
C99标准



数据块的嵌套层数
15
127


条件语句的嵌套层数
8
63


内部标识符中的有效字符个数
31
63


外部标识符中的有效字符个数
6
31


结构或联合中的成员个数
127
1023


函数调用中的参数个数
31
127


不再支持隐含式的int规则etc…
]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>_Bool</tag>
        <tag>ANSI C</tag>
        <tag>C89</tag>
        <tag>C99</tag>
      </tags>
  </entry>
  <entry>
    <title>C语言 语句</title>
    <url>/2013/03/31/c-statement/</url>
    <content><![CDATA[语句C语言中有很多的语句：空语句、表达式语句、代码块、if语句、while语句、break和continue语句、for语句、do语句、switch语句、switch中的break语句、default子句、goto语句。
基本上，C语言实现了其他现代高级语言所具有的所有语句。
if语句在C的if语句和其他语言的if语句中，只存在一个差别：就是C不具备布尔类型，而是用整型来代替。
对于if-else配对的问题，else字句从属于最靠近它的不完整的if语句。
break和continue语句在while语句中，使用break语句可以永久终止循环，而使用continue语句，用于永久终止当前的那次循环。这两条语句的任何一条如果出现于嵌套的循环内部，它只对最内层的循环起作用，你无法使用break或者continue语句影响外层循环的执行。
while语句的执行过程有时while语句在表达式中就可以完成整个语句的任务，于是循环体就无事可做，此时单独用一行表示一条空语句是比较好的做法，比如：
while((ch = getchar() ) != EOF &amp;&amp; ch != ‘\n’);

for语句for语句的形式为：
for (expression1; expression2; expression3)       statement;

其中expression1称为初始化部分，expression2称为条件部分，expression3称为调整部分。与上述for语句相同意义的while语句：
expression1;while(expression2){       statement;       expression3;}

从上面两个语句的对比，我们可以看出，for循环有一个风格上的优势，就是把所有用于操纵循环的表达式收集在一起，放在同一个地点，便于寻找。do语句
   当你需要循环体至少执行一次时，选择do语句。

switch中的break语句switch语句中的执行中遇到了break语句，执行流就会立即跳到语句列表的末尾。而break语句的实际效果是把语句列表划分为不同的不同，这样，switch语句就能够按照更为传统的方式工作。其实如果这样的话，那么最后一个语句就不用添加break了，但是还是加上了break，主要是在以后的维护中，如果维护人员添加代码而忘记了break就有可能影响程序的效果。default子句
对于switch中的default语句，我一直认为要放在最后，但是测试了一下，发现default可以出现在任何一个case标签出现的地方而不仅仅是最后。
switch语句的执行过程对于符合多个case的情况，最好写上注释，防止在检查的时候额外加上了break而导致出现bug。
goto语句goto语句可以出现在函数中的任何一个位置，这种无序的跳转是很危险的，所以，如果有其他方法搞定，最好少用goto语句。
当然，针对跳转出多层嵌套，goto确实是一种比较方便的方法。当然可以使用一个标志值，来跳转出所有的循环，或者将所有的循环放在一个函数中，直接使用return来跳出。对于设置标志值，例如：
enum {EXIT,OK} status;status = OK;while(status == OK &amp;&amp; condition1){while(status == OK &amp;&amp; condition2){while(status == OK &amp;&amp; condition3){       if(something wrong)       status = EXIT;       break;}}}

总结另外还需要注意：C并不具备任何的输入输出语句，IO是通过调用库函数实现的，C也不具备任何异常处理语句，它们也是通过调用库函数来完成的。
]]></content>
      <categories>
        <category>C</category>
        <category>C++</category>
      </categories>
      <tags>
        <tag>for</tag>
        <tag>if</tag>
        <tag>break</tag>
        <tag>case</tag>
        <tag>continue</tag>
        <tag>default</tag>
        <tag>goto</tag>
        <tag>switch</tag>
        <tag>while</tag>
      </tags>
  </entry>
  <entry>
    <title>C语言 字符串、字符和字节</title>
    <url>/2012/02/25/c-string/</url>
    <content><![CDATA[字符串、字符和字节查找任何几个字符strpbrk:
用法：#include &lt;string.h&gt;
功能：依次检验字符串s1中的字符，当被检验字符在字符串s2中也包含时，则停止检验，并返回该字符位置，空字符NULL不包括在内。
说明：返回s1中第一个满足条件的字符的指针，如果没有匹配字符则返回空指针NULL。
用途：在源字符串（s1）中找出最先含有搜索字符串（s2）中任一字符的位置并返回，若找不到则返回空指针。
   原型：extern char \*strpbrk(char \*s1, char \*s2);

查找一个字符串前缀strspn（返回字符串中第一个不在指定字符串中出现的字符下标）表头文件 #include&lt;string.h&gt;定义函数 size_t strspn (const char *s,const char * accept);函数说明 strspn()从参数s 字符串的开头计算连续的字符，而这些字符都完全是accept 所指字符串中的字符。简单的说，若strspn()返回的数值为n，则代表字符串s 开头连续有n 个字符都是属于字符串accept内的字符。返回值 返回字符串s开头连续包含字符串accept内的字符数目。
查找标记原型char *strtok(char s[], const char *delim);功能分解字符串为一组字符串。s为要分解的字符串，delim为分隔符字符串。注意：由于strtok函数保存它所处理的函数的局部状态信息，所以你不能用该函数同时解析两个字符串。
内存操作mem***函数提供了类似字符串函数的能力，但是它们可以处理包括NUL字节在内的任意字节。
]]></content>
      <categories>
        <category>C</category>
        <category>C++</category>
      </categories>
      <tags>
        <tag>string</tag>
        <tag>char</tag>
        <tag>memmove</tag>
        <tag>memcoy</tag>
        <tag>strpbrk</tag>
        <tag>strspn</tag>
        <tag>strtok</tag>
      </tags>
  </entry>
  <entry>
    <title>C语言 struct结构体</title>
    <url>/2013/03/31/c-struct/</url>
    <content><![CDATA[结构体无法比较由于结构体的成员不一定是连续地存储在内存中，所以不能用运算符==或!=来对结构体进行比较，事实上，在一个结构体的存储区域内可能会出现一些“空洞”，这是由于计算机是按照一定的边界，例如半字、字、双字边界来存储不同数据类型的变量。
对结构体的访问
结构体成员运算符structure member operator(.)，也被称为圆点运算符
结构体指针运算符structure pointer operator(-&gt;)，也被称为箭头运算符

指针方式的结构体在传递一个结构体时，用传地址的方式比采用传值的方式效率高，因为传值会要求复制整个结构体。
多重结构体变量访问这里由引出来另一个比较有意思的问题，既然结构体的变量可以不同类型的，当然结构体也可以作为内部变量，如下所示，shao_struct_v2.c
#include &lt;stdio.h&gt;#include &lt;string.h&gt;struct Date{    int year;    int month;    int day;};struct Student{    char id[5];    char name[10];    int age;    char sex[10];    struct Date date;};int main(int argc, char const *argv[]){    struct Student s1 = {"0001", "Little Bob", 20, "male"};    strcpy(s1.name, "Big Bob");    s1.date.year = 1990;    s1.date.month = 1;    s1.date.day = 12;    printf("ID \t Name \t AGE \t\t SEX \t\n");    printf("%s\t%s\t%d(%d-%d-%d)\t%s\n",s1.id, s1.name, s1.age, s1.date.year, s1.date.month, s1.date.day, s1.sex);    return 0;}

输出为➜  struct git:(master) ✗ gcc shao_struct_in_struct.c➜  struct git:(master) ✗ lsa.out                   shao_struct_in_struct.c shao_struct_simple.c➜  struct git:(master) ✗ ./a.outID       Name    AGE             SEX0001    Big Bob 20(1990-1-12)   male



根据“用户输入”初始化结构体用户输入信息需要访问到结构体变量所在的内存空间地址
#include&lt;stdio.h&gt;#include&lt;string.h&gt;#include&lt;stdlib.h&gt;struct Student{  char id[5];  char name[10];  int age;  char sex[3];};int main(){	struct Student s1;	printf("input id:&gt;");	scanf("%s",s1.id);   	printf("input age:&gt;");	scanf("%d",&amp;s1.age);}​```##  定义结构体类型数组，通过数组同时初始化多个结构体​```c#include&lt;stdio.h&gt;#include&lt;string.h&gt;#include&lt;stdlib.h&gt;struct Student{  ​char id[5];  ​char name[10];  ​int age;  ​char sex[3];};void main(){​	struct Student S[2]={{"0001","Newton",35,"男"},​	{"0002","Lagrange",30,"男"}};   //通过数组同时初始化多个结构体​	for(int i=0;i&lt;2;++i)​	{​		printf("id=%s,name=%s,age=%d,sex=%s\n",​			S[i].id,S[i].name,S[i].age,S[i].sex);​	}}

定义结构体指针，通过指针指向符-&gt;访问结构体成员变量#include&lt;stdio.h&gt;#include&lt;string.h&gt;#include&lt;stdlib.h&gt;struct Student{​	char id[5];​	char name[10];​	int age;​	char sex[3];};void main(){​	int a =10;​	int *pa=&amp;a;​	Student s1={"0001","Euler",32,"男"};​	printf("id=%s,name=%s,age=%d,sex=%s\n",s1.id,s1.name,s1.age,s1.sex);	struct Student *ps=&amp;s1;   //指向结构体的“结构体类型指针”	printf("id=%s,name=%s,age=%d,sex=%s\n",ps-&gt;id,ps-&gt;name,ps-&gt;age,ps-&gt;sex);   	//通过指针指向符-&gt;访问结构体成员变量}


线性链表#include&lt;stdio.h&gt;#include&lt;string.h&gt;#include&lt;stdlib.h&gt;#include&lt;malloc.h&gt;#define ElemType intstruct Node{​	ElemType data;​	struct Node *next;};typedef Node* List;void InitList(List *head){​	*head=NULL;}void CreateList(List *head){​	*head=(Node *)malloc(sizeof(Node));​	(*head)-&gt;data=1;​	(*head)-&gt;next=NULL;	Node *p=*head;	for(int i=2;i&lt;=10;++i)	{		Node *s=(Node *)malloc(sizeof(Node));		s-&gt;data=i;		s-&gt;next=NULL;		p-&gt;next=s;		p=s;	}}void ShowList(List head){​	Node *p=head;​	while(p!=NULL)​	{​		printf("%d--&gt;",p-&gt;data);​		p=p-&gt;next;​	}​	printf("Over!\n");}void main(){​	List mylist;​	InitList(&amp;mylist);​	CreateList(&amp;mylist);​	ShowList(mylist);}
]]></content>
      <categories>
        <category>C</category>
        <category>C++</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>c++</tag>
        <tag>struct</tag>
      </tags>
  </entry>
  <entry>
    <title>C语言 time函数学习</title>
    <url>/2013/04/17/c-time/</url>
    <content><![CDATA[linux中关于time.h的函数对time.h中的若干个获取时间以及时间转换的函数困惑了有一段时间了，每次操作都要man一下，查看一下具体含义，今天把这些总结一下，算是了了一桩心事。
关系图为（其实搞定这个图也就OK了）： 

time.h是C标准函数库中获取时间与日期、对时间与日期数据操作及格式化的头文件。
表示时间的三种数据类型
日历时间（calendar time），是从一个标准时间点（epoch）到现在的时间经过的秒数，不包括插入闰秒对时间的调整。开始计时的标准时间点，各种编译器一般使用1970年1月1日0时0秒。日历时间用数据类型time_t表示。time_t类型实际上一般是32位或64位整数类型;
时钟滴答数（clock tick），从进程启动开始计时，因此这是相对时间。每秒钟包含CLOCKS_PER_SEC（time.h中定义的常量，一般为1000）个时钟滴答。时钟滴答数用数据类型clock_t表示。clock_t类型一般是32位整数类型;
分解时间(broken-down time)，用结构数据类型tm表示，tm包含下列结构成员：




成员
描述



int tm_hour
hour (0 – 23)


int tm_isdst
夏令时 enabled (&gt; 0), disabled (= 0), or unknown (&lt; 0)


int tm_mday
day of the month (1 – 31)


int tm_min
minutes (0 – 59)


int tm_mon
month (0 – 11, 0 = January)


int tm_sec
seconds (0 – 60, 60 = Leap second)


int tm_wday
day of the week (0 – 6, 0 = Sunday)


int tm_yday
day of the year (0 – 365)


int tm_year
year since 1900


从计算机系统时钟获得时间的方法
time_t time(time_t* timer)：得到从标准计时点（一般是1970年1月1日午夜）到当前时间的秒数
clock_t clock(void)：得到从进程启动到此次函数调用的累计的时钟滴答数。

三种时间日期数据类型的转换函数structtm* gmtime(const time_t* timer)

从日历时间time_t到分解时间tm的转换。函数返回的是一个静态分配的tm结构存储空间，该存储空间被gmtime, localtime与ctime函数所共用. 这些函数的每一次调用会覆盖这块tm结构存储空间的内容。
structtm* gmtime_r(const time_t* timer, struct tm* result)

该函数是gmtime函数的线程安全版本.
structtm* localtime(const time_t* timer)

从日历时间time_t到分解时间tm的转换，即结果数据已经调整到本地时区与夏令时。
time_tmktime(struct tm* ptm)

从分解时间tm到日历时间time_t的转换。
time_ttimegm(struct tm* brokentime)

从分解时间tm（被视作UTC时间，不考虑本地时区设置）到日历时间time_t的转换。该函数较少被使用。
时间日期数据的格式化函数char *asctime(const struct tm* tmptr)

把分解时间tm输出到字符串，结果的格式为“Www Mmm dd hh:mm:ss yyyy”，即“周几月份数日数小时数:分钟数:秒钟数年份数”。函数返回的字符串为静态分配，长度不大于26，与ctime函数共用。函数的每次调用将覆盖该字符串内容。
char*ctime(const time_t* timer)

把日历时间time_t timer输出到字符串，输出格式与asctime函数一样.
size_tstrftime(char* s, size_t n, const char* format, const struct tm*tptr)

把分解时间tm转换为自定义格式的字符串，类似于常见的字符串格式输出函数sprintf。
char *strptime(const char* buf, const char* format, struct tm*tptr)

strftime的逆操作，把字符串按照自定义的格式转换为分解时间tm。
对时间数据的操作doubledifftime(time_t timer2, time_t timer1)

比较两个日历时间之差。

time – get the Coordinated Universal Time  seconds from 1970.1.1

time_ttime(time_t* timer)

获取当前的系统时间，返回的结果是一个time_t类型，其实就是一个大整数，其值表示从CUT（Coordinated Universal Time）时间1970年1月1日00:00:00（称为UNIX系统的Epoch时间）到当前时刻的秒数。然后调用localtime将time_t所表示的CUT时间转换为本地时间（我们是+8区，比CUT多8个小时）并转成struct tm类型，该类型的各数据成员分别表示年月日时分秒。
示例：
#include &lt;stdio.h&gt;#include &lt;time.h&gt;int main(void){time_t timer = time(NULL);printf(“The number of seconds since January 1, 1970 is %ld\n”, timer);return 0;}




gettimeofday – get time

获得当前精确时间（UNIX到现在的时间）。
示例：
#include&lt;stdio.h&gt;#include&lt;sys/time.h&gt;#include&lt;unistd.h&gt;int main(){struct timeval tv;struct timezone tz;gettimeofday(&amp;tv, &amp;tz);printf(“tv_sec:%ld\n”, tv.tv_sec);printf(“tv_usec:%ld\n”, tv.tv_usec);printf(“tz_minuteswest:%d\n”, tz.tz_minuteswest);printf(“tz_dsttime:%d\n”, tz.tz_dsttime);return 0;}


localtime – converts the calendar time timep to broken-down time representation, expressed relative to the user’s specified timezone.

struct tm *localtime(const time_t*timep);struct tm *localtime_r(const time_t *timep, struct tm*result);

功能: 把从1970-1-1零点零分到当前时间系统所偏移的秒数时间转换为日历时间。说明：此函数获得的tm结构体的时间，是 已经进行过时区转化为本地时间。返回值：返回指向tm 结构体的指针.tm结构体是time.h中定义的用于分别存储时间的各个量(年月日等)的结构体.
示例：
#include&lt;time.h&gt;#include&lt;stdio.h&gt;int main(){struct tm *t;time_t timer;time(&amp;timer);t = localtime(&amp;timer);printf(“%4d year%02d month%02d day %02d:%02d:%02d\n”, t-&gt;tm_year + 1900,t-&gt;tm_mon + 1, t-&gt;tm_mday, t-&gt;tm_hour, t-&gt;tm_min,t-&gt;tm_sec);return 0;}// 注意年份上要加上1900。


asctime – converts the broken-down time value tm into a null-terminated  string  with  the same  format as ctime()

char *asctime(const struct tm*tm);char *asctime_r(const struct tm *tm, char*buf);

功能: 转换日期和时间为相应的ASCII码，返回字符串格式：星期，月，日，小时，分，秒，年与此类似ctime是将相应时间转换为字符串格式。
示例：
#include &lt;stdio.h&gt;#include &lt;string.h&gt;#include &lt;time.h&gt;int main(void){struct tm t;char str[80];/* sample loading of tm structure */t.tm_sec = 1; /* Seconds */t.tm_min = 30; /* Minutes */t.tm_hour = 9; /* Hour */t.tm_mday = 22; /* Day of the Month */t.tm_mon = 11; /* Month */t.tm_year = 12; /* Year – does not include century */t.tm_wday = 4; /* Day of the week */t.tm_yday = 0; /* Does not show in asctime */t.tm_isdst = 0; /* Is Daylight SavTime; does not show in asctime *//* converts structure to null terminated string */strcpy(str, asctime(&amp;t));printf(“%s\n”, str);return 0;}


ctime – converts the calendar time t into a null-terminated string of the form

char*ctime(const time_t *timep);char*ctime_r(const time_t *timep, char *buf);

功能：把time_t描述转换为字符串
示例：
#include &lt;stdio.h&gt;#include &lt;time.h&gt;int main(void){time_t timer = time(NULL);printf(“Today’s data and time is %s\n”, ctime(&amp;timer));return 0;}


gmtime – converts the calendar time timep to broken-down time representation, expressed in Coordinated Universal Time (UTC)

struct tm *gmtime(const time_t*timep);struct tm *gmtime_r(const time_t *timep, struct tm*result);


功能：把日期和时间转换为格林威治(GMT)时间的函数。将参数timep 所指的time_t 结构中的信息转换成真实世界所使用的时间日期表示方法，然后将结果由结构tm返回，获取的时间未经过时区转换。与localtime唯一的区别就是相差了时区，比如对于中国而言，只有小时上相差了8个小时。
示例：
#include&lt;time.h&gt;#include&lt;stdio.h&gt;int main(){struct tm *t;time_t timer;time(&amp;timer);t = localtime(&amp;timer);printf(“%4d year%02d month%02d day %02d:%02d:%02d\n”, t-&gt;tm_year + 1900,t-&gt;tm_mon + 1, t-&gt;tm_mday, t-&gt;tm_hour, t-&gt;tm_min,t-&gt;tm_sec);return 0;}

timegm – inverses of gmtime
#include &lt;time.h&gt;time_t timegm(struct tm*tm);

将struct tm结构转成time_t结构,不使用时区信息
mktime – converts a broken-down time structure, expressed as local time, to calendar time representation.
time_t mktime(struct tm *tm);

功能：将时间转换为自1970年1月1日以来失去时间的秒数,发生错误是返回-1.
示例：
#include &lt;stdio.h&gt;#include &lt;time.h&gt;int main(void){time_t timep;struct tm *p;time(&amp;timep);printf(“time() : %ld \n”, timep);p = localtime(&amp;timep);timep = mktime(p);printf(“time()-&gt;localtime()-&gt;mktime():%ld\n”, timep);return 0;}


timelocal – inverses of localtime
time_ttimelocal(struct tm *tm);


timelocal 函数是GNU扩展的与posix函数mktime相当
strftime – format date and time
size_t strftime(char *s, size_t max, const char *format, const struct tm *tm);

函数功能：将时间格式化为一个我们想要的格式，或者说：格式化一个时间字符串。参数说明：我们可以根据format指向字符串中格式命令把timeptr中保存的时间信息放在strDest指向的字符串中，最多向strDest中存放maxsize个字符。该函数返回向strDest指向的字符串中放置的字符数。函数strftime()的操作有些类似于sprintf()：识别以百分号(%)开始的格式命令集合，格式化输出结果放在一个字符串中。格式化命令说明串strDest中各种日期和时间信息的确切表示方法。格式串中的其他字符原样放进串中。格式命令列在下面，它们是区分大小写的。



格式化
解释



%a
星期几的简写


%A
星期几的全称


%b
月份的简写


%B
月份的全称


%c
标准的日期的时间串


%C
年份的后两位数字


%d
十进制表示的每月的第几天


%D
月/天/年


%e
在两字符域中，十进制表示的每月的第几天


%F
年–月–日


%g
年份的后两位数字，使用基于周的年


%G
年份，使用基于周的年


%h
简写的月份名


%H
24小时制的小时


%I
12小时制的小时


%j
十进制表示的每年的第几天


%m
十进制表示的月份


%M
十时制表示的分钟数


%p
本地的AM或PM的等价显示


%n
新行符


%r
12小时的时间


%R
显示小时和分钟：hh:mm


%S
十进制的秒数


%t
水平制表符


%T
显示时分秒：hh:mm:ss


%U
第年的第几周，把星期日作为第一天（值从0到53）


%u
每周的第几天，星期一为第一天（值从0到6，星期一为0）


%V
每年的第几周，使用基于周的年


%w
十进制表示的星期几（值从0到6，星期天为0）


%W
每年的第几周，把星期一做为第一天（值从0到53）


%x
标准的日期串


%X
标准的时间串


%y
不带世纪的十进制年份（值从0到99）


%Y
带世纪部分的十制年份


%z
%Z 时区名称，如果不能得到时区名称则返回空字符。


%%
百分号


示例：
#include&lt;stdio.h&gt;#include&lt;time.h&gt;int main(void){struct tm *newtime;char tmpbuf[1280];time_t lt1;time(&amp;lt1);newtime = localtime(&amp;lt1);strftime(tmpbuf, 1280,“Today is\t %A – %a\nMonth is\t %B – %b\nDate is \t%c\nyear- month-day is\t %F\nhour %H\n Time is\t %T\nday %d of %B in the year %Y.\n”, newtime);printf(“%s\n”, tmpbuf);return 0;}

strptime – convert a string representation of time to a time tm structure
char *strptime(const char *s, const char *format, struct tm *tm);

功能：按照特定时间格式将字符串转换为时间类型，与上面说的strftime刚好相反。
示例：
#include &lt;stdio.h&gt;#include &lt;time.h&gt;#include &lt;stdlib.h&gt;int main(void){char fmt[] = “%Y-%m-%d-%H:%M:%S”;char buf[] = “2000-01-01-00:00:00”;struct tm tb;if (strptime(buf, fmt, &amp;tb) != NULL) {fprintf(stdout,“ok”);printf(“\nTime is %s\n”, asctime(&amp;tb));}return 0;}

tzset – function initializes the tzname variable from the TZ environment variable
功能：设置时间环境变量说明：tzset()函数使用环境变量TZ的当前设置把值赋给三个全局变量:daylight,timezone和tzname。示例：
#include &lt;stdio.h&gt;#include &lt;time.h&gt;#include &lt;stdlib.h&gt;int main(void){time_t td;putenv(“TZ=PST8PDT”);tzset();time(&amp;td);printf(“Current time = %s\n”, asctime(localtime(&amp;td)));return 0;}


关于time_t类型通过查看宏定义，我们知道time_t实际上是长整型，到未来的某一天，从一个时间点（一般是1970年1月1日0时0分0秒）到那时的秒数（即日历时间）超出了长整形所能表示的数的范围怎么办？对time_t数据类型的值来说，它所表示的时间不能晚于2038年1月18日19时14分07秒。为了能够表示更久远的时间，一些编译器厂商引入了64位甚至更长的整形数来保存日历时间。比如微软在Visual C++中采用了__time64_t数据类型来保存日历时间，并通过_time64()函数来获得日历时间（而不是通过使用32位字的time()函数），这样就可以通过该数据类型保存3001年1月1日0时0分0秒（不包括该时间点）之前的时间。clock – Determine processor time
clock_tclock(void);

功能: 返回处理器调用某个进程或函数所花费的时间。示例：
#include &lt;stdio.h&gt;#include &lt;time.h&gt;#include &lt;unistd.h&gt;int main(void){int i = 0;clock_t start, end;start = clock();while (i &lt; 10000000)i++;end = clock();printf(“The time was: %f\n”,(double) (end – start) / CLOCKS_PER_SEC);return 0;}

注意，在测试进程消耗时间的时候，不要使用sleep，因为sleep不使用CPU时间。difftime  – calculate time difference
doubledifftime(time_t time1, time_t time0);

功  能:返回两个time_t型变量之间的时间间隔，即计算两个时刻之间的时间差示例：
#include &lt;time.h&gt;#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;int main(void){time_t first, second;system(“clear”);first = time(NULL);sleep(2);second = time(NULL);printf(“The difference is: %f seconds\n”, difftime(second, first));return 0;}
]]></content>
      <categories>
        <category>C</category>
        <category>C++</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>c++</tag>
        <tag>time</tag>
      </tags>
  </entry>
  <entry>
    <title>C语言 鲜为人知的“三字母词”</title>
    <url>/2012/02/06/c-trigraph-sequences/</url>
    <content><![CDATA[C语言中鲜为人知的“三字母词”在ANSI标准中，定义了“三字母词”，或者成为“三联符序列”，英文为”trigraph sequences“。目的主要是为了在一些特定的字符集中，比如一些七位代码集中，解决一些特定字符的输入问题。
也许是由于这些字符集我们基本上用不到，所以在大多数C语言的书籍中，我们都看不到对“三字母词”的讲解。这里资料来源于参考ANSI C99标准（即传说中的《American National Standards Institute for Programming Languages-C》 1999年，我们习惯简称为“C99”）。
截止到现在，“三字母词”有且仅有9个，分别为：



三字母词
对应的字符



??=
#


??(
[


??)
]


??&lt;
{


??&gt;
}


??/
\


??!



??’
^


??-
~


就这9个，没有其他的三字母词。源代码中的“三字母词”，在编译阶段会被替换为“对应的字符”。对于以“?”开头的字符序列，如果不能与上面9个匹配，编译器将保持原状；一旦匹配，编译器就会做替换。
编译时可能需要加上选项-trigraphs。输出为：
其中缺的那项为\。并且会在编译的时候报警：
warning: unknown escape sequence: ‘\040’ [enabled by default]

因为我们知道\后面需要跟上有意义的转义字符才可以，比如n为换行等。
]]></content>
      <categories>
        <category>C</category>
        <category>C++</category>
      </categories>
      <tags>
        <tag>trigraphs</tag>
      </tags>
  </entry>
  <entry>
    <title>C语言 typedef</title>
    <url>/2013/03/27/c-typedef/</url>
    <content><![CDATA[关键词typedef
关键字typedef提供了一种为已定义好的数据类型创建同义词的机制，为了创建更简短的类型名，通常使用typedef来为结构体类型起名字；
关键字typedef还长用来为基本数据类型创建一个别名，用于提高程序的可移植性；

]]></content>
      <categories>
        <category>C</category>
        <category>C++</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>c++</tag>
        <tag>typedef</tag>
      </tags>
  </entry>
  <entry>
    <title>C语言 value</title>
    <url>/2013/03/20/c-value/</url>
    <content><![CDATA[按值调用C语言的所有调用都是按值调用，即将函数调用中的实参复制得到一个副本，然后传递给被调函数。所谓的“按引用调用”本质也是按值引用~Gotcha？
关于函数求值顺序对于类似printf(“%d  %d”,f(x),g(x));而言，因为函数调用时的参数求值顺序不确定，所以f()和g()没有确定的先后顺序，所以对于有歧义的i++和++i要特别注意。
]]></content>
      <categories>
        <category>C</category>
        <category>C++</category>
      </categories>
      <tags>
        <tag>typedef</tag>
      </tags>
  </entry>
  <entry>
    <title>CASA VLBI 2020 - Introduction to CASA</title>
    <url>/2018/01/25/casa-casavlbi2020-introduction/</url>
    <content><![CDATA[CASACASA : The Common Astronomy Software Applications packages

Single Dish
ALMA and VLA
CASA VLBI

Download
CASA 6.1 -python3
CASA 5.7 -python2.7

Data FormatMS : the standard CASA data format
Starting CASAcasa

The output from CASA commands is sent to the file casa-YYYYMMDD-HHMMSS.log.
CASA tasks
Just like tget listobs in aips

CASA &lt;1&gt; : default ('listobs')CASA &lt;2&gt; : inp

CASA tasks : Python scriptsStandard input
listobs (vis='EXMPL.ms', listfile='EXMPL.listfile')

Outside CASA, using casa -c yourfile.py.
CASA PlotMSPlotMS

can diplay X-Y plots of visibility data and calibration tables
can be started inside a CASA shell or as a stand-alone executable

CASA ViewerCan display both images and MS file
CASA vs AIPSCASA calibration tables]]></content>
      <categories>
        <category>射电天文</category>
        <category>天文</category>
        <category>射电</category>
      </categories>
      <tags>
        <tag>astronomy</tag>
        <tag>radio</tag>
        <tag>radio astronomy</tag>
      </tags>
  </entry>
  <entry>
    <title>CASA VLBI 2020 - Plot tools in CASA</title>
    <url>/2018/01/25/casa-casavlbi2020-plot/</url>
    <content><![CDATA[Plot tools in CASAWhy plotingWhat should we look at ?

Actual (visibility) data or calibration solutions
Antenna- or baseline-based data
Multi-dimensional data : baselines,source,times,frequenciese(subbands,channels),polarizations,…

plotmsInside the CASA
Outside the CASA
viewerInside CASA
viewer(vis='n14c3.ms')

Outside 
casaviewer vis="n14c3.ms"

plotcal
Only in CASA 5.7-

Other tools …
jplotter 
AOFlagger
CARTA : possible future replacement for DS9,kvis(casaviewer)

]]></content>
      <categories>
        <category>射电天文</category>
        <category>天文</category>
        <category>射电</category>
      </categories>
      <tags>
        <tag>astronomy</tag>
        <tag>radio</tag>
        <tag>radio astronomy</tag>
      </tags>
  </entry>
  <entry>
    <title>CMake 为工程生成目标文件</title>
    <url>/2015/12/17/cmake-add-executable/</url>
    <content><![CDATA[为工程生成目标文件语法：
add_executable(&lt;name&gt; [WIN32] [MACOSX_BUNDLE]               [EXCLUDE_FROM_ALL]               source1 [source2 ...])

简单的例子如下：
add_executable(demo        main.cpp)

]]></content>
      <categories>
        <category>CMake</category>
      </categories>
      <tags>
        <tag>cmake</tag>
        <tag>add_executable</tag>
      </tags>
  </entry>
  <entry>
    <title>CMake 查找库所在目录FIND_LIBRARY</title>
    <url>/2015/12/17/cmake-find-library/</url>
    <content><![CDATA[查找库所在目录FIND_LIBRARY语法：
find_library (          &lt;VAR&gt;          name | NAMES name1 [name2 ...] [NAMES_PER_DIR]          [HINTS path1 [path2 ... ENV var]]          [PATHS path1 [path2 ... ENV var]]          [PATH_SUFFIXES suffix1 [suffix2 ...]]          [DOC "cache documentation string"]          [NO_DEFAULT_PATH]          [NO_CMAKE_ENVIRONMENT_PATH]          [NO_CMAKE_PATH]          [NO_SYSTEM_ENVIRONMENT_PATH]          [NO_CMAKE_SYSTEM_PATH]          [CMAKE_FIND_ROOT_PATH_BOTH |           ONLY_CMAKE_FIND_ROOT_PATH |           NO_CMAKE_FIND_ROOT_PATH]         )

例子如下：
FIND_LIBRARY(RUNTIME_LIB mylib /usr/lib  /usr/local/lib NO_DEFAULT_PATH)

cmake会在目录中查找，如果所有目录中都没有，值RUNTIME_LIB就会被赋为NO_DEFAULT_PATH
]]></content>
      <categories>
        <category>CMake</category>
      </categories>
      <tags>
        <tag>cmake</tag>
      </tags>
  </entry>
  <entry>
    <title>CMake 头文件目录</title>
    <url>/2015/12/17/cmake-include-directories/</url>
    <content><![CDATA[添加头文件目录INCLUDE_DIRECTORIES语法：
include_directories([AFTER|BEFORE] [SYSTEM] dir1 [dir2 ...])

它相当于g++选项中的-I参数的作用，也相当于环境变量中增加路径到CPLUS_INCLUDE_PATH变量的作用。
include_directories(/include/path/)
]]></content>
      <categories>
        <category>CMake</category>
      </categories>
      <tags>
        <tag>cmake</tag>
      </tags>
  </entry>
  <entry>
    <title>CMake 添加需要链接的库文件目录LINK_DIRECTORIES</title>
    <url>/2015/12/17/cmake-link-directories/</url>
    <content><![CDATA[添加需要链接的库文件目录LINK_DIRECTORIES语法：
link_directories(directory1 directory2 ...)

它相当于g++命令的-L选项的作用，也相当于环境变量中增加LD_LIBRARY_PATH的路径的作用。
link_directories("/lib/directory/")
]]></content>
      <categories>
        <category>CMake</category>
      </categories>
      <tags>
        <tag>cmake</tag>
      </tags>
  </entry>
  <entry>
    <title>CMake 添加需要链接的库文件路径LINK_LIBRARIES</title>
    <url>/2015/12/17/cmake-link-libraries/</url>
    <content><![CDATA[添加需要链接的库文件路径LINK_LIBRARIES语法：
link_libraries(library1 &lt;debug | optimized&gt; library2 ...)

直接是全路径link_libraries(“/home/server/third/lib/libcommon.a”)

下面的例子，只有库名，cmake会自动去所包含的目录搜索link_libraries(iconv)

传入变量link_libraries(${RUNTIME_LIB})

也可以链接多个link_libraries("/the/path/of/lib1.so"　"/the/path/of/lib2.so")

可以链接一个，也可以多个，中间使用空格分隔.
]]></content>
      <categories>
        <category>CMake</category>
      </categories>
      <tags>
        <tag>cmake</tag>
      </tags>
  </entry>
  <entry>
    <title>CMake 显示信息</title>
    <url>/2015/12/17/cmake-message/</url>
    <content><![CDATA[message给用户显示一个信息.
message([&lt;mode&gt;] "message to display" ...)

The optional  keyword determines the type of message:
(none)         = Important informationSTATUS         = Incidental informationWARNING        = CMake Warning, continue processingAUTHOR_WARNING = CMake Warning (dev), continue processingSEND_ERROR     = CMake Error, continue processing,                              but skip generationFATAL_ERROR    = CMake Error, stop processing and generationDEPRECATION    = CMake Deprecation Error or Warning if variable                 CMAKE_ERROR_DEPRECATED or CMAKE_WARN_DEPRECATED                 is enabled, respectively, else no message.
The CMake command-line tool displays STATUS messages on stdout and all other message types on stderr. The CMake GUI displays all messages in its log area. The interactive dialogs (ccmake and CMakeSetup) show STATUS messages one at a time on a status line and other messages in interactive pop-up boxes.
CMake Warning and Error message text displays using a simple markup language. Non-indented text is formatted in line-wrapped paragraphs delimited by newlines. Indented text is considered pre-formatted.
]]></content>
      <categories>
        <category>CMake</category>
      </categories>
      <tags>
        <tag>cmake</tag>
      </tags>
  </entry>
  <entry>
    <title>CMake 设置要链接的库文件的名称TARGET_LINK_LIBRARIES</title>
    <url>/2015/12/17/cmake-target-link-libraries/</url>
    <content><![CDATA[设置要链接的库文件的名称TARGET_LINK_LIBRARIES语法：
target_link_libraries(&lt;target&gt; [item1 [item2 [...]]]                      [[debug|optimized|general] &lt;item&gt;] ...)

以下写法都可以：target_link_libraries(myProject hello)       # 连接libhello.so库，默认优先链接动态库target_link_libraries(myProject libhello.a)  # 显示指定链接静态库target_link_libraries(myProject libhello.so) # 显示指定链接动态库

再如：target_link_libraries(myProject libhello.so)　　#这些库名写法都可以。target_link_libraries(myProject hello)target_link_libraries(myProject -lhello)
]]></content>
      <categories>
        <category>CMake</category>
      </categories>
      <tags>
        <tag>cmake</tag>
      </tags>
  </entry>
  <entry>
    <title>CMake 简便手册</title>
    <url>/2015/12/07/cmake-tutorial-0-introduction/</url>
    <content><![CDATA[简介这个主要参考(CMake Documentation)的手册整理而成。 一步一步阐述了如何使用CMake构建一个工程。详细参考CMake Tutorial — CMake 3.21.3 Documentation。
所有的源码在下载的CMake软件包里面的Help/guide/tutorial文件夹。
原文：CMake Tutorial — CMake 3.21.3 Documentation
]]></content>
      <categories>
        <category>CMake</category>
      </categories>
      <tags>
        <tag>c++</tag>
        <tag>cmake</tag>
        <tag>cmake3.10</tag>
      </tags>
  </entry>
  <entry>
    <title>CMake 简便手册</title>
    <url>/2015/12/07/cmake-tutorial/</url>
    <content><![CDATA[简介这个主要参考CMake官网的手册整理而成。 一步一步阐述了如何使用CMake构建一个工程。详细参考Mastering CMake。
所有的源码在下载的CMake软件包里面的Tests/Tutorial文件夹。
第一步 开始吧大部分的项目都是从源码进行编译生成可执行程序的。对于最简单的工程，包含两行代码的CMakeLists.txt文件就可以搞定。下面就开始我们的第一个小目标，内容如下所示：
cmake_minimum_required (VERSION 3.2)project (Tutorial)add_executable(Tutorial tutorial.cxx)

从上面的例子看到，cmake的关键词都是小写的，其实大写、小写或者大小写混合，CMake都是支持的。
下面的代码是一个比较简单的计算平方根的小程序。
// A simple program that computes the square root of a number#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;math.h&gt;int main (int argc, char *argv[]){	if (argc &lt; 2)	{	fprintf(stdout,"Usage: %s number\n",argv[0]);	return 1;	}	double inputValue = atof(argv[1]);	double outputValue = sqrt(inputValue);	fprintf(stdout,"The square root of %g is %g\n",	inputValue, outputValue);	return 0;}

添加版本号并配置头文件我们将要添加的第一个特性为提供一个版本号，当然也可以在源码里面修改，不过在CMakeLists.txt里面修改更灵活一些。修改后的文件如下所示：
cmake_minimum_required (VERSION 2.6)project (Tutorial)# The version number.set (Tutorial_VERSION_MAJOR 1)set (Tutorial_VERSION_MINOR 0)# configure a header file to pass some of the CMake settings# to the source codeconfigure_file ("${PROJECT_SOURCE_DIR}/TutorialConfig.h.in""${PROJECT_BINARY_DIR}/TutorialConfig.h")# add the binary tree to the search path for include files# so that we will find TutorialConfig.hinclude_directories("${PROJECT_BINARY_DIR}")# add the executableadd_executable(Tutorial tutorial.cxx)

从上面的内容可以看到我们需要的头文件在binary目录，所以我们需要把该目录包含进来。
接下来我们创建一个文件TutorialConfig.h.in，内容如下所示：
// the configured options and settings for Tutorial#define Tutorial_VERSION_MAJOR @Tutorial_VERSION_MAJOR@#define Tutorial_VERSION_MINOR @Tutorial_VERSION_MINOR@

在CMake配置该头文件的时候，就会将@Tutorial_VERSION_MAJOR@和@Tutorial_VERSION_MINOR@ 自动替换为CMakeLists.txt文件中的值。
接下来，我们修改源码来使用这个版本号。源码如下所示。
// A simple program that computes the square root of a number#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;math.h&gt;#include "TutorialConfig.h"int main (int argc, char *argv[]){if (argc &lt; 2){	fprintf(stdout,"%s Version %d.%d\n",	argv[0],	Tutorial_VERSION_MAJOR,	Tutorial_VERSION_MINOR);	fprintf(stdout,"Usage: %s number\n",argv[0]);	return 1;	}	double inputValue = atof(argv[1]);	double outputValue = sqrt(inputValue);	fprintf(stdout,"The square root of %g is %g\n",	inputValue, outputValue);	return 0;}



第二步 添加一个库接下里我们给项目添加一个库。这个库包含我们自己实现的一个求平方根的算法。随后我们就使用这个库而不用系统自带的库。在这个示例中，我们把这个库放在子文件夹MathFunctions中，并在CMakeLists.txt文件中将添加下面一行
add_library(MathFunctions mysqrt.cxx)

源码文件mysqrt.cxx中包含了一个类似求平方根的功能。为了使用这个新的库，我们在顶级目录的CMakeLists.txt文件中添加add_subdirectory调用，这样就可以在编译的时候使用该库。同时我们也添加了一个头文件包含目录，用来使用头文件中的原型定义。最后新添加的几行内容如下所示：
include_directories ("${PROJECT_SOURCE_DIR}/MathFunctions")add_subdirectory (MathFunctions)# add the executableadd_executable (Tutorial tutorial.cxx)target_link_libraries (Tutorial MathFunctions)

接下来我们把这个库设置成可选的。虽然在这个示例中没有必要，不过对于其他依赖于第三方库的软件，这个就很有必要的。
第一步就是在顶级目录的 CMakeLists.txt 文件中添加option参数
# should we use our own math functions?option (USE_MYMATH"Use tutorial provided math implementation" ON)

上面的option选项ON就使能了参数USE_MYMATH。
为了在编译连接时使用到MathFunctions库，CMakeLists.txt文件如下所示：
# add the MathFunctions library?#if (USE_MYMATH)include_directories ("${PROJECT_SOURCE_DIR}/MathFunctions")add_subdirectory (MathFunctions)set (EXTRA_LIBS ${EXTRA_LIBS} MathFunctions)endif (USE_MYMATH)# add the executableadd_executable (Tutorial tutorial.cxx)target_link_libraries (Tutorial  ${EXTRA_LIBS})

USE_MYMATH会决定是否编译并使用MathFunctions，变量EXTRA_LIBS将收集后续使用到的库。这是大型工程的一个通用方法。
目前的代码如下：
// A simple program that computes the square root of a number#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;math.h&gt;#include "TutorialConfig.h"#ifdef USE_MYMATH#include "MathFunctions.h"#endifint main (int argc, char *argv[]){	if (argc &lt; 2)	{	fprintf(stdout,"%s Version %d.%d\n", argv[0],	Tutorial_VERSION_MAJOR,	Tutorial_VERSION_MINOR);	fprintf(stdout,"Usage: %s number\n",argv[0]);	return 1;	}	double inputValue = atof(argv[1]);	#ifdef USE_MYMATH	double outputValue = mysqrt(inputValue);	#else	double outputValue = sqrt(inputValue);	#endif	fprintf(stdout,"The square root of %g is %g\n",	inputValue, outputValue);	return 0;}

在源码中我们也使用了USE_MYMATH。我们可以通过在文件TutorialConfig.h.in中添加下面一行来搞定。
#cmakedefine USE_MYMATH

第三步 安装和测试下一步我们将增加项目的安装和测试。
只要增加下面两行命令就可以将库文件和头文件安装到指定位置。
install (TARGETS MathFunctions DESTINATION bin)install (FILES MathFunctions.h DESTINATION include)

然后在顶级目录加上下面两句话就可以安装可执行文件和配置头文件了。
# add the install targetsinstall (TARGETS Tutorial DESTINATION bin)install (FILES "${PROJECT_BINARY_DIR}/TutorialConfig.h"        DESTINATION include)

这些就是我们需要做的全部工作了，此时我们就可以编译这个项目了，然后输入make install就可以安装相应的头文件、库和可执行文件了。
CMAKE中的变量CMAKE_INSTALL_PREFIX用于指定文件安装的根路径。
增加测试也是很多程序都要做的，下面的几步用于测试程序能够正常运行。
include(CTest)# does the application runadd_test (TutorialRuns Tutorial 25)# does it sqrt of 25add_test (TutorialComp25 Tutorial 25)set_tests_properties (TutorialComp25 PROPERTIES PASS_REGULAR_EXPRESSION “25 is 5”)# does it handle negative numbersadd_test (TutorialNegative Tutorial -25)set_tests_properties (TutorialNegative PROPERTIES PASS_REGULAR_EXPRESSION “-25 is 0”)# does it handle small numbersadd_test (TutorialSmall Tutorial 0.0001)set_tests_properties (TutorialSmall PROPERTIES PASS_REGULAR_EXPRESSION “0.0001 is 0.01”)# does the usage message work?add_test (TutorialUsage Tutorial)set_tests_properties (TutorialUsage PROPERTIES PASS_REGULAR_EXPRESSION “Usage:.*number”)

在编译完之后就可以使用ctest命令来运行这些测试了。
第一个简单的例子主要用于检测程序是否出现段错误或者其他bug，有一个0值返回。这是CTest测试的基本框架。接下来的几个测试使用了参数PASS_REGULAR_EXPRESSION用来检测输出是否包含特定字符串。在这个示例中，如果测试的结果没有包含相应的字符，将会输出错误信息。
如果希望做很多不同输入的测试，可以考虑定义一个宏来完成。
#define a macro to simplify adding tests, then use itmacro (do_test arg result)add_test (TutorialComp${arg} Tutorial ${arg})set_tests_properties (TutorialComp${arg}PROPERTIES PASS_REGULAR_EXPRESSION ${result})endmacro (do_test)# do a bunch of result based testsdo_test (25 "25 is 5")do_test (-25 "-25 is 0")

第四部 增加系统Introspection接下来我们增加一些代码用来解决依赖于特定系统的特性。在这个示例中我们测试系统是否包含log和exp函数。当然大部分操作系统都具有。如果操作平台有log我们就使用它在mysqrt函数中来计算平方根。我们首先通过在文件CMakeLists.txt中添加CheckFunctionExists.cmake宏来测试这个功能的可用性。
# does this system provide the log and exp functions?include (CheckFunctionExists)check_function_exists (log HAVE_LOG)check_function_exists (exp HAVE_EXP)

接下来我们通过修改TutorialConfig.h.in文件来定义CMake是否发现了这些值。
// does the platform provide exp and log functions?#cmakedefine HAVE_LOG#cmakedefine HAVE_EXP

这里需要特别注意的是这些测试一定要在configure_file命令之前进行，因为configure_file命令会立即使用当前的一些设置。最后我们得到了一个没有log和exp函数的解决方案。
// if we have both log and exp then use them#if defined (HAVE_LOG) &amp;&amp; defined (HAVE_EXP)result = exp(log(x)*0.5);#else // otherwise use an iterative approach. . .

第五步 增加一个Generated File and Generator这个步骤里面我们将展示如何在编译应用程序的过程中添加一个源文件。在这个例子里面我们将在编译过程中创建一个表，然后把该表编译进我们的程序。首先我们需要生成该表的程序，在MathFunctions子目录我们创建一个新的文件MakeTable.cpp
// A simple program that builds a sqrt table#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;math.h&gt;int main (int argc, char *argv[]){	int i;	double result;	// make sure we have enough arguments	if (argc &lt; 2)	{	return 1;	}	// open the output file	FILE *fout = fopen(argv[1],"w");	if (!fout)	{	return 1;	}	// create a source file with a table of square roots	fprintf(fout,"double sqrtTable[] = {\n");	for (i = 0; i &lt; 10; ++i)	{	result = sqrt(static_cast&lt;double&gt;(i));	fprintf(fout,"%g,\n",result);	}	// close the table with a zero	fprintf(fout,"0};\n");	fclose(fout);	return 0;}

添加下面的几行命令来完成
# first we add the executable that generates the tableadd_executable(MakeTable MakeTable.cpp)# add the command to generate the source codeadd_custom_command (OUTPUT ${CMAKE_CURRENT_BINARY_DIR}/Table.hCOMMAND MakeTable ${CMAKE_CURRENT_BINARY_DIR}/Table.hDEPENDS MakeTable)# add the binary tree directory to the search path for# include filesinclude_directories( ${CMAKE_CURRENT_BINARY_DIR} )# add the main libraryadd_library(MathFunctions `mysqrt.cxx` ${CMAKE_CURRENT_BINARY_DIR}/Table.h  )

根目录的文件CMakeLists.txt内容如下所示：
cmake_minimum_required (VERSION 2.6)project (Tutorial)include(CTest)# The version number.set (Tutorial_VERSION_MAJOR 1)set (Tutorial_VERSION_MINOR 0)# does this system provide the log and exp functions?include (${CMAKE_ROOT}/Modules/CheckFunctionExists.cmake)check_function_exists (log HAVE_LOG)check_function_exists (exp HAVE_EXP)# should we use our own math functionsoption(USE_MYMATH"Use tutorial provided math implementation" ON)# configure a header file to pass some of the CMake settings# to the source codeconfigure_file ("${PROJECT_SOURCE_DIR}/TutorialConfig.h.in""${PROJECT_BINARY_DIR}/TutorialConfig.h")# add the binary tree to the search path for include files# so that we will find TutorialConfig.hinclude_directories ("${PROJECT_BINARY_DIR}")# add the MathFunctions library?if (USE_MYMATH)include_directories ("${PROJECT_SOURCE_DIR}/MathFunctions")add_subdirectory (MathFunctions)set (EXTRA_LIBS ${EXTRA_LIBS} MathFunctions)endif (USE_MYMATH)# add the executableadd_executable (Tutorial tutorial.cxx)target_link_libraries (Tutorial  ${EXTRA_LIBS})# add the install targetsinstall (TARGETS Tutorial DESTINATION bin)install (FILES "${PROJECT_BINARY_DIR}/TutorialConfig.h"        DESTINATION include)# does the application runadd_test (TutorialRuns Tutorial 25)# does the usage message work?add_test (TutorialUsage Tutorial)set_tests_properties (TutorialUsagePROPERTIESPASS_REGULAR_EXPRESSION "Usage:.*number")#define a macro to simplify adding testsmacro (do_test arg result)add_test (TutorialComp${arg} Tutorial ${arg})set_tests_properties (TutorialComp${arg}PROPERTIES PASS_REGULAR_EXPRESSION ${result})endmacro (do_test)# do a bunch of result based testsdo_test (4 "4 is 2")do_test (9 "9 is 3")do_test (5 "5 is 2.236")do_test (7 "7 is 2.645")do_test (25 "25 is 5")do_test (-25 "-25 is 0")do_test (0.0001 "0.0001 is 0.01")

文件TutorialConfig.h.in 如下所示：
// the configured options and settings for Tutorial#define Tutorial_VERSION_MAJOR @Tutorial_VERSION_MAJOR@#define Tutorial_VERSION_MINOR @Tutorial_VERSION_MINOR@#cmakedefine USE_MYMATH// does the platform provide exp and log functions?#cmakedefine HAVE_LOG#cmakedefine HAVE_EXP

MathFunctions目录的文件CMakeLists.txt内容为：
# first we add the executable that generates the tableadd_executable(MakeTable MakeTable.cxx)# add the command to generate the source codeadd_custom_command (OUTPUT ${CMAKE_CURRENT_BINARY_DIR}/Table.hDEPENDS MakeTableCOMMAND MakeTable ${CMAKE_CURRENT_BINARY_DIR}/Table.h)# add the binary tree directory to the search path# for include filesinclude_directories( ${CMAKE_CURRENT_BINARY_DIR} )# add the main libraryadd_library(MathFunctions `mysqrt.cxx` ${CMAKE_CURRENT_BINARY_DIR}/Table.h)install (TARGETS MathFunctions DESTINATION bin)install (FILES MathFunctions.h DESTINATION include)

第六步 构建一个安装包这一步假定我们需要把我们的项目打包给其他人来使用。我们希望能够提供多个系统版本的二进制和源码包。与直接编译源码不同，这里我们使用CPack来完成各个平台所需要的各种条件。
我们只需要在顶层目录的CMakeLists.txt文件中添加几行代码即可。
# build a CPack driven installer packageinclude (InstallRequiredSystemLibraries)set (CPACK_RESOURCE_FILE_LICENSE  "${CMAKE_CURRENT_SOURCE_DIR}/License.txt")set (CPACK_PACKAGE_VERSION_MAJOR "${Tutorial_VERSION_MAJOR}")set (CPACK_PACKAGE_VERSION_MINOR "${Tutorial_VERSION_MINOR}")include (CPack)

需要添加的就是上面几行代码，我们需要首先包含InstallRequiredSystemLibraries，这个模块将完成当前平台运行中需要的各种依赖库。接下来我们指定存储的许可信息以及版本信息。版本信息使用我们以前设定的值。最后我们包含CPack即可。
如果希望构建二进制版本，执行命令：
cpack --config CPackConfig.cmake

如果希望创建源码版本，执行命令：
cpack --config CPackSourceConfig.cmake
]]></content>
      <categories>
        <category>CMake</category>
      </categories>
      <tags>
        <tag>cmake</tag>
      </tags>
  </entry>
  <entry>
    <title>C++语言 网上流传的最好的10个用于开发C/C++的IDE环境。</title>
    <url>/2017/05/02/cpp-beginner-ide/</url>
    <content><![CDATA[IDE开发环境网上流传的最好的10个用于开发C/C++的IDE环境。




IDE
Windows
Linux
MacOSX
Free



eclipse
√
√
√
√


Code::Blocks
√
√
√
√


GNAT
√
√
√
√


CodeLite
√
√
√
√


NetBeans
√
√
√
√


Qt Creator
√
√
√
√


Dev C++
√


√


C++ Builder
√

√



Anjuta

√

√


MonoDevelop
√
√
√
√


]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>c++</tag>
        <tag>IDE</tag>
        <tag>eclipse</tag>
        <tag>Code::Blocks</tag>
        <tag>CodeLite</tag>
        <tag>Qt Creator</tag>
        <tag>Anjuta</tag>
        <tag>cpp-beginner</tag>
        <tag>C++语言从小白到入门</tag>
      </tags>
  </entry>
  <entry>
    <title>C++语言 简介</title>
    <url>/2015/02/22/cpp-beginner-introduction/</url>
    <content><![CDATA[C++简介C++ 相对于 C 的三件法宝：

C++ 继承了C 语言的高效、简介、快速和可移植特性
C++ 具备面向对象的特性
C++ 具备模板特性提供了泛型编程

另外C++支持4中不同的编程风格

C风格
基于对象
面向对象
泛型

]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>c++</tag>
        <tag>cpp-beginner</tag>
        <tag>C++语言从小白到入门</tag>
      </tags>
  </entry>
  <entry>
    <title>C++语言 简介</title>
    <url>/2015/02/22/cpp-beginner-template/</url>
    <content><![CDATA[C语言的存储类型关键字/*beginner/auto/auto1.c*/#include &lt;stdio.h&gt;int main(){    int year = 2011;    auto int month = 2;    printf("Year : %d\n", year);    printf("Month: %d\n", month);    return 0;}

上面的实例定义了两个带有相同存储类的变量。

auto 只能用在函数内，即 auto 只能修饰局部变量。

register 存储类型register 存储类型用于定义存储在寄存器中而不是 RAM 中的局部变量。这意味着变量的最大尺寸等于寄存器的大小（通常是一个词），且不能对它应用一元的 &amp; 运算符（因为它没有内存位置）。
/*beginner/register/register2.c*/#include &lt;stdio.h&gt;int main(){    register int sum = 0;    int i = 0;    for (i = 0; i &lt;= 100; i++)    {        sum += i;        printf("Sum : %d\n", sum);    }    return 0;}

寄存器主要用于快速访问及变化的变量，比如计数器。不过，定义 register 并不意味着变量将被存储在寄存器中，它意味着变量可能存储在寄存器中，只是可能，这取决于硬件和实现的限制，所以这个一般不太实用，除非对系统很精通，确认是寄存器使用，才能起到加速的效果。
static 存储类型static有多重用法，这里先说一下作为存储类型的用法，这个功能对于需要在某个函数进行初始化且需要保持状态作用大大滴。

static 存储类型指示编译器在程序的生命周期内保持局部变量的存在，而不需要在每次它进入和离开作用域时进行创建和销毁。因此，使用 static 修饰局部变量可以在函数调用之间保持局部变量的值。

static 修饰符也可以应用于全局变量。当 static 修饰全局变量时，会使变量的作用域限制在声明它的文件内，还未说到多个文件，后续再介绍

全局声明的一个 static 变量或方法可以被任何函数或方法调用，只要这些方法出现在跟 static 变量或方法同一个文件中。


以下实例演示了 static 修饰全局变量和局部变量的应用：
/*beginner/static/static3.c*/#include &lt;stdio.h&gt;void localfunc(void);static int global = 10;int main(){    while (global--)    {        localfunc();    }    return 0;}void localfunc(void){    static int local = 5;    local++;    printf(" local : %d , global : %d\n", local, global);}

可以看到运行的结果为：
$ ./storage3 local : 6 , global : 9 local : 7 , global : 8 local : 8 , global : 7 local : 9 , global : 6 local : 10 , global : 5 local : 11 , global : 4 local : 12 , global : 3 local : 13 , global : 2 local : 14 , global : 1 local : 15 , global : 0
]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>c++</tag>
        <tag>cpp-beginner</tag>
        <tag>C++语言从小白到入门</tag>
      </tags>
  </entry>
  <entry>
    <title>编译运行第一个C++程序</title>
    <url>/2012/02/22/cpp-compile/</url>
    <content><![CDATA[编译运行第一个C++程序编写好程序后，接下来需要做的就是进行编译，让操作系统懂得程序要做什么，然后再运行，假定在Linux系统上，那么大部分的编译可以从2个方向来进行：

通过命令行直接编译
通过IDE集成开发环境来编译

现在暂时不涉及IDE，所以我们从命令行来编译。
从上次的helloworld.cpp来进行描述。
此时打开终端，直接输入如下命令：
$ gcc helloworld.cpp

gcc可以是g++，或者cc，这个命令的含义为：

 gcc - GNU project C and C++ compiler

编译以后会默认生成一个a.out的文件，如下：
$ ls -lh-rwxrwxrwx 1 leo leo 17K Wed 22 2215:42 a.out-rwxrwxrwx 1 leo leo  31 Wed 22 22:20 helloworld.cpp



此时开始来执行这个程序，对于Linux而言，如果终端的路径在当前目录，那么此时使用如下命令：
$ ./a.out




其中.后跟一个斜线表示可执行文件为当前目录

]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>c++</tag>
        <tag>c++入门</tag>
      </tags>
  </entry>
  <entry>
    <title>C++中const常量和define宏定义的区别联系</title>
    <url>/2012/02/05/cpp-const/</url>
    <content><![CDATA[区别编译器处理方式不同　　

define宏是在预处理阶段展开。
const常量是编译运行阶段使用。

类型和安全检查不同
define宏没有类型，不做任何类型检查，仅仅是展开。
const常量有具体的类型，在编译阶段会执行类型检查。

存储方式不同
define宏仅仅是展开，有多少地方使用，就展开多少次，不会分配内存。
const常量会在内存中分配(可以是堆中也可以是栈中)。

const 可以节省空间，避免不必要的内存分配。const定义常量从汇编的角度来看，只是给出了对应的内存地址，而不是象#define一样给出的是立即数，所以，const定义的常量在程序运行过程中只有一份拷贝，而 #define定义的常量在内存中有若干个拷贝。
提高效率编译器通常不为普通const常量分配存储空间，而是将它们保存在符号表中，这使得它成为一个编译期间的常量，没有了存储与读内存的操作，使得它的效率也很高。
联系作为常量，两者都有很多的应用，在一个程序里面看不到const和define的可能性不大。
总结C++ 语言可以用const来定义常量，也可以用#define来定义常量。但是前者比后者有更多的优点：比较重要的是const常量有数据类型，而宏常量没有数据类型。编译器可以对前者进行类型安全检查。而对后者只进行字符替换，没有类型安全检查，并且在字符替换可能会产生意料不到的错误（边际效应）。
]]></content>
      <categories>
        <category>C</category>
        <category>C++</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>c++</tag>
        <tag>const</tag>
        <tag>defene</tag>
      </tags>
  </entry>
  <entry>
    <title>Cpp extern用法解析</title>
    <url>/2013/09/07/cpp-extern/</url>
    <content><![CDATA[[TOC]
C++调用C函数C++保留了一部分过程式语言的特点，但更重要的是C++是一种面向对象的程序设计语言，为了支持函数的重载，C++对全局函数的处理方式与C有明显的不同。下面会对C++的重载overload说明一下。
而extern "C"的主要作用就是为了能够正确实现C++代码调用其他C语言代码。
加上extern "C"后，会指示编译器这部分代码按C语言的进行编译，而不是C++的。
比如说你用C 开发了一个动态链接库，为了能够让C++语言也能够调用你的函数，你需要用extern "C"来强制编译器不要修改你的函数名。
通过例子来说明标准头文件#ifndef __TEST_H  /*防止该头文件被重复引用*/#define __TEST_H// some declaration#endif /* __TEST_H */

这个头文件，对于标准的C程序是没有任何问题的，编译/链接/调用。
改进头文件但是如果使用C++来调用上面的一些定义函数，就会出现undefined error，这就是由于C++函数重载的原因。
解决方法就是下面的头文件，使用extern "C"
#ifndef __TEST_H  /*防止该头文件被重复引用*/#define __TEST_H#ifdef __cplusplus    //__cplusplus是cpp中自定义的一个宏extern "C" {          //告诉编译器，这部分代码按C语言的格式进行编译，而不是C++的#endif// some declaration#ifdef __cplusplus}#endif#endif /* __TEST_H */

extern “C”的含义extern "C"代表两方面的意思，extern以及C，也就是说被其修饰的函数是可以被外部调用的，并且是C的函数定义。
C和C++的区别由于C++支持函数重载，因此编译器编译函数的过程中会将函数的参数类型也加到编译后的代码中，而不仅仅是函数名；而C语言并不支持函数重载，因此编译C语言代码的函数时不会带上函数的参数类型，一般只包括函数名。
比如，同一个函数
void add(int x,int y);
c编译后在符号库中的名字为_add,C++中为_add_int_int，可以看到C++中包含了函数名/函数参数数量及类型信息，这也是为什么C++能重载的原因。
]]></content>
      <categories>
        <category>C</category>
        <category>C++</category>
      </categories>
      <tags>
        <tag>define</tag>
        <tag>extern</tag>
        <tag>C</tag>
        <tag>C++</tag>
        <tag>ifndef</tag>
        <tag>endif</tag>
      </tags>
  </entry>
  <entry>
    <title>第一个简单的C++程序</title>
    <url>/2012/02/22/cpp-helloworld/</url>
    <content><![CDATA[第一个简单的C++程序大多数程序的第一个例子就是**Hello World!**，我们也不能免俗，先来第一个最最简单的程序秀一下：
int main(){    return 0;}



这个程序名假定为hello.cpp，其中cpp的后缀表示是C++程序。
再来看程序主体，每个程序主体可以包含一个或多个函数，但是必须包含一个main函数，这个可以认为是程序的入口。
这个最简单的程序，只是为了说明一个C++程序，不做任何事情。不过从这个程序我们可以看到，一个函数包含4个部分：

int : 函数返回类型
main : 函数名
() : 函数的形参列表
{}：中括号包含的函数体

返回类型对于main函数而言，其返回值为int，即整数类型。
这个值某些情况下，还是很有意思的，比如可以判断出程序是否运行成功，如果不成功会有一些错误编码，后面会说一说。
函数名这里个函数名为main。
函数的形参列表所谓的形参列表就是可以传递给函数的参数值。
函数体函数就是{}括起来的内容，函数所执行的动作均在函数体内完成。
]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>c++</tag>
        <tag>c++入门</tag>
      </tags>
  </entry>
  <entry>
    <title>Dell 显示器型号</title>
    <url>/2013/02/18/dell/</url>
    <content><![CDATA[前缀：
UP=Ultra-sharp with Premier color 最高端、出厂带校正颜色
U=Ultra-sharp 最高端
P=Productivity 生产力，面向商用
S=Stylish 时尚，面向家用
E=Essential 基本款

四位数字：
前两位=尺寸后两位=首发财年（比实际年份晚一年左右）

后缀：
H：FullHD 1920*1080，16：9
M：WUXGA 1920*1200，16：10
Q：4K
W：Wide 21：9 带鱼屏
D：QHD 2560*1440

作者：王昭链接：https://www.zhihu.com/question/23978102/answer/293333495
]]></content>
      <categories>
        <category>Dell</category>
      </categories>
      <tags>
        <tag>dell</tag>
      </tags>
  </entry>
  <entry>
    <title>关于开发/编程工具</title>
    <url>/2012/07/01/developement-tool/</url>
    <content><![CDATA[关于开发/编程工具Refer from ： http://www.zhihu.com/question/20302904
我认为开发编程工具分三类，需区别对待：

可以使用一辈子的工具，学习路径几乎没有尽头，值得在职业初期就好好考虑，仔细斟酌进行选择，并在整个生涯中不断努力力求学到更多，你的工作效率会因为这种努力不断提高。如：


编辑器： vim / emacs
基本操作系统环境：如shell
基本编程语言: c / lisp


任何时候都需要掌握的工具，这类工具总是每隔一个周期就有新的产品出现，取代掉旧有的产品，但相对来说是值得学习的，能保持一个较长的时代的有效期，如：


版本控制系统：git
社交网络: stack overflow/github
写作工具: markdown / latex / html
通用编程语言： python / ruby / javascript


特定领域需要的工具，此类工具往往时效性较短，不断被新产品取代，一旦掌握，能在特定领域获得非常高的效率，但缺点是很快会过期，通常是几年之内


各类编程框架： xcode / rails / backbone
各类测试框架：xunit / rspec
用户行为分析工具： ga
各类设计工具： balsamiq
各类项目管理，代码集成工具: github / trac / basecamp

]]></content>
      <categories>
        <category>Linux</category>
        <category>Python</category>
        <category>Shell</category>
        <category>Vim</category>
        <category>C</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>c</tag>
        <tag>linux</tag>
        <tag>emacs</tag>
        <tag>vim</tag>
        <tag>git</tag>
        <tag>github</tag>
        <tag>javascript</tag>
        <tag>latex</tag>
        <tag>lisp</tag>
        <tag>ruby</tag>
        <tag>shell</tag>
        <tag>xcode</tag>
      </tags>
  </entry>
  <entry>
    <title>102只老鼠</title>
    <url>/2021/07/16/diary-102-hiki-no-nezumi/</url>
    <content><![CDATA[102只老鼠102只老鼠，不管是吃面包还是喝茶都是极其壮观的。
画面特别的温馨可爱。
特别是鼠爸爸、鼠妈妈寻找可皮的时候，让人感动。
而把草莓顶在头上的时候，又让人忍俊不禁。

那天晚上，鼠爸爸多多和鼠妈妈加加
跟100只鼠宝宝道了晚安，
然后，吹灭了蜡烛，
一觉香香地睡到了天亮。

]]></content>
      <categories>
        <category>日记</category>
      </categories>
      <tags>
        <tag>阅读</tag>
        <tag>儿童</tag>
        <tag>文学</tag>
        <tag>长谷川香子</tag>
        <tag>天文读书</tag>
        <tag>生活</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux NTP 详细配置及使用方法</title>
    <url>/2011/01/11/diary-2011011-ntp/</url>
    <content><![CDATA[** Linux NTP**详细配置及使用方法实际配置   目前连续谱的两台机子已经配置好ntp服务。
   其中服务器IP为192.168.135.8，客户端IP为192.168.135.7，使用eth1进行直连。
在客户端只需要执行
   ntpdate 192.168.135.8
   hwclock –w
即可。
Linux NTP Introduction 
The Network Time Protocol (NTP) is a protocol used to help synchronize your Linux system’s clock with an accurate time source.
Linux NTP客户端的使用如果时间服务器端已经配置好，直接执行下面两条命令就可以。
如果时间服务器端还未配置好，参考下述服务器端的配置。
1.执行ntpdate *.*.*.*  #...是NTP服务器的IP 2.执行*hwclock –w***把时间信息写入BIOS
将上述文件写入.bashrc中就可以每次开启终端的时候进行时间同步。
Linux NTP服务器端的配置一般而言，安装系统的时候已经自带了ntp软件包，可以通过rpm -q ntp命令来查询是否已经安装ntp。
如果没有安装，终端中使用yum install ntp即可进行安装。（适用于redhat系列平台）    具体步骤为添加配置文件信息到/etc/ntp.conf。
每次配置好后，都需要重启一下ntp服务，service ntpd restart。
附： ntp.conf配置文件实例：
设置要求：不对 Internet 提供服务，仅对内部子网 .../24 提供服务，内部子网的客户端不能修改NTP服务器的时间参数。
在ntp.conf中增加以下内容：（有些）
  restrict default ignore　# 关闭所有的 NTP 要求封包   restrict 127.0.0.1　　 # 开启内部递归网络接口 lo   restrict 192.168.135.0 mask 255.255.255.0 nomodify notrap #在内部子网里面的客户端可以 进行网络校时，但不能修改NTP服务器的时间参数。
(192.168.135.0就可以保证在这个网段的255个地址都可以同步使用)
可能出现的问题如果出现htpd:the NTP socket is in used , exiting，需要在/etc/rc.d/init.d下运行./ntpd stop即可解决。另外还需要注意防火墙有可能屏蔽掉ntp使用的端口。
]]></content>
      <categories>
        <category>日记</category>
        <category>工作</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>ntp</tag>
      </tags>
  </entry>
  <entry>
    <title>Happy New Year. Buddies</title>
    <url>/2012/01/10/diary-20120110/</url>
    <content><![CDATA[Happy New Year. BuddiesFor now, I’v book my train ticket to my hometown on 18th Jan.
As it’s near to the traditional New Year of Chinese so there are more tasks for me. That’s why it’s a long time I haven’t update my website.
I’m glad that there are so many buddies love my blog, especailly the post about the pgplot &amp; c programming.(This post is also some technical article I’v search and summerise , not write by myself. haha).
So thank U so much who have leave a reply to me.
]]></content>
      <categories>
        <category>日记</category>
      </categories>
      <tags>
        <tag>生活</tag>
        <tag>new year</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux 3.11已经发布了</title>
    <url>/2013/07/16/diary-20130716-linux-3.11/</url>
    <content><![CDATA[Linus Torvalds 关闭了合并窗口，发布了Linux 3.11-rc1，同时正式将代号从Unicycling Gorilla改为Linux For Workgroups，并递交了一个替代的企鹅吉祥物logo（如图）。Linux For Workgroups这个代号应该对应的是1990年代初的Windows for Workgroups扩展，微软在1993年8月11日发布了Windows 3.11及其扩展Windows for Workgroups 3.11，企鹅上飘扬着视窗旗帜的恶搞logo不知道会不会遭到微软的反击？
]]></content>
      <categories>
        <category>日记</category>
      </categories>
      <tags>
        <tag>工作</tag>
        <tag>kernel</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title>积极牵头组织国际大科学计划和大科学工程方案</title>
    <url>/2018/03/14/diary-20180314-%E7%A7%AF%E6%9E%81%E7%89%B5%E5%A4%B4%E7%BB%84%E7%BB%87%E5%9B%BD%E9%99%85%E5%A4%A7%E7%A7%91%E5%AD%A6%E8%AE%A1%E5%88%92%E5%92%8C%E5%A4%A7%E7%A7%91%E5%AD%A6%E5%B7%A5%E7%A8%8B%E6%96%B9%E6%A1%88/</url>
    <content><![CDATA[积极牵头组织国际大科学计划和大科学工程方案积极牵头组织国际大科学计划
和大科学工程方案
积极提出并牵头组织国际大科学计划和大科学工程是党中央、国务院作出的重大决策部署。为做好组织实施工作，制定本方案。
一、重要意义
国际大科学计划和大科学工程（以下简称大科学计划）是人类开拓知识前沿、探索未知世界和解决重大全球性问题的重要手段，是一个国家综合实力和科技创新竞争力的重要体现。牵头组织大科学计划作为建设创新型国家和世界科技强国的重要标志，对于我国增强科技创新实力、提升国际话语权具有积极深远意义。
（一）牵头组织大科学计划是解决全球关键科学问题的有力工具。大科学计划以实现重大科学问题的原创性突破为目标，是基础研究在科学前沿领域的全方位拓展，对于推动世界科技创新与进步、应对人类社会面临的共同挑战具有重要支撑作用。牵头组织大科学计划有利于发挥我国主导作用，为解决世界性重大科学难题贡献中国智慧、提出中国方案、发出中国声音，提供全球公共产品，为世界文明发展作出积极贡献。
（二）牵头组织大科学计划是聚集全球优势科技资源的高端平台。牵头组织大科学计划，有利于面向全球吸引和集聚高端人才，培养和造就一批国际同行认可的领军科学家、高水平学科带头人、学术骨干、工程师和管理人员，形成具有国际水平的管理团队和良好机制，打造高端科研试验和协同创新平台，带动我国科技创新由跟跑为主向并跑和领跑为主转变。
（三）牵头组织大科学计划是构建全球创新治理体系的重要内容。开展大科学计划在优化全球科技资源布局、完善创新治理体系中扮演重要角色，已成为国际科技创新合作的重要议题。牵头组织大科学计划作为科技外交的重要途径，有利于建立以合作共赢为核心的新型国际关系和构建全球伙伴关系网络，对落实国家整体外交战略发挥积极作用。
二、总体要求
（一）指导思想。
全面贯彻党的十九大精神，以习近平新时代中国特色社会主义思想为指导，落实全国科技创新大会精神，统筹推进“五位一体”总体布局和协调推进“四个全面”战略布局，牢固树立和贯彻落实创新、协调、绿色、开放、共享的发展理念，按照《国家创新驱动发展战略纲要》总体要求和外交总体布局，坚持中方主导、前瞻布局、分步推进、量力而行的整体思路，以全球视野谋划科技开放合作，深入落实“一带一路”倡议，遵循共商共建共享原则，积极牵头组织实施大科学计划，着力提升战略前沿领域创新能力和国际影响力，打造创新能力开放合作新平台，推进构建全球创新治理新格局和人类命运共同体，为建设创新型国家和世界科技强国提供有力支撑，为中国特色大国外交作出重要贡献。
（二）基本原则。
国际尖端，科学前沿。适应大科学计划基础性、战略性和前瞻性特点，聚焦国际科技界普遍关注、对人类社会发展和科技进步影响深远的研究领域，选择能够在国际上引起广泛共鸣的项目，力求攻克重大科学问题。
战略导向，提升能力。落实建设世界科技强国“三步走”战略，服务于科技创新和经济社会发展整体战略需要，集聚国内外优秀科技力量，形成一批具有国际影响力的标志性科研成果，全面提升我国科技创新实力。
中方主导，合作共赢。发挥我国在大科学计划核心专家确定、研究问题提出、技术路线选择、科技资源配置、设施选址等问题上的主导作用，尊重各国及各方的优势特长，坚持多国多机构共同参与、优势互补，采取共同出资、实物贡献、成立基金等方式，共享知识产权，实现互利共赢。
创新机制，分步推进。借鉴国际先进经验，注重在大科学计划发起、组织、建设、运行和管理等方面进行系统创新，完善科技资源合作及共享机制，吸引部门、地方共同参加，加强科技界与产业界协作，试点先行，充分论证，根据实施条件成熟一个、启动一个。
（三）主要目标。
总体目标：通过牵头组织大科学计划，在世界科技前沿和驱动经济社会发展的关键领域，形成具有全球影响力的大科学计划布局，开展高水平科学研究，培养引进顶尖科技人才，增强凝聚国际共识和合作创新能力，提升我国科技创新和高端制造水平，推动科技创新合作再上新台阶，努力成为国际重大科技议题和规则的倡导者、推动者和制定者，提升在全球科技创新领域的核心竞争力和话语权。
近期目标：到2020年，培育3—5个项目，研究遴选并启动1—2个我国牵头组织的大科学计划，初步形成牵头组织大科学计划的机制做法，为后续工作探索积累有益经验。
中期目标：到2035年，培育6—10个项目，启动培育成熟项目，形成我国牵头组织的大科学计划初期布局，提升在全球若干科技领域的影响力。
远期目标：到本世纪中叶，培育若干项目，启动培育成熟项目，我国原始科技创新能力显著提高，在国际科技创新治理体系中发挥重要作用，持续为全球重大科技议题作出贡献。
三、重点任务
（一）制定战略规划，确定优先领域。
根据《国家创新驱动发展战略纲要》等部署，结合当前战略前沿领域发展趋势，立足我国现有基础条件，综合考虑潜在风险，组织编制牵头组织大科学计划规划，围绕物质科学、宇宙演化、生命起源、地球系统、环境和气候变化、健康、能源、材料、空间、天文、农业、信息以及多学科交叉领域的优先方向、潜在项目、建设重点、组织机制等，制定发展路线图，明确阶段性战略目标、资金来源、建设方式、运行管理等，科学有序推进各项任务实施。
（二）做好项目的遴选论证、培育倡议和启动实施。
立足我国优势特色领域，根据实施条件成熟度和人力财力保障等情况，遴选具有合作潜力的若干项目进行重点培育，发出相关国际倡议，开展磋商与谈判，视情确定启动实施项目。要加强与国家重大研究布局的统筹协调，做好与“科技创新2030—重大项目”等的衔接，充分利用国家实验室、综合性国家科学中心、国家重大科技基础设施等基础条件和已有优势，实现资源开放共享和人员深入交流。
（三）建立符合项目特点的管理机制。
依托具有国际影响力的国家实验室、科研机构、高等院校、科技社团，通过科研机构间合作或政府间合作等模式，整合各方资源，组建成立专门科研机构、股份公司或政府间国际组织进行大科学计划项目的规划、建设和运营。积极争取把新组建的政府间国际组织总部设在中国。每个大科学计划可成立项目理事会和专家咨询委员会，对项目实施作出决策部署和提供专业化咨询建议。
（四）积极参与他国发起的大科学计划。
继续参与他国发起或多国共同发起的大科学计划，积极承担项目任务，深度参与运行管理，积累组织管理经验，形成与我国牵头组织的大科学计划互为补充、相互支撑、有效联动的良好格局。积极参加重要国际组织的大科学计划相关活动，主动参与大科学计划相关国际规则的起草制定。
四、组织实施保障
（一）加强组织领导和协调管理。
在国家科技计划（专项、基金等）管理部际联席会议机制下，召开牵头组织大科学计划专题会议，由科技部、国家发展改革委、教育部、工业和信息化部、财政部、农业部、国家卫生计生委、国家知识产权局、中科院、工程院、自然科学基金会、国家国防科工局、中央军委装备发展部、中央军委科学技术委员会和中国科协等部门和单位参加，统筹和审议大科学计划的战略规划、发展方向、领域布局、重点任务、项目启动、运行管理机制、知识产权管理和开放共享政策等。
成立由科技界、工程界、产业界等高层次专家组成的大科学计划专家咨询委员会，对大科学计划的优先领域、战略规划、项目论证等进行咨询评审，为国家决策提供参考。战略规划和项目设置等重大事项，经国家科技体制改革和创新体系建设领导小组审议后，按程序报国务院，特别重大事项报党中央。
（二）建立多元化投入和管理机制。
完善财政投入机制，充分利用现有资源和资金渠道，更好发挥财政资金在我国牵头组织大科学计划过程中的引导作用，吸引地方、企业、外国及国际组织的投入。根据实际需求，测算和编制项目经费概算，鼓励社会资本参与，建立多元化投入机制。充分借鉴国际经验，通过有偿使用、知识产权共享等多种方式，吸引国内外政府、科研机构、高等院校、科技社团、企业及国际组织等参与支持大科学计划的建设、运营及管理。
（三）加强高水平专业人才队伍建设。
实施更加积极开放的高层次人才引进政策，依托国家重大人才工程培养和引进大科学计划所需人才，建立支持相关人员参与大科学计划的激励机制。探索建立与国际接轨的全球人才招聘制度，公开招聘世界一流科学家、国际顶尖工程技术人才。加强我国牵头组织大科学计划多层次专业人才队伍建设，构建可持续发展的人才梯队。
（四）建立大科学计划监督评估机制。
建立健全监督评估与动态调整机制，定期对大科学计划的执行情况与成效进行跟踪检查，并将监督评估结果作为项目目标、技术路线、研究任务、预算、进度等调整的重要依据。监督评估结果和调整建议及时报国务院。
]]></content>
      <categories>
        <category>日记</category>
      </categories>
      <tags>
        <tag>工作</tag>
        <tag>大科学工程</tag>
        <tag>中方主导</tag>
        <tag>合作共赢</tag>
      </tags>
  </entry>
  <entry>
    <title>LIFE 沿途的风景</title>
    <url>/2021/08/11/diary-20210811/</url>
    <content><![CDATA[沿途的风景平时上班都是开车，最近开始骑车，发现虽然是同一条道路，看到的风景决然不同。
开车的时候最多的时候是关注同行的车辆还有三色红绿灯🚥。
一旦骑上自行车，发现一切都美好纯粹了起来，风也是热的舒服起来，大汗淋漓。
平时没有留意，偶然看到路边的一汪清水，停下来感受一下。
触手可摸的白云
遥遥相望的嫩柳
如画如镜的清水
不觉已经进入到了秋的日子，虽然天气还是那么的夏。
昨天在给盖宝和达宝读《生命的一天》，两个小家伙竟然提前来2周前给他们度过的《一条聪明的鱼》。小孩子的记忆力真是好。
《生命的一天》把从宇宙大爆炸到现在浓缩成一天24个小时，这样看来恐龙时代存在了接近百分之一的时间，而我们人类是在基本不到两分钟才出现的。
再讲到鱼类爬到陆地上的时候，两个同时说读过这个故事，后来翻了一下，确实是。
希望经过夏的播种，能迎来秋的丰硕。

]]></content>
      <categories>
        <category>日记</category>
        <category>生活</category>
      </categories>
      <tags>
        <tag>读书</tag>
        <tag>life</tag>
        <tag>baby</tag>
        <tag>风景</tag>
        <tag>放松</tag>
      </tags>
  </entry>
  <entry>
    <title>积极牵头组织国际大科学计划和大科学工程方案</title>
    <url>/2022/02/24/diary-20220224-%E7%A7%AF%E6%9E%81%E7%89%B5%E5%A4%B4%E7%BB%84%E7%BB%87%E5%9B%BD%E9%99%85%E5%A4%A7%E7%A7%91%E5%AD%A6%E8%AE%A1%E5%88%92%E5%92%8C%E5%A4%A7%E7%A7%91%E5%AD%A6%E5%B7%A5%E7%A8%8B%E6%96%B9%E6%A1%88/</url>
    <content><![CDATA[学习 国务院印发《积极牵头组织国际大科学计划和大科学工程方案》《方案》要求，要全面贯彻党的十九大精神，以习近平新时代中国特色社会主义思想为指导，落实全国科技创新大会精神，按照《国家创新驱动发展战略纲要》总体要求，聚焦国际科技界普遍关注、对人类社会发展和科技进步影响深远的研究领域，集聚国内外优势力量，积极牵头组织国际大科学计划和大科学工程，着力提升战略前沿领域创新能力和国际影响力，打造创新能力开放合作新平台，推进构建全球创新治理新格局和人类命运共同体，为建设创新型国家和世界科技强国提供有力支撑，为中国特色大国外交作出重要贡献。
《方案》指出，要坚持“国际尖端、科学前沿，战略导向、提升能力，中方主导、合作共赢，创新机制、分步推进”的原则。明确了我国牵头组织国际大科学计划和大科学工程面向2020年、2035年以及本世纪中叶的“三步走”发展目标，提出到本世纪中叶，形成一批具有国际影响力的标志性科研成果，全面提升我国科技创新实力，增强凝聚国际共识和合作创新能力，提升我国在全球科技创新领域的核心竞争力和话语权，为全球重大科技议题作出贡献。

重点关注：其中原则属性
在本世纪中叶，行程一批国际影响力的标志性科研成果。

《方案》从四个方面提出了牵头组织国际大科学计划和大科学工程的重点任务。一是制定战略规划，确定优先领域。结合当前战略前沿领域发展趋势，立足我国现有基础条件，组织编制规划，围绕物质科学、宇宙演化、生命起源、地球系统等领域的优先方向、潜在项目、建设重点、组织机制等，制定发展路线图，科学有序推进各项任务实施。二是做好项目的遴选论证、培育倡议和启动实施。遴选具有合作潜力的若干项目进行重点培育，发出相关国际倡议，开展磋商与谈判，视情确定启动实施项目。要加强与国家重大研究布局的统筹协调，做好与“科技创新2030－重大项目”等的衔接。三是建立符合项目特点的管理机制。依托具有国际影响力的国家实验室、科研机构、高等院校、科技社团，整合各方资源，组建成立专门科研机构、股份公司或政府间国际组织进行大科学计划项目的规划、建设和运营。四是积极参与他国发起的国际大科学计划和大科学工程。继续参与他国发起或多国共同发起的大科学计划，积极承担项目任务，深度参与运行管理，积累组织管理经验，形成与我国牵头组织国际大科学计划和大科学工程互为补充、相互支撑、有效联动的良好格局。
]]></content>
      <categories>
        <category>日记</category>
      </categories>
      <tags>
        <tag>工作</tag>
        <tag>大科学工程</tag>
        <tag>中方主导</tag>
        <tag>合作共赢</tag>
      </tags>
  </entry>
  <entry>
    <title>不让妈妈抱</title>
    <url>/2021/09/20/diary-20210920-daddy-carry-baby/</url>
    <content><![CDATA[不让妈妈抱🐦小鸟自己飞
🐱小猫自己跑，
👶我们都是乖宝宝，
👩不要妈妈抱
👨就让爸爸抱
]]></content>
      <categories>
        <category>日记</category>
      </categories>
      <tags>
        <tag>生活</tag>
        <tag>life</tag>
        <tag>有趣</tag>
        <tag>尴尬</tag>
      </tags>
  </entry>
  <entry>
    <title>舌？</title>
    <url>/2022/03/18/diary-20220318-she/</url>
    <content><![CDATA[she 舌爸爸：宝贝，这个字念“she”
天天：哦，我认识，爸爸，就是蟒蛇she的she
]]></content>
      <categories>
        <category>日记</category>
        <category>生活</category>
      </categories>
      <tags>
        <tag>life</tag>
        <tag>认字</tag>
      </tags>
  </entry>
  <entry>
    <title>看我怎么收拾你</title>
    <url>/2022/04/11/diary-20220411/</url>
    <content><![CDATA[看我怎么收拾你今天居家办公，在书房忙了一会，出去接杯水。
刚出门，看到天文把整个客厅用一条绳子拦了起来，我直接跳了过去，然后念念有词，

竟然挡住我的去路

文哥直接来了一句，

看我怎么收拾你

文哥见势不对，赶紧说

不对，看爸爸怎么收拾我们

妈妈已经笑趴了
]]></content>
      <categories>
        <category>日记</category>
      </categories>
      <tags>
        <tag>生活</tag>
        <tag>词汇</tag>
      </tags>
  </entry>
  <entry>
    <title>老脚？</title>
    <url>/2022/04/12/diary-20220412-feet/</url>
    <content><![CDATA[老脚和小脚文文：爸爸..，我的脚好看吧
爸爸：好看，特别好看，跟爸爸的一样
文文：不一样，爸爸的是老脚，我的是漂亮的小脚
]]></content>
      <categories>
        <category>日记</category>
        <category>生活</category>
      </categories>
      <tags>
        <tag>life</tag>
        <tag>童言无忌</tag>
      </tags>
  </entry>
  <entry>
    <title>黑珠圆笔</title>
    <url>/2022/04/16/diary-20220416-ballpoint-pen/</url>
    <content><![CDATA[黑珠圆笔文文：爸爸..，给我用一下你的黑珠圆笔
爸爸：【黑线飘过】啥？
文文：黑珠圆笔，就这个 【手里拿着一个黑色圆珠笔】
爸爸：好吧，这就是黑珠圆笔
]]></content>
      <categories>
        <category>日记</category>
        <category>生活</category>
      </categories>
      <tags>
        <tag>life</tag>
        <tag>童言无忌</tag>
      </tags>
  </entry>
  <entry>
    <title>溪水里的小鱼</title>
    <url>/2024/01/05/diary-20240105-fish-in-the-water/</url>
    <content><![CDATA[溪水里的小鱼在所有卵中，我觉得最有意思的是鱼卵。
几乎所有鱼卵都是非常小的白色圆球，就像糖丸一样。
有些鱼卵像中等大小的玻璃珠，比如在急流中砾石滩上常见的鳟鱼或鲑鱼卵；还有许多小得能穿过织补针的针眼，比如贴着海面漂浮的海鱼卵。
不管怎样，特别令人感兴趣的是，那么多鱼卵像极了小玻璃球。
其外层薄膜非常清透，卵本身也非常透明，你完全可以用放大镜透视鱼卵，目睹里面的白色斑点从无到有，发育成真正的鱼。
它卧在卵里，身长足以环绕卵一周，尾巴几乎和嘴相连。
有些鱼卵更加清透。最清透的卵起初好似透明玻璃，在水下完全不见踪影。
不久以后，其底部开始形成模糊的小白点。
接着，你能看见卵上覆盖着相当厚的膜，膜中有一个狭窄而清澈的空间，充满了水，里面漂浮着更小的卵黄。
这个时候它才是即将变成小鱼的真正的卵。
卵黄中的白色斑点本身并不是鱼，而是鱼物质，是为逐渐发育成鱼而做的准备。
斑点越长越大，越长越厚，最终，看上去好似涂在大理石边的一圈腻子。
卵膜直径接近卵本身的一半时，中间开始变薄，边缘变厚，形成一个环。
紧接着，这个环会发生非常奇特的变化。它开始长大，并在这个过程中环绕着鱼卵越滑越远，不久便形成以卵为中心的带状物，继续向外滑行，直至卵的另一侧。
当然，它会相应变得小一些。就这样，其多余部分收进环上的某一点，形成小鱼的身体。
在经过卵中心之前，环的增厚部分已经形成鱼头，环的两端形成身体的两部分。鱼尾比较容易发育，所以很久以后才会长出来。现在，小鱼有头和身子了，唯一不同的是头比较大。
它还没有任何器官，没有眼睛、耳朵、鼻子，或完整的嘴，也没有鳍、脊椎、胃，以及鳞片。
这些都会在以后出现，就像小鸡的发育一样——眼睛、耳朵、大脑和心脏先发育，鳍、尾巴和鳞片，以及整个身体前部需要很久以后才发育成形。
许多科学家倾尽毕生精力，研究小动物各种肢体器官形成的方式。
这是一项最奇特，也最令人着迷的课题，值得任何人耗费一生进行研究。
但是，如果要我讲述鱼体最小部位形成的全部过程，本书就没有地方讲述其他故事了。
所以，我只想讲讲眼睛，部分因为它们是有趣而重要的器官，更多的是因为它们形成的方式碰巧和所有脊椎动物眼睛形成的方式相同——无论鱼类，蛙类、鸟类、四足野兽，还是人类。
亲爱的读者，你看这本书的眼睛也是如同我亲眼所见的鳕鱼和海鲈鱼的眼睛那样发育而成。
一般来说，最早形成的身体部位是大脑，紧接着是眼睛。
刚萌生的眼睛像两个蓓蕾，从即将成为头部的大脑两侧冒芽。此时，每只眼睛都是空的，好似挂在短柄上的气泡，很像铅笔头上粘着的空心橡皮球，只是大小不同。
你会以为，这个空心球会直接变成眼球。
可是，你错了，大自然很少简单行事。相反，像你用手指推动橡皮球一样，眼芽的一侧会向内折，直到形成杯状。
这个杯就是眼球。它的边缘长出来，杯口渐渐收缩至我们称之为瞳孔的眼睛中央。
各种各样的眼部物质在其边缘生长，构成眼睛的内部组织。其他组织在外部生长，加厚外壁，形成前面透明的角膜。
此时，瞳孔依然很大，以后会成为表皮的部分物质向眼球内生长，形成眼睛的晶状体。眼芽最初内折形成杯状，随后收缩成为我们最终使用的眼球，这种反向发育的目的是为了将各种物质纳入眼睛，最终留下瞳孔透入光明。
到目前为止，像小鸡一样，小鱼的身体前部还没有发育成形。
小鱼卧在卵黄里，好似肚子疼的孩子，抱着枕头，缩成一团。
渐渐地，尾巴从卵黄中长出来，鱼头也完全抬起来，给下颚留出发育的空间。
最后，身体各部在卵黄周围发育完成，并安置在最恰当的部位。这时，鱼已经做好孵化准备。它时不时地在卵膜中扭动一会儿，最后突破卵膜，漂浮出来。这是一个弱小无助的生命，只比半个卵黄大一点。它不会游泳，只是肚皮朝上漂浮着，嘴巴大张，还没能合拢下巴。从这时起，小鱼以越来越小的卵黄为食，迅速成长。
起初，这个小生命依靠背部浮动，时而摆动一下。随着卵黄变得易于掌控，小鱼越来越频繁地摆动起来。
不久，它翻为侧身，然后完全侧过身来。等到卵黄全部消失，它就侧身游动起来，并且开始进食更小的水生物。
在这个阶段，如果是淡水鱼，你会在浅滩处看见它们成群地游动。
不过，这些鱼长只有6毫米左右，而且多半是眼睛。
]]></content>
      <categories>
        <category>日记</category>
      </categories>
      <tags>
        <tag>life</tag>
        <tag>童言无忌</tag>
        <tag>儿童必读的自然奇迹</tag>
        <tag>天天文文</tag>
      </tags>
  </entry>
  <entry>
    <title>信佛姓佛</title>
    <url>/2024/02/24/diary-20240224-%E4%BF%A1%E4%BD%9B%E5%A7%93%E4%BD%9B/</url>
    <content><![CDATA[信佛姓佛妈妈：妈妈的外婆信佛，一辈子不吃肉
天文：妈妈，幸亏我们姓郭，不姓佛，不然就不能吃肉了
爸爸：一脸黑线
]]></content>
      <categories>
        <category>日记</category>
      </categories>
      <tags>
        <tag>天文</tag>
        <tag>生活</tag>
      </tags>
  </entry>
  <entry>
    <title>走近钱学森</title>
    <url>/2013/07/19/diary-All-about-Tsien-Hsue-shen/</url>
    <content><![CDATA[钱老的经历是传奇的，被美国关了5年，你不知道的钱学森。推荐看看。 
]]></content>
      <categories>
        <category>日记</category>
      </categories>
      <tags>
        <tag>励志</tag>
        <tag>读书</tag>
        <tag>阅读</tag>
        <tag>生活</tag>
        <tag>BOOK</tag>
      </tags>
  </entry>
  <entry>
    <title>山姆·麦克布雷尼</title>
    <url>/2022/04/12/diary-author-%E5%B1%B1%E5%A7%86%E9%BA%A6%E5%85%8B%E5%B8%83%E9%9B%B7%E5%B0%BC/</url>
    <content><![CDATA[山姆·麦克布雷尼山姆·麦克布雷尼（Sam McBratney），1945年出生于爱尔兰的贝尔法斯特。他在爱尔兰的著名学府都柏林主日学院求学多年，原本只是位教师，却在为患有阅读障碍的学生创作故事的同时，喜爱上了故事里丰富的想象力，进而陆续创作了数十本童书，包括JUST ONE!、《你们都是我的最爱》以及全球销售超过一千五百万本的《猜猜我有多爱你》。
安妮塔·婕朗（Anita Jeram），出生于英国朴次茅斯。在曼彻斯特工艺专科学校学习过美术，当她还是一个学生的时候，就为孩子们出版了第一本书。主要作品有《亲亲晚安》（Kiss Good Night）、《塞姆，你觉得不舒服吗？》（Don’t You Feel Well，Sam?）、《小兔，我的甜心》（Bunny，My Honey）。
山姆·麦克布雷尼1945年出生于爱尔兰的贝尔法斯特。他在爱尔兰的著名学府都柏林主日学院求学多年，后成为职业作家。继《猜猜我有多爱你》之后，他又与安妮塔·婕朗合作了《你们都是我的最爱》。
]]></content>
      <categories>
        <category>天文兄弟</category>
      </categories>
      <tags>
        <tag>儿童</tag>
        <tag>life</tag>
        <tag>绘本</tag>
        <tag>美国</tag>
      </tags>
  </entry>
  <entry>
    <title>路德维格贝梅尔曼斯</title>
    <url>/2022/04/12/diary-author-%E8%B7%AF%E5%BE%B7%E7%BB%B4%E6%A0%BC%E8%B4%9D%E6%A2%85%E5%B0%94%E6%9B%BC%E6%96%AF/</url>
    <content><![CDATA[路德维格贝梅尔曼斯路德维格·贝梅尔曼斯1898年4月27日出生于奥地利蒂罗尔州。他的父亲是一位画家，母亲是一位富有的啤酒酿造商的女儿。在他很小的时候，父母就离婚了，他跟随外公长大。他喜欢画画，却遭到了外公的反对。作为一名“问题少年”，他从公立学校转到私立学校，不断地惹是生非，后来还是辍学了。他拿着一叠叔叔写给纽约有名旅馆经理的介绍信，远渡重洋去了美国。可他在纽约的旅馆里没干多久，就因为穿着一只黄色的鞋子和一只白色的鞋子上班而丢掉了饭碗。不过，只要他还能付得起学费，他就去上美术课。1917年，他应征入伍，没有上前线，而是被送到了佐治亚州的一家精神病院当了一名陪伴和德语教师。后来根据这段亲身经历，他还写了一本名叫《我与美国的战争》的引人发笑的传记。第一次世界大战结束后，他又重新回到纽约，并且加入了美国籍。1925年，他得到了一个与别人共同经营“哈布斯堡王朝餐厅”的机会，他在餐厅的墙壁上画画，在自己住的公寓的窗户、窗帘和墙壁上画故乡的风景。有一天，Viking 出版社的童书编辑梅·玛斯看到了这些画，便鼓励他创作图画书。1939年出版的《玛德琳》不但成了他的代表作，还为他赢得了凯迪克奖银奖。十几年后，他又推出了《玛德琳的救援》、《玛德琳和坏帽子》、《玛德琳和吉普赛人》、《玛德琳在伦敦》，其中《玛德琳的救援》获得了1954年凯迪克奖金奖。他一生只创作了十三本图画书。
]]></content>
      <categories>
        <category>天文兄弟</category>
      </categories>
      <tags>
        <tag>儿童</tag>
        <tag>life</tag>
        <tag>绘本</tag>
        <tag>美国</tag>
      </tags>
  </entry>
  <entry>
    <title>这样的美,我无法描绘!(香格里拉)</title>
    <url>/2007/07/29/diary-beautiful-shangri-la/</url>
    <content><![CDATA[湖水都是清的,呼吸也显得是那么的清爽!
平平的锁桥,静静地走过!!
不是风吹草地见牛羊,是另一种美!
!!!!!!!!!!!!!!!
日出日落  !!

笑~~:–)zarina 2008-11-08 00:49哇，我什么时候去亲身体验体验就好了，一定要去！！

]]></content>
      <categories>
        <category>日记</category>
      </categories>
      <tags>
        <tag>生活</tag>
        <tag>香格里拉</tag>
      </tags>
  </entry>
  <entry>
    <title>哈哈，CSDN又支持Windows Live Writer了</title>
    <url>/2014/06/01/diary-csdn-support-wlw/</url>
    <content><![CDATA[从10年开始写CSDN博客，后面不支持WLW了，就不怎么写了，话说自带的编辑器确实不怎么样，不过又支持了，那就哈哈，重新开工了。
关于如何配置的，跟以前一样，详情如下所示：
http://blog.csdn.net/csdnproduct/article/details/27504397
话说经常上CSDN的肯定都是IT童鞋们，在Linux上怎么配置呢，参考：
http://blog.csdn.net/cnsword/article/details/27582331
]]></content>
      <categories>
        <category>blog</category>
        <category>Linux</category>
        <category>CSDN</category>
        <category>DIARY</category>
        <category>LIFE</category>
        <category>日记</category>
        <category>生活</category>
      </categories>
      <tags>
        <tag>blog</tag>
        <tag>csdn</tag>
        <tag>wlw</tag>
      </tags>
  </entry>
  <entry>
    <title>跳舞吧，小雅</title>
    <url>/2021/07/19/diary-dance-tanya/</url>
    <content><![CDATA[跳舞吧，小雅
看来你们家出了两位芭蕾舞明星呢。

爱跳舞的小雅最后终于通过自己的努力争取了妈妈的认可。
]]></content>
      <categories>
        <category>日记</category>
      </categories>
      <tags>
        <tag>阅读</tag>
        <tag>儿童</tag>
        <tag>文学</tag>
        <tag>天文读书</tag>
        <tag>生活</tag>
        <tag>帕特里夏</tag>
      </tags>
  </entry>
  <entry>
    <title>有那么一天</title>
    <url>/2021/07/15/diary-es-gibt-so-tage/</url>
    <content><![CDATA[有那么一天
有那么一天，无论是谁，都可以互相依靠。


有那么一天，所有的人都抬头仰望着天空。


有那么一天，所有的影子变得色彩斑斓。

]]></content>
      <categories>
        <category>日记</category>
      </categories>
      <tags>
        <tag>阅读</tag>
        <tag>儿童</tag>
        <tag>文学</tag>
        <tag>天文读书</tag>
        <tag>生活</tag>
        <tag>汉斯·雅尼什</tag>
      </tags>
  </entry>
  <entry>
    <title>金庸再见</title>
    <url>/2018/10/30/diary-goodbye-jinyong/</url>
    <content><![CDATA[金庸再见飞雪连天射白鹿，笑书神侠倚碧鸳
再见亦是江湖
]]></content>
      <categories>
        <category>日记</category>
      </categories>
      <tags>
        <tag>生活</tag>
        <tag>武侠</tag>
      </tags>
  </entry>
  <entry>
    <title>IBM 收购 Redhat &amp;&amp; 咏远有李</title>
    <url>/2018/10/29/diary-ibm-buy-redhat/</url>
    <content><![CDATA[IBM 收购 Redhat &amp;&amp; 咏远有李时光像指尖的沙漏，不留情面滴匆匆滑落，重阳、霜降马上就要立冬了。
看起来今年好像已经接近尾声了。
经历了春的娇艳/夏的火热/秋的繁华，在冬日的暖阳中又开始喋喋不休了。
今天去办事的时候读到两个消息，一个是蓝色巨人IBM斥资340亿美元收购Linux巨头Red Hat，这应该是今年Microsoft收购Github后的有一个重磅消息，也是开源市场有史以来的最大一次交易，看来free is not free；另一个就是李咏，咏哥是我比较喜欢的主持人，仔细算算好像是真的好久没有见到他了，愿他安息，一路走好，也希望医学界继续能给患者们带来一些福音。
也是在工作中碰到一些需要Linux GNU Build System，所以花了一些时间研究了一下相关内容，絮絮叨叨一些基本够用的知识，其他的做为非主文也是基本够了，OK，是时候开始下一段旅程了….
]]></content>
      <categories>
        <category>日记</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>生活</tag>
        <tag>IBM</tag>
        <tag>Redhat</tag>
      </tags>
  </entry>
  <entry>
    <title>WORK 今天完成文件io流的测试及LTA的测试</title>
    <url>/2011/10/26/diary-io-test/</url>
    <content><![CDATA[今天完成文件io流的测试及LTA的测试关于文件IO流的读书笔记明天有时间贴上。
今天主要做了一下GTK and pgplot的test
]]></content>
      <categories>
        <category>日记</category>
        <category>生活</category>
      </categories>
      <tags>
        <tag>PCI</tag>
        <tag>share memory</tag>
      </tags>
  </entry>
  <entry>
    <title>小米出问题，开机无法启动，换回原来的版本OK</title>
    <url>/2012/05/11/diary-mi-problem/</url>
    <content><![CDATA[详细情况：
开机后画面停留在白色MI，然后就是死等也等不开机。如此这般，设置无法关机，只能拔掉电板。
解决方法：

按住开机键 和 音量+ ；
选择（按电源键选择）简体中文，选择重启手机；
这时候提示两个系统 选择后缀没有注释最近的选项，然后OK。

PS.有注释的也就是无法启动的OS，我的问题应该是在MIUI上安装busybox导致的。
本来打算重新刷机的，看来不用了。
嘻嘻。
高兴
]]></content>
      <categories>
        <category>日记</category>
        <category>生活</category>
      </categories>
      <tags>
        <tag>mi</tag>
      </tags>
  </entry>
  <entry>
    <title>当你老了</title>
    <url>/2007/10/26/diary-poem-when-you-are-old/</url>
    <content><![CDATA[When you are old  当你老了第一次读到这首诗，是中文翻译版，应该还是大学的时候，每次读，都感觉是如此的唯美。
翻译的版本，有很多，感觉最喜欢的是袁可嘉的那一版。
When you are old - William Butler Yeats
When you are old
— William Butler Yeats
When you are old and grey and full of sleep，
And nodding by the fire, take down this book，
And slowly read，and dream of the soft look。
Your eyes had once，and of their shadows deep；
How many loved your moments of glad grace，
And loved your beauty with love false or true，
But one man loved the pilgrim Soul in you，
And loved the sorrows of your changing face；
And bending down beside the glowing bars，
Murmur，a little sadly，how Love fled。
And paced upon the mountains overhead，
And hid his face amid a crowd of stars。

当你老了 - 袁可嘉
 当你老了
翻译：袁可嘉*
当你老了，头白了，睡意昏沉，
炉火旁打盹，请取下这部诗歌，
慢慢读，回想你过去眼神的柔和，
回想它们昔日浓重的阴影；
多少人爱你青春欢畅的时辰，
爱慕你的美丽，假意或真心，
只有一个人爱你那朝圣者的灵魂，
爱你衰老了的脸上痛苦的皱纹；
垂下头来，在红光闪耀的炉子旁，
凄然地轻轻诉说那爱情的消逝，
在头顶的山上它缓缓踱着步子，
在一群星星中间隐藏着脸庞。


How many memories does this poem hit you?

]]></content>
      <categories>
        <category>日记</category>
        <category>生活</category>
      </categories>
      <tags>
        <tag>叶芝</tag>
        <tag>诗歌</tag>
      </tags>
  </entry>
  <entry>
    <title>WORK 完成share memory的测试</title>
    <url>/2011/10/24/diary-share-memory-test/</url>
    <content><![CDATA[今天完成了share memory的测试今天在hcorr上完成了share memory的测试。
通过PCI驱动存取LTA数据并通过PGPLOT实时刷新显示。
工作流程：
#include&lt;sys/types.h&gt;#include&lt;sys/ipc.h&gt;#include&lt;sys/shm.h&gt;

create share memoryshm_id = shmget(shm_key_id, SHM_BUF_SIZE, 0666|IPC_CREAT);if (shm_id &lt; 0) {         perror(“share memory error.”);         exit(1);}shm_data_buf= shmat(shm_id,0,1);


using share memoryshm_id = shmget(shm_key_id, SHM_BUF_SIZE, 0666);while (shm_id &lt; 0) {         printf(“waiting the share memory content …%dr”, j++);         sleep(1);}shm_data_buf = shmat(shm_id, 0, 1);
]]></content>
      <categories>
        <category>工作</category>
        <category>日记</category>
        <category>生活</category>
      </categories>
      <tags>
        <tag>PCI</tag>
        <tag>share memory</tag>
      </tags>
  </entry>
  <entry>
    <title>内心足够强大</title>
    <url>/2011/05/03/diary-strong-heart/</url>
    <content><![CDATA[内心足够强大
心情相当平静
]]></content>
      <categories>
        <category>日记</category>
        <category>生活</category>
      </categories>
      <tags>
        <tag>heart</tag>
      </tags>
  </entry>
  <entry>
    <title>研究生导师培训</title>
    <url>/2018/11/25/diary-supervisor-train/</url>
    <content><![CDATA[任重而道远的研究生导师第二次来到依然幽静的岳阳路，熙熙攘攘的人群从乍一拐进岳阳路就消失不见，特别喜欢这种闹市中安静的一隅。
这几天参加研究生导师的培训，本来以为做好了准备，过来听了听报告，发现还有很多东西是需要学习和补充的。
师者
DAY 1DAY 2DAY 3]]></content>
      <categories>
        <category>日记</category>
        <category>生活</category>
      </categories>
      <tags>
        <tag>导师</tag>
      </tags>
  </entry>
  <entry>
    <title>手心的魔法</title>
    <url>/2021/07/17/diary-tenohira/</url>
    <content><![CDATA[手心的魔法特别温馨可爱的想法，跟《窗边的小豆豆》有同样的感觉。

是呀，这是一个‘想哭就哭’的圈圈。

想哭的时候就哭，而真正看着的时候就笑了起来。
]]></content>
      <categories>
        <category>日记</category>
        <category>生活</category>
        <category>天文读书</category>
      </categories>
      <tags>
        <tag>阅读</tag>
        <tag>儿童</tag>
        <tag>文学</tag>
        <tag>泷村有子</tag>
      </tags>
  </entry>
  <entry>
    <title>隧道</title>
    <url>/2021/09/21/diary-the-monster-who-ate-darkness/</url>
    <content><![CDATA[吃掉黑暗的怪兽如果没有黑暗，世界会变成什么样呢？

它用又大又黑的双臂，把球球抱紧怀里。
球球觉得滑溜溜的，又柔软又舒服。
怪兽轻轻地摇晃，球球就好像躺在摇篮里。
怪兽还轻声哼着一首嘿啦啦摇篮曲。

]]></content>
      <categories>
        <category>日记</category>
        <category>生活</category>
        <category>天文读书</category>
      </categories>
      <tags>
        <tag>读书</tag>
        <tag>阅读</tag>
        <tag>儿童</tag>
        <tag>文学</tag>
        <tag>乔伊斯·邓巴</tag>
        <tag>几米</tag>
      </tags>
  </entry>
  <entry>
    <title>隧道</title>
    <url>/2021/09/21/diary-the-tunnel/</url>
    <content><![CDATA[隧道我以为天哥文哥听不下去，不料听得津津有味，哈哈。
故事的设定特别好，怕黑的妹妹为了哥哥，独自穿越隧道。
为了爱的人，克服恐惧。

“露丝，我就知道你回来。”哥哥说。

]]></content>
      <categories>
        <category>日记</category>
        <category>生活</category>
        <category>天文读书</category>
        <category>蒲蒲兰绘本馆</category>
      </categories>
      <tags>
        <tag>读书</tag>
        <tag>阅读</tag>
        <tag>儿童</tag>
        <tag>文学</tag>
        <tag>安东尼·布朗</tag>
      </tags>
  </entry>
  <entry>
    <title>Diary 向逝去的大牛人致敬</title>
    <url>/2011/10/26/diary-to-great-man/</url>
    <content><![CDATA[向逝去的大牛人致敬Steve Jobs 卸任后，2个月就辞世了；
Dennis Ritchie，c语言和UNIX之父，也辞世了；
今天刚刚收到消息Lisp之父，人工智能之父John McCarthy辞世
大牛们果然是一起来的，也是一起去呀………………
]]></content>
      <categories>
        <category>日记</category>
        <category>生活</category>
      </categories>
      <tags>
        <tag>Steve Jobs</tag>
        <tag>Dennis Ritchie</tag>
        <tag>John McCarthy</tag>
      </tags>
  </entry>
  <entry>
    <title>鳄鱼怕怕牙医怕怕</title>
    <url>/2021/03/13/diary-%E4%BA%94%E5%91%B3%E5%A4%AA%E9%83%8E-%E9%B3%84%E9%B1%BC%E6%80%95%E6%80%95%E7%89%99%E5%8C%BB%E6%80%95%E6%80%95/</url>
    <content><![CDATA[鳄鱼怕怕 牙医怕怕很简单有趣的故事。
鳄鱼牙痛不得不去看牙医，心里怕怕。牙医不得不给鳄鱼看牙病，也是心里怕怕。两人心里都在打鼓，又不得不做。
这个绘本除了绘图生动幽默外，一左一右，两厢的“心里打鼓”相映成趣。一见面，两个都“啊”的一声，接着两边都心惊惊地想“我一定得去吗？”，又鼓励自己“我一定要勇敢”　……，哈哈，他一会儿看看左边的鳄鱼“怕怕”，一会儿看看右边的牙医“怕怕”，一定是件很有趣的事。
]]></content>
      <categories>
        <category>天文兄弟</category>
      </categories>
      <tags>
        <tag>儿童</tag>
        <tag>绘本</tag>
        <tag>五味太郎</tag>
        <tag>1984</tag>
        <tag>日本《妈妈选择的128本图画书》</tag>
        <tag>日本精选世界447本童书</tag>
        <tag>信谊世界精选图画书</tag>
      </tags>
  </entry>
  <entry>
    <title>哈里霍斯-小兔子去上学</title>
    <url>/2021/03/13/diary-%E5%93%88%E9%87%8C%E9%9C%8D%E6%96%AF-%E5%B0%8F%E5%85%94%E5%AD%90%E5%8E%BB%E4%B8%8A%E5%AD%A6-little-rabbit-goes-to-school/</url>
    <content><![CDATA[哈里霍斯-小兔子去上学TODO
]]></content>
      <categories>
        <category>天文兄弟</category>
      </categories>
      <tags>
        <tag>儿童</tag>
        <tag>绘本</tag>
        <tag>哈里霍斯</tag>
        <tag>蒲蒲兰绘本馆</tag>
      </tags>
  </entry>
  <entry>
    <title>埃里克罗曼-我的兔子朋友</title>
    <url>/2021/04/13/diary-%E5%9F%83%E9%87%8C%E5%85%8B%E7%BD%97%E6%9B%BC-%E6%88%91%E7%9A%84%E5%85%94%E5%AD%90%E6%9C%8B%E5%8F%8B-my-friend-rabbit/</url>
    <content><![CDATA[埃里克罗曼-我的兔子朋友TODO
]]></content>
      <categories>
        <category>天文兄弟</category>
      </categories>
      <tags>
        <tag>儿童</tag>
        <tag>绘本</tag>
        <tag>埃里克罗曼</tag>
        <tag>美国凯迪克大奖</tag>
      </tags>
  </entry>
  <entry>
    <title>三只小猪</title>
    <url>/2021/03/13/diary-%E5%A4%A7%E5%8D%AB%E5%A8%81%E6%96%AF%E7%BA%B3-%E4%B8%89%E5%8F%AA%E5%B0%8F%E7%8C%AA/</url>
    <content><![CDATA[三只小猪TODO
]]></content>
      <categories>
        <category>天文兄弟</category>
      </categories>
      <tags>
        <tag>儿童</tag>
        <tag>绘本</tag>
        <tag>大卫威斯纳</tag>
      </tags>
  </entry>
  <entry>
    <title>像爸爸一样-just-like-my-dad</title>
    <url>/2021/10/30/diary-%E5%A4%A7%E5%8D%AB%E6%A2%85%E6%9E%97-%E5%83%8F%E7%88%B8%E7%88%B8%E4%B8%80%E6%A0%B7-just-like-my-dad/</url>
    <content><![CDATA[像爸爸一样一位好爸爸，胜过一百位好老师
送给父母和孩子很好的礼物
看到爸爸藏在小树后面捉迷藏，忍俊不禁~
]]></content>
      <categories>
        <category>天文兄弟</category>
      </categories>
      <tags>
        <tag>儿童</tag>
        <tag>life</tag>
        <tag>绘本</tag>
        <tag>大卫梅林</tag>
        <tag>凯特格林威大奖</tag>
        <tag>2岁</tag>
      </tags>
  </entry>
  <entry>
    <title>打瞌睡的房子</title>
    <url>/2022/03/13/diary-%E5%A5%A5%E6%88%B4%E8%8E%89%E4%BC%8D%E5%BE%B7-%E6%89%93%E7%9E%8C%E7%9D%A1%E7%9A%84%E6%88%BF%E5%AD%90-the-napping-house/</url>
    <content><![CDATA[打瞌睡的房子
图与文的天作之合


]]></content>
      <categories>
        <category>天文兄弟</category>
      </categories>
      <tags>
        <tag>儿童</tag>
        <tag>绘本</tag>
        <tag>1984</tag>
        <tag>奥戴莉伍德</tag>
        <tag>美国图书馆协会杰出童书奖</tag>
        <tag>纽约时报最佳儿童图画书奖</tag>
        <tag>美国童书作家协会金风筝奖</tag>
        <tag>美国全国英语教师协会最佳选书</tag>
        <tag>每个人都应该知道的100本图画书</tag>
        <tag>教师们推荐的100本书</tag>
      </tags>
  </entry>
  <entry>
    <title>威廉斯雷特-月亮生气了</title>
    <url>/2021/05/13/diary-%E5%A8%81%E5%BB%89%E6%96%AF%E9%9B%B7%E7%89%B9-%E6%9C%88%E4%BA%AE%E7%94%9F%E6%B0%94%E4%BA%86-the-angry-moon/</url>
    <content><![CDATA[威廉斯雷特-月亮生气了TODO
]]></content>
      <categories>
        <category>天文兄弟</category>
      </categories>
      <tags>
        <tag>儿童</tag>
        <tag>绘本</tag>
        <tag>威廉斯雷特-月亮生气了</tag>
      </tags>
  </entry>
  <entry>
    <title>我爸爸</title>
    <url>/2021/04/13/diary-%E5%AE%89%E4%B8%9C%E5%B0%BC%E5%B8%83%E6%9C%97-%E6%88%91%E7%88%B8%E7%88%B8-my-dada/</url>
    <content><![CDATA[我爸爸世界上总有一个人是你最安全的依靠。
]]></content>
      <categories>
        <category>天文兄弟</category>
      </categories>
      <tags>
        <tag>儿童</tag>
        <tag>绘本</tag>
        <tag>安东尼布朗</tag>
        <tag>热门儿童绘本TOP20</tag>
      </tags>
  </entry>
  <entry>
    <title>你看起来好像很好吃</title>
    <url>/2022/04/12/diary-%E5%AE%AB%E8%A5%BF%E8%BE%BE%E4%B9%9F-%E4%BD%A0%E7%9C%8B%E8%B5%B7%E6%9D%A5%E5%A5%BD%E5%83%8F%E5%BE%88%E5%A5%BD%E5%90%83-you-are-yumyum/</url>
    <content><![CDATA[你看起来好像很好吃可爱萌萌哒霸王龙
很久以前，在一个晴朗的日子里，山嘭嘭嘭地喷火，地咚咚咚地摇晃。这时，甲龙宝宝出生了。一天，它遇到了一头霸王龙，霸王龙流着口水，想要猛扑过去。就在这时，霸王龙忽然听到“爸爸”，原想吃掉小甲龙的霸王龙被小甲龙的一句“我想早点长得像爸爸一样！”击中了心底的柔情，从而改变了小甲龙和霸王龙之间的关系。小甲龙与霸王龙之间的感人的亲情让人为之动容，孩子在听故事之余，更可以潜移默化地体验到爱与被爱的快乐、人与人之间交往的真谛。
]]></content>
      <categories>
        <category>天文兄弟</category>
      </categories>
      <tags>
        <tag>儿童</tag>
        <tag>life</tag>
        <tag>绘本</tag>
        <tag>宫西达也</tag>
        <tag>蒲蒲兰</tag>
        <tag>日本</tag>
        <tag>豆瓣热门儿童绘本</tag>
      </tags>
  </entry>
  <entry>
    <title>你真好</title>
    <url>/2022/04/12/diary-%E5%AE%AB%E8%A5%BF%E8%BE%BE%E4%B9%9F-%E4%BD%A0%E7%9C%9F%E5%A5%BD-how-wonderful-you-are/</url>
    <content><![CDATA[你真好可爱的薄片龙改变了霸王龙
从前，有一只粗暴的、坏心眼的、狡猾的、任性的霸王龙，他总是欺负弱小。但他掉到海里，被善良的薄片龙救出来后，他就跟薄片龙交上朋友。他们天天在一起，霸王龙想到永远跟薄片龙在一起。可是，一天薄片龙被海里的坏家伙咬……
]]></content>
      <categories>
        <category>天文兄弟</category>
      </categories>
      <tags>
        <tag>儿童</tag>
        <tag>life</tag>
        <tag>绘本</tag>
        <tag>宫西达也</tag>
        <tag>蒲蒲兰</tag>
        <tag>日本</tag>
      </tags>
  </entry>
  <entry>
    <title>我相信你</title>
    <url>/2022/04/12/diary-%E5%AE%AB%E8%A5%BF%E8%BE%BE%E4%B9%9F-%E6%88%91%E7%9B%B8%E4%BF%A1%E4%BD%A0-i-believe-in-you/</url>
    <content><![CDATA[你真好信任可以改变霸王龙
]]></content>
      <categories>
        <category>天文兄弟</category>
      </categories>
      <tags>
        <tag>儿童</tag>
        <tag>life</tag>
        <tag>绘本</tag>
        <tag>宫西达也</tag>
        <tag>蒲蒲兰</tag>
        <tag>日本</tag>
      </tags>
  </entry>
  <entry>
    <title>我爱你</title>
    <url>/2022/04/12/diary-%E5%AE%AB%E8%A5%BF%E8%BE%BE%E4%B9%9F-%E6%88%91%E7%88%B1%E4%BD%A0-i-ove-you/</url>
    <content><![CDATA[我爱你可爱萌萌哒霸王龙
以前，以前，很久以前，恐龙们住在世界上各个地方。住在北方的恐龙和住在南方的恐龙完全不一样，颜色、长相，甚至说的语言都不一样。住在北方的霸王龙在下雪天里找不到吃的，饿的实在不行了，被一只它蓓翼龙骗去南方，它蓓翼龙咬伤后，看见了三只正在吃红果子的三只平头龙……
]]></content>
      <categories>
        <category>天文兄弟</category>
      </categories>
      <tags>
        <tag>儿童</tag>
        <tag>life</tag>
        <tag>绘本</tag>
        <tag>宫西达也</tag>
        <tag>蒲蒲兰</tag>
        <tag>日本</tag>
        <tag>book</tag>
      </tags>
  </entry>
  <entry>
    <title>最爱的是我</title>
    <url>/2022/04/12/diary-%E5%AE%AB%E8%A5%BF%E8%BE%BE%E4%B9%9F-%E6%9C%80%E7%88%B1%E7%9A%84%E6%98%AF%E6%88%91-i-am-loved-the-most/</url>
    <content><![CDATA[最爱的是我很久以前的一天，霸王龙在小山上发现了几个蛋，当他张开大嘴要把它们吃掉的时候……咔吧咔吧，几只甲龙宝宝出生了。甲龙宝宝把霸王龙当成了爸爸……当甲龙宝宝遇到危险时、当甲龙宝宝间相互产生矛盾时，霸王龙都肩负起一个“父亲”的责任。甲龙宝宝与霸王龙之间的感人的亲情让人为之动容，孩子在听故事之余，更可以潜移默化地体验到爱与被爱的快乐
这套绘本让我们沉浸在这个充满爱、善良和童真的世界里，抛开虚假的掩饰，共同体验和感受这种因爱和善良而生的幸福之感。绘本画面颜色鲜明、亮丽，作者用力度感极强的粗线条勾勒出一个生动的恐龙世界，并细致入微地描绘了它们的心理活动。文字与图画融为一体，生动形象地将故事娓娓道来。在爱与被爱之间存在着循环往复的通道，每一个人心里都有一颗爱的种子。小读者在这套书中能体验爱与被爱的快乐， 人与人之间交往的真谛。
]]></content>
      <categories>
        <category>天文兄弟</category>
      </categories>
      <tags>
        <tag>儿童</tag>
        <tag>life</tag>
        <tag>绘本</tag>
        <tag>宫西达也</tag>
        <tag>蒲蒲兰</tag>
        <tag>日本</tag>
      </tags>
  </entry>
  <entry>
    <title>永远永远爱你</title>
    <url>/2022/04/12/diary-%E5%AE%AB%E8%A5%BF%E8%BE%BE%E4%B9%9F-%E6%B0%B8%E8%BF%9C%E6%B0%B8%E8%BF%9C%E7%88%B1%E4%BD%A0-i-will-awlays-love-you/</url>
    <content><![CDATA[永远永远爱你可爱萌萌哒霸王龙
善良的慈母龙妈妈捡回了一个蛋，谁知破壳而出的竟是霸王龙的宝宝！慈母龙妈妈一开始很发愁：要是孩子将来知道自己是霸王龙，那可怎么办啊！不过，慈母龙妈妈还是把霸王龙宝宝留了下来，并给它起名良太，希望它永远心地善良。
在妈妈的关爱下，两个小家伙一天天长大了。他俩非常要好，像亲兄弟一样。一天，良太独自去采红果子，竟然遇到了可怕的霸王龙。霸王龙闻到良太的味道，还以为是好吃的慈母龙呢。在与霸王龙一同去找“好吃的东西”时……
]]></content>
      <categories>
        <category>天文兄弟</category>
      </categories>
      <tags>
        <tag>儿童</tag>
        <tag>life</tag>
        <tag>绘本</tag>
        <tag>宫西达也</tag>
        <tag>蒲蒲兰</tag>
        <tag>日本</tag>
      </tags>
  </entry>
  <entry>
    <title>遇到你真好</title>
    <url>/2022/04/12/diary-%E5%AE%AB%E8%A5%BF%E8%BE%BE%E4%B9%9F-%E9%81%87%E5%88%B0%E4%BD%A0%E7%9C%9F%E5%A5%BD-the-only-chance-in-one&#39;s-life/</url>
    <content><![CDATA[遇到你真好可爱萌萌哒霸王龙
棘龙宝宝到海边来摘红果子，不幸遇到了前来捕食的霸王龙。霸王龙一步步逼近，向棘龙宝宝张开血盆大口之时，轰隆隆，一阵地动山摇……他们被迫开始了一段海上漂泊之旅……
]]></content>
      <categories>
        <category>天文兄弟</category>
      </categories>
      <tags>
        <tag>儿童</tag>
        <tag>life</tag>
        <tag>绘本</tag>
        <tag>宫西达也</tag>
        <tag>蒲蒲兰</tag>
        <tag>日本</tag>
      </tags>
  </entry>
  <entry>
    <title>猜猜我有多爱你</title>
    <url>/2021/03/13/diary-%E5%B1%B1%E5%A7%86%E9%BA%A6%E5%85%8B%E5%B8%83%E9%9B%B7%E5%B0%BC-%E7%8C%9C%E7%8C%9C%E6%88%91%E6%9C%89%E5%A4%9A%E7%88%B1%E4%BD%A0guess-how-mush-i-love-you/</url>
    <content><![CDATA[猜猜我有多爱你guess-how-mush-i-love-you原来爱还可以这样告白！一篇经久不衰的睡前故事，可以放在床头时时阅读。
当你很爱一个人的时候，很难描述出来那种感觉，只是知道很多很多。
“我爱你一直到月亮那里，再从月亮上回到这里来。”
]]></content>
      <categories>
        <category>天文兄弟</category>
      </categories>
      <tags>
        <tag>儿童</tag>
        <tag>绘本</tag>
        <tag>热门儿童绘本TOP20</tag>
        <tag>宫西达也</tag>
        <tag>蒲蒲兰</tag>
        <tag>豆瓣热门儿童绘本</tag>
        <tag>山姆麦克布雷尼</tag>
        <tag>1994</tag>
        <tag>美国图书馆学会年度好书</tag>
        <tag>美国《出版者周刊》年度最佳图书</tag>
        <tag>美国书商协会年度童书奖</tag>
        <tag>美国《出版者周刊》“所有时代最畅销童书”</tag>
        <tag>美国全国教育协会推荐的100本最佳童书</tag>
        <tag>美国全国教育协会“教师们推荐的100本书”</tag>
        <tag>美国全国教育协会“孩子们推荐的100本书”</tag>
        <tag>美国收录44部“20世纪最重要的图画书”的《20世纪童书宝库》</tag>
      </tags>
  </entry>
  <entry>
    <title>小熊不刷牙</title>
    <url>/2021/03/13/diary-%E6%96%AF%E4%BC%90%E6%8B%89%E7%BA%B3%E6%8F%90%E6%AC%A7%E5%88%A9%E9%82%A3-%E5%B0%8F%E7%86%8A%E4%B8%8D%E5%88%B7%E7%89%99/</url>
    <content><![CDATA[小熊不刷牙TODO
]]></content>
      <categories>
        <category>天文兄弟</category>
      </categories>
      <tags>
        <tag>儿童</tag>
        <tag>绘本</tag>
        <tag>斯伐拉纳提欧利那</tag>
      </tags>
  </entry>
  <entry>
    <title>你住在哪里</title>
    <url>/2022/09/21/diary-%E6%9C%B1%E6%96%AF%E8%92%82%E5%A8%9C%E5%BE%B7%E6%8B%89%E6%88%88%E5%B8%8C-%E4%BD%A0%E4%BD%8F%E5%9C%A8%E5%93%AA%E9%87%8C/</url>
    <content><![CDATA[你住在哪里今天陪天天文文读朱斯蒂娜的你住在哪里。
这个时候，天天文文应该还没有家的概念，所以我们看看不同的人、动物或者植物都在什么地方居住吧。
这个里面包括城市、乡村、巢穴、洞穴亦或是船只，不管在哪里，家永远都是最幸福的。

]]></content>
      <categories>
        <category>天文兄弟</category>
      </categories>
      <tags>
        <tag>儿童</tag>
        <tag>绘本</tag>
        <tag>朱斯蒂娜</tag>
        <tag>逻辑思维</tag>
        <tag>翻翻书</tag>
      </tags>
  </entry>
  <entry>
    <title>李贤珠-白色画布</title>
    <url>/2019/03/13/diary-%E6%9D%8E%E8%B4%A4%E7%8F%A0-%E7%99%BD%E8%89%B2%E7%94%BB%E5%B8%83/</url>
    <content><![CDATA[李贤珠-白色画布太有趣了，
主人公小米用手中的蜡笔，绘出了一片纯白的天地。在这片天地中，小米遇到了啄木鸟爷爷、熊叔叔、青蛙姑娘、兔宝宝和兔妈妈。她用手中那支神奇的画笔创造了许许多多的奇迹。
]]></content>
      <categories>
        <category>天文兄弟</category>
      </categories>
      <tags>
        <tag>李贤珠</tag>
        <tag>博洛尼亚国际儿童书展最佳童书奖</tag>
        <tag>世界插画师巨匠展获奖画家代表作品</tag>
        <tag>韩国、法国两国同步出版的优秀绘本</tag>
      </tags>
  </entry>
  <entry>
    <title>比尔布莱森-万物简史-a-really-short-history-of-nearly-everything.md</title>
    <url>/2023/03/02/diary-%E6%AF%94%E5%B0%94%E5%B8%83%E8%8E%B1%E6%A3%AE-%E4%B8%87%E7%89%A9%E7%AE%80%E5%8F%B2-a-really-short-history-of-nearly-everything/</url>
    <content><![CDATA[比尔布莱森-万物简史-a-really-short-history-of-nearly-everything为天地立传 为万物简史
]]></content>
      <categories>
        <category>天文兄弟</category>
      </categories>
      <tags>
        <tag>儿童</tag>
        <tag>life</tag>
        <tag>绘本</tag>
        <tag>比尔布莱森</tag>
        <tag>欧盟委员会笛卡尔科普奖</tag>
        <tag>英国皇家学会安万特奖</tag>
        <tag>美国科学杂志最佳科学著作奖</tag>
        <tag>首届中华优秀出版物奖</tag>
        <tag>吴大猷科学普及奖及著作奖</tag>
        <tag>国家图书馆文津图书奖</tag>
        <tag>新中国60年最具影响力的600本书</tag>
        <tag>改革开发30年最具影响力的300本书</tag>
        <tag>改革开发30年30部优秀科普翻译图书</tag>
        <tag>大块头</tag>
        <tag>6岁</tag>
        <tag>中国</tag>
      </tags>
  </entry>
  <entry>
    <title>小脚尖蒂米的故事-the-tale-of-timmy-tiptose</title>
    <url>/2022/10/30/diary-%E6%AF%95%E7%BF%A0%E5%85%8B%E4%B8%9D%E6%B3%A2%E7%89%B9-%E5%B0%8F%E8%84%9A%E5%B0%96%E8%92%82%E7%B1%B3%E7%9A%84%E6%95%85%E4%BA%8B-the-tale-of-timmy-tiptose/</url>
    <content><![CDATA[小脚尖蒂米的故事听到吃胖了爬不出洞来， 让人忍俊不禁~
]]></content>
      <categories>
        <category>天文兄弟</category>
      </categories>
      <tags>
        <tag>儿童</tag>
        <tag>life</tag>
        <tag>绘本</tag>
        <tag>毕翠克丝波特</tag>
        <tag>3岁</tag>
      </tags>
  </entry>
  <entry>
    <title>比特兔的故事-the-tale-of-peter-rabbit</title>
    <url>/2022/10/12/diary-%E6%AF%95%E7%BF%A0%E5%85%8B%E4%B8%9D%E6%B3%A2%E7%89%B9-%E6%AF%94%E7%89%B9%E5%85%94%E7%9A%84%E6%95%85%E4%BA%8B-the-tale-of-peter-rabbit/</url>
    <content><![CDATA[彼得兔的故事-the tale of peter rabbit历经百年，获奖无数，依旧被世界喜欢的彼得兔。
所有的孩子都应该知道的“彼得兔”。
《比得兔》的创作来自于1893年，波特小姐写给她家庭教师的五岁儿子的信件。这位家庭老师的儿子长期卧病在床，波特小姐不知道这封信该说些什么，就讲个故事作为这位小男孩的娱乐，并且在故事当中鼓励他。 
]]></content>
      <categories>
        <category>天文兄弟</category>
      </categories>
      <tags>
        <tag>儿童</tag>
        <tag>life</tag>
        <tag>绘本</tag>
        <tag>毕翠克丝波特</tag>
        <tag>3岁</tag>
        <tag>百年绘本</tag>
        <tag>美国纽约公共图书馆-每个人都应该知道的100种图画书</tag>
        <tag>美国出版者周刊-所有时代最畅销童书-第2名</tag>
        <tag>美国全国教育协会-100本最佳童书</tag>
        <tag>美国全国教育协会-教师们推荐的100本书</tag>
        <tag>日本儿童文学者协会-世界图画书100选</tag>
        <tag>1902年</tag>
      </tags>
  </entry>
  <entry>
    <title>濑名惠子-小洋葱大作战</title>
    <url>/2022/12/12/diary-%E6%BF%91%E5%90%8D%E6%83%A0%E5%AD%90-%E5%B0%8F%E6%B4%8B%E8%91%B1%E5%A4%A7%E4%BD%9C%E6%88%98/</url>
    <content><![CDATA[濑名惠子-小洋葱大作战拟人化的小洋葱
]]></content>
      <categories>
        <category>天文兄弟</category>
      </categories>
      <tags>
        <tag>儿童</tag>
        <tag>life</tag>
        <tag>绘本</tag>
        <tag>濑名惠子</tag>
        <tag>小洋葱大作战</tag>
      </tags>
  </entry>
  <entry>
    <title>和我一起玩 play with me</title>
    <url>/2022/10/12/diary-%E7%8E%9B%E4%B8%BD%E8%8D%B7%E8%89%BE%E6%96%AF-%E5%92%8C%E6%88%91%E4%B8%80%E8%B5%B7%E7%8E%A9-play-with-me/</url>
    <content><![CDATA[和我一起玩 play with me虽然是1955年的绘本，读来还是真挚而怀念。
小女孩走在草地上，陆续邀请小动物和她一起玩，可是每当她提出邀请时，动物们却都离开了，直到她静静地坐在石头上，令人意外的事情发生了……小动物们又回来了！
静观万物的纯真童年
]]></content>
      <categories>
        <category>天文兄弟</category>
      </categories>
      <tags>
        <tag>儿童</tag>
        <tag>life</tag>
        <tag>绘本</tag>
        <tag>美国凯迪克大奖</tag>
        <tag>3岁</tag>
        <tag>玛丽·荷·艾斯</tag>
        <tag>国际安徒生文学奖优秀作品奖</tag>
        <tag>1955年</tag>
      </tags>
  </entry>
  <entry>
    <title>月下看猫头鹰</title>
    <url>/2021/03/13/diary-%E7%8F%8D%E5%B0%A4%E4%BC%A6-%E6%9C%88%E4%B8%8B%E7%9C%8B%E7%8C%AB%E5%A4%B4%E9%B9%B0/</url>
    <content><![CDATA[小熊不刷牙TODO
]]></content>
      <categories>
        <category>天文兄弟</category>
      </categories>
      <tags>
        <tag>儿童</tag>
        <tag>绘本</tag>
        <tag>珍尤伦</tag>
      </tags>
  </entry>
  <entry>
    <title>我可不怕打针</title>
    <url>/2022/04/12/diary-%E7%A9%97%E9%AB%98%E9%A1%BA%E4%B9%9F-%E6%88%91%E5%8F%AF%E4%B8%8D%E6%80%95%E6%89%93%E9%92%88/</url>
    <content><![CDATA[我可不怕打针好大的针，好小的针
与孩子的交流方式可能会减轻小孩子对针的恐惧，坦然面对。
]]></content>
      <categories>
        <category>天文兄弟</category>
      </categories>
      <tags>
        <tag>儿童</tag>
        <tag>life</tag>
        <tag>绘本</tag>
        <tag>穗高顺也</tag>
      </tags>
  </entry>
  <entry>
    <title>diary-米莱童书-生命简史从宇宙起源到人类文明</title>
    <url>/2023/03/02/diary-%E7%B1%B3%E8%8E%B1%E7%AB%A5%E4%B9%A6-%E7%94%9F%E5%91%BD%E7%AE%80%E5%8F%B2%E4%BB%8E%E5%AE%87%E5%AE%99%E8%B5%B7%E6%BA%90%E5%88%B0%E4%BA%BA%E7%B1%BB%E6%96%87%E6%98%8E/</url>
    <content><![CDATA[米莱童书-生命简史从宇宙起源到人类文明天文最爱看的是几次生物大灭绝事件
]]></content>
      <categories>
        <category>天文兄弟</category>
      </categories>
      <tags>
        <tag>儿童</tag>
        <tag>life</tag>
        <tag>绘本</tag>
        <tag>大块头</tag>
        <tag>6岁</tag>
        <tag>中国</tag>
        <tag>米莱童书</tag>
        <tag>自然资源部优秀科普图书</tag>
        <tag>原动力中国原创动漫出版大奖</tag>
      </tags>
  </entry>
  <entry>
    <title>艾德维尔-麦克斯在黑夜-Max-at-Night</title>
    <url>/2021/12/30/diary-%E8%89%BE%E5%BE%B7%E7%BB%B4%E5%B0%94-%E9%BA%A6%E5%85%8B%E6%96%AF%E5%9C%A8%E9%BB%91%E5%A4%9C-Max-at-Night/</url>
    <content><![CDATA[艾德维尔-麦克斯在黑夜-Max-at-Night可爱的麦克斯，温柔的月亮
]]></content>
      <categories>
        <category>天文兄弟</category>
      </categories>
      <tags>
        <tag>儿童</tag>
        <tag>life</tag>
        <tag>绘本</tag>
        <tag>2岁</tag>
        <tag>艾德维尔</tag>
        <tag>英国</tag>
      </tags>
  </entry>
  <entry>
    <title>画一个星星给我</title>
    <url>/2022/04/12/diary-%E8%89%BE%E7%91%9E%E5%8D%A1%E5%B0%94-%E7%94%BB%E4%B8%80%E4%B8%AA%E6%98%9F%E6%98%9F%E7%BB%99%E6%88%91-draw-me-a-star/</url>
    <content><![CDATA[画一个星星给我色彩斑斓的世界
 Eric Carle（艾瑞·卡尔
]]></content>
      <categories>
        <category>天文兄弟</category>
      </categories>
      <tags>
        <tag>儿童</tag>
        <tag>life</tag>
        <tag>绘本</tag>
        <tag>Eric Carle</tag>
        <tag>艾瑞·卡尔</tag>
      </tags>
  </entry>
  <entry>
    <title>贾尼罗大里-一条哪里也不通的路-la-strada-che-non-andava-in-nessun-posto</title>
    <url>/2021/12/30/diary-%E8%B4%BE%E5%B0%BC%E7%BD%97%E5%A4%A7%E9%87%8C-%E4%B8%80%E6%9D%A1%E5%93%AA%E9%87%8C%E4%B9%9F%E4%B8%8D%E9%80%9A%E7%9A%84%E8%B7%AF-la-strada-che-non-andava-in-nessun-posto/</url>
    <content><![CDATA[一条哪里也不通的路-la-strada-che-non-andava-in-nessun-posto勇于探索，勇于发现
]]></content>
      <categories>
        <category>天文兄弟</category>
      </categories>
      <tags>
        <tag>儿童</tag>
        <tag>life</tag>
        <tag>绘本</tag>
        <tag>2岁</tag>
        <tag>贾尼罗大里</tag>
        <tag>国际安徒生奖</tag>
        <tag>意大利</tag>
      </tags>
  </entry>
  <entry>
    <title>小黑鸟</title>
    <url>/2021/03/13/diary-%E8%B5%AB%E5%B0%94%E5%98%89%E5%98%89%E5%8B%92-%E5%B0%8F%E9%BB%91%E9%B8%9F/</url>
    <content><![CDATA[赫尔嘉·嘉勒 - 小黑鸟可爱的小黑鸟，自我认同的小黑鸟
小黑鸟灵机一动，在黑夜的掩护下，完成了一次英雄之举……
]]></content>
      <categories>
        <category>天文兄弟</category>
      </categories>
      <tags>
        <tag>信谊世界精选图画书</tag>
        <tag>赫尔嘉·嘉勒</tag>
      </tags>
  </entry>
  <entry>
    <title>路德维格贝梅尔斯曼-玛德琳游马戏团</title>
    <url>/2022/11/13/diary-%E8%B7%AF%E5%BE%B7%E7%BB%B4%E6%A0%BC%E8%B4%9D%E6%A2%85%E5%B0%94%E6%96%AF%E6%9B%BC-%E7%8E%9B%E5%BE%B7%E7%90%B3%E6%B8%B8%E9%A9%AC%E6%88%8F%E5%9B%A2/</url>
    <content><![CDATA[路德维格贝梅尔斯曼-玛德琳游马戏团有趣的探险
克拉菲老师和玛德琳等十二个小女孩儿受西班牙大使的孩子佩皮托邀请，一起去好玩儿的吉普赛马戏团。正当她们在摩天轮上尽情玩耍时，天空下起了瓢泼大雨，大家也乱作一团。当晚，克拉菲老师发现玛德琳不见了，原来玛德琳和佩皮托被遗忘在高高的摩天轮顶端。自此，玛德琳和佩皮托便开始了与吉普赛马戏团的奇遇之旅……
《玛德琳游马戏团》是作者路德维格 贝梅尔曼斯成功出版《玛德琳》之后再次奉献给大家的玛德琳系列作品，也是启发继成功引进、出版《玛德琳》，时隔5年再次推出的玛德琳系列绘本故事。此次路德维格给读者带来的也不仅仅是趣味横生的故事，更是一次开阔眼界的游历。令人思考：我们身边有许多像玛德琳一样的孩子，教她们学会生存技能，认识家庭以外的广阔天地该是多么重要！就让我们跟随玛德琳的身影去认识巴黎，完成一次平面视觉空间的游学吧。
]]></content>
      <categories>
        <category>天文兄弟</category>
      </categories>
      <tags>
        <tag>路德维格贝梅尔斯曼</tag>
        <tag>启发精选国际大师名作绘本</tag>
      </tags>
  </entry>
  <entry>
    <title>玛德琳-Madeline</title>
    <url>/2022/10/12/diary-%E8%B7%AF%E5%BE%B7%E7%BB%B4%E6%A0%BC%E8%B4%9D%E6%A2%85%E5%B0%94%E6%9B%BC%E6%96%AF-%E7%8E%9B%E5%BE%B7%E7%90%B3-Madeline/</url>
    <content><![CDATA[玛德琳-Madeline巴黎有一栋爬满了藤萝的老房子，住着十二个小女孩。她们常常排成两排吃面包、刷牙、上床睡觉。女孩当中个子最小的一个，名叫玛德琳。她不怕老鼠，喜欢冬天、下雪和在冰上跳舞，在动物园的老虎面前，轻轻松松地说：“喵！”过桥时，她还敢一个人走在桥沿儿上。她们的老师是修女克拉菲。
有一天半夜她觉得不对劲，小不点玛德琳坐在床上哭啊哭。医生来了一看，是盲肠炎，打电话叫来了救护车。两个小时以后，玛德琳在摆了花的房间里醒过来。没多久，她就能吃能喝了。她的床还可以摇上摇下，天花板的裂痕看上去像一只兔子。窗外有鸟儿、树木和天空。十天很快就过去了。在一个美好的早晨，克拉菲老师领女孩们来探望玛德琳，她们一人手上拿着一朵花。一进门，看到房间里有那么多玩具和糖果，都啊的一声叫了起来。最让她们吃惊的，还是玛德琳肚子上有一道疤！这天夜里，克拉菲老师又觉得有点不对劲。
她担心发生了什么大灾难：“告诉我，你们怎么了？”所有的女孩都哭着说：“呜呜呜……我们也要割盲肠！”
]]></content>
      <categories>
        <category>天文兄弟</category>
      </categories>
      <tags>
        <tag>儿童</tag>
        <tag>life</tag>
        <tag>绘本</tag>
        <tag>3岁</tag>
        <tag>百年绘本</tag>
        <tag>美国纽约公共图书馆-每个人都应该知道的100种图画书</tag>
        <tag>日本儿童文学者协会-世界图画书100选</tag>
        <tag>路德维格·贝梅尔曼斯</tag>
        <tag>美国凯迪克奖</tag>
        <tag>美国出版者周刊-所有时代最畅销童书</tag>
        <tag>美国-20世纪童书宝库</tag>
        <tag>1939年</tag>
      </tags>
  </entry>
  <entry>
    <title>阳野道子-好大的苹果</title>
    <url>/2018/03/13/diary-%E9%98%B3%E9%87%8E%E9%81%93%E5%AD%90-%E5%A5%BD%E5%A4%A7%E7%9A%84%E8%8B%B9%E6%9E%9C/</url>
    <content><![CDATA[阳野道子-好大的苹果是谁，在暗地里悄悄地看着我们呢？
几次过后，哈哈大笑。。
本书来自作者吃苹果时的随意想象，讲述了一个大大的苹果从树上掉下来，小鸟看见了开心地吃起来，随后相继引来兔子、松鼠、老鼠、蝴蝶、虫子们来吃。大大的苹果变成了苹果芯，最后由蚂蚁搬走了分着吃。这么一个大苹果，大家都吃得好开心。这是一个非常温馨动人的故事，画面讲究细节，却又简单好玩，作者还暗藏玄机，让读者去发现与惊喜。
]]></content>
      <categories>
        <category>天文兄弟</category>
      </categories>
      <tags>
        <tag>阳野道子</tag>
        <tag>启发绘本馆</tag>
      </tags>
  </entry>
  <entry>
    <title>麦克格雷涅茨-月亮的味道-a-taste-of-the-moon</title>
    <url>/2021/12/30/diary-%E9%BA%A6%E5%85%8B%E6%A0%BC%E9%9B%B7%E6%B6%85%E8%8C%A8-%E6%9C%88%E4%BA%AE%E7%9A%84%E5%91%B3%E9%81%93-a-taste-of-the-moon/</url>
    <content><![CDATA[麦克格雷涅茨-月亮的味道-a-taste-of-the-moon月亮什么味道，没有人知道
所有的小朋友都集结起来，一起合力去够月亮
显然小鱼终究不知道
]]></content>
      <categories>
        <category>天文兄弟</category>
      </categories>
      <tags>
        <tag>儿童</tag>
        <tag>life</tag>
        <tag>绘本</tag>
        <tag>2岁</tag>
        <tag>麦克格雷涅茨</tag>
        <tag>日本图画书翻译图画书奖</tag>
        <tag>亲子共读图画书300本</tag>
        <tag>为了孩子的300册</tag>
        <tag>波兰</tag>
      </tags>
  </entry>
  <entry>
    <title>龟冈亚西子-你是我的宝贝</title>
    <url>/2021/03/13/diary-%E9%BE%9F%E5%86%88%E4%BA%9A%E8%A5%BF%E5%AD%90-%E4%BD%A0%E6%98%AF%E6%88%91%E7%9A%84%E5%AE%9D%E8%B4%9D/</url>
    <content><![CDATA[龟冈亚西子-你是我的宝贝TODO
]]></content>
      <categories>
        <category>天文兄弟</category>
      </categories>
      <tags>
        <tag>儿童</tag>
        <tag>绘本</tag>
        <tag>龟冈亚西子</tag>
        <tag>国际绘本大师经典</tag>
      </tags>
  </entry>
  <entry>
    <title>Difmap ： 检查和编辑数据</title>
    <url>/2011/11/22/difmap-guide-3-examing-editing-data/</url>
    <content><![CDATA[检验和编辑数据最开始的时候，一个比较有用的检查是画出 Amplitude 与 uv radius的图，即radial plot。
直接输入命令：
0&gt; radplot

因为是第一次使用PGPLOT窗口，所以刚开始需要制定数据输出的设备，最好的选择是/xw，这个可以使用下面的命令来制定：
0&gt; device /xw

现在应该可以看到这幅图像了，下面是一些有用的键盘交互操作。如果希望了解更多的信息，可以使用h来获取更多的信息。

X - 退出radplot，也可以在任何时候右键点击来操作
L - 重绘整个图像，在做了一些修改后最好刷新一下
n - 高亮显示下一个望远镜
p - 高亮显示上一个望远镜
T - 从键盘制定需要高亮显示的望远镜
s - 显示鼠标最接近点的基线和时间
A - (Left-mouse-button) Flag 掉最接近光标的点
C - 选定需要flag掉的整块区域
Z - 选定一个新的amplitude 或 phase display 范围
U - 选定一个新的 UV-radius 范围

一些有用的技巧]]></content>
      <categories>
        <category>DIFMAP</category>
        <category>AIPS</category>
        <category>FITS</category>
      </categories>
      <tags>
        <tag>aips</tag>
        <tag>vlbi</tag>
        <tag>fits</tag>
        <tag>difmap</tag>
        <tag>vla</tag>
        <tag>observe</tag>
        <tag>header</tag>
      </tags>
  </entry>
  <entry>
    <title>MacOSX 上安装 Difmap</title>
    <url>/2014/05/14/difmap_install_on_macosx/</url>
    <content><![CDATA[Mac安装difmap参考：ftp://ftp.astro.caltech.edu/pub/difmap/README
步骤基本信息现在Difmap的版本是2.4l，支持以下的操作系统版本：
Architecture   OS           ANSI-C    FORTRAN-77   PGPLOT                            compiler  compiler     status————   ———–  ——–  ———–  ————Sparc          SunOS 4.x    gcc       f77          SupportedSparc          Solaris 2.x  gcc       f77          SupportedSparc          Solaris 2.x  SUN cc    f77          SupportedHP9000 700-800 HPUX         c89       fort77       SupportedIBM RS6000     AIX          c89       xlf          SupportedAlpha-AXP      OSF1         gcc       f77          SupportedPC i86         Linux        gcc       gfortran     SupportedPC AMD64       Linux        gcc       f77          SupportedPC Itanium     Linux        gcc       f77          SupportedPPC            MacOS X      gcc-4     gfortran     SupportedIntel          MacOS X      gcc-4     gfortran     Supported


为了成功安装difmap，我们需要满足下面的条件：

是上面支持OS版本和编辑器的一种；
一个ANSI-C的编译器；
一个FORTRAN-77的编译器；
需要PGPLOT5.0.2或以上版本，

下载最新版本的difmap：
$ wget ftp://ftp.astro.caltech.edu/pub/difmap/difmap2.4l.tar.gz

顺便得到cookbook：
$ wget ftp://ftp.astro.caltech.edu/pub/difmap/cookbook.ps.Z

然后解压difmap：
$ tar xzf difmap2.4l.tar.gz

完了会创建一个uvf_difmap的子目录。
安装步骤：
进入uvf_difmap子目录；
修改该目录下的configure文件，主要可能是HELPDIR和PGPLOT_LIB这两项；
编辑完成后，执行下述命令：
./configure operating_system_name-compiler_name
其中可识别的操作系统名称–编译器名称都可以在configure文件中找到，
比如，举个例子：./configure linux-i486-gcc
而对于mac而言就是./configure apple-os-gcc或者./configure intel-os-gcc
configure完成后，执行./makeall，如果出错，就检查下configure文件找找原因；
有可能会碰到lib找不到的error，此时可以将lib的路径导入到LIBRARY_PATH即可解决问题。
在doc子目录可以使用makemanual来生成LaTeX文件的帮助文档。
如果需要重装软件，可以运行./clean来清理生成的中间文件。

运行difmap在终端下执行：difmap如果成功，就能得到如下信息：
Caltech difference mapping program – version 2.4l (17 Apr 2010)Copyright (c) 1993-2010 California Institute of Technology. All Rights Reserved.Type ‘help difmap’ to list difference mapping commands and help topics.Started logfile: difmap.log_12 on Sat Apr 17 16:00:04 20100&gt;

然后就可以畅游在difmap的海洋中了。输入exit即可退出difmap。
]]></content>
      <categories>
        <category>macosx</category>
        <category>Difmap</category>
        <category>PGPLOT</category>
      </categories>
      <tags>
        <tag>astronomy</tag>
        <tag>pgplot</tag>
        <tag>difmap</tag>
        <tag>macosx</tag>
      </tags>
  </entry>
  <entry>
    <title>从一个共同的源代码构建多个版本</title>
    <url>/2023/03/30/difx-build/</url>
    <content><![CDATA[从一个共同的源代码构建多个版本脚本 install-difx 现在允许从 Git 源代码树之外的目录层次结构构建和安装 DiFX。例如，如果您需要为多个架构编译 DiFX，您可以为每个架构拥有独立的构建和根目录。
步骤如下：

运行 git pull 以使您的源代码保持最新（或不更新）
如以前一样准备并 source 一个设置脚本
在某个地方创建一个构建目录
在这个构建目录中运行 /fullpathto/install-difx`

如果你以前（大多数开发者都是这样）在源码目录中构建，第一个配置过程会抱怨“源已经配置好了，运行 make distclean”并停止。（这是一个功能，旨在防止您意外地将一个架构的构建错误地配置为另一个架构。）由于 DiFX 项目有多个子目录，修复这个问题可能会很繁琐，因此有一个选项（--pristine）可以为您完成这项工作。install-difx 有很多选项；使用 --help 查看简要说明。
安装示例你可能计划将根目录、源目录和构建目录都放在某个父目录中，例如 $DIFXROOT、$DIFXROOT/../difx-src 和 $DIFXROOT/../difx-build。因此，首先我们要更新源代码并检查我们的修改：
$ source setup-difx.bash$ cd $DIFXROOT/../difx-src$ git pull$ git log

然后我们创建一个构建目录。install-difx 在其中的一个目录（pkgconfig）中添加了一个目录，以便您可以在那里放置自定义的 pkg-config 文件，以便处理一些特殊情况（例如 IPP）：
$ cd $DIFXROOT/..$ mkdir difx-build$ cd difx-build$ mkdir pkgconfig$ cd pkgconfig$ $DIFXROOT/../difx-svn/setup/genipppc $IPPROOT$ cd ..     

If you have previously been building in the SVN directory, you will needto remove some configuration files (e.g. config.status) left overfrom your last install with如果你以前在源码目录中构建过，你需要删除一些配置文件（例如 config.status）：
$ $DIFXROOT/../difx-svn/setup/install-difx --pristine


有一些独立的包在 DiFX 项目中，每个包都需要系统配置。如果你经常重建代码，install-difx 可以创建一个缓存来加快这个配置过程：
$DIFXROOT/../difx-svn/setup/install-difx -v --cache=difx-config-cache
其中 -v 参数提供了一些额外的诊断信息，说明正在创建或遍历哪些目录。
一旦构建完成（你会看到 "Done!"），你可以删除构建目录。或者你可以留下它，以备下次 git pull 和构建循环。install-difx 的另一个有用的选项是 --targ 选项，它允许你将某些目标传递给树中的所有 make 步骤。例如：
$DIFXROOT/../difx-svn/setup/install-difx -v --targ='-n'
将遍历 DiFX 构建层次结构，并告诉你它将构建什么。 （即在每个 Makefile 中调用 make -n。）
]]></content>
      <categories>
        <category>DiFX</category>
      </categories>
      <tags>
        <tag>difx</tag>
        <tag>git</tag>
        <tag>build</tag>
      </tags>
  </entry>
  <entry>
    <title>DiFX 复数采样数据的限制和解决方法</title>
    <url>/2023/03/30/difx-complexsamplingvex/</url>
    <content><![CDATA[复数采样数据的限制和解决方法目前的vex 1.5标准只能传输有关复杂采样信号性质的有限信息，因此在某些情况下，必须修改v2d和vex文件以正确表征信号。
值得注意的是，这意味着vex文件中**$FREQ**标题下给出的采样率必须始终是带宽的两倍，即使对于复杂的采样天线也是如此。
因此，为了正确地表示一个复杂的采样信号，在vex文件中指定的采样率必须是复杂数据采样率的两倍。这意味着采样率增加2倍是错误的，但这是由FFT中的样本数量也被调整为2倍来补偿的。
$FREQ;
*
def 2400.00MHz1x4MHz;
* mode = 1 stations =T1:T2
sample_rate =      128.0 Ms/sec;
chan_def = :   200.00 MHz   :   U   :  64.00 MHz   :   &amp;CH01   :   &amp;BBC01   :   &amp;NoCal ;   *Rcp
enddef;

台站T1和T2以64 Ms / sec的采样率进行复杂采样，但是在vex文件中以128 Ms / sec定义它们，以进行上述解决方法。 要告诉vex2difx数据是复杂采样的，还必须修改v2d文件以反映采样是复杂的：
ANTENNA T1 {
sampling = COMPLEX
             .
             .
}
ANTENNA T2 {
sampling = COMPLEX
             .
           .
}

一个告诉vex2difx数据是复杂采样的替代方法，特别是在vex文件的$ TRACKS部分中显示：
$TRACKS;
def VDIF.1Ch2bit;
   track_frame_format = VDIFC/32032/2;
             .
             .
enddef;

在上面的示例中，VDIFC表示VDIF数据是复杂的，并且处于“单边带”模式。 对于“双边带”模式的复杂VDIF数据，需要VDIFD。 32032表示帧大小，2表示位深度。 请注意，对于具有实际Mark5B格式的台站时间表的vex文件，DiFX附带的perl脚本“ addVDIF.pl”会更改设置为VDIF，并包括一个复杂的选项以及帧大小和位深度的设置，这些设置会导致上面给出的track_frame_format行。
]]></content>
      <categories>
        <category>DiFX</category>
      </categories>
      <tags>
        <tag>difx</tag>
        <tag>dokuwiki</tag>
      </tags>
  </entry>
  <entry>
    <title>DiFX Debian 安装包依赖</title>
    <url>/2023/03/30/difx-dependenciesdebian/</url>
    <content><![CDATA[DiFX Debian 安装包依赖必装软件$ apt-get install pkg-config g++ gfortran bison flex libexpat1-dev fftw3-dev autoconf automake libtool build-essential pgplot5 subversion libgsl-dev

Etch 发行版$ apt-get install openmpi-dev

Lenny及以后的发行版$ apt-get install libopenmpi-dev openmpi-bin

HOPS如果使用Hops，您可能还需要安装
$ apt-get install libx11-dev libpng12-0 libpng12-dev

如果需要使用Espresso，还需要安装mxdatetime：
$ apt-get install python-egenix-mxdatetime]]></content>
      <categories>
        <category>DiFX</category>
      </categories>
      <tags>
        <tag>difx</tag>
        <tag>dokuwiki</tag>
      </tags>
  </entry>
  <entry>
    <title>DiFX Fedora 安装包依赖</title>
    <url>/2023/03/30/difx-dependenciesfedora/</url>
    <content><![CDATA[DiFX Fedora 安装包依赖Fedora core 8
对于Fedora core 8，您需要安装以下软件包：
$ yum install fuse fuse-libs fuse-devel gcc gcc-c++ gcc-gfortran fftw fftw-devel openmpi openmpi-devel expat-devel flex flex-devel bison gsl gsl-devel valgrind


对于Fedora Core 29，您需要安装以下软件包：
$ sudo dnf install libtirpc]]></content>
      <categories>
        <category>DiFX</category>
      </categories>
      <tags>
        <tag>difx</tag>
        <tag>dokuwiki</tag>
      </tags>
  </entry>
  <entry>
    <title>DiFX Max OSX 安装包依赖</title>
    <url>/2023/03/30/difx-dependenciesmac/</url>
    <content><![CDATA[DiFX Max OSX 安装包依赖DiFX编译和运行，但尚未经过广泛测试。必须安装Xcode。推荐使用“Brew”来满足外部依赖。具体安装：
$ brew install openmpi gcc fftw libtool pkg-config automake autoconf gawk pgplot bison


从Mojave开始，Apple似乎对规范的类Unix操作系统不太感兴趣。现在的Xcode安装过程是（全部作为root或sudo）：
从Apple商店下载Xcode
xcode-select --installxcodebuild -licenseinstaller -pkg /Library/Developer/CommandLineTools/Packages/macOS_SDK_headers_for_macOS_10.14.pkg -target /

最后一步是让/usr/include出现。显然，它现在被埋在SDK的某个地方，您可以通过以下命令查看：
xcrun --show-sdk-path
OSX附带了一个非常旧的bison版本，无法编译vex解析。Brew也拒绝以覆盖系统默认方式安装。所以你还需要
 export PATH="/usr/local/opt/bison/bin:$PATH"
]]></content>
      <categories>
        <category>DiFX</category>
      </categories>
      <tags>
        <tag>difx</tag>
        <tag>macosx</tag>
        <tag>install</tag>
      </tags>
  </entry>
  <entry>
    <title>DiFX Ubuntu 安装包依赖</title>
    <url>/2023/03/30/difx-dependenciesubuntu/</url>
    <content><![CDATA[DiFX Ubuntu 安装包依赖HardyLucid$ sudo apt-get install build-essential pkg-config bison flex libfftw3-dev libopenmpi-dev openmpi-bin automake gfortran libexpat1-dev

Natty &amp; Precise (12.04)$ sudo apt-get install build-essential pkg-config bison flex libfftw3-dev libopenmpi-dev openmpi-bin automake gfortran libexpat1-dev subversion libtool


可选的用于构建文档
$ sudo apt-get install doxygen

14.04 LTS Trusty Tahr &amp; 16.04 LTS$ sudo apt-get install build-essential subversion libopenmpi-dev libfftw3-dev libtool bison flex pkg-config automake autoconf libexpat1-dev gfortran openmpi-bin Xorg-dev rpcbind python

Note:

对于OpenMPI: libopenmpi-dev openmpi-bin

(for 16.04 LTS)
$ sudo apt-get install openmpi-common openssh-client openssh-server libopenmpi1.10


对于fftw: libfftw3-dev

sudo apt-get install libfftw*

对于PGPLOT: gfortran Xorg-dev

安装portmap以在16.04 LTS中激活calcserver，请安装以下软件包：
sudo apt-get install nfs-kernel-server rpcbind nfs-common
18.04 LTS bionic, 19.04 Disco Dingo, 20.04 Focal Fossa$ sudo apt-get install subversion build-essential python autotools-dev autoconf libtool libfftw3-dev pkg-config libexpat1-dev openmpi-bin libgsl-dev bison flex-old]]></content>
      <categories>
        <category>DiFX</category>
      </categories>
      <tags>
        <tag>difx</tag>
        <tag>dokuwiki</tag>
      </tags>
  </entry>
  <entry>
    <title>DiFX 2016 IVS school 练习</title>
    <url>/2023/03/30/difx-ivs2016/</url>
    <content><![CDATA[DiFX 示例教程一些基础要求需要掌握一些基础的 Linux / Unix 和 bash shell的内容。
另外一些基本的文本编辑知识也很必要，比如使用vim来编辑文件。
在演示中使用的程序基本都具有内置的帮助信息，可以通过在命令行中使用 -h 选项运行来访问。 例如：
$ vex2difx -hvex2difx version 3.1.0  Walter Brisken/Adam Deller 20221115Usage:  vex2difx [&lt;options&gt;] &lt;v2d file&gt;  &lt;options&gt; can include:     -h     --help        display this information and quit.     -v     --verbose     increase the verbosity of the output; -v -v for more.     -o     --output      create a v2d file with all defaults populated.     -d     --delete-old  delete all job(s) in this series before running.     -f     --force       continue desipte warnings.     -s     --strict      treat some warnings as errors and quit [default].     -6     --mk6         call mk62v2d utility to generate mark6 related files  &lt;v2d file&gt; is the vex2difx configuration file to process.$ difx2fits -hdifx2fits ver. 3.8.0   Walter Brisken &lt;wbrisken@nrao.edu&gt;A program to convert DiFX format data to FITS-IDIUsage : difx2fits [options] &lt;baseFilename1&gt; [&lt;baseFilename2&gt; ... ] [&lt;outfile&gt;]It assumed that SWIN format visibility file(s) to be converted livein directory &lt;baseFilename&gt;.difx/It is also assumed that at least 3 additional files exist:  &lt;baseFilename&gt;.input    DiFX input file  &lt;baseFilename&gt;.calc     Base file for calcif   &lt;baseFilename&gt;.im       Polynomial UVW and modelOne other files is optionally read:  &lt;baseFilename&gt;.flag     Antenna-based flaggingVLBA calibration transfer will produce 4 files:  flag, tsys, pcal, weatherIf these are present in the current directory, they will be used toform the FL, TS, PH and WR tablesIf env variable GAIN_CURVE_PATH is set, gain curves will be looked forand turned into a GN tableThe output file &lt;outfile&gt; will be written in FITS-IDI format nearlyidentical to that made at the VLBA HW correlator.  The first two optionalfiles are required for full model accountability.options can include:  --help  -h                  Print this help message  --bin        &lt;bin&gt;  -B           &lt;bin&gt;  Select on this pulsar bin number  --difx  -d                  Run on all .difx files in directory  --no-model  -n                  Don't write model (ML) table  --dont-combine  -1                  Don't combine jobs  --scale &lt;scale&gt;  -s      &lt;scale&gt;     Scale visibility data by &lt;scale&gt;  --deltat &lt;deltat&gt;  -t       &lt;deltat&gt;   Set interval (sec) in printing job matrix (default 20.0)  --difx-tsys-interval  -i       &lt;interval&gt; Set the Difx-derived tsys interval (sec) (default 30.0)  --difx-pcal-interval           &lt;interval&gt; Set the Difx-derived pcal interval (sec) (default 30.0), 0 means to average over a whole scan  --phaseCentre &lt;p&gt;  --phasecenter &lt;p&gt;   Create a fits file for all the &lt;p&gt;th phase centres (default 0)  --keep-order  -k                  Keep antenna order  --ac-always  -a                  Write standard autocorrelations into every output file  --profilemode       Don't discard autocorrelations for pulsar bins other than bin 0  --skip-extra-autocorrs                      Ignore e.g. LL autocorrs in a job with only RR cross-corrs  --history &lt;file&gt;  -H &lt;file&gt;           Read file &lt;file&gt; and populate FITS History  --sniff-all  -S                  Sniff all bins and centers  --dont-sniff  -x                  Don't produce sniffer output  --sniff-time &lt;t&gt;  -T           &lt;t&gt;    Sniff output on a &lt;t&gt; second timescale (default 30.0)                      Set to zero to disable sniffing  --union  -u                  Form union of frequency setups  --max-jobs &lt;max&gt;  -m &lt;max&gt;            Set maximum number of jobs to merge into one FITS file to &lt;max&gt;  --eop-merge-mode    Set the mode for merging differerent EOPs. Legal modes are strict (default), drop, relaxed.  --clock-merge-mode  Set the mode for merging clock entries of an antenna. Legal modes are strict (default), drop (ignore clock breaks).  --verbose  -v                  Be verbose.  -v -v for more!  --override-version  Ignore difx versions  --zero  -0                  Don't put visibility data in FITS file  --antpol            Use antenna-based polarization codes. Warning: fits-idi file will violate original specifcaitions and abide extended specifications.  --polxy2hv          Convert XY polarziation codes to HV codes. Requires --antpol option  --localdir  -l                  *.calc, *.im, and *.difx are sought in the same directory as *.input files  --all-pcal-tones  -A                  Extract all phase calibration tones  --primary-band &lt;pb&gt; Add PRIBAND keyword with value &lt;pb&gt; to FITS file  --relabelCircular   Change naming of all polarizations to R/L  --vanVleck          Force difx2fits to apply van Vleck correction  --bandpass          Write baseline-based bandpass to .bandpass file  --applybandpass &lt;file&gt;                      Read &lt;file&gt; and apply it as a bandpass to the output  --applydelaycal &lt;file&gt;                      Read &lt;file&gt; and apply it as delay corrections to the output  --sourcelist &lt;list&gt;                      Only propagate source(s) listed (comma separated)difx2fits responds to the following environment variables:    DIFX_GROUP_ID             If set, run with umask(2).    DIFX_VERSION              The DiFX version to report.    DIFX_LABEL                Your local DiFX version label.    GAIN_CURVE_PATH           Path where gain curves can be found.    TCAL_PATH                 Path where switched power T_cal values are found.    TCAL_FILE                 Path to single specific T_cal file.    DIFX_MAX_SNIFFER_MEMORY   Max number of bytes to allow for sniffing.    DIFX2FITS_UVFITS_DUMP         Prints in stdout the ascii dump of records from the binary visilibity file. Warning: the output may be huge.    DIFX2FITS_UVFITS_DUMP_UTCMIN  Sets the minimum UTC time tag for the visibility dump. Units are seconds. Default is zero.    DIFX2FITS_UVFITS_DUMP_UTCMAX  Sets the maximum UTC time tag for the visibility dump. Units are seconds. Default is 86400.    DIFX_USE_CABLE_CAL            If 0, then cable calibration files are ignored. Default is 1.PLEASE file all bug reports at http://svn.atnf.csiro.au/trac/difx .Include at a minimum the output of difx2fits with extra verbosity(that is with -v -v).  The .input, .im &amp; .calc files may help too.



通常，如果不熟悉一个程序的话，可以通过运行此程序，了解可用的选项以及语法的帮助。
如果需要更详细的帮助，可以参考DiFX的用户手册。
不过手册中也不一定是最新的内容，目前可以考虑通过阅读 https://difx.readthedocs.io 来阅读最新的文档。
预备工作DiFX包含一套程序，库和小型实用程序，通常安装在非系统目录中，所以如果没有配置的话，是不能使用的。
另外实际使用的相关处理机可能会安装多个版本。
这种情况下，每个版本都可以通过设置脚本进行选择。 对于本次的演示，使用单个DiFX版本，并且可以通过键入来配置
$ source setup.bash


其中setup.bash是一个设置脚本，可以在DiFX安装过程中找到。

这种方法的弊端在于，每次打开新的终端都需要键入这个命令，所以，可以把这个命令加到.bashrc中，这样每次打开终端都将自动设置好需要的环境。
启动时延模型服务在计算机启动后需要启动一次时延模型服务。 这可以通过以下方式完成：
$ startCalcServer

这个命令将在后台启动了一个名为CalcServer的进程。

不过在DiFX2版本之后，这个服务已经不再需要了，相关处理的时延多项式可以通过difxcalc来完成。 

准备数据集1：2台站UT1-UTC观测创建工作目录在您的主目录中创建一个新目录，比如~/data/，然后进入该目录
$ mkdir ~/data/$ cd ~/data/


拷贝.vex文件和.v2d文件.vex 文件是由观测纲要程序生成的，该文件包含实验的基本描述，观测源的坐标以及每个scan使用的设置。
大多数相关处理实验所需的信息都包含在此文件中。
$ cp /the/path/of/vex/file.vex .


详细的可以参考 https://vlbi.org/vlbi-standards/vex/ 

.v2d文件补充了.vex文件，它包含两种类型的信息：

不包含在.vex文件中的信息，例如积分时间（也称为累积周期）以及在相关处理中要使用的频谱分辨率;
覆盖.vex文件中包含的值信息。


一般的理念是.vex文件不需要编辑，并且相关处理所需的更改应包含在.v2d文件中。
所以对于常规的观测而言，vex文件避免编辑，需要的参数可以通过v2d文件来调整相关处理的参数。

$ cp /the/path/of/v2d/file.v2d .


.v2d文件的名称（.v2d扩展名之前的所有内容）构成相关处理作业名称的基础。为了防止混淆（稍后会详细介绍），建议将.v2d文件重命名为唯一的名称, 这可以是您的姓名或者处理中心的缩写。
$ mv file.v2d yourname.v2d



在接下来的示例中，假设它被称为yourname.v2d。 随时替换为你喜欢的名字。
生成要相关处理的基带数据列表相关处理需要知道在哪里找到数据以及要与每个文件关联的时间范围。 
这可以通过检查数据本身的工具来完成。 
对于这个特定的实验，数据是用称为Mark5B的数据格式记录的（这种数据的描述请参阅http://www.haystack.mit.edu/tech/vlbi/mark5/mark5_memos/019.pdf）。 
一个名为 m5bsum 的工具可以制作需要的列表信息。
比如分别对来自两个站点的数据执行此操作（其中PT = Pie Town和MK = Mauna Kea，这两个站点都是美国的VLBA天线）。
$ m5bsum -s /the/data/of/pt/station/n6043/NRAO+301* &gt; filelist.pt$ m5bsum -s /the/data/of/mk/station/n6043/NRAO+390* &gt; filelist.mk



-s 选项很重要，上面的命令会强制生成每个文件的一行摘要，可以给后来的软件使用。 
请注意，您可以将这些大型数据文件保留在当前位置，而不需要将其拷贝到处理目录，并且建议相关处理的目录和原始数据最好分开存放。比如相关处理的结果可以存放在~/corr/目录下，而原始数据可以存放在/data/目录下。如果您想查看单个文件的更多详细信息，可以尝试：
$ m5bsum /the/data/of/pt/station/n6043/NRAO+301_0540_N6043_PT_No0008


这里创建的两个文件将需要在.v2d文件中引用，进行后面的相关处理。 
这些文件是ASCII文本，可以使用cat，less或您喜欢的编辑器查看。 
长数字是以MJD表示的开始和停止时间。
cat filelist.pt
检查并修改.v2d文件.v2d文件已经创建好。 
文件中的许多内容都可以更改。
对于第一次相关处理，建议不要改变任何东西。 
如果时间允许，可以尝试更改一些参数。 
如果您这样做，最好重命名.v2d文件，以便可以保留以前相关处理的输出。 
可以尝试的一些相关参数是：

tInt  积分周期（秒）：数字最好在0.25和4之间
specRes 相关处理输出的谱分辨率（MHz）。 数字最好在0.05和0.5之间
fftSpecRes 执行FFT的分辨率。 必须是specRes必须是整数倍。 这会影响光谱响应。
clockOffset 改变时钟偏移（微秒）并产生输出中的相位斜率。 建议可以尝试数字高达0.2左右。
addZoomFreq  允许放大到带宽的一部分。 这是一个高级功能，对不同带宽的可以考虑。

关于 vex2difx 的详细文档可以参考其使用说明 vex2difx .
一旦 .v2d 文件准备就绪，运行 vex2difx :
$ vex2difx yourname.v2d

仔细查看输出。 可能会有有意义的消息。如果您看到错误，则该步骤失败，您需要调试.v2d文件。如果您看到警告，则可能会出现问题，但请仔细查看消息，因为它可能意味着某些内容可能是不对的。如果您看到一个注释，那么 vex2difx 中做出了一些假设，这可能是预期的，但您可能需要确保它是有意义的。
vex2difx 为项目生成一个或多个作业。 每个作业都有一个不同的数字（在下划线之后）。此阶段的每个作业应该已经有一些文件。 .input 文件包含作业的DiFX配置，.calc 文件包含生成延迟多项式所需的信息。这两个文件都是ASCII文本，可以像为filelist文件所做的那样查看。
生成时延多项式延迟多项式用于将每个数据流延迟所需的时间，以使波前从接收站传播到地球中心，通常为10毫秒或更少。Goddard Calc程序用于执行此操作。 当前的安装使用Calc 9.1，但是Calc 11可通过名为difxcalc的程序提供给difx。执行Calc的最简单方法是运行
calcif2 -a
$ calcif2 -a

它将遍历当前目录中所有的.calc文件并生成模型文件（以.im结尾）。同样，这些输出文件是ASCII文本，可以检查。
启动一些监视进程当DiFX运行时，它会产生信息（有时是错误）消息。 它还生成状态信息。 这些信息的位是多播的，以便本地网络上的任何进程都可以听到。 这意味着您将能够看到来自邻居进程的消息。 要仅过滤与您的进程相关的消息，请使用标准unix工具grep来过滤输出。 如果您愿意，可以在没有grep的情况下运行并立即查看所有人的信息！ 请注意，即使在相关处理正在进行时，您也可以启动和停止这些监视器进程。
启动错误或者消息监视启动一个新的终端窗口并在shell中设置环境：
$ source setup.bash

然后运行
$ errormon | grep yourname

但是不要忘记将我的名字更改为您的进程的名称。
启动状态监视启动一个新的终端窗口并在shell中设置环境：
$ source setup.bash

Then run 然后运行
$ statemon | grep yourname

启动DiFX!此时，一切就绪，可以开始进行相关处理了。可以使用以下命令运行DiFX：
startdifx -v -f -n yourname*.input
请注意，-f 选项强制执行并将覆盖同一作业的以前的相关结果。 小心使用！-v 选项仅增加输出的详细程度，并且在这种情况下需要 -n 选项以防止覆盖机器文件，描述要使用的计算机集群的哪些元素（在这种情况下仅为您的工作站）。
运行这些作业根据观测时常、台站等的不同需要一会时间。 在运行时，您可以监视两个诊断窗口。 
转换为FITS输出difx2fits 程序接受DiFX的原始输出以及用于驱动它的文件，以生成FITS-IDI格式的文件。FITS-IDI是干涉测量数据的标准格式，文档位于http://www.aoc.nrao.edu/~egreisen/AIPSMEM114.PDF。此文件格式适合读入AIPS，这是天文VLBI观测的常规数据路径。 
difx2fits 还会生成一些诊断输出，这些输出非常方便（请参见下一节）。
运行difx2fits:
$ difx2fits yourname*.difx YOURNAME.FITS


生成诊断图并检查一个名为difxsniff的工具可用于制作“sniffer plots”，以快速查看数据。 NRAO的数据分析师使用这些图来确定项目的成功。 运行：
$ difxsniff YOURNAME.FITS PT

第二个参数PT是将在某些图中用作“参考天线”的站点。 通常，VLBI阵列中心附近的行为良好的天线用于此。 这将在名为sniffer / PT /的子目录中生成文件。 主要感兴趣的文件如下：

YOURNAME.apd.ps : 绘制所有基线到参考天线的速率，延迟，相位和幅度随时间变化的图
YOURNAME.acb.ps : 绘制所有自相关带通
YOURNAME.xcb.ps : 绘制所有与参考天线的交叉相关带通
YOURNAME.wts.ps : 绘制数据有效权重随时间变化

所有这些文件都是PostScript文件，可以使用任何PostScript查看器查看。 例如，您可以使用evince：
$ evince YOURNAME.apd.ps

为大地测量处理制作Mark4输出确保回到实验目录（即，如果您进入了sniffer目录，请回来），您可以从相同的DiFX输出中制作Mark4数据集。 这可以通过以下方式调用：
$ difx2mark4 yourname*.input


输出文件将放在一个编号的目录中（默认为1234/）。 
数据集2：10站VLBA观测（如果时间允许）使用上面的工具（有一些例外：请参见下文），尝试相关10个站点的VLBA观测。 问题中的数据使用多线程VDIF数据（如果您想知道VDIF数据的格式，请参见http://vlbi.org/vdif/docs/VDIF_specification_Release_1.1.1.pdf）。 下面是一些最少的信息，应该可以让您开始：

一个scan的实验可用。
数据来自对夸克星的12.2 GHz观测，具有4个基带通道，每个通道4 MHz。
基带通道以极化对的形式出现：RCP和LCP。
数据文件可以在/home/avntrainee/difx_data/ts036h（站点名称是文件名的倒数第二个字段）
Vex和示例.v2d文件可以在同一位置找到（称为ts036h.vex.obs和ts036h.v2d）
为了生成文件列表，您需要使用vsum -s而不是m5bsum -s
您需要制作10个文件列表。 请注意，10个VLBA站点的站点代码为：BR，FD，HN，KP，LA，MK，NL，OV，PT，SC，如.v2d文件顶部所列。

]]></content>
      <categories>
        <category>DiFX</category>
      </categories>
      <tags>
        <tag>difx</tag>
        <tag>dokuwiki</tag>
      </tags>
  </entry>
  <entry>
    <title>可选的练习</title>
    <url>/2023/03/30/difx-ivs2016extras/</url>
    <content><![CDATA[可选的练习如果您有兴趣详细了解基带数据，则可以尝试以下内容。 这些主要是为了说明与相关处理无关的检查数据的一些工具。
制作基带通道的高分辨率频谱这个实用程序m5spec可以读取基带数据并生成频谱。 该程序和包含频谱的输出文本文件具体信息可以参考DiFX参考手册。
这个程序可以在许多种VLBA基带数据（包括第一个数据集中的Mark5B数据）上工作，但不能在具有多个线程的VDIF数据上工作（例如，来自第二个数据集的数据）。 适用于数据集1数据的数据格式参数是Mark5B-2048-16-2，生成每个基带通道500个频谱点的完整命令是：
m5spec /home/difx_data/n6043/NRAO+301_0540_N6043_PT_No0008 Mark5B-2048-16-2 500 2000 spec.out

这里的数字2000是要处理的FFT帧数。 增加该数字将导致更多的平均值和信噪比更高的频谱。可以更改这两个数字（频谱点数和要处理的FFT数），以了解这些参数如何更改输出。
gnuplot 程序可用于绘制数据。 首先在终端中启动gnuplot：
$ gnuplot

然后在提示符下，您可以发出绘图命令，例如：
p 'spec.out' u 1:2 w l

第1列（在1:2参数中标识）是频谱点频率偏移（从0开始，延伸到通道的带宽），第2列是第一个基带通道的幅度数据。 应该注意三个特征：

带通朝着带宽的边缘下降，但不会降至零。 这意味着什么？
数据中每1 MHz有尖峰。 这些是pcal信号。 随着频谱点数的增加，脉冲校准音的相对强度如何变化？ 为什么？
RFI: 信号在带通顶部，与脉冲校准音无关，可能是RFI。 特别是S波段通道有RFI。

或许逐个查看16个基带通道会更有启发性，以了解真实数据的样子。
探测VDIF数据头你可以使用名为printVDIFheader的程序解码并打印VDIF数据帧的帧头信息。此程序接受VDIF数据文件（例如，来自ts036h观测）并打印每个帧的头的内容。为了防止数据永远进行，您可能希望使用unix工具“ less”来控制输出。
cd /home/difx_data/ts036hprintVDIFheader NRAO+338_0039_TS036H_NL_No0001 | less

The header can be printed in binary with:头可以以二进制形式打印：
printVDIFheader NRAO+338_0039_TS036H_NL_No0001 5032 | less

或者可以打印更多输出：
printVDIFheader NRAO+338_0039_TS036H_NL_No0001 5032 long | less


探测80 Hz噪声一个名为m5fold的程序“折叠”给定频率处的功率，并产生该周期内相位的功率曲线。 在VLBA（以及其他几个VLBI天线）上，噪声功率是通过方波注入并由下游电子设备解码以确定系统温度的。
可以尝试查看n6043的数据：
cd /home/difx_data/n6043m5fold NRAO+301_0540_N6043_PT_No0008 Mark5B-2048-16-2 50 20000 80 fold80

然后使用gnuplot绘制输出文件“ fold80”。 第一列是相位（以秒为单位表示自第一个相位bin以来的时间），第2列到第17列对应于16个基带通道。 上述命令中的数字“ 80”是要折叠的频率。
gnuplot
p 'fold80' u 1:5
试一试其他频率，例如与80 Hz不成比例的频率（例如79 Hz）。 如果您尝试40 Hz，您会期望什么？
你可以通过增加命令中的数字“ 50”来增加折叠轮廓中的样本数。 您可以通过更改“ 20000”来增加或减少要处理的数据量。 越大，输出信噪比越高。
研究其他人的相关处理这个相关状态消息被发送到每个人都可以访问的本地网络上的多播地址。因此，您可以在不干扰的情况下查看其他机器正在做什么。要做到这一点，请启动2个以上的终端，并在每个终端中运行setup_difx setup脚本。 然后运行
$ errormon$ statemon

这两个终端将显示与专用监视器终端相同的输出，但将包括房间中运行的所有作业的信息。
]]></content>
      <categories>
        <category>DiFX</category>
      </categories>
      <tags>
        <tag>difx</tag>
        <tag>DiFX</tag>
        <tag>m5spec</tag>
        <tag>printVDIFheader</tag>
        <tag>m5fold</tag>
        <tag>gnuplot</tag>
        <tag>errormon</tag>
        <tag>statemon</tag>
      </tags>
  </entry>
  <entry>
    <title>DiFX 测试数据集</title>
    <url>/2018/12/24/difx_run/</url>
    <content><![CDATA[运行DiFX设置MPI和mpifxcorr设置 mpifxcorr 现在比以前简单了许多，只需将 setup.bash 或 setup.csh 添加到登录脚本中。你可以在安装目录的顶层找到这些设置文件。假设你使用的是 bash，并运行 DiFX-2.2（现在已经较旧，最新版本为2.8.1），你需要的文件是 master_tags/DiFX-2.2/setup.bash。你在安装 DiFX 时应该已经设置过这个文件。
要确保 MPI 准备好运行，输入 mpirun。它应该显示可用的选项列表。如果它抱怨环境没有准备好，可能需要运行 mpd。除此之外，咨询你所用 MPI 发行版的具体文档，这里有太多不同的 MPI 版本，无法进行详细的故障排除。
这个文件定义了一堆变量，例如$DIFXROOT，并将$DIFXROOT/bin/添加到路径中。因此，编译的所有程序都应该可以正常运行。输入which mpifxcorr - 您应该看到将要运行的mpifxcorr版本和路径。
为了确保MPI准备好运行，键入 mpirun 。 它应该给您提供它所采取的选项列表。 如果它抱怨环境还没有准备好，您可能需要运行’mpd’。除此之外 - 请参阅您的发行版的特定MPI文档，有太多不同的MPI发行版，无法在此处进行详细的故障排除。
运行mpifxcorr如果您已经下载了一些示例数据并且只想测试它，那么您可以立即开始，因为您不需要生成辅助文件。但是，最好从一开始就遵循正常的设置相关性的路径，您只需使用vex文件即可生成所有mpifxcorr配置文件。 
下面显示了一个相关处理方式的流程图：

如图所见，有两个步骤需要用户输入。第一个是生成 .v2d 文件。 有关此文件的介绍，可以参考vex2difx文档，但它可以（并且通常是）非常简单。另一个是机器文件和.threads文件。 这些描述了mpifxcorr将在哪台计算机上运行以及它将使用多少个计算线程。这里显示了一个示例，具体可以参考difx-files。 如果您只是在一台机器上运行（比如自己的笔记本或者服务器），那么只需一遍又一遍地使用它的名称即可。您至少需要N + 2个条目，其中N是望远镜的数量。
Before you start up the correlator, you should start up errormon2 to logthe messages which come out of the correlator. Just type errormon2, andit will write a file called log (you can rename it later if you want).在启动相关处理之前，您应该启动 errormon2 以记录相关处理输出的消息。 只需键入 errormon2 ，它将写入一个名为log的文件（如果需要，稍后可以将其重命名）。
一旦您拥有机器文件，并且errormon2正在运行，您就应该能够使用以下命令启动相关处理：
$ mpirun -machinefile machines.list -np X mpifxcorr example.input

将machines.list替换为您的机器文件名，将X替换为要使用的进程数，并将example.input替换为输入文件名。
目前，主要有以下几个工具可以运行：genmachines/startdifx、espresso 和 startcorr.pl。genmachines 适用于 Mark5 单元相关的相关性计算，espresso 用于基于文件的相关性计算，而 startcorr.pl 适用于 eVLBI。将来这些工具可能会统一。
辅助程序如上所述，DiFX 提供了一系列辅助程序，帮助设置相关处理作业并将输出转换为导出格式。下面列出了这些程序及其简要说明的链接。
vex2difxvex2difx在vex2difx有很好的文档。
calcif2使用 calcif2 生成相关模型文件。它处理由 vex2difx 生成的 .calc 文件，并生成 .delay、.uvw、.rate 和 .im 文件。你应该在 vex2difx 之后运行 calcif2，在 mpifxcorr 之前运行。
difx2fitsdifx2fits 用于生成 FITS 文件。要使用 difx2fits，需要将 .input 文件中的输出格式设置为 SWIN，并在相关性计算完成后使用 difx2fits。更多文档已记录在 这里。
difx2mark4difx2mark4 用于生成类地测量的 Mark4 可见性数据集。它的运行方式与 difx2fits 类似。相关文档已记录在 这里。
参考指南关于 mpifxcorr 及其支持软件的详细信息，可以在参考

https://www.atnf.csiro.au/vlbi/dokuwiki/doku.php/difx/difx_run
https://www.atnf.csiro.au/vlbi/dokuwiki/lib/exe/fetch.php/difx/difxuserguide.pdf

]]></content>
      <categories>
        <category>DiFX</category>
      </categories>
      <tags>
        <tag>DiFX</tag>
        <tag>DiFX-1.5</tag>
        <tag>DiFX-2.5</tag>
        <tag>DiFX-2.6.1</tag>
      </tags>
  </entry>
  <entry>
    <title>Django 忘记管理员或忘记管理员密码</title>
    <url>/2018/01/28/django-forget-password/</url>
    <content><![CDATA[Django 忘记管理员或忘记管理员密码第一步：运行django shell
python3 manage.py shell

第二步：重设密码
&gt;&gt;&gt; from django.contrib.auth.models import User&gt;&gt;&gt; user = User.object.get(username='your_account')&gt;&gt;&gt; user.set_password('your_new_password')&gt;&gt;&gt; user.save()&gt;&gt;&gt; quit()

如果你连管理员用户名都忘了。。。
&gt;&gt;&gt; from django.contrib.auth.models import User&gt;&gt;&gt; user = User.object.get(pk=1)&gt;&gt;&gt; user&lt;User: you_account&gt;&gt;&gt;&gt; user.set_password('your_new_password')&gt;&gt;&gt; user.save()&gt;&gt;&gt; quit()
]]></content>
      <categories>
        <category>Django</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>django</tag>
      </tags>
  </entry>
  <entry>
    <title>CentOS 安装 docker</title>
    <url>/2018/11/22/docker-centos/</url>
    <content><![CDATA[CentOS 安装 docker安装Docker$ sudo yum install -y yum-utils$ sudo yum-config-manager \    --add-repo \    https://download.docker.com/linux/centos/docker-ce.repo

安装 Docker$ sudo yum install docker-ce docker-ce-cli containerd.io

启动 Docker$ sudo systemctl start docker

参考https://docs.docker.com/engine/install/centos/
]]></content>
      <categories>
        <category>Docker</category>
        <category>Image</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>image</tag>
        <tag>images</tag>
        <tag>import</tag>
        <tag>tag</tag>
        <tag>push</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker清理命令</title>
    <url>/2017/11/24/docker-clean/</url>
    <content><![CDATA[Docker清理命令杀死所有正在运行的容器
docker kill $(docker ps -a -q)

删除所有已经停止的容器
docker rm $(docker ps -a -q)

删除所有未打 dangling 标签的镜像
docker rmi $(docker images -q -f dangling=true)

通过镜像的id来删除指定镜像
docker rmi &lt;image id&gt;
删除所有镜像
docker rmi $(docker images -q)



删除docker images中为none的镜像docker ps -a | grep "Exited" | awk '{print $1 }'|xargs docker stopdocker ps -a | grep "Exited" | awk '{print $1 }'|xargs docker rmdocker images|grep none|awk '{print $3 }'|xargs docker rmi

删除标签$ docker rmi shaoguangleo/test:tag
]]></content>
      <categories>
        <category>Docker</category>
        <category>Image</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>image</tag>
        <tag>images</tag>
        <tag>kill</tag>
        <tag>rm</tag>
        <tag>rmi</tag>
        <tag>dangling</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker commit</title>
    <url>/2017/11/24/docker-commit/</url>
    <content><![CDATA[docker commitdocker如何将运行中的容器保存为docker镜像$  docker commit &lt;container id&gt; &lt;repo-name&gt;:&lt;tag&gt;$  docker save -o &lt;repo-name&gt;-&lt;tag&gt;.img &lt;repo-name&gt;:&lt;tag&gt;

]]></content>
      <categories>
        <category>Docker</category>
        <category>Image</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>image</tag>
        <tag>images</tag>
        <tag>import</tag>
        <tag>tag</tag>
        <tag>push</tag>
        <tag>pull</tag>
        <tag>inspect</tag>
        <tag>history</tag>
        <tag>search</tag>
        <tag>commit</tag>
        <tag>save</tag>
        <tag>load</tag>
      </tags>
  </entry>
  <entry>
    <title>MacOSX Docker服务器如何分配硬盘空间大小？</title>
    <url>/2020/01/20/docker-container-size/</url>
    <content><![CDATA[MacOSX Docker服务器如何分配硬盘空间大小？打开电脑上的docker。

点击菜单栏上的图标，点击Dashboard打开面板。

打开后，点击上方的设置图标。

点击左边的Resources，资源设置项。
 
找到下方的Disk size的设置项，就是设置硬盘大小的。
设置好后，点击下方的apply按钮，完成设置。
]]></content>
      <categories>
        <category>Docker</category>
        <category>Linux</category>
        <category>GUI</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>docker</tag>
        <tag>run</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker Container</title>
    <url>/2017/11/24/docker-containers/</url>
    <content><![CDATA[Create a Container$ docker create -it ubuntu:lastest$ docker start ubuntu:lastest

is equal to
$ docker run -it ubuntu:lastest

Stop a Container$ docker stop ubuntu:lastest

Delete the contaier$ docker rm contaier_id


Export an contaier$ docker export --output=test.tar contaier_id

Import an contaier$ docker import test.tar - username/ubuntu:v1.0







Docker 快速删除所有容器
docker ps


查看所有容器
$ docker ps -a

进入容器其中字符串为容器ID:
$ docker exec -it d27bd3008ad9 /bin/bash

停用全部运行中的容器:
$ docker stop $(docker ps -q)

删除全部容器：
$ docker rm $(docker ps -aq)
一条命令实现停用并删除容器：
$ docker stop $(docker ps -q) &amp; docker rm $(docker ps -aq)
]]></content>
      <categories>
        <category>Docker</category>
        <category>Image</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>image</tag>
        <tag>images</tag>
        <tag>import</tag>
        <tag>tag</tag>
        <tag>push</tag>
        <tag>pull</tag>
        <tag>inspect</tag>
        <tag>history</tag>
        <tag>search</tag>
        <tag>commit</tag>
        <tag>save</tag>
        <tag>load</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker Data Management</title>
    <url>/2018/01/13/docker-data-management/</url>
    <content><![CDATA[Docker Data ManagementThere are two methods to handle Docker data.
Method 1 : Data Volume$ docker run -v /local/path:/docker/path shaoguangleo/ubuntu:lateset

Also , you can mount several directories at the same time.
$ docker run -v /local/path:/docker/path -v /local/path2:/docker/path2 -v /local/path3:/docker/path3 shaoguangleo/ubuntu:lateset

By default the data volume can be read and write, you can specify the parameter point out.
For example: Just read
$ docker run -v /local/path:/docker/path:ro shaoguangleo/ubuntu:lateset

Method 2 : Data Volume ContainerFirst create a data volume container and mount to /dbdata
$ docker run -it -v /dbdata shaoguangleo/ubuntu:lateset

Then we can using --volumes-from to mount the dbdata through many dockers.
$ docker run -it --volumes-from dbdata --name db1 ubuntu$ docker run -it --volumes-from dbdata --name db2 ubuntu$ docker run -it --volumes-from dbdata --name db3 ubuntu

So we can modify some file in dbdata which can immediately work in other dockers.
Docker backup/restore dataBy the way, we can also using docker to backup or restore data.
backup$ docker run --volumes-from dbdata -v $(pwd):/backup --name worker ubuntu tar cvf /backup/backup.tar /dbdata

restore$ docker run -v /dbdata --name dbdata2 ubuntu /bin/bash$ docker run --volumes-from dbdata2 -v $(pwd):/backup busybox tar xvf /backup/backup.tar
]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>data</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker examples</title>
    <url>/2018/01/12/docker-examples/</url>
    <content><![CDATA[Set up the wordpress using DockerFirst set up the enviromentMethod 1 : using dockersudo docker run --name db --env MYSQL_ROOT_PASSWORD=example -d mariadbsudo docker run --name MyWordPress --link db:mysql -p 8080:80 -d wordpress

Method 2 : using docker-composewordpress:        image: wordpress        links:                - db:mysql        port:                - 8080:80db:             image: mariadb        environment:                MYSQL_ROOT_PASSWORD: example

Now runaccess http://ip:8080
]]></content>
      <categories>
        <category>Docker</category>
        <category>Wordpress</category>
        <category>GitLab</category>
        <category>Redmind</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>wordpress</tag>
        <tag>gitlab</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker镜像</title>
    <url>/2017/11/22/docker-images/</url>
    <content><![CDATA[docker镜像操作获取镜像$ docker pull NAME[:TAG]


We should specificate the tag when deploy in real task

查看镜像$ docker images$ docker inspect image$ docker history image

搜素一个镜像$ docker search imagename

This will list official image by default.
删除一个镜像$ docker rmi imagename

Create the imageMethod 1提交更改并保存在contaier为一个镜像，假定为mynewimage
When you modify something in a container, you will get a new container id, remember it to create a new image.
$ docker commit -m message -a author CONTAINER_ID mynewimage:TAG

Method 2you can using a template to import an image.
保存镜像到一个tar文件保存该镜像到一个tar文件
$ docker save mynewimage &gt; /tmp/mynewimage.tar

导入一个镜像然后拷贝到另外一台主机，使用下述命令进行载入：
$ docker load &lt; /tmp/mynewimage

推送一个镜像$ docker tag test:lastest username/test:lastest$ docker push username/test:lastest
]]></content>
      <categories>
        <category>Docker</category>
        <category>Image</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>image</tag>
        <tag>images</tag>
        <tag>import</tag>
        <tag>tag</tag>
        <tag>push</tag>
        <tag>pull</tag>
        <tag>inspect</tag>
        <tag>history</tag>
        <tag>search</tag>
        <tag>commit</tag>
        <tag>save</tag>
        <tag>load</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker 导入镜像</title>
    <url>/2017/11/22/docker-import/</url>
    <content><![CDATA[docker镜像操作获取镜像$ docker pull NAME[:TAG]


We should specificate the tag when deploy in real task

查看镜像$ docker images$ docker inspect image$ docker history image

搜素一个镜像$ docker search imagename

This will list official image by default.
删除一个镜像$ docker rmi imagename

Create the imageMethod 1提交更改并保存在contaier为一个镜像，假定为mynewimage
When you modify something in a container, you will get a new container id, remember it to create a new image.
$ docker commit -m message -a author CONTAINER_ID mynewimage:TAG

Method 2you can using a template to import an image.
保存镜像到一个tar文件保存该镜像到一个tar文件
$ docker save mynewimage &gt; /tmp/mynewimage.tar

导入一个镜像然后拷贝到另外一台主机，使用下述命令进行载入：
$ docker load &lt; /tmp/mynewimage

推送一个镜像$ docker tag test:lastest username/test:lastest$ docker push username/test:lastest
]]></content>
      <categories>
        <category>Docker</category>
        <category>Image</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>image</tag>
        <tag>images</tag>
        <tag>import</tag>
      </tags>
  </entry>
  <entry>
    <title>构建Docker镜像时处理Configuring tzdata交互输入</title>
    <url>/2019/01/20/docker-install-tzdata/</url>
    <content><![CDATA[构建Docker镜像时处理Configuring tzdata交互输入在Dockerfile中安装deb软件包时，某些软件将tzdata作为依赖项安装。
tzdata会以交互方式提醒用户选择使用位置。
Configuring tzdata
------------------
Please select the geographic area in which you live. Subsequent configuration
questions will narrow this down by presenting a list of cities, representing
the time zones in which they are located.
 1. Africa      4. Australia  7. Atlantic  10. Pacific  13. Etc
 2. America     5. Arctic     8. Europe    11. SystemV
 3. Antarctica  6. Asia       9. Indian    12. US
Geographic area:

可能一直会卡在这个界面（我就遇到了）。
为了解决这个问题，我们需要将tzdata设置为非交互方式。
首选的方法是在Dockerfile的第一条RUN之前加入以下配置：
ENV DEBIAN_FRONTEND=noninteractive第二个方法是，在DEBIAN_FRONTEND=noninteractive条件下使用命令apt install或apt-get install配置安装tzdata：
RUN DEBIAN_FRONTEND=noninteractive apt install -y tzdata这将自动选择默认配置安装tzdata。
]]></content>
      <categories>
        <category>Docker</category>
        <category>Linux</category>
        <category>GUI</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>docker</tag>
        <tag>run</tag>
      </tags>
  </entry>
  <entry>
    <title>docker命令不需要敲sudo的方法</title>
    <url>/2017/11/22/docker-nosudo/</url>
    <content><![CDATA[docker命令不需要敲sudo的方法由于docker daemon需要绑定到主机的Unix socket而不是普通的TCP端口，而Unix socket的属主为root用户，所以其他用户只有在命令前添加sudo选项才能执行相关操作。
如果不想每次使用docker命令的时候还要额外的敲一下sudo，可以按照下面的方法配置一下。

创建一个docker组
$ sudo groupadd docker

添加当前用户到docker组
$ sudo usermod -aG docker $USER

登出，重新登录shell

验证docker命令是否可以运行
$ docker run hello-world

]]></content>
      <categories>
        <category>Docker</category>
        <category>Image</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>image</tag>
        <tag>images</tag>
      </tags>
  </entry>
  <entry>
    <title>在Linux平台上运行Docker GUI程序</title>
    <url>/2018/01/20/docker-run-gui-on-linux/</url>
    <content><![CDATA[在Linux平台上，运行Docker的GUI是很简单的事情，只要共享DISPLAY变量挂在/tmp/.X11-unix，并且开放控制X server的访问权限即可。
在宿主机上运行命令
$ xhost +

此时就可以使用docker的图形界面了，比如测试如下：
$ docker run -it -e DISPLAY=unix$DISPLAY -v /tmp/.X11-unix:/tmp/.X11-unix shaoguangleo/centos-pgplot然后输入# /usr/local/pgplot/pgdemo1

见证奇迹。
]]></content>
      <categories>
        <category>Docker</category>
        <category>Linux</category>
        <category>GUI</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>docker</tag>
        <tag>run</tag>
      </tags>
  </entry>
  <entry>
    <title>在Mac OS X平台上运行Docker GUI程序</title>
    <url>/2018/01/21/docker-run-gui-on-macosx/</url>
    <content><![CDATA[在MacOSX平台上运行Docker GUI程序在Linux平台上，运行Docker的GUI是很简单的事情，只要共享DISPLAY变量挂在/tmp/.X11-unix即可。
Mac OS X 稍微有些复杂，如下所示。
安装基础软件socatsocat用于创建两个节点的双向数据流通信。
$ brew install socat$ socat TCP-LISTEN:6000,reuseaddr,fork UNIX-CLIENT:\"$DISPLAY\"

XquartzXquartz为Mac OS X系统上的X窗口系统。
$ brew install Caskroom/cask/xquartz

打开Xquartz软件，偏好设置-&gt;安全性-&gt;勾选允许从网络客户端连接。
运行$ docker run -e DISPLAY=192.168.1.4:0 shaoguangleo/ubuntu-astrosoft


其中IP地址为本机的IP地址，注意修

其中IP可用通过下面的命令来获取：
IP=$(ifconfig en0 | grep inet | awk '$1=="inet" {print $2}')




另外一种方法在MacOSX上运行,
$xhost +127.0.0/1#或者$xhost +localhost

确保localhost允许X11转发
然后在docker镜像内部执行显示映射
$ export DISPLAY=$IP:0$ docker run -it -e DISPLAY=$IP:0 shaoguangleo/ubuntu-astrosoft



ARM芯片Apple在2021年发布了搭载ARM芯片的操作系统，会出现linux/arm64/v8不执行的提示，可以通过下面的方式来解决。
$ export DOCKER_DEFAULT_PLATFORM=linux/amd64 

或者使用指定的参数--platform=linux/amd64 来编译或者运行amd的镜像与版本。
参考：cflags - How to add ‘-march=’ as default option to gcc? - Stack Overflow
]]></content>
      <categories>
        <category>Docker</category>
        <category>MacOSX</category>
        <category>GUI</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>run</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker 保存和导入</title>
    <url>/2018/11/22/docker-save-load/</url>
    <content><![CDATA[Docker 保存和导入docker load 和docker save 用于操作images.
而
docker import 和docker export 用于操作容器。
所以要确保成对使用，不然可能需要加上一些参数。
docker: Error response from daemon: No command specified.这个问题可能是因为用save来保存了镜像，而用import导入了这个镜像，此时需要跟上命令：
这个命令可以通过save的镜像来查找，命令为：
docker ps -a --no-trunc

这个命令输出的最后作为docker run的参数，基本可以解决。
]]></content>
      <categories>
        <category>Docker</category>
        <category>Image</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>image</tag>
        <tag>images</tag>
        <tag>tag</tag>
        <tag>push</tag>
      </tags>
  </entry>
  <entry>
    <title>Singularity 镜像无法更新</title>
    <url>/2020/11/02/docker-singularity/</url>
    <content><![CDATA[Singularity 镜像无法更新在编译的时候碰到的问题为：https://registry-1.docker.io io timeout
很明显就是国外的docker仓库无法使用，这是就需要指定国内的镜像即可解决。
如下，把下面的内容更改为国内的镜像即可。
From: ubuntu:16.04

修改为：
From: hub-mirror.c.163.com/library/ubuntu:16.04

或者
From: docker.mirrors.ustc.edu.cn/library/ubuntu:16.04

]]></content>
      <categories>
        <category>Docker</category>
        <category>Singularity</category>
        <category>Image</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>image</tag>
        <tag>pull</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker 标签</title>
    <url>/2018/11/22/docker-tag/</url>
    <content><![CDATA[Docker tag 命令docker tag : 标记本地镜像，将其归入某一仓库。
语法docker tag [OPTIONS] IMAGE[:TAG] [REGISTRYHOST/][USERNAME/]NAME[:TAG]

实例将镜像ubuntu:18.04标记为 192.168.1.123:/ubuntu:v18.04 镜像。
$ docker tag ubuntu:18.04 192.168.1.123:/ubuntu:v18.04

]]></content>
      <categories>
        <category>Docker</category>
        <category>Image</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>image</tag>
        <tag>images</tag>
        <tag>tag</tag>
        <tag>push</tag>
      </tags>
  </entry>
  <entry>
    <title>Erlang 开始erlang</title>
    <url>/2013/12/02/erlang-getting-started-quickly/</url>
    <content><![CDATA[开始erlang在终端中输入erl，即可看到如下所示：
$ erlErlang R14B (erts-5.8.1.1) [source] [smp:2:2] [rq:2] [async-threads:0] [kernel-poll:false]Eshell V5.8.1.1  (abort with ^G)1&gt;

其中 “&gt;” 表示系统正等待输入。将Erlang当做一个计算器：
1&gt; 2*6.122&gt;

切记，每个表达式** 使用一个句点.** 来结束。编辑以前的表达式
可以使用类似emacs行编辑命令来取回以前的表达式进行编辑。最常用的命令为：
^P 获取前一行^N 获取下一行^A 移至当前行首^E 移至当前行尾^D 删除当前光标下字符^F 前移一个字符^B 后退一个字符Return 执行命令

注: ^X 表示Control + X

赶紧使用Control+P看看结果吧。编译你的第一个程序
使用你最爱的编辑器输入下列内容:
-module(test).-export([fac/1]).fac(0) -&gt; 1;fac(N) -&gt; N * fac(N-1).
保存为 test.erl ，注意文件名必须和模块名相同。
通过输入c(test) 来编译该程序然后运行它:
3&gt; c(test).{ok,test}30&gt; test:fac(20).24329020081766400004&gt; test:fac(40).81591528324789773434561126959611589427200000000032&gt;
]]></content>
      <categories>
        <category>Erlang</category>
      </categories>
      <tags>
        <tag>erl</tag>
      </tags>
  </entry>
  <entry>
    <title>Flex handles ambiguous patterns</title>
    <url>/2017/01/23/flex_manual_handle_ambiguous_patterns/</url>
    <content><![CDATA[Most flex programs are quite ambiguous, with multiple patterns that can match the same input. Flex resolves the ambiguity with two simple rules:

Match the longest possible string every time the scanner matches input.
In the case of a tie, use the pattern that appears first in the program.

These turn out to do the right thing in the vast majority of cases. Consider this snippetfrom a scanner for C source code:
"+""=""+=" { return ADD; }{ return ASSIGN; }{ return ASSIGNADD; }"if""else"[a-zA-Z_][a-zA-Z0-9_]* { return KEYWORDIF; }{ return KEYWORDELSE; }{ return IDENTIFIER; }

For the first three patterns, the string += is matched as one token, since += is longer than+ . For the last three patterns, so long as the patterns for keywords precede the patternthat matches an identifier, the scanner will match keywords correctly.
]]></content>
      <categories>
        <category>Flex</category>
      </categories>
      <tags>
        <tag>flex</tag>
      </tags>
  </entry>
  <entry>
    <title>输入文件的格式</title>
    <url>/2017/01/23/flex_manual_format_of_input_file/</url>
    <content><![CDATA[Flex输入文件的格式flex的输入文件包含三个部分，使用%%来分隔，格式如下：
定义段%%规则段%%用户代码

定义段的格式定义段的格式如下：
name definition

 name 的定义跟C语言类似，由开头为字母或者下划线组成的。definition为从第一个为非空格的字符一直到行尾。定义可以后续使用{name}来代替，会自动展开为(definition)。例如
DIGIT    [0-9]ID       [a-z][a-z0-9]*

DIGIT为匹配一个数字的正则表达式，ID为一个第一个为字符，后面跟着零个或者多个的数字字符。
{DIGIT}+"."{DIGIT}*

可以展开为：
([0-9])+"."([0-9])*

可以认为是浮点数的表达式。
在符号%{和 %}之间的部分都会被原版拷贝到输出，不过需要注意的是%{和%}字符必须 顶格写 。
另外一个比较有用的为%top，使用方法与%{ … %} 使用类似。
这个字段的作用为，内部含的内容全部出现在生成文件的最开始，这对于定义一些宏或者写一些提示信息是比较有用的。
比如可以写些如下的内容：
%top{  /*   * Author       :       Guo Shaoguang   * Email        :       sgguo@shao.ac.cn   * Date         :       201010   * Version      :       v1.0   * Name         :       heal the world   *   * Copyright (c) 2010-2016, SHAO   * All rights reserved.}

%top字段可以写多个，顺序就按照书写的顺序。
规则段的格式规则段的格式为：
pattern action

需要注意的是pattern必须顶格写。
用户代码的格式用户代码被原版照搬到lex.yy.c文件中，可以省略不写。
如何写注释注释的写法与C语言类似，唯一需要注意的是，最好在/*的前面加上几个空格，并且都是在单独一行里面。
]]></content>
      <categories>
        <category>Flex</category>
      </categories>
      <tags>
        <tag>flex</tag>
        <tag>yylex</tag>
      </tags>
  </entry>
  <entry>
    <title>Flex 介绍</title>
    <url>/2017/01/23/flex_manual_intro/</url>
    <content><![CDATA[flex为生成字符解析的一个工具。
flex读取文件或者终端输入，然后分析吃入的文本。
这些解析都按照正则表达式来描述，并生成C代码，默认为lex.yy.c，这个文件定义了函数yylex。
然后就可以通过编译lex.yy.c文件来测试了。
]]></content>
      <categories>
        <category>Flex</category>
      </categories>
      <tags>
        <tag>flex</tag>
        <tag>yylex</tag>
      </tags>
  </entry>
  <entry>
    <title>Flex expressions</title>
    <url>/2017/01/23/flex_manual_regular_expressions/</url>
    <content><![CDATA[The patterns at the heart of every flex scanner use a rich regular expression language.A regular expression is a pattern description using a metalanguage, a language that youuse to describe what you want the pattern to match. Flex’s regular expression languageis essentially POSIX-extended regular expressions (which is not surprising consideringtheir shared Unix heritage). The metalanguage uses standard text characters, some ofwhich represent themselves and others of which represent patterns. All characters otherthan the ones listed below, including all letters and digits, match themselves.The characters with special meaning in regular expressions are:

. Matches any single character except the newline character ( \n ).
[] A character class that matches any character within the brackets. If the first char- acter is a circumflex ( ^ ), it changes the meaning to match any character except the ones within the brackets. A dash inside the square brackets indicates a character range; for example, [0-9] means the same thing as [0123456789] and [a-z] means any lowercase letter. A - or ] as the first character after the [ is interpreted literally to let you include dashes and square brackets in character classes. POSIX intro- duced other special square bracket constructs that are useful when handling non- English alphabets, described later in this chapter. Other metacharacters do not have any special meaning within square brackets except that C escape sequences starting with \ are recognized. Character ranges are interpreted relative to the character coding in use, so the range [A-z] with ASCII character coding would match all uppercase and lowercase letters, as well as six punctuation characters whose codes fall between the code for Z and the code for a . In practice, useful ranges are ranges of digits, of uppercase letters, or of lowercase letters.
[a-z]{-}[jv] A differenced character class, with the characters in the first class omitting the characters in the second class (only in recent versions of flex).
^ Matches the beginning of a line as the first character of a regular expression. Also used for negation within square brackets.
$ Matches the end of a line as the last character of a regular expression.
{} If the braces contain one or two numbers, indicate the minimum and maximum number of times the previous pattern can match. For example, A{1,3} matches one to three occurrences of the letter A, and 0{5} matches 00000. If the braces contain a name, they refer to a named pattern by that name.
\ Used to escape metacharacters and as part of the usual C escape sequences; for example, \n is a newline character, while * is a literal asterisk.

Matches zero or more copies of the preceding expression. For example, [ \t]* is a common pattern to match optional spaces and tabs, that is, whitespace, which matches “ ”, “ ”, or an empty string.



Matches one or more occurrences of the preceding regular expression. For example, [0-9]+ matches strings of digits such as 1 , 111 , or 123456 but not an empty string.


? Matches zero or one occurrence of the preceding regular expression. For example, -?[0-9]+ matches a signed number including an optional leading minus sign.
| The alternation operator; matches either the preceding regular expression or the following regular expression. For example, faith|hope|charity matches any of the three virtues.
“…” Anything within the quotation marks is treated literally. Metacharacters other than C escape sequences lose their meaning. As a matter of style, it’s good practice to quote any punctuation characters intended to be matched literally.
() Groups a series of regular expressions together into a new regular expression. For example, (01) matches the character sequence 01, and a(bc|de) matches abc or ade. Parentheses are useful when building up complex patterns with *, +, ?, and |.
/ Trailing context, which means to match the regular expression preceding the slash but only if followed by the regular expression after the slash. For example, 0/1 matches 0 in the string 01 but would not match anything in the string 0 or 02 . The material matched by the pattern following the slash is not “consumed” and remains to be turned into subsequent tokens. Only one slash is permitted per pattern. The repetition operators affect the smallest preceding expression, so abc+ matches ab followed by one or more c’s. Use parentheses freely to be sure your expressions match what you want, such as (abc)+ to match one or more repetitions of abc.

]]></content>
      <categories>
        <category>Flex</category>
      </categories>
      <tags>
        <tag>flex</tag>
      </tags>
  </entry>
  <entry>
    <title>Flex 的一些简单例子</title>
    <url>/2017/01/23/flex_manual_simple_examples/</url>
    <content><![CDATA[来看看NB闪闪的flex的使用。
接下来简单的一句话的含义为，在遇到字符 username的时自动替换为 用户名的登录名：
%%username    printf( "%s", getlogin() );

默认情况下，任何不匹配的信息都会拷贝输出到终端。
上面的就是一个规则，其中 username' 是模式， printf’ 为动作。`%%’ 标记规则的开始。
下面说一个简单的例子example1.l：
        int num_lines = 0, num_chars = 0;%%\n      ++num_lines; ++num_chars;.       ++num_chars;%%main()        {        yylex();        printf( "# of lines = %d, # of chars = %d\n",                num_lines, num_chars );        }

这个程序将统计字符数和行数。程序将只输出最后的统计信息。
第一行定义了两个全局变量num_lines 和 num_chars，这两个变量可以被后面的yylex() 和  main() 函数来访问。
接下来有2个规则，匹配成 (`\n’) ，将增加 line 和 character 计数；两外一个就是匹配任何字符的将增加字符计数。
再来一个比较复杂的例子example2.l
/* scanner for a toy Pascal-like language */%{/* need this for the call to atof() below */#include &lt;math.h&gt;%}DIGIT    [0-9]ID       [a-z][a-z0-9]*%%{DIGIT}+    {            printf( "An integer: %s (%d)\n", yytext,                    atoi( yytext ) );            }{DIGIT}+"."{DIGIT}*        {            printf( "A float: %s (%g)\n", yytext,                    atof( yytext ) );            }if|then|begin|end|procedure|function        {            printf( "A keyword: %s\n", yytext );            }{ID}        printf( "An identifier: %s\n", yytext );"+"|"-"|"*"|"/"   printf( "An operator: %s\n", yytext );"{"[\^{}}\n]*"}"     /* eat up one-line comments */[ \t\n]+          /* eat up whitespace */.           printf( "Unrecognized character: %s\n", yytext );%%int main( int argc, char **argv )    {    ++argv, --argc;  /* skip over program name */    if ( argc &gt; 0 )            yyin = fopen( argv[0], "r" );    else            yyin = stdin;    yylex();    }

这个实例是解析类似Pascal语言的开始。程序解析了不同类型的标记并显示出来。
下一节介绍这个例子的含义。
]]></content>
      <categories>
        <category>Flex</category>
      </categories>
      <tags>
        <tag>flex</tag>
        <tag>yylex</tag>
      </tags>
  </entry>
  <entry>
    <title>聊聊版本</title>
    <url>/2014/01/26/git-about/</url>
    <content><![CDATA[聊聊版本控制Git是一款分布式版本控制系统，有别于CVS和SVN等集中式版本控制系统，Git可以让研发团队更加高效地协同工作，从而提高生产率。
 有很长一段时间Linus只使用diff、patch和tar包来管理Linux的代码。
大家平时在安装软件包的时候会发现软件包的名字后面有-svn,-git等等字眼。。到底有什么区别呢？看下面～～～

RCS(Revision Control System) 修订控制系统，特点:
简单
使用Lock机制防止多个开发人员对同一个文件同时进行修改.
CVS(Cocurrent Version System)并发版本系统,建立在RCS基础上,最流行的开放源代码版本控制系统,特点:
使用单一的主代码树,而不像RCS那样依赖多个目录.
最大优点在于多名开发人员可以同时对一个文件进行修改.允许合并.这就“并发“开发.
SVN(SubVersion)
目录的版本控制,CVS 只能对文件进行版本控制，不能对目录进行版本控制.CVS 只能注意到，一个文件在一个位置被删除了，而在一个新位置创建了另外一个文件。由于它不会连接两个操作，因此也很容易使文件历史轨迹丢失,SVN可以
原子性提交,CVS 采用线性、串行的批量提交，即依次地，一个接一个地执行提交，每成功提交一个文件，该文件的一个新的版本即被记录到版本库中，提交时用户提供的日志信息被重复地存储到每一个被修改的文件的版本历史中。CVS 串行批量提交模式的弊端在于 －当任何原因造成批量操作的中断时（典型原因包括：网络中断、客户端死机等），版本库往往处于一个不一致的状态：原本应该全部入库的文件只有一部分入库，很有可能版本库中的最新版本不能顺利编译，更为严重的是，随着其他的用户执行cvs update 操作，该不一致性将迅速在开发团队中扩散，从而严重影响团队的开发效率，并存在质量隐患。另外，假如该批量提交的中断没有被及时发现，开发团队往往要花更多的时间进行软件调试和排错。
Git, Git 是用于 Linux 内核开发的版本控制工具。与常用的版本控制工具 CVS, Subversion 等不同，它采用了分布式版本库的方式，不必服务器端软件支持，使源代码的发布和交流极其方便。 Git 的速度很快，这对于诸如 Linux kernel 这样的大项目来说自然很重要。 Git 最为出色的是它的合并跟踪（merge tracing）能力。git更加适合分布式开发项目。而svn（当然全称是subversion）则更适合于集中式大型开发项目。也有在git之上再使用一层svn的做法。

几个版本控制
本地版本控制：这个可能是大多数人使用的方式，不同的名字或者时间信息等，但很容易混淆文件
集中化版本控制：有个单一的集中管理的服务器，保持所有文件的修改版本，容易管理，但万一服务器宕机，风险就超级大了
分布式版本控制：多地克隆备份

总结CVS,Git,Mercurial,Subversion比较



特征
CVS
Git
Mercurial
Subversion



是否原子提交
没有
是
是的
是


文件和目录是否可以移动或重命名
CVS: 不是. 重命名不支持. 如果手动进行, 可能会损坏历史记录
Git: 支持重命名, 这是很实用的目的. git甚至能检测到重命名之后文件的改变. 尽管如此, 基于特殊的存储结构, 重命名不会被显示的记录, git能够推导出来(在实际使用中很容易做到)
是的, 重命名是支持的
是的. 支持重命名


在移动或重命名之后智能合并
CVS: 不能. 重命名都不支持, 就不必说智能了
Git: 不支持.
Mercurial: 是的. 重命名之后智能合并是支持的.
不支持.


文件和目录拷贝
不能
不能
支持拷贝
拷贝非常容易(O(1)). 包括产生分支


远程存储仓库的备份
间接的.
git的内部特征
是的
间接的.


是否传递变更到父仓库
CVS: 不会
是的
是的
是的,


仓库权限
CVS: 很有限.

Mercutial: 是的.
Subversion: 是的.


变更集
CVS: 不是. 变更是基于文件的
Git: 是的. 是支持的, 创建他们很容易
Mercurial: 是的. 变更集是支持的
Subversion: 部分支持. 对于一次提交会隐式创建一个变更集


跟踪线性的文件历史
CVS: 是的. cvs annotate
Git: 是的.(git blame)
Mercurial: 是的(hg annotate)
Subversion: 是的(svn blame)


能够只在仓库的单目录下作用
CVS: 是的
Git: 不是. 尽管如此, 提交多少能被限制
Mercurial: 能够基于某树的某个子集进行提交. 也有局部检出的能力
Subversion: 是的


跟踪未提交的变化
CVS: 是的. 通过cvs diff
Git: 是的.
Mercurial: 是的. 使用hg diff
Subversion: 是的. 使用svn diff


基于单个文件的提交信息
CVS: 不是. 提交信息是基于单次变化的
Git: 是的. 提交信息基于变更集
Mercurial: 不是
Subversion: 不是. 没有这个特征


文档
CVS: 非常棒. 有很多在线的tutorials和资源, 在线的书籍.
Git: 良好. 短的帮助比较简洁难懂.
Mercurial: 很好. 有基于公司的书籍和wiki. 每个命令都集成了帮助
Subversion: 很好. 有一些在线的书籍和一些在线的tutorials和资源. 并且书籍是以docbook/xml写的


配置是否轻松
CVS: 好. 是个事实上的标准. 基于每个系统都有并且很容易配置
Git: 好. 在现有平台上二进制可用. 需要C编译器和Perl. 在windows上需要cygwin. 并有一些Unix特征
Mercurial: 非常好. 几乎所有平台都有二进制包. 从源码编译需要python2.3以上, 并且需要C编译器
有些复杂


命令集
CVS: 包含了3个经常用到的命令的简单的命令集(cvs commit, cvs update和cvs checkout)和其它一些
Git: 命令集很丰富, 并且和CVS不兼容
Mercurial: 尝试模仿CVS交互方式, 但是偏离了基于不同的设计的意图
Subversion: 类CVS的命令集, 能够很容易被CVS用户使用


网络支持
CVS: 好. cvs在不同的场合使用不同的协议. 协议能够通过ssh链接的加密隧道进行
Git: 非常棒. 能够使用本地的git协议, 但也能在rsync, ssh, HTTP和HTTPS上使用
Mercurial: 非常棒. 使用HTTP或ssh. 远程访问会非常安全, 在只读网络里不需要上锁
Subversion: 非常好. Subversion服务器支持WebDAV+DeltaV(基于HTTP或HTTPS)作为底层协议, 或者它自身的协议同样能在ssh链接通道里使用.


可移植性
客户端能在UNIX, Windows和Mac OS上使用.
客户端运行在大多数的UNIX系统上,
运行在基于所有能运行python的平台
客户端和服务器端都能在UNIX, Windows和Mac OS X上运行


web接口
.CVSweb, ViewVC, Chora和wwCVS
Gitweb
Mercurial: 是的. Web接口是内置组件
ViewVC, SVN::Web, WebSVN, ViewSVN, mod_svn_view, Chora, Trac,SVN::RaWeb::Light,SVN Browser, Insurrection和perl_svn.


图形用户界面
WinCVS, Cervisia, TortoiseCVS
Gitk,Qqit和Git-gui
Hgit,hgct
RapidSVN, TortoiseSVN, Jsvn(java),


Git 是什么Git与其他版本控制系统的区别，其他的一般基于差异delta-based版本控制，如下：

而git是基于快照流的，如下：

近乎所有的操作都是本地执行。
]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>cvs</tag>
        <tag>diff</tag>
        <tag>patch</tag>
        <tag>rcs</tag>
        <tag>scv</tag>
        <tag>tar</tag>
      </tags>
  </entry>
  <entry>
    <title>Git 新功能Actions</title>
    <url>/2019/12/21/git-actions/</url>
    <content><![CDATA[Git 新功能ActionsGit Actions是一个好东西，回头有时间要研究一下。
可以参考 http://www.ruanyifeng.com/blog/2019/09/getting-started-with-github-actions.html.
https://github.com/marketplace/actions/hexo-action
对于配置Hexo自动CI的可以参考：https://blog.csdn.net/z_johnny/article/details/103910373
]]></content>
      <categories>
        <category>Git</category>
        <category>github</category>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>github</tag>
        <tag>Action</tag>
      </tags>
  </entry>
  <entry>
    <title>Git archive发布</title>
    <url>/2020/12/21/git-archive/</url>
    <content><![CDATA[准备一次发布现在你可以发布一个构建了。 其中一件事情就是为那些不怎么使用 Git 的兄弟们创建一个最新的快照归档。 使用 git archive 命令完成此工作：
$ git archive master --prefix='project/' | gzip &gt; `git describe master`.tar.gz$ ls *.tar.gzv1.6.2-rc1-20-g8c5b85c.tar.gz

如果有人将这个压缩包解压，他就可以在一个 project 目录中得到你项目的最新快照。 你也可以以类似的方式创建一个 zip 压缩包，但此时你应该向 git archive 命令传递 –format=zip 选项：
$ git archive master --prefix='project/' --format=zip &gt; `git describe master`.zip

现在你有了本次发布的一个 tar 包和一个 zip 包，可以将其上传到网站或以电子邮件的形式发送给人们。
制作提交简报现在是时候通知邮件列表里那些好奇你的项目发生了什么的人了。 使用 git shortlog 命令可以快速生成一份包含从上次发布之后项目新增内容的修改日志（changelog）类文档。 它会对你给定范围内的所有提交进行总结；比如，你的上一次发布名称是 v1.0.1，那么下面的命令可以给出上次发布以来所有提交的总结：
$ git shortlog --no-merges master --not v1.0.1Chris Wanstrath (6):      Add support for annotated tags to Grit::Tag      Add packed-refs annotated tag support.      Add Grit::Commit#to_patch      Update version and History.txt      Remove stray `puts`      Make ls_tree ignore nilsTom Preston-Werner (4):      fix dates in history      dynamic version method      Version bump to 1.0.2      Regenerated gemspec for version 1.0.2

这份整洁的总结包括了自 v1.0.1 以来的所有提交，并且已经按照作者分好组，你可以通过电子邮件将其直接发送到列表中。
]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>github</tag>
        <tag>archive</tag>
      </tags>
  </entry>
  <entry>
    <title>Git 分支</title>
    <url>/2013/12/22/git-branch/</url>
    <content><![CDATA[Git分支使用分支意味着你可以从开发主线上分离开来，然后在不影响主线的同时继续工作。在很多版本控制系统中，这是个昂贵的过程，常常需要创建一个源代码目录的完整副本，对大型项目来说会花费很长时间。
 Git 的分支模型可谓是“必杀技特性”，而正是因为它，将 Git 从版本控制系统家族里区分出来。Git 有何特别之处呢？Git 的分支可谓是难以置信的轻量级，它的新建操作几乎可以在瞬间完成，并且在不同分支间切换起来也差不多一样快。与许多其它版本控制系统不同，Git 鼓励在工作流程中频繁地使用分支与合并，哪怕一天之内进行许多次。 理解和精通这一特性，你便会意识到 Git 是如此的强大而又独特，并且从此真正改变你的开发方式。
何谓分支Git与其他版本管理的区别在于，Git保存的不是文件差异或者变化量，而是一系列的文件快照。而在git中所谓的分支就是一个40个字符长度的SHA-1表示的一个指针。
Git 中的分支，其实本质上仅仅是个指向 commit 对象的可变指针。Git 会使用 master 作为分支的默认名字。在若干次提交后，你其实已经有了一个指向最后一次提交对象的 master 分支，它在每次提交的时候都会自动向前移动。
那么，Git 是如何知道你当前在哪个分支上工作的呢？其实答案也很简单，它保存着一个名为 HEAD 的特别指针，在 Git 中，它是一个指向你正在工作中的本地分支的指针（译注：将 HEAD 想象为当前分支的别名。）。运行 git branch 命令，仅仅是建立了一个新的分支，但不会自动切换到这个分支中去，除非你使用checkout切换到另外一个分支中。
分支简介为了真正理解 Git 处理分支的方式，我们需要回顾一下 Git 是如何保存数据的。
或许你还记得 起步 的内容， Git 保存的不是文件的变化或者差异，而是一系列不同时刻的 快照 。
在进行提交操作时，Git 会保存一个提交对象（commit object）。 知道了 Git 保存数据的方式，我们可以很自然的想到——该提交对象会包含一个指向暂存内容快照的指针。 但不仅仅是这样，该提交对象还包含了作者的姓名和邮箱、提交时输入的信息以及指向它的父对象的指针。 首次提交产生的提交对象没有父对象，普通提交操作产生的提交对象有一个父对象， 而由多个分支合并产生的提交对象有多个父对象，
为了更加形象地说明，我们假设现在有一个工作目录，里面包含了三个将要被暂存和提交的文件。 暂存操作会为每一个文件计算校验和（使用我们在 起步 中提到的 SHA-1 哈希算法），然后会把当前版本的文件快照保存到 Git 仓库中 （Git 使用 blob 对象来保存它们），最终将校验和加入到暂存区域等待提交：
$ git add README test.rb LICENSE$ git commit -m 'The initial commit of my project'

当使用 git commit 进行提交操作时，Git 会先计算每一个子目录（本例中只有项目根目录）的校验和， 然后在 Git 仓库中这些校验和保存为树对象。随后，Git 便会创建一个提交对象， 它除了包含上面提到的那些信息外，还包含指向这个树对象（项目根目录）的指针。 如此一来，Git 就可以在需要的时候重现此次保存的快照。
现在，Git 仓库中有五个对象：三个 blob 对象（保存着文件快照）、一个 树 对象 （记录着目录结构和 blob 对象索引）以及一个 提交 对象（包含着指向前述树对象的指针和所有提交信息）。

做些修改后再次提交，那么这次产生的提交对象会包含一个指向上次提交对象（父对象）的指针。

Git 的分支，其实本质上仅仅是指向提交对象的可变指针。 Git 的默认分支名字是 master。 在多次提交操作之后，你其实已经有一个指向最后那个提交对象的 master 分支。 master 分支会在每次提交时自动向前移动。

分支创建Git 是怎么创建新分支的呢？ 很简单，它只是为你创建了一个可以移动的新的指针。 比如，创建一个 testing 分支， 你需要使用 git branch 命令：
$ git branch testing

这会在当前所在的提交对象上创建一个指针。

那么，Git 又是怎么知道当前在哪一个分支上呢？ 也很简单，它有一个名为 HEAD 的特殊指针。 请注意它和许多其它版本控制系统（如 Subversion 或 CVS）里的 HEAD 概念完全不同。 在 Git 中，它是一个指针，指向当前所在的本地分支（译注：将 HEAD 想象为当前分支的别名）。 在本例中，你仍然在 master 分支上。 因为 git branch 命令仅仅 创建 一个新分支，并不会自动切换到新分支中去。

你可以简单地使用 git log 命令查看各个分支当前所指的对象。 提供这一功能的参数是 --decorate。
$ git log --oneline --decoratef30ab (HEAD -&gt; master, testing) add feature #32 - ability to add new formats to the central interface34ac2 Fixed bug #1328 - stack overflow under certain conditions98ca9 The initial commit of my project

正如你所见，当前 master 和 testing 分支均指向校验和以 f30ab 开头的提交对象。
分支切换要切换到一个已存在的分支，你需要使用 git checkout 命令。 我们现在切换到新创建的 testing 分支去：
$ git checkout testing

这样 HEAD 就指向 testing 分支了。

那么，这样的实现方式会给我们带来什么好处呢？ 现在不妨再提交一次：
$ vim test.rb$ git commit -a -m 'made a change'


如图所示，你的 testing 分支向前移动了，但是 master 分支却没有，它仍然指向运行 git checkout 时所指的对象。 这就有意思了，现在我们切换回 master 分支看看：
$ git checkout master


这条命令做了两件事。 一是使 HEAD 指回 master 分支，二是将工作目录恢复成 master 分支所指向的快照内容。 也就是说，你现在做修改的话，项目将始于一个较旧的版本。 本质上来讲，这就是忽略 testing 分支所做的修改，以便于向另一个方向进行开发。



Note
分支切换会改变你工作目录中的文件在切换分支时，一定要注意你工作目录里的文件会被改变。 如果是切换到一个较旧的分支，你的工作目录会恢复到该分支最后一次提交时的样子。 如果 Git 不能干净利落地完成这个任务，它将禁止切换分支。







我们不妨再稍微做些修改并提交：
$ vim test.rb$ git commit -a -m 'made other changes'

现在，这个项目的提交历史已经产生了分叉（参见 项目分叉历史）。 因为刚才你创建了一个新分支，并切换过去进行了一些工作，随后又切换回 master 分支进行了另外一些工作。 上述两次改动针对的是不同分支：你可以在不同分支间不断地来回切换和工作，并在时机成熟时将它们合并起来。 而所有这些工作，你需要的命令只有 branch、checkout 和 commit。

你可以简单地使用 git log 命令查看分叉历史。 运行 git log --oneline --decorate --graph --all ，它会输出你的提交历史、各个分支的指向以及项目的分支分叉情况。
$ git log --oneline --decorate --graph --all* c2b9e (HEAD, master) made other changes| * 87ab2 (testing) made a change|/* f30ab add feature #32 - ability to add new formats to the* 34ac2 fixed bug #1328 - stack overflow under certain conditions* 98ca9 initial commit of my project

由于 Git 的分支实质上仅是包含所指对象校验和（长度为 40 的 SHA-1 值字符串）的文件，所以它的创建和销毁都异常高效。 创建一个新分支就相当于往一个文件中写入 41 个字节（40 个字符和 1 个换行符），如此的简单能不快吗？
这与过去大多数版本控制系统形成了鲜明的对比，它们在创建分支时，将所有的项目文件都复制一遍，并保存到一个特定的目录。 完成这样繁琐的过程通常需要好几秒钟，有时甚至需要好几分钟。所需时间的长短，完全取决于项目的规模。 而在 Git 中，任何规模的项目都能在瞬间创建新分支。 同时，由于每次提交都会记录父对象，所以寻找恰当的合并基础（译注：即共同祖先）也是同样的简单和高效。 这些高效的特性使得 Git 鼓励开发人员频繁地创建和使用分支。
接下来，让我们看看你为什么应该这样做。

创建新分支的同时切换过去通常我们会在创建一个新分支后立即切换过去，这可以用 git checkout -b &lt;newbranchname&gt; 一条命令搞定。

分支的新建与合并让我们来看一个简单的分支新建与分支合并的例子，实际工作中你可能会用到类似的工作流。 你将经历如下步骤：

开发某个网站。
为实现某个新的用户需求，创建一个分支。
在这个分支上开展工作。

正在此时，你突然接到一个电话说有个很严重的问题需要紧急修补。 你将按照如下方式来处理：

切换到你的线上分支（production branch）。
为这个紧急任务新建一个分支，并在其中修复它。
在测试通过之后，切换回线上分支，然后合并这个修补分支，最后将改动推送到线上分支。
切换回你最初工作的分支上，继续工作。

新建分支首先，我们假设你正在你的项目上工作，并且在 master 分支上已经有了一些提交。

现在，你已经决定要解决你的公司使用的问题追踪系统中的 #53 问题。 想要新建一个分支并同时切换到那个分支上，你可以运行一个带有 -b 参数的 git checkout 命令：
$ git checkout -b iss53Switched to a new branch "iss53"

它是下面两条命令的简写：
$ git branch iss53$ git checkout iss53


你继续在 #53 问题上工作，并且做了一些提交。 在此过程中，iss53 分支在不断的向前推进，因为你已经检出到该分支 （也就是说，你的 HEAD 指针指向了 iss53 分支）
$ vim index.html$ git commit -a -m 'added a new footer [issue 53]'


现在你接到那个电话，有个紧急问题等待你来解决。 有了 Git 的帮助，你不必把这个紧急问题和 iss53 的修改混在一起， 你也不需要花大力气来还原关于 53# 问题的修改，然后再添加关于这个紧急问题的修改，最后将这个修改提交到线上分支。 你所要做的仅仅是切换回 master 分支。
但是，在你这么做之前，要留意你的工作目录和暂存区里那些还没有被提交的修改， 它可能会和你即将检出的分支产生冲突从而阻止 Git 切换到该分支。 最好的方法是，在你切换分支之前，保持好一个干净的状态。 有一些方法可以绕过这个问题（即，暂存（stashing） 和 修补提交（commit amending））， 我们会在 贮藏与清理 中看到关于这两个命令的介绍。 现在，我们假设你已经把你的修改全部提交了，这时你可以切换回 master 分支了：
$ git checkout masterSwitched to branch 'master'

这个时候，你的工作目录和你在开始 #53 问题之前一模一样，现在你可以专心修复紧急问题了。 请牢记：当你切换分支的时候，Git 会重置你的工作目录，使其看起来像回到了你在那个分支上最后一次提交的样子。 Git 会自动添加、删除、修改文件以确保此时你的工作目录和这个分支最后一次提交时的样子一模一样。
接下来，你要修复这个紧急问题。 我们来建立一个 hotfix 分支，在该分支上工作直到问题解决：
$ git checkout -b hotfixSwitched to a new branch 'hotfix'$ vim index.html$ git commit -a -m 'fixed the broken email address'[hotfix 1fb7853] fixed the broken email address 1 file changed, 2 insertions(+)


你可以运行你的测试，确保你的修改是正确的，然后将 hotfix 分支合并回你的 master 分支来部署到线上。 你可以使用 git merge 命令来达到上述目的：
$ git checkout master$ git merge hotfixUpdating f42c576..3a0874cFast-forward index.html | 2 ++ 1 file changed, 2 insertions(+)

在合并的时候，你应该注意到了“快进（fast-forward）”这个词。 由于你想要合并的分支 hotfix 所指向的提交 C4 是你所在的提交 C2 的直接后继， 因此 Git 会直接将指针向前移动。换句话说，当你试图合并两个分支时， 如果顺着一个分支走下去能够到达另一个分支，那么 Git 在合并两者的时候， 只会简单的将指针向前推进（指针右移），因为这种情况下的合并操作没有需要解决的分歧——这就叫做 “快进（fast-forward）”。
现在，最新的修改已经在 master 分支所指向的提交快照中，你可以着手发布该修复了。

关于这个紧急问题的解决方案发布之后，你准备回到被打断之前时的工作中。 然而，你应该先删除 hotfix 分支，因为你已经不再需要它了 —— master 分支已经指向了同一个位置。 你可以使用带 -d 选项的 git branch 命令来删除分支：
$ git branch -d hotfixDeleted branch hotfix (3a0874c).

现在你可以切换回你正在工作的分支继续你的工作，也就是针对 #53 问题的那个分支（iss53 分支）。
$ git checkout iss53Switched to branch "iss53"$ vim index.html$ git commit -a -m 'finished the new footer [issue 53]'[iss53 ad82d7a] finished the new footer [issue 53]1 file changed, 1 insertion(+)


你在 hotfix 分支上所做的工作并没有包含到 iss53 分支中。 如果你需要拉取 hotfix 所做的修改，你可以使用 git merge master 命令将 master 分支合并入 iss53 分支，或者你也可以等到 iss53 分支完成其使命，再将其合并回 master 分支。
分支的合并假设你已经修正了 #53 问题，并且打算将你的工作合并入 master 分支。 为此，你需要合并 iss53 分支到 master 分支，这和之前你合并 hotfix 分支所做的工作差不多。 你只需要检出到你想合并入的分支，然后运行 git merge 命令：
$ git checkout masterSwitched to branch 'master'$ git merge iss53Merge made by the 'recursive' strategy.index.html |    1 +1 file changed, 1 insertion(+)

这和你之前合并 hotfix 分支的时候看起来有一点不一样。 在这种情况下，你的开发历史从一个更早的地方开始分叉开来（diverged）。 因为，master 分支所在提交并不是 iss53 分支所在提交的直接祖先，Git 不得不做一些额外的工作。 出现这种情况的时候，Git 会使用两个分支的末端所指的快照（C4 和 C5）以及这两个分支的公共祖先（C2），做一个简单的三方合并。

和之前将分支指针向前推进所不同的是，Git 将此次三方合并的结果做了一个新的快照并且自动创建一个新的提交指向它。 这个被称作一次合并提交，它的特别之处在于他有不止一个父提交。

Figure 25. 一个合并提交
既然你的修改已经合并进来了，就不再需要 iss53 分支了。 现在你可以在任务追踪系统中关闭此项任务，并删除这个分支。
$ git branch -d iss53

遇到冲突时的分支合并有时候合并操作不会如此顺利。 如果你在两个不同的分支中，对同一个文件的同一个部分进行了不同的修改，Git 就没法干净的合并它们。 如果你对 #53 问题的修改和有关 hotfix 分支的修改都涉及到同一个文件的同一处，在合并它们的时候就会产生合并冲突：
$ git merge iss53Auto-merging index.htmlCONFLICT (content): Merge conflict in index.htmlAutomatic merge failed; fix conflicts and then commit the result.

此时 Git 做了合并，但是没有自动地创建一个新的合并提交。 Git 会暂停下来，等待你去解决合并产生的冲突。 你可以在合并冲突后的任意时刻使用 git status 命令来查看那些因包含合并冲突而处于未合并（unmerged）状态的文件：
$ git statusOn branch masterYou have unmerged paths.  (fix conflicts and run "git commit")Unmerged paths:  (use "git add &lt;file&gt;..." to mark resolution)    both modified:      index.htmlno changes added to commit (use "git add" and/or "git commit -a")

任何因包含合并冲突而有待解决的文件，都会以未合并状态标识出来。 Git 会在有冲突的文件中加入标准的冲突解决标记，这样你可以打开这些包含冲突的文件然后手动解决冲突。 出现冲突的文件会包含一些特殊区段，看起来像下面这个样子：
&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD:index.html&lt;div id="footer"&gt;contact : email.support@github.com&lt;/div&gt;=======&lt;div id="footer"&gt; please contact us at support@github.com&lt;/div&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; iss53:index.html

这表示 HEAD 所指示的版本（也就是你的 master 分支所在的位置，因为你在运行 merge 命令的时候已经检出到了这个分支）在这个区段的上半部分（======= 的上半部分），而 iss53 分支所指示的版本在 ======= 的下半部分。 为了解决冲突，你必须选择使用由 ======= 分割的两部分中的一个，或者你也可以自行合并这些内容。 例如，你可以通过把这段内容换成下面的样子来解决冲突：
&lt;div id="footer"&gt;please contact us at email.support@github.com&lt;/div&gt;

上述的冲突解决方案仅保留了其中一个分支的修改，并且 &lt;&lt;&lt;&lt;&lt;&lt;&lt; , ======= , 和 &gt;&gt;&gt;&gt;&gt;&gt;&gt; 这些行被完全删除了。 在你解决了所有文件里的冲突之后，对每个文件使用 git add 命令来将其标记为冲突已解决。 一旦暂存这些原本有冲突的文件，Git 就会将它们标记为冲突已解决。
如果你想使用图形化工具来解决冲突，你可以运行 git mergetool，该命令会为你启动一个合适的可视化合并工具，并带领你一步一步解决这些冲突：
$ git mergetoolThis message is displayed because 'merge.tool' is not configured.See 'git mergetool --tool-help' or 'git help config' for more details.'git mergetool' will now attempt to use one of the following tools:opendiff kdiff3 tkdiff xxdiff meld tortoisemerge gvimdiff diffuse diffmerge ecmerge p4merge araxis bc3 codecompare vimdiff emergeMerging:index.htmlNormal merge conflict for 'index.html':  {local}: modified file  {remote}: modified fileHit return to start merge resolution tool (opendiff):

如果你想使用除默认工具（在这里 Git 使用 opendiff 做为默认的合并工具，因为作者在 Mac 上运行该程序） 外的其他合并工具，你可以在 “下列工具中（one of the following tools）” 这句后面看到所有支持的合并工具。 然后输入你喜欢的工具名字就可以了。



Note
如果你需要更加高级的工具来解决复杂的合并冲突，我们会在 高级合并 介绍更多关于分支合并的内容。







等你退出合并工具之后，Git 会询问刚才的合并是否成功。 如果你回答是，Git 会暂存那些文件以表明冲突已解决： 你可以再次运行 git status 来确认所有的合并冲突都已被解决：
$ git statusOn branch masterAll conflicts fixed but you are still merging.  (use "git commit" to conclude merge)Changes to be committed:    modified:   index.html



































新建分支新建分支并切换到该分支的命令：
git checkout -b new-branch-name

相当于下面的两条命令
git branch new-branch-namegit checkout new-branch-name

在切换分支的时候需要留心暂存区或者工作目录里，那些还没有提交的修改，它会和你即将检出的分支产生冲突从而阻止 Git 为你切换分支。切换分支的时候最好保持一个清洁的工作区域。
删除分支在分支完成开发后，可以使用参数d来删除该分支
git branch --delete new-branch-name

有时由于一些分支中包含没有被合并的修改，简单地使用上述命令可能会提示分支删除错误，此时可以使用-D来强制删除改分支。
合并分支首先切换到master分支，然后合并修改的分支
git checkout mastergit merge new-branch-name

在合并的时候，你应该注意到了“快进（fast-forward）”这个词。 由于你想要合并的分支 hotfix 所指向的提交 C4 是你所在的提交 C2 的直接后继， 因此 Git 会直接将指针向前移动。换句话说，当你试图合并两个分支时， 如果顺着一个分支走下去能够到达另一个分支，那么 Git 在合并两者的时候， 只会简单的将指针向前推进（指针右移），因为这种情况下的合并操作没有需要解决的分歧——这就叫做 “快进（fast-forward）”。
关于这个紧急问题的解决方案发布之后，你准备回到被打断之前时的工作中。 然而，你应该先删除 hotfix 分支，因为你已经不再需要它了 —— master 分支已经指向了同一个位置。 你可以使用带 -d 选项的 git branch 命令来删除分支：
$ git branch -d hotfixDeleted branch hotfix (3a0874c).


遇到冲突时的分支合并如果你想用一个有图形界面的工具来解决这些问题，不妨运行 git mergetool，它会调用一个可视化的合并工具并引导你解决所有冲突。
显示分支信息默认情况下，使用git branch会显示目前分支信息，如果加上-v参数，则会显示每一个分支的最后一次提交信息。
如果使用git branch -a会显示所有的分支。
远程分支远程分支（remote branch）是对远程仓库中的分支的索引。它们是一些无法移动的本地分支；只有在 Git 进行网络交互时才会更新。远程分支就像是书签，提醒着你上次连接远程仓库时上面各分支的位置。
获取所有远程分支
git branch -r | grep -v '\-&gt;' | while read remote; do git branch --track "${remote#origin/}" "$remote"; donegit fetch --allgit pull --all

推送本地分支要想和其他人分享某个本地分支，你需要把它推送到一个你拥有写权限的远程仓库。你创建的本地分支不会因为你的写入操作而被自动同步到你引入的远程服务器上，你需要明确地执行推送分支的操作。换句话说，对于无意分享的分支，你尽管保留为私人分支好了，而只推送那些协同工作要用到的特性分支。
git push (远程仓库名) (分支名)

删除远程分支如果不再需要某个远程分支了，比如搞定了某个特性并把它合并进了远程的 master 分支（或任何其他存放稳定代码的分支），可以用这个非常无厘头的语法来删除它：git push [远程名] :[分支名]。如果想在服务器上删除 serverfix 分支，运行下面的命令：
git push origin :branch-name

或者使用下面比较简单的命令：
git push origin --delete branch-name


分支的衍合把一个分支中的修改整合到另一个分支的办法有两种：merge 和 rebase
使用方法为：
git checkout mastergit merge branch-name

git checkout branch-namegit rebase master

一般我们使用衍合的目的，是想要得到一个能在远程分支上干净应用的补丁 — 比如某些项目你不是维护者，但想帮点忙的话，最好用衍合：先在自己的一个分支里进行开发，当准备向主项目提交补丁的时候，根据最新的 origin/master 进行一次衍合操作然后再提交，这样维护者就不需要做任何整合工作（译注：实际上是把解决分支补丁同最新主干代码之间冲突的责任，化转为由提交补丁的人来解决。），只需根据你提供的仓库地址作一次快进合并，或者直接采纳你提交的补丁。

rebase的风险： 一旦分支中的提交对象发布到公共仓库，就千万不要对该分支进行衍合操作。

跟踪分支从一个远程跟踪分支检出一个本地分支会自动创建所谓的“跟踪分支”（它跟踪的分支叫做“上游分支”）。 跟踪分支是与远程分支有直接关系的本地分支。 如果在一个跟踪分支上输入 git pull，Git 能自动地识别去哪个服务器上抓取、合并到哪个分支。
当克隆一个仓库时，它通常会自动地创建一个跟踪 origin/master 的 master 分支。 然而，如果你愿意的话可以设置其他的跟踪分支，或是一个在其他远程仓库上的跟踪分支，又或者不跟踪 master 分支。 最简单的实例就是像之前看到的那样，运行 git checkout -b  /。 这是一个十分常用的操作所以 Git 提供了 –track 快捷方式：
$ git checkout --track origin/serverfixBranch serverfix set up to track remote branch serverfix from origin.Switched to a new branch 'serverfix'



分支开发工作流长期分支因为 Git 使用简单的三方合并，所以就算在一段较长的时间内，反复把一个分支合并入另一个分支，也不是什么难事。 也就是说，在整个项目开发周期的不同阶段，你可以同时拥有多个开放的分支；你可以定期地把某些主题分支合并入其他分支中。
许多使用 Git 的开发者都喜欢使用这种方式来工作，比如只在 master 分支上保留完全稳定的代码——有可能仅仅是已经发布或即将发布的代码。 他们还有一些名为 develop 或者 next 的平行分支，被用来做后续开发或者测试稳定性——这些分支不必保持绝对稳定，但是一旦达到稳定状态，它们就可以被合并入 master 分支了。 这样，在确保这些已完成的主题分支（短期分支，比如之前的 iss53 分支）能够通过所有测试，并且不会引入更多 bug 之后，就可以合并入主干分支中，等待下一次的发布。
事实上我们刚才讨论的，是随着你的提交而不断右移的指针。 稳定分支的指针总是在提交历史中落后一大截，而前沿分支的指针往往比较靠前。

通常把他们想象成流水线（work silos）可能更好理解一点，那些经过测试考验的提交会被遴选到更加稳定的流水线上去。

Figure 27. 趋于稳定分支的流水线（“silo”）视图
你可以用这种方法维护不同层次的稳定性。 一些大型项目还有一个 proposed（建议） 或 pu: proposed updates（建议更新）分支，它可能因包含一些不成熟的内容而不能进入 next 或者 master 分支。 这么做的目的是使你的分支具有不同级别的稳定性；当它们具有一定程度的稳定性后，再把它们合并入具有更高级别稳定性的分支中。 再次强调一下，使用多个长期分支的方法并非必要，但是这么做通常很有帮助，尤其是当你在一个非常庞大或者复杂的项目中工作时。
主题分支主题分支对任何规模的项目都适用。 主题分支是一种短期分支，它被用来实现单一特性或其相关工作。 也许你从来没有在其他的版本控制系统（VCS）上这么做过，因为在那些版本控制系统中创建和合并分支通常很费劲。 然而，在 Git 中一天之内多次创建、使用、合并、删除分支都很常见。
你已经在上一节中你创建的 iss53 和 hotfix 主题分支中看到过这种用法。 你在上一节用到的主题分支（iss53 和 hotfix 分支）中提交了一些更新，并且在它们合并入主干分支之后，你又删除了它们。 这项技术能使你快速并且完整地进行上下文切换（context-switch）——因为你的工作被分散到不同的流水线中，在不同的流水线中每个分支都仅与其目标特性相关，因此，在做代码审查之类的工作的时候就能更加容易地看出你做了哪些改动。 你可以把做出的改动在主题分支中保留几分钟、几天甚至几个月，等它们成熟之后再合并，而不用在乎它们建立的顺序或工作进度。
考虑这样一个例子，你在 master 分支上工作到 C1，这时为了解决一个问题而新建 iss91 分支，在 iss91 分支上工作到 C4，然而对于那个问题你又有了新的想法，于是你再新建一个 iss91v2 分支试图用另一种方法解决那个问题，接着你回到 master 分支工作了一会儿，你又冒出了一个不太确定的想法，你便在 C10 的时候新建一个 dumbidea 分支，并在上面做些实验。 你的提交历史看起来像下面这个样子：

Figure 28. 拥有多个主题分支的提交历史
现在，我们假设两件事情：你决定使用第二个方案来解决那个问题，即使用在 iss91v2 分支中方案。 另外，你将 dumbidea 分支拿给你的同事看过之后，结果发现这是个惊人之举。 这时你可以抛弃 iss91 分支（即丢弃 C5 和 C6 提交），然后把另外两个分支合并入主干分支。 最终你的提交历史看起来像下面这个样子：

Figure 29. 合并了 dumbidea 和 iss91v2 分支之后的提交历史
我们将会在 分布式 Git 中向你揭示更多有关分支工作流的细节， 因此，请确保你阅读完那个章节之后，再来决定你的下个项目要使用什么样的分支策略（branching scheme）。
请牢记，当你做这么多操作的时候，这些分支全部都存于本地。 当你新建和合并分支的时候，所有这一切都只发生在你本地的 Git 版本库中 —— 没有与服务器发生交互。
]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>branch</tag>
      </tags>
  </entry>
  <entry>
    <title>git checkout</title>
    <url>/2018/01/26/git-checkout/</url>
    <content><![CDATA[git chekcout请务必记得 git checkout -- &lt;file&gt; 是一个危险的命令。 你对那个文件在本地的任何修改都会消失——Git 会用最近提交的版本覆盖掉它。 除非你确实清楚不想要对那个文件的本地修改了，否则请不要使用这个命令。
分支切换要切换到一个已存在的分支，你需要使用 git checkout 命令。 我们现在切换到新创建的 testing 分支去：
$ git checkout testing

这样 HEAD 就指向 testing 分支了。
检出特定的标签tag如果你想查看某个标签所指向的文件版本，可以使用 git checkout 命令， 虽然这会使你的仓库处于“分离头指针（detached HEAD）”的状态——这个状态有些不好的副作用：
$ git checkout 2.0.0Note: checking out '2.0.0'.You are in 'detached HEAD' state. You can look around, make experimentalchanges and commit them, and you can discard any commits you make in thisstate without impacting any branches by performing another checkout.If you want to create a new branch to retain commits you create, you maydo so (now or later) by using -b with the checkout command again. Example:  git checkout -b &lt;new-branch&gt;HEAD is now at 99ada87... Merge pull request #89 from schacon/appendix-final$ git checkout 2.0-beta-0.1Previous HEAD position was 99ada87... Merge pull request #89 from schacon/appendix-finalHEAD is now at df3f601... add atlas.json and cover image

在“分离头指针”状态下，如果你做了某些更改然后提交它们，标签不会发生变化， 但你的新提交将不属于任何分支，并且将无法访问，除非通过确切的提交哈希才能访问。 因此，如果你需要进行更改，比如你要修复旧版本中的错误，那么通常需要创建一个新分支：
$ git checkout -b version2 v2.0.0Switched to a new branch 'version2'




如果在这之后又进行了一次提交，version2 分支就会因为这个改动向前移动， 此时它就会和 v2.0.0 标签稍微有些不同，这时就要当心了。 
建立本地分支并将远程分支拉取至本地$ git checkout -b 本地分支名 origin/远程分支名

]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>checkoutemail</tag>
      </tags>
  </entry>
  <entry>
    <title>git 中文设置</title>
    <url>/2018/01/26/git-chinese/</url>
    <content><![CDATA[Git 中文git在显示的过程中，中文可能会乱码，解决方法如下
git status 乱码解决方法：git config --global core.quotepath false
git commit 乱码解决方法：git config --global i18n.commitencoding utf-8
git status 乱码解决方法：git config --global i18n.logoutputencoding utf-8

注意：如果是Linux系统，需要设置环境变量 export LESSCHARSET=utf-8

]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>commit</tag>
        <tag>config</tag>
        <tag>status</tag>
        <tag>coding</tag>
      </tags>
  </entry>
  <entry>
    <title>git 初始配置</title>
    <url>/2014/01/26/git-config/</url>
    <content><![CDATA[git的初始配置查看git版本在终端中输入git --version，比如我的输出为：

git version 2.7.0

设置用户名和邮箱地址下面的设置主要是告诉git是哪位大神在用git。
在使用git提交或者操作的时候，git需要知道你是谁，邮箱是什么，可以通过下面的命令进行配置：
$ git config --global user.name "Your Name"$ git config --global user.email "youremail@xyz.com"

设置文本编辑器如果你想使用不同的文本编辑器，例如 vim，可以这样做：
$ git config --global core.editor vim

提供命令输出的可读性默认情况下，git的操作可能都是黑白的，如果更改为彩色，就可以注意到很多特性，并且提高可读性，让你的世界不再只是黑白色。
$ git config --global color.ui auto


当然也可以在文件~/.gitconfig加上以上
[color]  ui = auto


Git 在Windows上的配置git add 提示warning: LF will be replaced by CRLF in 解决办法在使用git的时候，每次执行
$ git add filename

都会提示这样一个警告消息：
 这里主要是因为不同的操作系统之间对换行的定义不同，比如Windows为CRLF，Linux为LF，而MacOSX为CR。
 这就导致从不同系统checkout代码的时候，文件并未修改，反而出现了modified的情况，如下可以避免这种情况。
$ git config core.autocrlf false

这样设置git的配置后在执行add操作就没有问题了。
]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>global</tag>
        <tag>git</tag>
        <tag>config</tag>
        <tag>name</tag>
        <tag>email</tag>
      </tags>
  </entry>
  <entry>
    <title>git contribution policy</title>
    <url>/2018/01/26/git-contribution-policy/</url>
    <content><![CDATA[CODE contribution policyEverybody is encouraged to help improve the quality of the code.You can help by reporting issues or even better fix issues yourself.
If you have a patch for CODE we use the github pull request system.
Also to keep the CODE code quality high we have written down some guidelines for contributing, see below.
General considerationsIf you have problems or questions with/about git or github, first check [1].If you modify any code, make sure the test suite still runs (make test). If it fails, fix the code or the relevant test.If you change a function/method signature, update the doxygen documentation accordingly.If you add a function or method, add a test for it add it to the doxygen documentation.The tested code coverage line count should increase, not decrease.Follow the google style code as much as possible [2].
Contribution procedureCreate a github account, setup SSH keys.Fork the CODE repository on github [3].Create a branch and commit your changes to this branch.Push your branch to your github fork (not the original CODE, you probably don’t have permission).Issue a pull request [4].When the pull request is reviewed and there are no problems it will be accepted. Merging a pull request should always happen by someone else.It can happen there are some mistakes here and there, we use the github commenting system to discuss these issues.If there is a problem with the commit, you need to fix it. You can commit to the same branch, the PR will be updated automatically.
General notes about Pull requestsPlease create descriptive commits containing atomic changes. Use short commit messages (try 50 characters, max is 70 characters); longer commit messages are possible in the body of the commit message (separated from the subject by an empty line). See [5].If you fix an existing github issue, reference it in the commit message body, e.g. ‘Fixes #41’.If your Pull request does not refer to an existing github issue, it is not necessary to create one (because github will present the PR just like an issue).You can rewrite the history of the commits in your branch using rebase, but don’t rewrite the history before the first commit of your new branch.We like to keep the history clean, and prevent a lot of ‘fix typo’ messages.If you rewrite your history of your branch you can force push those changes to your branch. The PR will be updated. See e.g. [6].
Links[1] http://help.github.com[2] https://google-styleguide.googlecode.com/svn/trunk/cppguide.html[3] https://help.github.com/articles/fork-a-repo/[4] https://help.github.com/articles/creating-a-pull-request/[5] https://chris.beams.io/posts/git-commit[6] https://developer.atlassian.com/blog/2015/04/force-with-lease/
Referhttps://github.com/casacore/casacore/blob/master/CONTRIBUTING.md
]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>global</tag>
        <tag>git</tag>
        <tag>config</tag>
        <tag>name</tag>
        <tag>email</tag>
      </tags>
  </entry>
  <entry>
    <title>如何使用git来做贡献及提交PR</title>
    <url>/2016/01/26/git-contribute/</url>
    <content><![CDATA[Git Contributor / PR 建议步骤
首先Fork将要提交的工程，比如原地址为https://github.com/offical/repo.git

clone到本地，并创建一个upstream远程

git clone git@github.com:username/repo.git
git remote add upstream git@github.com:offical/repo.git


创建自己的特性分支

git checkout -b Name/AmazingFeature
修改并提交修改 (git commit -m 'Add some AmazingFeature')
将更新推送到远程分支 (git push origin Name/AmazingFeature)


登陆到github，提交一个Pull Request到官方repository

如果PR被接收了，此时可以更新master分支并删除创建的branch

更新master分支git pull upstream master
删除branch分支 git branch -D Name/AmazingFeature


恭喜成为代码贡献者


如果PR出现冲突，解决方式为：
将源版本库添加为一个远端，并命名为“upstream”（上游）
从远端抓取最新的内容
将该仓库的主分支的内容合并到你的分支中
修复产生的冲突
再推送回同一个分支

当然，在这个过程中最好不要rebase操作
]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>global</tag>
        <tag>git</tag>
        <tag>config</tag>
        <tag>name</tag>
        <tag>email</tag>
      </tags>
  </entry>
  <entry>
    <title>Git 生成一个构建号</title>
    <url>/2018/12/27/git-describe/</url>
    <content><![CDATA[生成一个构建号Git 中不存在随每次提交递增的“v123”之类的数字序列，如果你想要为提交附上一个可读的名称， 可以对其运行 git describe 命令。作为回应，Git 将会生成一个字符串， 它由最近的标签名、自该标签之后的提交数目和你所描述的提交的部分 SHA-1 值（前缀的 g 表示 Git）构成：
$ git describe masterv1.6.2-rc1-20-g8c5b85c

这样你在导出一个快照或构建时，可以给出一个便于人们理解的命名。 实际上，如果你的 Git 是从 Git 自己的版本库克隆下来并构建的，那么 git –version 命令给出的结果是与此类似的。 如果你所描述的提交自身就有一个标签，那么它将只会输出标签名，没有后面两项信息。
]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>describe</tag>
      </tags>
  </entry>
  <entry>
    <title>Git 的 fetch与pull</title>
    <url>/2014/12/21/git-fetch-and-pull/</url>
    <content><![CDATA[添加远端仓库有时一个仓库可能有多个分支或者多个维护者版本，此时我们可能希望跟踪多个版本。
如何解决呢，就需要添加远程仓库。
可以使用一个简单的名字，以便将来引用，运行 git remote add [shortname] [url]
然后使用$ git remote -v就可以看到远端分支与对应的网址了，此时就可以使用git fetch [shortname]或者git pull [shortname]来抓取更新了。
从远程仓库抓取数据正如之前所说的，可以用下面的命令从远程仓库抓取数据到本地：
$ git fetch [remote-name]$ git pull [remote-name]

那么这两个命令的区别在那里呢？
如果是克隆了一个仓库，此命令会自动将远程仓库归于 origin 名下。所以，git fetch origin 会抓取从你上次克隆以来别人上传到此远程仓库中的所有更新（或是上次 fetch 以来别人提交的更新）。有一点很重要，需要记住，fetch 命令只是将远端的数据拉到本地仓库，并不自动合并到当前工作分支，只有当你确实准备好了，才能手工合并。
如果设置了某个分支用于跟踪某个远端仓库的分支，可以使用 git pull 命令自动抓取数据下来，然后将远端分支自动合并到本地仓库中当前分支。在日常工作中我们经常这么用，既快且好。实际上，默认情况下 git clone 命令本质上就是自动创建了本地的 master 分支用于跟踪远程仓库中的 master 分支（假设远程仓库确实有 master 分支）。所以一般我们运行 git pull，目的都是要从原始克隆的远端仓库中抓取数据后，合并到工作目录中的当前分支。
]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>pull</tag>
        <tag>fetch</tag>
      </tags>
  </entry>
  <entry>
    <title>Git关于文件权限修改引起的冲突及忽略文件权限的办法</title>
    <url>/2014/12/27/git-file-mode/</url>
    <content><![CDATA[如果涉及到在多个系统里面操作，有可能会不经意间修改了文件的权限。
如果是使用git版本管理软件来管理的话，明明文件没有修改，也会因为文件权限而导致需要解决这些冲突，为什么呢，因为git把文件权限也算作文件差异的一部分。
如果权限的更改不纳入到版本可中，解决办法如下：
$ git config core.filemode false

这时候再更新代码就OK了。
处理权限Unix系统对拥有者、组、其他几种用户都有明确的读写执行权限，这些在windows上没有对应的机制，这个问题在使用git时表现为没有修改文件却出现很多modified的文件，git status显示 typechange。一般出现在增加可执行权限的文件上。git对此也有一定的策略，可以设置core.filemode为false,这样就会忽略文件权限带来的改变。
$ git config --add core.filemode false

这样设置后就可以避免下面的问题出现
diff --git a/a.py b/a.pyold mode 100755new mode 100644


如果clone前没有设置，导致已经进行了修改，可以用下面的命令来批量恢复这些修改。
$ git status | grep typechange | awk '{print $2}' | xargs git checkout

]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title>核弹级的git指令 git filter-branch</title>
    <url>/2018/02/01/git-filter-branch/</url>
    <content><![CDATA[Git核弹级指令核弹级这个概念应该是Pro Git的作者说的，这就说明了这个指令的强悍指出，除非特别清楚你准备干什么。
否则不要抱着尝试的想法来试试，除非你想尝试下核弹的威力。
其实用到这个指令主要是因为以前是自己做的局域网Git，文件的大小没有多少限制，比如几百兆的文件我也给放上去了。
但是碰到将这个repo公开到github上的时候，就碰到这个问题了。
remote : error: GH001: Large files detected.

当然处理方法还是有的，就是使用git的lfs，不过不太像折腾，索性使用核弹指令。
具体的命令如下，其中big_file为准备删除的文件，含义就是讲大文件从以前8次的提交中删除，注意是从提交中删除，所以意思就是以前所有的提交都是可以修改的，OMG，这是什么意思，让我静静。
$ git filter-branch --index-filter 'git rm --cached --ignore-unmatch big_file1' HEAD~8..HEAD$ git filter-branch -f --index-filter 'git rm --cached --ignore-unmatch big_file2' HEAD~8..HEAD





核武器级选项：filter-branch有另一个历史改写的选项，如果想要通过脚本的方式改写大量提交的话可以使用它——例如，全局修改你的邮箱地址或从每一个提交中移除一个文件。 这个命令是 filter-branch，它可以改写历史中大量的提交，除非你的项目还没有公开并且其他人没有基于要改写的工作的提交做的工作，否则你不应当使用它。 然而，它可以很有用。 你将会学习到几个常用的用途，这样就得到了它适合使用地方的想法。



Caution
git filter-branch 有很多陷阱，不再推荐使用它来重写历史。 请考虑使用 git-filter-repo，它是一个 Python 脚本，相比大多数使用 filter-branch 的应用来说，它做得要更好。它的文档和源码可访问 https://github.com/newren/git-filter-repo 获取。







从每一个提交中移除一个文件这经常发生。 有人粗心地通过 git add . 提交了一个巨大的二进制文件，你想要从所有地方删除。 可能偶然地提交了一个包括一个密码的文件，然而你想要开源项目。 filter-branch 是一个可能会用来擦洗整个提交历史的工具。 为了从整个提交历史中移除一个叫做 passwords.txt 的文件，可以使用 --tree-filter 选项给 filter-branch：
$ git filter-branch --tree-filter 'rm -f passwords.txt' HEADRewrite 6b9b3cf04e7c5686a9cb838c3f36a8cb6a0fc2bd (21/21)Ref 'refs/heads/master' was rewritten

--tree-filter 选项在检出项目的每一个提交后运行指定的命令然后重新提交结果。 在本例中，你从每一个快照中移除了一个叫作 passwords.txt 的文件，无论它是否存在。 如果想要移除所有偶然提交的编辑器备份文件，可以运行类似 git filter-branch --tree-filter 'rm -f *~' HEAD 的命令。
最后将可以看到 Git 重写树与提交然后移动分支指针。 通常一个好的想法是在一个测试分支中做这件事，然后当你决定最终结果是真正想要的，可以硬重置 master 分支。 为了让 filter-branch 在所有分支上运行，可以给命令传递 --all 选项。
使一个子目录做为新的根目录假设已经从另一个源代码控制系统中导入，并且有几个没意义的子目录（trunk、tags 等等）。 如果想要让 trunk 子目录作为每一个提交的新的项目根目录，filter-branch 也可以帮助你那么做：
$ git filter-branch --subdirectory-filter trunk HEADRewrite 856f0bf61e41a27326cdae8f09fe708d679f596f (12/12)Ref 'refs/heads/master' was rewritten

现在新项目根目录是 trunk 子目录了。 Git 会自动移除所有不影响子目录的提交。
全局修改邮箱地址另一个常见的情形是在你开始工作时忘记运行 git config 来设置你的名字与邮箱地址， 或者你想要开源一个项目并且修改所有你的工作邮箱地址为你的个人邮箱地址。 任何情形下，你也可以通过 filter-branch 来一次性修改多个提交中的邮箱地址。 需要小心的是只修改你自己的邮箱地址，所以你使用 --commit-filter：
$ git filter-branch --commit-filter '        if [ "$GIT_AUTHOR_EMAIL" = "schacon@localhost" ];        then                GIT_AUTHOR_NAME="Scott Chacon";                GIT_AUTHOR_EMAIL="schacon@example.com";                git commit-tree "$@";        else                git commit-tree "$@";        fi' HEAD

这会遍历并重写每一个提交来包含你的新邮箱地址。 因为提交包含了它们父提交的 SHA-1 校验和，这个命令会修改你的历史中的每一个提交的 SHA-1 校验和， 而不仅仅只是那些匹配邮箱地址的提交。
]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>filter-branch</tag>
        <tag>index-filter</tag>
        <tag>ignore-unmatch</tag>
      </tags>
  </entry>
  <entry>
    <title>Git gitlab服务器迁移</title>
    <url>/2018/03/14/git-gitlab/</url>
    <content><![CDATA[gitlab服务器迁移新换了服务器，需要将原来服务器商的gitlab项目迁移到新的服务器上.
1.迁移准备工作和思路:从a服务器迁移到b服务器,由于Gitlab自身的兼容性问题，高版本的Gitlab无法恢复低版本备份的数据,需要注意在b服务器部署和a服务器一样版本的gitlab,部署好环境后开始备份和数据迁移.
查看gitlab版本的命令:
gitlab-rake gitlab:env:info


备份原a服务器上的的数据

gitlab-rake gitlab:backup:create RAILS_ENV=production

PS: 备份后的文件一般是位于/var/opt/gitlab/backups下, 自动生成文件名文件名如1481529483_gitlab_backup.tar

将步骤2生成的tar文件拷贝到b服务器上相应的backups目录下可以利用scp进行直接拷贝.

scp username@src_ip:/var/opt/gitlab/backups/xxxxxxxxxx_yyyy_mm_dd_gitlab_backup.tar /var/opt/gitlab/backups

PS: username为原服务器的用户名，src_ip原服务器IP地址

在b服务器恢复数据

gitlab-rake gitlab:backup:restore RAILS_ENV=production BACKUP=xxxxxxxxxx_yyyy_mm_dd_

PS：BACKUP的时间点必须与原服务器备份后的文件名一致
gitlab启动$ gitlab-ctl reconfigure$ gitlab-ctl restart



gitlab 仓库的存储地址$ ls /var/opt/gitlab/git-data/repositories





gitlab 手动备份$ gitlab-backup create

]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>gitlab</tag>
        <tag>gitlab-rake</tag>
        <tag>backup</tag>
        <tag>create</tag>
        <tag>restore</tag>
      </tags>
  </entry>
  <entry>
    <title>Git 好习惯</title>
    <url>/2012/02/07/git-good-habit/</url>
    <content><![CDATA[git好习惯正确的版本控制系统的使用方法是，一次提交只干一件事情：或是完成了一个新功能，或是修改了一个bug，或是写完了一节的内容，或是添加了一副图片，就执行一次提交，千万不要下班了才想起来要提交，那样的话版本控制系统就被降格为文件备份系统了。
Git的命令行加入了大量的人性化设计，包括命令补全、彩色字符输出等。
Git的智能更体现在它的人性化设计上，它能够实时地显示完成的进度，因为Git的智能协议源于会话过程中在客户端和服务器端各自启用了一个会话的角色，用于按需传输和获取进度。
]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>commit</tag>
      </tags>
  </entry>
  <entry>
    <title>git中使用GPP来提交到github</title>
    <url>/2020/03/07/git-gpg/</url>
    <content><![CDATA[git中使用GPP来提交到githubIf  you do not have an GPG key, you can generate a new key by using gpg to use in git commit and tags to identify that it’s absolute you did it.
生成一个新的GPG key以MacOSX系统为例.
# first install gpg on MacOSX$ brew install gpg# then gpg-suite to save passwd in MacOSX chains$ brew cask install gpg-suite

生成key
$ gpg --full-generate-key

列出GPG key
$ gpg --list-secret-keys --keyid-format LONG/Users/&lt;userid&gt;/.gnupg/pubring.gpg----------------------------------sec   rsa4096/ABCDABCDABCDABCD 2015-11-17 [SC] [expires: 2020-11-15]      SASASASASASASASAASASASASASASASASASASASASuid                 [ultimate] Username (userid) &lt;email@address.com&gt;ssb   rsa4096/ABCDABCDABCDABCD 2015-11-17 [E] [expires: 2020-11-15]

or
# or for SHORT format$ gpg --list-secret-keys --keyid-format SHORT/Users/&lt;userid&gt;/.gnupg/pubring.gpg----------------------------------sec   rsa4096/ABCDABCD 2015-11-17 [SC] [expires: 2020-11-15]      SASASASASASASASAASASASASASASASASASASASASuid                 [ultimate] Username (userid) &lt;email@address.com&gt;ssb   rsa4096/ABCDABCD 2015-11-17 [E] [expires: 2020-11-15]

The different between LONG and SHORT is the .
将GPG keys添加到GithubIf you want show a Verified label in Github, now you should add a GPG key in github setting.
Using the following command to get a ASCII-armored format of GPG then paste it in Github,following Settings -&gt; SSH and GPG keys -&gt; New GPGP key
$ gpg --armor --export &lt;key ID&gt;-----BEGIN PGP PUBLIC KEY BLOCK-----&lt;ASCII armored PGP Public Key Block (exported to a *.asc file)&gt;-----END PGP PUBLIC KEY BLOCK-----


the  is ABCDABCD when using LONG or SHORT.

在git终端中配置GPG sign签名默认情况下是禁用的，可以通过以下设置来使能这个功能。
$ gpg --list-secret-keys --keyid-format SHORT#if no key found then generate new one# replace the ABCDABCD using your own key ID$ git config --global user.signingkey ABCDABCD$ git config --global commit.gpgsign true


Some post said that you should do export GPG_TTY=$(tty),I am not encounter this problems fortunately.

使用SourceTree来提交签名在SourceTree中的 “Enable GPG key signing for commit” 一直是灰色的，并且终端中支持提交前，而SourceTree无法push成功，此时主要是以为gpg程序没有设置，执行下面的命令，然后重启SourceTree即可解决。
$ which gpg/usr/bin/gpg$ git config --global gpg.program /usr/bin/gpg

其中的gpg路径不同的操作系统可能不同，需要根据具体情况来设置。
error: gpg 数据签名失败在提交的时候，出现
error: gpg 数据签名失败fatal: 写提交对象失败

解决方法，在zshrc中加上一句export GPG_TTY=$(tty)，然后重启gpg-agent就可以了
重启命令为
$ gpgconf --kill gpg-agent]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>commit</tag>
      </tags>
  </entry>
  <entry>
    <title>Git log查看提交历史</title>
    <url>/2016/12/27/git-log/</url>
    <content><![CDATA[Git log 查看提交历史在提交了若干更新，又或者克隆了某个项目之后，你也许想回顾下提交历史。 完成这个任务最简单而又有效的工具是 git log 命令。
当你在此项目中运行 git log 命令时，可以看到下面的输出：
$ git logcommit ca82a6dff817ec66f44342007202690a93763949Author: Scott Chacon &lt;schacon@gee-mail.com&gt;Date:   Mon Mar 17 21:52:11 2008 -0700    changed the version number

不传入任何参数的默认情况下，git log 会按时间先后顺序列出所有的提交，最近的更新排在最上面。 正如你所看到的，这个命令会列出每个提交的 SHA-1 校验和、作者的名字和电子邮件地址、提交时间以及提交说明。
git log 有许多选项可以帮助你搜寻你所要找的提交， 下面我们会介绍几个最常用的选项。
显示差异其中一个比较有用的选项是 -p 或 --patch ，它会显示每次提交所引入的差异（按 补丁 的格式输出）。 你也可以限制显示的日志条目数量，例如使用 -2 选项来只显示最近的两次提交：
$ git log -p -2commit ca82a6dff817ec66f44342007202690a93763949Author: Scott Chacon &lt;schacon@gee-mail.com&gt;Date:   Mon Mar 17 21:52:11 2008 -0700    changed the version numberdiff --git a/Rakefile b/Rakefileindex a874b73..8f94139 100644--- a/Rakefile+++ b/Rakefile@@ -5,7 +5,7 @@ require 'rake/gempackagetask' spec = Gem::Specification.new do |s|     s.platform  =   Gem::Platform::RUBY     s.name      =   "simplegit"-    s.version   =   "0.1.0"+    s.version   =   "0.1.1"     s.author    =   "Scott Chacon"     s.email     =   "schacon@gee-mail.com"     s.summary   =   "A simple gem for using Git in Ruby code."commit 085bb3bcb608e1e8451d4b2432f8ecbe6306e7e7Author: Scott Chacon &lt;schacon@gee-mail.com&gt;Date:   Sat Mar 15 16:40:33 2008 -0700    removed unnecessary testdiff --git a/lib/simplegit.rb b/lib/simplegit.rbindex a0a60ae..47c6340 100644--- a/lib/simplegit.rb+++ b/lib/simplegit.rb@@ -18,8 +18,3 @@ class SimpleGit     end end--if $0 == __FILE__-  git = SimpleGit.new-  puts git.show-end

该选项除了显示基本信息之外，还附带了每次提交的变化。 当进行代码审查，或者快速浏览某个搭档的提交所带来的变化的时候，这个参数就非常有用了。 你也可以为 git log 附带一系列的总结性选项。
统计信息 比如你想看到每次提交的简略统计信息，可以使用 --stat 选项：
$ git log --statcommit ca82a6dff817ec66f44342007202690a93763949Author: Scott Chacon &lt;schacon@gee-mail.com&gt;Date:   Mon Mar 17 21:52:11 2008 -0700    changed the version number Rakefile | 2 +- 1 file changed, 1 insertion(+), 1 deletion(-)commit 085bb3bcb608e1e8451d4b2432f8ecbe6306e7e7Author: Scott Chacon &lt;schacon@gee-mail.com&gt;Date:   Sat Mar 15 16:40:33 2008 -0700    removed unnecessary test lib/simplegit.rb | 5 ----- 1 file changed, 5 deletions(-)commit a11bef06a3f659402fe7563abf99ad00de2209e6Author: Scott Chacon &lt;schacon@gee-mail.com&gt;Date:   Sat Mar 15 10:31:28 2008 -0700    first commit README           |  6 ++++++ Rakefile         | 23 +++++++++++++++++++++++ lib/simplegit.rb | 25 +++++++++++++++++++++++++ 3 files changed, 54 insertions(+)

正如你所看到的，--stat 选项在每次提交的下面列出所有被修改过的文件、有多少文件被修改了以及被修改过的文件的哪些行被移除或是添加了。 在每次提交的最后还有一个总结。
展示方式另一个非常有用的选项是 --pretty。 这个选项可以使用不同于默认格式的方式展示提交历史。 这个选项有一些内建的子选项供你使用。 比如 oneline 会将每个提交放在一行显示，在浏览大量的提交时非常有用。 另外还有 short，full 和 fuller 选项，它们展示信息的格式基本一致，但是详尽程度不一：
$ git log --pretty=onelineca82a6dff817ec66f44342007202690a93763949 changed the version number085bb3bcb608e1e8451d4b2432f8ecbe6306e7e7 removed unnecessary testa11bef06a3f659402fe7563abf99ad00de2209e6 first commit

最有意思的是 format ，可以定制记录的显示格式。 这样的输出对后期提取分析格外有用——因为你知道输出的格式不会随着 Git 的更新而发生改变：
$ git log --pretty=format:"%h - %an, %ar : %s"ca82a6d - Scott Chacon, 6 years ago : changed the version number085bb3b - Scott Chacon, 6 years ago : removed unnecessary testa11bef0 - Scott Chacon, 6 years ago : first commit

git log --pretty=format 常用的选项 列出了 format 接受的常用格式占位符的写法及其代表的意义。



选项
说明



%H
提交的完整哈希值


%h
提交的简写哈希值


%T
树的完整哈希值


%t
树的简写哈希值


%P
父提交的完整哈希值


%p
父提交的简写哈希值


%an
作者名字


%ae
作者的电子邮件地址


%ad
作者修订日期（可以用 –date=选项 来定制格式）


%ar
作者修订日期，按多久以前的方式显示


%cn
提交者的名字


%ce
提交者的电子邮件地址


%cd
提交日期


%cr
提交日期（距今多长时间）


%s
提交说明


你一定奇怪 作者 和 提交者 之间究竟有何差别， 其实作者指的是实际作出修改的人，提交者指的是最后将此工作成果提交到仓库的人。 所以，当你为某个项目发布补丁，然后某个核心成员将你的补丁并入项目时，你就是作者，而那个核心成员就是提交者。 我们会在 分布式 Git 再详细介绍两者之间的细微差别。
当 oneline 或 format 与另一个 log 选项 --graph 结合使用时尤其有用。 这个选项添加了一些 ASCII 字符串来形象地展示你的分支、合并历史：
$ git log --pretty=format:"%h %s" --graph* 2d3acf9 ignore errors from SIGCHLD on trap*  5e3ee11 Merge branch 'master' of git://github.com/dustin/grit|\| * 420eac9 Added a method for getting the current branch.* | 30e367c timeout code and tests* | 5a09431 add timeout protection to grit* | e1193f8 support for heads with slashes in them|/* d6016bc require time for xmlschema*  11d191e Merge branch 'defunkt' into local

这种输出类型会在我们下一章学完分支与合并以后变得更加有趣。
format选项以上只是简单介绍了一些 git log 命令支持的选项。 git log 的常用选项 列出了我们目前涉及到的和没涉及到的选项，以及它们是如何影响 log 命令的输出的：



选项
说明



-p
按补丁格式显示每个提交引入的差异。


--stat
显示每次提交的文件修改统计信息。


--shortstat
只显示 –stat 中最后的行数修改添加移除统计。


--name-only
仅在提交信息后显示已修改的文件清单。


--name-status
显示新增、修改、删除的文件清单。


--abbrev-commit
仅显示 SHA-1 校验和所有 40 个字符中的前几个字符。


--relative-date
使用较短的相对时间而不是完整格式显示日期（比如“2 weeks ago”）。


--graph
在日志旁以 ASCII 图形显示分支与合并历史。


--pretty
使用其他格式显示历史提交信息。可用的选项包括 oneline、short、full、fuller 和 format（用来定义自己的格式）。


--oneline
--pretty=oneline --abbrev-commit 合用的简写。


限制输出长度除了定制输出格式的选项之外，git log 还有许多非常实用的限制输出长度的选项，也就是只输出一部分的提交。 之前你已经看到过 -2 选项了，它只会显示最近的两条提交， 实际上，你可以使用类似 -&lt;n&gt; 的选项，其中的 n 可以是任何整数，表示仅显示最近的 n 条提交。 不过实践中这个选项不是很常用，因为 Git 默认会将所有的输出传送到分页程序中，所以你一次只会看到一页的内容。
但是，类似 --since 和 --until 这种按照时间作限制的选项很有用。 例如，下面的命令会列出最近两周的所有提交：
$ git log --since=2.weeks

该命令可用的格式十分丰富——可以是类似 "2008-01-15" 的具体的某一天，也可以是类似 "2 years 1 day 3 minutes ago" 的相对日期。
还可以过滤出匹配指定条件的提交。 用 --author 选项显示指定作者的提交，用 --grep 选项搜索提交说明中的关键字。



Note
你可以指定多个 --author 和 --grep 搜索条件，这样会只输出匹配 任意 --author 模式和 任意 --grep 模式的提交。然而，如果你添加了 --all-match 选项， 则只会输出匹配 所有 --grep 模式的提交。







另一个非常有用的过滤器是 -S（俗称“pickaxe”选项，取“用鹤嘴锄在土里捡石头”之意）， 它接受一个字符串参数，并且只会显示那些添加或删除了该字符串的提交。 假设你想找出添加或删除了对某一个特定函数的引用的提交，可以调用：
$ git log -S function_name

最后一个很实用的 git log 选项是路径（path）， 如果只关心某些文件或者目录的历史提交，可以在 git log 选项的最后指定它们的路径。 因为是放在最后位置上的选项，所以用两个短划线（–）隔开之前的选项和后面限定的路径名。
在 限制 git log 输出的选项 中列出了常用的选项



选项
说明



-&lt;n&gt;
仅显示最近的 n 条提交。


--since, --after
仅显示指定时间之后的提交。


--until, --before
仅显示指定时间之前的提交。


--author
仅显示作者匹配指定字符串的提交。


--committer
仅显示提交者匹配指定字符串的提交。


--grep
仅显示提交说明中包含指定字符串的提交。


-S
仅显示添加或删除内容匹配指定字符串的提交。


来看一个实际的例子，如果要在 Git 源码库中查看 Junio Hamano 在 2008 年 10 月其间， 除了合并提交之外的哪一个提交修改了测试文件，可以使用下面的命令：
$ git log --pretty="%h - %s" --author='Junio C Hamano' --since="2008-10-01" \   --before="2008-11-01" --no-merges -- t/5610e3b - Fix testcase failure when extended attributes are in useacd3b9e - Enhance hold_lock_file_for_{update,append}() APIf563754 - demonstrate breakage of detached checkout with symbolic link HEADd1a43f2 - reset --hard/read-tree --reset -u: remove unmerged new paths51a94af - Fix "checkout --track -b newbranch" on detached HEADb0ad11e - pull: allow "git pull origin $something:$current_branch" into an unborn branch

在近 40000 条提交中，上面的输出仅列出了符合条件的 6 条记录。

隐藏合并提交按照你代码仓库的工作流程，记录中可能有为数不少的合并提交，它们所包含的信息通常并不多。 为了避免显示的合并提交弄乱历史记录，可以为 log 加上 --no-merges 选项。

查看当前分支指向的对象可以简单地使用 git log 命令查看各个分支当前所指的对象。 提供这一功能的参数是 –decorate。
$ git log --oneline --decoratef30ab (HEAD -&gt; master, testing) add feature #32 - ability to add new formats to the central interface34ac2 Fixed bug #1328 - stack overflow under certain conditions98ca9 The initial commit of my project

正如你所见，当前 master 和 testing 分支均指向校验和以 f30ab 开头的提交对象。
项目分叉历史项目分叉历史你可以简单地使用 git log 命令查看分叉历史。 运行 git log –oneline –decorate –graph –all ，它会输出你的提交历史、各个分支的指向以及项目的分支分叉情况。
$ git log --oneline --decorate --graph --all* c2b9e (HEAD, master) made other changes| * 87ab2 (testing) made a change|/* f30ab add feature #32 - ability to add new formats to the* 34ac2 fixed bug #1328 - stack overflow under certain conditions* 98ca9 initial commit of my project

由于 Git 的分支实质上仅是包含所指对象校验和（长度为 40 的 SHA-1 值字符串）的文件，所以它的创建和销毁都异常高效。 创建一个新分支就相当于往一个文件中写入 41 个字节（40 个字符和 1 个换行符），如此的简单能不快吗？
制作提交简报现在是时候通知邮件列表里那些好奇你的项目发生了什么的人了。 使用 git shortlog 命令可以快速生成一份包含从上次发布之后项目新增内容的修改日志（changelog）类文档。 它会对你给定范围内的所有提交进行总结；比如，你的上一次发布名称是 v1.0.1，那么下面的命令可以给出上次发布以来所有提交的总结：
$ git shortlog --no-merges master --not v1.0.1



包含修改历史This repo has a lot of files which have been renamed over the years. To see the full history of a file through all of the renames, add --follow to the git log command:
$ git log -p --follow README.md

The above log also illustrates a cosmetic problem we have with file history thanks to the svn-to-git conversion in 2020: some svn branch creation events have caused a large number of spurious file deletions in individual file histories
]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>log</tag>
      </tags>
  </entry>
  <entry>
    <title>服务器上的Git</title>
    <url>/2013/12/27/git-on-server/</url>
    <content><![CDATA[]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title>git Markdown 格式</title>
    <url>/2014/03/14/git-markdown/</url>
    <content><![CDATA[Markdown 格式集锦$Markdown$ 由亚伦·斯沃茨此处有掌声（Aaron Hillel Swartz；1986年11月8日－2013年1月11日）和美国著名博客作者约翰·格鲁伯（John Gruber）合作发明了。
$Markdown$格式主要在程序员间流行，自从自己入了git的坑，就喜欢上了简洁明了的语法，除非特殊需要，已经不在接触Office系列了。^_^
这里主要列举一些$Markdown$的语法，其实只要掌握几个就能用的相当遛了。
内容目录测试只需要加入[TOC]就可以看到内容目录了。
标题标题共有6级，从最大的第1级到第6级，是几级就加几个#即可。
# 标题1## 标题2### 标题3#### 标题4##### 标题5###### 标题6

输出为：
标题1标题2标题3标题4标题5标题6引用引用以&gt;开始，例如
&gt;&gt; 这是引用。&gt;&gt; 你想说点啥？

输出为：


这是引用。

你想说点啥？

列表Markdown 支持有序列表和无序列表。
无序列表使用星号、加号或是减号作为列表标记：$Markdown$ 如下所示：
*   Red*   Green*   Blue

等同于：
+   Red+   Green+   Blue

也等同于：
-   Red-   Green-   Blue

输出均为：

Red 
Green 
Blue

有序列表则使用数字接着一个英文句点：
1.  Bird2.  McHale3.  Parish

其实1，2，3也可以写成1，3，4，但是并不影响输出信息：

Bird 
McHale 
Parish

强调$Markdown$ 使用星号（*）和底线（_）作为标记强调字词的符号，被&nbsp;*&nbsp;或&nbsp;_&nbsp;包围的字词会被转成用斜体&nbsp;，用两个&nbsp;*&nbsp;或&nbsp;_&nbsp;包起来的话，则会被转成&nbsp;__粗体__，例如：
Markdown:
Some of these words *are emphasized*.Some of these words _are emphasized also_.Use two asterisks for **strong emphasis**.Or, if you prefer, __use two underscores instead__.~~要划除的行内内容~~&lt;u&gt;下划线&lt;/u&gt;上划线$\overline{X}$下划线$\underline{X}$

输出:
Some of these words are emphasized. 
Some of these words are emphasized also. 
Use two asterisks for strong emphasis. 
Or, if you prefer, use two underscores instead.
下划线
所添加的需要加下划线的行内文字
$\underline{下划线}$
要划除的行内内容
上划线$\overline{X}$下划线$\underline{X}$
表格$Markdown$插入表格的语法相对复杂，必须要按格式来敲，注意表头与内容的分割线横线-不能少于3个，$Markdown$如下所示：
第一格表头 | 第二格表头--- | ---内容单元格 第一列第一格 | 内容单元格第二列第一格内容单元格 第一列第二格 多加文字 | 内容单元格第二列第二格

输出如下：



第一格表头
第二格表头



内容单元格 第一列第一格
内容单元格第二列第一格


内容单元格 第一列第二格 多加文字
内容单元格第二列第二格


链接链接特别简单，只要使用尖括号扩起来网址即可。
例如$Markdown$：
这是谷歌的地址&lt;https://www.google.com&gt;。[example link](http://example.com/).

输出为:
这是谷歌的地址https://www.google.com
也可以建立一个标签，此时需要使用的格式例如Markdown为：
这是谷歌的地址[Google](https://www.google.com)

输出为:
这是谷歌的地址Google
图片图片的格式就是在链接的基础上加上一个**!**即可，注意alt text是在图片无法显示或找到是显示的，而Title是在鼠标悬停到图片上显示的内容。
![alt text](/path/to/img.jpg "Title")

比如Markdown为：
![Markdown](https://timgsa.baidu.com/timg?image&amp;quality=80&amp;size=b9999_10000&amp;sec=1528972647389&amp;di=2e41e45c2b6eb093a1035af76894fe70&amp;imgtype=0&amp;src=http%3A%2F%2Fimg.mp.itc.cn%2Fupload%2F20170531%2F2857e3a50356480c976833fd36d87051_th.jpg ”TEST“)




---fignos-cleveref: Truefignos-plus-name: 图fignos-caption-name: 图



为了处理图形的交叉引用，我们需要添加一个 Pandoc 插件。
在终端（macOS、Linux）或者命令行（Windows）下，执行：
pip install pandoc-fignos



插入页首页尾的图片header-includes:    \usepackage{graphicx}   \usepackage{fancyhdr}   \pagestyle{fancy}   \setlength\headheight{28pt}   \fancyhead[L]{\includegraphics[width=5cm]{images.jpeg}}   \fancyfoot[LE,RO]{GPIM}

插入首页一幅图片header-includes:- \titlegraphic{\centering \includegraphics[width=10cm]{images/Ska_landscape_night_v2.jpeg}}



LaTeX公式$ 表示行内公式：质能守恒方程可以用一个很简洁的方程式 $E=mc^2$ 来表达。

view 质能守恒方程可以用一个很简洁的方程式 $E=mc^2$ 来表达。
$$ 表示整行公式：$$\sum_{i=1}^n a_i=0$$$$f(x_1,x_x,\ldots,x_n) = x_1^2 + x_2^2 + \cdots + x_n^2 $$$$\sum^{j-1}_{k=0}{\widehat{\gamma}_{kj} z_k}$$

希腊字母\alpha, \beta,... \omega: \Gamma, \Delta, …, \Omega:

$\alpha .. \beta,.. \omega .. \Gamma .. \Delta ..  \Omega:$
上下标^ 和 _

$𝑥_𝑖^2$, $log_2𝑥$
访问 MathJax 参考更多使用方法。
代码其实$Markdown$最赞的就是代码功能了，各种个样的代码，并且可以上色，格式就是使用三个反斜点来扩起来，比如C预言为例：
```c#include &lt;stdio.h&gt;int main(){    return 0;}​```

输出为：
#include &lt;stdio.h&gt; int main() {     return 0; } 


目前支持市面上的大部分语言，比如c/c++/python/php/java等等。

方框显示$${\boxed{BOXED\ BOLD}}$$
参考样式参考样式类似文章中的引用文献，可以做一个标记，全部列在文末，如下所示：
这篇文章引用了来自 [Google][1] 、[Yahoo][2] 和 [MSN][3]的搜索结果。[1]: http://google.com/        "Google"[2]: http://search.yahoo.com/  "Yahoo Search"[3]: http://search.msn.com/    "MSN Search"

输出如下：
这篇文章引用了来自 Google 、Yahoo 和 MSN的搜索结果。
脚注在需要添加注脚的文字后加上脚注名字[^注脚名字],称为加注。 然后在文本的任意位置(一般在最后)添加脚注，脚注前必须有对应的脚注名字。
注意：经测试脚注与脚注之间必须空一行，不然会失效。成功后会发现，即使你没有把脚注写在文末，经Markdown转换后，也会自动归类到文章的最后。
使用 Markdown[^1]可以效率的书写文档, 直接转换成 HTML[^2], 你可以使用 Leanote[^Le] 编辑器进行书写。[^1]:Markdown是一种纯文本标记语言[^2]:HyperText Markup Language 超文本标记语言[^Le]:开源笔记平台，支持Markdown和笔记直接发为博文



使用 Markdown^1可以效率的书写文档, 直接转换成 HTML^2, 你可以使用 Typora^3 编辑器进行书写。
注：脚注自动被搬运到最后面，请到文章末尾查看，并且脚注后方的链接可以直接跳转回到加注的地方。
锚点 - 编辑器暂时木有效果网页中，锚点其实就是页内超链接，也就是链接本文档内部的某些元素，实现当前页面中的跳转。
NB：

Markdown Extra 只支持在标题后插入锚点，其它地方无效。
Leanote 编辑器右侧显示效果区域暂时不支持锚点跳转，所以点来点去发现没有跳转不必惊慌，但是你发布成笔记或博文后是支持跳转的。

跳转到[引用](#ref)

跳转到引用
嵌套HTML其实$Markdown$的语法都可以使用HTML来实现并增强大部分的功能，比如可以使用&lt;font&gt;来对字体进行设置。
颜色$\color{red} {text}$

$\color{red} {red text}$
Coffee break
这样就可以显示不同的颜色了。
浅红色文字：&lt;font color="#dd0000"&gt;浅红色文字：&lt;/font&gt;&lt;br /&gt; 深红色文字：&lt;font color="#660000"&gt;深红色文字&lt;/font&gt;&lt;br /&gt; 浅绿色文字：&lt;font color="#00dd00"&gt;浅绿色文字&lt;/font&gt;&lt;br /&gt; 深绿色文字：&lt;font color="#006600"&gt;深绿色文字&lt;/font&gt;&lt;br /&gt; 浅蓝色文字：&lt;font color="#0000dd"&gt;浅蓝色文字&lt;/font&gt;&lt;br /&gt; 深蓝色文字：&lt;font color="#000066"&gt;深蓝色文字&lt;/font&gt;&lt;br /&gt; 浅黄色文字：&lt;font color="#dddd00"&gt;浅黄色文字&lt;/font&gt;&lt;br /&gt; 深黄色文字：&lt;font color="#666600"&gt;深黄色文字&lt;/font&gt;&lt;br /&gt; 浅青色文字：&lt;font color="#00dddd"&gt;浅青色文字&lt;/font&gt;&lt;br /&gt; 深青色文字：&lt;font color="#006666"&gt;深青色文字&lt;/font&gt;&lt;br /&gt; 浅紫色文字：&lt;font color="#dd00dd"&gt;浅紫色文字&lt;/font&gt;&lt;br /&gt; 深紫色文字：&lt;font color="#660066"&gt;深紫色文字&lt;/font&gt;&lt;br /&gt; 



浅红色文字：浅红色文字：深红色文字：深红色文字浅绿色文字：浅绿色文字深绿色文字：深绿色文字浅蓝色文字：浅蓝色文字深蓝色文字：深蓝色文字浅黄色文字：浅黄色文字深黄色文字：深黄色文字浅青色文字：浅青色文字深青色文字：深青色文字浅紫色文字：浅紫色文字深紫色文字：深紫色文字 
大小size为1：size为1size为2：size为2size为3：size为3size为4：size为4size为10：size为10 
size为1：&lt;font size="1"&gt;size为1&lt;/font&gt;&lt;br /&gt; size为2：&lt;font size="2"&gt;size为2&lt;/font&gt;&lt;br /&gt; size为3：&lt;font size="3"&gt;size为3&lt;/font&gt;&lt;br /&gt; size为4：&lt;font size="4"&gt;size为4&lt;/font&gt;&lt;br /&gt; size为10：&lt;font size="10"&gt;size为10&lt;/font&gt;&lt;br /&gt; 



字体&lt;font face="黑体"&gt;我是黑体字&lt;/font&gt;&lt;font face="宋体"&gt;我是宋体字&lt;/font&gt;&lt;font face="微软雅黑"&gt;我是微软雅黑字&lt;/font&gt;&lt;font face="fantasy"&gt;我是fantasy字&lt;/font&gt;&lt;font face="Helvetica"&gt;我是Helvetica字&lt;/font&gt;

我是黑体字我是宋体字我是微软雅黑字我是fantasy字我是Helvetica字
红色字体的微软雅黑
这是黑体字这是微软雅黑这是华文彩云红色字体的微软雅黑蓝色字体的华文彩云我是尺寸我是黑体，绿色，尺寸为5
TODO黄色高亮利用  标签实现
语法 黄色高亮
页面展示效果如下：
我不知道怎么设置别的颜色的高亮，因为 html 的 style 属性和标签这里都不支持有知道的求告知。
为文字添加背景色由于 style 标签和标签的 style 属性不被支持，所以这里只能是借助 table, tr, td 等表格标签的 bgcolor 属性来实现背景色。故这里对于文字背景色的设置，只是将那一整行看作一个表格，更改了那个格子的背景色（bgcolor）。
语法如下：
背景色蓝色

1页面展示效果如下：
背景色蓝色表格添加背景色表格里的某个格子如何设置背景色呢？
参考下面的例子：

    
        方法说明颜色名称颜色
    
    
        此处实现方法利用 CSDN-markdown 内嵌 html 语言的优势Hotpinkrgb(240, 248, 255)
    
    
        借助 table, tr, td 等表格标签的 bgcolor 属性实现背景色设置AntiqueWhitergb(255, 192, 203)
    


页面展示效果如下：
方法说明	颜色名称	颜色此处实现方法利用 CSDN-markdown 内嵌 html 语言的优势	Hotpink	rgb(240, 248, 255)借助 table, tr, td 等表格标签的 bgcolor 属性实现背景色设置	AntiqueWhite	rgb(255, 192, 203)跨行表格示例如下：

    
        我占了三行
        第一列
        第二列
        第三列
    
    
        第一列
        第二列
        第三列
    
    
        第一列
        第二列
        第三列
    
  






分栏begin{columns}column{0.5textwidth}heicolumn{0.5textwidth}Ohend{columns}

begin{columns}column{0.5textwidth}heicolumn{0.5textwidth}Ohend{columns}


&lt;table style="margin-left: auto; margin-right: auto;"&gt;
    &lt;tr&gt;
        &lt;td&gt;
            &lt;!--左侧内容--&gt;
            左侧
        &lt;/td&gt;
        &lt;td&gt;
            &lt;!--右侧内容--&gt;
            右侧
        &lt;/td&gt;
    &lt;/tr&gt;
&lt;/table&gt;





Works::: columns
:::: columnCOLUMN 1:::: 
:::: columnCOLUMN 2::::
:::: 
Sphinx嵌入Markdown
甘特图gantt                dateFormat  YYYY-MM-DD          title 甘特图       section 任务清单       已完成的任务           :done,    des1, 2014-01-06,2014-01-08       正在进行的任务               :active,  des2, 2014-01-09, 3d       待完成任务1               :         des3, after des2, 5d       待完成任务2              :         des4, after des3, 5d       section 核心研发       已完成的关键任务 		:crit, done, 2014-01-06,24h       已完成的关键任务2     	:crit, done, after des1, 2d       正在进行的关键任务    	:crit, active, 3d       待完成的关键任务      	:crit, 5d       待完成任务      		  :2d       待完成任务2          	  :1d       section 文档编写       描述甘特图语法               :active, a1, after des1, 3d       完成甘特图实例1      :after a1  , 20h       完成甘特图实例2    :doc1, after a1  , 48h





MarkdownSphinx可以使用 [recommonmark 来支持Markdown的格式文档。
参考：https://docutils.sourceforge.io/docs/ref/rst/restructuredtext.html
配置为了配置Sphinx支持 Markdown ，根据下面步骤操作即可：

安装 recommonmark:
$ pip install --upgrade recommonmark



添加 recommonmark 到可支持扩展 list of configured extensions:
extensions = ['recommonmark']

如果希望不只是.md后缀的也按照Markdown解析，可以使用 source_suffix ，如下使Sphinx  将.md 和 .txt解析为Markdown:
source_suffix = {    '.rst': 'restructuredtext',    '.txt': 'markdown',    '.md': 'markdown',}

You can further configure recommonmark to allow custom syntax that standard CommonMark doesn’t support. Read more in the recommonmark documentation.


参考https://pandoc.org/MANUAL.html
https://sspai.com/post/57082
(17条消息) 【Markdown笔记】设置字体颜色_dadalaohua的博客-CSDN博客_markdown 颜色
]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>markdown</tag>
      </tags>
  </entry>
  <entry>
    <title>Git Pro学习手册</title>
    <url>/2014/12/21/git-pro-git/</url>
    <content><![CDATA[起步版本控制版本控制是一种记录一个或若干文件内容变化，以便将来查阅特定版本修订情况的系统。
大多数人使用的方法就是本地文件改名，然后加上时间，好处是比较简单，坏处就是一旦混淆所在的工作目录，或者一旦丢失弄错了文件就没有办法撤销了。
所以出现了下面的版本控制系统：

本地版本控制系统：rcs，工作原理就是保存并管理文件补丁patch，根据每次的补丁，计算出各个版本的文件内容
集中化的版本控制系统：CVS/SVN等，有一个单一的集中管理的服务器，保存所有文件的修订版本，协同工作的人们通过客户端连接到这台服务器，取出最新的文件或者提交更新
分布式版本控制系统，Git/Mercurial等，客户端把代码仓库完整地镜像下来，每次都是对代码仓库的完整备份

Git 基础直接记录快照，而非差异比较
Git和其他其他版本控制系统的主要差别在于，Git 只关心文件数据的整体是否发生变化，而大多数其他系统则只关心文件内容的具体差异。
Git 并不保存这些前后变化的差异数据。实际上，Git 更像是把变化的文件作快照后，记录在一个微型的文件系统中。每次提交更新时，它会纵览一遍所有文件的指纹信息并对文件作一快照，然后保存一个指向这次快照的索引。为提高性能，若文件没有变化，Git 不会再次保存，而只对上次保存的快照作一链接。
近乎所有操作都是本地执行
在 Git 中的绝大多数操作都只需要访问本地文件和资源，不用连网。但如果用 CVCS 的话，差不多所有操作都需要连接网络。因为 Git 在本地磁盘上就保存着所有当前项目的历史更新，所以处理起来速度飞快。
时刻保持数据完整性
在保存到 Git 之前，所有数据都要进行内容的校验和（checksum）计算，并将此结果作为数据的唯一标识和索引。换句话说，不可能在你修改了文件或目录之后，Git 一无所知。这项特性作为 Git 的设计哲学，建在整体架构的最底层。所以如果文件在传输时变得不完整，或者磁盘损坏导致文件数据缺失，Git 都能立即察觉。
文件的三种状态
对于任何一个文件，在 Git 内都只有三种状态：已提交（committed），已修改（modified）和已暂存（staged）。

已提交表示该文件已经被安全地保存在本地数据库中了；
已修改表示修改了某个文件，但还没有提交保存；
已暂存表示把已修改的文件放在下次提交时要保存的清单中。

由此我们看到 Git 管理项目时，文件流转的三个工作区域：Git 的工作目录，暂存区域，以及本地仓库。
初次运行 Git 前的配置一般在新的系统上，我们都需要先配置下自己的 Git 工作环境。配置工作只需一次，以后升级时还会沿用现在的配置。当然，如果需要，你随时可以用相同的命令修改已有的配置。
Git 提供了一个叫做 git config 的工具（译注：实际是 git-config 命令，只不过可以通过 git 加一个名字来呼叫此命令。），专门用来配置或读取相应的工作环境变量。而正是由这些环境变量，决定了 Git 在各个环节的具体工作方式和行为。这些变量可以存放在以下三个不同的地方：

/etc/gitconfig 文件：系统中对所有用户都普遍适用的配置。若使用 git config 时用 –system 选项，读写的就是这个文件。
~/.gitconfig 文件：用户目录下的配置文件只适用于该用户。若使用 git config 时用 –global 选项，读写的就是这个文件。
当前项目的 git 目录中的配置文件（也就是工作目录中的 .git/config 文件）：这里的配置仅仅针对当前项目有效。每一个级别的配置都会覆盖上层的相同配置，所以 .git/config 里的配置会覆盖 /etc/gitconfig 中的同名变量。

用户信息
第一个要配置的是你个人的用户名称和电子邮件地址。这两条配置很重要，每次 Git 提交时都会引用这两条信息，说明是谁提交了更新，所以会随更新内容一起被永久纳入历史记录：
$ git config --global user.name "Your name"$ git config --global user.email youremail@example.com

如果用了 –global 选项，那么更改的配置文件就是位于你用户主目录下的那个，以后你所有的项目都会默认使用这里配置的用户信息。如果要在某个特定的项目中使用其他名字或者电邮，只要去掉 –global 选项重新配置即可，新的设定保存在当前项目的 .git/config 文件里。
文本编辑器
接下来要设置的是默认使用的文本编辑器。Git 需要你输入一些额外消息的时候，会自动调用一个外部文本编辑器给你用。默认会使用操作系统指定的默认编辑器，一般可能会是 Vi 或者 Vim。如果你有其他偏好，比如 Emacs 的话，可以重新设置：
$ git config --global core.editor emacs

差异分析工具
还有一个比较常用的是，在解决合并冲突时使用哪种差异分析工具。比如要改用 vimdiff 的话：
$ git config --global merge.tool vimdiff

Git 可以理解 kdiff3，tkdiff，meld，xxdiff，emerge，vimdiff，gvimdiff，ecmerge，和 opendiff 等合并工具的输出信息。当然，你也可以指定使用自己开发的工具，具体怎么做可以参阅第七章。
查看配置信息
要检查已有的配置信息，可以使用 git config –list 命令：
$ git config --list

Git 基础要查看尚未暂存的文件更新了哪些部分，不加参数直接输入 git diff
若要看已经暂存起来的文件和上次提交时的快照之间的差异，可以用 git diff --cached 命令。（Git 1.6.1 及更高版本还允许使用 git diff –staged，效果是相同的，但更好记些。
跳过使用暂存区域
尽管使用暂存区域的方式可以精心准备要提交的细节，但有时候这么做略显繁琐。Git 提供了一个跳过使用暂存区域的方式，只要在提交的时候，给 git commit 加上 -a 选项，Git 就会自动把所有已经跟踪过的文件暂存起来一并提交，从而跳过 git add 步骤
移除文件
要从 Git 中移除某个文件，就必须要从已跟踪文件清单中移除（确切地说，是从暂存区域移除），然后提交。可以用 git rm 命令完成此项工作，并连带从工作目录中删除指定的文件，这样以后就不会出现在未跟踪文件清单中了。
另外一种情况是，我们想把文件从 Git 仓库中删除（亦即从暂存区域移除），但仍然希望保留在当前工作目录中。 换句话说，仅是从跟踪清单中删除。比如一些大型日志文件或者一堆 .a 编译文件，不小心纳入仓库后，要移除跟踪但不删除文件，以便稍后在 .gitignore 文件中补上，用 –cached 选项即可：
$ git rm --cached readme.txt

移动文件
运行 git mv 就相当于运行了下面三条命令：
$ mv README.txt README$ git rm README.txt$ git add README

查看提交历史在提交了若干更新之后，又或者克隆了某个项目，想回顾下提交历史，可以使用 git log 命令查看。
我们常用 -p 选项展开显示每次提交的内容差异，用 -2 则仅显示最近的两次更新。
在做代码审查，或者要快速浏览其他协作者提交的更新都作了哪些改动时，就可以用这个选项。此外，还有许多摘要选项可以用，比如 –stat，仅显示简要的增改行数统计。
每个提交都列出了修改过的文件，以及其中添加和移除的行数，并在最后列出所有增减行数小计。还有个常用的 –pretty 选项，可以指定使用完全不同于默认格式的方式展示提交历史。比如用 oneline 将每个提交放在一行显示，这在提交数很大时非常有用。另外还有 short，full 和 fuller 可以用，展示的信息或多或少有些不同。
但最有意思的是 format，可以定制要显示的记录格式，这样的输出便于后期编程提取分析，像这样：
$ git log --pretty=format:"%h - %an, %ar : %s"

选项 说明%H 提交对象（commit）的完整哈希字串%h 提交对象的简短哈希字串%T 树对象（tree）的完整哈希字串%t 树对象的简短哈希字串%P 父对象（parent）的完整哈希字串%p 父对象的简短哈希字串%an 作者（author）的名字%ae 作者的电子邮件地址%ad 作者修订日期（可以用 -date= 选项定制格式）%ar 作者修订日期，按多久以前的方式显示%cn 提交者(committer)的名字%ce 提交者的电子邮件地址%cd 提交日期%cr 提交日期，按多久以前的方式显示%s 提交说明


用 oneline 或 format 时结合 –graph 选项，可以看到开头多出一些 ASCII 字符串表示的简单图形，形象地展示了每个提交所在的分支及其分化衍合情况。
git log 支持的命令选项



选项
说明



-p
按补丁格式显示每个更新之间的差异。


–stat
显示每次更新的文件修改统计信息。


–shortstat
只显示 –stat 中最后的行数修改添加移除统计。


–name-only
仅在提交信息后显示已修改的文件清单。


–name-status
显示新增、修改、删除的文件清单。


–abbrev-commit
仅显示 SHA-1 的前几个字符，而非所有的 40 个字符。


–relative-date
使用较短的相对时间显示（比如，“2 weeks ago”）。


–graph
显示 ASCII 图形表示的分支合并历史。


–pretty
使用其他格式显示历史提交信息。可用的选项包括 oneline，short，full，fuller 和 format（后跟指定格式）。


限制输出长度
除了定制输出格式的选项之外，git log 还有许多非常实用的限制输出长度的选项，也就是只输出部分提交信息。之前我们已经看到过 -2 了，它只显示最近的两条提交，实际上，这是 - 选项的写法，其中的 n 可以是任何自然数，表示仅显示最近的若干条提交。不过实践中我们是不太用这个选项的，Git 在输出所有提交时会自动调用分页程序（less），要看更早的更新只需翻到下页即可。
另外还有按照时间作限制的选项，比如 –since 和 –until。下面的命令列出所有最近两周内的提交：
$ git log --since=2.weeks

你可以给出各种时间格式，比如说具体的某一天（“2008-01-15”），或者是多久以前（“2 years 1 day 3 minutes ago”）。
还可以给出若干搜索条件，列出符合的提交。用 --author 选项显示指定作者的提交，用 --grep 选项搜索提交说明中的关键字。（请注意，如果要得到同时满足这两个选项搜索条件的提交，就必须用 –all-match 选项。否则，满足任意一个条件的提交都会被匹配出来）
另一个真正实用的git log选项是路径(path)，如果只关心某些文件或者目录的历史提交，可以在 git log 选项的最后指定它们的路径。因为是放在最后位置上的选项，所以用两个短划线（–）隔开之前的选项和后面限定的路径名。
撤消操作任何时候，你都有可能需要撤消刚才所做的某些操作。接下来，我们会介绍一些基本的撤消操作相关的命令。请注意，有些撤销操作是不可逆的，所以请务必谨慎小心，一旦失误，就有可能丢失部分工作成果。
修改最后一次提交
有时候我们提交完了才发现漏掉了几个文件没有加，或者提交信息写错了。想要撤消刚才的提交操作，可以使用 –amend 选项重新提交：
$ git commit --amend

此命令将使用当前的暂存区域快照提交。如果刚才提交完没有作任何改动，直接运行此命令的话，相当于有机会重新编辑提交说明，但将要提交的文件快照和之前的一样。
启动文本编辑器后，会看到上次提交时的说明，编辑它确认没问题后保存退出，就会使用新的提交说明覆盖刚才失误的提交。
如果刚才提交时忘了暂存某些修改，可以先补上暂存操作，然后再运行 –amend 提交：
$ git commit -m 'initial commit'$ git add forgotten_file$ git commit --amend

上面的三条命令最终只是产生一个提交，第二个提交命令修正了第一个的提交内容。
取消已经暂存的文件
$ git reset HEAD &lt;filename&gt;

取消对文件的修改
$ git checkout -- &lt;filename&gt;

这个命令将丢弃所有的修改，特别危险，所有对文件的修改都没有了，所以只有百分比确定的时候，在使用该命令。
远程仓库的使用查看当前的远程库
可以使用git remote命令来列出当前的远程库，或者git remove -v来显示对应的克隆地址。
推送数据到远程仓库
git push [remote-name] [branch-name]

查看远程仓库信息
$ git remote show origin

远程仓库的删除和重命名
$ git remote rename old new

碰到远端仓库服务器迁移，或者原来的克隆镜像不再使用，又或者某个参与者不再贡献代码，那么需要移除对应的远端仓库，可以运行 git remote rm 命令：
$ git remote rm [remote-name]
]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>cvs</tag>
        <tag>rcs</tag>
        <tag>svn</tag>
      </tags>
  </entry>
  <entry>
    <title>Git linux服务器git pull/push时不输入密码</title>
    <url>/2018/02/26/git-push-without-passwd/</url>
    <content><![CDATA[linux服务器git pull/push时不输入密码step1 先cd到根目录，执行git config –global credential.helper store命令
[root@iZ25mi9h7ayZ ~]# git config --global credential.helper store

step2执行之后会在.gitconfig文件中多加红色字体项
[user]        name = shaoguangleo        email = xxxx@xxxx.com[credential]        helper = store

step3之后cd到项目目录，执行git pull命令，会提示输入账号密码。输完这一次以后就不再需要，并且会在根目录生成一个.git-credentials文件
[~/gittest]# git pullUsername for 'https://github.com': xxxx@xxxx.comPassword for 'https://shaoguangleo@github.com':[~]# cat .git-credentialshttps://Username:Password@github.com

step4之后pull/push代码都不再需要输入账号密码了~
]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>push</tag>
        <tag>pull</tag>
        <tag>credential</tag>
      </tags>
  </entry>
  <entry>
    <title>git push用法</title>
    <url>/2016/12/21/git-push/</url>
    <content><![CDATA[git push origin master

origin指定了你要push到哪个remote
master其实是一个“refspec”，正常的“refspec”的形式为”+:”，冒号前表示local branch的名字，冒号后表示remote repository下 branch的名字。
注意，如果你省略了，git就认为你想push到remote repository下和local branch相同名字的branch。
比如
$git push origin master:master

(在local repository中找到名字为master的branch，使用它去更新remote repository下名字为master的branch，如果remote repository下不存在名字是master的branch，那么新建一个)
$git push origin master

（省略了，等价于“git push origin master:master”）
$git push origin master:refs/for/mybranch

(在local repository中找到名字为master的branch，用他去更新remote repository下面名字为mybranch的branch)
$git push origin HEAD:refs/for/mybranch

（HEAD指向当前工作的branch，master不一定指向当前工作的branch，所以我觉得用HEAD还比master好些）
$git push origin :mybranch

（再origin repository里面查找mybranch，删除它。用一个空的去更新它，就相当于删除了）
]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>push</tag>
      </tags>
  </entry>
  <entry>
    <title>Git 参考材料</title>
    <url>/2014/12/21/git-reference/</url>
    <content><![CDATA[Git 使用说明的各种比较好的文章或者书籍：

码云出品

]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>cvs</tag>
        <tag>svn</tag>
      </tags>
  </entry>
  <entry>
    <title>git reset</title>
    <url>/2019/01/26/git-reset/</url>
    <content><![CDATA[世上还是有后悔药 - git reset如果你想 **取消上一次的 git commit**，可以根据具体情况使用不同的方法：

1. 仅撤销 commit（保留修改）如果你只想 撤销 commit 但保留文件的修改（即回到 git commit 之前的状态）：
git reset --soft HEAD~


--soft 选项会 保留你的修改，只是撤销了 commit 记录，相当于回到了 git add 之后但还没 commit 的状态。


2. 撤销 commit 并取消 git add如果你还想 **同时取消 git add**，让所有文件恢复为未暂存（unstaged）的状态：
git reset HEAD~


这会撤销 commit，并且将已经 git add 的文件放回未暂存状态。


3. 彻底撤销 commit 并删除修改如果你想 完全撤销 commit 并丢弃所有修改：
git reset --hard HEAD~


这个操作是不可逆的，会删除所有的未推送的修改，谨慎使用！


4. 如果 commit 已经推送到远程仓库如果 commit 已经被推送到远程仓库（如 GitHub、GitLab），git reset 只是本地生效，远程不会变化。此时需要强制推送：
git reset --soft HEAD~git push origin -f


警告： git push -f 会重写远程仓库的提交记录，可能影响其他开发者，谨慎使用！


5. 使用 git revert（安全方式）如果 commit 已推送，并且你不希望使用 git push -f 强制覆盖历史，推荐使用 git revert：
git revert HEAD


这会创建一个新的 commit 来撤销上一次提交，而不会改变历史记录（适用于多人协作的情况）。


总结如下


操作
影响



git reset --soft HEAD~
仅撤销 commit，保留所有修改（回到 git add 之后的状态）


git reset HEAD~
撤销 commit，并取消 git add（回到 git status 可见的未暂存状态）


git reset --hard HEAD~
彻底删除 commit 和修改（谨慎使用！）


git revert HEAD
创建一个新的 commit 来撤销上一次提交（安全方式，适用于已推送的 commit）


git push origin -f
强制推送修改后的提交历史（危险操作，谨慎使用）


如果你不确定哪种方式适合你的情况，可以先运行 git status 看看当前状态，然后选择合适的操作。
使用 git reset HEAD &lt;file&gt;... 来取消暂存。 所以，我们可以这样来取消暂存 CONTRIBUTING.md 文件：
$ git reset HEAD CONTRIBUTING.mdUnstaged changes after reset:M	CONTRIBUTING.md$ git statusOn branch masterChanges to be committed:  (use "git reset HEAD &lt;file&gt;..." to unstage)    renamed:    README.md -&gt; READMEChanges not staged for commit:  (use "git add &lt;file&gt;..." to update what will be committed)  (use "git checkout -- &lt;file&gt;..." to discard changes in working directory)    modified:   CONTRIBUTING.md

这个命令有点儿奇怪，但是起作用了。 CONTRIBUTING.md 文件已经是修改未暂存的状态了。

 git reset 确实是个危险的命令，如果加上了 --hard 选项则更是如此。 然而在上述场景中，工作目录中的文件尚未修改，因此相对安全一些。

]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>reset</tag>
      </tags>
  </entry>
  <entry>
    <title>Git rm删除文件</title>
    <url>/2020/11/02/git-rm/</url>
    <content><![CDATA[Git rm删除文件从版本库中删除该文件，那就用命令git rm删掉，并且git commit：
$ git rm file$ git commit -m "remove file"

现在，文件就从版本库中被删除了。
如果删错了，因为版本库里还有呢，所以可以很轻松地把误删的文件恢复到最新版本：
$ git checkout -- test.txt

git checkout其实是用版本库里的版本替换工作区的版本，无论工作区是修改还是删除，都可以“一键还原”。
还有一种情况是如何从版本库中删除，而不删除本地文件：
对于单个文件：
$ git rm --cached mylogfile.log

对于单个目录：
$ git rm --cached -r mydirectory

git rm和rm的区别直接在工作区删除文件对暂存区和版本库没有影响，但是如果使用git rm命令删除文件，那么删除动作将加入暂存区，这时执行提交命令，就从真正意义上执行了文件删除。不过，不要担心，文件只是在版本库的最新提交中被删除了，在历史提交中尚在。
git push存在大文件报错git push 时，存在大文件会报错，即使删除大文件后，还会报错。主要是因为大文件存在没有被提交的commit记录里面。
解决方案：删除有大文件的commit记录即可
1、git status 查看未被传送到远程代码库的提交状态
2、git cherry -v 查看未被传送到远程代码库的提交描述和说明
3、git reset commit_id 撤销未被传送到远程代码库的提交
移除大文件：
$ git rm --cached giant_file（文件名） # Stage our giant file for removal, but leave it on disk  $ git commit --amend$ git push]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>push</tag>
        <tag>rm</tag>
        <tag>cherry</tag>
      </tags>
  </entry>
  <entry>
    <title>Git 使用git将本地文件上传至github</title>
    <url>/2012/11/30/git-simple-tutorial/</url>
    <content><![CDATA[使用git将本地文件上传至github我的使用配置
首先在https://github.com/上注册，然后新建一个Repository，输入Repository的名称以及对这个Repository的描述。
红色斜体只需要操作一次即可。
首先clone下来工程gtk-programming：
git clone git://github.com/shaoguangleo/gtk-programming.git

这里如果要上传代码，有几个关键步骤：
git init

这个命令会在当前目录下创建一个.git文件夹。
git add filename

这个命令会把当前路径下的所有文件，添加到待上传的文件列表中。
git commit -m "xxxxx"  

提交至本地的git库git read-only方式
git remote add origin  git://github.com/shaoguangleo/gtk-programming.git

ssh方式
git remote add origin git@github.com:shaoguangleo/gtk-programming.git

http方式
git remote add origin https://github.com/shaoguangleo/gtk-programming.git

通过三种方式为远程的服务器定义别名origin，我用的是第三种方式。
git push origin master

提交当地文件到远端服务器，其中master为默认的本地开发别名。
网络上关于github的使用使用GitHub步骤：
1、申请GitHub帐户 xxx ，创建名为new-project的新Repository
2、安装Git客户端（Linux）
#yum install git git-gui

3、 生成密钥对，这样项目可以push到 GitHub上
#ssh-keygen -t rsa -C "xxx@gmail.com"

4、将.ssh/id_rsa.pub拷贝到GitHub网站
5、为了方便，设置ssh不输入口令
# eval `ssh-agent`# ssh-add（输入passphrase）

6、测试是否能联通GitHub
#ssh git@github.com

如果配置正确，显示
ERROR: Hi xxx! You've successfully authenticated, but GitHub does not provide shell accessConnection to github.com closed.

7、设置Git全局用户配置
# git config --global user.name "xxx"# git config --global user.email xxx@gmail.com

8、创建本地新项目工作树
# mkdir new-project# cd new-project# git init# touch README# git add README# git commit -m 'first commit'

定义远程服务器别名origin
#  git remote add origin git@github.com:xxx/new-project.git   

本地和远程合并，本地默认分支为master
# git push origin master  

GitHub网站上就可以看见了， http://github.com/xxx/new-project

更新文件

# vi README自动commit更改文件# git commit -a     更新至远程# git push origin master


创建和合并分支

$git branch 显示当前分支是master$git branch new-feature  创建分支$ git checkout new-feature 切换到新分支$ vi page_cache.inc.php$ git add page_cache.inc.php# Commit 到本地GIT$ git commit -a -m "added initial version of page cache"# 合并到远程服务器$ git push origin new-feature

如果new-feature分支成熟了，觉得有必要合并进master
#git checkout master#git merge new-feature#git branch#git push

则master中也合并了new-feature 的代码
再登录到GitHub可以看见”Switch Branches”下的分支选项：
GitHub还有一个很实用的功能，查看开发进程网络图（Network）
]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>github</tag>
        <tag>commit</tag>
        <tag>clone</tag>
        <tag>init</tag>
      </tags>
  </entry>
  <entry>
    <title>Git 向Github增加SSH keys</title>
    <url>/2018/12/21/git-ssh-keys/</url>
    <content><![CDATA[什么是SSH key?SSH 密钥对 最直观的作用：让你方便的登录到 SSH 服务器，而无需输入密码。由于你无需发送你的密码到网络中，SSH 密钥对被认为是更加安全的方式。
SSH Key是比较简单的保护账户安全的一种方式，SSH key提供了一种与GitHub通信的方式，通过这种方式，能够在不输入密码的情况下，将GitHub作为自己的remote端服务器.这样也就保证了你的密码不会被其他人或者robot暴力破解，理论上只有你拥有这个密码。
如何创建SSH Key创建公用密钥的步骤如下所示：
$ ssh-keygen -t rsa -b 4096 -C "youremail@email.com"# 回车即可#显示公钥$ cat .ssh/id_rsa.pub# 此时就需要拷贝公钥了


注意ssh-keygen会生成两部分，公钥和私钥，切记不要公开私钥(除非是本单位机构的管理员)，文件名为.ssh/id_rsa

把SSH Key添加到Github Account按照下面的步骤即可：

登录github账户
点击头像选择settings
选择SSH and GPG kyes
在SSH Keys点击New SSH Key
输入一个title并将刚才复制的内容粘贴进去即可搞定

]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>github</tag>
        <tag>ssh</tag>
      </tags>
  </entry>
  <entry>
    <title>Git stash</title>
    <url>/2020/09/07/git-stash/</url>
    <content><![CDATA[Git中文件的状态$ git stash保存工作目录和索引状态 WIP on master: b9a733eff make python3 compatible错误：unable to create symlink filename: File name too long错误：unable to create symlink filename: File name too long

解决方法：
$ git config --global core.symlinks false
]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>stash</tag>
      </tags>
  </entry>
  <entry>
    <title>Git中文件的状态</title>
    <url>/2017/09/07/git-status/</url>
    <content><![CDATA[Git中文件的状态Git 有三种状态，

已提交（committed）
已提交表示数据已经安全地保存在本地数据库中。


已修改（modified）
已修改表示修改了文件，但还没保存到数据库中


已暂存（staged）
已暂存表示对一个已修改文件的当前版本做了标记，使之包含在下次提交的快照中。



这会让我们的 Git 项目拥有三个阶段：工作区、暂存区以及 Git 目录。

工作区是对项目的某个版本独立提取出来的内容。 这些从 Git 仓库的压缩数据库中提取出来的文件，放在磁盘上供你使用或修改。
暂存区是一个文件，保存了下次将要提交的文件列表信息，一般在 Git 仓库目录中。 按照 Git 的术语叫做“索引”，不过一般说法还是叫“暂存区”。
Git 仓库目录是 Git 用来保存项目的元数据和对象数据库的地方。 这是 Git 中最重要的部分，从其它计算机克隆仓库时，复制的就是这里的数据。
基本的 Git 工作流程如下：

在工作区中修改文件。
将你想要下次提交的更改选择性地暂存，这样只会将更改的部分添加到暂存区。
提交更新，找到暂存区的文件，将快照永久性存储到 Git 目录。

如果 Git 目录中保存着特定版本的文件，就属于 已提交 状态。 如果文件已修改并放入暂存区，就属于 已暂存 状态。 如果自上次检出后，作了修改但还没有放到暂存区域，就是 已修改 状态。
记录每次更新到仓库现在我们的机器上有了一个 真实项目 的 Git 仓库，并从这个仓库中检出了所有文件的 工作副本。 通常，你会对这些文件做些修改，每当完成了一个阶段的目标，想要将记录下它时，就将它提交到仓库。
请记住，你工作目录下的每一个文件都不外乎这两种状态：已跟踪 或 未跟踪。 已跟踪的文件是指那些被纳入了版本控制的文件，在上一次快照中有它们的记录，在工作一段时间后， 它们的状态可能是未修改，已修改或已放入暂存区。简而言之，已跟踪的文件就是 Git 已经知道的文件。
工作目录中除已跟踪文件外的其它所有文件都属于未跟踪文件，它们既不存在于上次快照的记录中，也没有被放入暂存区。 初次克隆某个仓库的时候，工作目录中的所有文件都属于已跟踪文件，并处于未修改状态，因为 Git 刚刚检出了它们， 而你尚未编辑过它们。
编辑过某些文件之后，由于自上次提交后你对它们做了修改，Git 将它们标记为已修改文件。 在工作时，你可以选择性地将这些修改过的文件放入暂存区，然后提交所有已暂存的修改，如此反复。

使用git status 命令的输出十分详细，但其用语有些繁琐。 Git 有一个选项可以帮你缩短状态命令的输出，这样可以以简洁的方式查看更改。 如果你使用 git status -s 命令或 git status --short 命令，你将得到一种格式更为紧凑的输出。
$ git status -s M READMEMM RakefileA  lib/git.rbM  lib/simplegit.rb?? LICENSE.txt

新添加的未跟踪文件前面有 ?? 标记，新添加到暂存区中的文件前面有 A 标记，修改过的文件前面有 M 标记。 输出中有两栏，左栏指明了暂存区的状态，右栏指明了工作区的状态。例如，上面的状态报告显示： README 文件在工作区已修改但尚未暂存，而 lib/simplegit.rb 文件已修改且已暂存。 Rakefile 文件已修，暂存后又作了修改，因此该文件的修改中既有已暂存的部分，又有未暂存的部分。
]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>status</tag>
      </tags>
  </entry>
  <entry>
    <title>Git submodule 的使用</title>
    <url>/2019/12/21/git-submodule/</url>
    <content><![CDATA[git submodule 的使用项目中经常会使用到第三方的 git 库, 将三方库整合到项目中最简单的办法就是复制粘贴, 但是如果这个库升级了一个很酷炫的功能, 你要怎么整合进来呢?(其实就是 git 版的包管理器)
这就是 git-submodule 的功能, 直接把第三方的版本库合并到自己的库中.
添加第三方库比如自己开了两个库做测试, 主库叫 main, 另一个库叫 sub
首先在本地的main库中添加sub
$ git clone https://www.github.com/username/main.git$ cd main$ git submodule add https://www.github.com/username/sub.git &lt;directory_name&gt;

这时查看下状态会多两个文件
➜  main git:(master) ✗ git statusOn branch masterYour branch is ahead of 'origin/master' by 1 commit.  (use "git push" to publish your local commits)Changes to be committed:  (use "git reset HEAD &lt;file&gt;..." to unstage)           new file:   .gitmodules           new file:   sub

这就多了一个 sub的库, 和一个.gitmodules的文件, 现在提交一下
$ git commit -am "add sub"

在其他地方使用合并后的版本库本地提交了版本之后可以提交到远程试一下
$ git push

这时去远程库中看的话库中的内容是这样的
这里有个奇怪的 sub @ 2b79b47, 明明是没有的啊?点一下原来是一个快捷方式, 直接给连接到了 sub库的地址, 版本库中不会存第三方引入库的实体文件, 而是通过 .gitmodules的方式存储三方的联系方式, 当下载到本地运行的时候才会再拉取文件
而且这个时候在其他的地方安装main这个库的时候直接运行 git clone 是生成不了完整的文件的, 缺少了 sub库的文件因为这个时候的 main/sub目录是空的需要多走一步, 这时为什么呢? 我们下面会讲到原因
$ git clone the/path/of/main.git$ git submodule init &amp;&amp; git submodule update#下面这一句的效果和上面三条命令的效果是一样的,多加了个参数  `--recursive`$ git clone the/path/of/main.git --recursive

这时才是一个完整的库
将三方库同步到主线之前的一些步骤其实还不完整, 因为 main/sub 这个目录中的文件并没有和主线在一条线上, 这也是为什么在远程库的 sub 目录是空的, 因为在 master 分支里面它确实是空的, 文件是在另一个分支上, 我们先去看一下
cd path/to/main/sub➜  sub git:(2b79b47) git branch* (HEAD detached at 2b79b47)  master

别的文件的分支都是 master 到这个文件的时候就是 2b79b47分支了, 其实这个值也是 sub库当前的 commitId而且如果不把第三方的库纳入自己的主线的话会非常的危险, 因为你对项目中的三方库发生的任何改动都不会对主线产生任何影响, 被主线遗忘了, 因此我们还需要接下来的操作
cd path/to/main/subgit checkout master

更新第三方库这里有个问题就是如果main/sub发生了更新就首先在这个文件中提交一个commit, 然后在main这个目录下再 commit一次第一次 commit 是为了更新 sub的版本控制, 第二次更新是更新main的版本控制, 同时更新 sub库在main的指针
如果更新的比较多, 可以运行
批量更新第三方库假设你的项目当中引入了 100 个第三方的库, 你需要同步的时候难道还要每一个都要执行:
$ cd module-dir/$ git checkout master$ git pull

这些东西 git 早就帮你想好了具体操作可以看一下git help submodule有相关的介绍的
git submodule foreach &lt;command&gt;比如:git submodule foreach git checkout master

这条命令就会按照 .gitmodules会根据path寻找所有的三方模块, 并在每一个模块中都执行 foreach 后的命令,比如你想批量更新模块到最新的时候就:
git submodule foreach git submodule update

怎么删除 submodule?在当前 git 版本1.7.8之前, 删除指定的 submodule 的命令是
git rm &lt;submodule-name&gt;

在新版的 git 下, 则是运行以下命令
$ git submodule deinit -f — mymodule$ rm -rf .git/modules/mymodule$ git rm -f mymodule

查看本地有哪些三方模块可以查看 .gitmodules
➜  maint  git:(master) cat .gitmodules[submodule "sub"]           path = sub           url = the/path/of/sub.git



拉取所有子模块git submodule foreach git pull
git submodule foreach –recursive git submodule init 
git submodule foreach –recursive git submodule update 
$ git submodule add &lt;url&gt; &lt;path&gt;


url：替换为自己要引入的子模块仓库地址
path：要存放的本地路径

执行添加命令成功后，可以在当前路径中看到一个.gitsubmodule文件，里面的内容就是我们刚刚add的内容
如果在添加子模块的时候想要指定分支，可以利用 -b 参数
$ git submodule add -b &lt;branch&gt; &lt;url&gt; &lt;path&gt;



未指定分支$ git submodule add https://github.com/tensorflow/benchmarks.git 3rdparty/benchmarks

.gitsubmodule内容
[submodule "3rdparty/benchmarks"]	path = 3rdparty/benchmarks	url = https://github.com/tensorflow/benchmarks.git

指定分支$ git submodule add -b cnn_tf_v1.10_compatible https://github.com/tensorflow/benchmarks.git 3rdparty/benchmarks

.gitsubmodule内容
[submodule "3rdparty/benchmarks"]	path = 3rdparty/benchmarks	url = https://github.com/tensorflow/benchmarks.git	branch = cnn_tf_v1.10_compatible

使用当我们add子模块之后，会发现文件夹下没有任何内容。这个时候我们需要再执行下面的指令添加源码。
$ git submodule update --init --recursive

这个命令是下面两条命令的合并版本
$ git submodule init$ git submodule update

更新我们引入了别人的仓库之后，如果该仓库作者进行了更新，我们需要手动进行更新。即进入子模块后，执行
$ git pull或者在根目录执行# 远程仓库更新以后# fatal: Needed a single revision# fatal: Unable to find current revision in submodule path 'xxx'$ git pull --recurse-submodules#或者$ git submodule foreach git pull origin master

进行更新。
删除
删除子模块目录及源码

$ rm -rf 子模块目录


删除.gitmodules中的对应子模块内容

$ vi .gitmodules


删除.git/config配置中的对应子模块内容

$ vi .git/config


删除.git/modules/下对应子模块目录

$ rm -rf .git/modules/子模块目录


删除git索引中的对应子模块

$ git rm --cached 子模块目录



TO-read
Using submodules in Git - Tutorial (vogella.com)
Using submodules in Git - TutorialLars Vogel (c) 2009-2022 vogella GmbHVersion 5.8,10.08.2015
TABLE OF CONTENTS
- 
  \1. Submodules - repositories inside other Git repositories
- 
  \2. Working with repositories that contain submodules
- 
  \3. Creating repositories with submodules

\4. Links and Literature


This tutorial explains the usage of submodules with the Git version control system.

Learn more in the Learning Portal. Check out ourGit Online Training priority_high
1. Submodules - repositories inside other Git repositories1.1. Using Git repositories inside other Git repositoriesGit allows you to include other Git repositories called submodules into a repository. This allows you to track changes in several repositories via a central one. Submodules are Git repositories nested inside a parent Git repository at a specific path in the parent repository’s working directory. A submodule can be located anywhere in a parent Git repository’s working directory and is configured via a .gitmodules file located at the root of the parent repository. This file contains which paths are submodules and what URL should be used when cloning and fetching for that submodule. Submodule support includes support for adding, updating, synchronizing, and cloning submodules.
Git allows you to commit, pull and push to these repositories independently.
Submodules allow you to keep projects in separate repositories but still be able to reference them as folders in the working directory of other repositories.
2. Working with repositories that contain submodules2.1. Cloning a repository that contains submodulesIf you want to clone a repository including its submodules you can use the --recursive parameter.
git clone --recursive [URL to Git repo]



2.2. Downloading multiple submodules at onceSince a repository can include many submodules, downloading them all sequentially can take much time. For this reason clone and submodule update command support the --jobs parameter to fetch multiple submodules at the same time.
# download up to 8 submodules at oncegit submodule update --init --recursive --jobs 8git clone --recursive --jobs 8 [URL to Git repo]# short versiongit submodule update --init --recursive -j 8

2.3. Pulling with submodulesOnce you have set up the submodules you can update the repository with fetch/pull like you would normally do. To pull everything including the submodules, use the --recurse-submodules and the --remote parameter in the git pull command.
# pull all changes in the repo including changes in the submodulesgit pull --recurse-submodules# pull all changes for the submodulesgit submodule update --remote

2.4. Executing a command on every submoduleGit provides a command that lets us execute an arbitrary shell command on every submodule. To allow execution in nested subprojects the --recursive parameter is supported. For our example we assume that we want to reset all submodules.
git submodule foreach 'git reset --hard'# including nested submodulesgit submodule foreach --recursive 'git reset --hard'



3. Creating repositories with submodules3.1. Adding a submodule to a Git repository and tracking a branchIf you add a submodule, you can specify which branch should be tracked via the -b parameter of the submodule add command. The git submodule init command creates the local configuration file for the submodules, if this configuration does not exist.
# add submodule and define the master branch as the one you want to trackgit submodule add -b master [URL to Git repo] git submodule init 





adds a new submodule to an existing Git repository and defines that the master branch should be tracked




initialize submodule configuration


If you track branches in your submodules, you can update them via the --remote parameter of the git submodule update command. This pulls in new commits into the main repository and its submodules. It also changes the working directories of the submodules to the commit of the tracked branch.
# update your submodule --remote fetches new commits in the submodules# and updates the working tree to the commit described by the branchgit submodule update --remote

3.2. Adding a submodule and tracking commitsAlternatively to the tracking of a branch, you can also control which commit of the submodule should be used. In this case the Git parent repository tracks the commit that should be checked out in each configured submodule. Performing a submodule update checks out that specific revision in the submodule’s Git repository. You commonly perform this task after you pull a change in the parent repository that updates the revision checked out in the submodule. You would then fetch the latest changes in the submodule’s Git repository and perform a submodule update to check out the current revision referenced in the parent repository. Performing a submodule update is also useful when you want to restore your submodule’s repository to the current commit tracked by the parent repository. This is common when you are experimenting with different checked out branches or tags in the submodule and you want to restore it back to the commit tracked by the parent repository. You can also change the commit that is checked out in each submodule by performing a checkout in the submodule repository and then committing the change in the parent repository.
You add a submodule to a Git repository via the git submodule add command.
git submodule add [URL to Git repo] git submodule init 





adds a submodule to the existing Git repository




initialize submodule configuration


3.3. Updating which commit your are trackingThe relevant state for the submodules are defined by the main repository. If you commit in your main repository, the state of the submodule is also defined by this commit.
The git submodule update command sets the Git repository of the submodule to that particular commit. The submodule repository tracks its own content which is nested into the main repository. The main repository refers to a commit of the nested submodule repository.
Use the git submodule update command to set the submodules to the commit specified by the main repository. This means that if you pull in new changes into the submodules, you need to create a new commit in your main repository in order to track the updates of the nested submodules.
The following example shows how to update a submodule to its latest commit in its master branch.
# update submodule in the master branch# skip this if you use --recurse-submodules# and have the master branch checked outcd [submodule directory]git checkout mastergit pull# commit the change in main repo# to use the latest commit in master of the submodulecd ..git add [submodule directory]git commit -m "move submodule to latest commit in master"# share your changesgit push

Another developer can get the update by pulling in the changes and running the submodules update command.
# another developer wants to get the changesgit pull# this updates the submodule to the latest# commit in master as set in the last examplegit submodule update





With this setup you need to create a new commit in the master repository, to use a new state in the submodule. You need to repeat this procedure every time you want to use another state in one of the submodules. See Adding a submodule to a Git repository and tracking a branch for tracking a certain branch of a submodule.







]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>github</tag>
        <tag>submodule</tag>
      </tags>
  </entry>
  <entry>
    <title>svn cleanup 递归清理工作拷贝</title>
    <url>/2020/11/20/git-svn-cleanup/</url>
    <content><![CDATA[svn cleanupsvn cleanup        — 递归清理工作拷贝。
使用方法为：
$ svn cleanup [PATH...]


递归清理工作拷贝，删除未完成的工作拷贝锁定，并恢复未完成的操作。如果你得到一个“工作拷贝已锁定”的错误，运行这个命令可以删除无效的锁定，让你的工作拷贝再次回到可用的状态。
如果，因为一些原因，运行外置的区别程序（例如，用户输入或是网络错误）有时候会导致一个svn update失败，使用--diff3-cmd选项可以完全清除你的外置区别程序所作的合并，你也可以使用--config-dir指定任何配置目录，但是你应该不会经常使用这些选项。
选项--diff3-cmd CMD --config-dir DIR


例子svn cleanup没有输出，没有太多的例子，如果你没有传递*PATH*，会使用“.”。
$ svn cleanup $ svn cleanup /path/to/working-copy]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>svn</tag>
        <tag>cleanup</tag>
      </tags>
  </entry>
  <entry>
    <title>Git svn项目转移到git</title>
    <url>/2019/12/22/git-svn2git/</url>
    <content><![CDATA[Git svn项目转移到gitgit-svn用于Git和SVN的转换,可以把Git仓库迁移成SVN仓库,反之亦可
安装git-svn
$ yum install -y git-svn

创建一个空目录
$ mkdir /opt/git$ cd /opt/git


创建svn用户和git用户对应表
vim userinfo.txt
格式如下
svn用户=git用户&lt;邮箱地址&gt;
例如
Linus=Linus&lt;linus@linux.com&gt;



导出 svn 工程$ git svn clone /the/path/of/svn/repo --authors-file=userinfo.txt

如果出现
Author: XX not defined in userinfo.txt file
那就在userinfo.txt里面添加一个XX用户
重新执行git svn clone命令
其中userinfo.txt的内容可以通过下面的命令获得：
cat log.txt | awk -F '|' '{print $2}' | sort -u | awk '/./{print}' |awk '{print $1 " " $1 " &lt;" $1"@mail&gt;"}' &gt; users.txt

其中log.txt为svn log的内容
上传到 git 服务器
$ cd svn_repo$ git remote add origin /the/path/of/git/repo

用git push命令推送全部的分支和标签信息到git服务器上面
$ git push origin master --tags


登录到gitlab/github，查看更改记录是否存在.
]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>svn</tag>
      </tags>
  </entry>
  <entry>
    <title>Git标签tag相关操作</title>
    <url>/2013/09/07/git-tag/</url>
    <content><![CDATA[如何打标签标签tag主要是在完成了一个版本后，用于发布该版本。
相关的命令如下：
列出标签$ git tag              # 打印出当前仓库的所有标签$ git tag -l '1.0.*'   # 搜索符合模式的标签

创建标签git标签有两种类型：轻量标签和附注标签，创建的方法如下所示：
$ git tag v1.0-light                 # 创建轻量标签，只有一个引用$ git tag -a v1.0 -m 'Release 1.0'   # 创建附注标签，是个独立对象

一般创建都建议是附注标签（虽然轻量标签没有很多参数），搞个引用没有多大意思。
创建附注标签时，参数a即annotated的缩写，指定标签类型，后附标签名。参数m指定标签说明，说明信息会保存在标签对象中。
可以通过git show v1.0来看到标签信息和与之对应的提交信息。
补打标签打标签不必要在head之上，也可在之前的版本上打，这需要你知道某个提交对象的校验和（通过git log获取）。
$ git log --pretty=oneline15027957951b64cf874c3557a0f3547bd83b3ff6 Merge branch 'experiment'a6b4c97498bd301d84096da251c98a07c7723e65 beginning write support0d52aaab4479697da7686c15f77a3d64d9165190 one more thing6d52a271eda8725415634dd79daabbc4d9b6008e Merge branch 'experiment'0b7434d86859cc7b8c3d5e1dddfed66ff742fcbc added a commit function4682c3261057305bdd616e23b64b0857d832627b added a todo file166ae0c4d3f420721acbb115cc33848dfcc2121a started write support9fceb02d0ae598e95dc970b74767f19372d61af8 updated rakefile964f16d36dfccde844893cac5b347e7b3d44abbc commit the todo8a5cbc430f1a9c3d00faaeffd07798508422908a updated readme# 如果此时希望在updated rankfile补打标签，可以通过# git tag -a v0.1.1 校验和$ git tag -a v0.1.1 9fceb02

签署标签如果你有自己的私钥，可以使用GPG来签署标签，只要把-a改为-s即可，也就是signed的意思。
$ git tag -s v0.1.1 校验和

验证标签可以使用
$ git tag -v [tag-name]

的方式来验证已经签署的标签，其中v的意思为verify，此命令会调用GPG来验证签名，所以需要有签署者的公钥，存放在keyring中，才能验证。
后期加注标签如果对早前的那一次提交忘记加注标签了，那么可以使用git log --pretty=oneline来查看提交的HASH ID，然后使用
git tag -a v1.1 HASH-ID
即可补上标签。
切换标签切换标签与切换分支命令一样，是用checkout即可，比如：
$ git checkout v1.0.0    # 注意前提是版本存在，可以是用git tag先检查一下

删除标签不需要或者误操作提交一个标签的时候，删除即可，使用的是delete的缩写
$ git tag -d v1.1.1

删除远程tag这么用：
$ git push origin --delete tagname# 或者$ git push origin :refs/tags/tagname

查看标签信息用git show命令可以查看标签的版本信息：
$ git show v0.1.2
标签发布一般情况下，git push 不会将tag提交到服务端，我们需要显式的操作，如下所示：
$ git push origin [tag-name]$ git push origin v1.1.1  #发布版本v1.1.1$ git push origin -tags   #一次发布所有的tag版本

查看某个标签$ git  tag   		#查看当前分支下的标签$ git  checkout v0.21   	#此时会指向打v0.21标签时的代码状态，（但现在处于一个空的分支上）$ cat  test.txt   	#查看某个文件
]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>tag</tag>
        <tag>push</tag>
        <tag>checkout</tag>
        <tag>show</tag>
      </tags>
  </entry>
  <entry>
    <title>github上更新fork的代码</title>
    <url>/2013/12/01/git-update-fork-repo/</url>
    <content><![CDATA[问题github上有个功能叫fork，可以将别人的工程复制到自己账号下。这个功能很方便，但其有一个缺点是：当源项目更新后，你fork的分支并不会一起更新，需要自己手动去更新。
方法这个需要在命令行里面操作了。

clone 自己账号里fork的分支
 git clone https://github.com/user/test.gitcd sql-parser

查看远程原始分支（可以用 git remote -v 命令查看远程分支列表）
 $ git remote -vorigin	https://github.com/user/test.git (fetch)origin	https://github.com/user/test.git (push)
如果没有远程原始分支则需要增加：
 git remote add upstream https://github.com/another/test.git
查看确认远程分支列表：
git remote -vorigin	https://github.com/user/test.git (fetch)origin	https://github.com/user/test.git (push)upstream	https://github.com/another/test.git (fetch)upstream	https://github.com/another/test.git (push)

fetch原始源分支的新版本到本地 git fetch upstream

合并两个版本的代码
 git merge upstream/master

把最新的代码提交到github自己（user）的账号上
 git push origin master


]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>push</tag>
        <tag>clone</tag>
        <tag>fork</tag>
        <tag>remote</tag>
      </tags>
  </entry>
  <entry>
    <title>Gitbook</title>
    <url>/2014/12/22/gitbook/</url>
    <content><![CDATA[gitbook 转换为pdf文件
确保全局安装gitbook-cli：**npm install gitbook-cli -g**
安装**Calibre**
运行**gitbook pdf ./..path../BookFloder ./..path../xxx.pdf**
运行**gitbook epub ./..path../BookFloder ./..path../xxx.pdf**
运行**gitbook mobi ./..path../BookFloder ./..path../xxx.pdf**

使用node.js制作书籍
安装node.js
npm install gitbook -g
npm install gitbook-cli -g
gitbook init
新建章节文件夹，在SUMMARY.md里建立映射关系
创建book.json，设置参数
gitbook serve 会编译书籍并建立一个临时服务器，可以再浏览器浏览
git来commit和push

InstallRequiredError: “ebook-convert” is not installed.ln -s /Applications/calibre.app/Contents/MacOS/ebook-convert /usr/local/bin
]]></content>
      <categories>
        <category>Git</category>
        <category>Gitbook</category>
      </categories>
      <tags>
        <tag>branch</tag>
        <tag>gitbook</tag>
      </tags>
  </entry>
  <entry>
    <title>git修改远程仓库地址</title>
    <url>/2014/09/07/git-url-modify/</url>
    <content><![CDATA[git修改远程仓库地址有些情况下git的远程地址可能有变动，那么此时就需要修改找个repo地址。
方法有下面三种：
修改命令git remote set-url origin [url]例如：git remote set-url origin new-address.git
先删除再添加git remote rm origingit remote add origin [url]
直接修改config文件打开当前目录的.git/config文件，修改对应的地址即可。
]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>tag</tag>
        <tag>push</tag>
        <tag>checkout</tag>
        <tag>show</tag>
      </tags>
  </entry>
  <entry>
    <title>什么是github</title>
    <url>/2014/12/21/github-introduction/</url>
    <content><![CDATA[什么是github好多人会把git与github搞混淆，两个是截然不同的东西。
git是一套版本管理软件，而github是托管git仓库的平台。
另外github还提供了很多好的特性，比如Pull Request、issue、wiki等等。
方便大家协作开发，共同进步。
]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>github</tag>
      </tags>
  </entry>
  <entry>
    <title>CUDA的安装</title>
    <url>/2018/06/06/gpu-cuda-install/</url>
    <content><![CDATA[[TOC]
NVIDIANvidia显卡驱动安装CentOS7/RHEL安装依赖包
yum -y updateyum -y groupinstall "GNOME Desktop" "Development Tools"yum -y install kernel-devel

下载最新的NVIDIA驱动，==&gt;&nbsp;http://www.nvidia.com/object/unix.html ==&gt;&nbsp;Latest Long Lived Branch version
增加自动内核编辑的选项
yum -y install epel-releaseyum -y install dkms

重新启动系统确保系统使用的为最新的内核版本。
编辑 /etc/default/grub在 “GRUB_CMDLINE_LINUX”增加rd.driver.blacklist=nouveau nouveau.modeset=0
更新包含上述更改的grub文件
grub2-mkconfig -o /boot/grub2/grub.cfg

编辑或创建文件`/etc/modprobe.d/blacklist.conf并增加内容blacklist nouveau
备份旧的initramfs文件并创建一个新的
mv /boot/initramfs-(uname -r).img /boot/initramfs-(uname -r)-nouveau.imgdracut /boot/initramfs-$(uname -r).img $(uname -r)

重启机器，切换到文本模式，systemctl isolate multi-user.target，运行sh NVIDIA-Linux-x86_64-*.run，选项全部选yes即可。
CUDA Toolkit安装Redhat/CentOS下载最新的CUDA Toolkit文件 (run文件，不要下载rpm)==&gt; https://developer.nvidia.com/cuda-downloads ==&gt; Linux ==&gt; x86_64 ==&gt; RHEL/CentOS ==&gt; 7 ==&gt; runfile (local)
sh cuda_*.run在安装NVIDIA driver的时候选no，因为我们已经在前面安装了，一般CUDA内置的会旧一些。其他选项默认即可。
添加环境变量：
$ export PATH=/usr/local/cuda-9.2/bin:$PATH$ export LD_LIBRARY_PATH=/usr/local/cuda-9.2/lib64:$LD_LIBRARY_PATH

过程sudo ./cuda_9.2.88_396.26_linux.run Logging to /tmp/cuda_install_6554.logUsing more to view the EULA.End User License Agreement--------------------------Preface-------The Software License Agreement in Chapter 1 and the Supplementin Chapter 2 contain license terms and conditions that governthe use of NVIDIA software. By accepting this agreement, youagree to comply with all the terms and conditions applicableto the product(s) included herein.NVIDIA DriverDescriptionThis package contains the operating system driver andfundamental system software components for NVIDIA GPUs.NVIDIA CUDA ToolkitDescriptionThe NVIDIA CUDA Toolkit provides command-line and graphicaltools for building, debugging and optimizing the performanceof applications accelerated by NVIDIA GPUs, runtime and mathlibraries, and documentation including programming guides,user manuals, and API references.Default Install Location of CUDA ToolkitWindows platform:%ProgramFiles%\NVIDIA GPU Computing Toolkit\CUDA\v#.#Linux platform:/usr/local/cuda-#.#Mac platform:/Developer/NVIDIA/CUDA-#.#NVIDIA CUDA SamplesDescriptionThis package includes over 100+ CUDA examples that demonstratevarious CUDA programming principles, and efficient CUDAimplementation of algorithms in specific application domains.Default Install Location of CUDA SamplesWindows platform:%ProgramData%\NVIDIA Corporation\CUDA Samples\v#.#Linux platform:/usr/local/cuda-#.#/samplesand$HOME/NVIDIA_CUDA-#.#_SamplesMac platform:/Developer/NVIDIA/CUDA-#.#/samplesNVIDIA Nsight Visual Studio Edition (Windows only)DescriptionNVIDIA Nsight Development Platform, Visual Studio Edition is adevelopment environment integrated into Microsoft VisualStudio that provides tools for debugging, profiling, analyzingand optimizing your GPU computing and graphics applications.Default Install Location of Nsight Visual Studio EditionWindows platform:%ProgramFiles(x86)%\NVIDIA Corporation\Nsight Visual Studio Edition #.#1. NVIDIA Software License Agreement------------------------------------Release Date: October 20, 2016------------------------------IMPORTANT NOTICE -- READ BEFORE DOWNLOADING, INSTALLING,COPYING OR USING THE LICENSED SOFTWARE:--------------------------------------------------------This Software License Agreement ("SLA”), made and enteredinto as of the time and date of click through action(“Effective Date”), is a legal agreement between you andNVIDIA Corporation ("NVIDIA") and governs the use of theNVIDIA computer software and the documentation made availablefor use with such NVIDIA software. By downloading, installing,copying, or otherwise using the NVIDIA software and/ordocumentation, you agree to be bound by the terms of this SLA.If you do not agree to the terms of this SLA, do not download,install, copy or use the NVIDIA software or documentation. IFYOU ARE ENTERING INTO THIS SLA ON BEHALF OF A COMPANY OR OTHERLEGAL ENTITY, YOU REPRESENT THAT YOU HAVE THE LEGAL AUTHORITYTO BIND THE ENTITY TO THIS SLA, IN WHICH CASE “YOU” WILLMEAN THE ENTITY YOU REPRESENT. IF YOU DON’T HAVE SUCHAUTHORITY, OR IF YOU DON’T ACCEPT ALL THE TERMS ANDCONDITIONS OF THIS SLA, THEN NVIDIA DOES NOT AGREE TO LICENSETHE LICENSED SOFTWARE TO YOU, AND YOU MAY NOT DOWNLOAD,INSTALL, COPY OR USE IT.1.1. License1.1.1. License GrantSubject to the terms of the AGREEMENT, NVIDIA hereby grantsyou a non-exclusive, non-transferable license, without theright to sublicense (except as expressly set forth in aSupplement), during the applicable license term unless earlierterminated as provided below, to have Authorized Users installand use the Software, including modifications (if expresslypermitted in a Supplement), in accordance with theDocumentation. You are only licensed to activate and useLicensed Software for which you a have a valid license, evenif during the download or installation you are presented withother product options. No Orders are binding on NVIDIA untilaccepted by NVIDIA. Your Orders are subject to the AGREEMENT.SLA SupplementsCertain Licensed Software licensed under this SLA may besubject to additional terms and conditions that will bepresented to you in a Supplement for acceptance prior to thedelivery of such Licensed Software under this SLA and theapplicable Supplement. Licensed Software will only bedelivered to you upon your acceptance of all applicable terms.1.1.2. Limited Purposes LicensesIf your license is provided for one of the purposes indicatedbelow, then notwithstanding contrary terms in Section 1.1 orin a Supplement, such licenses are for internal use and do notinclude any right or license to sub-license and distribute theLicensed Software or its output in any way in any publicrelease, however limited, and/or in any manner that providesthird parties with use of or access to the Licensed Softwareor its functionality or output, including (but not limited to)external alpha or beta testing or development phases. Further:  1.     Evaluation License: You may use evaluation licenses solely    for your internal evaluation of the Licensed Software for    broader adoption within your Enterprise or in connection    with a NVIDIA product purchase decision, and such licenses    have an expiration date as indicated by NVIDIA in its sole    discretion (or ninety days from the date of download if no    other duration is indicated).  2.     Educational/Academic License: You may use    educational/academic licenses solely for educational    purposes and all users must be enrolled or employed by an    academic institution. If you do not meet NVIDIA’s    academic program requirements for educational    institutions, you have no rights under this license.  3.     Test/Development License. You may use test/development    licenses solely for your internal development, testing    and/or debugging of your software applications or for    interoperability testing with the Licensed Software, and    such licenses have an expiration date as indicated by    NVIDIA in its sole discretion (or one year from the date    of download if no other duration is indicated). NVIDIA    Confidential Information under the AGREEMENT includes    output from Licensed Software developer tools identified    as “Pro” versions, where the output reveals    functionality or performance data pertinent to NVIDIA    hardware or software products.1.1.3. Pre-release LicensesWith respect to alpha, beta, preview, and other pre-releaseSoftware and Documentation (“Pre-Release LicensedSoftware”) delivered to you under the AGREEMENT youacknowledge and agree that such Pre-Release Licensed Software(i) may not be fully functional, may contain errors or designflaws, and may have reduced or different security, privacy,accessibility, availability, and reliability standardsrelative to commercially provided NVIDIA software anddocumentation, and (ii) use of such Pre-Release LicensedSoftware may result in unexpected results, loss of data,project delays or other unpredictable damage or loss.THEREFORE, PRE-RELEASE LICENSED SOFTWARE IS NOT INTENDED FORUSE, AND SHOULD NOT BE USED, IN PRODUCTION ORBUSINESS-CRITICAL SYSTEMS. NVIDIA has no obligation to makeavailable a commercial version of any Pre-Release LicensedSoftware and NVIDIA has the right to abandon development ofPre-Release Licensed Software at any time without liability.1.1.4. Enterprise and Contractor UsageYou may allow your Enterprise employees and Contractors toaccess and use the Licensed Software pursuant to the terms ofthe AGREEMENT solely to perform work on your behalf, providedfurther that with respect to Contractors: (i) you obtain awritten agreement from each Contractor which contains termsand obligations with respect to access to and use of LicensedSoftware no less protective of NVIDIA than those set forth inthe AGREEMENT, and (ii) such Contractor’s access and useexpressly excludes any sublicensing or distribution rights forthe Licensed Software. You are responsible for the compliancewith the terms and conditions of the AGREEMENT by yourEnterprise and Contractors. Any act or omission that, ifcommitted by you, would constitute a breach of the AGREEMENTshall be deemed to constitute a breach of the AGREEMENT ifcommitted by your Enterprise or Contractors.1.1.5. ServicesExcept as expressly indicated in an Order, NVIDIA is under noobligation to provide support for the Licensed Software or toprovide any patches, maintenance, updates or upgrades underthe AGREEMENT. Unless patches, maintenance, updates orupgrades are provided with their separate governing terms andconditions, they constitute Licensed Software licensed to youunder the AGREEMENT.1.2. Limitations1.2.1. License RestrictionsExcept as expressly authorized in the AGREEMENT, you agreethat you will not (nor authorize third parties to): (i) copyand use Software that was licensed to you for use in one ormore NVIDIA hardware products in other unlicensed products(provided that copies solely for backup purposes are allowed);(ii) reverse engineer, decompile, disassemble (except to theextent applicable laws specifically require that suchactivities be permitted) or attempt to derive the source code,underlying ideas, algorithm or structure of Software providedto you in object code form; (iii) sell, transfer, assign,distribute, rent, loan, lease, sublicense or otherwise makeavailable the Licensed Software or its functionality to thirdparties (a) as an application services provider or servicebureau, (b) by operating hosted/virtual system environments,(c) by hosting, time sharing or providing any other type ofservices, or (d) otherwise by means of the internet; (iv)modify, translate or otherwise create any derivative works ofany Licensed Software; (v) remove, alter, cover or obscure anyproprietary notice that appears on or with the LicensedSoftware or any copies thereof; (vi) use the LicensedSoftware, or allow its use, transfer, transmission or exportin violation of any applicable export control laws, rules orregulations; (vii) distribute, permit access to, or sublicensethe Licensed Software as a stand-alone product; (viii) bypass,disable, circumvent or remove any form of copy protection,encryption, security or digital rights management orauthentication mechanism used by NVIDIA in connection with theLicensed Software, or use the Licensed Software together withany authorization code, serial number, or other copyprotection device not supplied by NVIDIA directly or throughan authorized reseller; (ix) use the Licensed Software for thepurpose of developing competing products or technologies orassisting a third party in such activities; (x) use theLicensed Software with any system or application where the useor failure of such system or application can reasonably beexpected to threaten or result in personal injury, death, orcatastrophic loss including, without limitation, use inconnection with any nuclear, avionics, navigation, military,medical, life support or other life critical application(“Critical Applications”), unless the parties have enteredinto a Critical Applications agreement; (xi) distribute anymodification or derivative work you make to the LicensedSoftware under or by reference to the same name as used byNVIDIA; or (xii) use the Licensed Software in any manner thatwould cause the Licensed Software to become subject to an OpenSource License. Nothing in the AGREEMENT shall be construed togive you a right to use, or otherwise obtain access to, anysource code from which the Software or any portion thereof iscompiled or interpreted. You acknowledge that NVIDIA does notdesign, test, manufacture or certify the Licensed Software foruse in the context of a Critical Application and NVIDIA shallnot be liable to you or any third party, in whole or in part,for any claims or damages arising from such use. You agree todefend, indemnify and hold harmless NVIDIA and its Affiliates,and their respective employees, contractors, agents, officersand directors, from and against any and all claims, damages,obligations, losses, liabilities, costs or debt, fines,restitutions and expenses (including but not limited toattorney’s fees and costs incident to establishing the rightof indemnification) arising out of or related to you and yourEnterprise, and their respective employees, contractors,agents, distributors, resellers, end users, officers anddirectors use of Licensed Software outside of the scope of theAGREEMENT or any other breach of the terms of the AGREEMENT.1.2.2. Third Party License ObligationsYou acknowledge and agree that the Licensed Software mayinclude or incorporate third party technology (collectively“Third Party Components”), which is provided for use in orwith the Software and not otherwise used separately. If theLicensed Software includes or incorporates Third PartyComponents, then the third-party pass-through terms andconditions (“Third Party Terms”) for the particular ThirdParty Component will be bundled with the Software or otherwisemade available online as indicated by NVIDIA and will beincorporated by reference into the AGREEMENT. In the event ofany conflict between the terms in the AGREEMENT and the ThirdParty Terms, the Third Party Terms shall govern. Copyright toThird Party Components are held by the copyright holdersindicated in the copyright notices indicated in the ThirdParty Terms.Audio/Video Encoders and DecodersYou acknowledge and agree that it is your sole responsibilityto obtain any additional third party licenses required tomake, have made, use, have used, sell, import, and offer forsale your products or services that include or incorporate anyThird Party Components and content relating to audio and/orvideo encoders and decoders from, including but not limitedto, Microsoft, Thomson, Fraunhofer IIS, Sisvel S.p.A.,MPEG-LA, and Coding Technologies as NVIDIA does not grant toyou under the AGREEMENT any necessary patent or other rightswith respect to audio and/or video encoders and decoders.1.2.3. Limited RightsYour rights in the Licensed Software are limited to thoseexpressly granted under the AGREEMENT and no other licensesare granted whether by implication, estoppel or otherwise.NVIDIA reserves all rights, title and interest in and to theLicensed Software not expressly granted under the AGREEMENT.1.3. ConfidentialityNeither party will use the other party’s ConfidentialInformation, except as necessary for the performance of theAGREEMENT, nor will either party disclose such ConfidentialInformation to any third party, except to personnel of NVIDIAand its Affiliates, you, your Enterprise, your EnterpriseContractors, and each party’s legal and financial advisorsthat have a need to know such Confidential Information for theperformance of the AGREEMENT, provided that each suchpersonnel, employee and Contractor is subject to a writtenagreement that includes confidentiality obligations consistentwith those set forth herein. Each party will use allreasonable efforts to maintain the confidentiality of all ofthe other party’s Confidential Information in its possessionor control, but in no event less than the efforts that itordinarily uses with respect to its own ConfidentialInformation of similar nature and importance. The foregoingobligations will not restrict either party from disclosing theother party’s Confidential Information or the terms andconditions of the AGREEMENT as required under applicablesecurities regulations or pursuant to the order or requirementof a court, administrative agency, or other governmental body,provided that the party required to make such disclosure (i)gives reasonable notice to the other party to enable it tocontest such order or requirement prior to its disclosure(whether through protective orders or otherwise), (ii) usesreasonable effort to obtain confidential treatment or similarprotection to the fullest extent possible to avoid such publicdisclosure, and (iii) discloses only the minimum amount ofinformation necessary to comply with such requirements.1.4. OwnershipYou are not obligated to disclose to NVIDIA any modificationsthat you, your Enterprise or your Contractors make to theLicensed Software as permitted under the AGREEMENT. As betweenthe parties, all modifications are owned by NVIDIA andlicensed to you under the AGREEMENT unless otherwise expresslyprovided in a Supplement. The Licensed Software and allmodifications owned by NVIDIA, and the respective IntellectualProperty Rights therein, are and will remain the sole andexclusive property of NVIDIA or its licensors, whether theLicensed Software is separate from or combined with any otherproducts or materials. You shall not engage in any act oromission that would impair NVIDIA’s and/or its licensors’Intellectual Property Rights in the Licensed Software or anyDo you accept the previously read EULA?accept/decline/quit: acceptInstall NVIDIA Accelerated Graphics Driver for Linux-x86_64 396.26?(y)es/(n)o/(q)uit: yDo you want to install the OpenGL libraries?(y)es/(n)o/(q)uit [ default is yes ]: Do you want to run nvidia-xconfig?This will update the system X configuration file so that the NVIDIA X driveris used. The pre-existing X configuration file will be backed up.This option should not be used on systems that require a customX configuration, such as systems with multiple GPU vendors.(y)es/(n)o/(q)uit [ default is no ]: yInstall the CUDA 9.2 Toolkit?(y)es/(n)o/(q)uit: yEnter Toolkit Location [ default is /usr/local/cuda-9.2 ]: Do you want to install a symbolic link at /usr/local/cuda?(y)es/(n)o/(q)uit: yInstall the CUDA 9.2 Samples?(y)es/(n)o/(q)uit: yEnter CUDA Samples Location [ default is /home/leo ]: /home/leo/cuda-exampleInstalling the NVIDIA display driver...Installing the CUDA Toolkit in /usr/local/cuda-9.2 ...Missing recommended library: libGLU.soMissing recommended library: libXi.soMissing recommended library: libXmu.soInstalling the CUDA Samples in /home/leo/cuda-example ...Copying samples to /home/leo/cuda-example/NVIDIA_CUDA-9.2_Samples now...Finished copying samples.============ Summary ============Driver:   InstalledToolkit:  Installed in /usr/local/cuda-9.2Samples:  Installed in /home/leo/cuda-example, but missing recommended librariesPlease make sure that -   PATH includes /usr/local/cuda-9.2/bin -   LD_LIBRARY_PATH includes /usr/local/cuda-9.2/lib64, or, add /usr/local/cuda-9.2/lib64 to /etc/ld.so.conf and run ldconfig as rootTo uninstall the CUDA Toolkit, run the uninstall script in /usr/local/cuda-9.2/binTo uninstall the NVIDIA Driver, run nvidia-uninstallPlease see CUDA_Installation_Guide_Linux.pdf in /usr/local/cuda-9.2/doc/pdf for detailed information on setting up CUDA.Logfile is /tmp/cuda_install_6554.log



问题集锦
ERROR: Unable to load the ‘nvidia-drm’ kernel module.


One probable reason is that the system is boot from UEFI but Secure Boot option is turned on in the BIOS setting. Turn it off and the problem will be solved.


Error: You Appear To Be Running An X Server; Please Exit X Before Installing1.按住CTRL+ALT+F1 进入命令行2.sudo service lightdm stop    或者   sudo stop lightdm3.sudo init 34.安装驱动程序：＃:  sudo ./NVIDIA-Linux-x86_64-177.67-pkg2.run //当前目录下执行NVIDIA驱动程序5.按照提示安装完成，简单方法重启就好了     sudo  reboot

]]></content>
      <categories>
        <category>GPU</category>
      </categories>
      <tags>
        <tag>cuda</tag>
        <tag>gpu</tag>
      </tags>
  </entry>
  <entry>
    <title>IE 再见</title>
    <url>/2015/03/20/ie-goodbye/</url>
    <content><![CDATA[IE 再见微软内部已经正式放弃了 Internet Explorer 的后续迭代工作，全力开发代号为 Spartan 的新一代浏览器。微软表示，将于今夏上市的 Windows 10 系统的部分版本中仍将内置 Internet Explorer，主要用于企业级用户的兼容性工作。Windows 10 系统中的主力将是「Spartan」浏览器。
较于Chrome、Firefox，相比之下，Internet Explorer 就好像一台跑不动的老古董。自 1995 年伴随 Windows 95 面世以来，Internet Explorer 的峥嵘岁月完全可以写本书了。得益于 Windows 的市场份额和绑定策略，Internet Explorer 轻松干掉了曾经的浏览器先锋 NetScape；可添加 Active 控件为广告和病毒提供可乘之机的同时，却又成为网银发展的先决条件；对 HTML 5 支持不良以及慢吞吞的加载速度终究让 Internet Explorer 败给了 Webkit 阵营，更不要提 Chrome 强大的扩展组件了。

是时候说再见了，Internet Explorer，这次是真的再也不见。这次再见说了好多年。

至少曾经爱过~
]]></content>
      <categories>
        <category>Windows</category>
      </categories>
      <tags>
        <tag>Windows</tag>
        <tag>IE</tag>
        <tag>Chrome</tag>
        <tag>Firefox</tag>
        <tag>HTML</tag>
      </tags>
  </entry>
  <entry>
    <title>Intel Virtualization Technology虚拟化技术</title>
    <url>/2011/11/01/intel-vt-technology/</url>
    <content><![CDATA[[TOC]
Intel Virtualization Technology虚拟化技术为什么会设计到Intel VT在使用VirtualBox安装64位的CentOS的时候提示是否开启了该选项。
开启方法，进入BIOS，在Advanced中有选项Intel Virtualization Technology，使其Enabled即可。Intel Virtualization Technology有什么实在的用处呢，最简单来说就是可以使虚拟机的运行速度几乎接近实体机器的水平
Intel VT虚拟化技术的作用：1、在开启VT时，能够提高虚拟机软件（VMWare，MS Virtual server等）所产生的虚拟机的内存和磁盘性能，对CPU性能的提升不明显！2、只有在开启VT后，才能够在32位的操作系统中（如XP，Vista）虚拟出64位的操作体统（如64-bit XP等）。
不开启VT，32位系统不能虚拟出64位系统。这点对于日常使用32位系统，偶尔使用64位系统的用户很有用！！
用户如何选择CPU对VT的支持与否？1、如果你只是使用单一操作系统，如XP，Vista，没有机会使用虚拟机，那么VT对你毫无用处！！还不如选择不支持VT的CPU，省钱！！2、如果你需要使用虚拟机，不管是VMWare，还是MSVS2005，使用支持VT的CPU都能够提高虚拟机的性能，特别是磁盘和内存性能。应该选支持VT的CPU，何况也贵不了多少钱！呵呵
下面参考文章的重点信息1、VMware在不支持Intel VT的IA32架构CPU上无法虚拟64-bit客户操作系统，因为无法在客户OS之间安全地隔离。2、我们谈到了目前IA32架构采用Ring等级带来的虚拟化难题，自然而言地，我们可以预料到Intel Virtualization Technology可以解决这些问题。　　不错，Intel VT就是为此而生。作为一个芯片辅助（Chip-Assisted）的虚拟化技术，VT可以同时提升虚拟化效率和虚拟机的安全性，下面我们就来看看 Intel VT带来了什么架构上的变迁。我们谈论的主要是IA32上的VT技术，一般称之为VT-x，而在Itanium平台上的VT技术，被称之为VT-i。
3、主流的虚拟机软件都开始支持x86虚拟化技术了——包括Intel VT和AMD-V。
4、 软件虚拟化领域的巨头VMware的产品是完全虚拟化的著名例子，一般的VMware Workstation和VMware Server都属于Hosted Architecture寄居架构，而企业级产品VMware ESX Server则属于Bare Metal Architecture裸金属架构，这种架构在商业化产品上很难得，可以充分地发挥硬件的威力。我们使用VMware Server的原因是：易于使用。ESX Server难以配置。VMware Server包含了很多组件。强大的网络功能是VMware的特色：两个VMware虚拟网卡。VMware可以实现非常复杂的虚拟化网络环境。
5、Microsoft Virtual Server 2005 R2发布也有了一段时日，虽然仍不如VMware完善，不过提供了一些VMware不能提供的有趣特性。
6、Intel方只有在支持VT的CPU上才能安装64-bit客户操作系统。
7、同时运行两个虚拟机，VMware就建立两个VMware Server VMX进程。每个虚拟机虚拟了两个CPU，因此每个VMware Server VMX进程就具有两个虚拟CPU线程，并分布在我们硬件的两个CPU核心上。
8、 我们分别在Window Server 2003 R2 Enterprise Edition SP2的32bit和64bit环境下进行了测试——主机操作系统和客户操作系统都分别采用了这两种操作系统，并再分别测试了VT和无VT下的表现。主机 的性能也进行了测试。（详细测试数据参看原文）
9、CPU性能　　在仅运行单个虚拟机的情况下，理论测试表明，在32bit主机操作系统下打开VT并没有性能上的优势——64bit下则相反，打开VT可以获得更好的CPU性能。　　虽然VMware虚拟出来的显卡并不能支持“硬件”3D操作，不过OpenGL仍然可以运行，我们可以看出其虚拟OpenGL运行的性能非常之低，这时VT在32bit下的CPU表现不错。　　总体而言，VT在CPU性能上没有显示出什么特别的地方，看来VT须要在更大的虚拟机负荷下才能表现出其性能上的优势。
10、内存性能　　由于虚拟架构改变，VT下的内存性能表现非常好，如WinRAR这样的成绩非常突出。
11、磁盘性能　　虚拟机情况下的磁盘性能非常之强劲，这是因为相关的数据很容易地就可以缓冲的缘故，这需要大量的内存支持。　　这是我们虚拟机所在的硬盘HD Tach RW测试成绩，虚拟机的虚拟磁盘都位于这个WD3200YS的前端。
　　32bit Host OS/32bit Guest OS，VT打开下的HD Tach RW，读写速度和WDC3200YS前段速度一致，而突发速率则要高出不少。
　　32bit Host OS/64bit Guest OS下的突发传输更快，达到了349.1MB/s，这实际上表现了64bit系统比32bit系统的内存性能更加强劲。
　　64bit Host OS/32bit Guest OS，没有打开VT的情况下，也能提供很不错的突发速度：300.5MB/s。
　　64bit Host OS/32bit Guest，打开VT之后与上面对比，突发略有下降。
64bit性能
　　毫无疑问，64bit下可以提供更好的CPU性能、内存性能。
12、 由于使用了负荷并不算强的理论测试软件，因此仅能测试架构带来的理论性能表现：CPU理论性能方面并无太大差别，而内存性能则使用VT后具有明显的提升。 同时，Intel的Long模式64bit无法提供内存隔离所需要的足够保护措施，而通过Intel VT技术，则能解决这个问题，因此Intel CPU只有具有VT技术的时候才能运行64bit虚拟机。更好的隔离性或许用户一眼无法看到，然而当客户操作系统异常崩溃的时候，你才可以感觉到它的用处。在3~4个虚拟机的普通CPU负载下，VMware有望从芯片辅助的虚拟化技术中获益，我们期望在下一篇文章中对ESX Server 3.0进行测试，ESX看起来可以充分利用新的处理器特性，应该会有大量的性能提升。
参考文章为：http://pc.sanhaostreet.com/NewsData/2007/6/20076261759506061.shtml
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>BIOS</tag>
        <tag>Intel</tag>
        <tag>VT</tag>
        <tag>VMvare</tag>
        <tag>VirtualBox</tag>
      </tags>
  </entry>
  <entry>
    <title>LaTex 排版流程</title>
    <url>/2010/01/23/latex-process/</url>
    <content><![CDATA[LaTeX排版流程在使用LaTeX进行排版时，从输入文本到最后在打印机上得到输出结果，通常需要经过下面的几个步骤。
编辑用编辑器编写文稿（源文件），同时插入排版命令。需要注意的是，源文件必须是纯文本格式的，并且通常以.tex作为其扩展名（如hello.tex）。在Linux下建议使用XEmacs或者VIM编辑器，它们都能够识别LaTeX语法并且可以高亮显示LaTeX命令中的关键字。
编译生成的LaTeX源文件中如果没有语法错误，那么就可以使用latex命令进行编译，生成DVI文件：
[leo@localhost latex]$ latex hello.tex
在处理过程中LaTeX会显示页号以及可能会有的错误和警告信息，如果在该过程中出现错误，则表明源文件中的某些排版命令有误，此时应该重新对源文件进行修改。当LaTeX成功结束这一处理过程后，将生成一个名为hello.dvi的文件，该文件是与设备无关的，它由格式化后的文本以及所需要的字体信息组成，但是与要使用的打印机的特征无关，该文件通常也称为元文件（metafile）。
查看在正式打印输出或者照排制版之前，可以先在计算机屏幕上显示DVI文件，察看文件内容或者排版结果是否合乎要求，如果有不满意之外，则应重新对LaTeX源文件进行修改。在Linux下有许多软件可以用来查看DVI文件，其中最常用的是X-Window环境下的xdvi，下面的命令可以用来查看hello.dvi： [leo@localhost latex]$ xdvi hello.dvi 由于DVI文件是与设备无关的，因而用xdvi在屏幕上看到的结果是不会受到输出设备、操作系统、硬件环境等因素影响的。
打印DVI元文件中的信息最终要被转化成可以在特定打印机上输出的形式，该过程是由一个称为打印驱动程序来完成的，它是与具体打印机相关的。例如，在Linux下可以用下面的命令将hello.dvi送到惠普激光打印机上打印：
[leo@localhost latex]$ dvihp hello.dvi
输出在很多场合下，使用latex得到的DVI文件并不总是需要打印出来，而是要转化成更加便于阅读的格式，如PDF（Portable Document Format）或者PS（PostScript），LaTeX系统提供了相应的工具在这些格式之间进行转换。要将hello.dvi转化成hello.pdf和hello.ps，可以分别使用如下的命令：
[leo@localhost latex]$ dvipdf hello.dvi
[leo@localhost latex]$ dvips hello.dvi -o
]]></content>
      <categories>
        <category>LaTex</category>
      </categories>
      <tags>
        <tag>latex</tag>
        <tag>dvihp</tag>
        <tag>xdvi</tag>
        <tag>dvips</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux aio异步读写</title>
    <url>/2015/10/23/linux-aio/</url>
    <content><![CDATA[[TOC]
linux下aio异步读写为什么会有异步I/Oaio异步读写是在linux内核2.6之后才正式纳入其标准。之所以会增加此模块，是因为众所周知我们计算机CPU的执行速度远大于I/O读写的执行速度，如果我们用传统的阻塞式或非阻塞式来操作I/O的话，那么我们在同一个程序中(不用多线程或多进程)就不能同时操作俩个以上的文件I/O，每次只能对一个文件进行I/O操作，很明显这样效率很低下(因为CPU速度远大于I/O操作的速度，所以当执行I/O时，CPU其实还可以做更多的事)。因此就诞生了相对高效的异步I/O
2.异步I/O的基本概念所谓异步I/O即我们在调用I/O操作时(读或写)我们的程序不会阻塞在当前位置，而是在继续往下执行。例如当我们调用异步读API aio_read()时，程序执行此代码之后会接着运行此函数下面的代码，并且与此同时程序也在进行刚才所要读的文件的读取工作，但是具体什么时候读完是不确定的
3.异步aio的基本API


API函数
说明



aio_read
异步读操作


aio_write
异步写操作


aio_error
检查异步请求的状态


aio_return
获得异步请求完成时的返回值


aio_suspend
挂起调用进程，直到一个或多个异步请求已完成


aio_cancel
取消异步请求


lio_list
发起一系列异步I/O请求


并发与并行你吃饭吃到一半，电话来了，你一直到吃完了以后才去接，这就说明你不支持并发也不支持并行。你吃饭吃到一半，电话来了，你停了下来接了电话，接完后继续吃饭，这说明你支持并发。你吃饭吃到一半，电话来了，你一边打电话一边吃饭，这说明你支持并行。
并发的关键是你有处理多个任务的能力，不一定要同时。并行的关键是你有同时处理多个任务的能力。
所以我认为它们最关键的点就是：是否是『同时』。
并发与并行的区别：

并发和并行都可以是很多线程，就看这些线程能不能被多个CPU执行，如果可以就是并行，而并发是多个线程被一个CPU轮流切换着执行。
顺序：上一个任务完成后，才能执行当前任务
并发：无论上一个任务是否完成，当前任务就可以开始

串行：有一个任务执行单元，物理上只能一个任务、一个任务地执行

并行：有多个任务执行单元，物理上可以多个任务一起执行

OpenMP：一个job凤城若干个部分，分给不同的processor去做，每个process又可以多线程去完成任务
MPI：Master节点把job分成若干个部分，分给其他slave和自己去run，可能会涉及到node之间的message passing，比如node A完成以后在开始node B



异步：a synchronized，类似UDP
同步：synchronize，类似TCP
多线程：同时做N件事情
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>aio</tag>
        <tag>aio_read</tag>
        <tag>aio_write</tag>
      </tags>
  </entry>
  <entry>
    <title>别有一番风趣的alias</title>
    <url>/2011/02/12/linux-alias-beginner/</url>
    <content><![CDATA[别有一番风趣的alias.. _linux_alias_beginner:
.. note::  寒蝉凄切，对长亭晚，骤雨初歇。  柳永《雨霖铃》
Linux alias命令用于设置指令的别名，可以将比较长的命令进行简化。
默认情况下会输出当前的设置：
$ aliasl='ls -lah'la='ls -lAh'll='ls -lh'ls='ls --color=tty'



所以此时输入ll以后，就相当于输入了ls -lh。
给命令设置别名也很简单，方法为：
$ alias newcommand='command setting'

比如：
$ alias ll='ls -lh' # 相当的实用

不过需要注意的时，这个命令如果在终端操作，关闭后并不会保持。
如果需要每次都可以使用，需要将这个命令输入到.bashrc中。
比较常用的一些为：
$ alias alias cp='cp -i' alias l.='ls -d .* --color=tty' alias ll='ls -l --color=tty' alias ls='ls --color=tty' alias mv='mv -i' alias rm='rm -i' alias which='alias | /usr/bin/which --tty-only --read-alias --show-dot --show-tilde  #对路径切换很有用$ alias ..='cd ..'$ alias ...='cd ../../../'$ alias ....='cd ../../../../'$ alias .....='cd ../../../../'$ alias .4='cd ../../../../'$ alias .5='cd ../../../../..'#获取disk的信息##$ alias df='df -H'$ alias du='du -ch'#设置一些系统信息$ alias cpuinfo='lscpu'$ alias meminfo='free -h'



在比如一个稍微复杂一点的：
$ alias lt='ls --human-readable --size -1 -S --classify'

lt将排序并显示一个总的文件大小。

当前，可以设定alias，也可以清除，只要使用unalias即可。

]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>alias</tag>
        <tag>unalias</tag>
        <tag>系统设置</tag>
      </tags>
  </entry>
  <entry>
    <title>anjuta的安装、配置以及第一个hello程序</title>
    <url>/2011/05/22/linux-anjuta/</url>
    <content><![CDATA[安装Anjuta$ sudo apt-get install anjuta


安装GUI开发包安装图形接口和本地化等开发包。
$ sudo apt-get install libglademm-2.4-dev libgnomemm-2.6-dev intltool

其中，intltool是为了支持国际化/本地化，并将同时安装gettext包。
编码提示和自动补全edit-&gt;preferences-&gt;c/c++/java/vala-&gt;autocompleteenable smart brace completion

安装API文档安装开发中常用的API文档，及查看器DevHelp（因libdevhelp的问题，Anjuta 的 “API帮助”插件不能工作）。
$ sudo apt-get install devhelp libgtkmm-2.4-doc libcairomm-1.0-doc libglib2.0-doc libgnome2-doc libsigc++-2.0-doc

解决依赖为让Anjuta能自动配置、编译、和更好的工作，我们需要安装一些必要的工具包，比如，本地化的”intltool”；自动格式的”indent”。在“终端”执行以下命令：
$ sudo apt-get install autogen automake build-essential indent intltool

这样能避免出现不能新建项目、编译，以及下面这类运行时错误（其它可能还有autoconf, automake等）。
代码:
Unable to exec g++.real: No such file or directorymake: *** [main.o] 错误 2Completed… unsuccessful
注：Ubuntu 8.04 出现的”anjuta不能build” 问题，可加装libtool(apt-get install libtool) 解决。感谢 russell18721970 提供！（于2008-8-31）安装完成后要重启X（即登出再重新登录），Anjuta的部分图标才能完全正常显示。怪异 =_=||
写个Hello World 的C++程序1。打开Anjuta：点击主菜单上的“应用程序”》“编程”》“Anjuta IDE”。2。建立项目：在Anjuta中点击菜单，“文件”》“新建”》“Project”。出现“应用程序向导”，点“前进”；工程类型选“C++”中的“Generic C++”（附图anjuta-1.png），之后点“前进”；“前进”；工程选项(Project Options)中，全选“否”，再点“前进”，应用即可。3。查看源码：点左侧“工程”按钮，切换到“工程”选项卡。点工程名“foobar-cpp”,双击“main.cc”打开它.4。编译运行：可以看到，main() 函数已预先写好了。我们按下“F9”编译，再按“F3”就能运行了！（这两个快捷键对应菜单在“生成”菜单下。）安装C/C++开发文档在编程的过程中有时会记不得某个函数的用法，通常这时查man手册是比较快的，所以把这个manpages-dev软件包安装上。想要看某个函数的用法就man它。执行安装命令：
$ sudo apt-get install manpages-dev

更新一下索引
~$ mandb -c

然后，就可以查看这些文档了。比如，fopen的：
代码:
~$ man fopen
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>anjuta</tag>
        <tag>api</tag>
      </tags>
  </entry>
  <entry>
    <title>刚刚好合适的 apropos 命令</title>
    <url>/2015/04/17/linux-apropos-beginner/</url>
    <content><![CDATA[刚刚好合适的 apropos 命令.. _linux_apropos_beginner:
.. note::  旧时月色，算几番照我，梅边吹笛。  宋·姜夔《暗香》
apropos的中文含义就是恰好的、合适的，奈何这个单词或者命令确实不好记，当然是可以扩充词汇量的。
什么时候会用到这个命令呢，先看看这个命令的定义。
apropos 命令的官方定义为:

 search the manual page names and descriptions

意思很明显，如果我不记得命令或者不知道该用什么命令的时候，可以通过关键词来索引查找这些命令，比如我们想用linux绘制图像，但是不知道什么命令，测试可以使用：
$ apropos plotbno_plot (1) – generate interactive 3D plot of IO blocks and sizes gnuplot (1) – an interactive plotting program pbmtoplot (1) – convert a PBM image into a Unix 'plot' file


或许每个人的输出不同，这个主要取决于安装的软件包和索引的数据库。以上。

再来一个实例，这个应该大部分的都类似：
$ apropos whoat.allow (5)         - determine who can submit jobs via at or batchat.deny (5)          - determine who can submit jobs via at or batchbtrfs-filesystem (8) - command group of btrfs that usually work on the whole filesystemdocker-trust-signer (1) - Manage entities who can sign Docker imagesipsec_newhostkey (8) - generate a new raw RSA authentication key for a hostipsec_showhostkey (8) - show host's authentication keyw (1)                - Show who is logged on and what they are doing.who (1)              - show who is logged onwho (1p)             - display who is on the systemwhoami (1)           - print effective userid




 这个命令平时用的不多，跟whatis类似，因为这些功能都被加到了包罗万象的man命令。

]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>apropos</tag>
        <tag>man</tag>
        <tag>帮助命令</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux apropos命令</title>
    <url>/2015/04/17/linux-apropos/</url>
    <content><![CDATA[apropos 显示合适的一些命令apropos的中文含义就是恰好的、合适的，奈何这个单词或者命令确实不好记，当然是可以扩充词汇量的。
什么时候会用到这个命令呢，先看看这个命令的定义。
apropos 命令的官方定义为:

 search the manual page names and descriptions

意思很明显，如果我不记得命令或者不知道该用什么命令的时候，可以通过关键词来索引查找这些命令，比如我们想用linux绘制图像，但是不知道什么命令，测试可以使用：
$ apropos plotbno_plot (1) – generate interactive 3D plot of IO blocks and sizes gnuplot (1) – an interactive plotting program pbmtoplot (1) – convert a PBM image into a Unix 'plot' file


或许每个人的输出不同，这个主要取决于安装的软件包和索引的数据库。以上。

再来一个实例，这个应该大部分的都类似：
$ apropos whoat.allow (5)         - determine who can submit jobs via at or batchat.deny (5)          - determine who can submit jobs via at or batchbtrfs-filesystem (8) - command group of btrfs that usually work on the whole filesystemdocker-trust-signer (1) - Manage entities who can sign Docker imagesipsec_newhostkey (8) - generate a new raw RSA authentication key for a hostipsec_showhostkey (8) - show host's authentication keyw (1)                - Show who is logged on and what they are doing.who (1)              - show who is logged onwho (1p)             - display who is on the systemwhoami (1)           - print effective userid




 这个命令平时用的不多，跟whatis类似，因为这些功能都被加到了包罗万象的man命令。

]]></content>
      <categories>
        <category>Linux</category>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>apropos</tag>
        <tag>man</tag>
      </tags>
  </entry>
  <entry>
    <title>软件管理利器  - Debian系的apt</title>
    <url>/2012/03/12/linux-apt-beginner/</url>
    <content><![CDATA[软件管理利器  - Debian系的apt.. _linux_apt_beginner:
.. note::  当年不肯嫁春风，无端却被秋风误。  贺铸《芳心苦·杨柳回塘》
对于最常用的命令而言，apt可能排不上号，但是，在新安装的系统中，apt 命令绝对应该是排在前十位的存在，所以apt是管理 Debian 系列系统中软件包的必备工具。

apt - command-line interface

apt是Advanced Package Tool的缩写，恰如字面描述高级包工具，apt 命令是用于 Debian 系列 Linux 发行版的强大工具，比如广为人知的Ubuntu，还有超赞桌面的Linux Mint。
apt使得处理软件包，比如安装、更新和删除软件包的过程特别丝滑，也结合了较早的工具如 apt-get 和 apt-cache 的功能，提供了更友好的交互体验。
更新软件包列表在安装或升级软件包之前，可以更新软件包列表，以确保拥有可用软件包的最新信息。
使用以下命令：
$ sudo apt update

此命令从配置的仓库中获取最新的软件包信息。
升级软件包要将所有已安装的软件包升级到最新版本，可以使用：
$ sudo apt upgrade

要进行更全面的升级，包括删除旧软件包和安装新依赖项，请使用：
$ sudo apt full-upgrade # 特别留意，这个会把老版本给删除

安装软件包apt 命令使得软件包安装变得非常简单。要安装一个软件包，只需要使用：
$ sudo apt install &lt;软件包名称&gt;

例如，要安装文本编辑器瑞士军刀 vim，您可以运行：
$ sudo apt install vim

删除软件包卸载软件包同样简单。要删除一个软件包，使用：
$ sudo apt remove &lt;软件包名称&gt;

如果您想删除软件包及其配置文件，使用：
$ sudo apt purge &lt;软件包名称&gt;

搜索软件包要查找某个软件包，可以使用关键词进行搜索：
$ apt search &lt;关键词&gt;

例如，要搜索与 “python” 相关的软件包，您可以运行：
$ apt search python

显示软件包信息要查看特定软件包的详细信息，使用：
$ apt show &lt;软件包名称&gt;

此命令提供软件包描述、依赖关系和版本信息等详细信息。
清理随着时间的推移，积累过时的软件包和缓存文件。要清理不必要的软件包，使用：
$ sudo apt autoremove

要清除本地存储库中获取的包文件，使用：
$ sudo apt clean

管理仓库apt 获取软件包信息的仓库列表存储在 /etc/apt/sources.list 及 /etc/apt/sources.list.d/ 目录下的文件中。
要添加新的仓库，可以直接编辑这些文件或使用 add-apt-repository 命令：
$ sudo add-apt-repository ppa:&lt;仓库名称&gt;

添加仓库后，需要更新软件包列表才能使用：
$ sudo apt update
]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>apt</tag>
        <tag>software</tag>
        <tag>Debian</tag>
        <tag>必备命令</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux Automake 1 简介</title>
    <url>/2018/03/06/linux-automake-1-introduction/</url>
    <content><![CDATA[
GNU Automake 版本(version 1.16.1, 26 February 2018)
Permission is granted to copy, distribute and/or modify thisdocument under the terms of the GNU Free Documentation License,Version 1.3 or any later version published by the Free SoftwareFoundation; with no Invariant Sections, with no Front-Cover texts,and with no Back-Cover Texts.  A copy of the license is included inthe section entitled “GNU Free Documentation License.”

简介Automake从文件Makefile.am中自动生成Makefile.in。
Makefile.am基本由make的一系列变量定义组成。
按照GNU Makefile的标准生成 ‘Makefile.in’十分复杂，而Automake就是希望解放这个工作。
]]></content>
      <categories>
        <category>Linux</category>
        <category>Automake</category>
      </categories>
      <tags>
        <tag>autotools</tag>
        <tag>automake</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux Automake 15 Support for test suites</title>
    <url>/2018/03/20/linux-automake-15-support-for-test-suites/</url>
    <content><![CDATA[
GNU Automake 版本(version 1.16.1, 26 February 2018)
Permission is granted to copy, distribute and/or modify thisdocument under the terms of the GNU Free Documentation License,Version 1.3 or any later version published by the Free SoftwareFoundation; with no Invariant Sections, with no Front-Cover texts,and with no Back-Cover Texts.  A copy of the license is included inthe section entitled “GNU Free Documentation License.”

15 Support for test suites

Automake can generate code to handle two kinds of test suites.  One isbased on integration with the ‘dejagnu’ framework.  The other (and mostused) form is based on the use of generic test scripts, and itsactivation is triggered by the definition of the special ‘TESTS’variable.  This second form allows for various degrees of sophisticationand customization; in particular, it allows for concurrent execution oftest scripts, use of established test protocols such as TAP, anddefinition of custom test drivers and test runners.
In either case, the testsuite is invoked via ‘make check’.
15.1 Generalities about TestingThe purpose of testing is to determine whether a program or systembehaves as expected (e.g., known inputs produce the expected outputs,error conditions are correctly handled or reported, and older bugs donot resurface).
   The minimal unit of testing is usually called test case, or simplytest.  How a test case is defined or delimited, and even what exactlyconstitutes a test case, depends heavily on the testing paradigmand/or framework in use, so we won’t attempt any more precisedefinition.  The set of the test cases for a given program or systemconstitutes its testsuite.
   A test harness (also testsuite harness) is a program or softwarecomponent that executes all (or part of) the defined test cases,analyzes their outcomes, and report or register these outcomesappropriately.  Again, the details of how this is accomplished (and howthe developer and user can influence it or interface with it) varieswildly, and we’ll attempt no precise definition.
   A test is said to pass when it can determine that the condition orbehaviour it means to verify holds, and is said to fail when it candetermine that such condition of behaviour does not hold.
   Sometimes, tests can rely on non-portable tools or prerequisites, orsimply make no sense on a given system (for example, a test checking aWindows-specific feature makes no sense on a GNU/Linux system).  In thiscase, accordingly to the definition above, the tests can neither beconsidered passed nor failed; instead, they are skipped – i.e., theyare not run, or their result is anyway ignored for what concerns thecount of failures an successes.  Skips are usually explicitly reportedthough, so that the user will be aware that not all of the testsuite hasreally run.
   It’s not uncommon, especially during early development stages, thatsome tests fail for known reasons, and that the developer doesn’t wantto tackle these failures immediately (this is especially true when thefailing tests deal with corner cases).  In this situation, the betterpolicy is to declare that each of those failures is an expectedfailure (or xfail).  In case a test that is expected to fail ends uppassing instead, many testing environments will flag the result as aspecial kind of failure called unexpected pass (or xpass).
   Many testing environments and frameworks distinguish between testfailures and hard errors.  As we’ve seen, a test failure happens whensome invariant or expected behaviour of the software under test is notmet.  An hard error happens when e.g., the set-up of a test casescenario fails, or when some other unexpected or highly undesirablecondition is encountered (for example, the program under testexperiences a segmentation fault).
15.2 Simple Tests15.2.1 Scripts-based TestsuitesIf the special variable ‘TESTS’ is defined, its value is taken to be alist of programs or scripts to run in order to do the testing.  Underthe appropriate circumstances, it’s possible for ‘TESTS’ to list alsodata files to be passed to one or more test scripts defined by differentmeans (the so-called “log compilers”, *note Parallel Test Harness::).
   Test scripts can be executed serially or concurrently.  Automakesupports both these kinds of test execution, with the parallel testharness being the default.  The concurrent test harness relies on theconcurrence capabilities (if any) offered by the underlying ‘make’implementation, and can thus only be as good as those are.
   By default, only the exit statuses of the test scripts are consideredwhen determining the testsuite outcome.  But Automake allows also theuse of more complex test protocols, either standard (*note Using the TAPtest protocol::) or custom (*note Custom Test Drivers::).  Note that youcan’t enable such protocols when the serial harness is used, though.  Inthe rest of this section we are going to concentrate mostly onprotocol-less tests, since we cover test protocols in a later section(again, *note Custom Test Drivers::).
   When no test protocol is in use, an exit status of 0 from a testscript will denote a success, an exit status of 77 a skipped test, anexit status of 99 an hard error, and any other exit status will denote afailure.
   You may define the variable ‘XFAIL_TESTS’ to a list of tests (usuallya subset of ‘TESTS’) that are expected to fail; this will effectivelyreverse the result of those tests (with the provision that skips andhard errors remain untouched).  You may also instruct the testsuiteharness to treat hard errors like simple failures, by defining the‘DISABLE_HARD_ERRORS’ make variable to a nonempty value.
   Note however that, for tests based on more complex test protocols,the exact effects of ‘XFAIL_TESTS’ and ‘DISABLE_HARD_ERRORS’ mightchange, or they might even have no effect at all (for example, in testsusing TAP, there is no way to disable hard errors, and the‘DISABLE_HARD_ERRORS’ variable has no effect on them).
   The result of each test case run by the scripts in ‘TESTS’ will beprinted on standard output, along with the test name.  For testprotocols that allow more test cases per test script (such as TAP), anumber, identifier and/or brief description specific for the single testcase is expected to be printed in addition to the name of the testscript.  The possible results (whose meanings should be clear from theprevious *note Generalities about Testing::) are ‘PASS’, ‘FAIL’, ‘SKIP’,‘XFAIL’, ‘XPASS’ and ‘ERROR’.  Here is an example of output from anhypothetical testsuite that uses both plain and TAP tests:     PASS: foo.sh     PASS: zardoz.tap 1 - Daemon started     PASS: zardoz.tap 2 - Daemon responding     SKIP: zardoz.tap 3 - Daemon uses /proc # SKIP /proc is not mounted     PASS: zardoz.tap 4 - Daemon stopped     SKIP: bar.sh     PASS: mu.tap 1     XFAIL: mu.tap 2 # TODO frobnication not yet implemented
A testsuite summary (expected to report at least the number of run,skipped and failed tests) will be printed at the end of the testsuiterun.
   If the standard output is connected to a capable terminal, then thetest results and the summary are colored appropriately.  The developerand the user can disable colored output by setting the ‘make’ variable‘AM_COLOR_TESTS=no’; the user can in addition force colored output evenwithout a connecting terminal with ‘AM_COLOR_TESTS=always’.  It’s alsoworth noting that some ‘make’ implementations, when used in parallelmode, have slightly different semantics (*note (autoconf)Parallelmake::), which can break the automatic detection of a connection to acapable terminal.  If this is the case, the user will have to resort tothe use of ‘AM_COLOR_TESTS=always’ in order to have the testsuite outputcolorized.
   Test programs that need data files should look for them in ‘srcdir’(which is both a make variable and an environment variable madeavailable to the tests), so that they work when building in a separatedirectory (*note Build Directories: (autoconf)Build Directories.), andin particular for the ‘distcheck’ rule (*note Checking theDistribution::).
   The ‘AM_TESTS_ENVIRONMENT’ and ‘TESTS_ENVIRONMENT’ variables can beused to run initialization code and set environment variables for thetest scripts.  The former variable is developer-reserved, and can bedefined in the ‘Makefile.am’, while the latter is reserved for the user,which can employ it to extend or override the settings in the former;for this to work portably, however, the contents of a non-empty‘AM_TESTS_ENVIRONMENT’ must be terminated by a semicolon.
   The ‘AM_TESTS_FD_REDIRECT’ variable can be used to define filedescriptor redirections for the test scripts.  One might think that‘AM_TESTS_ENVIRONMENT’ could be used for this purpose, but experiencehas shown that doing so portably is practically impossible.  The mainhurdle is constituted by Korn shells, which usually set theclose-on-exec flag on file descriptors opened with the ‘exec’ builtin,thus rendering an idiom like ‘AM_TESTS_ENVIRONMENT = exec 9&gt;&amp;2;’ineffectual.  This issue also affects some Bourne shells, such as theHP-UX’s ‘/bin/sh’,
 AM_TESTS_ENVIRONMENT = \
 ## Some environment initializations are kept in a separate shell
 ## file 'tests-env.sh', which can make it easier to also run tests
 ## from the command line.
   . $(srcdir)/tests-env.sh; \
 ## On Solaris, prefer more POSIX-compliant versions of the standard
 ## tools by default.
   if test -d /usr/xpg4/bin; then \
     PATH=/usr/xpg4/bin:$$PATH; export PATH; \
   fi;
 ## With this, the test scripts will be able to print diagnostic
 ## messages to the original standard error stream, even if the test
 ## driver redirects the stderr of the test scripts to a log file
 ## before executing them.
 AM_TESTS_FD_REDIRECT = 9&gt;&amp;2

Note however that ‘AM_TESTS_ENVIRONMENT’ is, for historical andimplementation reasons, not supported by the serial harness (*noteSerial Test Harness::).
   Automake ensures that each file listed in ‘TESTS’ is built before itis run; you can list both source and derived programs (or scripts) in‘TESTS’; the generated rule will look both in ‘srcdir’ and ‘.’.  Forinstance, you might want to run a C program as a test.  To do this youwould list its name in ‘TESTS’ and also in ‘check_PROGRAMS’, and thenspecify it as you would any other program.
   Programs listed in ‘check_PROGRAMS’ (and ‘check_LIBRARIES’,‘check_LTLIBRARIES’…)  are only built during ‘make check’, not during‘make all’.  You should list there any program needed by your tests thatdoes not need to be built by ‘make all’.  Note that ‘check_PROGRAMS’ arenot automatically added to ‘TESTS’ because ‘check_PROGRAMS’ usuallylists programs used by the tests, not the tests themselves.  Of courseyou can set ‘TESTS = $(check_PROGRAMS)’ if all your programs are testcases.
15.2.2 Older (and discouraged) serial test harnessFirst, note that today the use of this harness is strongly discouragedin favour of the parallel test harness (*note Parallel Test Harness::).Still, there are few situations when the advantages offered by theparallel harness are irrelevant, and when test concurrency can evencause tricky problems.  In those cases, it might make sense to still usethe serial harness, for simplicity and reliability (we still suggesttrying to give the parallel harness a shot though).
   The serial test harness is enabled by the Automake option‘serial-tests’.  It operates by simply running the tests serially, oneat the time, without any I/O redirection.  It’s up to the user toimplement logging of tests’ output, if that’s required or desired.
   For historical and implementation reasons, the ‘AM_TESTS_ENVIRONMENT’variable is not supported by this harness (it will be silently ignoredif defined); only ‘TESTS_ENVIRONMENT’ is, and it is to be considered adeveloper-reserved variable.  This is done so that, when using theserial harness, ‘TESTS_ENVIRONMENT’ can be defined to an invocation ofan interpreter through which the tests are to be run.  For instance, thefollowing setup may be used to run tests with Perl:
 TESTS_ENVIRONMENT = $(PERL) -Mstrict -w
 TESTS = foo.pl bar.pl baz.pl

It’s important to note that the use of ‘TESTS_ENVIRONMENT’ endorsed herewould be invalid with the parallel harness.  That harness provides amore elegant way to achieve the same effect, with the further benefit offreeing the ‘TESTS_ENVIRONMENT’ variable for the user (*note ParallelTest Harness::).
   Another, less serious limit of the serial harness is that it doesn’treally distinguish between simple failures and hard errors; this is dueto historical reasons only, and might be fixed in future Automakeversions.
15.2.3 Parallel Test HarnessBy default, Automake generated a parallel (concurrent) test harness.  Itfeatures automatic collection of the test scripts output in ‘.log’files, concurrent execution of tests with ‘make -j’, specification ofinter-test dependencies, lazy reruns of tests that have not completed ina prior run, and hard errors for exceptional failures.
   The parallel test harness operates by defining a set of ‘make’ rulesthat run the test scripts listed in ‘TESTS’, and, for each such script,save its output in a corresponding ‘.log’ file and its results (andother “metadata”, *note API for Custom Test Drivers::) in acorresponding ‘.trs’ (as in Test ReSults) file.  The ‘.log’ file willcontain all the output emitted by the test on its standard output andits standard error.  The ‘.trs’ file will contain, among the otherthings, the results of the test cases run by the script.
   The parallel test harness will also create a summary log file,‘TEST_SUITE_LOG’, which defaults to ‘test-suite.log’ and requires a‘.log’ suffix.  This file depends upon all the ‘.log’ and ‘.trs’ filescreated for the test scripts listed in ‘TESTS’.
   As with the serial harness above, by default one status line isprinted per completed test, and a short summary after the suite hascompleted.  However, standard output and standard error of the test areredirected to a per-test log file, so that parallel execution does notproduce intermingled output.  The output from failed tests is collectedin the ‘test-suite.log’ file.  If the variable ‘VERBOSE’ is set, thisfile is output after the summary.
   Each couple of ‘.log’ and ‘.trs’ files is created when thecorresponding test has completed.  The set of log files is listed in theread-only variable ‘TEST_LOGS’, and defaults to ‘TESTS’, with theexecutable extension if any (*note EXEEXT::), as well as any suffixlisted in ‘TEST_EXTENSIONS’ removed, and ‘.log’ appended.  Results areundefined if a test file name ends in several concatenated suffixes.‘TEST_EXTENSIONS’ defaults to ‘.test’; it can be overridden by the user,in which case any extension listed in it must be constituted by a dot,followed by a non-digit alphabetic character, followed by any number ofalphabetic characters.  For example, ‘.sh’, ‘.T’ and ‘.t1’ are validextensions, while ‘.x-y’, ‘.6c’ and ‘.t.1’ are not.
   It is important to note that, due to current limitations (unlikely tobe lifted), configure substitutions in the definition of ‘TESTS’ canonly work if they will expand to a list of tests that have a suffixlisted in ‘TEST_EXTENSIONS’.
   For tests that match an extension ‘.EXT’ listed in ‘TEST_EXTENSIONS’,you can provide a custom “test runner” using the variable‘EXT_LOG_COMPILER’ (note the upper-case extension) and pass options in‘AM_EXT_LOG_FLAGS’ and allow the user to pass options in‘EXT_LOG_FLAGS’.  It will cause all tests with this extension to becalled with this runner.  For all tests without a registered extension,the variables ‘LOG_COMPILER’, ‘AM_LOG_FLAGS’, and ‘LOG_FLAGS’ may beused.  For example,
 TESTS = foo.pl bar.py baz
 TEST_EXTENSIONS = .pl .py
 PL_LOG_COMPILER = $(PERL)
 AM_PL_LOG_FLAGS = -w
 PY_LOG_COMPILER = $(PYTHON)
 AM_PY_LOG_FLAGS = -v
 LOG_COMPILER = ./wrapper-script
 AM_LOG_FLAGS = -d

will invoke ‘$(PERL) -w foo.pl’, ‘$(PYTHON) -v bar.py’, and‘./wrapper-script -d baz’ to produce ‘foo.log’, ‘bar.log’, and‘baz.log’, respectively.  The ‘foo.trs’, ‘bar.trs’ and ‘baz.trs’ fileswill be automatically produced as a side-effect.
   It’s important to note that, differently from what we’ve seen for theserial test harness (*note Serial Test Harness::), the‘AM_TESTS_ENVIRONMENT’ and ‘TESTS_ENVIRONMENT’ variables cannot beused to define a custom test runner; the ‘LOG_COMPILER’ and ‘LOG_FLAGS’(or their extension-specific counterparts) should be used instead:
 ## This is WRONG!
 AM_TESTS_ENVIRONMENT = PERL5LIB='$(srcdir)/lib' $(PERL) -Mstrict -w

 ## Do this instead.
 AM_TESTS_ENVIRONMENT = PERL5LIB='$(srcdir)/lib'; export PERL5LIB;
 LOG_COMPILER = $(PERL)
 AM_LOG_FLAGS = -Mstrict -w

   By default, the test suite harness will run all tests, but there areseveral ways to limit the set of tests that are run:
   • You can set the ‘TESTS’ variable.  For example, you can use a     command like this to run only a subset of the tests:
      env TESTS="foo.test bar.test" make -e check

 Note however that the command above will unconditionally overwrite
 the ‘test-suite.log’ file, thus clobbering the recorded results of
 any previous testsuite run.  This might be undesirable for packages
 whose testsuite takes long time to execute.  Luckily, this problem
 can easily be avoided by overriding also ‘TEST_SUITE_LOG’ at
 runtime; for example,

      env TEST_SUITE_LOG=partial.log TESTS="..." make -e check

 will write the result of the partial testsuite runs to the
 ‘partial.log’, without touching ‘test-suite.log’.

   • You can set the ‘TEST_LOGS’ variable.  By default, this variable is     computed at ‘make’ run time from the value of ‘TESTS’ as described     above.  For example, you can use the following:
      set x subset*.log; shift
      env TEST_LOGS="foo.log $*" make -e check

 The comments made above about ‘TEST_SUITE_LOG’ overriding applies
 here too.

   • By default, the test harness removes all old per-test ‘.log’ and     ‘.trs’ files before it starts running tests to regenerate them.     The variable ‘RECHECK_LOGS’ contains the set of ‘.log’ (and, by     implication, ‘.trs’) files which are removed.  ‘RECHECK_LOGS’     defaults to ‘TEST_LOGS’, which means all tests need to be     rechecked.  By overriding this variable, you can choose which tests     need to be reconsidered.  For example, you can lazily rerun only     those tests which are outdated, i.e., older than their prerequisite     test files, by setting this variable to the empty value:
      env RECHECK_LOGS= make -e check

   • You can ensure that all tests are rerun which have failed or passed     unexpectedly, by running ‘make recheck’ in the test directory.     This convenience target will set ‘RECHECK_LOGS’ appropriately     before invoking the main test harness.
In order to guarantee an ordering between tests even with ‘make -jN’,dependencies between the corresponding ‘.log’ files may be specifiedthrough usual ‘make’ dependencies.  For example, the following snippetlets the test named ‘foo-execute.test’ depend upon completion of thetest ‘foo-compile.test’:
 TESTS = foo-compile.test foo-execute.test
 foo-execute.log: foo-compile.log

Please note that this ordering ignores the results of required tests,thus the test ‘foo-execute.test’ is run even if the test‘foo-compile.test’ failed or was skipped beforehand.  Further, pleasenote that specifying such dependencies currently works only for teststhat end in one of the suffixes listed in ‘TEST_EXTENSIONS’.
   Tests without such specified dependencies may be run concurrentlywith parallel ‘make -jN’, so be sure they are prepared for concurrentexecution.
   The combination of lazy test execution and correct dependenciesbetween tests and their sources may be exploited for efficient unittesting during development.  To further speed up the edit-compile-testcycle, it may even be useful to specify compiled programs in‘EXTRA_PROGRAMS’ instead of with ‘check_PROGRAMS’, as the former allowsintertwined compilation and test execution (but note that‘EXTRA_PROGRAMS’ are not cleaned automatically, *note Uniform::).
   The variables ‘TESTS’ and ‘XFAIL_TESTS’ may contain conditional partsas well as configure substitutions.  In the latter case, however,certain restrictions apply: substituted test names must end with anonempty test suffix like ‘.test’, so that one of the inference rulesgenerated by ‘automake’ can apply.  For literal test names, ‘automake’can generate per-target rules to avoid this limitation.
   Please note that it is currently not possible to use ‘$(srcdir)/’ or‘$(top_srcdir)/’ in the ‘TESTS’ variable.  This technical limitation isnecessary to avoid generating test logs in the source tree and has theunfortunate consequence that it is not possible to specify distributedtests that are themselves generated by means of explicit rules, in a waythat is portable to all ‘make’ implementations (*note (autoconf)MakeTarget Lookup::, the semantics of FreeBSD and OpenBSD ‘make’ conflictwith this).  In case of doubt you may want to require to use GNU ‘make’,or work around the issue with inference rules to generate the tests.
15.3 Custom Test Drivers15.3.1 Overview of Custom Test Drivers SupportStarting from Automake version 1.12, the parallel test harness allowsthe package authors to use third-party custom test drivers, in case thedefault ones are inadequate for their purposes, or do not support theirtesting protocol of choice.
   A custom test driver is expected to properly run the test programspassed to it (including the command-line arguments passed to thoseprograms, if any), to analyze their execution and outcome, to create the‘.log’ and ‘.trs’ files associated to these test runs, and to displaythe test results on the console.  It is responsibility of the author ofthe test driver to ensure that it implements all the above stepsmeaningfully and correctly; Automake isn’t and can’t be of any helphere.  On the other hand, the Automake-provided code for testsuitesummary generation offers support for test drivers allowing several testresults per test script, if they take care to register such resultsproperly (*note Log files generation and test results recording::).
   The exact details of how test scripts’ results are to be determinedand analyzed is left to the individual drivers.  Some drivers might onlyconsider the test script exit status (this is done for example by thedefault test driver used by the parallel test harness, described in theprevious section).  Other drivers might implement more complex andadvanced test protocols, which might require them to parse andinterpreter the output emitted by the test script they’re running(examples of such protocols are TAP and SubUnit).
   It’s very important to note that, even when using custom testdrivers, most of the infrastructure described in the previous sectionabout the parallel harness remains in place; this includes:
   • list of test scripts defined in ‘TESTS’, and overridable at runtime     through the redefinition of ‘TESTS’ or ‘TEST_LOGS’;   • concurrency through the use of ‘make’’s option ‘-j’;   • per-test ‘.log’ and ‘.trs’ files, and generation of a summary     ‘.log’ file from them;   • ‘recheck’ target, ‘RECHECK_LOGS’ variable, and lazy reruns of     tests;   • inter-test dependencies;   • support for ‘check_*’ variables (‘check_PROGRAMS’,     ‘check_LIBRARIES’, …);   • use of ‘VERBOSE’ environment variable to get verbose output on     testsuite failures;   • definition and honoring of ‘TESTS_ENVIRONMENT’,     ‘AM_TESTS_ENVIRONMENT’ and ‘AM_TESTS_FD_REDIRECT’ variables;   • definition of generic and extension-specific ‘LOG_COMPILER’ and     ‘LOG_FLAGS’ variables.
On the other hand, the exact semantics of how (and if) testsuite outputcolorization, ‘XFAIL_TESTS’, and hard errors are supported and handledis left to the individual test drivers.
15.3.2 Declaring Custom Test DriversCustom testsuite drivers are declared by defining the make variables‘LOG_DRIVER’ or ‘EXT_LOG_DRIVER’ (where EXT must be declared in‘TEST_EXTENSIONS’).  They must be defined to programs or scripts thatwill be used to drive the execution, logging, and outcome report of thetests with corresponding extensions (or of those with no registeredextension in the case of ‘LOG_DRIVER’).  Clearly, multiple distinct testdrivers can be declared in the same ‘Makefile.am’.  Note moreover thatthe ‘LOG_DRIVER’ variables are not a substitute for the ‘LOG_COMPILER’variables: the two sets of variables can, and often do, usefully andlegitimately coexist.
   The developer-reserved variable ‘AM_LOG_DRIVER_FLAGS’ and theuser-reserved variable ‘LOG_DRIVER_FLAGS’ can be used to define flagsthat will be passed to each invocation of ‘LOG_DRIVER’, with theuser-defined flags obviously taking precedence over thedeveloper-reserved ones.  Similarly, for each extension EXT declared in‘TEST_EXTENSIONS’, flags listed in ‘AM_EXT_LOG_DRIVER_FLAGS’ and‘EXT_LOG_DRIVER_FLAGS’ will be passed to invocations of‘EXT_LOG_DRIVER’.
15.3.3 API for Custom Test DriversNote that the APIs described here are still highly experimental, andwill very likely undergo tightenings and likely also extensive changesin the future, to accommodate for 新特性 or to satisfy additionalportability requirements.
   The main characteristic of these APIs is that they are designed toshare as much infrastructure, semantics, and implementation details aspossible with the parallel test harness and its default driver.
15.3.3.1 Command-line arguments for test drivers…………………………………………
A custom driver can rely on various command-line options and argumentsbeing passed to it automatically by the Automake-generated test harness.It is mandatory that it understands all of them (even if the exactinterpretation of the associated semantics can legitimately changebetween a test driver and another, and even be a no-op in some drivers).
Here is the list of options:
‘–test-name=NAME’     The name of the test, with VPATH prefix (if any) removed.  This can     have a suffix and a directory component (as in e.g.,     ‘sub/foo.test’), and is mostly meant to be used in console reports     about testsuite advancements and results (*note Testsuite progress     output::).‘–log-file=PATH.log’     The ‘.log’ file the test driver must create (*note Basics of test     metadata::).  If it has a directory component (as in e.g.,     ‘sub/foo.log’), the test harness will ensure that such directory     exists before the test driver is called.‘–trs-file=PATH.trs’     The ‘.trs’ file the test driver must create (*note Basics of test     metadata::).  If it has a directory component (as in e.g.,     ‘sub/foo.trs’), the test harness will ensure that such directory     exists before the test driver is called.‘–color-tests={yes|no}’     Whether the console output should be colorized or not (*note Simple     tests and color-tests::, to learn when this option gets activated     and when it doesn’t).‘–expect-failure={yes|no}’     Whether the tested program is expected to fail.‘–enable-hard-errors={yes|no}’     Whether “hard errors” in the tested program should be treated     differently from normal failures or not (the default should be     ‘yes’).  The exact meaning of “hard error” is highly dependent from     the test protocols or conventions in use.‘–’     Explicitly terminate the list of options.
The first non-option argument passed to the test driver is the programto be run, and all the following ones are command-line options andarguments for this program.
   Note that the exact semantics attached to the ‘–color-tests’,‘–expect-failure’ and ‘–enable-hard-errors’ options are left up to theindividual test drivers.  Still, having a behaviour compatible or atleast similar to that provided by the default driver is advised, as thatwould offer a better consistency and a more pleasant user experience.
15.3.3.2 Log files generation and test results recording………………………………………………..
The test driver must correctly generate the files specified by the‘–log-file’ and ‘–trs-file’ option (even when the tested program failsor crashes).
   The ‘.log’ file should ideally contain all the output produced by thetested program, plus optionally other information that might facilitatedebugging or analysis of bug reports.  Apart from that, its format isbasically free.
   The ‘.trs’ file is used to register some metadata through the use ofcustom reStructuredText fields.  This metadata is expected to beemployed in various ways by the parallel test harness; for example, tocount the test results when printing the testsuite summary, or to decidewhich tests to re-run upon ‘make recheck’.  Unrecognized metadata in a‘.trs’ file is currently ignored by the harness, but this might changein the future.  The list of currently recognized metadata follows.
‘:test-result:’     The test driver must use this field to register the results of     each test case run by a test script file.  Several     ‘:test-result:’ fields can be present in the same ‘.trs’ file; this     is done in order to support test protocols that allow a single test     script to run more test cases.
 The only recognized test results are currently ‘PASS’, ‘XFAIL’,
 ‘SKIP’, ‘FAIL’, ‘XPASS’ and ‘ERROR’.  These results, when declared
 with ‘:test-result:’, can be optionally followed by text holding
 the name and/or a brief description of the corresponding test; the
 harness will ignore such extra text when generating
 ‘test-suite.log’ and preparing the testsuite summary.

‘:recheck:’     If this field is present and defined to ‘no’, then the     corresponding test script will not be run upon a ‘make recheck’.     What happens when two or more ‘:recheck:’ fields are present in the     same ‘.trs’ file is undefined behaviour.
‘:copy-in-global-log:’     If this field is present and defined to ‘no’, then the content of     the ‘.log’ file will not be copied into the global     ‘test-suite.log’.  We allow to forsake such copying because, while     it can be useful in debugging and analysis of bug report, it can     also be just a waste of space in normal situations, e.g., when a     test script is successful.  What happens when two or more     ‘:copy-in-global-log:’ fields are present in the same ‘.trs’ file     is undefined behaviour.
‘:test-global-result:’     This is used to declare the “global result” of the script.     Currently, the value of this field is needed only to be reported     (more or less verbatim) in the generated global log file     ‘$(TEST_SUITE_LOG)’, so it’s quite free-form.  For example, a test     script which run 10 test cases, 6 of which pass and 4 of which are     skipped, could reasonably have a ‘PASS/SKIP’ value for this field,     while a test script which run 19 successful tests and one failed     test could have an ‘ALMOST PASSED’ value.  What happens when two or     more ‘:test-global-result:’ fields are present in the same ‘.trs’     file is undefined behaviour.
Let’s see a small example.  Assume a ‘.trs’ file contains the followinglines:
 :test-result: PASS server starts
 :global-log-copy: no
 :test-result: PASS HTTP/1.1 request
 :test-result: FAIL HTTP/1.0 request
 :recheck: yes
 :test-result: SKIP HTTPS request (TLS library wasn't available)
 :test-result: PASS server stops

Then the corresponding test script will be re-run by ‘make check’, willcontribute with five test results to the testsuite summary (three ofthese tests being successful, one failed, and one skipped), and thecontent of the corresponding ‘.log’ file will not be copied in theglobal log file ‘test-suite.log’.
15.3.3.3 Testsuite progress output…………………………….
A custom test driver also has the task of displaying, on the standardoutput, the test results as soon as they become available.  Depending onthe protocol in use, it can also display the reasons for failures andskips, and, more generally, any useful diagnostic output (but rememberthat each line on the screen is precious, so that cluttering the screenwith overly verbose information is bad idea).  The exact format of thisprogress output is left up to the test driver; in fact, a custom testdriver might theoretically even decide not to do any such report,leaving it all to the testsuite summary (that would be a very lousyidea, of course, and serves only to illustrate the flexibility that isgranted here).
   Remember that consistency is good; so, if possible, try to beconsistent with the output of the built-in Automake test drivers,providing a similar “look &amp; feel”.  In particular, the testsuiteprogress output should be colorized when the ‘–color-tests’ is passedto the driver.  On the other end, if you are using a known andwidespread test protocol with well-established implementations, beingconsistent with those implementations’ output might be a good idea too.
15.4 Using the TAP test protocol15.4.1 Introduction to TAPTAP, the Test Anything Protocol, is a simple text-based interfacebetween testing modules or programs and a test harness.  The tests (alsocalled “TAP producers” in this context) write test results in a simpleformat on standard output; a test harness (also called “TAP consumer”)will parse and interpret these results, and properly present them to theuser, and/or register them for later analysis.  The exact details of howthis is accomplished can vary among different test harnesses.  TheAutomake harness will present the results on the console in the usualfashion (*note Testsuite progress on console::), and will use the ‘.trs’files (*note Basics of test metadata::) to store the test results andrelated metadata.  Apart from that, it will try to remain as muchcompatible as possible with pre-existing and widespread utilities, suchas the ‘prove’ utility(http://search.cpan.org/~andya/Test-Harness/bin/prove), at least for thesimpler usages.
   TAP started its life as part of the test harness for Perl, but todayit has been (mostly) standardized, and has various independentimplementations in different languages; among them, C, C++, Perl,Python, PHP, and Java.  For a semi-official specification of the TAPprotocol, please refer to the documentation of ‘Test::Harness::TAP’(http://search.cpan.org/~petdance/Test-Harness/lib/Test/Harness/TAP.pod).
   The most relevant real-world usages of TAP are obviously in thetestsuites of ‘perl’ and of many perl modules.  Still, also otherimportant third-party packages, such as ‘git’ (http://git-scm.com/), useTAP in their testsuite.
15.4.2 Use TAP with the Automake test harnessCurrently, the TAP driver that comes with Automake requires some by-handsteps on the developer’s part (this situation should hopefully beimproved in future Automake versions).  You’ll have to grab the‘tap-driver.sh’ script from the Automake distribution by hand, copy itin your source tree, and use the Automake support for third-party testdrivers to instruct the harness to use the ‘tap-driver.sh’ script andthe awk program found by ‘AM_INIT_AUTOMAKE’ to run your TAP-producingtests.  See the example below for clarification.
   Apart from the options common to all the Automake test drivers (*noteCommand-line arguments for test drivers::), the ‘tap-driver.sh’ supportsthe following options, whose names are chosen for enhanced compatibilitywith the ‘prove’ utility.
‘–ignore-exit’     Causes the test driver to ignore the exit status of the test     scripts; by default, the driver will report an error if the script     exits with a non-zero status.  This option has effect also on     non-zero exit statuses due to termination by a signal.‘–comments’     Instruct the test driver to display TAP diagnostic (i.e., lines     beginning with the ‘#’ character) in the testsuite progress output     too; by default, TAP diagnostic is only copied to the ‘.log’ file.‘–no-comments’     Revert the effects of ‘–comments’.‘–merge’     Instruct the test driver to merge the test scripts’ standard error     into their standard output.  This is necessary if you want to     ensure that diagnostics from the test scripts are displayed in the     correct order relative to test results; this can be of great help     in debugging (especially if your test scripts are shell scripts run     with shell tracing active).  As a downside, this option might cause     the test harness to get confused if anything that appears on     standard error looks like a test result.‘–no-merge’     Revert the effects of ‘–merge’.‘–diagnostic-string=STRING’     Change the string that introduces TAP diagnostic from the default     value of “‘#’” to ‘STRING’.  This can be useful if your TAP-based     test scripts produce verbose output on which they have limited     control (because, say, the output comes from other tools invoked in     the scripts), and it might contain text that gets spuriously     interpreted as TAP diagnostic: such an issue can be solved by     redefining the string that activates TAP diagnostic to a value you     know won’t appear by chance in the tests’ output.  Note however     that this feature is non-standard, as the “official” TAP protocol     does not allow for such a customization; so don’t use it if you can     avoid it.
Here is an example of how the TAP driver can be set up and used.
 % cat configure.ac
 AC_INIT([GNU Try Tap], [1.0], [bug-automake@gnu.org])
 AC_CONFIG_AUX_DIR([build-aux])
 AM_INIT_AUTOMAKE([foreign -Wall -Werror])
 AC_CONFIG_FILES([Makefile])
 AC_REQUIRE_AUX_FILE([tap-driver.sh])
 AC_OUTPUT

 % cat Makefile.am
 TEST_LOG_DRIVER = env AM_TAP_AWK='$(AWK)' $(SHELL) \
                   $(top_srcdir)/build-aux/tap-driver.sh
 TESTS = foo.test bar.test baz.test
 EXTRA_DIST = $(TESTS)

 % cat foo.test
 #!/bin/sh
 echo 1..4 # Number of tests to be executed.
 echo 'ok 1 - Swallows fly'
 echo 'not ok 2 - Caterpillars fly # TODO metamorphosis in progress'
 echo 'ok 3 - Pigs fly # SKIP not enough acid'
 echo '# I just love word plays ...'
 echo 'ok 4 - Flies fly too :-)'

 % cat bar.test
 #!/bin/sh
 echo 1..3
 echo 'not ok 1 - Bummer, this test has failed.'
 echo 'ok 2 - This passed though.'
 echo 'Bail out! Ennui kicking in, sorry...'
 echo 'ok 3 - This will not be seen.'

 % cat baz.test
 #!/bin/sh
 echo 1..1
 echo ok 1
 # Exit with error, even if all the tests have been successful.
 exit 7

 % cp PREFIX/share/automake-APIVERSION/tap-driver.sh .
 % autoreconf -vi &amp;&amp; ./configure &amp;&amp; make check
 ...
 PASS: foo.test 1 - Swallows fly
 XFAIL: foo.test 2 - Caterpillars fly # TODO metamorphosis in progress
 SKIP: foo.test 3 - Pigs fly # SKIP not enough acid
 PASS: foo.test 4 - Flies fly too :-)
 FAIL: bar.test 1 - Bummer, this test has failed.
 PASS: bar.test 2 - This passed though.
 ERROR: bar.test - Bail out! Ennui kicking in, sorry...
 PASS: baz.test 1
 ERROR: baz.test - exited with status 7
 ...
 Please report to bug-automake@gnu.org
 ...
 % echo exit status: $?
 exit status: 1

 % env TEST_LOG_DRIVER_FLAGS='--comments --ignore-exit' \
       TESTS='foo.test baz.test' make -e check
 ...
 PASS: foo.test 1 - Swallows fly
 XFAIL: foo.test 2 - Caterpillars fly # TODO metamorphosis in progress
 SKIP: foo.test 3 - Pigs fly # SKIP not enough acid
 # foo.test: I just love word plays...
 PASS: foo.test 4 - Flies fly too :-)
 PASS: baz.test 1
 ...
 % echo exit status: $?
 exit status: 0

15.4.3 Incompatibilities with other TAP parsers and driversFor implementation or historical reasons, the TAP driver and harness asimplemented by Automake have some minors incompatibilities with themainstream versions, which you should be aware of.
   • A ‘Bail out!’ directive doesn’t stop the whole testsuite, but only     the test script it occurs in.  This doesn’t follow TAP     specifications, but on the other hand it maximizes compatibility     (and code sharing) with the “hard error” concept of the default     testsuite driver.   • The ‘version’ and ‘pragma’ directives are not supported.   • The ‘–diagnostic-string’ option of our driver allows to modify the     string that introduces TAP diagnostic from the default value of     “‘#’”.  The standard TAP protocol has currently no way to allow     this, so if you use it your diagnostic will be lost to more     compliant tools like ‘prove’ and ‘Test::Harness’   • And there are probably some other small and yet undiscovered     incompatibilities, especially in corner cases or with rare usages.
15.4.4 Links and external resources on TAPHere are some links to more extensive official or third-partydocumentation and resources about the TAP protocol and related tools andlibraries.   •  ‘Test::Harness::TAP’     (http://search.cpan.org/~petdance/Test-Harness/lib/Test/Harness/TAP.pod),     the (mostly) official documentation about the TAP format and     protocol.   •  ‘prove’ (http://search.cpan.org/~andya/Test-Harness/bin/prove),     the most famous command-line TAP test driver, included in the     distribution of ‘perl’ and ‘Test::Harness’     (http://search.cpan.org/~andya/Test-Harness/lib/Test/Harness.pm).   • The TAP wiki (http://testanything.org/wiki/index.php/Main_Page).   • A “gentle introduction” to testing for perl coders:     ‘Test::Tutorial’     (http://search.cpan.org/dist/Test-Simple/lib/Test/Tutorial.pod).   •  ‘Test::Simple’     (http://search.cpan.org/~mschwern/Test-Simple/lib/Test/Simple.pm)     and ‘Test::More’     (http://search.cpan.org/~mschwern/Test-Simple/lib/Test/More.pm),     the standard perl testing libraries, which are based on TAP.   • C TAP Harness     (http://www.eyrie.org/~eagle/software/c-tap-harness/), a C-based     project implementing both a TAP producer and a TAP consumer.   • tap4j (http://www.tap4j.org/), a Java-based project implementing     both a TAP producer and a TAP consumer.
15.5 DejaGnu TestsIf ‘dejagnu’ (https://ftp.gnu.org/gnu/dejagnu/) appears in‘AUTOMAKE_OPTIONS’, then a ‘dejagnu’-based test suite is assumed.  Thevariable ‘DEJATOOL’ is a list of names that are passed, one at a time,as the ‘–tool’ argument to ‘runtest’ invocations; it defaults to thename of the package.
   The variable ‘RUNTESTDEFAULTFLAGS’ holds the ‘–tool’ and ‘–srcdir’flags that are passed to dejagnu by default; this can be overridden ifnecessary.
   The variables ‘EXPECT’ and ‘RUNTEST’ can also be overridden toprovide project-specific values.  For instance, you will need to do thisif you are testing a compiler toolchain, because the default values donot take into account host and target names.
   The contents of the variable ‘RUNTESTFLAGS’ are passed to the‘runtest’ invocation.  This is considered a “user variable” (*note UserVariables::).  If you need to set ‘runtest’ flags in ‘Makefile.am’, youcan use ‘AM_RUNTESTFLAGS’ instead.
   Automake will generate rules to create a local ‘site.exp’ file,defining various variables detected by ‘configure’.  This file isautomatically read by DejaGnu.  It is OK for the user of a package toedit this file in order to tune the test suite.  However this is not theplace where the test suite author should define new variables: thisshould be done elsewhere in the real test suite code.  Especially,‘site.exp’ should not be distributed.
   Still, if the package author has legitimate reasons to extend‘site.exp’ at ‘make’ time, he can do so by defining the variable‘EXTRA_DEJAGNU_SITE_CONFIG’; the files listed there will be considered‘site.exp’ prerequisites, and their content will be appended to it (inthe same order in which they appear in ‘EXTRA_DEJAGNU_SITE_CONFIG’).Note that files are not distributed by default.
   For more information regarding DejaGnu test suites, see *note(dejagnu)Top::.
15.6 Install TestsThe ‘installcheck’ target is available to the user as a way to run anytests after the package has been installed.  You can add tests to thisby writing an ‘installcheck-local’ rule.
]]></content>
      <categories>
        <category>Linux</category>
        <category>Automake</category>
      </categories>
      <tags>
        <tag>autotools</tag>
        <tag>automake</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux Automake 2 Autotools 简介</title>
    <url>/2018/03/07/linux-automake-2-introduction-autotools/</url>
    <content><![CDATA[
GNU Automake 版本(version 1.16.1, 26 February 2018)
Permission is granted to copy, distribute and/or modify thisdocument under the terms of the GNU Free Documentation License,Version 1.3 or any later version published by the Free SoftwareFoundation; with no Invariant Sections, with no Front-Cover texts,and with no Back-Cover Texts.  A copy of the license is included inthe section entitled “GNU Free Documentation License.”

2 Autotools 简介
如果以前没有接触过Automake，你可能大概也许知道它是 Autotools 工具集的一部分。
如果你已经开始研究诸如 configure,configure.ac,Makefile.in,Makefile.am,aclocal.m等，那么你可能已经看到他们被声明为 generated by Autoconf or Automake。
整套生成过程异常复杂，本章准备一点点介绍讲解出来。
Alexandre Duret-Lutz 的 Autotools 教程特别好，供参考(http://www.lrde.epita.fr/~adl/autotools.html)。
2.1 GNU Build System 简介
作为一个开发人员，有一套构建系统是相当有必要的。
在Unix的世界里，一般使用make。所有的规则都在文件Makefile中描述。
比如程序prog链接到文件 main.o,foo.o,bar.o，文件 main.o 由 main.c编译而成。
每次执行 make的时候，它都会读取Makefile，检查文件的修改日期，来决定哪些文件需要重新构建。
在不同的平台上进行编译的时候，Makefile 可能需要微调。
1991年David J. MacKenzie在厌倦反复修改 Makefile后，编写了一个支持20个平台的脚本。这个脚本的文件称为 configure，可以自动调整 Makefile。
现在编译软件包简化为 ./configure &amp;&amp; make.
目前GNU项目已经标准化这个过程，安装只需要解压软件包，然后执行 ./configure &amp;&amp; make &amp;&amp; make install,即可安装。
Autotools 工具可以帮助我们构建自己的工具包。
Autoconf 主要完成configure， Automake 完成Makefile。
2.2 GNU Build System的用例
随automake发布的还有一个示例程序 amhello-1.0.tar.gz ，一般位于PREFIX/share/doc/automake/amhello-1.0.tar.gz，其中PREFIX为安装路径的前缀，
默认为/usr/local，还有一些发行版位于/usr。
2.2.1 基本安装
最常见的安装如下：
~ % tar zxf amhello-1.0.tar.gz~ % cd amhello-1.0~/amhello-1.0 % ./configure...config.status: creating Makefileconfig.status: creating src/Makefile...~/amhello-1.0 % make...~/amhello-1.0 % make check...~/amhello-1.0 % suPassword:/home/adl/amhello-1.0 # make install.../home/adl/amhello-1.0 # exit~/amhello-1.0 % make installcheck...

我们首先解压文件，然后执行configure，将会创建Makefile文件，此时就可以执行make命令了。
make命令将编译程序、库和相关脚本。
make check会测试程序是否运行，不过需要编写测试用例。
当一切完成后，我们就可以使用make install来安装程序的，默认情况下降安装在目录/usr/local，比如：

可执行程序在 /usr/local/bin,
库文件在 /usr/local/lib

2.2.2 标准的 Makefile目标
前面我们接触了 make, make check, make install, 和 make installcheck.这里的 check, install和 installcheck称为目标，而 make本身是 make all的缩写。下面是一些常用的make命令：

make all ：编译程序、库、文档等
make install ：安装并拷贝相关文件到系统目录
make uninstall：清除安装的文件（需要在同一个目录执行）
make clean：清除由make生产的编译文件
make distclean：清除由configure创建的文件
make check：运行测试用例
make installcheck：检查安装的程序或库
make dist：从源码制作发布归档文件PACKAGE-VERSION.tar.gz

2.2.3 标准目录变量
GNU的编码标准也指定了安装的目录层，如下所示：



目录变量
默认值



prefix
/usr/local


exec_prefix
${prefix}


bindir
${exec_prefix}/bin


libdir
${exec_prefix}/lib


…



includedir
${prefix}/include


datarootdir
${prefix}/share


datadir
${datarootdir}


mandir
${datarootdir}/man


infodir
${datarootdir}/info


docdir
${datarootdir}/doc/${PACKAGE}


…



安装的时候，安装的文件就会按照到上述变量的一个目录中。比如示例 amhello-1.0，可执行程序 hello将安装到BINDIR， README安装到DOCDIR，默认路径为/usr/local/share/doc/amhello.
如果希望安装到自己的目录，可以使用以下参数：
~/amhello-1.0 % ./configure --prefix ~/usr...~/amhello-1.0 % make...~/amhello-1.0 % make install...

将安装为 ~/usr/bin/hello，~/usr/share/doc/amhello/README.
更多参数可以使用 ./configure --help.
2.2.4 标准配置变量
GNU的编码标准也指定了编译中一系列的配置变量，如下所示：



变量
含义



CC
C编译器


CFLAGS
C编译器参数


CXX
C++编译器


CXXFLAGS
C++编译器参数


LDFLAGS
链接参数


CPPFLAGS
C/C++预处理参数


…



configure一本都会设定好默认的参数值，不过如果希望覆盖默认参数，就需要修改这些值了比如通过 configure强制设定 gcc-3作为C编译器，使用 ~/usr/include的头文件编译，使用 ~/usr/lib的库进行连接。
~/amhello-1.0 % ./configure --prefix ~/usr CC=gcc-3 CPPFLAGS=-I$HOME/usr/include LDFLAGS=-L$HOME/usr/lib


这些变量均可以通过./configure --help查看

2.2.5 使用文件config.site重置默认的配置
在安装多个文件的时候，如果配置参数一致，那么创建一个通用的文件将十分简便。如果文件PREFIX/share/config.site存在，在configure的时候将自动导入这些参数。
重新调用上一节的命令：
~/amhello-1.0 % ./configure --prefix ~/usr CC=gcc-3 \CPPFLAGS=-I$HOME/usr/include LDFLAGS=-L$HOME/usr/lib

此时我们就可以把下面的内容写入文件 ~/usr/share/config.site
 test -z "$CC" &amp;&amp; CC=gcc-3
 test -z "$CPPFLAGS" &amp;&amp; CPPFLAGS=-I$HOME/usr/include
 test -z "$LDFLAGS" &amp;&amp; LDFLAGS=-L$HOME/usr/lib

然后，每次执行 configure都会load这个文件
~/amhello-1.0 % ./configure --prefix ~/usrconfigure: loading site script /home/adl/usr/share/config.site...

2.2.6 并行编译树（Parallel Build Trees） (又名VPATH Builds)
GNU Build System区分两个目录树：源码树和编译树。
源码树包含文件 configure及源码，编译树位于 configure运行的目录。一般编译树的布局与源码树类似。
正常情况下，我们可能会在源码树目录直接执行 configure命令，还有一种情况是如果希望保持源码树的整洁，在其他目录来进行编译，如下所示：
~ % tar zxf ~/amhello-1.0.tar.gz~ % cd amhello-1.0~/amhello-1.0 % mkdir build &amp;&amp; cd build~/amhello-1.0/build % ../configure...~/amhello-1.0/build % make...

源码树与编译树的目录不同即被称为“parallel builds” 或 “VPATH builds”。
这个源码与编译不在同一个目录的方式对不同的配置参数进行编译特别方便，比如我们通过不同的配置参数来分别编译：
~ % tar zxf ~/amhello-1.0.tar.gz~ % cd amhello-1.0~/amhello-1.0 % mkdir debug optim &amp;&amp; cd debug~/amhello-1.0/debug % ../configure CFLAGS='-g -O0'...~/amhello-1.0/debug % make...~/amhello-1.0/debug % cd ../optim~/amhello-1.0/optim % ../configure CFLAGS='-O3 -fomit-frame-pointer'...~/amhello-1.0/optim % make...

对于网络文件系统，这种方式更方便了，比如我们在两个主机 HOST1和HOST2上分别编译，
~ % cd /nfs/src/nfs/src % tar zxf ~/amhello-1.0.tar.gz#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%[HOST1] ~ % mkdir /tmp/amh &amp;&amp; cd /tmp/amh[HOST1] /tmp/amh % /nfs/src/amhello-1.0/configure...[HOST1] /tmp/amh % make &amp;&amp; sudo make install...#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%[HOST2] ~ % mkdir /tmp/amh &amp;&amp; cd /tmp/amh[HOST2] /tmp/amh % /nfs/src/amhello-1.0/configure...[HOST2] /tmp/amh % make &amp;&amp; sudo make install...

 这种情况下，不会对源码目录有任何特殊需求，就算是只读也可编译，这个功能最开始主要是因为当时FSF使用CD-ROM发布，而CD只能读取。
2.2.7 两步安装
GNU编译系统还支持两步安装，什么意思的，也就是区分两种类型的文件，架构相关的和架构无关的，可以通过不同的 Makefile 来完成相关安装。
其实对于我们平时使用的make install是由两部分组成的：

架构相关的 install-exec
架构无关的install-data

 从GNU编译系统的角度来看，架构相关与架构无关主要是安装环境及变量不同。所以架构相关的我们使用 make install-exec来安装，架构无关的直接使用make install-data来安装。
举个例子来看看：有两台主机需要安装，假定 (1) 程序安装到 /usr, (2) 目录 /usr/share共享。
在第一台host上，执行On the first host we would run
[HOST1] ~ % mkdir /tmp/amh &amp;&amp; cd /tmp/amh[HOST1] /tmp/amh % /nfs/src/amhello-1.0/configure --prefix /usr...[HOST1] /tmp/amh % make &amp;&amp; sudo make install...

   On the second host, however, we need only install thearchitecture-specific files.
[HOST2] ~ % mkdir /tmp/amh &amp;&amp; cd /tmp/amh[HOST2] /tmp/amh % /nfs/src/amhello-1.0/configure --prefix /usr...[HOST2] /tmp/amh % make &amp;&amp; sudo make install-exec...

   In packages that have installation checks, it would make sense to runmake installcheck to verify that thepackage works correctly despite the apparent partial installation.
2.2.8 交叉编译
这个功能特别有用，我们可以在一个平台编译，而在另外一个平台运行。
其中参数为：

--build=BUILD：软件包的编译系统
--host=HOST：软件和库将要运行的系统

 再加上 --host参数的时候， configure就会搜索这个平台的交叉编译套件。交叉编译工具一般在名字前有目标架构作为前缀，比如 MinGW32 编译环境被称为i586-mingw32msvc-gcc, i586-mingw32msvc-ld, i586-mingw32msvc-as等。
接下来的操作介绍如何在GNU/Linux上为 i586-mingw32msvc编译 amhello-1.0。
~/amhello-1.0 % ./configure --build i686-pc-linux-gnu --host i586-mingw32msvcchecking for a BSD-compatible install... /usr/bin/install -cchecking whether build environment is sane... yeschecking for gawk... gawkchecking whether make sets $(MAKE)... yeschecking for i586-mingw32msvc-strip... i586-mingw32msvc-stripchecking for i586-mingw32msvc-gcc... i586-mingw32msvc-gccchecking for C compiler default output file name... a.exechecking whether the C compiler works... yeschecking whether we are cross compiling... yeschecking for suffix of executables... .exechecking for suffix of object files... ochecking whether we are using the GNU C compiler... yeschecking whether i586-mingw32msvc-gcc accepts -g... yeschecking for i586-mingw32msvc-gcc option to accept ANSI C......~/amhello-1.0 % make...~/amhello-1.0 % cd src; file hello.exehello.exe: MS Windows PE 32-bit Intel 80386 console executable not relocatable

2.2.9 安装时重命名程序
可以使用 configure的编译选项，在安装之前加上特定的前缀或后缀来避免与系统程序冲突。

--program-prefix=PREFIX：增加前缀
--program-suffix=SUFFIX：增加后缀
--program-transform-name=PROGRAM：安装时运行sed PROGRAM

比如下面的例子将安装 hello到/usr/local/bin/test-hello。
~/amhello-1.0 % ./configure --program-prefix test-...~/amhello-1.0 % make...~/amhello-1.0 % sudo make install...

2.2.10 使用DESTDIR编译二进制包
单纯的GNU Build System的 make install和 make uninstall接口并不能完全满足系统管理员的部署，比如我们希望在编译的时候安装指定路径，而在make的时候因为可能没有root权限暂时放在一个临时目录，然后再部署到其他机器。
比如像下面这个例子就很好的诠释了这个方法。
~/amhello-1.0 % ./configure --prefix /usr...~/amhello-1.0 % make...~/amhello-1.0 % make DESTDIR=$HOME/inst install...~/amhello-1.0 % cd ~/inst~/inst % find . -type f -print &gt; ../files.lst~/inst % tar zcvf ~/amhello-1.0-i686.tar.gz `cat ../files.lst`./usr/bin/hello./usr/share/doc/amhello/README

然后，我们就可以把 amhello-1.0-i686.tar.gz解压到大部分主机的 /目录了。

注意使用cat ../files.lst而不是.是为了避免子目录的归档问题，保证在解压的时候按照预定的目录进行解压。

2.2.11 准备发布
 make dist收集源码及必须的文件创建一个压缩包，名为 PACKAGE-VERSION.tar.gz。
虽然也能满足大部分的功能，但是还有一个更有用的命令 make distcheck，这个命令也会像 make dist一样创建压缩包 PACKAGE-VERSION.tar.gz，并会做各种各样的检查以确保压缩包没有问题：
   • 将运行所有的软件包命令，比如 make, make check, make install和 make installcheck, 甚至是 make dist，来确保软件发布没有问题   • 测试只读源码树的VPATH编译   • 确保 make clean, make distclean, and make uninstall不忽略任何文件   • 检查 DESTDIR安装是否工作
所有的这些操作都在一个临时目录进行，所以并不需要root权限。
如果 make distcheck失败了，意味着其中的一个场景没有满足，可能不会影响程序的使用，不过最好根据失败的提示进一步改进得到一个完美的发布包。
2.2.12 自动依赖跟踪
Automake自动生成代码来解决依赖的问题。
在 configure执行的时候，我们可以看到这个过程：
~/amhello-1.0 % ./configure --prefix /usr...checking dependency style of gcc... gcc3...

可以通过下面两个选项来使能或禁用依赖跟踪：

--disable-dependency-tracking ：Speed up one-time builds.
--enable-dependency-tracking：Do not reject slow dependency extractors.

2.2.13 嵌套包
虽然并不推荐刚开始接触Autotools的时候就了解嵌套包，但是最为一个极具特性的功能还是需要了解一下的。 
使用Autotools或者相关工具开发的时候可以任意潜逃子模块，比如包A的发布将需要字幕了的一个库，库B拥有自己的一套构建系统，那么包A的 configure脚本将先运行库B的 configure脚本，所以安装编译包A的同时也安装编译了库B。生成的包A的发型版也将包含库B。
当然还可以收集更多的包，GCC重度使用这个功能，这样就可以保证每个子模块均可以独立的开发了。 
可以使用命令 configure --help=recursive来显示所有包含包的选项。
2.3 Autotools大有裨益
或许你只是希望完成一些可以通过自行编写 configure和 Makefile来完成的功能：
   • 不需要特别多的功能   • 需要考虑移植的代价   • 随着GNU Coding Standards的改变需要及时升级配置文件
   而 GNU Autotools 就把这些工作自己悄悄的做掉了，只需要关注你的代码即可。
2.4 经典Hello World小程序
本节中我们首先重新从头创建 amhello-1.0软件包，然后介绍下configure.ac和 Makefile.am的含义。
2.4.1 创建 amhello-1.0.tar.gz
接下来我们从头创建 amhello-1.0.tar.gz ，这个压缩包很简单，我们只需要准备5个文件即可。在一个空目录中创建以下文件：
   • src/main.c：程序 hello的源文件，我们把这个文件保存在 src/子目录，这样方便以后添加诸如man/和 data/的文件夹。
~/amhello % cat src/main.c#include &lt;config.h&gt;#include &lt;stdio.h&gt;intmain (void){	puts ("Hello World!");	puts ("This is " PACKAGE_STRING ".");	return 0;}

   • README：包含一些说明文档
~/amhello % cat READMEThis is a demonstration package for GNU Automake.Type 'info Automake' to read the Automake manual.

   • Makefile.am和 src/Makefile.am包含Automake的指令
~/amhello % cat src/Makefile.ambin_PROGRAMS = hellohello_SOURCES = main.c#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%~/amhello % cat Makefile.amSUBDIRS = srcdist_doc_DATA = README

   •  configure.ac包含创建 configure脚本的Autoconf指令
~/amhello % cat configure.acAC_INIT([amhello], [1.0], [bug-automake@gnu.org])AM_INIT_AUTOMAKE([-Wall -Werror foreign])AC_PROG_CCAC_CONFIG_HEADERS([config.h])AC_CONFIG_FILES([Makefilesrc/Makefile])AC_OUTPUT

准备好这些文件就可以运行 Autotools 了，使用 autoreconf指令：
~/amhello % autoreconf --installconfigure.ac: installing './install-sh'configure.ac: installing './missing'configure.ac: installing './compile'src/Makefile.am: installing './depcomp'

搞定，此时就完成了编译工作。
除了提示的添加的文件， autoreconf还会创建另外4个文件： configure, config.h.in,Makefile.in和 src/Makefile.in.   configure将使用后面的3个文件来创建 config.h, Makefile和 src/Makefile。
~/amhello % ./configurechecking for a BSD-compatible install... /usr/bin/install -cchecking whether build environment is sane... yeschecking for gawk... nochecking for mawk... mawkchecking whether make sets $(MAKE)... yeschecking for gcc... gccchecking for C compiler default output file name... a.outchecking whether the C compiler works... yeschecking whether we are cross compiling... nochecking for suffix of executables...checking for suffix of object files... ochecking whether we are using the GNU C compiler... yeschecking whether gcc accepts -g... yeschecking for gcc option to accept ISO C89... none neededchecking for style of include used by make... GNUchecking dependency style of gcc... gcc3configure: creating ./config.statusconfig.status: creating Makefileconfig.status: creating src/Makefileconfig.status: creating config.hconfig.status: executing depfiles commands

此时我们就可以看到已经创建了 Makefile, src/Makefile和 config.h。
~/amhello % make...~/amhello % src/helloHello World!This is amhello 1.0.~/amhello % make distcheck...=============================================amhello-1.0 archives ready for distribution:amhello-1.0.tar.gz=============================================

autoreconf只需要运行一次即可，在构建后环境，后续更改了 Makefile.am及 configure.ac，在 make的时候会自动重建需要的依赖。
autoreconf是 autoconf, automake等一些列命令的集合。
其中 autoconf负责从configure.ac创建 configure；
automake从configure.ac和Makefile.am创建 Makefile.in。
2.4.2  configure.ac 配置详解
看看文件 configure.ac：
 AC_INIT([amhello], [1.0], [bug-automake@gnu.org])
 AM_INIT_AUTOMAKE([-Wall -Werror foreign])
 AC_PROG_CC
 AC_CONFIG_HEADERS([config.h])
 AC_CONFIG_FILES([
  Makefile
  src/Makefile
 ])
 AC_OUTPUT

这个文件被 autoconf(创建 configure) 和automake(创建 Makefile.ins)读取。这个文件包含一系列的M4宏。
以 AC_开头的是Autoconf 宏，以 AM_开头的是Automake 宏。
configure.ac的前两行用于初始化 Autoconf 和Automake。 AC_INIT的参数为软件包，版本及联系邮箱(可以使用 ./configure --help来看到)。

记得邮箱要使用自己的

AM_INIT_AUTOMAKE的参数为automake的选项，比如  -Wall和 -Werror为打开所有的警告和错误报告。                                                                                                                                                                                                       foreign选项告诉Automake这个包不遵从GNU标准。GNU包需要包含ChangeLog, AUTHORS等文件。如果我们不希望automake抱怨就需要加上这个选项。
 AC_PROG_CC可以指定 configure脚本的C编译器。文件src/Makefile.in将使用这里定义的编译器来编译生成hello，当 configure从 src/Makefile.in创建src/Makefile的时候会用到。
选项 AC_CONFIG_HEADERS([config.h])将使 configure脚本创建一个文件config.h用于汇总configure.ac文件中所有定义的宏。在我们的例子中国呢，AC_INIT宏已经定义了一部分了。比如下面这个例子：
.../* Define to the address where bug reports for this package should be sent. */#define PACKAGE_BUGREPORT "bug-automake@gnu.org"/* Define to the full name and version of this package. */#define PACKAGE_STRING "amhello 1.0"...

我们可能注意到文件src/main.c 包含头文件config.h，这样就可以使用 PACKAGE_STRING。
AC_CONFIG_FILES宏定义了configure需要从 *.in模版生成的文件。Automake将遍历需要的 Makefile.am文件，所以如果新增了一个文件夹，一定要记得添加 Makefile到这个列表。
 AC_OUTPUT行为结束命令。
2.4.3 amhello 的 Makefile.am配置详解
接下来我们看看文件 src/Makefile.am，这个文件包含Automake编译安装 hello的指令。
bin_PROGRAMS = hello
hello_SOURCES = main.c

 Makefile.am 与 Makefile有相同的语法。automake在处理Makefile.am的时候，会拷贝整个文件到 Makefile.in。
以 _PROGRAMS结尾的变量为 Makefiles将要编译的程序。还有其他后缀变量，比如 _SCRIPTS, _DATA, _LIBRARIES等，参考后面的章节。
 bin_PROGRAMS的 bin部分表示 automake将把该程序安装到BINDIR。

注意此处省略了dir

程序需要从源码编译，所以对于每一个以 _PROGRAMS结尾的PROG都需要有一个变量为 PROG_SOURCES，后面将列出所有编译时需要的源文件。
Automake也会通过这个源码文件在打包 make dist的时候一起发布。
最后我们看看顶层目录的文件Makefile.am
SUBDIRS = src
dist_doc_DATA = README

SUBDIRS是一个特殊的变量，用来列出在处理当前目录之前 make需要遍历的目录。
 dist_doc_DATA = README将会把文件 README发布和安装到DOCDIR。以 _DATA结尾的变量默认情况下在 make dist发布时是不包含的，所以我们新增了前缀dist_。
]]></content>
      <categories>
        <category>Linux</category>
        <category>Automake</category>
        <category>Makefile</category>
      </categories>
      <tags>
        <tag>autotools</tag>
        <tag>automake</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux Automake 27 Frequently Asked Questions about Automake</title>
    <url>/2018/05/20/linux-automake-27-frequently-asked-questions-about-automake/</url>
    <content><![CDATA[
GNU Automake 版本(version 1.16.1, 26 February 2018)
Permission is granted to copy, distribute and/or modify thisdocument under the terms of the GNU Free Documentation License,Version 1.3 or any later version published by the Free SoftwareFoundation; with no Invariant Sections, with no Front-Cover texts,and with no Back-Cover Texts.  A copy of the license is included inthe section entitled “GNU Free Documentation License.”

27 Frequently Asked Questions about Automake

This chapter covers some questions that often come up on the mailinglists.
27.1 CVS and generated filesBackground: distributed generated FilesPackages made with Autoconf and Automake ship with some generated fileslike ‘configure’ or ‘Makefile.in’.  These files were generated on thedeveloper’s machine and are distributed so that end-users do not have toinstall the maintainer tools required to rebuild them.  Other generatedfiles like Lex scanners, Yacc parsers, or Info documentation, areusually distributed on similar grounds.
   Automake output rules in ‘Makefile’s to rebuild these files.  Forinstance, ‘make’ will run ‘autoconf’ to rebuild ‘configure’ whenever‘configure.ac’ is changed.  This makes development safer by ensuring a‘configure’ is never out-of-date with respect to ‘configure.ac’.
   As generated files shipped in packages are up-to-date, and because‘tar’ preserves times-tamps, these rebuild rules are not triggered whena user unpacks and builds a package.
Background: CVS and TimestampsUnless you use CVS keywords (in which case files must be updated atcommit time), CVS preserves timestamp during ‘cvs commit’ and ‘cvsimport -d’ operations.
   When you check out a file using ‘cvs checkout’ its timestamp is setto that of the revision that is being checked out.
   However, during ‘cvs update’, files will have the date of the update,not the original timestamp of this revision.  This is meant to make surethat ‘make’ notices sources files have been updated.
   This timestamp shift is troublesome when both sources and generatedfiles are kept under CVS.  Because CVS processes files in lexical order,‘configure.ac’ will appear newer than ‘configure’ after a ‘cvs update’that updates both files, even if ‘configure’ was newer than‘configure.ac’ when it was checked in.  Calling ‘make’ will then triggera spurious rebuild of ‘configure’.
Living with CVS in Autoconfiscated ProjectsThere are basically two clans amongst maintainers: those who keep alldistributed files under CVS, including generated files, and those whokeep generated files out of CVS.
All Files in CVS…………….
   • The CVS repository contains all distributed files so you know     exactly what is distributed, and you can checkout any prior version     entirely.
   • Maintainers can see how generated files evolve (for instance, you     can see what happens to your ‘Makefile.in’s when you upgrade     Automake and make sure they look OK).
   • Users do not need the autotools to build a checkout of the project,     it works just like a released tarball.
   • If users use ‘cvs update’ to update their copy, instead of ‘cvs     checkout’ to fetch a fresh one, timestamps will be inaccurate.     Some rebuild rules will be triggered and attempt to run developer     tools such as ‘autoconf’ or ‘automake’.
 Calls to such tools are all wrapped into a call to the ‘missing’
 script discussed later (*note maintainer-mode::), so that the user
 will see more descriptive warnings about missing or out-of-date
 tools, and possible suggestions about how to obtain them, rather
 than just some “command not found” error, or (worse) some obscure
 message from some older version of the required tool they happen to
 have installed.

 Maintainers interested in keeping their package buildable from a
 CVS checkout even for those users that lack maintainer-specific
 tools might want to provide an helper script (or to enhance their
 existing bootstrap script) to fix the timestamps after a ‘cvs
 update’ or a ‘git checkout’, to prevent spurious rebuilds.  In case
 of a project committing the Autotools-generated files, as well as
 the generated ‘.info’ files, such script might look something like
 this:

      #!/bin/sh
      # fix-timestamp.sh: prevents useless rebuilds after "cvs update"
      sleep 1
      # aclocal-generated aclocal.m4 depends on locally-installed
      # '.m4' macro files, as well as on 'configure.ac'
      touch aclocal.m4
      sleep 1
      # autoconf-generated configure depends on aclocal.m4 and on
      # configure.ac
      touch configure
      # so does autoheader-generated config.h.in
      touch config.h.in
      # and all the automake-generated Makefile.in files
      touch `find . -name Makefile.in -print`
      # finally, the makeinfo-generated '.info' files depend on the
      # corresponding '.texi' files
      touch doc/*.info

   • In distributed development, developers are likely to have different     version of the maintainer tools installed.  In this case rebuilds     triggered by timestamp lossage will lead to spurious changes to     generated files.  There are several solutions to this:
    • All developers should use the same versions, so that the
      rebuilt files are identical to files in CVS.  (This starts to
      be difficult when each project you work on uses different
      versions.)
    • Or people use a script to fix the timestamp after a checkout
      (the GCC folks have such a script).
    • Or ‘configure.ac’ uses ‘AM_MAINTAINER_MODE’, which will
      disable all of these rebuild rules by default.  This is
      further discussed in *note maintainer-mode::.

   • Although we focused on spurious rebuilds, the converse can also     happen.  CVS’s timestamp handling can also let you think an     out-of-date file is up-to-date.
 For instance, suppose a developer has modified ‘Makefile.am’ and
 has rebuilt ‘Makefile.in’, and then decides to do a last-minute
 change to ‘Makefile.am’ right before checking in both files
 (without rebuilding ‘Makefile.in’ to account for the change).

 This last change to ‘Makefile.am’ makes the copy of ‘Makefile.in’
 out-of-date.  Since CVS processes files alphabetically, when
 another developer ‘cvs update’s his or her tree, ‘Makefile.in’ will
 happen to be newer than ‘Makefile.am’.  This other developer will
 not see that ‘Makefile.in’ is out-of-date.

Generated Files out of CVS……………………..
One way to get CVS and ‘make’ working peacefully is to never storegenerated files in CVS, i.e., do not CVS-control files that are‘Makefile’ targets (also called derived files).
   This way developers are not annoyed by changes to generated files.It does not matter if they all have different versions (assuming theyare compatible, of course).  And finally, timestamps are not lost,changes to sources files can’t be missed as in the‘Makefile.am’/‘Makefile.in’ example discussed earlier.
   The drawback is that the CVS repository is not an exact copy of whatis distributed and that users now need to install various developmenttools (maybe even specific versions) before they can build a checkout.But, after all, CVS’s job is versioning, not distribution.
   Allowing developers to use different versions of their tools can alsohide bugs during distributed development.  Indeed, developers will beusing (hence testing) their own generated files, instead of thegenerated files that will be released actually.  The developer whoprepares the tarball might be using a version of the tool that producesbogus output (for instance a non-portable C file), something otherdevelopers could have noticed if they weren’t using their own versionsof this tool.
Third-party FilesAnother class of files not discussed here (because they do not causetimestamp issues) are files that are shipped with a package, butmaintained elsewhere.  For instance, tools like ‘gettextize’ and‘autopoint’ (from Gettext) or ‘libtoolize’ (from Libtool), will installor update files in your package.
   These files, whether they are kept under CVS or not, raise similarconcerns about version mismatch between developers’ tools.  The Gettextmanual has a section about this, see *note CVS Issues: (gettext)CVSIssues.
27.2 ‘missing’ and ‘AM_MAINTAINER_MODE’‘missing’The ‘missing’ script is a wrapper around several maintainer tools,designed to warn users if a maintainer tool is required but missing.Typical maintainer tools are ‘autoconf’, ‘automake’, ‘bison’, etc.Because file generated by these tools are shipped with the other sourcesof a package, these tools shouldn’t be required during a user build andthey are not checked for in ‘configure’.
   However, if for some reason a rebuild rule is triggered and involvesa missing tool, ‘missing’ will notice it and warn the user, evensuggesting how to obtain such a tool (at least in case it is awell-known one, like ‘makeinfo’ or ‘bison’).  This is more helpful anduser-friendly than just having the rebuild rules spewing out a terseerror message like ‘sh: TOOL: command not found’.  Similarly, ‘missing’will warn the user if it detects that a maintainer tool it attempted touse seems too old (be warned that diagnosing this correctly is typicallymore difficult that detecting missing tools, and requires cooperationfrom the tool itself, so it won’t always work).
   If the required tool is installed, ‘missing’ will run it and won’tattempt to continue after failures.  This is correct during development:developers love fixing failures.  However, users with missing or too oldmaintainer tools may get an error when the rebuild rule is spuriouslytriggered, halting the build.  This failure to let the build continue isone of the arguments of the ‘AM_MAINTAINER_MODE’ advocates.
‘AM_MAINTAINER_MODE’‘AM_MAINTAINER_MODE’ allows you to choose whether the so called “rebuildrules” should be enabled or disabled.  With‘AM_MAINTAINER_MODE([enable])’, they are enabled by default, otherwisethey are disabled by default.  In the latter case, if you have‘AM_MAINTAINER_MODE’ in ‘configure.ac’, and run ‘./configure &amp;&amp; make’,then ‘make’ will never attempt to rebuild ‘configure’, ‘Makefile.in’s,Lex or Yacc outputs, etc.  I.e., this disables build rules for filesthat are usually distributed and that users should normally not have toupdate.
   The user can override the default setting by passing either‘–enable-maintainer-mode’ or ‘–disable-maintainer-mode’ to‘configure’.
   People use ‘AM_MAINTAINER_MODE’ either because they do not want theirusers (or themselves) annoyed by timestamps lossage (*note CVS::), orbecause they simply can’t stand the rebuild rules and prefer runningmaintainer tools explicitly.
   ‘AM_MAINTAINER_MODE’ also allows you to disable some custom buildrules conditionally.  Some developers use this feature to disable rulesthat need exotic tools that users may not have available.
   Several years ago François Pinard pointed out several argumentsagainst this ‘AM_MAINTAINER_MODE’ macro.  Most of them relate toinsecurity.  By removing dependencies you get non-dependable builds:changes to sources files can have no effect on generated files and thiscan be very confusing when unnoticed.  He adds that security shouldn’tbe reserved to maintainers (what ‘–enable-maintainer-mode’ suggests),on the contrary.  If one user has to modify a ‘Makefile.am’, then either‘Makefile.in’ should be updated or a warning should be output (this iswhat Automake uses ‘missing’ for) but the last thing you want is thatnothing happens and the user doesn’t notice it (this is what happenswhen rebuild rules are disabled by ‘AM_MAINTAINER_MODE’).
   Jim Meyering, the inventor of the ‘AM_MAINTAINER_MODE’ macro wasswayed by François’s arguments, and got rid of ‘AM_MAINTAINER_MODE’ inall of his packages.
   Still many people continue to use ‘AM_MAINTAINER_MODE’, because ithelps them working on projects where all files are kept under versioncontrol, and because ‘missing’ isn’t enough if you have the wrongversion of the tools.
27.3 Why doesn’t Automake support wildcards?Developers are lazy.  They would often like to use wildcards in‘Makefile.am’s, so that they would not need to remember to update‘Makefile.am’s every time they add, delete, or rename a file.
   There are several objections to this:   • When using CVS (or similar) developers need to remember they have     to run ‘cvs add’ or ‘cvs rm’ anyway.  Updating ‘Makefile.am’     accordingly quickly becomes a reflex.
 Conversely, if your application doesn’t compile because you forgot
 to add a file in ‘Makefile.am’, it will help you remember to ‘cvs
 add’ it.

   • Using wildcards makes it easy to distribute files by mistake.  For     instance, some code a developer is experimenting with (a test case,     say) that should not be part of the distribution.
   • Using wildcards it’s easy to omit some files by mistake.  For     instance, one developer creates a new file, uses it in many places,     but forgets to commit it.  Another developer then checks out the     incomplete project and is able to run ‘make dist’ successfully,     even though a file is missing.  By listing files, ‘make dist’     will complain.
   • Wildcards are not portable to some non-GNU ‘make’ implementations,     e.g., NetBSD ‘make’ will not expand globs such as ‘*’ in     prerequisites of a target.
   • Finally, it’s really hard to forget to add a file to     ‘Makefile.am’: files that are not listed in ‘Makefile.am’ are not     compiled or installed, so you can’t even test them.
   Still, these are philosophical objections, and as such you maydisagree, or find enough value in wildcards to dismiss all of them.Before you start writing a patch against Automake to teach it aboutwildcards, let’s see the main technical issue: portability.
   Although ‘$(wildcard …)’ works with GNU ‘make’, it is not portableto other ‘make’ implementations.
   The only way Automake could support ‘$(wildcard …)’ is by expanding‘$(wildcard …)’ when ‘automake’ is run.  The resulting ‘Makefile.in’swould be portable since they would list all files and not use‘$(wildcard …)’.  However that means developers would need to rememberto run ‘automake’ each time they add, delete, or rename files.
   Compared to editing ‘Makefile.am’, this is a very small gain.  Sure,it’s easier and faster to type ‘automake; make’ than to type ‘emacsMakefile.am; make’.  But nobody bothered enough to write a patch to addsupport for this syntax.  Some people use scripts to generate file listsin ‘Makefile.am’ or in separate ‘Makefile’ fragments.
   Even if you don’t care about portability, and are tempted to use‘$(wildcard …)’ anyway because you target only GNU Make, you shouldknow there are many places where Automake needs to know exactly whichfiles should be processed.  As Automake doesn’t know how to expand‘$(wildcard …)’, you cannot use it in these places.  ‘$(wildcard …)’is a black box comparable to ‘AC_SUBST’ed variables as far Automake isconcerned.
   You can get warnings about ‘$(wildcard …’) constructs using the‘-Wportability’ flag.
27.4 Limitations on File NamesAutomake attempts to support all kinds of file names, even those thatcontain unusual characters or are unusually long.  However, somelimitations are imposed by the underlying operating system and tools.
   Most operating systems prohibit the use of the null byte in filenames, and reserve ‘/’ as a directory separator.  Also, they requirethat file names are properly encoded for the user’s locale.  Automake issubject to these limits.
   Portable packages should limit themselves to POSIX file names.  Thesecan contain ASCII letters and digits, ‘_’, ‘.’, and ‘-’.  File namesconsist of components separated by ‘/’.  File name components cannotbegin with ‘-’.
   Portable POSIX file names cannot contain components that exceed a14-byte limit, but nowadays it’s normally safe to assume themore-generous XOPEN limit of 255 bytes.  POSIX limits file names to 255bytes (XOPEN allows 1023 bytes), but you may want to limit a sourcetarball to file names of 99 bytes to avoid interoperability problemswith old versions of ‘tar’.
   If you depart from these rules (e.g., by using non-ASCII charactersin file names, or by using lengthy file names), your installers may haveproblems for reasons unrelated to Automake.  However, if this does notconcern you, you should know about the limitations imposed by Automakeitself.  These limitations are undesirable, but some of them seem to beinherent to underlying tools like Autoconf, Make, M4, and the shell.They fall into three categorie: install directories, build directories,and file names.
   The following characters:
 newline " # $ ' `

   should not appear in the names of install directories.  For example,the operand of ‘configure’’s ‘–prefix’ option should not contain thesecharacters.
   Build directories suffer the same limitations as install directories,and in addition should not contain the following characters:
 &amp; @ \

   For example, the full name of the directory containing the sourcefiles should not contain these characters.
   Source and installation file names like ‘main.c’ are limited evenfurther: they should conform to the POSIX/XOPEN rules described above.In addition, if you plan to port to non-POSIX environments, you shouldavoid file names that differ only in case (e.g., ‘makefile’ and‘Makefile’).  Nowadays it is no longer worth worrying about the 8.3limits of DOS file systems.
27.5 Errors with distcleanThis is a diagnostic you might encounter while running ‘make distcheck’.
   As explained in *note Checking the Distribution::, ‘make distcheck’attempts to build and check your package for errors like this one.
   ‘make distcheck’ will perform a ‘VPATH’ build of your package (*noteVPATH Builds::), and then call ‘make distclean’.  Files left in thebuild directory after ‘make distclean’ has run are listed after thiserror.
   This diagnostic really covers two kinds of errors:
   • files that are forgotten by distclean;   • distributed files that are erroneously rebuilt.
   The former left-over files are not distributed, so the fix is to markthem for cleaning (*note Clean::), this is obvious and doesn’t deservemore explanations.
   The latter bug is not always easy to understand and fix, so let’sproceed with an example.  Suppose our package contains a program forwhich we want to build a man page using ‘help2man’.  GNU ‘help2man’produces simple manual pages from the ‘–help’ and ‘–version’ output ofother commands (*note Overview: (help2man)Top.).  Because we don’t wantto force our users to install ‘help2man’, we decide to distribute thegenerated man page using the following setup.
 # This Makefile.am is bogus.
 bin_PROGRAMS = foo
 foo_SOURCES = foo.c
 dist_man_MANS = foo.1

 foo.1: foo$(EXEEXT)
         help2man --output=foo.1 ./foo$(EXEEXT)

   This will effectively distribute the man page.  However, ‘makedistcheck’ will fail with:
 ERROR: files left in build directory after distclean:
 ./foo.1

   Why was ‘foo.1’ rebuilt?  Because although distributed, ‘foo.1’depends on a non-distributed built file: ‘foo$(EXEEXT)’.  ‘foo$(EXEEXT)’is built by the user, so it will always appear to be newer than thedistributed ‘foo.1’.
   ‘make distcheck’ caught an inconsistency in our package.  Our intentwas to distribute ‘foo.1’ so users do not need to install ‘help2man’,however since this rule causes this file to be always rebuilt, usersdo need ‘help2man’.  Either we should ensure that ‘foo.1’ is notrebuilt by users, or there is no point in distributing ‘foo.1’.
   More generally, the rule is that distributed files should neverdepend on non-distributed built files.  If you distribute somethinggenerated, distribute its sources.
   One way to fix the above example, while still distributing ‘foo.1’ isto not depend on ‘foo$(EXEEXT)’.  For instance, assuming ‘foo –version’and ‘foo –help’ do not change unless ‘foo.c’ or ‘configure.ac’ change,we could write the following ‘Makefile.am’:
 bin_PROGRAMS = foo
 foo_SOURCES = foo.c
 dist_man_MANS = foo.1

 foo.1: foo.c $(top_srcdir)/configure.ac
         $(MAKE) $(AM_MAKEFLAGS) foo$(EXEEXT)
         help2man --output=foo.1 ./foo$(EXEEXT)

   This way, ‘foo.1’ will not get rebuilt every time ‘foo$(EXEEXT)’changes.  The ‘make’ call makes sure ‘foo$(EXEEXT)’ is up-to-date before‘help2man’.  Another way to ensure this would be to use separatedirectories for binaries and man pages, and set ‘SUBDIRS’ so thatbinaries are built before man pages.
   We could also decide not to distribute ‘foo.1’.  In this case it’sfine to have ‘foo.1’ dependent upon ‘foo$(EXEEXT)’, since both will haveto be rebuilt.  However it would be impossible to build the package in across-compilation, because building ‘foo.1’ involves an execution of‘foo$(EXEEXT)’.
   Another context where such errors are common is when distributedfiles are built by tools that are built by the package.  The pattern issimilar:
 distributed-file: built-tools distributed-sources
         build-command

should be changed to
 distributed-file: distributed-sources
         $(MAKE) $(AM_MAKEFLAGS) built-tools
         build-command

or you could choose not to distribute ‘distributed-file’, ifcross-compilation does not matter.
   The points made through these examples are worth a summary:
   • Distributed files should never depend upon non-distributed built     files.   • Distributed files should be distributed with all their     dependencies.   • If a file is intended to be rebuilt by users, then there is no     point in distributing it.
   For desperate cases, it’s always possible to disable this check bysetting ‘distcleancheck_listfiles’ as documented in *note Checking theDistribution::.  Make sure you do understand the reason why ‘makedistcheck’ complains before you do this.  ‘distcleancheck_listfiles’ isa way to hide errors, not to fix them.  You can always do better.
27.6 Flag Variables Ordering What is the difference between ‘AM_CFLAGS’, ‘CFLAGS’, and
 ‘mumble_CFLAGS’?

 Why does ‘automake’ output ‘CPPFLAGS’ after
 ‘AM_CPPFLAGS’ on compile lines?  Shouldn’t it be the converse?

 My ‘configure’ adds some warning flags into ‘CXXFLAGS’.  In
 one ‘Makefile.am’ I would like to append a new flag, however if I
 put the flag into ‘AM_CXXFLAGS’ it is prepended to the other
 flags, not appended.

Compile Flag VariablesThis section attempts to answer all the above questions.  We will mostlydiscuss ‘CPPFLAGS’ in our examples, but actually the answer holds forall the compile flags used in Automake: ‘CCASFLAGS’, ‘CFLAGS’,‘CPPFLAGS’, ‘CXXFLAGS’, ‘FCFLAGS’, ‘FFLAGS’, ‘GCJFLAGS’, ‘LDFLAGS’,‘LFLAGS’, ‘LIBTOOLFLAGS’, ‘OBJCFLAGS’, ‘OBJCXXFLAGS’, ‘RFLAGS’,‘UPCFLAGS’, and ‘YFLAGS’.
   ‘CPPFLAGS’, ‘AM_CPPFLAGS’, and ‘mumble_CPPFLAGS’ are three variablesthat can be used to pass flags to the C preprocessor (actually thesevariables are also used for other languages like C++ or preprocessedFortran).  ‘CPPFLAGS’ is the user variable (*note User Variables::),‘AM_CPPFLAGS’ is the Automake variable, and ‘mumble_CPPFLAGS’ is thevariable specific to the ‘mumble’ target (we call this a per-targetvariable, *note Program and Library Variables::).
   Automake always uses two of these variables when compiling C sourcesfiles.  When compiling an object file for the ‘mumble’ target, the firstvariable will be ‘mumble_CPPFLAGS’ if it is defined, or ‘AM_CPPFLAGS’otherwise.  The second variable is always ‘CPPFLAGS’.
   In the following example,
 bin_PROGRAMS = foo bar
 foo_SOURCES = xyz.c
 bar_SOURCES = main.c
 foo_CPPFLAGS = -DFOO
 AM_CPPFLAGS = -DBAZ

‘xyz.o’ will be compiled with ‘$(foo_CPPFLAGS) $(CPPFLAGS)’, (because‘xyz.o’ is part of the ‘foo’ target), while ‘main.o’ will be compiledwith ‘$(AM_CPPFLAGS) $(CPPFLAGS)’ (because there is no per-targetvariable for target ‘bar’).
   The difference between ‘mumble_CPPFLAGS’ and ‘AM_CPPFLAGS’ beingclear enough, let’s focus on ‘CPPFLAGS’.  ‘CPPFLAGS’ is a user variable,i.e., a variable that users are entitled to modify in order to compilethe package.  This variable, like many others, is documented at the endof the output of ‘configure –help’.
   For instance, someone who needs to add ‘/home/my/usr/include’ to theC compiler’s search path would configure a package with
 ./configure CPPFLAGS='-I /home/my/usr/include'

and this flag would be propagated to the compile rules of all‘Makefile’s.
   It is also not uncommon to override a user variable at ‘make’-time.Many installers do this with ‘prefix’, but this can be useful withcompiler flags too.  For instance, if, while debugging a C++ project,you need to disable optimization in one specific object file, you canrun something like
 rm file.o
 make CXXFLAGS=-O0 file.o
 make

   The reason ‘$(CPPFLAGS)’ appears after ‘$(AM_CPPFLAGS)’ or‘$(mumble_CPPFLAGS)’ in the compile command is that users should alwayshave the last say.  It probably makes more sense if you think about itwhile looking at the ‘CXXFLAGS=-O0’ above, which should supersede anyother switch from ‘AM_CXXFLAGS’ or ‘mumble_CXXFLAGS’ (and this of coursereplaces the previous value of ‘CXXFLAGS’).
   You should never redefine a user variable such as ‘CPPFLAGS’ in‘Makefile.am’.  Use ‘automake -Woverride’ to diagnose such mistakes.Even something like
 CPPFLAGS = -DDATADIR=\"$(datadir)\" @CPPFLAGS@

is erroneous.  Although this preserves ‘configure’’s value of‘CPPFLAGS’, the definition of ‘DATADIR’ will disappear if a userattempts to override ‘CPPFLAGS’ from the ‘make’ command line.
 AM_CPPFLAGS = -DDATADIR=\"$(datadir)\"

is all that is needed here if no per-target flags are used.
   You should not add options to these user variables within ‘configure’either, for the same reason.  Occasionally you need to modify thesevariables to perform a test, but you should reset their valuesafterwards.  In contrast, it is OK to modify the ‘AM_’ variables within‘configure’ if you ‘AC_SUBST’ them, but it is rather rare that you needto do this, unless you really want to change the default definitions ofthe ‘AM_’ variables in all ‘Makefile’s.
   What we recommend is that you define extra flags in separatevariables.  For instance, you may write an Autoconf macro that computesa set of warning options for the C compiler, and ‘AC_SUBST’ them in‘WARNINGCFLAGS’; you may also have an Autoconf macro that determineswhich compiler and which linker flags should be used to link withlibrary ‘libfoo’, and ‘AC_SUBST’ these in ‘LIBFOOCFLAGS’ and‘LIBFOOLDFLAGS’.  Then, a ‘Makefile.am’ could use these variables asfollows:
 AM_CFLAGS = $(WARNINGCFLAGS)
 bin_PROGRAMS = prog1 prog2
 prog1_SOURCES = ...
 prog2_SOURCES = ...
 prog2_CFLAGS = $(LIBFOOCFLAGS) $(AM_CFLAGS)
 prog2_LDFLAGS = $(LIBFOOLDFLAGS)

   In this example both programs will be compiled with the flagssubstituted into ‘$(WARNINGCFLAGS)’, and ‘prog2’ will additionally becompiled with the flags required to link with ‘libfoo’.
   Note that listing ‘AM_CFLAGS’ in a per-target ‘CFLAGS’ variable is acommon idiom to ensure that ‘AM_CFLAGS’ applies to every target in a‘Makefile.in’.
   Using variables like this gives you full control over the ordering ofthe flags.  For instance, if there is a flag in $(WARNINGCFLAGS) thatyou want to negate for a particular target, you can use something like‘prog1_CFLAGS = $(AM_CFLAGS) -no-flag’.  If all of these flags had beenforcefully appended to ‘CFLAGS’, there would be no way to disable oneflag.  Yet another reason to leave user variables to users.
   Finally, we have avoided naming the variable of the example‘LIBFOO_LDFLAGS’ (with an underscore) because that would cause Automaketo think that this is actually a per-target variable (like‘mumble_LDFLAGS’) for some non-declared ‘LIBFOO’ target.
Other VariablesThere are other variables in Automake that follow similar principles toallow user options.  For instance, Texinfo rules (*note Texinfo::) use‘MAKEINFOFLAGS’ and ‘AM_MAKEINFOFLAGS’.  Similarly, DejaGnu tests (*noteDejaGnu Tests::) use ‘RUNTESTDEFAULTFLAGS’ and ‘AM_RUNTESTDEFAULTFLAGS’.The tags and ctags rules (*note Tags::) use ‘ETAGSFLAGS’,‘AM_ETAGSFLAGS’, ‘CTAGSFLAGS’, and ‘AM_CTAGSFLAGS’.  Java rules (*noteJava::) use ‘JAVACFLAGS’ and ‘AM_JAVACFLAGS’.  None of these rulessupport per-target flags (yet).
   To some extent, even ‘AM_MAKEFLAGS’ (*note Subdirectories::) obeysthis naming scheme.  The slight difference is that ‘MAKEFLAGS’ is passedto sub-‘make’s implicitly by ‘make’ itself.
   ‘ARFLAGS’ (*note A Library::) is usually defined by Automake and hasneither ‘AM_’ nor per-target cousin.
   Finally you should not think that the existence of a per-targetvariable implies the existence of an ‘AM_’ variable or of a uservariable.  For instance, the ‘mumble_LDADD’ per-target variableoverrides the makefile-wide ‘LDADD’ variable (which is not a uservariable), and ‘mumble_LIBADD’ exists only as a per-target variable.*Note Program and Library Variables::.
27.7 Why are object files sometimes renamed?This happens when per-target compilation flags are used.  Object filesneed to be renamed just in case they would clash with object filescompiled from the same sources, but with different flags.  Consider thefollowing example.
 bin_PROGRAMS = true false
 true_SOURCES = generic.c
 true_CPPFLAGS = -DEXIT_CODE=0
 false_SOURCES = generic.c
 false_CPPFLAGS = -DEXIT_CODE=1

Obviously the two programs are built from the same source, but it wouldbe bad if they shared the same object, because ‘generic.o’ cannot bebuilt with both ‘-DEXIT_CODE=0’ and ‘-DEXIT_CODE=1’.  Therefore‘automake’ outputs rules to build two different objects:‘true-generic.o’ and ‘false-generic.o’.
   ‘automake’ doesn’t actually look whether source files are shared todecide if it must rename objects.  It will just rename all objects of atarget as soon as it sees per-target compilation flags used.
   It’s OK to share object files when per-target compilation flags arenot used.  For instance, ‘true’ and ‘false’ will both use ‘version.o’ inthe following example.
 AM_CPPFLAGS = -DVERSION=1.0
 bin_PROGRAMS = true false
 true_SOURCES = true.c version.c
 false_SOURCES = false.c version.c

   Note that the renaming of objects is also affected by the‘_SHORTNAME’ variable (*note Program and Library Variables::).
27.8 Per-Object Flags Emulation One of my source files needs to be compiled with different flags.  How
 do I do?

   Automake supports per-program and per-library compilation flags (see*note Program and Library Variables:: and *note Flag VariablesOrdering::).  With this you can define compilation flags that apply toall files compiled for a target.  For instance, in
 bin_PROGRAMS = foo
 foo_SOURCES = foo.c foo.h bar.c bar.h main.c
 foo_CFLAGS = -some -flags

‘foo-foo.o’, ‘foo-bar.o’, and ‘foo-main.o’ will all be compiled with‘-some -flags’.  (If you wonder about the names of these object files,see *note Renamed Objects::.)  Note that ‘foo_CFLAGS’ gives the flags touse when compiling all the C sources of the program ‘foo’, it hasnothing to do with ‘foo.c’ or ‘foo-foo.o’ specifically.
   What if ‘foo.c’ needs to be compiled into ‘foo.o’ using some specificflags, that none of the other files requires?  Obviously per-programflags are not directly applicable here.  Something like per-object flagsare expected, i.e., flags that would be used only when creating‘foo-foo.o’.  Automake does not support that, however this is easy tosimulate using a library that contains only that object, and compilingthis library with per-library flags.
 bin_PROGRAMS = foo
 foo_SOURCES = bar.c bar.h main.c
 foo_CFLAGS = -some -flags
 foo_LDADD = libfoo.a
 noinst_LIBRARIES = libfoo.a
 libfoo_a_SOURCES = foo.c foo.h
 libfoo_a_CFLAGS = -some -other -flags

   Here ‘foo-bar.o’ and ‘foo-main.o’ will all be compiled with ‘-some-flags’, while ‘libfoo_a-foo.o’ will be compiled using ‘-some -other-flags’.  Eventually, all three objects will be linked to form ‘foo’.
   This trick can also be achieved using Libtool convenience libraries,for instance ‘noinst_LTLIBRARIES = libfoo.la’ (*note Libtool ConvenienceLibraries::).
   Another tempting idea to implement per-object flags is to overridethe compile rules ‘automake’ would output for these files.  Automakewill not define a rule for a target you have defined, so you could thinkabout defining the ‘foo-foo.o: foo.c’ rule yourself.  We recommendagainst this, because this is error prone.  For instance, if you addsuch a rule to the first example, it will break the day you decide toremove ‘foo_CFLAGS’ (because ‘foo.c’ will then be compiled as ‘foo.o’instead of ‘foo-foo.o’, *note Renamed Objects::).  Also in order tosupport dependency tracking, the two ‘.o’/‘.obj’ extensions, and all theother flags variables involved in a compilation, you will end upmodifying a copy of the rule previously output by ‘automake’ for thisfile.  If a new release of Automake generates a different rule, yourcopy will need to be updated by hand.
27.9 Handling Tools that Produce Many OutputsThis section describes a ‘make’ idiom that can be used when a toolproduces multiple output files.  It is not specific to Automake and canbe used in ordinary ‘Makefile’s.
   Suppose we have a program called ‘foo’ that will read one file called‘data.foo’ and produce two files named ‘data.c’ and ‘data.h’.  We wantto write a ‘Makefile’ rule that captures this one-to-two dependency.
   The naive rule is incorrect:
 # This is incorrect.
 data.c data.h: data.foo
         foo data.foo

What the above rule really says is that ‘data.c’ and ‘data.h’ eachdepend on ‘data.foo’, and can each be built by running ‘foo data.foo’.In other words it is equivalent to:
 # We do not want this.
 data.c: data.foo
         foo data.foo
 data.h: data.foo
         foo data.foo

which means that ‘foo’ can be run twice.  Usually it will not be runtwice, because ‘make’ implementations are smart enough to check for theexistence of the second file after the first one has been built; theywill therefore detect that it already exists.  However there are a fewsituations where it can run twice anyway:
   • The most worrying case is when running a parallel ‘make’.  If     ‘data.c’ and ‘data.h’ are built in parallel, two ‘foo data.foo’     commands will run concurrently.  This is harmful.   • Another case is when the dependency (here ‘data.foo’) is (or     depends upon) a phony target.
   A solution that works with parallel ‘make’ but not with phonydependencies is the following:
 data.c data.h: data.foo
         foo data.foo
 data.h: data.c

The above rules are equivalent to
 data.c: data.foo
         foo data.foo
 data.h: data.foo data.c
         foo data.foo

therefore a parallel ‘make’ will have to serialize the builds of‘data.c’ and ‘data.h’, and will detect that the second is no longerneeded once the first is over.
   Using this pattern is probably enough for most cases.  However itdoes not scale easily to more output files (in this scheme all outputfiles must be totally ordered by the dependency relation), so we willexplore a more complicated solution.
   Another idea is to write the following:
 # There is still a problem with this one.
 data.c: data.foo
         foo data.foo
 data.h: data.c

The idea is that ‘foo data.foo’ is run only when ‘data.c’ needs to beupdated, but we further state that ‘data.h’ depends upon ‘data.c’.  Thatway, if ‘data.h’ is required and ‘data.foo’ is out of date, thedependency on ‘data.c’ will trigger the build.
   This is almost perfect, but suppose we have built ‘data.h’ and‘data.c’, and then we erase ‘data.h’.  Then, running ‘make data.h’ willnot rebuild ‘data.h’.  The above rules just state that ‘data.c’ must beup-to-date with respect to ‘data.foo’, and this is already the case.
   What we need is a rule that forces a rebuild when ‘data.h’ ismissing.  Here it is:
 data.c: data.foo
         foo data.foo
 data.h: data.c
 ## Recover from the removal of $@
         @if test -f $@; then :; else \
           rm -f data.c; \
           $(MAKE) $(AM_MAKEFLAGS) data.c; \
         fi

   The above scheme can be extended to handle more outputs and moreinputs.  One of the outputs is selected to serve as a witness to thesuccessful completion of the command, it depends upon all inputs, andall other outputs depend upon it.  For instance, if ‘foo’ shouldadditionally read ‘data.bar’ and also produce ‘data.w’ and ‘data.x’, wewould write:
 data.c: data.foo data.bar
         foo data.foo data.bar
 data.h data.w data.x: data.c
 ## Recover from the removal of $@
         @if test -f $@; then :; else \
           rm -f data.c; \
           $(MAKE) $(AM_MAKEFLAGS) data.c; \
         fi

   However there are now three minor problems in this setup.  One isrelated to the timestamp ordering of ‘data.h’, ‘data.w’, ‘data.x’, and‘data.c’.  Another one is a race condition if a parallel ‘make’ attemptsto run multiple instances of the recover block at once.  Finally, therecursive rule breaks ‘make -n’ when run with GNU ‘make’ (as well assome other ‘make’ implementations), as it may remove ‘data.h’ even whenit should not (*note How the ‘MAKE’ Variable Works: (make)MAKEVariable.).
   Let us deal with the first problem.  ‘foo’ outputs four files, but wedo not know in which order these files are created.  Suppose that‘data.h’ is created before ‘data.c’.  Then we have a weird situation.The next time ‘make’ is run, ‘data.h’ will appear older than ‘data.c’,the second rule will be triggered, a shell will be started to executethe ‘if…fi’ command, but actually it will just execute the ‘then’branch, that is: nothing.  In other words, because the witness weselected is not the first file created by ‘foo’, ‘make’ will start ashell to do nothing each time it is run.
   A simple riposte is to fix the timestamps when this happens.
 data.c: data.foo data.bar
         foo data.foo data.bar
 data.h data.w data.x: data.c
         @if test -f $@; then \
           touch $@; \
         else \
 ## Recover from the removal of $@
           rm -f data.c; \
           $(MAKE) $(AM_MAKEFLAGS) data.c; \
         fi

   Another solution is to use a different and dedicated file as witness,rather than using any of ‘foo’’s outputs.
 data.stamp: data.foo data.bar
         @rm -f data.tmp
         @touch data.tmp
         foo data.foo data.bar
         @mv -f data.tmp $@
 data.c data.h data.w data.x: data.stamp
 ## Recover from the removal of $@
         @if test -f $@; then :; else \
           rm -f data.stamp; \
           $(MAKE) $(AM_MAKEFLAGS) data.stamp; \
         fi

   ‘data.tmp’ is created before ‘foo’ is run, so it has a timestampolder than output files output by ‘foo’.  It is then renamed to‘data.stamp’ after ‘foo’ has run, because we do not want to update‘data.stamp’ if ‘foo’ fails.
   This solution still suffers from the second problem: the racecondition in the recover rule.  If, after a successful build, a usererases ‘data.c’ and ‘data.h’, and runs ‘make -j’, then ‘make’ may startboth recover rules in parallel.  If the two instances of the ruleexecute ‘$(MAKE) $(AM_MAKEFLAGS) data.stamp’ concurrently the build islikely to fail (for instance, the two rules will create ‘data.tmp’, butonly one can rename it).
   Admittedly, such a weird situation does not arise during ordinarybuilds.  It occurs only when the build tree is mutilated.  Here ‘data.c’and ‘data.h’ have been explicitly removed without also removing‘data.stamp’ and the other output files.  ‘make clean; make’ will alwaysrecover from these situations even with parallel makes, so you maydecide that the recover rule is solely to help non-parallel make usersand leave things as-is.  Fixing this requires some locking mechanism toensure only one instance of the recover rule rebuilds ‘data.stamp’.  Onecould imagine something along the following lines.
 data.c data.h data.w data.x: data.stamp
 ## Recover from the removal of $@
         @if test -f $@; then :; else \
           trap 'rm -rf data.lock data.stamp' 1 2 13 15; \
 ## mkdir is a portable test-and-set
           if mkdir data.lock 2&gt;/dev/null; then \
 ## This code is being executed by the first process.
             rm -f data.stamp; \
             $(MAKE) $(AM_MAKEFLAGS) data.stamp; \
             result=$$?; rm -rf data.lock; exit $$result; \
           else \
 ## This code is being executed by the follower processes.
 ## Wait until the first process is done.
             while test -d data.lock; do sleep 1; done; \
 ## Succeed if and only if the first process succeeded.
             test -f data.stamp; \
           fi; \
         fi

   Using a dedicated witness, like ‘data.stamp’, is very handy when thelist of output files is not known beforehand.  As an illustration,consider the following rules to compile many ‘*.el’ files into ‘*.elc’files in a single command.  It does not matter how ‘ELFILES’ is defined(as long as it is not empty: empty targets are not accepted by POSIX).
 ELFILES = one.el two.el three.el ...
 ELCFILES = $(ELFILES:=c)

 elc-stamp: $(ELFILES)
         @rm -f elc-temp
         @touch elc-temp
         $(elisp_comp) $(ELFILES)
         @mv -f elc-temp $@

 $(ELCFILES): elc-stamp
         @if test -f $@; then :; else \
 ## Recover from the removal of $@
           trap 'rm -rf elc-lock elc-stamp' 1 2 13 15; \
           if mkdir elc-lock 2&gt;/dev/null; then \
 ## This code is being executed by the first process.
             rm -f elc-stamp; \
             $(MAKE) $(AM_MAKEFLAGS) elc-stamp; \
             rmdir elc-lock; \
           else \
 ## This code is being executed by the follower processes.
 ## Wait until the first process is done.
             while test -d elc-lock; do sleep 1; done; \
 ## Succeed if and only if the first process succeeded.
             test -f elc-stamp; exit $$?; \
           fi; \
         fi

   These solutions all still suffer from the third problem, namely thatthey break the promise that ‘make -n’ should not cause any actualchanges to the tree.  For those solutions that do not create lock files,it is possible to split the recover rules into two separate recipecommands, one of which does all work but the recursion, and the otherinvokes the recursive ‘$(MAKE)’.  The solutions involving locking couldact upon the contents of the ‘MAKEFLAGS’ variable, but parsing thatportably is not easy (*note (autoconf)The Make Macro MAKEFLAGS::).  Hereis an example:
 ELFILES = one.el two.el three.el ...
 ELCFILES = $(ELFILES:=c)

 elc-stamp: $(ELFILES)
         @rm -f elc-temp
         @touch elc-temp
         $(elisp_comp) $(ELFILES)
         @mv -f elc-temp $@

 $(ELCFILES): elc-stamp
 ## Recover from the removal of $@
         @dry=; for f in x $$MAKEFLAGS; do \
           case $$f in \
             *=*|--*);; \
             *n*) dry=:;; \
           esac; \
         done; \
         if test -f $@; then :; else \
           $$dry trap 'rm -rf elc-lock elc-stamp' 1 2 13 15; \
           if $$dry mkdir elc-lock 2&gt;/dev/null; then \
 ## This code is being executed by the first process.
             $$dry rm -f elc-stamp; \
             $(MAKE) $(AM_MAKEFLAGS) elc-stamp; \
             $$dry rmdir elc-lock; \
           else \
 ## This code is being executed by the follower processes.
 ## Wait until the first process is done.
             while test -d elc-lock &amp;&amp; test -z "$$dry"; do \
               sleep 1; \
             done; \
 ## Succeed if and only if the first process succeeded.
             $$dry test -f elc-stamp; exit $$?; \
           fi; \
         fi

   For completeness it should be noted that GNU ‘make’ is able toexpress rules with multiple output files using pattern rules (*notePattern Rule Examples: (make)Pattern Examples.).  We do not discusspattern rules here because they are not portable, but they can beconvenient in packages that assume GNU ‘make’.
27.10 Installing to Hard-Coded Locations My package needs to install some configuration file.  I tried to use
 the following rule, but ‘make distcheck’ fails.  Why?

      # Do not do this.
      install-data-local:
              $(INSTALL_DATA) $(srcdir)/afile $(DESTDIR)/etc/afile

 My package needs to populate the installation directory of another
 package at install-time.  I can easily compute that installation
 directory in ‘configure’, but if I install files therein,
 ‘make distcheck’ fails.  How else should I do?

   These two setups share their symptoms: ‘make distcheck’ fails becausethey are installing files to hard-coded paths.  In the later case thepath is not really hard-coded in the package, but we can consider it tobe hard-coded in the system (or in whichever tool that supplies thepath).  As long as the path does not use any of the standard directoryvariables (‘$(prefix)’, ‘$(bindir)’, ‘$(datadir)’, etc.), the effectwill be the same: user-installations are impossible.
   As a (non-root) user who wants to install a package, you usually haveno right to install anything in ‘/usr’ or ‘/usr/local’.  So you dosomething like ‘./configure –prefix /usr’ to install a package in yourown ‘/usr’ tree.
   If a package attempts to install something to some hard-coded path(e.g., ‘/etc/afile’), regardless of this ‘–prefix’ setting, then theinstallation will fail.  ‘make distcheck’ performs such a ‘–prefix’installation, hence it will fail too.
   Now, there are some easy solutions.
   The above ‘install-data-local’ example for installing ‘/etc/afile’would be better replaced by
 sysconf_DATA = afile

by default ‘sysconfdir’ will be ‘$(prefix)/etc’, because this is whatthe GNU Standards require.  When such a package is installed on an FHScompliant system, the installer will have to set ‘–sysconfdir=/etc’.As the maintainer of the package you should not be concerned by suchsite policies: use the appropriate standard directory variable toinstall your files so that the installer can easily redefine thesevariables to match their site conventions.
   Installing files that should be used by another package is slightlymore involved.  Let’s take an example and assume you want to install ashared library that is a Python extension module.  If you ask Pythonwhere to install the library, it will answer something like this:
 % python -c 'from distutils import sysconfig;
              print sysconfig.get_python_lib(1,0)'
 /usr/lib/python2.5/site-packages

   If you indeed use this absolute path to install your shared library,non-root users will not be able to install the package, hence distcheckfails.
   Let’s do better.  The ‘sysconfig.get_python_lib()’ function actuallyaccepts a third argument that will replace Python’s installation prefix.
 % python -c 'from distutils import sysconfig;
              print sysconfig.get_python_lib(1,0,"${exec_prefix}")'
 ${exec_prefix}/lib/python2.5/site-packages

   You can also use this new path.  If you do   • root users can install your package with the same ‘–prefix’ as     Python (you get the behavior of the previous attempt)
   • non-root users can install your package too, they will have the     extension module in a place that is not searched by Python but they     can work around this using environment variables (and if you     installed scripts that use this shared library, it’s easy to tell     Python were to look in the beginning of your script, so the script     works in both cases).
   The ‘AM_PATH_PYTHON’ macro uses similar commands to define‘$(pythondir)’ and ‘$(pyexecdir)’ (*note Python::).
   Of course not all tools are as advanced as Python regarding thatsubstitution of PREFIX.  So another strategy is to figure the part ofthe installation directory that must be preserved.  For instance, hereis how ‘AM_PATH_LISPDIR’ (*note Emacs Lisp::) computes ‘$(lispdir)’:
 $EMACS -batch -Q -eval '(while load-path
   (princ (concat (car load-path) "\n"))
   (setq load-path (cdr load-path)))' &gt;conftest.out
 lispdir=`sed -n
   -e 's,/$,,'
   -e '/.*\/lib\/x*emacs\/site-lisp$/{
         s,.*/lib/\(x*emacs/site-lisp\)$,${libdir}/\1,;p;q;
       }'
   -e '/.*\/share\/x*emacs\/site-lisp$/{
         s,.*/share/\(x*emacs/site-lisp\),${datarootdir}/\1,;p;q;
       }'
   conftest.out`

   I.e., it just picks the first directory that looks like‘*/lib/emacs/site-lisp’ or ‘/share/*emacs/site-lisp’ in the searchpath of emacs, and then substitutes ‘${libdir}’ or ‘${datadir}’appropriately.
   The emacs case looks complicated because it processes a list andexpects two possible layouts, otherwise it’s easy, and the benefits fornon-root users are really worth the extra ‘sed’ invocation.
27.11 Debugging Make RulesThe rules and dependency trees generated by ‘automake’ can get rathercomplex, and leave the developer head-scratching when things don’t workas expected.  Besides the debug options provided by the ‘make’ command(*note (make)Options Summary::), here’s a couple of further hints fordebugging makefiles generated by ‘automake’ effectively:
   • If less verbose output has been enabled in the package with the use     of silent rules (*note Automake Silent Rules::), you can use ‘make     V=1’ to see the commands being executed.   • ‘make -n’ can help show what would be done without actually doing     it.  Note however, that this will still execute commands prefixed     with ‘+’, and, when using GNU ‘make’, commands that contain the     strings ‘$(MAKE)’ or ‘${MAKE}’ (*note (make)Instead of     Execution::).  Typically, this is helpful to show what recursive     rules would do, but it means that, in your own rules, you should     not mix such recursion with actions that change any files.(1)     Furthermore, note that GNU ‘make’ will update prerequisites for the     ‘Makefile’ file itself even with ‘-n’ (*note (make)Remaking     Makefiles::).   • ‘make SHELL=”/bin/bash -vx”’ can help debug complex rules.  *Note     (autoconf)The Make Macro SHELL::, for some portability quirks     associated with this construct.   • ‘echo ‘print: ; @echo “$(VAR)”‘ | make -f Makefile -f - print’ can     be handy to examine the expanded value of variables.  You may need     to use a target other than ‘print’ if that is already used or a     file with that name exists.   • http://bashdb.sourceforge.net/remake/ provides a modified GNU     ‘make’ command called ‘remake’ that copes with complex GNU     ‘make’-specific Makefiles and allows to trace execution, examine     variables, and call rules interactively, much like a debugger.
   ———- Footnotes ———-
   (1) Automake’s ‘dist’ and ‘distcheck’ rules had a bug in this regardin that they created directories even with ‘-n’, but this has been fixedin Automake 1.11.
27.12 Reporting BugsMost nontrivial software has bugs.  Automake is no exception.  Althoughwe cannot promise we can or will fix a bug, and we might not even agreethat it is a bug, we want to hear about problems you encounter.  Oftenwe agree they are bugs and want to fix them.
   To make it possible for us to fix a bug, please report it.  In orderto do so effectively, it helps to know when and how to do it.
   Before reporting a bug, it is a good idea to see if it is alreadyknown.  You can look at the GNU Bug Tracker (https://debbugs.gnu.org/)and the bug-automake mailing list archives(https://lists.gnu.org/archive/html/bug-automake/) for previous bugreports.  We previously used a Gnats database(http://sourceware.org/cgi-bin/gnatsweb.pl?database=automake) for bugtracking, so some bugs might have been reported there already.  Pleasedo not use it for new bug reports, however.
   If the bug is not already known, it should be reported.  It is veryimportant to report bugs in a way that is useful and efficient.  Forthis, please familiarize yourself with How to Report Bugs Effectively(http://www.chiark.greenend.org.uk/~sgtatham/bugs.html) and How to AskQuestions the Smart Way(http://catb.org/~esr/faqs/smart-questions.html).  This helps you anddevelopers to save time which can then be spent on fixing more bugs andimplementing more features.
   For a bug report, a feature request or other suggestions, please sendemail to bug-automake@gnu.org.  This will then open a new bug in thebug tracker (https://debbugs.gnu.org/automake).  Be sure to include theversions of Autoconf and Automake that you use.  Ideally, post a minimal‘Makefile.am’ and ‘configure.ac’ that reproduces the problem youencounter.  If you have encountered test suite failures, please attachthe ‘test-suite.log’ file.
]]></content>
      <categories>
        <category>Linux</category>
        <category>Automake</category>
      </categories>
      <tags>
        <tag>autotools</tag>
        <tag>automake</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux Automake 3 General ideas</title>
    <url>/2018/03/10/linux-automake-3-general-ideas/</url>
    <content><![CDATA[
GNU Automake 版本(version 1.16.1, 26 February 2018)
Permission is granted to copy, distribute and/or modify thisdocument under the terms of the GNU Free Documentation License,Version 1.3 or any later version published by the Free SoftwareFoundation; with no Invariant Sections, with no Front-Cover texts,and with no Back-Cover Texts.  A copy of the license is included inthe section entitled “GNU Free Documentation License.”

3 Automake的设计理念
本节主要讲讲Automake是如何工作的。
3.1 一般操作
Automake 读取Makefile.am 并生成文件Makefile.in。
Makefile.am定义的变量和规则会指导Automake生成相关的代码。
比如bin_PROGRAMS 变量定义了如何编译连接的规则。
 Makefile.am 大部分定义的变量和规则会拷贝到生成的文件。
GNU make支持追加操作符 +=。
Automake在解析时并不是特别聪明，所以最好不要编写一些奇形怪状的语句。
特别是最好不要使用 &lt;TAB&gt; ，如果使用很多复杂的宏也会引起诸多问题：
 % cat Makefile.am
 $(FOO:=x): bar
 % automake
 Makefile.am:1: bad characters in variable name '$(FOO'
 Makefile.am:1: ':='-style assignments are not portable

Automake 也支持下面的书写方法：
 xs = a.c b.c
 foo_SOURCES = c.c $(xs)

它将使用 a.c, b.c和 c.c 来代替foo_SOURCES.
 Automake 也支持#开头的注释，如果以 ##开头，那么将被Automake忽略，不显示在输出中。
比如一般Makefile.am的第一行可以写成：
## Process this file with automake to produce Makefile.in

3.2 限定级别
Automake用于 GNU packages的维护，所以可能根据不同的需求有了一些标准，有些标准可能并不适合所有的开发人员，这里说一下三种限定级别：
foreignAutomake只检查一些必须的文件，比如标准的GNU是需要 NEWS 文件的，而这个选项就不强制，建议新手使用。
gnu​ Automake的默认级别，会尽可能多地检查，建议极大程度上匹配GNU标准的高手使用。
gnits​ Automake检查是否与Gnits标准一致，虽然该标准还没有定下来，所以这个暂时没有必要。
3.3 统一的命名方案
Automake变量遵循一个统一的命名方案是的很容易决定程序是如何编译和安装的。
决定 automake 什么需要编译的通常称为primary，比如称为 PROGRAMS 的primary决定了一系列将编译和链接的程序。
primary 还有一个前缀，用于决定安装到什么路径。这个可以参考GNU的编码标准，比如bindir简写为bin，其中的dir省略掉。

所有应该写成bin_PROGRAMS，而不是bindir_PROGRAMS

标准目录并不一定满足我们的需求，这时就可以通过自定义参数来解决，比如：我们将把 file.xml 安装到$(datadir)/xml.
 xmldir = $(datadir)/xml
 xml_DATA = file.xml

前缀 noinst_ 将编译但是不安装，这个参数多用于编译其他包需要目标文件的时候，比如编译创建静态库或者帮助脚本。
前缀 check_ 只有在 make check 的时候才编译，但是不安装。
目前的   primary 由： PROGRAMS, LIBRARIES, LTLIBRARIES,LISP, PYTHON, JAVA, SCRIPTS, DATA, HEADERS, MANS 和TEXINFOS。
一些primaries 还有一些附加前缀用于控制 automake 的行为，比如：dist_, nodist_, nobase_和 notrans_。
3.4 命令行长度不要过长
大部分的类unix系统对命令行参数和环境变量都有长度限制，详细的可以参考http://www.in-ulm.de/~mascheck/various/argmax/ ，这个在 make的时候也存在，所以我们可以采用下述策略：
 data_DATA = file1 ... fileN fileN+1 ... file2N

改写为：
 data_DATA = file1 ... fileN
 data2dir = $(datadir)
 data2_DATA = fileN+1 ... file2N

3.5 变量是如何命名的
命名中除了字母、数组和@符号，其他的都会转换为下划线。比如程序命名为 sniff-glue，最后的变量名为 sniff_glue_PROGRAMS，而不是 sniff-glue_PROGRAMS，再比如一个库 libmumble++.a将被更改为 libmumble___a_SOURCES 。

其中@符号的保留主要是为了防止后续Autoconf在变量替换时出现问题。

3.6 Variables reserved for the user
Some Makefile variables are reserved by the GNU Coding Standards forthe use of the “user”—the person building the package.  For instance,CFLAGS is one such variable.
   Sometimes package developers are tempted to set user variables suchas CFLAGS because it appears to make their job easier.  However, thepackage itself should never set a user variable, particularly not toinclude switches that are required for proper compilation of thepackage.  Since these variables are documented as being for the packagebuilder, that person rightfully expects to be able to override any ofthese variables at build time.
   To get around this problem, Automake introduces an automake-specificshadow variable for each user flag variable.  (Shadow variables are notintroduced for variables like CC, where they would make no sense.)The shadow variable is named by prepending AM_ to the user variable’sname.  For instance, the shadow variable for YFLAGS is AM_YFLAGS.The package maintainer—that is, the author(s) of the Makefile.am andconfigure.ac files—may adjust these shadow variables howevernecessary.
3.7 automake可能需要的一些软件包
Automake在生成Makefile 的时候并非单兵作战，它在为了支持多个操作系统的路上需要一帮好朋友软件来支持。如下：
ar-lib：提供给微软的一个lib归档包装器
compile 方便不能同时接受参数选项 -c 和​ -o 的编辑器，
config.guessconfig.sub​     These two programs compute the canonical triplets for the given​     build, host, or target architecture.  These programs are updated​     regularly to support new architectures and fix probes broken by​     changes in new kernel versions.  Each new release of Automake comes​     with up-to-date copies of these programs.  If your copy of Automake​     is getting old, you are encouraged to fetch the latest versions of​     these files from https://savannah.gnu.org/git/?group=config​     before making a release.
depcomp​     This program understands how to run a compiler so that it will​     generate not only the desired output but also dependency​     information that is then used by the automatic dependency tracking​     feature
install-sh​     This is a replacement for the install program that works on​     platforms where install is unavailable or unusable.
mdate-sh​     This script is used to generate a version.texi file.  It examines​     a file and prints some date information about it.
missing​     This wraps a number of programs that are typically only required by​     maintainers.  If the program in question does not exist, or seems to​     old, missing will print an informative warning before failing​     out, to provide the user with more context and information.
mkinstalldirs​     This script used to be a wrapper around mkdir -p, which is not​     portable.  Now we prefer to use install-sh -d when configure​     finds that mkdir -p does not work, this makes one less script to​     distribute.​     For backward compatibility mkinstalldirs is still used and​     distributed when automake finds it in a package.  But it is no​     longer installed automatically, and it should be safe to remove it.
py-compile​     This is used to byte-compile Python scripts.
test-driver​     This implements the default test driver offered by the parallel​     testsuite harness.
texinfo.tex​     Not a program, this file is required for make dvi, make ps and​     make pdf to work when Texinfo sources are in the package.  The​     latest version can be downloaded from​     https://www.gnu.org/software/texinfo/.
ylwrap​     This program wraps lex and yacc to rename their output files.​     It also ensures that, for instance, multiple yacc instances can​     be invoked in a single directory in parallel.
]]></content>
      <categories>
        <category>Linux</category>
        <category>Automake</category>
      </categories>
      <tags>
        <tag>autotools</tag>
        <tag>automake</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux Automake 4  一些示例包</title>
    <url>/2018/03/14/linux-automake-4-some-example-packages/</url>
    <content><![CDATA[
GNU Automake 版本(version 1.16.1, 26 February 2018)
Permission is granted to copy, distribute and/or modify thisdocument under the terms of the GNU Free Documentation License,Version 1.3 or any later version published by the Free SoftwareFoundation; with no Invariant Sections, with no Front-Cover texts,and with no Back-Cover Texts.  A copy of the license is included inthe section entitled “GNU Free Documentation License.”

4 两个例子小程序
本章讲两个例子，一个是假定一个工程已经使用Autoconf来处理并手工编写 Makefile，现在切换到 Automake来处理；第二个例子是如何从同一套源码中使用不同的参数编译出两个程序。
4.1 简单小程序，几步就搞定
假定我们已经完成了一个软件zardoz，使用Autoconf提供一个可扩展的框架，不过 Makefile.in是专门另行准备的，现在为了完善这部分工作，我们转而使用Automake。.
第一步就是更新configure.ac，在AC_INIT之后添加AM_INIT_AUTOMAKE ：
 AC_INIT([zardoz], [1.0])
 AM_INIT_AUTOMAKE
 ...

此时还需要重新生成 configure文件，在此之前需要告诉 autoconf如何找到新的使用宏。最简单的方法是使用aclocal生成 aclocal.m4
$ aclocal$ autoconf

 接下来就要编写文件Makefile.am了，下面的内容说明我们要安装在bin目录，还指定了源码并且还有一个Texinfo文档。
bin_PROGRAMS = zardozzardoz_SOURCES = main.c head.c float.c vortex9.c gun.cinfo_TEXINFOS = zardoz.texi

最后使用automake --add-missing就可以生成Makefile.in 了，赞。
4.2 一套源码编译两套可执行程序
OK来看第二个例子，这个例子展示了如何从相同的源码true.c通过不同的cpp参数生成两个程序 (true 和 false) 。
bin_PROGRAMS = true falsefalse_SOURCES =false_LDADD = false.otrue.o: true.c        $(COMPILE) -DEXIT_CODE=0 -c true.cfalse.o: true.c        $(COMPILE) -DEXIT_CODE=1 -o false.o -c true.c

注意例子里面没有 true_SOURCES，Automake会自动假定源码名为 true.c，编译为 true.o 并链接到true，规则段true.o: true.c 会覆盖默认由 Automake 产生的，使用新的一些规则。
false_SOURCES 置为空，因为没有相应的源码，所以我们需要告诉 Automake 它是如何编译链接的。false_LDADD 给出了方案。
如果编译器不能同时支持 -c和 -o，上面的这个文件可能不会工作，此时我们就需要变通一下，使用下面的文件解决：
true.o: true.c false.o        $(COMPILE) -DEXIT_CODE=0 -c true.cfalse.o: true.c        $(COMPILE) -DEXIT_CODE=1 -c true.c &amp;&amp; mv true.o false.o

上面是比较有技巧的处理方法，刚开始的操作，还是希望尽量简化，简单，易于理解，如下所示：
bin_PROGRAMS = false truefalse_SOURCES = true.cfalse_CPPFLAGS = -DEXIT_CODE=1true_SOURCES = true.ctrue_CPPFLAGS = -DEXIT_CODE=0

]]></content>
      <categories>
        <category>Linux</category>
        <category>Automake</category>
      </categories>
      <tags>
        <tag>autotools</tag>
        <tag>automake</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux Automake 5  创建`Makefile.in`</title>
    <url>/2018/03/15/linux-automake-5-create-makefile-in/</url>
    <content><![CDATA[
GNU Automake 版本(version 1.16.1, 26 February 2018)
Permission is granted to copy, distribute and/or modify thisdocument under the terms of the GNU Free Documentation License,Version 1.3 or any later version published by the Free SoftwareFoundation; with no Invariant Sections, with no Front-Cover texts,and with no Back-Cover Texts.  A copy of the license is included inthe section entitled “GNU Free Documentation License.”

5 创建一个 Makefile.in
为了创建一个包的Makefile.in，只需要在顶层目录执行命令 automake即可。 automake 会通过扫描文件configure.ac来找到每一个 Makefile.am 并生成相应的Makefile.in。

 此处留意： automake 假定一个包只有一个configure.ac，所以如果你的包包含多个configure.ac就需要在每个包含的目录执行 automake ，或者使用Autoconf的命令autoreconf，这个命令可以自动遍历所有的目录。

另外还需要留意 automake 必须在顶层目录执行，顶层目录需要包含文件 configure.ac。
Automake通过运行autoconf来扫描文件 configure.ac及它的依赖，因此autoconf 必须在你的环境变量里面，如果有另外一个 AUTOCONF 环境变量，那么就会 替代默认的 autoconf，这在使用另外一个版本的时候比较有用。

注：automake 只是通过 autoconf 来扫描configure.ac，并不会构建 configure ，所以还需要使用autoconf来构建。

   automake 接收下面的参数：
-a--add-missing​     Automake requires certain common files to exist in certain​     situations; for instance, config.guess is required if​     configure.ac invokes AC_CANONICAL_HOST.  Automake is​     distributed with several of these files (; this option will cause the missing ones to be​     automatically added to the package, whenever possible.  In general​     if Automake tells you a file is missing, try using this option.  By​     default Automake tries to make a symbolic link pointing to its own​     copy of the missing file; this can be changed with --copy.
 Many of the potentially-missing files are common scripts whose
 location may be specified via the `AC_CONFIG_AUX_DIR` macro.
 Therefore, `AC_CONFIG_AUX_DIR``s setting affects whether a file is
 considered missing, and where the missing file is added (.

 In some strictness modes, additional files are installed, x

--libdir=DIR​     Look for Automake data files in directory DIR instead of in the​     installation directory.  This is typically used for debugging.
 The environment variable `AUTOMAKE_LIBDIR` provides another way to
 set the directory containing Automake data files.  However
 `--libdir` takes precedence over it.

--print-libdir​     Print the path of the installation directory containing​     Automake-provided scripts and data files (like e.g., texinfo.texi​     and install-sh).
-c--copy​     使用 --add-missing的时候默认会生成一个符号链接，这个选项会拷贝文件。
-f--force-missing​     When used with --add-missing, causes standard files to be​     reinstalled even if they already exist in the source tree.  This​     involves removing the file from the source tree before creating the​     new symlink (or, with --copy, copying the new file).
--foreign​     设定级别为 foreign.
--gnits​     设定级别为 gnits.  
--gnu​     设定级别为 gnu.
--help​     打印一系列命令行选项并退出
-i--ignore-deps​     This disables the dependency tracking feature in generated​     Makefiles; see
--include-deps​     This enables the dependency tracking feature.  This feature is​     enabled by default.  This option is provided for historical reasons​     only and probably should not be used.
--no-force​     Ordinarily automake creates all Makefile.ins mentioned in​     configure.ac.  This option causes it to only update those​     Makefile.ins that are out of date with respect to one of their​     dependents.
-o DIR--output-dir=DIR​     Put the generated Makefile.in in the directory DIR.  Ordinarily​     each Makefile.in is created in the directory of the corresponding​     Makefile.am.  This option is deprecated and will be removed in a​     future release.
-v--verbose​     Cause Automake to print information about which files are being​     read or created.
--version​     打印版本号并退出
-W CATEGORY--warnings=CATEGORY​     Output warnings falling in CATEGORY.  CATEGORY can be one of:​     gnu​          warnings related to the GNU Coding Standards (​     obsolete​          obsolete features or constructions​     override​          user redefinitions of Automake rules or variables​     portability​          portability issues (e.g., use of make features that are​          known to be not portable)​     extra-portability​          extra portability issues related to obscure tools.  One​          example of such a tool is the Microsoft lib archiver.​     syntax​          weird syntax, unused variables, typos​     unsupported​          unsupported or incomplete features​     all​          all the warnings​     none​          turn off all the warnings​     error​          treat warnings as errors
 A category can be turned off by prefixing its name with `no-`.  For
 instance, `-Wno-syntax` will hide the warnings about unused
 variables.

 The categorie output by default are `obsolete`, `syntax` and
 `unsupported`.  Additionally, `gnu` and `portability` are enabled
 in `--gnu` and `--gnits` strictness.

 Turning off `portability` will also turn off `extra-portability`,
 and similarly turning on `extra-portability` will also turn on
 `portability`.  However, turning on `portability` or turning off
 `extra-portability` will not affect the other category.

 The environment variable `WARNINGS` can contain a comma separated
 list of categorie to enable.  It will be taken into account before
 the command-line switches, this way `-Wnone` will also ignore any
 warning category enabled by `WARNINGS`.  This variable is also used
 by other tools like `autoconf`; unknown categorie are ignored for
 this reason.

   If the environment variable AUTOMAKE_JOBS contains a positivenumber, it is taken as the maximum number of Perl threads to use inautomake for generating multiple Makefile.in files concurrently.This is an experimental feature.
]]></content>
      <categories>
        <category>Linux</category>
        <category>Automake</category>
      </categories>
      <tags>
        <tag>autotools</tag>
        <tag>automake</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux Automake 6  解析`configure.ac`</title>
    <url>/2018/03/16/linux-automake-6-scanning-configure-ac/</url>
    <content><![CDATA[
GNU Automake 版本(version 1.16.1, 26 February 2018)
Permission is granted to copy, distribute and/or modify thisdocument under the terms of the GNU Free Documentation License,Version 1.3 or any later version published by the Free SoftwareFoundation; with no Invariant Sections, with no Front-Cover texts,and with no Back-Cover Texts.  A copy of the license is included inthe section entitled “GNU Free Documentation License.”

6 使用aclocal解析configure.ac
Automake通过解析文件 configure.ac 来决定软件包的信息。一些 autoconf 宏需要定义在该文件中。
6.1 Configuration requirements
Automake需要的一个必须的参数是AM_INIT_AUTOMAKE。
初次之外还有一些其他的宏，如下所示：
AC_CONFIG_FILESAC_OUTPUT​     这个两个宏一般位于文件的最末尾。
      AC_CONFIG_FILES([
        Makefile
        doc/Makefile
        src/Makefile
        src/lib/Makefile
        ...
      ])
      AC_OUTPUT

Automake使用这些信息来确定哪些文件需要被创建，上面的内容就是如果在目录中存在 Makefile.am的文件，那么将生成Makefile文件。When using AC_CONFIG_FILES with multiple input files, as inAC_CONFIG_FILES([Makefile:top.in:Makefile.in:bot.in])​automake will generate the first .in input file for which a.am file exists.  If no such file exists the output file is notconsidered to be generated by Automake.​ 通过 AC_CONFIG_FILES创建的文件在使用 make distclean的时候都会被清除。  Their inputs areautomatically distributed, unless they are the output of priorAC_CONFIG_FILES commands.  Finally, rebuild rules are generatedin the Automake Makefile existing in the subdirectory of theoutput file, if there is one, or in the top-level Makefileotherwise.
The above machinery (cleaning, distributing, and rebuilding) worksfine if the AC_CONFIG_FILES specifications contain only literals.If part of the specification uses shell variables, automake willnot be able to fulfill this setup, and you will have to completethe missing bits by hand.  For instance, on
      file=input
      ...
      AC_CONFIG_FILES([output:$file],, [file=$file])

automake will output rules to clean output, and rebuild it.However the rebuild rule will not depend on input, and this filewill not be distributed either.  (You must add EXTRA_DIST = inputto your Makefile.am if input is a source file.)
Similarly​​     file=output​     file2=out:in​     …​     AC_CONFIG_FILES([$file:input],, [file=$file])​     AC_CONFIG_FILES([$file2],, [file2=$file2])
will only cause input to be distributed.  No file will be cleanedautomatically (add DISTCLEANFILES = output out yourself), and norebuild rule will be output.
Obviously automake cannot guess what value $file is going tohold later when configure is run, and it cannot use the shellvariable $file in a Makefile.  However, if you make referenceto $file as ${file} (i.e., in a way that is compatible withmake``s syntax) and furthermore use AC_SUBSTto ensure that${file}is meaningful in aMakefile, then automakewill be able to use${file}` to generate all of these rules.  Forinstance, here is how the Automake package itself generatesversioned scripts for its test suite:
 AC_SUBST([APIVERSION], ...)
 ...
 AC_CONFIG_FILES(
   [tests/aclocal-${APIVERSION}:tests/aclocal.in],
   [chmod +x tests/aclocal-${APIVERSION}],
   [APIVERSION=$APIVERSION])
 AC_CONFIG_FILES(
   [tests/automake-${APIVERSION}:tests/automake.in],
   [chmod +x tests/automake-${APIVERSION}])

Here cleaning, distributing, and rebuilding are done automatically,because ${APIVERSION} is known at make-time.
Note that you should not use shell variables to declare Makefilefiles for which automake must create Makefile.in.  EvenAC_SUBST does not help here, because automake needs to know thefile name when it runs in order to check whether Makefile.amexists.  (In the very hairy case that your setup requires such useof variables, you will have to tell Automake which Makefile.insto generate on the command-line.)
It is possible to let automake emit conditional rules forAC_CONFIG_FILES with the help of AM_COND_IF .
To summarize:   • Use literals for Makefiles, and for other files whenever​     possible.   • Use $file (or ${file} without AC_SUBST([file])) for​     files that automake should ignore.   • Use ${file} and AC_SUBST([file]) for files that automake​     should not ignore.
6.2 Other things Automake recognizes
Every time Automake is run it calls Autoconf to trace configure.ac.This way it can recognize the use of certain macros and tailor thegenerated Makefile.in appropriately.  Currently recognized macros andtheir effects are:
AC_CANONICAL_BUILDAC_CANONICAL_HOSTAC_CANONICAL_TARGET​     Automake will ensure that config.guess and config.sub exist.​     Also, the Makefile variables build_triplet, host_triplet and​     target_triplet are introduced.
AC_CONFIG_AUX_DIR​     Automake will look for various helper scripts, such as​     install-sh, in the directory named in this macro invocation.​     (The full list of scripts is: ar-lib, config.guess,​     config.sub, depcomp, compile, install-sh, ltmain.sh,​     mdate-sh, missing, mkinstalldirs, py-compile,​     test-driver, texinfo.tex, ylwrap.)  Not all scripts are​     always searched for; some scripts will only be sought if the​     generated Makefile.in requires them.
 If `AC_CONFIG_AUX_DIR` is not given, the scripts are looked for in
 their standard locations.  For `mdate-sh`, `texinfo.tex`, and
 `ylwrap`, the standard location is the source directory
 corresponding to the current `Makefile.am`.  For the rest, the
 standard location is the first one of `.`, `..`, or `../..`
 (relative to the top source directory) that provides any one of the
 helper scripts.  

 Required files from `AC_CONFIG_AUX_DIR` are automatically
 distributed, even if there is no `Makefile.am` in this directory.

AC_CONFIG_LIBOBJ_DIR​     Automake will require the sources file declared with AC_LIBSOURCE​     (see below) in the directory specified by this macro.
AC_CONFIG_HEADERS​     Automake will generate rules to rebuild these headers from the​     corresponding templates (usually, the template for a foo.h header​     being foo.h.in).  Older versions of Automake required the use of​     AM_CONFIG_HEADER; this is no longer the case, and that macro has​     indeed been removed.
 As with `AC_CONFIG_FILES` , parts of the
 specification using shell variables will be ignored as far as
 cleaning, distributing, and rebuilding is concerned.

AC_CONFIG_LINKS​     Automake will generate rules to remove configure generated links​     on make distclean and to distribute named source files as part of​     make dist.
 As for `AC_CONFIG_FILES` parts of the
 specification using shell variables will be ignored as far as
 cleaning and distributing is concerned.  (There are no rebuild
 rules for links.)

AC_LIBOBJAC_LIBSOURCEAC_LIBSOURCES​     Automake will automatically distribute any file listed in​     AC_LIBSOURCE or AC_LIBSOURCES.
 Note that the `AC_LIBOBJ` macro calls `AC_LIBSOURCE`.  So if an
 Autoconf macro is documented to call `AC_LIBOBJ([file])`, then
 `file.c` will be distributed automatically by Automake.  This
 encompasses many macros like `AC_FUNC_ALLOCA`, `AC_FUNC_MEMCMP`,
 `AC_REPLACE_FUNCS`, and others.

 By the way, direct assignments to `LIBOBJS` are no longer
 supported.  You should always use `AC_LIBOBJ` for this purpose.
 Note `AC_LIBOBJ` vs. `LIBOBJS`: (autoconf)AC_LIBOBJ vs LIBOBJS.

AC_PROG_RANLIB​     This is required if any libraries are built in the package.  Note​     Particular Program Checks: (autoconf)Particular Programs.
AC_PROG_CXX​     This is required if any C++ source is included.  Note Particular​     Program Checks: (autoconf)Particular Programs.
AC_PROG_OBJC​     This is required if any Objective C source is included.  Note​     Particular Program Checks: (autoconf)Particular Programs.
AC_PROG_OBJCXX​     This is required if any Objective C++ source is included.  Note​     Particular Program Checks: (autoconf)Particular Programs.
AC_PROG_F77​     This is required if any Fortran 77 source is included.  Note​     Particular Program Checks: (autoconf)Particular Programs.
AC_F77_LIBRARY_LDFLAGS​     This is required for programs and shared libraries that are a​     mixture of languages that include Fortran 77 .  
AC_FC_SRCEXT​     Automake will add the flags computed by AC_FC_SRCEXT to​     compilation of files with the respective source extension
AC_PROG_FC​     This is required if any Fortran 90/95 source is included.  This​     macro is distributed with Autoconf version 2.58 and later.  Note​     Particular Program Checks: (autoconf)Particular Programs.
AC_PROG_LIBTOOL​     Automake will turn on processing for libtool
AC_PROG_YACC​     If a Yacc source file is seen, then you must either use this macro​     or define the variable YACC in configure.ac.  The former is​     preferred
AC_PROG_LEX​     If a Lex source file is seen, then this macro must be used.  Note​     Particular Program Checks: (autoconf)Particular Programs.
AC_REQUIRE_AUX_FILE​     For each AC_REQUIRE_AUX_FILE([FILE]), automake will ensure that​     FILE exists in the aux directory, and will complain otherwise.​     It will also automatically distribute the file.  This macro should​     be used by third-party Autoconf macros that require some supporting​     files in the aux directory specified with AC_CONFIG_AUX_DIR​     above.  Note Finding configure Input: (autoconf)Input.
AC_SUBST​     The first argument is automatically defined as a variable in each​     generated Makefile.in, unless AM_SUBST_NOTMAKE is also used for​     this variable.  Note Setting Output Variables: (autoconf)Setting​     Output Variables.
 For every substituted variable VAR, `automake` will add a line `VAR
 = VALUE` to each `Makefile.in` file.  Many Autoconf macros invoke
 `AC_SUBST` to set output variables this way, e.g., `AC_PATH_XTRA`
 defines `X_CFLAGS` and `X_LIBS`.  Thus, you can access these
 variables as `$(X_CFLAGS)` and `$(X_LIBS)` in any `Makefile.am` if
 `AC_PATH_XTRA` is called.

AM_CONDITIONAL​     This introduces an Automake conditional
AM_COND_IF​     This macro allows automake to detect subsequent access within​     configure.ac to a conditional previously introduced with​     AM_CONDITIONAL, thus enabling conditional AC_CONFIG_FILES
AM_GNU_GETTEXT​     This macro is required for packages that use GNU gettext .  It is distributed with gettext.  If Automake sees this​     macro it ensures that the package meets some of gettext`s​     requirements.
AM_GNU_GETTEXT_INTL_SUBDIR​     This macro specifies that the intl/ subdirectory is to be built,​     even if the AM_GNU_GETTEXT macro was invoked with a first​     argument of external.
AM_MAINTAINER_MODE([DEFAULT-MODE])​     This macro adds an --enable-maintainer-mode option to​     configure.  If this is used, automake will cause​     “maintainer-only” rules to be turned off by default in the​     generated Makefile.ins, unless DEFAULT-MODE is enable.  This​     macro defines the MAINTAINER_MODE conditional, which you can use​     in your own Makefile.am.  Note maintainer-mode::.
AM_SUBST_NOTMAKE(VAR)​     Prevent Automake from defining a variable VAR, even if it is​     substituted by config.status.  Normally, Automake defines a​     make variable for each configure substitution, i.e., for each​     AC_SUBST([VAR]).  This macro prevents that definition from​     Automake.  If AC_SUBST has not been called for this variable,​     then AM_SUBST_NOTMAKE has no effects.  Preventing variable​     definitions may be useful for substitution of multi-line values,​     where VAR = @VALUE@ might yield unintended results.
m4_include​     Files included by configure.ac using this macro will be detected​     by Automake and automatically distributed.  They will also appear​     as dependencies in Makefile rules.
 `m4_include` is seldom used by `configure.ac` authors, but can
 appear in `aclocal.m4` when `aclocal` detects that some required
 macros come from files local to your package (as opposed to macros
 installed in a system-wide directory, note aclocal Invocation::).

6.3 Auto-generating aclocal.m4
Automake includes a number of Autoconf macros that can be used in yourpackage (Macros::); some of them are actually required by Automakein certain situations.  These macros must be defined in youraclocal.m4; otherwise they will not be seen by autoconf.
程序 aclocal 将根据 configure.ac自动生成文件 aclocal.m4 。  This provides a convenient wayto get Automake-provided macros, without having to search around.  Theaclocal mechanism allows other packages to supply their own macros(Extending aclocal::).  You can also use it to maintain your ownset of custom macros (Local Macros::).
   At startup, aclocal scans all the .m4 files it can find, lookingfor macro definitions (Macro Search Path::).  Then it scansconfigure.ac.  Any mention of one of the macros found in the firststep causes that macro, and any macros it in turn requires, to be putinto aclocal.m4.
   Putting the file that contains the macro definition intoaclocal.m4 is usually done by copying the entire text of this file,including unused macro definitions as well as both # and dnlcomments.  If you want to make a comment that will be completely ignoredby aclocal, use ## as the comment leader.
   When a file selected by aclocal is located in a subdirectoryspecified as a relative search path with aclocal``s -Iargument,aclocalassumes the file belongs to the package and usesm4_includeinstead of copying it intoaclocal.m4.  This makes the package smaller, eases dependency tracking, and cause the file to be distributed automatically.  (Note Local Macros::, for an example.)  Any macro that is found in a system-wide directory, or via an absolute search path will be copied.  So use -I pwd/reldirinstead of-I reldir` wheneversome relative directory should be considered outside the package.
   The contents of acinclude.m4, if this file exists, are alsoautomatically included in aclocal.m4.  We recommend against usingacinclude.m4 in new packages (note Local Macros::).
   While computing aclocal.m4, aclocal runs autom4te (note UsingAutom4te: (autoconf)Using autom4te.) in order to trace the macros thatare really used, and omit from aclocal.m4 all macros that arementioned but otherwise unexpanded (this can happen when a macro iscalled conditionally).  autom4te is expected to be in the PATH, justas autoconf.  Its location can be overridden using the AUTOM4TEenvironment variable.
6.3.1 aclocal Options

aclocal accepts the following options:
--automake-acdir=DIR​     Look for the automake-provided macro files in DIR instead of in the​     installation directory.  This is typically used for debugging.
 The environment variable `ACLOCAL_AUTOMAKE_DIR` provides another
 way to set the directory containing automake-provided macro files.
 However `--automake-acdir` takes precedence over it.

--system-acdir=DIR​     Look for the system-wide third-party macro files (and the special​     dirlist file) in DIR instead of in the installation directory.​     This is typically used for debugging.
--diff[=COMMAND]​     Run COMMAND on M4 file that would be installed or overwritten by​     --install.  The default COMMAND is diff -u.  This option​     implies --install and --dry-run.
--dry-run​     Do not actually overwrite (or create) aclocal.m4 and M4 files​     installed by --install.
--help​     Print a summary of the command line options and exit.
-I DIR​     Add the directory DIR to the list of directories searched for .m4​     files.
--install​     Install system-wide third-party macros into the first directory​     specified with -I DIR instead of copying them in the output file.​     Note that this will happen also if DIR is an absolute path.
 When this option is used, and only when this option is used,
 `aclocal` will also honor `#serial NUMBER` lines that appear in
 macros: an M4 file is ignored if there exists another M4 file with
 the same basename and a greater serial number in the search path
 (note Serials::).

--force​     Always overwrite the output file.  The default is to overwrite the​     output file only when really needed, i.e., when its contents​     changes or if one of its dependencies is younger.
 This option forces the update of `aclocal.m4` (or the file
 specified with `--output` below) and only this file, it has
 absolutely no influence on files that may need to be installed by
 `--install`.

--output=FILE​     Cause the output to be put into FILE instead of aclocal.m4.
--print-ac-dir​     Prints the name of the directory that aclocal will search to find​     third-party .m4 files.  When this option is given, normal​     processing is suppressed.  This option was used in the past by​     third-party packages to determine where to install .m4 macro​     files, but this usage is today discouraged, since it causes​     $(prefix) not to be thoroughly honored (which violates the GNU​     Coding Standards), and a similar semantics can be better obtained​     with the ACLOCAL_PATH environment variable; note Extending​     aclocal::.
--verbose​     Print the names of the files it examines.
--version​     Print the version number of Automake and exit.
-W CATEGORY--warnings=CATEGORY​     Output warnings falling in CATEGORY.  CATEGORY can be one of:​     syntax​          dubious syntactic constructs, underquoted macros, unused​          macros, etc.​     unsupported​          unknown macros​     all​          all the warnings, this is the default​     none​          turn off all the warnings​     error​          treat warnings as errors
 All warnings are output by default.

 The environment variable `WARNINGS` is honored in the same way as
 it is for `automake` (note automake Invocation::).

6.3.2 Macro Search Path

默认情况下 aclocal 按照下面的目录顺序来搜索 .m4 文件：
ACDIR-APIVERSION​     This is where the .m4 macros distributed with Automake itself are​     stored.  APIVERSION depends on the Automake release used; for​     example, for Automake 1.11.x, APIVERSION = 1.11.
ACDIR​     This directory is intended for third party .m4 files, and is​     configured when automake itself is built.  This is​     @datadir@/aclocal/, which typically expands to​     ${prefix}/share/aclocal/.  To find the compiled-in value of​     ACDIR, use the --print-ac-dir option (note aclocal Options::).
   As an example, suppose that automake-1.11.2 was configured with--prefix=/usr/local.  Then, the search path would be:

/usr/local/share/aclocal-1.11.2/
/usr/local/share/aclocal/

   The paths for the ACDIR and ACDIR-APIVERSION directories can bechanged respectively through aclocal options --system-acdir and--automake-acdir (note aclocal Options::).  Note however that theseoptions are only intended for use by the internal Automake test suite,or for debugging under highly unusual situations; they are notordinarily needed by end-users.
   As explained in (note aclocal Options::), there are several optionsthat can be used to change or extend this search path.
Modifying the Macro Search Path: -I DIR…………………………………..
Any extra directories specified using -I options (note aclocalOptions::) are prepended to this search list.  Thus, aclocal -I /foo -I /bar results in the following search path:

/foo
/bar
ACDIR-APIVERSION
ACDIR

Modifying the Macro Search Path: dirlist……………………………………
There is a third mechanism for customizing the search path.  If adirlist file exists in ACDIR, then that file is assumed to contain alist of directory patterns, one per line.  aclocal expands thesepatterns to directory names, and adds them to the search list afterall other directories.  dirlist entries may use shell wildcards suchas *, ?, or [...].
   For example, suppose ACDIR/dirlist contains the following:
 /test1
 /test2
 /test3*

and that aclocal was called with the -I /foo -I /bar options.  Then,the search path would be

/foo
/bar
ACDIR-APIVERSION
ACDIR
/test1
/test2

and all directories with path names starting with /test3.
   If the --system-acdir=DIR option is used, then aclocal willsearch for the dirlist file in DIR; but remember the warnings aboveagainst the use of --system-acdir.
   dirlist is useful in the following situation: suppose thatautomake version 1.11.2 is installed with --prefix=/usr by thesystem vendor.  Thus, the default search directories are

/usr/share/aclocal-1.11/
/usr/share/aclocal/

   However, suppose further that many packages have been manuallyinstalled on the system, with $prefix=/usr/local, as is typical.  Inthat case, many of these “extra” .m4 files are in/usr/local/share/aclocal.  The only way to force /usr/bin/aclocal tofind these “extra” .m4 files is to always call aclocal -I /usr/local/share/aclocal.  This is inconvenient.  With dirlist, onemay create a file /usr/share/aclocal/dirlist containing only thesingle line
 /usr/local/share/aclocal

   Now, the “default” search path on the affected system is

/usr/share/aclocal-1.11/
/usr/share/aclocal/
/usr/local/share/aclocal/

   without the need for -I options; -I options can be reserved forproject-specific needs (my-source-dir/m4/), rather than using it towork around local system-dependent tool installation directories.
   Similarly, dirlist can be handy if you have installed a local copyof Automake in your account and want aclocal to look for macrosinstalled at other places on the system.
Modifying the Macro Search Path: ACLOCAL_PATH………………………………………..
The fourth and last mechanism to customize the macro search path is alsothe simplest.  Any directory included in the colon-separated environmentvariable ACLOCAL_PATH is added to the search path and takes precedenceover system directories (including those found via dirlist), with theexception of the versioned directory ACDIR-APIVERSION (note MacroSearch Path::).  However, directories passed via -I will takeprecedence over directories in ACLOCAL_PATH.
   Also note that, if the --install option is used, any .m4 filecontaining a required macro that is found in a directory listed inACLOCAL_PATH will be installed locally.  In this case, serial numbersin .m4 are honored too, note Serials::.
   Conversely to dirlist, ACLOCAL_PATH is useful if you are using aglobal copy of Automake and want aclocal to look for macros somewhereunder your home directory.
Planned future incompatibilities…………………………..
The order in which the directories in the macro search path arecurrently looked up is confusing and/or suboptimal in various aspects,and is probably going to be changed in the future Automake release.  Inparticular, directories in ACLOCAL_PATH and ACDIR might end uptaking precedence over ACDIR-APIVERSION, and directories inACDIR/dirlist might end up taking precedence over ACDIR.  This is apossible future incompatibility!
6.3.3 Writing your own aclocal macros

The aclocal program doesn`t have any built-in knowledge of any macros,so it is easy to extend it with your own macros.
   This can be used by libraries that want to supply their own Autoconfmacros for use by other programs.  For instance, the gettext librarysupplies a macro AM_GNU_GETTEXT that should be used by any packageusing gettext.  When the library is installed, it installs this macroso that aclocal will find it.
   A macro files name should end in .m4.  Such files should be installed in $(datadir)/aclocal`.  This is as simple as writing:
 aclocaldir = $(datadir)/aclocal
 aclocal_DATA = mymacro.m4 myothermacro.m4

Please do use $(datadir)/aclocal, and not something based on theresult of aclocal --print-ac-dir (note Hard-Coded Install Paths::,for arguments).  It might also be helpful to suggest to the user to addthe $(datadir)/aclocal directory to his ACLOCAL_PATH variable (noteACLOCAL_PATH::) so that aclocal will find the .m4 files installed byyour package automatically.
   A file of macros should be a series of properly quoted AC_DEFUN``s (note (autoconf)Macro Definitions::).  The aclocalprograms also understandsAC_REQUIRE(note (autoconf)Prerequisite Macros::), so it is safe to put each macro in a separate file.  Each file should have no side effects but macro definitions.  Especially, any call toAC_PREREQ`should be done inside the defined macro, not at the beginning of thefile.
   Starting with Automake 1.8, aclocal will warn about all underquotedcalls to AC_DEFUN.  We realize this will annoy a lot of people,because aclocal was not so strict in the past and many third partymacros are underquoted; and we have to apologize for this temporaryinconvenience.  The reason we have to be stricter is that a futureimplementation of aclocal (note Future of aclocal::) will have totemporarily include all of these third party .m4 files, maybe severaltimes, including even files that are not actually needed.  Doing soshould alleviate many problems of the current implementation, however itrequires a stricter style from the macro authors.  Hopefully it is easyto revise the existing macros.  For instance,
 # bad style
 AC_PREREQ(2.68)
 AC_DEFUN(AX_FOOBAR,
 [AC_REQUIRE([AX_SOMETHING])dnl
 AX_FOO
 AX_BAR
 ])

should be rewritten as
 AC_DEFUN([AX_FOOBAR],
 [AC_PREREQ([2.68])dnl
 AC_REQUIRE([AX_SOMETHING])dnl
 AX_FOO
 AX_BAR
 ])

   Wrapping the AC_PREREQ call inside the macro ensures that Autoconf2.68 will not be required if AX_FOOBAR is not actually used.  Mostimportantly, quoting the first argument of AC_DEFUN allows the macroto be redefined or included twice (otherwise this first argument wouldbe expanded during the second definition).  For consistency we like toquote even arguments such as 2.68 that do not require it.
   If you have been directed here by the aclocal diagnostic but arenot the maintainer of the implicated macro, you will want to contact themaintainer of that macro.  Please make sure you have the latest versionof the macro and that the problem hasnt already been reported before doing so: people tend to work faster when they arent flooded by mails.
   Another situation where aclocal is commonly used is to managemacros that are used locally by the package, note Local Macros::.
6.3.4 Handling Local Macros

Feature tests offered by Autoconf do not cover all needs.  People oftenhave to supplement existing tests with their own macros, or withthird-party macros.
   There are two ways to organize custom macros in a package.
   The first possibility (the historical practice) is to list all yourmacros in acinclude.m4.  This file will be included in aclocal.m4when you run aclocal, and its macro(s) will henceforth be visible toautoconf.  However if it contains numerous macros, it will rapidlybecome difficult to maintain, and it will be almost impossible to sharemacros between packages.
   The second possibility, which we do recommend, is to write each macroin its own file and gather all these files in a directory.  Thisdirectory is usually called m4/.  Then its enough to update configure.acby adding a proper call toAC_CONFIG_MACRO_DIRS`:
 AC_CONFIG_MACRO_DIRS([m4])

   aclocal will then take care of automatically adding m4/ to itssearch path for m4 files.
   When aclocal is run, it will build an aclocal.m4 thatm4_includes any file from m4/ that defines a required macro.  Macrosnot found locally will still be searched in system-wide directories, asexplained in note Macro Search Path::.
   Custom macros should be distributed for the same reason thatconfigure.ac is: so that other people have all the sources of yourpackage if they want to work on it.  Actually, this distribution happensautomatically because all m4_included files are distributed.
   However there is no consensus on the distribution of third-partymacros that your package may use.  Many libraries install their ownmacro in the system-wide aclocal directory (note Extendingaclocal::).  For instance, Guile ships with a file called guile.m4that contains the macro GUILE_FLAGS that can be used to define setupcompiler and linker flags appropriate for using Guile.  UsingGUILE_FLAGS in configure.ac will cause aclocal to copy guile.m4into aclocal.m4, but as guile.m4 is not part of the project, it willnot be distributed.  Technically, that means a user who needs to rebuildaclocal.m4 will have to install Guile first.  This is probably OK, ifGuile already is a requirement to build the package.  However, if Guileis only an optional feature, or if your package might run onarchitectures where Guile cannot be installed, this requirement willhinder development.  An easy solution is to copy such third-party macrosin your local m4/ directory so they get distributed.
   Since Automake 1.10, aclocal offers the option --install to copythese system-wide third-party macros in your local macro directory,helping to solve the above problem.
   With this setup, system-wide macros will be copied to m4/ the firsttime you run aclocal.  Then the locally installed macros will haveprecedence over the system-wide installed macros each time aclocal isrun again.
   One reason why you should keep --install in the flags even afterthe first run is that when you later edit configure.ac and depend on anew macro, this macro will be installed in your m4/ automatically.Another one is that serial numbers (note Serials::) can be used toupdate the macros in your source tree automatically when new system-wideversions are installed.  A serial number should be a single line of theform
 #serial NNN

where NNN contains only digits and dots.  It should appear in the M4file before any macro definition.  It is a good practice to maintain aserial number for each macro you distribute, even if you do not use the--install option of aclocal: this allows other people to use it.
6.3.5 Serial Numbers

Because third-party macros defined in *.m4 files are naturally sharedbetween multiple projects, some people like to version them.  This makesit easier to tell which of two M4 files is newer.  Since at least 1996,the tradition is to use a #serial line for this.
   A serial number should be a single line of the form
 # serial VERSION

where VERSION is a version number containing only digits and dots.Usually people use a single integer, and they increment it each timethey change the macro (hence the name of “serial”).  Such a line shouldappear in the M4 file before any macro definition.
   The # must be the first character on the line, and it is OK to haveextra words after the version, as in
 #serial VERSION GARBAGE

   Normally these serial numbers are completely ignored by aclocal andautoconf, like any genuine comment.  However when using aclocal``s –installfeature, these serial numbers will modify the wayaclocalselects the macros to install in the package: if two files with the same basename exist in your search path, and if at least one of them uses a#serialline,aclocalwill ignore the file that has the older#serial` line (or the file that has none).
   Note that a serial number applies to a whole M4 file, not to anymacro it contains.  A file can contains multiple macros, but only oneserial.
   Here is a use case that illustrates the use of --install and itsinteraction with serial numbers.  Lets assume we maintain a package called MyPackage, the configure.acof which requires a third-party macroAX_THIRD_PARTYdefined in/usr/share/aclocal/thirdparty.m4` asfollows:
 # serial 1
 AC_DEFUN([AX_THIRD_PARTY], [...])

   MyPackage uses an m4/ directory to store local macros as explainedin note Local Macros::, and has
 AC_CONFIG_MACRO_DIRS([m4])

in its configure.ac.
   Initially the m4/ directory is empty.  The first time we runaclocal --install, it will notice that
   • configure.ac uses AX_THIRD_PARTY   • No local macros define AX_THIRD_PARTY   • /usr/share/aclocal/thirdparty.m4 defines AX_THIRD_PARTY with​     serial 1.
Because /usr/share/aclocal/thirdparty.m4 is a system-wide macro andaclocal was given the --install option, it will copy this file inm4/thirdparty.m4, and output an aclocal.m4 that containsm4_include([m4/thirdparty.m4]).
   The next time aclocal --install is run, something differenthappens.  aclocal notices that
   • configure.ac uses AX_THIRD_PARTY   • m4/thirdparty.m4 defines AX_THIRD_PARTY with serial 1.   • /usr/share/aclocal/thirdparty.m4 defines AX_THIRD_PARTY with​     serial 1.
Because both files have the same serial number, aclocal uses the firstit found in its search path order (note Macro Search Path::).aclocal therefore ignores /usr/share/aclocal/thirdparty.m4 andoutputs an aclocal.m4 that contains m4_include([m4/thirdparty.m4]).
   Local directories specified with -I are always searched beforesystem-wide directories, so a local file will always be preferred to thesystem-wide file in case of equal serial numbers.
   Now suppose the system-wide third-party macro is changed.  This canhappen if the package installing this macro is updated.  Lets suppose the new macro has serial number 2.  The next time aclocal –install` isrun the situation is the following:
   • configure.ac uses AX_THIRD_PARTY   • m4/thirdparty.m4 defines AX_THIRD_PARTY with serial 1.   • /usr/share/aclocal/thirdparty.m4 defines AX_THIRD_PARTY with​     serial 2.
When aclocal sees a greater serial number, it immediately forgetsanything it knows from files that have the same basename and a smallerserial number.  So after it has found /usr/share/aclocal/thirdparty.m4with serial 2, aclocal will proceed as if it had never seenm4/thirdparty.m4.  This brings us back to a situation similar to thatat the beginning of our example, where no local file defined the macro.aclocal will install the new version of the macro inm4/thirdparty.m4, in this case overriding the old version.  MyPackagejust had its macro updated as a side effect of running aclocal.
   If you are leery of letting aclocal update your local macro, youcan run aclocal --diff to review the changes aclocal --install wouldperform on these macros.
   Finally,note that the --force option of aclocal has absolutelyno effect on the files installed by --install.  For instance, if youhave modified your local macros, do not expect --install --force toreplace the local macros by their system-wide versions.  If you want todo so, simply erase the local macros you want to revert, and runaclocal --install.
6.3.6 The Future of aclocal

aclocal is expected to disappear.  This feature really should not beoffered by Automake.  Automake should focus on generating Makefiles;dealing with M4 macros really is Autoconfs job.  The fact that some people install Automake just to use aclocal, but do not use automake`otherwise is an indication of how that feature is misplaced.
   The new implementation will probably be done slightly differently.For instance, it could enforce the m4/-style layout discussed in noteLocal Macros::.
   We have no idea when and how this will happen.  This has beendiscussed several times in the past, but someone still has to commit tothat non-trivial task.
   From the user point of view, aclocal``s removal might turn out to be painful.  There is a simple precaution that you may take to make that switch more seamless: never call aclocalyourself.  Keep this guy under the exclusive control ofautoreconf and Automakes rebuildrules.  Hopefully you wont need to worry about things breaking, when aclocaldisappears, because everything will have been taken care of. If otherwise you used to callaclocal` directly yourself or from somescript, you will quickly notice the change.
   Many packages come with a script called bootstrap or autogen.sh,that will just call aclocal, libtoolize, gettextize orautopoint, autoconf, autoheader, and automake in the rightorder.  Actually this is precisely what autoreconf can do for you.  Ifyour package has such a bootstrap or autogen.sh script, considerusing autoreconf.  That should simplify its logic a lot (less thingsto maintain, yum!), its even likely you will not need the script anymore, and more to the point you will not call aclocal` directlyanymore.
   For the time being, third-party packages should continue to installpublic macros into /usr/share/aclocal/.  If aclocal is replaced byanother tool it might make sense to rename the directory, but supporting/usr/share/aclocal/ for backward compatibility should be really easyprovided all macros are properly written (note Extending aclocal::).
6.4 Autoconf macros supplied with Automake
Automake ships with several Autoconf macros that you can use from yourconfigure.ac.  When you use one of them it will be included byaclocal in aclocal.m4.
6.4.1 Public Macros

AM_INIT_AUTOMAKE([OPTIONS])​     Runs many macros required for proper operation of the generated​     Makefiles.
 Today, `AM_INIT_AUTOMAKE` is called with a single argument: a
 space-separated list of Automake options that should be applied to
 every `Makefile.am` in the tree.  The effect is as if each option
 were listed in `AUTOMAKE_OPTIONS` (note Options::).

 This macro can also be called in another, _deprecated_ form:
 `AM_INIT_AUTOMAKE(PACKAGE, VERSION, [NO-DEFINE])`.  In this form,
 there are two required arguments: the package and the version
 number.  This usage is mostly obsolete because the PACKAGE and
 VERSION can be obtained from Autoconf`s `AC_INIT` macro.  However,
 differently from what happens for `AC_INIT` invocations, this
 `AM_INIT_AUTOMAKE` invocation supports shell variables` expansions
 in the `PACKAGE` and `VERSION` arguments (which otherwise defaults,
 respectively, to the `PACKAGE_TARNAME` and `PACKAGE_VERSION`
 defined via the `AC_INIT` invocation; note The `AC_INIT` macro:
 (autoconf)AC_INIT.); and this can be still be useful in some
 selected situations.  Our hope is that future Autoconf versions
 will improve their support for package versions defined dynamically
 at configure runtime; when (and if) this happens, support for the
 two-args `AM_INIT_AUTOMAKE` invocation will likely be removed from
 Automake.

 If your `configure.ac` has:

      AC_INIT([src/foo.c])
      AM_INIT_AUTOMAKE([mumble], [1.5])

 you should modernize it as follows:

      AC_INIT([mumble], [1.5])
      AC_CONFIG_SRCDIR([src/foo.c])
      AM_INIT_AUTOMAKE

 Note that if you`re upgrading your `configure.ac` from an earlier
 version of Automake, it is not always correct to simply move the
 package and version arguments from `AM_INIT_AUTOMAKE` directly to
 `AC_INIT`, as in the example above.  The first argument to
 `AC_INIT` should be the name of your package (e.g., `GNU
 Automake`), not the tarball name (e.g., `automake`) that you used
 to pass to `AM_INIT_AUTOMAKE`.  Autoconf tries to derive a tarball
 name from the package name, which should work for most but not all
 package names.  (If it doesn`t work for yours, you can use the
 four-argument form of `AC_INIT` to provide the tarball name
 explicitly).

 By default this macro `AC_DEFINE``s `PACKAGE` and `VERSION`.  This
 can be avoided by passing the `no-define` option (note List of
 Automake options::):
      AM_INIT_AUTOMAKE([no-define ...])

AM_PATH_LISPDIR​     Searches for the program emacs, and, if found, sets the output​     variable lispdir to the full path to Emacs` site-lisp directory.
 Note that this test assumes the `emacs` found to be a version that
 supports Emacs Lisp (such as GNU Emacs or XEmacs).  Other emacsen
 can cause this test to hang (some, like old versions of MicroEmacs,
 start up in interactive mode, requiring `C-x C-c` to exit, which is
 hardly obvious for a non-emacs user).  In most cases, however, you
 should be able to use `C-c` to kill the test.  In order to avoid
 problems, you can set `EMACS` to “no” in the environment, or use
 the `--with-lispdir` option to `configure` to explicitly set the
 correct path (if you`re sure you have an `emacs` that supports
 Emacs Lisp).

AM_PROG_AR([ACT-IF-FAIL])​     You must use this macro when you use the archiver in your project,​     if you want support for unusual archivers such as Microsoft lib.​     The content of the optional argument is executed if the archiver​     interface is not recognized; the default action is to abort​     configure with an error message.
AM_PROG_AS​     Use this macro when you have assembly code in your project.  This​     will choose the assembler for you (by default the C compiler) and​     set CCAS, and will also set CCASFLAGS if required.
AM_PROG_CC_C_O​     This is an obsolescent macro that checks that the C compiler​     supports the -c and -o options together.  Note that, since​     Automake 1.14, the AC_PROG_CC is rewritten to implement such​     checks itself, and thus the explicit use of AM_PROG_CC_C_O should​     no longer be required.
AM_PROG_LEX​     Like AC_PROG_LEX (note Particular Program Checks:​     (autoconf)Particular Programs.), but uses the missing script on​     systems that do not have lex.  HP-UX 10 is one such system.
AM_PROG_GCJ​     This macro finds the gcj program or causes an error.  It sets​     GCJ and GCJFLAGS.  gcj is the Java front-end to the GNU​     Compiler Collection.
AM_PROG_UPC([COMPILER-SEARCH-LIST])​     Find a compiler for Unified Parallel C and define the UPC​     variable.  The default COMPILER-SEARCH-LIST is upcc upc.  This​     macro will abort configure if no Unified Parallel C compiler is​     found.
AM_MISSING_PROG(NAME, PROGRAM)​     Find a maintainer tool PROGRAM and define the NAME environment​     variable with its location.  If PROGRAM is not detected, then NAME​     will instead invoke the missing script, in order to give useful​     advice to the user about the missing maintainer tool.   for more information on when the missing​     script is appropriate.
AM_SILENT_RULES​     Control the machinery for less verbose build output (note Automake​     Silent Rules::).
AM_WITH_DMALLOC​     Add support for the Dmalloc package (http://dmalloc.com/).  If the​     user runs configure with --with-dmalloc, then define​     WITH_DMALLOC and add -ldmalloc to LIBS.
6.4.2 Obsolete Macros

Although using some of the following macros was required in pastreleases, you should not use any of them in new code.  All these macroswill be removed in the next major Automake version; if you are stillusing them, running autoupdate should adjust your configure.acautomatically (note Using autoupdate to Modernize configure.ac:(autoconf)autoupdate Invocation.).  Do it NOW!
AM_PROG_MKDIR_P
 From Automake 1.8 to 1.9.6 this macro used to define the output
 variable `mkdir_p` to one of `mkdir -p`, `install-sh -d`, or
 `mkinstalldirs`.

 Nowadays Autoconf provides a similar functionality with
 `AC_PROG_MKDIR_P` (note Particular Program Checks:
 (autoconf)Particular Programs.), however this defines the output
 variable `MKDIR_P` instead.  In case you are still using the
 `AM_PROG_MKDIR_P` macro in your `configure.ac`, or its provided
 variable `$(mkdir_p)` in your `Makefile.am`, you are advised to
 switch ASAP to the more modern Autoconf-provided interface instead;
 both the macro and the variable might be removed in a future major
 Automake release.

6.4.3 Private Macros***********************The following macros are private macros you should not call directly.They are called by the other public macros when appropriate.  Do notrely on them, as they might be changed in a future version.  Considerthem as implementation details; or better, do not consider them at all:skip this section!
_AM_DEPENDENCIESAM_SET_DEPDIRAM_DEP_TRACKAM_OUTPUT_DEPENDENCY_COMMANDS​     These macros are used to implement Automake`s automatic dependency​     tracking scheme.  They are called automatically by Automake when​     required, and there should be no need to invoke them manually.
AM_MAKE_INCLUDE​     This macro is used to discover how the users makehandles ​    include` statements.  This macro is automatically invoked when​     needed; there should be no need to invoke it manually.
AM_PROG_INSTALL_STRIP​     This is used to find a version of install that can be used to​     strip a program at installation time.  This macro is automatically​     included when required.
AM_SANITY_CHECK​     This checks to make sure that a file created in the build directory​     is newer than a file in the source directory.  This can fail on​     systems where the clock is set incorrectly.  This macro is​     automatically run from AM_INIT_AUTOMAKE.
]]></content>
      <categories>
        <category>Linux</category>
        <category>Automake</category>
      </categories>
      <tags>
        <tag>autotools</tag>
        <tag>automake</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux Automake 7 目录</title>
    <url>/2018/03/17/linux-automake-7-directories/</url>
    <content><![CDATA[
GNU Automake 版本(version 1.16.1, 26 February 2018)
Permission is granted to copy, distribute and/or modify thisdocument under the terms of the GNU Free Documentation License,Version 1.3 or any later version published by the Free SoftwareFoundation; with no Invariant Sections, with no Front-Cover texts,and with no Back-Cover Texts.  A copy of the license is included inthe section entitled “GNU Free Documentation License.”

7 Directories

For simple projects that distribute all files in the same directory itis enough to have a single ‘Makefile.am’ that builds everything inplace.
   In larger projects, it is common to organize files in differentdirectories, in a tree.  For example, there could be a directory for theprogram’s source, one for the testsuite, and one for the documentation;or, for very large projects, there could be one directory per program,per library or per module.
   The traditional approach is to build these subdirectoriesrecursively, employing make recursion: each directory contains its own‘Makefile’, and when ‘make’ is run from the top-level directory, itenters each subdirectory in turn, and invokes there a new ‘make’instance to build the directory’s contents.
   Because this approach is very widespread, Automake offers built-insupport for it.  However, it is worth nothing that the use of makerecursion has its own serious issues and drawbacks, and that it’s wellpossible to have packages with a multi directory layout that make littleor no use of such recursion (examples of such packages are GNU Bison andGNU Automake itself); see also the
7.1 Recursing subdirectoriesIn packages using make recursion, the top level ‘Makefile.am’ must tellAutomake which subdirectories are to be built.  This is done via the‘SUBDIRS’ variable.
   The ‘SUBDIRS’ variable holds a list of subdirectories in whichbuilding of various sorts can occur.  The rules for many targets (e.g.,‘all’) in the generated ‘Makefile’ will run commands both locally and inall specified subdirectories.  Note that the directories listed in‘SUBDIRS’ are not required to contain ‘Makefile.am’s; only ‘Makefile’s(after configuration).  This allows inclusion of libraries from packagesthat do not use Automake (such as ‘gettext’; see also
   In packages that use subdirectories, the top-level ‘Makefile.am’ isoften very short.  For instance, here is the ‘Makefile.am’ from the GNUHello distribution:
 EXTRA_DIST = BUGS ChangeLog.O README-alpha
 SUBDIRS = doc intl po src tests

   When Automake invokes ‘make’ in a subdirectory, it uses the value ofthe ‘MAKE’ variable.  It passes the value of the variable ‘AM_MAKEFLAGS’to the ‘make’ invocation; this can be set in ‘Makefile.am’ if there areflags you must always pass to ‘make’.
   The directories mentioned in ‘SUBDIRS’ are usually direct children ofthe current directory, each subdirectory containing its own‘Makefile.am’ with a ‘SUBDIRS’ pointing to deeper subdirectories.Automake can be used to construct packages of arbitrary depth this way.
   By default, Automake generates ‘Makefiles’ that work depth-first inpostfix order: the subdirectories are built before the currentdirectory.  However, it is possible to change this ordering.  You can dothis by putting ‘.’ into ‘SUBDIRS’.  For instance, putting ‘.’ firstwill cause a prefix ordering of directories.
   Using
 SUBDIRS = lib src . test

will cause ‘lib/’ to be built before ‘src/’, then the current directorywill be built, finally the ‘test/’ directory will be built.  It iscustomary to arrange test directories to be built after everything elsesince they are meant to test what has been constructed.
   In addition to the built-in recursive targets defined by Automake(‘all’, ‘check’, etc.), the developer can also define his own recursivetargets.  That is done by passing the names of such targets as argumentsto the m4 macro ‘AM_EXTRA_RECURSIVE_TARGETS’ in ‘configure.ac’.Automake generates rules to handle the recursion for such targets; andthe developer can define real actions for them by defining corresponding‘-local’ targets.
 % cat configure.ac
 AC_INIT([pkg-name], [1.0]
 AM_INIT_AUTOMAKE
 AM_EXTRA_RECURSIVE_TARGETS([foo])
 AC_CONFIG_FILES([Makefile sub/Makefile sub/src/Makefile])
 AC_OUTPUT
 % cat Makefile.am
 SUBDIRS = sub
 foo-local:
         @echo This will be run by "make foo".
 % cat sub/Makefile.am
 SUBDIRS = src
 % cat sub/src/Makefile.am
 foo-local:
         @echo This too will be run by a "make foo" issued either in
         @echo the 'sub/src/' directory, the 'sub/' directory, or the
         @echo top-level directory.

7.2 Conditional SubdirectoriesIt is possible to define the ‘SUBDIRS’ variable conditionally if, likein the case of GNU Inetutils, you want to only build a subset of theentire package.
   To illustrate how this works, let’s assume we have two directories‘src/’ and ‘opt/’.  ‘src/’ should always be built, but we want to decidein ‘configure’ whether ‘opt/’ will be built or not.  (For this examplewe will assume that ‘opt/’ should be built when the variable ‘$want_opt’was set to ‘yes’.)
   Running ‘make’ should thus recurse into ‘src/’ always, and then maybein ‘opt/’.
   However ‘make dist’ should always recurse into both ‘src/’ and‘opt/’.  Because ‘opt/’ should be distributed even if it is not neededin the current configuration.  This means ‘opt/Makefile’ should becreated unconditionally.
   There are two ways to setup a project like this.  You can useAutomake conditionals () or use Autoconf ‘AC_SUBST’variables  Using Automake conditionals is the preferred solution.Before we illustrate these two possibilities, let’s introduce‘DIST_SUBDIRS’.
7.2.1 ‘SUBDIRS’ vs. ‘DIST_SUBDIRS’Automake considers two sets of directories, defined by the variables‘SUBDIRS’ and ‘DIST_SUBDIRS’.
   ‘SUBDIRS’ contains the subdirectories of the current directory thatmust be built .  It must be defined manually;Automake will never guess a directory is to be built.  As we will see inthe next two sections, it is possible to define it conditionally so thatsome directory will be omitted from the build.
   ‘DIST_SUBDIRS’ is used in rules that need to recurse in alldirectories, even those that have been conditionally left out of thebuild.  Recall our example where we may not want to build subdirectory‘opt/’, but yet we want to distribute it?  This is where ‘DIST_SUBDIRS’comes into play: ‘opt’ may not appear in ‘SUBDIRS’, but it must appearin ‘DIST_SUBDIRS’.
   Precisely, ‘DIST_SUBDIRS’ is used by ‘make maintainer-clean’, ‘makedistclean’ and ‘make dist’.  All other recursive rules use ‘SUBDIRS’.
   If ‘SUBDIRS’ is defined conditionally using Automake conditionals,Automake will define ‘DIST_SUBDIRS’ automatically from the possiblevalues of ‘SUBDIRS’ in all conditions.
   If ‘SUBDIRS’ contains ‘AC_SUBST’ variables, ‘DIST_SUBDIRS’ will notbe defined correctly because Automake does not know the possible valuesof these variables.  In this case ‘DIST_SUBDIRS’ needs to be definedmanually.
7.2.2 Subdirectories with ‘AM_CONDITIONAL’‘configure’ should output the ‘Makefile’ for each directory and define acondition into which ‘opt/’ should be built.
 ...
 AM_CONDITIONAL([COND_OPT], [test "$want_opt" = yes])
 AC_CONFIG_FILES([Makefile src/Makefile opt/Makefile])
 ...

   Then ‘SUBDIRS’ can be defined in the top-level ‘Makefile.am’ asfollows.
 if COND_OPT
   MAYBE_OPT = opt
 endif
 SUBDIRS = src $(MAYBE_OPT)

   As you can see, running ‘make’ will rightly recurse into ‘src/’ andmaybe ‘opt/’.
   As you can’t see, running ‘make dist’ will recurse into both ‘src/’and ‘opt/’ directories because ‘make dist’, unlike ‘make all’, doesn’tuse the ‘SUBDIRS’ variable.  It uses the ‘DIST_SUBDIRS’ variable.
   In this case Automake will define ‘DIST_SUBDIRS = src opt’automatically because it knows that ‘MAYBE_OPT’ can contain ‘opt’ insome condition.
7.2.3 Subdirectories with ‘AC_SUBST’Another possibility is to define ‘MAYBE_OPT’ from ‘./configure’ using‘AC_SUBST’:
 ...
 if test "$want_opt" = yes; then
   MAYBE_OPT=opt
 else
   MAYBE_OPT=
 fi
 AC_SUBST([MAYBE_OPT])
 AC_CONFIG_FILES([Makefile src/Makefile opt/Makefile])
 ...

   In this case the top-level ‘Makefile.am’ should look as follows.
 SUBDIRS = src $(MAYBE_OPT)
 DIST_SUBDIRS = src opt

   The drawback is that since Automake cannot guess what the possiblevalues of ‘MAYBE_OPT’ are, it is necessary to define ‘DIST_SUBDIRS’.
7.2.4 Unconfigured SubdirectoriesThe semantics of ‘DIST_SUBDIRS’ are often misunderstood by some usersthat try to configure and build subdirectories conditionally.  Here byconfiguring we mean creating the ‘Makefile’ (it might also involverunning a nested ‘configure’ script: this is a costly operation thatexplains why people want to do it conditionally, but only the ‘Makefile’is relevant to the discussion).
   The above examples all assume that every ‘Makefile’ is created, evenin directories that are not going to be built.  The simple reason isthat we want ‘make dist’ to distribute even the directories that are notbeing built (e.g., platform-dependent code), hence ‘make dist’ mustrecurse into the subdirectory, hence this directory must be configuredand appear in ‘DIST_SUBDIRS’.
   Building packages that do not configure every subdirectory is atricky business, and we do not recommend it to the novice as it is easyto produce an incomplete tarball by mistake.  We will not discuss thistopic in depth here, yet for the adventurous here are a few rules toremember.
   • ‘SUBDIRS’ should always be a subset of ‘DIST_SUBDIRS’.
 It makes little sense to have a directory in ‘SUBDIRS’ that is not
 in ‘DIST_SUBDIRS’.  Think of the former as a way to tell which
 directories listed in the latter should be built.

   • Any directory listed in ‘DIST_SUBDIRS’ and ‘SUBDIRS’ must be     configured.
 I.e., the ‘Makefile’ must exists or the recursive ‘make’ rules will
 not be able to process the directory.

   • Any configured directory must be listed in ‘DIST_SUBDIRS’.
 So that the cleaning rules remove the generated ‘Makefile’s.  It
 would be correct to see ‘DIST_SUBDIRS’ as a variable that lists all
 the directories that have been configured.

   In order to prevent recursion in some unconfigured directory you musttherefore ensure that this directory does not appear in ‘DIST_SUBDIRS’(and ‘SUBDIRS’).  For instance, if you define ‘SUBDIRS’ conditionallyusing ‘AC_SUBST’ and do not define ‘DIST_SUBDIRS’ explicitly, it will bedefault to ‘$(SUBDIRS)’; another possibility is to force ‘DIST_SUBDIRS =$(SUBDIRS)’.
   Of course, directories that are omitted from ‘DIST_SUBDIRS’ will notbe distributed unless you make other arrangements for this to happen(for instance, always running ‘make dist’ in a configuration where alldirectories are known to appear in ‘DIST_SUBDIRS’; or writing a‘dist-hook’ target to distribute these directories).
   In few packages, unconfigured directories are not even expected to bedistributed.  Although these packages do not require the aforementionedextra arrangements, there is another pitfall.  If the name of adirectory appears in ‘SUBDIRS’ or ‘DIST_SUBDIRS’, ‘automake’ will makesure the directory exists.  Consequently ‘automake’ cannot be run onsuch a distribution when one directory has been omitted.  One way toavoid this check is to use the ‘AC_SUBST’ method to declare conditionaldirectories; since ‘automake’ does not know the values of ‘AC_SUBST’variables it cannot ensure the corresponding directory exists.
7.3 An Alternative Approach to SubdirectoriesIf you’ve ever read Peter Miller’s excellent paper, Recursive MakeConsidered Harmful (http://miller.emu.id.au/pmiller/books/rmch/), thepreceding sections on the use of make recursion will probably come asunwelcome advice.  For those who haven’t read the paper, Miller’s mainthesis is that recursive ‘make’ invocations are both slow anderror-prone.
   Automake provides sufficient cross-directory support (1) to enableyou to write a single ‘Makefile.am’ for a complex multi-directorypackage.
   By default an installable file specified in a subdirectory will haveits directory name stripped before installation.  For instance, in thisexample, the header file will be installed as ‘$(includedir)/stdio.h’:
 include_HEADERS = inc/stdio.h

   However, the ‘nobase_’ prefix can be used to circumvent this pathstripping.  In this example, the header file will be installed as‘$(includedir)/sys/types.h’:
 nobase_include_HEADERS = sys/types.h

   ‘nobase_’ should be specified first when used in conjunction witheither ‘dist_’ or ‘nodist_’ (.For instance:
 nobase_dist_pkgdata_DATA = images/vortex.pgm sounds/whirl.ogg

   Finally, note that a variable using the ‘nobase_’ prefix can often bereplaced by several variables, one for each destination directory (.  For instance, the last example could be rewritten asfollows:
 imagesdir = $(pkgdatadir)/images
 soundsdir = $(pkgdatadir)/sounds
 dist_images_DATA = images/vortex.pgm
 dist_sounds_DATA = sounds/whirl.ogg

This latter syntax makes it possible to change one destination directorywithout changing the layout of the source tree.
   Currently, ‘nobase_*_LTLIBRARIES’ are the only exception to thisrule, in that there is no particular installation order guarantee for anotherwise equivalent set of variables without ‘nobase_’ prefix.
   ———- Footnotes ———-
   (1) We believe.  This work is new and there are probably warts.
7.4 Nesting PackagesIn the GNU Build System, packages can be nested to arbitrary depth.This means that a package can embed other packages with their own‘configure’, ‘Makefile’s, etc.
   These other packages should just appear as subdirectories of theirparent package.  They must be listed in ‘SUBDIRS’ like other ordinarydirectories.  However the subpackage’s ‘Makefile’s should be output byits own ‘configure’ script, not by the parent’s ‘configure’.  This isachieved using the ‘AC_CONFIG_SUBDIRS’ Autoconf macro (
   Here is an example package for an ‘arm’ program that links with a‘hand’ library that is a nested package in subdirectory ‘hand/’.
   ‘arm’’s ‘configure.ac’:
 AC_INIT([arm], [1.0])
 AC_CONFIG_AUX_DIR([.])
 AM_INIT_AUTOMAKE
 AC_PROG_CC
 AC_CONFIG_FILES([Makefile])
 # Call hand's ./configure script recursively.
 AC_CONFIG_SUBDIRS([hand])
 AC_OUTPUT

   ‘arm’’s ‘Makefile.am’:
 # Build the library in the hand subdirectory first.
 SUBDIRS = hand

 # Include hand's header when compiling this directory.
 AM_CPPFLAGS = -I$(srcdir)/hand

 bin_PROGRAMS = arm
 arm_SOURCES = arm.c
 # link with the hand library.
 arm_LDADD = hand/libhand.a

   Now here is ‘hand’’s ‘hand/configure.ac’:
 AC_INIT([hand], [1.2])
 AC_CONFIG_AUX_DIR([.])
 AM_INIT_AUTOMAKE
 AC_PROG_CC
 AM_PROG_AR
 AC_PROG_RANLIB
 AC_CONFIG_FILES([Makefile])
 AC_OUTPUT

and its ‘hand/Makefile.am’:
 lib_LIBRARIES = libhand.a
 libhand_a_SOURCES = hand.c

   When ‘make dist’ is run from the top-level directory it will createan archive ‘arm-1.0.tar.gz’ that contains the ‘arm’ code as well as the‘hand’ subdirectory.  This package can be built and installed like anyordinary package, with the usual ‘./configure &amp;&amp; make &amp;&amp; make install’sequence (the ‘hand’ subpackage will be built and installed by theprocess).
   When ‘make dist’ is run from the hand directory, it will create aself-contained ‘hand-1.2.tar.gz’ archive.  So although it appears to beembedded in another package, it can still be used separately.
   The purpose of the ‘AC_CONFIG_AUX_DIR([.])’ instruction is to forceAutomake and Autoconf to search for auxiliary scripts in the currentdirectory.  For instance, this means that there will be two copies of‘install-sh’: one in the top-level of the ‘arm’ package, and another onein the ‘hand/’ subdirectory for the ‘hand’ package.
   The historical default is to search for these auxiliary scripts inthe parent directory and the grandparent directory.  So if the‘AC_CONFIG_AUX_DIR([.])’ line was removed from ‘hand/configure.ac’, thatsubpackage would share the auxiliary script of the ‘arm’ package.  Thismay looks like a gain in size (a few kilobytes), but it is actually aloss of modularity as the ‘hand’ subpackage is no longer self-contained(‘make dist’ in the subdirectory will not work anymore).
   Packages that do not use Automake need more work to be integratedthis way.  
]]></content>
      <categories>
        <category>Linux</category>
        <category>Automake</category>
      </categories>
      <tags>
        <tag>autotools</tag>
        <tag>automake</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux Automake 8 编译程序和库</title>
    <url>/2018/03/20/linux-automake-8-building-programs-and-libraries/</url>
    <content><![CDATA[
GNU Automake 版本(version 1.16.1, 26 February 2018)
Permission is granted to copy, distribute and/or modify thisdocument under the terms of the GNU Free Documentation License,Version 1.3 or any later version published by the Free SoftwareFoundation; with no Invariant Sections, with no Front-Cover texts,and with no Back-Cover Texts.  A copy of the license is included inthe section entitled “GNU Free Documentation License.”

8 Building Programs and Libraries
A large part of Automake functionality is dedicated to making it easyto build programs and libraries.
8.1 Building a program======================
为了编译一个程序，你需要告诉Automake需要哪些源码，需要链接哪些库。
8.1.1 Defining program sources
In a directory containing source that gets built into a program (asopposed to a library or a script), the PROGRAMS primary is used.Programs can be installed in bindir, sbindir, libexecdir,pkglibexecdir, or not at all (noinst_).  They can also be built onlyfor make check, in which case the prefix is check_.
   For instance:
 bin_PROGRAMS = hello

   In this simple case, the resulting Makefile.in will contain code togenerate a program named hello.
   Associated with each program are several assisting variables that arenamed after the program.  These variables are all optional, and havereasonable defaults.  Each variable, its use, and default is spelled outbelow; we use the “hello” example throughout.
   The variable hello_SOURCES is used to specify which source filesget built into an executable:
 hello_SOURCES = hello.c version.c getopt.c getopt1.c getopt.h system.h

   This causes each mentioned .c file to be compiled into thecorresponding .o.  Then all are linked to produce hello.
   If hello_SOURCES is not specified, then it defaults to the singlefile hello.c
   Multiple programs can be built in a single directory.  Multipleprograms can share a single source file, which must be listed in each_SOURCES definition.
   Header files listed in a _SOURCES definition will be included inthe distribution but otherwise ignored.  In case it isnt obvious, you should not include the header file generated by configurein a_SOURCES variable; this file should not be distributed.  Lex (.l) and Yacc (.y`) files can also be listed; see *note Yacc and Lex::.
8.1.2 Linking the program
如果希望链接 configure文件中没有的库，可以使用 LDADD 搞定。这个变量用于指定链接的目标文件或者库，如果希望再指定一些参数，可以使用 AM_LDFLAGS 。
   Sometimes, multiple programs are built in one directory but do notshare the same link-time requirements.  In this case, you can use thePROG_LDADD variable (where PROG is the name of the program as itappears in some _PROGRAMS variable, and usually written in lowercase)to override LDADD.  If this variable exists for a given program, thenthat program is not linked using LDADD.
   For instance, in GNU cpio, pax, cpio and mt are linked againstthe library libcpio.a.  However, rmt is built in the same directory,and has no such link requirement.  Also, mt and rmt are only builton certain architectures.  Here is what cpios src/Makefile.am` lookslike (abridged):
 bin_PROGRAMS = cpio pax $(MT)
 libexec_PROGRAMS = $(RMT)
 EXTRA_PROGRAMS = mt rmt

 LDADD = ../lib/libcpio.a $(INTLLIBS)
 rmt_LDADD =

 cpio_SOURCES = ...
 pax_SOURCES = ...
 mt_SOURCES = ...
 rmt_SOURCES = ...

   PROG_LDADD is inappropriate for passing program-specific linkerflags (except for -l, -L, -dlopen and -dlpreopen).  So, use thePROG_LDFLAGS variable for this purpose.
   It is also occasionally useful to have a program depend on some othertarget that is not actually part of that program.  This can be doneusing either the PROG_DEPENDENCIES or the EXTRA_PROG_DEPENDENCIESvariable.  Each program depends on the contents both variables, but nofurther interpretation is done.
   Since these dependencies are associated to the link rule used tocreate the programs they should normally list files used by the linkcommand.  That is *.$(OBJEXT), *.a, or *.la files.  In rare casesyou may need to add other kinds of files such as linker scripts, butlisting a source file in _DEPENDENCIES is wrong.  If some sourcefile needs to be built before all the components of a program are built,consider using the BUILT_SOURCES variable instead (*note Sources::).
   If PROG_DEPENDENCIES is not supplied, it is computed by Automake.The automatically-assigned value is the contents of PROG_LDADD, withmost configure substitutions, -l, -L, -dlopen and -dlpreopenoptions removed.  The configure substitutions that are left in are only$(LIBOBJS) and $(ALLOCA); these are left because it is known thatthey will not cause an invalid value for PROG_DEPENDENCIES to begenerated.
  The EXTRA_PROG_DEPENDENCIES may be useful for cases where youmerely want to augment the automake-generated PROG_DEPENDENCIESrather than replacing it.
   We recommend that you avoid using -l options in LDADD orPROG_LDADD when referring to libraries built by your package.Instead, write the file name of the library explicitly as in the abovecpio example.  Use -l only to list third-party libraries.  If youfollow this rule, the default value of PROG_DEPENDENCIES will list allyour local libraries and omit the other ones.
8.1.3 Conditional compilation of sources
You cant put a configure substitution (e.g., @FOO@or$(FOO)whereFOOis defined viaAC_SUBST) into a _SOURCES variable.  The reason for this is a bit hard to explain, but suffice to say that it simply wont work.  Automake will give an error if you try to do this.
   Fortunately there are two other ways to achieve the same result.  Oneis to use configure substitutions in _LDADD variables, the other is touse an Automake conditional.
Conditional Compilation using _LDADD Substitutions…………………………………………….
Automake must know all the source files that could possibly go into aprogram, even if not all the files are built in every circumstance.  Anyfiles that are only conditionally built should be listed in theappropriate EXTRA_ variable.  For instance, if hello-linux.c orhello-generic.c were conditionally included in hello, theMakefile.am would contain:
 bin_PROGRAMS = hello
 hello_SOURCES = hello-common.c
 EXTRA_hello_SOURCES = hello-linux.c hello-generic.c
 hello_LDADD = $(HELLO_SYSTEM)
 hello_DEPENDENCIES = $(HELLO_SYSTEM)

You can then setup the $(HELLO_SYSTEM) substitution fromconfigure.ac:
 ...
 case $host in
   *linux*) HELLO_SYSTEM='hello-linux.$(OBJEXT)' ;;
   *)       HELLO_SYSTEM='hello-generic.$(OBJEXT)' ;;
 esac
 AC_SUBST([HELLO_SYSTEM])
 ...

   In this case, the variable HELLO_SYSTEM should be replaced byeither hello-linux.o or hello-generic.o, and added to bothhello_DEPENDENCIES and hello_LDADD in order to be built and linkedin.
Conditional Compilation using Automake Conditionals……………………………………………
An often simpler way to compile source files conditionally is to useAutomake conditionals.  For instance, you could use this Makefile.amconstruct to build the same hello example:
 bin_PROGRAMS = hello
 if LINUX
 hello_SOURCES = hello-linux.c hello-common.c
 else
 hello_SOURCES = hello-generic.c hello-common.c
 endif

   In this case, configure.ac should setup the LINUX conditionalusing AM_CONDITIONAL (*note Conditionals::).
   When using conditionals like this you dont need to use the EXTRA_`variable, because Automake will examine the contents of each variable toconstruct the complete list of source files.
   If your program uses a lot of files, you will probably prefer aconditional +=.
 bin_PROGRAMS = hello
 hello_SOURCES = hello-common.c
 if LINUX
 hello_SOURCES += hello-linux.c
 else
 hello_SOURCES += hello-generic.c
 endif

8.1.4 Conditional compilation of programs
Sometimes it is useful to determine the programs that are to be built atconfigure time.  For instance, GNU cpio only builds mt and rmtunder special circumstances.  The means to achieve conditionalcompilation of programs are the same you can use to compile source filesconditionally: substitutions or conditionals.
Conditional Programs using configure Substitutions…………………………………………….
In this case, you must notify Automake of all the programs that canpossibly be built, but at the same time cause the generatedMakefile.in to use the programs specified by configure.  This isdone by having configure substitute values into each _PROGRAMSdefinition, while listing all optionally built programs inEXTRA_PROGRAMS.
 bin_PROGRAMS = cpio pax $(MT)
 libexec_PROGRAMS = $(RMT)
 EXTRA_PROGRAMS = mt rmt

   As explained in *note EXEEXT::, Automake will rewrite bin_PROGRAMS,libexec_PROGRAMS, and EXTRA_PROGRAMS, appending $(EXEEXT) to eachbinary.  Obviously it cannot rewrite values obtained at run-time throughconfigure substitutions, therefore you should take care of appending$(EXEEXT) yourself, as in AC_SUBST([MT], ['mt${EXEEXT}']).
Conditional Programs using Automake Conditionals…………………………………………
You can also use Automake conditionals (*note Conditionals::) to selectprograms to be built.  In this case you dont have to worry about $(EXEEXT)orEXTRA_PROGRAMS`.
 bin_PROGRAMS = cpio pax
 if WANT_MT
   bin_PROGRAMS += mt
 endif
 if WANT_RMT
   libexec_PROGRAMS = rmt
 endif

8.2 Building a library======================
Building a library is much like building a program.  In this case, thename of the primary is LIBRARIES.  Libraries can be installed inlibdir or pkglibdir.
   *Note A Shared Library::, for information on how to build sharedlibraries using libtool and the LTLIBRARIES primary.
   Each _LIBRARIES variable is a list of the libraries to be built.For instance, to create a library named libcpio.a, but not install it,you would write:
 noinst_LIBRARIES = libcpio.a
 libcpio_a_SOURCES = ...

   The sources that go into a library are determined exactly as they arefor programs, via the _SOURCES variables.  Note that the library nameis canonicalized (*note Canonicalization::), so the _SOURCES variablecorresponding to libcpio.a is libcpio_a_SOURCES, notlibcpio.a_SOURCES.
   Extra objects can be added to a library using the LIBRARY_LIBADDvariable.  This should be used for objects determined by configure.Again from cpio:
 libcpio_a_LIBADD = $(LIBOBJS) $(ALLOCA)

   In addition, sources for extra objects that will not exist untilconfigure-time must be added to the BUILT_SOURCES variable (*noteSources::).
   Building a static library is done by compiling all object files, thenby invoking $(AR) $(ARFLAGS) followed by the name of the library andthe list of objects, and finally by calling $(RANLIB) on that library.You should call AC_PROG_RANLIB from your configure.ac to defineRANLIB (Automake will complain otherwise).  You should also callAM_PROG_AR to define AR, in order to support unusual archivers suchas Microsoft lib.  ARFLAGS will default to cru; you can overridethis variable by setting it in your Makefile.am or by AC_SUBSTing itfrom your configure.ac.  You can override the AR variable bydefining a per-library maude_AR variable (*note Program and LibraryVariables::).
   Be careful when selecting library components conditionally.  Becausebuilding an empty library is not portable, you should ensure that anylibrary always contains at least one object.
   To use a static library when building a program, add it to LDADDfor this program.  In the following example, the program cpio isstatically linked with the library libcpio.a.
 noinst_LIBRARIES = libcpio.a
 libcpio_a_SOURCES = ...

 bin_PROGRAMS = cpio
 cpio_SOURCES = cpio.c ...
 cpio_LDADD = libcpio.a

8.3 Building a Shared Library=============================
Building shared libraries portably is a relatively complex matter.  Forthis reason, GNU Libtool (*note Introduction: (libtool)Top.) was createdto help build shared libraries in a platform-independent way.
8.3.1 The Libtool Concept
Libtool abstracts shared and static libraries into a unified concepthenceforth called “libtool libraries”.  Libtool libraries are filesusing the .la suffix, and can designate a static library, a sharedlibrary, or maybe both.  Their exact nature cannot be determined until./configure is run: not all platforms support all kinds of libraries,and users can explicitly select which libraries should be built.(However the packages maintainers can tune the default, *note The AC_PROG_LIBTOOL` macro: (libtool)AC_PROG_LIBTOOL.)
   Because object files for shared and static libraries must be compileddifferently, libtool is also used during compilation.  Object filesbuilt by libtool are called “libtool objects”: these are files using the.lo suffix.  Libtool libraries are built from these libtool objects.
   You should not assume anything about the structure of .la or .lofiles and how libtool constructs them: this is libtools concern, and the last thing one wants is to learn about libtools guts.  However theexistence of these files matters, because they are used as targets anddependencies in Makefiles rules when building libtool libraries.There are situations where you may have to refer to these, for instancewhen expressing dependencies for building source files conditionally(*note Conditional Libtool Sources::).
   People considering writing a plug-in system, with dynamically loadedmodules, should look into libltdl: libtool`s dlopening library (*noteUsing libltdl: (libtool)Using libltdl.).  This offers a portabledlopening facility to load libtool libraries dynamically, and can alsoachieve static linking where unavoidable.
   Before we discuss how to use libtool with Automake in details, itshould be noted that the libtool manual also has a section about how touse Automake with libtool (*note Using Automake with Libtool:(libtool)Using Automake.).
8.3.2 Building Libtool Libraries
Automake uses libtool to build libraries declared with the LTLIBRARIESprimary.  Each _LTLIBRARIES variable is a list of libtool libraries tobuild.  For instance, to create a libtool library named libgettext.la,and install it in libdir, write:
 lib_LTLIBRARIES = libgettext.la
 libgettext_la_SOURCES = gettext.c gettext.h ...

   Automake predefines the variable pkglibdir, so you can usepkglib_LTLIBRARIES to install libraries in $(libdir)/@PACKAGE@/.
   If gettext.h is a public header file that needs to be installed inorder for people to use the library, it should be declared using a_HEADERS variable, not in libgettext_la_SOURCES.  Headers listed inthe latter should be internal headers that are not part of the publicinterface.
 lib_LTLIBRARIES = libgettext.la
 libgettext_la_SOURCES = gettext.c ...
 include_HEADERS = gettext.h ...

   A package can build and install such a library along with otherprograms that use it.  This dependency should be specified usingLDADD.  The following example builds a program named hello that islinked with libgettext.la.
 lib_LTLIBRARIES = libgettext.la
 libgettext_la_SOURCES = gettext.c ...

 bin_PROGRAMS = hello
 hello_SOURCES = hello.c ...
 hello_LDADD = libgettext.la

Whether hello is statically or dynamically linked with libgettext.lais not yet known: this will depend on the configuration of libtool andthe capabilities of the host.
8.3.3 Building Libtool Libraries Conditionally
Like conditional programs (*note Conditional Programs::), there are twomain ways to build conditional libraries: using Automake conditionals orusing Autoconf AC_SUBSTitutions.
   The important implementation detail you have to be aware of is thatthe place where a library will be installed matters to libtool: it needsto be indicated at link-time using the -rpath option.
   For libraries whose destination directory is known when Automakeruns, Automake will automatically supply the appropriate -rpath optionto libtool.  This is the case for libraries listed explicitly in someinstallable _LTLIBRARIES variables such as lib_LTLIBRARIES.
   However, for libraries determined at configure time (and thusmentioned in EXTRA_LTLIBRARIES), Automake does not know the finalinstallation directory.  For such libraries you must add the -rpathoption to the appropriate _LDFLAGS variable by hand.
   The examples below illustrate the differences between these twomethods.
   Here is an example where WANTEDLIBS is an AC_SUBSTed variable setat ./configure-time to either libfoo.la, libbar.la, both, or none.Although $(WANTEDLIBS) appears in the lib_LTLIBRARIES, Automakecannot guess it relates to libfoo.la or libbar.la at the time itcreates the link rule for these two libraries.  Therefore the -rpathargument must be explicitly supplied.
 EXTRA_LTLIBRARIES = libfoo.la libbar.la
 lib_LTLIBRARIES = $(WANTEDLIBS)
 libfoo_la_SOURCES = foo.c ...
 libfoo_la_LDFLAGS = -rpath '$(libdir)'
 libbar_la_SOURCES = bar.c ...
 libbar_la_LDFLAGS = -rpath '$(libdir)'

   Here is how the same Makefile.am would look using Automakeconditionals named WANT_LIBFOO and WANT_LIBBAR.  Now Automake isable to compute the -rpath setting itself, because its clear that both libraries will end up in $(libdir)` if they are installed.
 lib_LTLIBRARIES =
 if WANT_LIBFOO
 lib_LTLIBRARIES += libfoo.la
 endif
 if WANT_LIBBAR
 lib_LTLIBRARIES += libbar.la
 endif
 libfoo_la_SOURCES = foo.c ...
 libbar_la_SOURCES = bar.c ...

8.3.4 Libtool Libraries with Conditional Sources
Conditional compilation of sources in a library can be achieved in thesame way as conditional compilation of sources in a program (*noteConditional Sources::).  The only difference is that _LIBADD should beused instead of _LDADD and that it should mention libtool objects(.lo files).
   So, to mimic the hello example from *note Conditional Sources::, wecould build a libhello.la library using either hello-linux.c orhello-generic.c with the following Makefile.am.
 lib_LTLIBRARIES = libhello.la
 libhello_la_SOURCES = hello-common.c
 EXTRA_libhello_la_SOURCES = hello-linux.c hello-generic.c
 libhello_la_LIBADD = $(HELLO_SYSTEM)
 libhello_la_DEPENDENCIES = $(HELLO_SYSTEM)

And make sure configure defines HELLO_SYSTEM as eitherhello-linux.lo or hello-generic.lo.
   Or we could simply use an Automake conditional as follows.
 lib_LTLIBRARIES = libhello.la
 libhello_la_SOURCES = hello-common.c
 if LINUX
 libhello_la_SOURCES += hello-linux.c
 else
 libhello_la_SOURCES += hello-generic.c
 endif

8.3.5 Libtool Convenience LibrariesSometimes you want to build libtool libraries that should not beinstalled.  These are called “libtool convenience libraries” and aretypically used to encapsulate many sublibraries, later gathered into onebig installed library.
   Libtool convenience libraries are declared by directory-lessvariables such as noinst_LTLIBRARIES, check_LTLIBRARIES, or evenEXTRA_LTLIBRARIES.  Unlike installed libtool libraries they do notneed an -rpath flag at link time (actually this is the onlydifference).
   Convenience libraries listed in noinst_LTLIBRARIES are alwaysbuilt.  Those listed in check_LTLIBRARIES are built only upon make check.  Finally, libraries listed in EXTRA_LTLIBRARIES are neverbuilt explicitly: Automake outputs rules to build them, but if thelibrary does not appear as a Makefile dependency anywhere it wont be built (this is why EXTRA_LTLIBRARIES` is used for conditionalcompilation).
   Here is a sample setup merging libtool convenience libraries fromsubdirectories into one main libtop.la library.
 # -- Top-level Makefile.am --
 SUBDIRS = sub1 sub2 ...
 lib_LTLIBRARIES = libtop.la
 libtop_la_SOURCES =
 libtop_la_LIBADD = \
   sub1/libsub1.la \
   sub2/libsub2.la \
   ...

 # -- sub1/Makefile.am --
 noinst_LTLIBRARIES = libsub1.la
 libsub1_la_SOURCES = ...

 # -- sub2/Makefile.am --
 # showing nested convenience libraries
 SUBDIRS = sub2.1 sub2.2 ...
 noinst_LTLIBRARIES = libsub2.la
 libsub2_la_SOURCES =
 libsub2_la_LIBADD = \
   sub21/libsub21.la \
   sub22/libsub22.la \
   ...

   When using such setup, beware that automake will assume libtop.lais to be linked with the C linker.  This is because libtop_la_SOURCESis empty, so automake picks C as default language.  Iflibtop_la_SOURCES was not empty, automake would select the linker asexplained in *note How the Linker is Chosen::.
   If one of the sublibraries contains non-C source, it is importantthat the appropriate linker be chosen.  One way to achieve this is topretend that there is such a non-C file among the sources of thelibrary, thus forcing automake to select the appropriate linker.  Hereis the top-level Makefile of our example updated to force C++ linking.
 SUBDIRS = sub1 sub2 ...
 lib_LTLIBRARIES = libtop.la
 libtop_la_SOURCES =
 # Dummy C++ source to cause C++ linking.
 nodist_EXTRA_libtop_la_SOURCES = dummy.cxx
 libtop_la_LIBADD = \
   sub1/libsub1.la \
   sub2/libsub2.la \
   ...

   EXTRA_*_SOURCES variables are used to keep track of source filesthat might be compiled (this is mostly useful when doing conditionalcompilation using AC_SUBST, *note Conditional Libtool Sources::), andthe nodist_ prefix means the listed sources are not to be distributed(*note Program and Library Variables::).  In effect the file dummy.cxxdoes not need to exist in the source tree.  Of course if you have somereal source file to list in libtop_la_SOURCES there is no point incheating with nodist_EXTRA_libtop_la_SOURCES.
8.3.6 Libtool Modules
These are libtool libraries meant to be dlopened.  They are indicated tolibtool by passing -module at link-time.
 pkglib_LTLIBRARIES = mymodule.la
 mymodule_la_SOURCES = doit.c
 mymodule_la_LDFLAGS = -module

   Ordinarily, Automake requires that a librarys name start with lib. However, when building a dynamically loadable module you might wish to use a "nonstandard" name.  Automake will not complain about such nonstandard names if it knows the library being built is a libtool module, i.e., if -module explicitly appears in the librarys_LDFLAGS variable (or in the common AM_LDFLAGS variable when noper-library _LDFLAGS variable is defined).
   As always, AC_SUBST variables are black boxes to Automake sincetheir values are not yet known when automake is run.  Therefore if-module is set via such a variable, Automake cannot notice it and willproceed as if the library was an ordinary libtool library, with strictnaming.
   If mymodule_la_SOURCES is not specified, then it defaults to thesingle file mymodule.c (*note Default _SOURCES::).
8.3.7 _LIBADD, _LDFLAGS, and _LIBTOOLFLAGS
As shown in previous sections, the LIBRARY_LIBADD variable should beused to list extra libtool objects (.lo files) or libtool libraries(.la) to add to LIBRARY.
   The LIBRARY_LDFLAGS variable is the place to list additionallibtool linking flags, such as -version-info, -static, and a lotmore.  *Note Link mode: (libtool)Link mode.
   The libtool command has two kinds of options: mode-specific optionsand generic options.  Mode-specific options such as the aforementionedlinking flags should be lumped with the other flags passed to the toolinvoked by libtool (hence the use of LIBRARY_LDFLAGS for libtoollinking flags).  Generic options include --tag=TAG and --silent(*note Invoking libtool: (libtool)Invoking libtool. for more options)should appear before the mode selection on the command line; inMakefile.ams they should be listed in the LIBRARY_LIBTOOLFLAGSvariable.
   If LIBRARY_LIBTOOLFLAGS is not defined, then the variableAM_LIBTOOLFLAGS is used instead.
   These flags are passed to libtool after the --tag=TAG optioncomputed by Automake (if any), so LIBRARY_LIBTOOLFLAGS (orAM_LIBTOOLFLAGS) is a good place to override or supplement the--tag=TAG setting.
   The libtool rules also use a LIBTOOLFLAGS variable that should notbe set in Makefile.am: this is a user variable (*note Flag VariablesOrdering::.  It allows users to run make LIBTOOLFLAGS=--silent, forinstance.  Note that the verbosity of libtool can also be influencedby the Automake support for silent rules (*note Automake SilentRules::).
8.3.8 LTLIBOBJS and LTALLOCAWhere an ordinary library might include $(LIBOBJS) or $(ALLOCA)(*note LIBOBJS::), a libtool library must use $(LTLIBOBJS) or$(LTALLOCA).  This is required because the object files that libtooloperates on do not necessarily end in .o.
   Nowadays, the computation of LTLIBOBJS from LIBOBJS is performedautomatically by Autoconf (*note AC_LIBOBJ vs. LIBOBJS:(autoconf)AC_LIBOBJ vs LIBOBJS.).
8.3.9 Common Issues Related to Libtool`s Use8.3.9.1 Error: required file ./ltmain.sh’ not found`………………………………………………
Libtool comes with a tool called libtoolize that will installlibtools supporting files into a package.  Running this command will install ltmain.sh.  You should execute it before aclocalandautomake`.
   People upgrading old packages to newer autotools are likely to facethis issue because older Automake versions used to call libtoolize.Therefore old build scripts do not call libtoolize.
   Since Automake 1.6, it has been decided that running libtoolize wasnone of Automakes business.  Instead, that functionality has been moved into the autoreconfcommand (*note Usingautoreconf: (autoconf)autoreconf Invocation.).  If you do not want to remember what to run and when, just learn the autoreconfcommand.  Hopefully, replacing existingbootstraporautogen.shscripts by a call toautoreconf` should also free you from any similar incompatible changein the future.
8.3.9.2 Objects created with both libtool and without……………………………………………….
Sometimes, the same source file is used both to build a libtool libraryand to build another non-libtool target (be it a program or anotherlibrary).
   Lets consider the following Makefile.am`.
 bin_PROGRAMS = prog
 prog_SOURCES = prog.c foo.c ...

 lib_LTLIBRARIES = libfoo.la
 libfoo_la_SOURCES = foo.c ...

(In this trivial case the issue could be avoided by linking libfoo.lawith prog instead of listing foo.c in prog_SOURCES.  But lets assume we really want to keep progandlibfoo.la` separate.)
   Technically, it means that we should build foo.$(OBJEXT) forprog, and foo.lo for libfoo.la.  The problem is that in the courseof creating foo.lo, libtool may erase (or replace) foo.$(OBJEXT),and this cannot be avoided.
   Therefore, when Automake detects this situation it will complain witha message such as​     object ‘foo.$(OBJEXT)’ created both with libtool and without
   A workaround for this issue is to ensure that these two objects getdifferent basenames.  As explained in *note Renamed Objects::, thishappens automatically when per-targets flags are used.
 bin_PROGRAMS = prog
 prog_SOURCES = prog.c foo.c ...
 prog_CFLAGS = $(AM_CFLAGS)

 lib_LTLIBRARIES = libfoo.la
 libfoo_la_SOURCES = foo.c ...

Adding prog_CFLAGS = $(AM_CFLAGS) is almost a no-op, because when theprog_CFLAGS is defined, it is used instead of AM_CFLAGS.  However asa side effect it will cause prog.c and foo.c to be compiled asprog-prog.$(OBJEXT) and prog-foo.$(OBJEXT), which solves the issue.
8.4 Program and Library VariablesAssociated with each program is a collection of variables that can beused to modify how that program is built.  There is a similar list ofsuch variables for each library.  The canonical name of the program (orlibrary) is used as a base for naming these variables.
   In the list below, we use the name “maude” to refer to the program orlibrary.  In your Makefile.am you would replace this with thecanonical name of your program.  This list also refers to “maude” as aprogram, but in general the same rules apply for both static and dynamiclibraries; the documentation below notes situations where programs andlibraries differ.
maude_SOURCES​     This variable, if it exists, lists all the source files that are​     compiled to build the program.  These files are added to the​     distribution by default.  When building the program, Automake will​     cause each source file to be compiled to a single .o file (or​     .lo when using libtool).  Normally these object files are named​     after the source file, but other factors can change this.  If a​     file in the _SOURCES variable has an unrecognized extension,​     Automake will do one of two things with it.  If a suffix rule​     exists for turning files with the unrecognized extension into .o​     files, then automake will treat this file as it will any other​     source file (*note Support for Other Languages::).  Otherwise, the​     file will be ignored as though it were a header file.
 The prefixes `dist_` and `nodist_` can be used to control whether
 files listed in a `_SOURCES` variable are distributed.  `dist_` is
 redundant, as sources are distributed by default, but it can be
 specified for clarity if desired.

 It is possible to have both `dist_` and `nodist_` variants of a
 given `_SOURCES` variable at once; this lets you easily distribute
 some files and not others, for instance:

      nodist_maude_SOURCES = nodist.c
      dist_maude_SOURCES = dist-me.c

 By default the output file (on Unix systems, the `.o` file) will be
 put into the current build directory.  However, if the option
 `subdir-objects` is in effect in the current directory then the
 `.o` file will be put into the subdirectory named after the source
 file.  For instance, with `subdir-objects` enabled,
 `sub/dir/file.c` will be compiled to `sub/dir/file.o`.  Some people
 prefer this mode of operation.  You can specify `subdir-objects` in
 `AUTOMAKE_OPTIONS` (*note Options::).

EXTRA_maude_SOURCES​     Automake needs to know the list of files you intend to compile​     statically.  For one thing, this is the only way Automake has of​     knowing what sort of language support a given Makefile.in​     requires.  (1) This means that, for example, you cant put a ​     configure substitution like @my_sources@into a_SOURCES​     variable.  If you intend to conditionally compile source files and ​     useconfigureto substitute the appropriate object names into, ​     e.g.,LDADD(see below), then you should list the corresponding ​     source files in theEXTRA` variable.
 This variable also supports `dist_` and `nodist_` prefixes.  For
 instance, `nodist_EXTRA_maude_SOURCES` would list extra sources
 that may need to be built, but should not be distributed.

maude_AR​     A static library is created by default by invoking $(AR) ​     $(ARFLAGS) followed by the name of the library and then the​     objects being put into the library.  You can override this by​     setting the _AR variable.  This is usually used with C++; some​     C++ compilers require a special invocation in order to instantiate​     all the templates that should go into a library.  For instance, the​     SGI C++ compiler likes this variable set like so:​          libmaude_a_AR = $(CXX) -ar -o
maude_LIBADD​     Extra objects can be added to a library using the _LIBADD​     variable.  For instance, this should be used for objects determined​     by configure (*note A Library::).
 In the case of libtool libraries, `maude_LIBADD` can also refer to
 other libtool libraries.

maude_LDADD​     Extra objects (*.$(OBJEXT)) and libraries (*.a, *.la) can be​     added to a program by listing them in the _LDADD variable.  For​     instance, this should be used for objects determined by configure​     (*note Linking::).
 `_LDADD` and `_LIBADD` are inappropriate for passing
 program-specific linker flags (except for `-l`, `-L`, `-dlopen` and
 `-dlpreopen`).  Use the `_LDFLAGS` variable for this purpose.

 For instance, if your `configure.ac` uses `AC_PATH_XTRA`, you could
 link your program against the X libraries like so:

      maude_LDADD = $(X_PRE_LIBS) $(X_LIBS) $(X_EXTRA_LIBS)

 We recommend that you use `-l` and `-L` only when referring to
 third-party libraries, and give the explicit file names of any
 library built by your package.  Doing so will ensure that
 `maude_DEPENDENCIES` (see below) is correctly defined by default.

maude_LDFLAGS​     This variable is used to pass extra flags to the link step of a​     program or a shared library.  It overrides the AM_LDFLAGS​     variable.
maude_LIBTOOLFLAGS​     This variable is used to pass extra options to libtool.  It​     overrides the AM_LIBTOOLFLAGS variable.  These options are output​     before libtool``s –mode=MODE` option, so they should not be​     mode-specific options (those belong to the compiler or linker​     flags).  *Note Libtool Flags::.
maude_DEPENDENCIESEXTRA_maude_DEPENDENCIES​     It is also occasionally useful to have a target (program or​     library) depend on some other file that is not actually part of​     that target.  This can be done using the _DEPENDENCIES variable.​     Each target depends on the contents of such a variable, but no​     further interpretation is done.
 Since these dependencies are associated to the link rule used to
 create the programs they should normally list files used by the
 link command.  That is `*.$(OBJEXT)`, `*.a`, or `*.la` files for
 programs; `*.lo` and `*.la` files for Libtool libraries; and
 `*.$(OBJEXT)` files for static libraries.  In rare cases you may
 need to add other kinds of files such as linker scripts, but
 _listing a source file in `_DEPENDENCIES` is wrong_.  If some
 source file needs to be built before all the components of a
 program are built, consider using the `BUILT_SOURCES` variable
 (*note Sources::).

 If `_DEPENDENCIES` is not supplied, it is computed by Automake.
 The automatically-assigned value is the contents of `_LDADD` or
 `_LIBADD`, with most configure substitutions, `-l`, `-L`, `-dlopen`
 and `-dlpreopen` options removed.  The configure substitutions that
 are left in are only `$(LIBOBJS)` and `$(ALLOCA)`; these are left
 because it is known that they will not cause an invalid value for
 `_DEPENDENCIES` to be generated.

 `_DEPENDENCIES` is more likely used to perform conditional
 compilation using an `AC_SUBST` variable that contains a list of
 objects.  *Note Conditional Sources::, and *note Conditional
 Libtool Sources::.

 The `EXTRA_*_DEPENDENCIES` variable may be useful for cases where
 you merely want to augment the `automake`-generated `_DEPENDENCIES`
 variable rather than replacing it.

maude_LINK​     You can override the linker on a per-program basis.  By default the​     linker is chosen according to the languages used by the program.​     For instance, a program that includes C++ source code would use the​     C++ compiler to link.  The _LINK variable must hold the name of a​     command that can be passed all the .o file names and libraries to​     link against as arguments.  Note that the name of the underlying​     program is not passed to _LINK; typically one uses $@:
      maude_LINK = $(CCLD) -magic -o $@

 If a `_LINK` variable is not supplied, it may still be generated
 and used by Automake due to the use of per-target link flags such
 as `_CFLAGS`, `_LDFLAGS` or `_LIBTOOLFLAGS`, in cases where they
 apply.

maude_CCASFLAGSmaude_CFLAGSmaude_CPPFLAGSmaude_CXXFLAGSmaude_FFLAGSmaude_GCJFLAGSmaude_LFLAGSmaude_OBJCFLAGSmaude_OBJCXXFLAGSmaude_RFLAGSmaude_UPCFLAGSmaude_YFLAGS​     Automake allows you to set compilation flags on a per-program (or​     per-library) basis.  A single source file can be included in​     several programs, and it will potentially be compiled with​     different flags for each program.  This works for any language​     directly supported by Automake.  These “per-target compilation​     flags” are _CCASFLAGS, _CFLAGS, _CPPFLAGS, _CXXFLAGS,​     _FFLAGS, _GCJFLAGS, _LFLAGS, _OBJCFLAGS, _OBJCXXFLAGS,​     _RFLAGS, _UPCFLAGS, and _YFLAGS.
 When using a per-target compilation flag, Automake will choose a
 different name for the intermediate object files.  Ordinarily a
 file like `sample.c` will be compiled to produce `sample.o`.
 However, if the program`s `_CFLAGS` variable is set, then the
 object file will be named, for instance, `maude-sample.o`.  (See
 also *note Renamed Objects::).

 In compilations with per-target flags, the ordinary `AM_` form of
 the flags variable is _not_ automatically included in the
 compilation (however, the user form of the variable _is_ included).
 So for instance, if you want the hypothetical `maude` compilations
 to also use the value of `AM_CFLAGS`, you would need to write:

      maude_CFLAGS = ... your flags ... $(AM_CFLAGS)

 *Note Flag Variables Ordering::, for more discussion about the
 interaction between user variables, `AM_` shadow variables, and
 per-target variables.

maude_SHORTNAME​     On some platforms the allowable file names are very short.  In​     order to support these systems and per-target compilation flags at​     the same time, Automake allows you to set a “short name” that will​     influence how intermediate object files are named.  For instance,​     in the following example,
      bin_PROGRAMS = maude
      maude_CPPFLAGS = -DSOMEFLAG
      maude_SHORTNAME = m
      maude_SOURCES = sample.c ...

 the object file would be named `m-sample.o` rather than
 `maude-sample.o`.

 This facility is rarely needed in practice, and we recommend
 avoiding it until you find it is required.

   (1) There are other, more obscure reasons for this limitation aswell.
8.5 Default _SOURCES_SOURCES variables are used to specify source files of programs (*noteA Program::), libraries (*note A Library::), and Libtool libraries(*note A Shared Library::).
   When no such variable is specified for a target, Automake will defineone itself.  The default is to compile a single C file whose base nameis the name of the target itself, with any extension replaced byAM_DEFAULT_SOURCE_EXT, which defaults to .c.
   For example if you have the following somewhere in your Makefile.amwith no corresponding libfoo_a_SOURCES:
 lib_LIBRARIES = libfoo.a sub/libc++.a

libfoo.a will be built using a default source file named libfoo.c,and sub/libc++.a will be built from sub/libc++.c.  (In olderversions sub/libc++.a would be built from sub_libc___a.c, i.e., thedefault source was the canonized name of the target, with .c appended.We believe the new behavior is more sensible, but for backwardcompatibility automake will use the old name if a file or a rule withthat name exists and AM_DEFAULT_SOURCE_EXT is not used.)
   Default sources are mainly useful in test suites, when building manytest programs each from a single source.  For instance, in
 check_PROGRAMS = test1 test2 test3
 AM_DEFAULT_SOURCE_EXT = .cpp

test1, test2, and test3 will be built from test1.cpp,test2.cpp, and test3.cpp.  Without the last line, they will be builtfrom test1.c, test2.c, and test3.c.
   Another case where this is convenient is building many Libtoolmodules (moduleN.la), each defined in its own file (moduleN.c).
 AM_LDFLAGS = -module
 lib_LTLIBRARIES = module1.la module2.la module3.la

   Finally, there is one situation where this default source computationneeds to be avoided: when a target should not be built from sources.  Wealready saw such an example in *note true::; this happens when all theconstituents of a target have already been compiled and just need to becombined using a _LDADD variable.  Then it is necessary to define anempty _SOURCES variable, so that automake does not compute adefault.
 bin_PROGRAMS = target
 target_SOURCES =
 target_LDADD = libmain.a libmisc.a

8.6 Special handling for LIBOBJS and ALLOCAThe $(LIBOBJS) and $(ALLOCA) variables list object files that shouldbe compiled into the project to provide an implementation for functionsthat are missing or broken on the host system.  They are substituted byconfigure.
   These variables are defined by Autoconf macros such as AC_LIBOBJ,AC_REPLACE_FUNCS (*note Generic Function Checks: (autoconf)GenericFunctions.), or AC_FUNC_ALLOCA (*note Particular Function Checks:(autoconf)Particular Functions.).  Many other Autoconf macros callAC_LIBOBJ or AC_REPLACE_FUNCS to populate $(LIBOBJS).
   Using these variables is very similar to doing conditionalcompilation using AC_SUBST variables, as described in *noteConditional Sources::.  That is, when building a program, $(LIBOBJS)and $(ALLOCA) should be added to the associated *_LDADD variable, orto the *_LIBADD variable when building a library.  However there is noneed to list the corresponding sources in EXTRA_*_SOURCES nor todefine *_DEPENDENCIES.  Automake automatically adds $(LIBOBJS) and$(ALLOCA) to the dependencies, and it will discover the list ofcorresponding source files automatically (by tracing the invocations ofthe AC_LIBSOURCE Autoconf macros).  If you have already defined*_DEPENDENCIES explicitly for an unrelated reason, then you eitherneed to add these variables manually, or use EXTRA_*_DEPENDENCIESinstead of *_DEPENDENCIES.
   These variables are usually used to build a portability library thatis linked with all the programs of the project.  We now review a samplesetup.  First, configure.ac contains some checks that affect eitherLIBOBJS or ALLOCA.
 # configure.ac
 ...
 AC_CONFIG_LIBOBJ_DIR([lib])
 ...
 AC_FUNC_MALLOC             dnl May add malloc.$(OBJEXT) to LIBOBJS
 AC_FUNC_MEMCMP             dnl May add memcmp.$(OBJEXT) to LIBOBJS
 AC_REPLACE_FUNCS([strdup]) dnl May add strdup.$(OBJEXT) to LIBOBJS
 AC_FUNC_ALLOCA             dnl May add alloca.$(OBJEXT) to ALLOCA
 ...
 AC_CONFIG_FILES([
   lib/Makefile
   src/Makefile
 ])
 AC_OUTPUT

   The AC_CONFIG_LIBOBJ_DIR tells Autoconf that the source files ofthese object files are to be found in the lib/ directory.  Automakecan also use this information, otherwise it expects the source files areto be in the directory where the $(LIBOBJS) and $(ALLOCA) variablesare used.
   The lib/ directory should therefore contain malloc.c, memcmp.c,strdup.c, alloca.c.  Here is its Makefile.am:
 # lib/Makefile.am

 noinst_LIBRARIES = libcompat.a
 libcompat_a_SOURCES =
 libcompat_a_LIBADD = $(LIBOBJS) $(ALLOCA)

   The library can have any name, of course, and anyway it is not goingto be installed: it just holds the replacement versions of the missingor broken functions so we can later link them in.  Many projects alsoinclude extra functions, specific to the project, in that library: theyare simply added on the _SOURCES line.
   There is a small trap here, though: $(LIBOBJS) and $(ALLOCA)might be empty, and building an empty library is not portable.  Youshould ensure that there is always something to put in libcompat.a.Most projects will also add some utility functions in that directory,and list them in libcompat_a_SOURCES, so in practice libcompat.acannot be empty.
   Finally here is how this library could be used from the src/directory.
 # src/Makefile.am

 # Link all programs in this directory with libcompat.a
 LDADD = ../lib/libcompat.a

 bin_PROGRAMS = tool1 tool2 ...
 tool1_SOURCES = ...
 tool2_SOURCES = ...

   When option subdir-objects is not used, as in the above example,the variables $(LIBOBJS) or $(ALLOCA) can only be used in thedirectory where their sources lie.  E.g., here it would be wrong to use$(LIBOBJS) or $(ALLOCA) in src/Makefile.am.  However if bothsubdir-objects and AC_CONFIG_LIBOBJ_DIR are used, it is OK to usethese variables in other directories.  For instance src/Makefile.amcould be changed as follows.
 # src/Makefile.am

 AUTOMAKE_OPTIONS = subdir-objects
 LDADD = $(LIBOBJS) $(ALLOCA)

 bin_PROGRAMS = tool1 tool2 ...
 tool1_SOURCES = ...
 tool2_SOURCES = ...

   Because $(LIBOBJS) and $(ALLOCA) contain object file names thatend with .$(OBJEXT), they are not suitable for Libtool libraries(where the expected object extension is .lo): LTLIBOBJS andLTALLOCA should be used instead.
   LTLIBOBJS is defined automatically by Autoconf and should not bedefined by hand (as in the past), however at the time of writingLTALLOCA still needs to be defined from ALLOCA manually.  *NoteAC_LIBOBJ vs. LIBOBJS: (autoconf)AC_LIBOBJ vs LIBOBJS.
8.7 Variables used when building a programOccasionally it is useful to know which Makefile variables Automakeuses for compilations, and in which order (*note Flag VariablesOrdering::); for instance, you might need to do your own compilation insome special cases.
   Some variables are inherited from Autoconf; these are CC, CFLAGS,CPPFLAGS, DEFS, LDFLAGS, and LIBS.
   There are some additional variables that Automake defines on its own:
AM_CPPFLAGS​     The contents of this variable are passed to every compilation that​     invokes the C preprocessor; it is a list of arguments to the​     preprocessor.  For instance, -I and -D options should be listed​     here.
 Automake already provides some `-I` options automatically, in a
 separate variable that is also passed to every compilation that
 invokes the C preprocessor.  In particular it generates `-I.`,
 `-I$(srcdir)`, and a `-I` pointing to the directory holding
 `config.h` (if you`ve used `AC_CONFIG_HEADERS`).  You can disable
 the default `-I` options using the `nostdinc` option.

 When a file to be included is generated during the build and not
 part of a distribution tarball, its location is under
 `$(builddir)`, not under `$(srcdir)`.  This matters especially for
 packages that use header files placed in sub-directories and want
 to allow builds outside the source tree (*note VPATH Builds::).  In
 that case we recommend to use a pair of `-I` options, such as,
 e.g., `-Isome/subdir -I$(srcdir)/some/subdir` or
 `-I$(top_builddir)/some/subdir -I$(top_srcdir)/some/subdir`.  Note
 that the reference to the build tree should come before the
 reference to the source tree, so that accidentally leftover
 generated files in the source directory are ignored.

 `AM_CPPFLAGS` is ignored in preference to a per-executable (or
 per-library) `_CPPFLAGS` variable if it is defined.

INCLUDES​     This does the same job as AM_CPPFLAGS (or any per-target​     _CPPFLAGS variable if it is used).  It is an older name for the​     same functionality.  This variable is deprecated; we suggest using​     AM_CPPFLAGS and per-target _CPPFLAGS instead.
AM_CFLAGS​     This is the variable the Makefile.am author can use to pass in​     additional C compiler flags.  In some situations, this is not used,​     in preference to the per-executable (or per-library) _CFLAGS.
COMPILE​     This is the command used to actually compile a C source file.  The​     file name is appended to form the complete command line.
AM_LDFLAGS​     This is the variable the Makefile.am author can use to pass in​     additional linker flags.  In some situations, this is not used, in​     preference to the per-executable (or per-library) _LDFLAGS.
LINK​     This is the command used to actually link a C program.  It already​     includes -o $@ and the usual variable references (for instance,​     CFLAGS); it takes as “arguments” the names of the object files​     and libraries to link in.  This variable is not used when the​     linker is overridden with a per-target _LINK variable or​     per-target flags cause Automake to define such a _LINK variable.
8.8 Yacc and Lex supportAutomake has somewhat idiosyncratic support for Yacc and Lex.
   Automake assumes that the .c file generated by yacc (or lex)should be named using the basename of the input file.  That is, for ayacc source file foo.y, Automake will cause the intermediate file tobe named foo.c (as opposed to y.tab.c, which is more traditional).
   The extension of a yacc source file is used to determine theextension of the resulting C or C++ source and header files.  Note thatheader files are generated only when the -d Yacc option is used; seebelow for more information about this flag, and how to specify it.Files with the extension .y will thus be turned into .c sources and.h headers; likewise, .yy will become .cc and .hh, .y++ willbecome c++ and h++, .yxx will become .cxx and .hxx, and .yppwill become .cpp and .hpp.
   Similarly, lex source files can be used to generate C or C++; theextensions .l, .ll, .l++, .lxx, and .lpp are recognized.
   You should never explicitly mention the intermediate (C or C++) filein any SOURCES variable; only list the source file.
   The intermediate files generated by yacc (or lex) will beincluded in any distribution that is made.  That way the user doesnt need to have yaccorlex`.
   If a yacc source file is seen, then your configure.ac must definethe variable YACC.  This is most easily done by invoking the macroAC_PROG_YACC (*note Particular Program Checks: (autoconf)ParticularPrograms.).
   When yacc is invoked, it is passed AM_YFLAGS and YFLAGS.  Thelatter is a user variable and the former is intended for theMakefile.am author.
   AM_YFLAGS is usually used to pass the -d option to yacc.Automake knows what this means and will automatically adjust its rulesto update and distribute the header file built by yacc -d(1).  WhatAutomake cannot guess, though, is where this header will be used: it isup to you to ensure the header gets built before it is first used.Typically this is necessary in order for dependency tracking to workwhen the header is included by another file.  The common solution islisting the header file in BUILT_SOURCES (*note Sources::) as follows.
 BUILT_SOURCES = parser.h
 AM_YFLAGS = -d
 bin_PROGRAMS = foo
 foo_SOURCES = ... parser.y ...

   If a lex source file is seen, then your configure.ac must definethe variable LEX.  You can use AC_PROG_LEX to do this (*noteParticular Program Checks: (autoconf)Particular Programs.), but usingAM_PROG_LEX macro (*note Macros::) is recommended.
   When lex is invoked, it is passed AM_LFLAGS and LFLAGS.  Thelatter is a user variable and the former is intended for theMakefile.am author.
   When AM_MAINTAINER_MODE (*note maintainer-mode::) is used, therebuild rule for distributed Yacc and Lex sources are only used whenmaintainer-mode is enabled, or when the files have been erased.
   When lex or yacc sources are used, automake -a automaticallyinstalls an auxiliary program called ylwrap in your package (*noteAuxiliary Programs::).  This program is used by the build rules torename the output of these tools, and makes it possible to includemultiple yacc (or lex) source files in a single directory.  (This isnecessary because yaccs output file name is fixed, and a parallel make could conceivably invoke more than one instance of yacc`simultaneously.)
   For yacc, simply managing locking is insufficient.  The output ofyacc always uses the same symbol names internally, so it isnt possible to link two yacc` parsers into the same executable.
   We recommend using the following renaming hack used in gdb:​     #define yymaxdepth c_maxdepth​     #define yyparse c_parse​     #define yylex   c_lex​     #define yyerror c_error​     #define yylval  c_lval​     #define yychar  c_char​     #define yydebug c_debug​     #define yypact  c_pact​     #define yyr1    c_r1​     #define yyr2    c_r2​     #define yydef   c_def​     #define yychk   c_chk​     #define yypgo   c_pgo​     #define yyact   c_act​     #define yyexca  c_exca​     #define yyerrflag c_errflag​     #define yynerrs c_nerrs​     #define yyps    c_ps​     #define yypv    c_pv​     #define yys     c_s​     #define yy_yys  c_yys​     #define yystate c_state​     #define yytmp   c_tmp​     #define yyv     c_v​     #define yy_yyv  c_yyv​     #define yyval   c_val​     #define yylloc  c_lloc​     #define yyreds  c_reds​     #define yytoks  c_toks​     #define yylhs   c_yylhs​     #define yylen   c_yylen​     #define yydefred c_yydefred​     #define yydgoto  c_yydgoto​     #define yysindex c_yysindex​     #define yyrindex c_yyrindex​     #define yygindex c_yygindex​     #define yytable  c_yytable​     #define yycheck  c_yycheck​     #define yyname   c_yyname​     #define yyrule   c_yyrule
   For each define, replace the c_ prefix with whatever you like.These defines work for bison, byacc, and traditional yaccs.  Ifyou find a parser generator that uses a symbol not covered here, pleasereport the new name so it can be added to the list.
   (1) Please note that automake recognizes -d in AM_YFLAGS onlyif it is not clustered with other options; for example, it wont be recognized if AM_YFLAGSis-dt, but it will be if AM_YFLAGSis-d-tor-t -d`.
8.9 C++ SupportAutomake includes full support for C++.
   Any package including C++ code must define the output variable CXXin configure.ac; the simplest way to do this is to use theAC_PROG_CXX macro (*note Particular Program Checks:(autoconf)Particular Programs.).
   A few additional variables are defined when a C++ source file isseen:
CXX​     The name of the C++ compiler.
CXXFLAGS​     Any flags to pass to the C++ compiler.
AM_CXXFLAGS​     The maintainers variant of CXXFLAGS`.
CXXCOMPILE​     The command used to actually compile a C++ source file.  The file​     name is appended to form the complete command line.
CXXLINK​     The command used to actually link a C++ program.
8.10 Objective C SupportAutomake includes some support for Objective C.
   Any package including Objective C code must define the outputvariable OBJC in configure.ac; the simplest way to do this is to usethe AC_PROG_OBJC macro (*note Particular Program Checks:(autoconf)Particular Programs.).
   A few additional variables are defined when an Objective C sourcefile is seen:
OBJC​     The name of the Objective C compiler.
OBJCFLAGS​     Any flags to pass to the Objective C compiler.
AM_OBJCFLAGS​     The maintainers variant of OBJCFLAGS`.
OBJCCOMPILE​     The command used to actually compile an Objective C source file.​     The file name is appended to form the complete command line.
OBJCLINK​     The command used to actually link an Objective C program.
8.11 Objective C++ SupportAutomake includes some support for Objective C++.
   Any package including Objective C++ code must define the outputvariable OBJCXX in configure.ac; the simplest way to do this is touse the AC_PROG_OBJCXX macro (*note Particular Program Checks:(autoconf)Particular Programs.).
   A few additional variables are defined when an Objective C++ sourcefile is seen:
OBJCXX​     The name of the Objective C++ compiler.
OBJCXXFLAGS​     Any flags to pass to the Objective C++ compiler.
AM_OBJCXXFLAGS​     The maintainers variant of OBJCXXFLAGS`.
OBJCXXCOMPILE​     The command used to actually compile an Objective C++ source file.​     The file name is appended to form the complete command line.
OBJCXXLINK​     The command used to actually link an Objective C++ program.
8.12 Unified Parallel C SupportAutomake includes some support for Unified Parallel C.
   Any package including Unified Parallel C code must define the outputvariable UPC in configure.ac; the simplest way to do this is to usethe AM_PROG_UPC macro (*note Public Macros::).
   A few additional variables are defined when a Unified Parallel Csource file is seen:
UPC​     The name of the Unified Parallel C compiler.
UPCFLAGS​     Any flags to pass to the Unified Parallel C compiler.
AM_UPCFLAGS​     The maintainers variant of UPCFLAGS`.
UPCCOMPILE​     The command used to actually compile a Unified Parallel C source​     file.  The file name is appended to form the complete command line.
UPCLINK​     The command used to actually link a Unified Parallel C program.
8.13 Assembly SupportAutomake includes some support for assembly code.  There are two formsof assembler files: normal (*.s) and preprocessed by CPP (*.S or*.sx).
   The variable CCAS holds the name of the compiler used to buildassembly code.  This compiler must work a bit like a C compiler; inparticular it must accept -c and -o.  The values of CCASFLAGS andAM_CCASFLAGS (or its per-target definition) is passed to thecompilation.  For preprocessed files, DEFS, DEFAULT_INCLUDES,INCLUDES, CPPFLAGS and AM_CPPFLAGS are also used.
   The autoconf macro AM_PROG_AS will define CCAS and CCASFLAGSfor you (unless they are already set, it simply sets CCAS to the Ccompiler and CCASFLAGS to the C compiler flags), but you are free todefine these variables by other means.
   Only the suffixes .s, .S, and .sx are recognized by automakeas being files containing assembly code.
8.14 Fortran 77 SupportAutomake includes full support for Fortran 77.
   Any package including Fortran 77 code must define the output variableF77 in configure.ac; the simplest way to do this is to use theAC_PROG_F77 macro (*note Particular Program Checks:(autoconf)Particular Programs.).
   A few additional variables are defined when a Fortran 77 source fileis seen:
F77​     The name of the Fortran 77 compiler.
FFLAGS​     Any flags to pass to the Fortran 77 compiler.
AM_FFLAGS​     The maintainers variant of FFLAGS`.
RFLAGS​     Any flags to pass to the Ratfor compiler.
AM_RFLAGS​     The maintainers variant of RFLAGS`.
F77COMPILE​     The command used to actually compile a Fortran 77 source file.  The​     file name is appended to form the complete command line.
FLINK​     The command used to actually link a pure Fortran 77 program or​     shared library.
   Automake can handle preprocessing Fortran 77 and Ratfor source filesin addition to compiling them(1).  Automake also contains some supportfor creating programs and shared libraries that are a mixture of Fortran77 and other languages (*note Mixing Fortran 77 With C and C++::).
   These issues are covered in the following sections.
   (1) Much, if not most, of the information in the following sectionspertaining to preprocessing Fortran 77 programs was taken almostverbatim from *note Catalogue of Rules: (make)Catalogue of Rules.
8.14.1 Preprocessing Fortran 77N.f is made automatically from N.F or N.r.  This rule runs justthe preprocessor to convert a preprocessable Fortran 77 or Ratfor sourcefile into a strict Fortran 77 source file.  The precise command used isas follows:
.F​     $(F77) -F $(DEFS) $(INCLUDES) $(AM_CPPFLAGS) $(CPPFLAGS) ​     $(AM_FFLAGS) $(FFLAGS)
.r​     $(F77) -F $(AM_FFLAGS) $(FFLAGS) $(AM_RFLAGS) $(RFLAGS)
8.14.2 Compiling Fortran 77 FilesN.o is made automatically from N.f, N.F or N.r by running theFortran 77 compiler.  The precise command used is as follows:
.f​     $(F77) -c $(AM_FFLAGS) $(FFLAGS)
.F​     $(F77) -c $(DEFS) $(INCLUDES) $(AM_CPPFLAGS) $(CPPFLAGS) ​     $(AM_FFLAGS) $(FFLAGS)
.r​     $(F77) -c $(AM_FFLAGS) $(FFLAGS) $(AM_RFLAGS) $(RFLAGS)
8.14.3 Mixing Fortran 77 With C and C++Automake currently provides limited support for creating programs andshared libraries that are a mixture of Fortran 77 and C and/or C++.However, there are many other issues related to mixing Fortran 77 withother languages that are not (currently) handled by Automake, but thatare handled by other packages(1).
   Automake can help in two ways:

Automatic selection of the linker depending on which combinationsof source code.

Automatic selection of the appropriate linker flags (e.g., -L and-l) to pass to the automatically selected linker in order to linkin the appropriate Fortran 77 intrinsic and run-time libraries.
These extra Fortran 77 linker flags are supplied in the outputvariable FLIBS by the AC_F77_LIBRARY_LDFLAGS Autoconf macro.*Note Fortran Compiler Characteristics: (autoconf)Fortran Compiler.


   If Automake detects that a program or shared library (as mentioned insome _PROGRAMS or _LTLIBRARIES primary) contains source code that isa mixture of Fortran 77 and C and/or C++, then it requires that themacro AC_F77_LIBRARY_LDFLAGS be called in configure.ac, and thateither $(FLIBS) appear in the appropriate _LDADD (for programs) or_LIBADD (for shared libraries) variables.  It is the responsibility ofthe person writing the Makefile.am to make sure that $(FLIBS)appears in the appropriate _LDADD or _LIBADD variable.
   For example, consider the following Makefile.am:
 bin_PROGRAMS = foo
 foo_SOURCES  = main.cc foo.f
 foo_LDADD    = libfoo.la $(FLIBS)

 pkglib_LTLIBRARIES = libfoo.la
 libfoo_la_SOURCES  = bar.f baz.c zardoz.cc
 libfoo_la_LIBADD   = $(FLIBS)

   In this case, Automake will insist that AC_F77_LIBRARY_LDFLAGS ismentioned in configure.ac.  Also, if $(FLIBS) hadnt been mentioned in foo_LDADDandlibfoo_la_LIBADD`, then Automake would have issued awarning.
   (1) For example, the cfortran package(http://www-zeus.desy.de/~burow/cfortran/) addresses all of theseinter-language issues, and runs under nearly all Fortran 77, C and C++compilers on nearly all platforms.  However, cfortran is not yet FreeSoftware, but it will be in the next major release.
8.14.3.1 How the Linker is Chosen……………………………
When a program or library mixes several languages, Automake choose thelinker according to the following priorities.  (The names in parenthesesare the variables containing the link command.)

Native Java (GCJLINK)
Objective C++ (OBJCXXLINK)
C++ (CXXLINK)
Fortran 77 (F77LINK)
Fortran (FCLINK)
Objective C (OBJCLINK)
Unified Parallel C (UPCLINK)
C (LINK)

   For example, if Fortran 77, C and C++ source code is compiled into aprogram, then the C++ linker will be used.  In this case, if the C orFortran 77 linkers required any special libraries that werent included by the C++ linker, then they must be manually added to an _LDADDor_LIBADDvariable by the user writing theMakefile.am`.
   Automake only looks at the file names listed in _SOURCES variablesto choose the linker, and defaults to the C linker.  Sometimes this isinconvenient because you are linking against a library written inanother language and would like to set the linker more appropriately.*Note Libtool Convenience Libraries::, for a trick withnodist_EXTRA_..._SOURCES.
   A per-target _LINK variable will override the above selection.Per-target link flags will cause Automake to write a per-target _LINKvariable according to the language chosen as above.
8.15 Fortran 9x Support=======================
Automake includes support for Fortran 9x.
   Any package including Fortran 9x code must define the output variableFC in configure.ac; the simplest way to do this is to use theAC_PROG_FC macro (*note Particular Program Checks:(autoconf)Particular Programs.).
   A few additional variables are defined when a Fortran 9x source fileis seen:
FC​     The name of the Fortran 9x compiler.
FCFLAGS​     Any flags to pass to the Fortran 9x compiler.
AM_FCFLAGS​     The maintainers variant of FCFLAGS`.
FCCOMPILE​     The command used to actually compile a Fortran 9x source file.  The​     file name is appended to form the complete command line.
FCLINK​     The command used to actually link a pure Fortran 9x program or​     shared library.
8.15.1 Compiling Fortran 9x Files
FILE.o is made automatically from FILE.f90, FILE.f95, FILE.f03,or FILE.f08 by running the Fortran 9x compiler.  The precise commandused is as follows:
.f90​     $(FC) $(AM_FCFLAGS) $(FCFLAGS) -c $(FCFLAGS_f90) $&lt;
.f95​     $(FC) $(AM_FCFLAGS) $(FCFLAGS) -c $(FCFLAGS_f95) $&lt;
.f03​     $(FC) $(AM_FCFLAGS) $(FCFLAGS) -c $(FCFLAGS_f03) $&lt;
.f08​     $(FC) $(AM_FCFLAGS) $(FCFLAGS) -c $(FCFLAGS_f08) $&lt;
8.16 Compiling Java sources using gcjAutomake includes support for natively compiled Java, using gcj, theJava front end to the GNU Compiler Collection (rudimentary support forcompiling Java to bytecode using the javac compiler is also present,albeit deprecated; *note Java::).
   Any package including Java code to be compiled must define the outputvariable GCJ in configure.ac; the variable GCJFLAGS must also bedefined somehow (either in configure.ac or Makefile.am).  Thesimplest way to do this is to use the AM_PROG_GCJ macro.
   By default, programs including Java source files are linked withgcj.
   As always, the contents of AM_GCJFLAGS are passed to everycompilation invoking gcj (in its role as an ahead-of-time compiler,when invoking it to create .class files, AM_JAVACFLAGS is usedinstead).  If it is necessary to pass options to gcj fromMakefile.am, this variable, and not the user variable GCJFLAGS,should be used.
   gcj can be used to compile .java, .class, .zip, or .jarfiles.
   When linking, gcj requires that the main class be specified usingthe --main= option.  The easiest way to do this is to use the_LDFLAGS variable for the program.
8.17 Vala Support=================
Automake provides initial support for Vala(http://www.vala-project.org/).  This requires valac version 0.7.0 orlater, and currently requires the user to use GNU make.
 foo_SOURCES = foo.vala bar.vala zardoc.c

   Any .vala file listed in a _SOURCES variable will be compiledinto C code by the Vala compiler.  The generated .c files aredistributed.  The end user does not need to have a Vala compilerinstalled.
   Automake ships with an Autoconf macro called AM_PROG_VALAC thatwill locate the Vala compiler and optionally check its version number.
 – Macro: AM_PROG_VALAC ([MINIMUM-VERSION], [ACTION-IF-FOUND],​     [ACTION-IF-NOT-FOUND]) Search for a Vala compiler in PATH.  If it​     is found, the variable VALAC is set to point to it (see below for​     more details).  This macro takes three optional arguments.  The​     first argument, if present, is the minimum version of the Vala​     compiler required to compile this package.  If a compiler is found​     and satisfies MINIMUM-VERSION, then ACTION-IF-FOUND is run (this​     defaults to do nothing).  Otherwise, ACTION-IF-NOT-FOUND is run.​     If ACTION-IF-NOT-FOUND is not specified, the default value is to​     print a warning in case no compiler is found, or if a too-old​     version of the compiler is found.
   There are a few variables that are used when compiling Vala sources:
VALAC​     Absolute path to the Vala compiler, or simply valac if no​     suitable compiler Vala could be found at configure runtime.
VALAFLAGS​     Additional arguments for the Vala compiler.
AM_VALAFLAGS​     The maintainers variant of VALAFLAGS`.
      lib_LTLIBRARIES = libfoo.la
      libfoo_la_SOURCES = foo.vala

   Note that currently, you cannot use per-target *_VALAFLAGS (*noteRenamed Objects::) to produce different C files from one Vala sourcefile.
8.18 Support for Other LanguagesAutomake currently only includes full support for C, C++ (*note C++Support::), Objective C (*note Objective C Support::), Objective C++(*note Objective C++ Support::), Fortran 77 (*note Fortran 77Support::), Fortran 9x (*note Fortran 9x Support::), and Java (*noteJava Support with gcj::).  There is only rudimentary support for otherlanguages, support for which will be improved based on user demand.
   Some limited support for adding your own languages is available viathe suffix rule handling (*note Suffixes::).
8.19 Automatic dependency trackingAs a developer it is often painful to continually update theMakefile.am whenever the include-file dependencies change in aproject.  Automake supplies a way to automatically track dependencychanges (*note Dependency Tracking::).
   Automake always uses complete dependencies for a compilation,including system headers.  Automakes model is that dependency computation should be a side effect of the build.  To this end, dependencies are computed by running all compilations through a special wrapper program called depcomp.  depcompunderstands how to coax many different C and C++ compilers into generating dependency information in the format it requires. automake -awill installdepcompinto your source tree for you.  Ifdepcomp cant figure outhow to properly invoke your compiler, dependency tracking will simply bedisabled for your build.
   Experience with earlier versions of Automake (*note DependencyTracking Evolution: (automake-history)Dependency Tracking Evolution.)taught us that it is not reliable to generate dependencies only on themaintainer`s system, as configurations vary too much.  So insteadAutomake implements dependency tracking at build time.
   Automatic dependency tracking can be suppressed by puttingno-dependencies in the variable AUTOMAKE_OPTIONS, or passingno-dependencies as an argument to AM_INIT_AUTOMAKE (this should bethe preferred way).  Or, you can invoke automake with the -i option.Dependency tracking is enabled by default.
   The person building your package also can choose to disabledependency tracking by configuring with --disable-dependency-tracking.
8.20 Support for executable extensionsOn some platforms, such as Windows, executables are expected to have anextension such as .exe.  On these platforms, some compilers (GCC amongthem) will automatically generate foo.exe when asked to generatefoo.
   Automake provides mostly-transparent support for this.  Unfortunatelymostly doesn`t yet mean fully.  Until the English dictionary isrevised, you will have to assist Automake if your package must supportthose platforms.
   One thing you must be aware of is that, internally, Automake rewritessomething like this:
 bin_PROGRAMS = liver

   to this:
 bin_PROGRAMS = liver$(EXEEXT)

   The targets Automake generates are likewise given the $(EXEEXT)extension.
   The variables TESTS and XFAIL_TESTS (*note Simple Tests::) arealso rewritten if they contain filenames that have been declared asprograms in the same Makefile.  (This is mostly useful when someprograms from check_PROGRAMS are listed in TESTS.)
   However, Automake cannot apply this rewriting to configuresubstitutions.  This means that if you are conditionally building aprogram using such a substitution, then your configure.ac must takecare to add $(EXEEXT) when constructing the output variable.
   Sometimes maintainers like to write an explicit link rule for theirprogram.  Without executable extension support, this is easy—you simplywrite a rule whose target is the name of the program.  However, whenexecutable extension support is enabled, you must instead add the$(EXEEXT) suffix.
   This might be a nuisance for maintainers who know their package willnever run on a platform that has executable extensions.  For thosemaintainers, the no-exeext option (*note Options::) will disable thisfeature.  This works in a fairly ugly way; if no-exeext is seen, thenthe presence of a rule for a target named foo in Makefile.am willoverride an automake-generated rule for foo$(EXEEXT).  Without theno-exeext option, this use will give a diagnostic.
]]></content>
      <categories>
        <category>Linux</category>
        <category>Automake</category>
      </categories>
      <tags>
        <tag>autotools</tag>
        <tag>automake</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux 自动化编译autotools的使用</title>
    <url>/2011/12/06/linux-automake/</url>
    <content><![CDATA[[TOC]
自动化编译autotools的使用具体操作步骤
准备好源码文件helloworld.c 及 Makefile.am文件。
执行autoscan生成configure.ac并修改configure.ac
aclocal;
autoheader;
touch README NEWS AUTHORS ChangeLog
autoconf;
automake –add-missing;
./configure;
make;
./helloworld ;         —运行程序
make dist            —制作发布的包
make dist            —制作发布的包并对其进行测试检查
make clean        —清除make命令产生的目标文件及可执行文件

automake autoconf 自动化编译说明利用autotools自动生成makefile文件，自动化编译自己的工程，autotools工具只需要用户输入简单的目标文件、依赖文件、文件目录就可以轻松地生成Makefile了。
首先安装autotools系列工具，包括aclocal、autoscan、automake、autoheader、autoconf等。
可以通过rpm –qa | grep auto来查看各个应用程序，如果没有
yum install automake 即可安装。
详细步骤：1 建立自己的工程，编写源文件并创建Makefile.am1)最顶层目录名为模块名 helloworld
源文件放在模块下面的src子目录,例如helloworld/src

在src 下面，创建源文件main.c

在helloworld目录下面创建Makefile.am文件—（为Makefile.in的模板文件，.am扩展名是automake的缩写）,内容如下:


SUBDIRS=src


在helloworld/src 目录下创建Makefile.am文件 内容如下：

bin_PROGRAMS=helloworldhelloworld_SOURCES=main.c

其中，PROGRAMS表示要产生的是可执行文件，有多个可执行文件文件时，可用空格分开，而bin表示可执行文件的安装目录SOURCES表示生成可执行文件需要的源文件，有多个源文件时，也用空格分开。比如想生成两个可执行程序helloworld1和helloworld2，那么就需要写成：
bin_PROGRAMS=helloworld1 helloworld2helloworld1_SOURCES=main1.chelloworld2_SOURCES=main2.c

2. autoscan —创建autoconf的模板autoscan—将生成configure.ac和autoscan.log文件，它会在给定目录及其子目录树中检查源文件，若没有给定目录，就在当前目录及其子目录树中进行检查。它会搜索源文件以寻找一般的移植性问题并且创建一个文件configure.ac，通过这个文件我们可以创建autoconf需要的模版文件。
1).目录下面生成了configure.ac 文件，利用命令
configure.ac 文件为autoconf 的模板文件，内容如下所示，其中#行为注释行：
# -*- Autoconf -*-# Process this file with autoconf to produce a configure script.AC_PREREQ([2.68])AC_INIT([FULL-PACKAGE-NAME], [VERSION], [BUG-REPORT-ADDRESS])AC_CONFIG_SRCDIR([src/main.c])AC_CONFIG_HEADERS([config.h])# Checks for programs.AC_PROG_CC# Checks for libraries.# Checks for header files.# Checks for typedefs, structures, and compiler characteristics.# Checks for library functions.AC_CONFIG_FILES([Makefilesrc/Makefile])AC_OUTPUT

2). 修改configure.ac文件
将
AC_INIT([FULL-PACKAGE-NAME], [VERSION], [BUG-REPORT-ADDRESS])

修改为：
AC_INIT(helloworld, 0.1, shaoguangleo@gmail.com)     =–初始化autoconf
并添加
AM_INIT_AUTOMAKE(helloworld, 0.1)         =–初始化automake 必须的宏，这个如果不添加就会导致在autoconf时出错，信息大概为configure.in:no proper invocation of AM_INIT_AUTOMAKE was found
3.运行 aclocal — 复制所有的宏命令aclocal

备注：configure.ac 里面包含了一系列的宏命令，运行aclocal的目的是把工程需要的宏命令展开。（aclocal.m4 就是configure.ac中用到的宏定义）会生成autom4te.cache文件夹和aclocal.m4文件。
4.运行autoheader —生成配置头文件的模板config.h.in并创建4个必要的文件autoheader

备注：此时再创建4个必要的文件
touch README NEWS AUTHORS ChangeLog


README :描述模块的功能，用法和注意事项
NEWS : 描述模块最新的动态
AUTHORS : 模块的作者及联系方式
ChangeLog : 记录模块的修改历史

上述几个文件可以暂时为空。
5. automake –add-missing   — 生成Makefiel.in和所需要的脚本automake –add-missing   —其中add-missing选项会让automake自动添加一些必须的脚本文件。

6. autoconf — 生成configure脚本autoconf

—生成configure脚本
7. ./configure — 生成最终的Makefile文件./configure

configure 通常有两个参数

–prefix 用来指定安装目录 linux默认/usr/local
–host 用于交叉编译

8 编译make

9 安装make install


10 发布软件包make dist或者make distcheck

生成helloworld-0.1.tar.gz
autotools生成Makefile流程图
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>autotools</tag>
        <tag>automake</tag>
        <tag>autoconf</tag>
        <tag>aclocal</tag>
        <tag>autoscan</tag>
        <tag>autoheader</tag>
        <tag>configure</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux 启动命令如何不输入./</title>
    <url>/2013/03/23/linux-bashrc/</url>
    <content><![CDATA[启动命令如何不输入./执行当前文件夹下的可执行程序，不加”./”的方法：
直接执行当前目录下的程序可以使用一下方法：

将export PATH=$PATH:. 语句(冒号后加一个点)写到用户主目录的.bashrc中；
将可执行程序拷贝至/usr/bin或者/usr/local/bin （如果程序需要经常修改，还是采用第一种方法较好）

执行当前可执行程序加”./”的原因：
主要是安全原因，因为在linux中执行程序时，会先搜索当前目录然后是系统目录，所以如果当前目录中有与系统可执行程序重名的程序，比如cp，她就会优先执行当前目录中的cp，但是如果当前目录的cp是木马，就会威胁到系统安全，所以这是Linux的一种安全策略，所以默认并没有把当前目录加到环境变量PATH中去。
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>bashrc</tag>
        <tag>Linux</tag>
        <tag>export</tag>
        <tag>PATH</tag>
      </tags>
  </entry>
  <entry>
    <title>迷你计算器 bc</title>
    <url>/2017/04/07/linux-bc-beginner/</url>
    <content><![CDATA[迷你计算器 bc.. _linux_bc_beginner:
.. note::  北斗南辰日夜移，飞走鸟和兔。  元·王哲《卜算子·叹世迷》 
Linux bc命令是一种支持任意精度的交互执行的命令。
bc也是一种支持交互式执行语句的任意精度数的语言。与C语言有一些相似之处。 标准数学库也可以由  通过命令行选项使用。
官方定义为：

bc - An arbitrary precision calculator language

使用方法为：
$ bc [ -hlwsqv ] [long-options] [  file ... ]



默认实例默认进入交互环境，直接可以执行计算
$ bcbc 1.07.1Copyright 1991-1994, 1997, 1998, 2000, 2004, 2006, 2008, 2012-2017 Free Software Foundation, Inc.This is free software with ABSOLUTELY NO WARRANTY.For details type `warranty'.12*336

输入quit即可退出。
通过管道使用简单的情况可以使用管道来实现，如下：
$ echo "3.1415926 * 3" | bc9.4247778



高级一点可以通过scale来指定一些精度信息，如下可以保留3为有效精度
$ echo "scale=3; 2/3" | bc.666



另外还可以使用一些数学函数，比如：
$ echo "sqrt(36)" | bc6



还可以方便地使用ibase进行进制的转换，下面分别是输入为111，对应在2、4、8进制下的输出。
$ echo 'ibase=2;111' | bc 7$ echo 'ibase=4;111' | bc21$ echo 'ibase=8;111' | bc73



当然也可以通过obase来指定输入进制，如下将输入的8进制的111，分别转换为2、4、8进制。
$ echo 'ibase=8;obase=2;111' | bc1001001$ echo 'ibase=8;obase=4;111' | bc1021$ echo 'ibase=8;obase=8;111' | bc111

]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>bc</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux 终端中漂亮的几款字体</title>
    <url>/2023/11/02/linux-beautify-fonts-in-console/</url>
    <content><![CDATA[linux终端中最漂亮的几款字体.. note::  念去去，千里烟波，暮霭沉沉楚天阔。  柳永 《雨霖铃·寒蝉凄切》

仅个人想法，会持续不间断更新和改进。

对于长时间盯着终端来操作的拥趸而言，漂亮赏心悦目的字体是不可或缺的。
但编程字体的选择，看似简单，实则深藏玄机，不同的字体设计初衷各有千秋。
而编码阅读字体，追求的是流畅的感觉，轻松的识别和愉悦的体验。
不过，在编程的世界里，字体的功能性有点凌驾于美学之上。
这也是缘何程序员们偏爱等宽字体的原因，不易出bug。
所以结合功能性，兼具美术感，就是最佳的字体选择了。
举个最简单的例子，不易区分的1和I，不同宽度的W和I，给编程带来的体验是不同的。
这里整理的一些字体尽量能兼具以上的优点，规避一些缺点，助力书写代码新篇章。
Ubuntu 发行版是最开始用的，可是对终端下的字体一直不是很满意，今天终于找到了一些比较好看的终端字体，尤其是Droid sans mono字体，超爱，linux迷在Ubuntu下一直用的就是这款字体，很漂亮，极力推荐下面的几种字体:
Inconsolata 优雅漂亮的等宽字体我最喜欢的等宽字体，免费。线条清晰，很适合长时间的阅读和编写代码。
偶遇它之后，很快就把原来的默认字体DejaVu Sans Mono抛弃了。真正适合任何字号的好字体。感谢它的创造者Raph Levien！

monaspace 变成利器Github出品的Monaspace字体家族，具有能够满足程序员挑剔需求的利器。

Ubuntu安装命令如下：
$ sudo apt-get install fonts-inconsolata



MonacoMac的默认字体，好像也只有Mac上有。小字号的时候表现不错，而且再大些也不寒碜。普遍被认为是写代码的专用字体。随后的Menlo字体也是相当的不错。

Profont与Monaco类似的位图字体，你能够在Mac, Windows和Linux上面使用。小字号的时候表现好。非Mac平台上Monaco的最佳替代。喜欢小字号且不怕眼睛疲劳的同学可以考虑。

Envy Code R 具备复古风格复古的风格，线条流畅，字母衔接自然，代码阅读更流畅。

Droid Sans Mono开源字体，适合手机屏幕。是等宽字体中最突出的一个。可惜0和O区别不大。
安装命令：
$ sudo apt-get install ttf-droid


DejaVu Sans Mono 很多Linux发行版的标配我以前最喜欢的免费字体系列，以Vera为基础，但是比后者提供更多字符了。
适于任何字号，最重要的是无论终端窗口如何变化，始终能保持字体的清晰。

安装命令如下：
$ sudo apt-get install fonts-dejavu-core



Terminus 机械感十足机械感十足的字体，安装命令如下：
$ sudo apt-get install xfonts-terminus


Fira Code 特别好的编程字体Fira Code也是一款等宽字体，以其独特的编码连字和ASCII支持而闻名。
这款字体能够提供清晰、易读的文本，非常适合长时间在终端中工作。

安装方法如下：
$ sudo apt-get install firacode

SourceCode Pro 优雅且剑指源码SourceCode Pro单看这名字就知道剑指源码编辑，不过作为Adobe开发的字体，当然不仅仅为编码环境优化，清晰的线条和易读的字母，无论在何处使用，都能为你提供愉悦的体验。
更多详细的信息，可以参考官网：Source Code Pro (adobe-fonts.github.io) 

安装方法对于MacOSX而言，其他很多字体都已经打包好了，以monaspace为例，执行下面的两个命令即可安装。
$ brew tap homebrew/cask-fonts$ brew install font-monaspace



参考文献
https://en.wikipedia.org/wiki/Inconsolata


]]></content>
      <categories>
        <category>Linux集锦</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>ubuntu</tag>
        <tag>DejaVu</tag>
        <tag>droid</tag>
        <tag>envy</tag>
        <tag>inconsolata</tag>
        <tag>monaco</tag>
        <tag>Profont</tag>
      </tags>
  </entry>
  <entry>
    <title>可看黄道吉日的 cal</title>
    <url>/2011/02/12/linux-cal-beginner/</url>
    <content><![CDATA[可看黄道吉日的 cal.. _linux_cal_beginner:
.. note::  但愿人长久，千里共婵娟。  苏轼《水调歌头·明月几时有》 
cal用于显示当前日历信息或者指定日期的公历信息。
cal的官方定义为：

 cal, ncal — displays a calendar and the date of Easter

cal也是来自于calendar的前三个字母。
其用法有好几种，比如可以为：
$ cal [-31jy] [-A number] [-B number] [-d yyyy-mm] [[month] year]$ cal [-31j] [-A number] [-B number] [-d yyyy-mm] -m month [year]$ ncal [-C] [-31jy] [-A number] [-B number] [-d yyyy-mm] [[month] year]$ ncal [-C] [-31j] [-A number] [-B number] [-d yyyy-mm] -m month [year]$ ncal [-31bhjJpwySM] [-A number] [-B number] [-H yyyy-mm-dd] [-d yyyy-mm] [-s country_code] [[month] year]$ ncal [-31bhJeoSM] [-A number] [-B number] [-d yyyy-mm] [year]



cal可以没有参数，也可以多个参数组合。
[[month] year]的含义是，比如有year这个参数，然后可以出现month year两个参数。
主要使用的参数为：

-3 ：显示前后和当前3个月的日历
-y ：显示一年的日历，此时不要指定月份参数
-j ：显示在当年中的第几天（儒略日）

显示当前月份的日历默认无参数会显示当前的月份等信息
$ cal   February 2011Su Mo Tu We Th Fr Sa       1  2  3  4  5 6  7  8  9 10 11 1213 14 15 16 17 18 1920 21 22 23 24 25 2627 28



显示指定年月的日历比如希望看看2012年12月份，可以运行如下命令：
$ cal 12 2012   December 2012Su Mo Tu We Th Fr Sa                   1 2  3  4  5  6  7  8 9 10 11 12 13 14 1516 17 18 19 20 21 2223 24 25 26 27 28 2930 31



显示3个月的日历-3将显示当前月份、前一个月、后一个月，共计3个月的日历。
$ cal -3                            2011      January               February               MarchSu Mo Tu We Th Fr Sa  Su Mo Tu We Th Fr Sa  Su Mo Tu We Th Fr Sa                   1         1  2  3  4  5         1  2  3  4  5 2  3  4  5  6  7  8   6  7  8  9 10 11 12   6  7  8  9 10 11 12 9 10 11 12 13 14 15  13 14 15 16 17 18 19  13 14 15 16 17 18 1916 17 18 19 20 21 22  20 21 22 23 24 25 26  20 21 22 23 24 25 2623 24 25 26 27 28 29  27 28                 27 28 29 30 3130 31



显示一年的日历使用-y参数，可以查看一年的日历。
$ cal -y                            2011      January               February               MarchSu Mo Tu We Th Fr Sa  Su Mo Tu We Th Fr Sa  Su Mo Tu We Th Fr Sa                   1         1  2  3  4  5         1  2  3  4  5 2  3  4  5  6  7  8   6  7  8  9 10 11 12   6  7  8  9 10 11 12 9 10 11 12 13 14 15  13 14 15 16 17 18 19  13 14 15 16 17 18 1916 17 18 19 20 21 22  20 21 22 23 24 25 26  20 21 22 23 24 25 2623 24 25 26 27 28 29  27 28                 27 28 29 30 3130 31       April                  May                   JuneSu Mo Tu We Th Fr Sa  Su Mo Tu We Th Fr Sa  Su Mo Tu We Th Fr Sa                1  2   1  2  3  4  5  6  7            1  2  3  4 3  4  5  6  7  8  9   8  9 10 11 12 13 14   5  6  7  8  9 10 1110 11 12 13 14 15 16  15 16 17 18 19 20 21  12 13 14 15 16 17 1817 18 19 20 21 22 23  22 23 24 25 26 27 28  19 20 21 22 23 24 2524 25 26 27 28 29 30  29 30 31              26 27 28 29 30        July                 August              SeptemberSu Mo Tu We Th Fr Sa  Su Mo Tu We Th Fr Sa  Su Mo Tu We Th Fr Sa                1  2      1  2  3  4  5  6               1  2  3 3  4  5  6  7  8  9   7  8  9 10 11 12 13   4  5  6  7  8  9 1010 11 12 13 14 15 16  14 15 16 17 18 19 20  11 12 13 14 15 16 1717 18 19 20 21 22 23  21 22 23 24 25 26 27  18 19 20 21 22 23 2424 25 26 27 28 29 30  28 29 30 31           25 26 27 28 29 3031      October               November              DecemberSu Mo Tu We Th Fr Sa  Su Mo Tu We Th Fr Sa  Su Mo Tu We Th Fr Sa                   1         1  2  3  4  5               1  2  3 2  3  4  5  6  7  8   6  7  8  9 10 11 12   4  5  6  7  8  9 10 9 10 11 12 13 14 15  13 14 15 16 17 18 19  11 12 13 14 15 16 1716 17 18 19 20 21 22  20 21 22 23 24 25 26  18 19 20 21 22 23 2423 24 25 26 27 28 29  27 28 29 30           25 26 27 28 29 30 3130 31



显示儒略日-j用于显示儒略日，这里的儒略日的概念为从1月1日开始计算的多少天，这个在倒计时的时候挺好用的。
$ cal -j  cal 02 2011 -j       February 2011 Su  Mo  Tu  We  Th  Fr  Sa         32  33  34  35  36 37  38  39  40  41  42  43 44  45  46  47  48  49  50 51  52  53  54  55  56  57 58  59
]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>cal</tag>
      </tags>
  </entry>
  <entry>
    <title>查看庐山真面貌的cat</title>
    <url>/2011/02/12/linux-cat-beginner/</url>
    <content><![CDATA[查看庐山真面貌的cat.. note::  此去经年，应是良辰好景虚设  宋 柳永《雨霖铃》
cat命令可用于输出文件的内容到标准输出。
cat的官方定义为：

concatenate files and print on the standard output
翻译过来就是：把档案串连接后传到基本输出

其用法一般为：
$ cat [OPTION]... [FILE]...

cat命令的可选参数[OPTION]如下所示：

-n 或 --number： 由 1 开始对所有输出的行数编号
-b 或 --number-nonblank： 和 -n 相似，只不过对于空白行不编号
-s 或 --squeeze-blank ：当遇到有连续两行以上的空白行，就代换为一行的空白行
-T或--show-tabs：显示TAB字符，显示为^I
-E或--show-ends：显示行末符号，字符为$
-A或--show-all：显示所有的信息

此时假定我们的文件为hello.c，内容为最经典的：
#include &lt;stdio.h&gt;int main(int argc, char * argv[]){    printf("Hello World\n");        return 0;}


接下来的实例全部根据这个文件展开，Hello World. Hello Linux

实例 ：简单显示内容$ cat hello.c #include &lt;stdio.h&gt;int main(int argc, char * argv[]){	printf("Hello World\n");	        	return 0;}



实例 ：显示行号 -n$ cat -n hello.c      1	#include &lt;stdio.h&gt;     2	     3	int main(int argc, char * argv[])     4	{     5		printf("Hello World\n");     6		             7		return 0;     8	}



实例 ： 显示行末$ cat -E hello.c #include &lt;stdio.h&gt;$$int main(int argc, char * argv[])${$	printf("Hello World\n");$	        $	return 0;$}$



实例：显示空白字符cat -T hello.c #include &lt;stdio.h&gt;int main(int argc, char * argv[]){^Iprintf("Hello World\n");^I        ^Ireturn 0;}


此时可以看到^I，which means Tab charcter.

加一个管道比如，此时希望看到你的源码文件一共多少行，每行代表什么意思，就可以把含有行号的输入通过管道发送到另外一个文件，如下所示：
$ cat -n hello.c &gt; hello_number.c$ cat hello_number.c      1	#include &lt;stdio.h&gt;     2	     3	int main(int argc, char * argv[])     4	{     5		printf("Hello World\n");     6		             7		return 0;     8	}




其他的一些选项可以自行尝试。

]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>cat</tag>
        <tag>文档查看</tag>
        <tag>文件操作</tag>
        <tag>文件管理</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux的 cat 命令</title>
    <url>/2011/02/12/linux-cat/</url>
    <content><![CDATA[cat 显示文件内容cat命令可用于输出文件的内容到标准输出。
cat的官方定义为：

concatenate files and print on the standard output
翻译过来就是：把档案串连接后传到基本输出

其用法一般为：
$ cat [OPTION]... [FILE]...

cat命令的可选参数[OPTION]如下所示：

-n 或 --number： 由 1 开始对所有输出的行数编号
-b 或 --number-nonblank： 和 -n 相似，只不过对于空白行不编号
-s 或 --squeeze-blank ：当遇到有连续两行以上的空白行，就代换为一行的空白行
-T或--show-tabs：显示TAB字符，显示为^I
-E或--show-ends：显示行末符号，字符为$
-A或--show-all：显示所有的信息

此时假定我们的文件为hello.c，内容为最经典的：
#include &lt;stdio.h&gt;int main(int argc, char * argv[]){    printf("Hello World\n");        return 0;}


接下来的实例全部根据这个文件展开，Hello World. Hello Linux

实例 ：简单显示内容$ cat hello.c #include &lt;stdio.h&gt;int main(int argc, char * argv[]){	printf("Hello World\n");	        	return 0;}



实例 ：显示行号 -n$ cat -n hello.c      1	#include &lt;stdio.h&gt;     2	     3	int main(int argc, char * argv[])     4	{     5		printf("Hello World\n");     6		             7		return 0;     8	}



实例 ： 显示行末$ cat -E hello.c #include &lt;stdio.h&gt;$$int main(int argc, char * argv[])${$	printf("Hello World\n");$	        $	return 0;$}$



实例：显示空白字符cat -T hello.c #include &lt;stdio.h&gt;int main(int argc, char * argv[]){^Iprintf("Hello World\n");^I        ^Ireturn 0;}


此时可以看到^I，which means Tab charcter.

加一个管道比如，此时希望看到你的源码文件一共多少行，每行代表什么意思，就可以把含有行号的输入通过管道发送到另外一个文件，如下所示：
$ cat -n hello.c &gt; hello_number.c$ cat hello_number.c      1	#include &lt;stdio.h&gt;     2	     3	int main(int argc, char * argv[])     4	{     5		printf("Hello World\n");     6		             7		return 0;     8	}




其他的一些选项可以自行尝试。

]]></content>
      <categories>
        <category>Linux</category>
        <category>Linux入门</category>
        <category>文档查看</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>cat</tag>
      </tags>
  </entry>
  <entry>
    <title>探索未知世界的cd</title>
    <url>/2011/04/17/linux-cd-beginner/</url>
    <content><![CDATA[探索未知世界的cd.. _linux_cd_beginner:
.. note::  月桥花院，琐窗朱户，只有春知处。  宋 辛弃疾《青玉案·元夕》
cd 命令应该是除了 ls 命令外用的最多的命令了。
除非你大门不出二门不迈，做个大家闺秀。
cd 命令的含义为

 cd - change directory

可以让我们访问不同的文件夹。
最简单的用法为：
$ cd /the/path/you/want/to/go/


 接下来说一些技巧，让效率加倍。

让cd命令对参数大小写不敏感如果你需要同时显示大写和小写的目录名（即便是你给的参数只是小写的），执行下面的bind命令，此时就可以避免Linux和linux的尴尬。
$ bind "set completion-ignore-case on"



cd之进入刚才的目录想要进入刚才进入的地方（目测没有很多人再用，但是真的很好用）运行：
$ cd –



快速返回家目录需要快速地回到你的家目录，输入cd即可，这里其实不用一级一级的进入
$ cd



进入某用户的家目录这个需要你有root权限
cd ~username

进入username的家目录。

这些是一些比较基础和入门的，还有一些高级一点的，这些技巧可能用的比较少，不过也是很有帮助的。

一步直达 - CDPATH的妙用
适用于贼长的目录路径

如果你的目录路径足够长长长长长长长长长长长长长长长那么一定要用一下这个技巧。
变量CDPATH定义了目录的搜索路径，这个设置特别适合经常需要进入到某个目录，此时这个设置就及其有用
$ export CDPATH=/the/first/path/you/want/to/go/:/the/second/path/you/want/to/go

现在，不用输入/the/first/path/you/want/to/go/hello 这样长了，我可以直接输入下面的命令进入 ：
$ cd hello

此时即可一步直达/the/first/path/you/want/to/go/hello目录
快速折返的 cd和alias​	有没有碰到这个痛点，一直需要cd ..，如此这番，好多次，那么此时就可以通过结合cd和alias的强大结合，快速折返，如下：在一个多级的目录下希望返回上级目录是，经常要使用cd ../../../../../..，如果层次很多，比如，在目录/home/username/1/2/3/4/5/6/7/8/9中，希望返回，那么可以使用cd ../../../，或者在bashrc中定义如下：
alias ..=”cd .. ”alias ..2=”cd ../..”alias ..3=”cd ../../..”alias ..4=”cd ../../../..”alias ..5=”cd ../../../../.. ”alias ..6=”cd ../../../../../.. ”alias ..7=”cd ../../../../../../.. ”alias ..8=”cd ../../../../../../../.. ”alias ..9=”cd ../../../../../../../../.. ”alias ..10=”cd ../../../../../../../../.. ”

这样就可以通过..N来快速返回N级父目录了。
进入某用户的家目录如果你拥有root权限，可以进入某个用户的家目录
$ cd ~username



其中username为实际用户名
创建后立即进入该目录的mkdircd经常需要的操作是创建一个目录，然后再进入该目录，那么可以把下面的一行语句放在bashrc里面即可实现。
function mkdircd () { mkdir –p "$@" &amp;&amp; eval cd "\"\$$#\""; }



此时使用如下的命令进行测试：
$ mkdircd /tmp/the/test/folder/we/want/to/create







!$这个命令目测，用的人不多，其实比较有用，且有效。
$ cd !$

表明的意思是将上一个命令的参数作为cd的参数来使用。
用shopt –s cdspell自动纠正cd命令的目录名输入错误使用shopt -s cdspell可以自动修正cd时拼写错误的目录名。
如果你在输入时经常犯些错误，这个命令是很有用的。详见以下示例：
# cd /etc/mall-bash: cd: /etc/mall: No such file or directory# shopt -s cdspell# cd /etc/mall# pwd/etc/mail


 注: 当我错误的把mail敲成了mall，用这个命令mall就自动被换成了mail

详细的配置信息可以参考：
.. literalinclude:: ../../src/linux-bashrc.sh
]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>alias</tag>
        <tag>cd</tag>
        <tag>bind</tag>
        <tag>pwd</tag>
        <tag>shopt</tag>
        <tag>目录导航</tag>
        <tag>Linux炫技</tag>
        <tag>Linux杂谈</tag>
        <tag>磁盘管理</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux cd命令</title>
    <url>/2011/04/17/linux-cd/</url>
    <content><![CDATA[cdcd 命令应该是除了 ls 命令外用的最多的命令了。除非你大门不出二门不迈，做个大家闺秀。
cd 命令的含义为

 change directory

可以让我们访问不同的文件夹。
最简单的用法为：
$ cd /the/path/you/want/to/go/


 接下来说一些技巧，让效率加倍。

让cd命令对参数大小写不敏感如果你需要同时显示大写和小写的目录名（即便是你给的参数只是小写的），执行下面的bind命令，此时就可以避免Linux和linux的尴尬。
$ bind “set completion-ignore-case on”



进入刚才的目录想要进入刚才进入的地方（目测没有很多人再用，但是真的很好用）运行：
$ cd –



快速返回家目录需要快速地回到你的家目录，输入cd即可，这里其实不用一级一级的进入
$ cd



进入某用户的家目录这个需要你有root权限
cd ~username

进入username的家目录。

这些是一些比较基础和入门的，还有一些高级一点的，这些技巧可能用的比较少，不过也是很有帮助的。

结合CDPATH的妙用变量CDPATH定义了目录的搜索路径：
$ export CDPATH=/the/path/you/add/:/another/path/

现在，不用输入cd /the/path/you/add/hello/ 这样长了，我可以直接输入下面的命令进入 /the/path/you/add/hello/：
$ cd html



!$这个命令目测，用的人不多，其实比较有用，且有效。
$ cd !$

表明的意思是将上一个命令的参数作为cd的参数来使用。
用shopt –s cdspell自动纠正cd命令的目录名输入错误使用shopt -s cdspell可以自动修正cd时拼写错误的目录名。
如果你在输入时经常犯些错误，这个命令是很有用的。详见以下示例：
# cd /etc/mall-bash: cd: /etc/mall: No such file or directory# shopt -s cdspell# cd /etc/mall# pwd/etc/mail


 注: 当我错误的把mail敲成了mall，用这个命令mall就自动被换成了mail

]]></content>
      <categories>
        <category>Linux</category>
        <category>Linux入门</category>
        <category>目录导航</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>cd</tag>
        <tag>bind</tag>
        <tag>pwd</tag>
        <tag>shopt</tag>
      </tags>
  </entry>
  <entry>
    <title>CentOS 添加 EPEL 源</title>
    <url>/2014/01/17/linux-centos-add-epel-repo/</url>
    <content><![CDATA[关于EPEL源以前在fedora上都是使用163或者sohu的源，感觉速度很快，包也挺全的，但是在CentOS上就不能这么用了，忽然就碰到了EPEL，简直是柳暗花明又一村呀，以前一直为CentOS的稳定而庆幸，为N多包要自己rpm而小失望，现在加上这个源一切都是向fedora的yum体验靠拢呀，赞(≧▽≦)/

企业版 Linux 附加软件包(以下简称 EPEL)是一个由特别兴趣小组创建、维护并管理的，针对 红帽企业版 Linux(RHEL)及其衍生发行版(比如 CentOS、Scientific Linux、Oracle Enterprise Linux)的一个高质量附加软件包项目。

EPEL 的软件包通常不会与企业版 Linux 官方源中的软件包发生冲突，或者互相替换文件。EPEL 项目与 Fedora 基本一致，包含完整的构建系统、升级管理器、镜像管理器等等。
使用方法：添加源创建一个文件/etc/yum.repos.d:
# touch /etc/yum.repos.d/epel.repo

添加以下内容
[epel]name=epel repobaseurl=http://dl.fedoraproject.org/pub/epel/6/$basearch/gpgcheck=0enabled=1
当然，如果你的CentOS是5.X版本的就把上面的6改成5即可了。
使用yum更新# yum update# yum install ipython.noarch

现在再试试以前不能安装的诸如ntfs-3g，ipython等等，赞
]]></content>
      <categories>
        <category>CentOS</category>
        <category>Linux</category>
        <category>Fedora</category>
      </categories>
      <tags>
        <tag>rpm</tag>
        <tag>centos</tag>
        <tag>epel</tag>
        <tag>Fedora</tag>
        <tag>ntfs-3g</tag>
        <tag>ipython</tag>
      </tags>
  </entry>
  <entry>
    <title>System BootOrder not found. Initializing defaults</title>
    <url>/2020/04/02/linux-centos-booterror/</url>
    <content><![CDATA[CentOS8最近碰到的问题：
System BootOrder not found. Initializing defaults.Creating boot entry “Boot0002” with label “CentOS” for file /EFI/centos/shimx64.efi
问题的解决很简单：在BIOS里面把secure chip给禁止掉即可正常启动。
]]></content>
      <categories>
        <category>CentOS</category>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>CentOS</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux package-cleanup的使用</title>
    <url>/2013/07/18/linux-centos-fedora-package-cleanup/</url>
    <content><![CDATA[package-cleanup的使用以前对于多余的内核，都是rpm-grep-remove你懂的，这次发现了这个软件包。神呐，节省了很多时间，只需要package-cleanup –oldkernels就可以把就内核（对于版本升级而言）删除，加上–count参数就可以指定留下几个grub选项，注意最好轻易不要设定1，除非你确定刚升级好的内核是OK的，默认值是2，即会保存前一个内核。
package-cleanup ： 用于清理本地安装的RPM软件包
注意：这是一个只对RPM有用的工具，Ubuntu 之类的无法使用。
Fedora系统中package-cleanup是默认安装的，而且manpage也比较好懂，这里挑出几个命令来解释一下。
命令格式：
package-cleanup [options] &lt;item …&gt;


列出与其他RPM没有依赖关系的软件包，又叫叶节点（leaf node），即，没有软件包依赖叶节点。

$ package-cleanup –leaveslibacl-devel-2.2.49-8.fc14.i686libcap-devel-2.17-1.fc13.i686libchamplain-gtk-0.6.1-4.fc14.i686libcurl-devel-7.21.0-5.fc14.i686libdbi-dbd-mysql-0.8.3-6.fc14.i686libertas-usb8388-firmware-5.110.22.p23-4.fc13.noarchlibgail-gnome-1.20.3-1.fc14.i686libgtop2-devel-2.28.2-1.fc14.i686libidn-devel-1.18-1.fc14.i686libiodbc-3.52.7-1.fc12.i686

可以看到，列出的都是一些函数库，这些库函数没有被其他程序用到。

列出当前软件仓库中不再提供支持的本地已安装的软件包。也就是说，列出的软件包将不会再升级。

$ package-cleanup –orphansalchemist-1.0.37-8.fc12.i686antlr-2.7.7-6.fc12.i686kernel-2.6.34.7-61.fc13.i686kernel-devel-2.6.34.7-61.fc13.i686kmod-nvidia-2.6.34.7-61.fc13.i686-260.19.12-1.fc13.1.i686schroedinger-1.0.10-1.fc13.i686system-config-display-2.2-1.fc12.i686xorg-x11-drv-wacom-0.10.8-2.fc13.i686


删除旧内核文件（kernel, kernel-devel）。

$ package-cleanup –oldkernels

前面一篇文章提到过如何手工删除旧内核文件，这条命令就可以解决了。
可以用参数 “–count ” 指定要保留的内核个数，默认是2。
可以用参数 “–keepdevel” 指定不要删除 kernel-devel 。
例如：
$ package-cleanup –oldkernels –count=3 –keepdevel

含义是：保留最近3个内核文件和kernel-devel文件，并删除其余的kernels。

列出有依赖问题的软件包。

$ package-cleanup –problemsPackage alchemist-1.0.37-8.fc12.i686 requires python(abi) = (’0′, ’2.6′, None)Package alchemist-1.0.37-8.fc12.i686 requires python-abi = (’0′, ’2.6′, None)Package system-config-display-2.2-1.fc12.i686 requires libpython2.6.so.1.0Package system-config-display-2.2-1.fc12.i686 requires python(abi) = (’0′, ’2.6′, None)

我的运行结果显示有些软件包需要python 2.6的支持，Fedora 14已经默认安装python 2.7。

扫描重复安装的RPM软件包。

$ package-cleanup –dupes


扫描重复安装的软件包，并删除老版本的软件包。

$ package-cleanup –cleandupes
]]></content>
      <categories>
        <category>Linux</category>
        <category>CentOS</category>
        <category>Fedora</category>
      </categories>
      <tags>
        <tag>yum</tag>
        <tag>linux</tag>
        <tag>package-cleanup</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux CentOS7图形界面与命令行界面切换</title>
    <url>/2013/08/18/linux-centos-gui-command-screen/</url>
    <content><![CDATA[Linux CentOS7图形界面与命令行界面切换在图形界面使用 ctrl+alt+F2 切换到终端界面  
终端界面 ctrl+alt+F2 切换回图形界面
在命令上 输入 init 3 命令 切换到终端界面
输入 init 5命令 切换到图形界面
如果想系统默认以某种方式启动， 使用systemd创建符号链接指向默认运行级别。
 修改方法为：
1.首先删除已经存在的符号链接：
$ rm /etc/systemd/system/default.target

2.默认级别转换为3(文本模式)：
$ ln -sf /lib/systemd/system/multi-user.target /etc/systemd/system/default.target

或者默认级别转换为5(图形模式)：
$ ln -sf /lib/systemd/system/graphical.target /etc/systemd/system/default.target

3.重启即可生效
reboot


centos7以下的版本
以管理员权限编辑/etc/inittab把
id:5:initdefault:#改为id:3:initdefault:

就ok。
]]></content>
      <categories>
        <category>Linux</category>
        <category>CentOS</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>GUI</tag>
        <tag>multi-user</tag>
        <tag>graphical</tag>
      </tags>
  </entry>
  <entry>
    <title>CentOS下安装微软雅黑字体</title>
    <url>/2014/09/01/linux-centos-install-chinese-fonts/</url>
    <content><![CDATA[CentOS下安装微软雅黑字体
所有操作均在root权限下进行

1、到Windows下复制字体到CentOS
字体路径 C:/WINDOWS/Fonts
雅黑：msyh黑体：SimHei宋体：SimSun华文细黑：STXihei华文楷体：STKaiti
等等 你要的字体
2、将要的字体复制到/usr/share/fonts/chinese/TrueType目录下
3、修改字体权限，使root以外的用户可以使用这些字体。
4、建立字体缓存，命令：
$ cd /usr/share/fonts/chinses/TrueType$ mkfontscale$ mkfontdir$ fc-cache -fv

查看安装的字体
$ fc-list :lang=zh
]]></content>
      <categories>
        <category>CentOS</category>
      </categories>
      <tags>
        <tag>centos</tag>
        <tag>windows</tag>
        <tag>mkfontscale</tag>
        <tag>mkfontdir</tag>
        <tag>fc-cache</tag>
        <tag>fc-list</tag>
      </tags>
  </entry>
  <entry>
    <title>Centos 如何安装Django环境</title>
    <url>/2015/03/09/linux-centos-install-django/</url>
    <content><![CDATA[Centos 如何安装Django环境首先你要有一个Centos系统，一般情况系统会自带Python的。如果没有安装，可以用yum install python 解决。
Django安装大致有pip、git、源码包三种方式安装。下面主要介绍pip方式，也是最常用的方式之一！
pip安装：wget https://bootstrap.pypa.io/get-pip.pypython get-pip.py
提示：

   Downloading/unpacking pip    Downloading pip-1.5.6-py2.py3-none-any.whl (1.0MB): 1.0MB downloaded  Installing collected packages: pip Successfully installed pip Cleaning up…

表示成功安装了pip。

然后：
pip install Django==1.7.6   //后面跟的是官网发布的最新版本。

提示：

Downloading/unpacking Django==1.7Downloading Django-1.7-py2.py3-none-any.whl (7.4MB): 7.4MB downloadedInstalling collected packages: DjangoSuccessfully installed DjangoCleaning up…

表示已经成功安装Django
验证执行：python -c “import django; print(django.get_version())”
返回版本：1.7.6
]]></content>
      <categories>
        <category>CentOS</category>
        <category>Django</category>
      </categories>
      <tags>
        <tag>yum</tag>
        <tag>python</tag>
        <tag>django</tag>
        <tag>centos</tag>
        <tag>pip</tag>
        <tag>wget</tag>
      </tags>
  </entry>
  <entry>
    <title>CentOS 7 安装配置Docker</title>
    <url>/2016/11/30/linux-centos-install-docker/</url>
    <content><![CDATA[CentOS 7 中 Docker 的安装Docker 软件包已经包括在默认的 CentOS-Extras 软件源里。因此想要安装 docker，只需要运行下面的 yum 命令：
# yum install docker

启动 Docker 服务安装完成后，使用下面的命令来启动 docker 服务，并将其设置为开机启动：
# service docker start# chkconfig docker on

or
# systemctl start docker.service# systemctl enable docker.service

以非root用户的身份来运行Docker将Docker安装到CentOS上后，你需要将自己添加到docker群组，那样才能以非root用户的身份来运行Docker。为此，使用这个命令：
sudo usermod -a -G docker $USER


Cannot connect to the Docker daemon. Is the docker daemon running on this host?# service docker restart

下载官方的 CentOS 镜像到本地# docker pull centos


确认 CentOS 镜像已经被获取# docker imagesREPOSITORY          TAG                 IMAGE ID            CREATED             SIZEdocker.io/centos    latest              67591570dd29        2 weeks ago         191.8 MB

运行一个 Docker 容器：[root@localhost ~]# docker run -i -t centos /bin/bash[root@67591570dd29 /]#


搜索基于 Fedora 和 Ubuntu 操作系统的容器。# docker search ubuntu# docker search fedora

docker从主机上复制文件方法通过docker run命令的-v/–volume参数
假设我们需要将本机的/data 目录分享到Docker的/mnt 目录下, 我们可以通过这样的命令:
$ docker run -v /data:/mnt -i -t image-id bash

（假如，在centos或者redhat需要关闭selinux）
]]></content>
      <categories>
        <category>Linux</category>
        <category>CentOS</category>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>centos</tag>
      </tags>
  </entry>
  <entry>
    <title>CentOS 如何安装hexo</title>
    <url>/2015/09/02/linux-centos-install-hexo/</url>
    <content><![CDATA[CentOS 如何安装hexo安装编译Git基础包yum -y install gcc zlib-devel openssl-devel perl cpio expat-devel gettext-devel curl autoconf

安装Node.js环境因为Hexo是基于Node.js环境的，所以我们需要安装Node.js.
安装Node.js依赖包yum -y install gcc-c++ openssl-devel python

下载和安装Node.js源代码安装wget http://nodejs.org/dist/node-latest.tar.gztar -zxvf node-latest.tar.gzcd node-v0.12.7./configuremake &amp;&amp; make install
命令行安装yum install nodejs

部署且安装Hexo博客安装Hexo
yum install npmnpm install -g hexo-clinpm install hexo-generator-index --savenpm install hexo-generator-archive --savenpm install hexo-generator-category --savenpm install hexo-generator-tag --savenpm install hexo-server --save # server独立出来了，需要单独安装npm install hexo-deployer-git --savenpm install hexo-renderer-marked@0.2 --savenpm install hexo-renderer-stylus@0.2 --savenpm install hexo-generator-feed@1 --savenpm install hexo-generator-sitemap@1 --save
这里采用npm方式来部署hexo静态博客。
部署文件夹这里我们可以先建立一个文件夹，用来安装hexo
mkdir hexocd hexo
初始化Hexo
hexo init


安装依赖包
npm install

生成静态页面
hexo generate

本地预览
hexo server

此时就可以打开浏览器输入http://localhost:4000来预览了。
]]></content>
      <categories>
        <category>CentOS</category>
        <category>Git</category>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>CentOS</tag>
        <tag>git</tag>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>CentOS安装IDLE</title>
    <url>/2011/05/06/linux-centos-install-idle/</url>
    <content><![CDATA[CentOS安装IDLE
yum install tkinteryum install python-imaginyum install python-tools
]]></content>
      <categories>
        <category>Linux</category>
        <category>CentOS</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>centos</tag>
        <tag>idle</tag>
      </tags>
  </entry>
  <entry>
    <title>如何在CentOS上安装VLC</title>
    <url>/2015/04/02/linux-centos-install-vlc/</url>
    <content><![CDATA[CentOS7rpm -Uvh http://li.nux.ro/download/nux/dextop/el7/x86_64/nux-dextop-release-0-1.el7.nux.noarch.rpm

CentOS6rpm -Uvh http://dl.fedoraproject.org/pub/epel/6/i386/epel-release-6-8.noarch.rpmorrpm -Uvh http://li.nux.ro/download/nux/dextop/el6/x86_64/nux-dextop-release-0-2.el6.nux.noarch.rpm

VLCyum updateyum  install vlc
]]></content>
      <categories>
        <category>CentOS</category>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>CentOS</tag>
        <tag>VLC</tag>
      </tags>
  </entry>
  <entry>
    <title>CentOS 6 安装配置VNC</title>
    <url>/2014/01/18/linux-centos-install-vnc/</url>
    <content><![CDATA[CentOS 6安装和配置VNCVNC是Linux上的一款非常优秀的远程控制工具软件，通常我们在Windows上面安装vnc客户端软件来远程访问Linux机器(Windows上常用的客户端RealVNC)，要远程连接到Linux首先要确保Linux上面已经安装了VNC server，下面以CentOS 6为例来说明：
1. 检查是否已经安装了VNC server[root@centos6 ~]# rpm -qa | grep vnctigervnc-1.0.90–0.17.20110314svn4359.el6.i686gtk-vnc-0.3.10–3.el6.i686tigervnc-server-1.0.90–0.17.20110314svn4359.el6.i686gtk-vnc-python-0.3.10–3.el6.i686

如果上面的几个rpm包已经存在，说明VNC server已经安装好了，接下来跳转步骤3启动vncserver就可以了，否则执行步骤2
2. 安装VNC server# yum install tigervnc# yum install tigervnc-server
3. 启动vncserver第一次启动vncserver需要输入密码两次
[root@centos6 mnt]# vncserverYou will require a password to access your desktops.Password:Verify:New ‘centos6.xman.org:1 (root)’ desktop is centos6.xman.org:1Creating default startup script /root/.vnc/xstartupStarting applications specified in /root/.vnc/xstartupLog file is /root/.vnc/centos6.xman.org:1.log

可以看到已经生成了一个desktop：centos6.xman.org:1
为了方便，可见将vncserver添加到开机启动的服务中，使用setup-&gt;System services, 选择vncserver保存即可
接下来在VNC客户端输入上面的desktop就可以连接上Linux的desktop，如果发现连接不上，有可能是下面两个原因导致的：
(1) 本地windows的hosts文件中没有配置远程Linux的hostname，解决方案也很简单，只需要将desktop的hostname替换为IP地址或者在本地windows的hosts文件中添加相应的hostname与IP的映射关系即可
(2) 是由于Linux的防火墙阻止了，这时我们可以选择关闭防火墙或者将VNC的服务端口加入到Linux防火墙的信任列表
关闭防火墙# /sbin/service iptables stop
]]></content>
      <categories>
        <category>Linux</category>
        <category>CentOS</category>
      </categories>
      <tags>
        <tag>rpm</tag>
        <tag>yum</tag>
        <tag>Linux</tag>
        <tag>centos</tag>
        <tag>vnc</tag>
        <tag>RealVNC</tag>
        <tag>grep</tag>
        <tag>tigervnc</tag>
        <tag>vncserver</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux centos自动挂载ntfs</title>
    <url>/2011/10/31/linux-centos-mount-ntfs/</url>
    <content><![CDATA[centos自动挂载ntfsCentOS内核没有添加对ntfs的支持，所以我们需要安装ntfs-3g和fuse，这个有详细的介绍。安装完成后我们就可以使用mount –t ntfs-3g来对U盘或者移动硬盘进行挂载了。
那我们能不能对其进行自动挂载呢，这里涉及到每次插入不同的盘，可能出现的盘符不相同，所以在fstab中不能写这些东西，当然，双系统是另外一回事了。
解决方法如下：
用root权限建立/sbin/mount.ntfs文件，内容如下：
#!/bin/shexport LANG=en_US.UTF-8exec /sbin/mount.ntfs-3g "$@"

给/sbin/mount.ntfs文件可执行权限
chmod a+x /sbin/mount.ntfs

保存后重新插入移动硬盘
PS：这个针对CentOS系统，对于直接支持ntfs的Fedora和Ubuntu等发行版不适用。
]]></content>
      <categories>
        <category>Linux</category>
        <category>CentOS</category>
        <category>Fedora</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>centos</tag>
        <tag>ntfs</tag>
      </tags>
  </entry>
  <entry>
    <title>Centos问题集锦</title>
    <url>/2013/12/04/linux-centos-troubleshooting/</url>
    <content><![CDATA[CentOS 问题集锦rpm相关rpm删除出现”error: %preun( ) scriptlet failed, exit status 1解决方法
今天删除软件的时候报了下面的这个错误：错误提示是：error: %preun(xxxxxx) scriptlet failed, exit status 1
最后在网上找到一个办法，就是加 –noscripts 标记来删除RPM。 –noscripts 相当于 -nopre -nopost  -nopreun -nopostun。即卸载命令变为：
$rpm -e –noscripts xxxxxx

若要查看与RPM关联的scripts，使用-script查询RPM包。
＄rpm -q -scripts package
卸载时，若系统里有同一程序的多个安装版本要一起删除，可使用-allmatches标记，如
＄ rpm -e –noscripts -allmatches xxxxxx
]]></content>
      <categories>
        <category>Linux</category>
        <category>CentOS</category>
      </categories>
      <tags>
        <tag>rpm</tag>
        <tag>linux</tag>
        <tag>centos</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux CentOS的版本</title>
    <url>/2018/06/06/linux-centos-version/</url>
    <content><![CDATA[快速确定CentOS/RHEL的系统版本你是否清楚的知道目前你使用的CentOS/RHEL的系统版本呢？
或许你认为系统版本对你而言不是很重要，不过如果涉及到bug修改，驱动支持，软件配置的问题，你就需要很清楚的知道到底属于哪个发行版，内核版本是多少了。
对于系统管理员这个问题可能比较简单，如果你是个小白，给你提供几个方法来快速确定吧。
uname命令$ uname -or3.10.0-693.17.1.el7.x86_64 GNU/Linux$ uname -a Linux local 3.10.0-693.17.1.el7.x86_64 #1 SMP Thu Jan 25 20:13:58 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux


$uname$主要用于打印系统的信息，其中$-a$表示打印所有信息，$-or$表示打印操作系统和内核版本信息。

RPM命令$RPM$为$Red\ Hat\ Package\ Manager$的缩写，是类Redhat系统普遍使用的软件包管理程序，我们可以使用它来确定CentOS/RHEL的发行版本。
$rpm --query centos-release/redhat-releasecentos-release-7-4.1708.el7.centos.x86_64

hostnamectl命令$ hostnamectl   Static hostname: local         Icon name: computer-server           Chassis: server        Machine ID: xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx           Boot ID: xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx  Operating System: CentOS Linux 7 (Core)       CPE OS Name: cpe:/o:centos:centos:7            Kernel: Linux 3.10.0-693.17.1.el7.x86_64      Architecture: x86-64

lsb_release命令lsb_release命令显示一些$LSB$ （Linux Standard Base）和发行信息。
如果这个命令找不到，可能需要安装一下yum install redhat-lsb。
$ lsb_release -dDescription:	CentOS Linux release 7.4.1708 (Core)

通过查看系统文件上面的一些命令都是通过检索系统的一些信息来得到，我们也可以通过系统本身的文件直接获取，如下所示：
$ cat /etc/centos-releaseCentOS Linux release 7.4.1708 (Core) $ cat /etc/system-releaseCentOS Linux release 7.4.1708 (Core) $ cat /etc/os-release NAME="CentOS Linux"VERSION="7 (Core)"ID="centos"ID_LIKE="rhel fedora"VERSION_ID="7"PRETTY_NAME="CentOS Linux 7 (Core)"ANSI_COLOR="0;31"CPE_NAME="cpe:/o:centos:centos:7"HOME_URL="https://www.centos.org/"BUG_REPORT_URL="https://bugs.centos.org/"CENTOS_MANTISBT_PROJECT="CentOS-7"CENTOS_MANTISBT_PROJECT_VERSION="7"REDHAT_SUPPORT_PRODUCT="centos"REDHAT_SUPPORT_PRODUCT_VERSION="7"

]]></content>
      <categories>
        <category>Linux</category>
        <category>CentOS</category>
        <category>RedHat</category>
      </categories>
      <tags>
        <tag>rpm</tag>
        <tag>linux</tag>
        <tag>centos</tag>
        <tag>redhat</tag>
        <tag>uname</tag>
        <tag>hostnamectl</tag>
        <tag>lsb_release</tag>
        <tag>centos-release</tag>
        <tag>os-release</tag>
      </tags>
  </entry>
  <entry>
    <title>solved - RPMDB altered outside of yum</title>
    <url>/2014/01/21/linux-centos-yum-rpmdb/</url>
    <content><![CDATA[solved : RPMDB altered outside of yum在使用yum的时候报的错误，解决方法为：
yum history sync

主要是将我们rpmdb和yumdb进行同步一下，注意，这个过程根据你的机器情况和安装软件包的数量可能会小小的需要一段时间。
Refer：

https://access.redhat.com/site/documentation/en-US/Red_Hat_Enterprise_Linux/7-Beta/html/System_Administrators_Guide/sect-Yum-Transaction_History.html

5.4. Working with Transaction History
The yum history command allows users to review information about a timeline of Yum transactions, the dates and times they occurred, the number of packages affected, whether transactions succeeded or were aborted, and if the RPM database was changed between transactions. Additionally, this command can be used to undo or redo certain transactions. All history data are stored in the history DB in the var/lib/yum/history/ directory.
5.4.1. Listing Transactions
To display a list of twenty most recent transactions, as root, either run yum history with no additional arguments, or type the following at a shell prompt:
yum history list
To display all transactions, add the all keyword:
yum history list all
To display only transactions in a given range, use the command in the following form:
yum history list start_id..end_id
You can also list only transactions regarding a particular package or packages. To do so, use the command with a package name or a glob expression:
yum history list glob_expression…
Example 5.18. Listing the five oldest transactions
In the output of yum history list, the most recent transaction is displayed at the top of the list. To display information about the five oldest transactions stored in the history data base, type:
~]# yum history list 1..5
Loaded plugins: product-id, refresh-packagekit, subscription-manager
ID     | Login user               | Date and time    | Action(s)      | Altered
——————————————————————————-
 5 | Jaromir … &lt;jhradilek&gt;  | 2013-07-29 15:33 | Install        |    1

 4 | Jaromir … &lt;jhradilek&gt;  | 2013-07-21 15:10 | Install        |    1

 3 | Jaromir … &lt;jhradilek&gt;  | 2013-07-16 15:27 | I, U           |   73

 2 | System &lt;unset&gt;           | 2013-07-16 15:19 | Update         |    1

 1 | System &lt;unset&gt;           | 2013-07-16 14:38 | Install        | 1106

history list
All forms of the yum history list command produce tabular output with each row consisting of the following columns:
ID — an integer value that identifies a particular transaction.
Login user — the name of the user whose login session was used to initiate a transaction. This information is typically presented in the Full Name  form. For transactions that were not issued by a user (such as an automatic system update), System  is used instead.
Date and time — the date and time when a transaction was issued.
Action(s) — a list of actions that were performed during a transaction as described in Table 5.1, “Possible values of the Action(s) field”.
Altered — the number of packages that were affected by a transaction, possibly followed by additional information as described in Table 5.2, “Possible values of the Altered field”.
Table 5.1. Possible values of the Action(s) field
Action   Abbreviation   Description
Downgrade D    At least one package has been downgraded to an older version.
Erase    E     At least one package has been removed.
Install    I      At least one new package has been installed.
Obsoleting  O    At least one package has been marked as obsolete.
Reinstall      R     At least one package has been reinstalled.
Update U    At least one package has been updated to a newer version.
Table 5.2. Possible values of the Altered field
Symbol Description
&lt;     Before the transaction finished, the rpmdb database was changed outside Yum.

After the transaction finished, the rpmdb database was changed outside Yum.



The transaction failed to finish.



The transaction finished successfully, but yum returned a non-zero exit code.E     The transaction finished successfully, but an error or a warning was displayed.
P     The transaction finished successfully, but problems already existed in the rpmdb database.
s     The transaction finished successfully, but the –skip-broken command line option was used and certain packages were skipped.
To synchronize the rpmdb or yumdb database contents for any installed package with the currently used rpmdb or yumdb database, type the following:
yum history sync
To display some overall statistics about the currently used history DB use the following command:
yum history stats
Example 5.19. Example output of yum history stats
~]# yum history stats
Loaded plugins: langpacks, presto, refresh-packagekit
File        : //var/lib/yum/history/history-2012-08-15.sqlite
Size        : 2,766,848
Transactions: 41
Begin time  : Wed Aug 15 16:18:25 2012
End time    : Wed Feb 27 14:52:30 2013
Counts      :
  NEVRAC :  2,204
  NEVRA  :  2,204
  NA     :  1,759
  NEVR   :  2,204
  rpm DB :  2,204
  yum DB :  2,204
history stats
Yum also allows you to display a summary of all past transactions. To do so, run the command in the following form as root:
yum history summary
To display only transactions in a given range, type:
yum history summary start_id..end_id
Similarly to the yum history list command, you can also display a summary of transactions regarding a certain package or packages by supplying a package name or a glob expression:
yum history summary glob_expression…
Example 5.20. Summary of the five latest transactions
~]# yum history summary 1..5
Loaded plugins: product-id, refresh-packagekit, subscription-manager
Login user                 | Time                | Action(s)        | Altered
——————————————————————————-
Jaromir …     | Last day            | Install          |        1
Jaromir …     | Last week           | Install          |        1
Jaromir …     | Last 2 weeks        | I, U             |       73
System              | Last 2 weeks        | I, U             |     1107
history summary
All forms of the yum history summary command produce simplified tabular output similar to the output of yum history list.
As shown above, both yum history list and yum history summary are oriented towards transactions, and although they allow you to display only transactions related to a given package or packages, they lack important details, such as package versions. To list transactions from the perspective of a package, run the following command as root:
yum history package-list glob_expression…
Example 5.21. Tracing the history of a package
For example, to trace the history of subscription-manager and related packages, type the following at a shell prompt:
~]# yum history package-list subscription-manager*
Loaded plugins: product-id, refresh-packagekit, subscription-manager
ID     | Action(s)      | Package
——————————————————————————-
 3 | Updated        | subscription-manager-0.95.11-1.el6.x86_64

 3 | Update         |                      0.95.17-1.el6_1.x86_64

 3 | Updated        | subscription-manager-firstboot-0.95.11-1.el6.x86_64

 3 | Update         |                                0.95.17-1.el6_1.x86_64

 3 | Updated        | subscription-manager-gnome-0.95.11-1.el6.x86_64

 3 | Update         |                            0.95.17-1.el6_1.x86_64

 1 | Install        | subscription-manager-0.95.11-1.el6.x86_64

 1 | Install        | subscription-manager-firstboot-0.95.11-1.el6.x86_64

 1 | Install        | subscription-manager-gnome-0.95.11-1.el6.x86_64

history package-list
In this example, three packages were installed during the initial system installation: subscription-manager, subscription-manager-firstboot, and subscription-manager-gnome. In the third transaction, all these packages were updated from version 0.95.11 to version 0.95.17.
5.4.2. Examining Transactions
To display the summary of a single transaction, as root, use the yum history summary command in the following form:
yum history summary id
To examine a particular transaction or transactions in more detail, run the following command as root:
yum history info id…
The id argument is optional and when you omit it, yum automatically uses the last transaction. Note that when specifying more than one transaction, you can also use a range:
yum history info start_id..end_id
Example 5.22. Example output of yum history info
The following is sample output for two transactions, each installing one new package:
~]# yum history info 4..5
Loaded plugins: product-id, refresh-packagekit, subscription-manager
Transaction ID : 4..5
Begin time     : Thu Jul 21 15:10:46 2011
Begin rpmdb    : 1107:0c67c32219c199f92ed8da7572b4c6df64eacd3a
End time       :            15:33:15 2011 (22 minutes)
End rpmdb      : 1109:1171025bd9b6b5f8db30d063598f590f1c1f3242
User           : Jaromir Hradilek 
Return-Code    : Success
Command Line   : install screen
Command Line   : install yum-plugin-fs-snapshot
Transaction performed with:
Installed     rpm-4.8.0-16.el6.x86_64

Installed     yum-3.2.29-17.el6.noarch

Installed     yum-metadata-parser-1.1.2-16.el6.x86_64

Packages Altered:
Install screen-4.0.3-16.el6.x86_64

Install yum-plugin-fs-snapshot-1.1.30-6.el6.noarch

history info
You can also view additional information, such as what configuration options were used at the time of the transaction, or from what repository and why were certain packages installed. To determine what additional information is available for a certain transaction, type the following at a shell prompt as root:
yum history addon-info id
Similarly to yum history info, when no id is provided, yum automatically uses the latest transaction. Another way to refer to the latest transaction is to use the last keyword:
yum history addon-info last
Example 5.23. Example output of yum history addon-info
For the fourth transaction in the history, the yum history addon-info command provides the following output:
~]# yum history addon-info 4
Loaded plugins: product-id, refresh-packagekit, subscription-manager
Transaction ID: 4
Available additional history information:
  config-main
  config-repos
  saved_tx
history addon-info
In the output of the yum history addon-info command, three types of information are available:
config-main — global Yum options that were in use during the transaction. Refer to Section 5.5.1, “Setting [main] Options” for information on how to change global options.
config-repos — options for individual Yum repositories. Refer to Section 5.5.2, “Setting [repository] Options” for information on how to change options for individual repositories.
saved_tx — the data that can be used by the yum load-transaction command in order to repeat the transaction on another machine (see below).
To display selected type of additional information, run the following command as root:
yum history addon-info id information
5.4.3. Reverting and Repeating Transactions
Apart from reviewing the transaction history, the yum history command provides means to revert or repeat a selected transaction. To revert a transaction, type the following at a shell prompt as root:
yum history undo id
To repeat a particular transaction, as root, run the following command:
yum history redo id
Both commands also accept the last keyword to undo or repeat the latest transaction.
Note that both yum history undo and yum history redo commands only revert or repeat the steps that were performed during a transaction. If the transaction installed a new package, the yum history undo command will uninstall it, and if the transaction uninstalled a package the command will again install it. This command also attempts to downgrade all updated packages to their previous version, if these older packages are still available. If you need to restore the system to the state before an update, consider using the fs-snapshot plug-in described in Section 5.6.3, “Working with Plug-ins”.
When managing several identical systems, Yum also allows you to perform a transaction on one of them, store the transaction details in a file, and after a period of testing, repeat the same transaction on the remaining systems as well. To store the transaction details to a file, type the following at a shell prompt as root:
yum -q history addon-info id saved_tx &gt; file_name
Once you copy this file to the target system, you can repeat the transaction by using the following command as root:
yum load-transaction file_name
You can configure load-transaction to ignore missing packages or rpmdb version. For more information on these configuration options see the yum.conf man page.
5.4.4. Starting New Transaction History
Yum stores the transaction history in a single SQLite database file. To start new transaction history, run the following command as root:
yum history new
This will create a new, empty database file in the /var/lib/yum/history/ directory. The old transaction history will be kept, but will not be accessible as long as a newer database file is present in the directory.
]]></content>
      <categories>
        <category>CentOS</category>
        <category>Fedora</category>
      </categories>
      <tags>
        <tag>yum</tag>
        <tag>centos</tag>
        <tag>redhat</tag>
        <tag>fedora</tag>
        <tag>rpmdb</tag>
        <tag>yumdb</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux CentOS下查看. 更新. 删除yum安装包</title>
    <url>/2016/10/31/linux-centos-yum/</url>
    <content><![CDATA[Linux CentOS下查看. 更新. 删除yum安装包查看CentOS下安装了哪些yum软件包，查看指定包是否有安装，查看已安装包详细说明信息. 更新软件包. 删除软件包等常用操作

查找指定软件包

$ yum search softwate_package_name


列出所有可安装的软件包

$ yum list


列出所有可更新的软件包

$ yum list updates


列出所有已安装的软件包

$ yum list installed


列出所有已安装但不在Yum Repository软件包资源库内的软件包

$ yum list extras

列出指定的软件包安装信息

$ yum list software_package_name


查看软件包说明信息

$ yum info software_package_name

查看所有软件包说明信息

这个太没有意义了也，就算列出来也是懒得看，实在太多了
$ yum info


更新软件包

$ yum update software_package_name


更新系统

$ yum update


卸载软件包

$ yum remove software_package_name

关于yum警告“警告：RPM 数据库已被非 yum 程序修改这个警告主要因为对一些软件的操作，没有使用yum，比如直接rpm卸载造成的。
至于上面的警告的问题，不必太过惊慌。
主要因为yum的新特征是要成为系统中用户对程序进行管理的接口，这要求yum知道系统中所有的对软件包的操作（yum history）。如果你会用到但不仅只用到yum的话，又不喜欢看到这个警告，你可以去“yum.conf”里把“history_record”设置为“false”。
参考https://www.cnblogs.com/HermitCarb/p/4759413.html
]]></content>
      <categories>
        <category>Linux</category>
        <category>CentOS</category>
        <category>Fedora</category>
      </categories>
      <tags>
        <tag>yum</tag>
        <tag>linux</tag>
        <tag>centos</tag>
      </tags>
  </entry>
  <entry>
    <title>CentOS 7 安装配置Docker-CE</title>
    <url>/2016/11/30/linux-centos7-install-docker/</url>
    <content><![CDATA[CentOS 7 中 Docker 的安装以前的版本可能为docker-io或者docker，版本比较旧，现在已经更新到docker-ce和docker-ee了。
卸载旧版本$ sudo yum remove docker docker-common docker-selinux container-selinux docker-engine

安装所需包$ sudo yum install yum-utils device-mapper-persistent-data lvm2

配置更新源$ sudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo

&lt;可选&gt;使能edge与test版本$ sudo yum-config-manager --enable docker-ce-edge$ sudo yum-config-manager --enable docker-ce-test



更新缓存$ sudo yum makecache fast

安装$ sudo yum intall docker-ce

开启docker$ sudo systemctl start docker.service$ sudo systemctl enable docker.service

]]></content>
      <categories>
        <category>Linux</category>
        <category>CentOS</category>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>yum</tag>
        <tag>docker</tag>
        <tag>centos</tag>
        <tag>yum-utils</tag>
        <tag>makecache</tag>
        <tag>systemctl</tag>
      </tags>
  </entry>
  <entry>
    <title>CentOS7安装gitlab-ce</title>
    <url>/2017/05/06/linux-centos7-install-gitlab-ce/</url>
    <content><![CDATA[CentOS7安装gitlab-ce安装配置相关依赖在系统防火墙中打开HTTP和SSH。
sudo yum install curl policycoreutils openssh-server openssh-clients -ysudo systemctl enable sshdsudo systemctl start sshdsudo yum install postfixsudo systemctl enable postfixsudo systemctl start postfixsudo firewall-cmd --permanent --add-service=httpsudo systemctl reload firewalld

添加GitLab包服务器并安装curl -sS https://packages.gitlab.com/install/repositories/gitlab/gitlab-ce/script.rpm.sh | sudo bashsudo yum install gitlab-ce -y

也可以下载软件包然后安装
curl -LJO https://packages.gitlab.com/gitlab/gitlab-ce/packages/el/7/gitlab-ce-XXX.rpm/downloadrpm -i gitlab-ce-XXX.rpm

清华镜像如果这版本不能下载，可以考虑清华版本，
新建/etc/yum.repos.d/gitlab-ce.repo
[gitlab-ce]name=Gitlab CE Repositorybaseurl=https://mirrors.tuna.tsinghua.edu.cn/gitlab-ce/yum/el$releasever/gpgcheck=0enabled=1

sudo yum makecachesudo yum install gitlab-ce

配置并启动GitLabsudo gitlab-ctl reconfigure

浏览并登陆此时就可以设置用户名和密码了。
Enjoy!!!
]]></content>
      <categories>
        <category>Linux</category>
        <category>CentOS</category>
        <category>GitLab</category>
      </categories>
      <tags>
        <tag>gitlab</tag>
        <tag>centos</tag>
        <tag>systemctl</tag>
        <tag>ce</tag>
        <tag>curl</tag>
        <tag>openssh</tag>
        <tag>sshd</tag>
        <tag>postfix</tag>
        <tag>firewalld</tag>
      </tags>
  </entry>
  <entry>
    <title>CentOS7升级gitlab-ce</title>
    <url>/2018/05/06/linux-centos7-update-gitlab-ce/</url>
    <content><![CDATA[备份升级sudo gitlab-rake gitlab:backup:create STRATEGY=copy  sudo yum install -y gitlab-ce

如果是从8.12的版本进行升级，首先需要升级到8.17.7
sudo yum install gitlab-ce-8.17.7# 此时就可以升级到最新的release版本了sudo yum install gitlab-ce-10.0.0sudo yum install gitlab-ce-11.0.0#sudo yum install gitlab-ce-12.0.0#sudo yum install gitlab-ce-13.0.0sudo yum install -y gitlab-ce

配置并启动GitLabsudo gitlab-ctl reconfiguresudo gitlab-ctl restart# 偶尔提示需要升级数据库sudo gitlab-ctl pg-upgrade

浏览并登陆此时就可以设置用户名和密码了。
Enjoy!!!
]]></content>
      <categories>
        <category>Linux</category>
        <category>CentOS</category>
        <category>GitLab</category>
      </categories>
      <tags>
        <tag>gitlab</tag>
        <tag>centos</tag>
      </tags>
  </entry>
  <entry>
    <title>更改linux的MAC地址</title>
    <url>/2014/01/20/linux-change-mac-address/</url>
    <content><![CDATA[更改linux的MAC地址执行下列命令，重启后失效：/sbin/ifconfig eth0 down/sbin/ifconfig eth0 hw ether 00:11:22:33:44:55/sbin/ifconfig eth0 upservice network restart


永久更改的方法：vi /etc/sysconfig/network-scripts/ifcfg-eth0

 添加MACADDR=00:11:22:33:44:55
 注释掉原来的HWADDR
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>service</tag>
        <tag>linux</tag>
        <tag>ifconfig</tag>
        <tag>ifup</tag>
        <tag>ifdown</tag>
        <tag>mac</tag>
      </tags>
  </entry>
  <entry>
    <title>有所依靠的chgrp</title>
    <url>/2014/01/20/linux-chgrp-beginner/</url>
    <content><![CDATA[有所依靠的chgrp.. _linux_chgrp_beginner:
.. code::  鸿鹄志、向炎天。  宋 刘克庄《贺新郎·杜子昕凯歌》
Linux的chgrp命令用于变更文件或者目录所属的组group。
这里的变更不仅限于本人的组，只要用户属于的组，均可以使用chgrp更改相应的权限而不是必须使用管理员权限。
很多权限的操作可以与chmod来交叉。比如如果希望文件只有本组成员访问，可以通过chmod 770 file/directory，此时就涉及到组的概念了。
官方定义为：

chgrp - change group ownership

语法为：
$ chgrp [OPTION]... GROUP FILE...$ chgrp [OPTION]... --reference=RFILE FILE...



常用的几个参数为：

--reference=RFILE : 参考指定文件进行所属组更换

-R, --recursive ：递归处理，将某个目录的所有文件均更改用户组


默认用法最简单的使用为将文件file归属到组group，使用方法为：
$ chgrp group file$ chgrp group1 file1

此时的file数组组group，file1属于组group1。
更改文件夹的所属组对于文件夹而言，就需要使用-R参数来递归实现了，不然会报错的。
$ chgrp -R group1 directory1$ chgrp -R group2 directory2



根据指定文件来修改组这个参数比较有趣，也比较高效，如果希望某个用户的组权限与另外一个文件一致，此时--reference强势出现
$ chgrp --reference=ref_file stage_file

该命令执行后，stage_file的权限将与ref_file的组权限一样。
]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>groupadd</tag>
        <tag>usermod</tag>
        <tag>chgrp</tag>
        <tag>chmod</tag>
      </tags>
  </entry>
  <entry>
    <title>不明所以的core文件，就这样出现了</title>
    <url>/2020/08/27/linux-chgrp/</url>
    <content><![CDATA[chgrp高级设置SGID属性（确保NEWGROUP组拥有所有新建的文件），设置sticky(沾滞位)属性（以免文件被拥有者以外的其他人删除）
$ chmod g+s,o+t /home/groupdir

具体参考SGID/SUID/SBID以及sticky的详细含义。
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>groupadd</tag>
        <tag>usermod</tag>
        <tag>chgrp</tag>
        <tag>chmod</tag>
        <tag>Linux进阶</tag>
      </tags>
  </entry>
  <entry>
    <title>你或他是否可读写  chmod</title>
    <url>/2011/02/12/linux-chmod-beginner/</url>
    <content><![CDATA[你或他是否可读写执行的  chmod.. _linux_chmod_beginner:
文件权限指的是文件是否可以执行、写入、读取等操作。
该命令官方定义为：

chmod - change mode

所以可以通过chmod来控制文件如何被他人所存取。
而Linux/Unix的文件存取权限分为三级 : 文件所有者、用户组及其他，分别使用以下字母来表示：

u：所有者
g：用户组
o：其他用户

如下图所示，每个级别都可以设置为rwx三种权限 。

使用语法使用的语法如下所示：
$ chmod [-cfvR] [--help] [--version] mode file...



其中mode权限设定的格式如下 : [ugoa] [+-=] [rwxX]
其中u表示该文件的拥有者，g表示与该文件的拥有者属于同一个群体(group)者，o表示其他以外的人，a表示这三者皆是。

+ 表示加权限、– 表示减权限、= 表示设定唯一权限。
r 表示可读取，w 表示可写入，x 表示可执行，X 表示只有当该文件是个子目录或者该文件已经被设定过为可执行。
-R : 对目前目录下的所有文件与子目录进行相同的权限变更(即以递回的方式逐个变更)


对于chmod的使用而言，只有文件所有者和超级用户可以修改文件或目录的权限。

具体的方法为可以使用符号模式或者绝对模式来进行操作。
而我比较喜欢用的是绝对数字模式，粗暴简单易理解。
符号模式使用符号模式需要考虑多个因素，其中包括用户类型，操作符 和设定权限。



who
用户类型
说明



u
user
文件所有者


g
group
文件所有者所在组


o
others
所有其他用户


a
all
所用用户, 相当于 ugo


operator 的符号模式表:



Operator
说明



+
为指定的用户类型增加权限


-
去除指定用户类型的权限


=
设置指定用户权限的设置，即将用户类型的所有权限重新设置


permission 的符号模式表:



模式
名字
说明



r
读
设置为可读权限


w
写
设置为可写权限


x
执行权限
设置为可执行权限


绝对数字模式chmod命令可以使用八进制数来指定权限。文件或目录的权限位是由9个权限位来控制，每三位为一组，它们分别是文件所有者的读、写、执行权限，用户组的读、写、执行以及其它用户的读、写、执行。
历史上，文件权限被放在一个比特掩码中，掩码中指定的比特位设为1，用来说明一个类具有相应的优先级。比如下面的0-7分别表示各自的权限定义。



No
权限
rwx
二进制



7
读 + 写 + 执行
rwx
111


6
读 + 写
rw-
110


5
读 + 执行
r-x
101


4
只读
r–
100


3
写 + 执行
-wx
011


2
只写
-w-
010


1
只执行
–x
001


0
无
—
000


如表所示：

对于7而言就表示所有者的权限为可读、可写、可执行，也就是对应的八进制为111，所以就是7；
而对于 5而言，表示所有者的权限为可读、可执行，对应的八进制为101，所以就是5；

其他类似。
实例更改为全部可读接下来将文件 a.c 设为所有人皆可读取 ，有三种方式可以使用，如下，分别为 ：

chmod ugo+r filename
chmod a+r filename
chmod 444 filename

具体如下所示：
通过方法1：
# 默认设定为没有任何属性$ ll----------  1 user  user     5KB  Feb  12 22:22 a.c# 更改为全部可读$ chmod ugo+r file1.txt$ ll-r--r--r--  1 user  user     5KB  Feb  12 22:22 a.c



通过方法2：
# 默认设定为没有任何属性$ ll----------  1 user  user     5KB  Feb  12 22:23 a.c# 更改为全部可读$ chmod a+r file1.txt$ ll-r--r--r--  1 user  user     5KB  Feb  12 22:23 a.c



通过方法3：
# 默认设定为没有任何属性$ ll----------  1 user  user     5KB  Feb  12 22:23 a.c# 更改为全部可读$ chmod 444 file1.txt$ ll-r--r--r--  1 user  user     5KB  Feb  12 22:24 a.c



设置用户及组可读写，其他用户无法写入但可以查看接下来继续把文件 a.c设置为用户 和组可以读写，而其他 用户无法写入但是 可以查看 。
使用符号模式如下：
$ ll-r--r--r--  1 user  user     5KB  Feb  12 22:24 a.c$ chmod ug+rw,o+r,o-w a.c$ ll-rw-rw-r--  1 user  user     5KB  Feb  12 22:26 a.c



使用数字模式如下：
$ ll-r--r--r--  1 user  user     5KB  Feb  12 22:24 b.c$ chmod 664 a.c$ ll-rw-rw-r--  1 user  user     5KB  Feb  12 22:26 b.c



设定为所有人只有可执行权限此时不管文件的权限是什么，因为只具有可执行权限，所以符号模式可以使用**=**，而数字模式只需要1即可，如下：
$ chmod a=x filename#或者$ chmod 111 filename# 无法读取$ cat a.c cat: a.c: Permission denied

所以对于只有可执行权限的文件，是无法执行读取或者写入操作的，这也保证了文件的安全性。
]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>Linux炫技</tag>
        <tag>chmod</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux的 chmod 命令</title>
    <url>/2011/02/12/linux-chmod/</url>
    <content><![CDATA[文件权限设置命令 chmod文件权限指的是文件是否可以执行、写入、读取等操作。
而Linux/Unix的文件存取权限分为三级 : 文件所有者、用户组及其他，分别使用以下字母来表示：

u：所有者
g：用户组
o：其他用户

如下图所示，每个级别都可以设置为rwx三种权限 。

改命令官方的解释为：

change mode

所以可以通过chmod来控制文件如何被他人所存取。
使用的语法如下所示：
$ chmod [-cfvR] [--help] [--version] mode file...



其中mode权限设定的格式如下 : [ugoa] [+-=] [rwxX]
其中u表示该文件的拥有者，g表示与该文件的拥有者属于同一个群体(group)者，o表示其他以外的人，a表示这三者皆是。

+ 表示加权限、– 表示减权限、= 表示设定唯一权限。
r 表示可读取，w 表示可写入，x 表示可执行，X 表示只有当该文件是个子目录或者该文件已经被设定过为可执行。
-R : 对目前目录下的所有文件与子目录进行相同的权限变更(即以递回的方式逐个变更)


对于chmod的使用而言，只有文件所有者和超级用户可以修改文件或目录的权限。

具体的方法为可以使用符号模式或者绝对模式来进行操作。
而我比较喜欢用的是绝对数字模式，比较粗暴简单。
符号模式使用符号模式需要考虑多个因素，其中包括用户类型，操作符 和设定权限。



who
用户类型
说明



u
user
文件所有者


g
group
文件所有者所在组


o
others
所有其他用户


a
all
所用用户, 相当于 ugo


operator 的符号模式表:



Operator
说明



+
为指定的用户类型增加权限


-
去除指定用户类型的权限


=
设置指定用户权限的设置，即将用户类型的所有权限重新设置


permission 的符号模式表:



模式
名字
说明



r
读
设置为可读权限


w
写
设置为可写权限


x
执行权限
设置为可执行权限


绝对数字模式chmod命令可以使用八进制数来指定权限。文件或目录的权限位是由9个权限位来控制，每三位为一组，它们分别是文件所有者的读、写、执行权限，用户组的读、写、执行以及其它用户的读、写、执行。历史上，文件权限被放在一个比特掩码中，掩码中指定的比特位设为1，用来说明一个类具有相应的优先级。比如下面的0-7分别表示各自的权限定义。



No
权限
rwx
二进制



7
读 + 写 + 执行
rwx
111


6
读 + 写
rw-
110


5
读 + 执行
r-x
101


4
只读
r–
100


3
写 + 执行
-wx
011


2
只写
-w-
010


1
只执行
–x
001


0
无
—
000


如表所示：

对于7而言就表示所有者的权限为可读、可写、可执行，也就是对应的八进制为111，所以就是7；
而对于 5而言，表示所有者的权限为可读、可执行，对应的八进制为101，所以就是5；

其他类似。
实例更改为全部可读接下来将文件 a.c 设为所有人皆可读取 ，有三种方式可以使用，如下，分别为 ：

chmod ugo+r filename
chmod a+r filename
chmod 444 filename

具体如下所示：
通过方法1：
# 默认设定为没有任何属性$ ll----------  1 user  user     5KB  Feb  12 22:22 a.c# 更改为全部可读$ chmod ugo+r file1.txt$ ll-r--r--r--  1 user  user     5KB  Feb  12 22:22 a.c



通过方法2：
# 默认设定为没有任何属性$ ll----------  1 user  user     5KB  Feb  12 22:23 a.c# 更改为全部可读$ chmod a+r file1.txt$ ll-r--r--r--  1 user  user     5KB  Feb  12 22:23 a.c



通过方法3：
# 默认设定为没有任何属性$ ll----------  1 user  user     5KB  Feb  12 22:23 a.c# 更改为全部可读$ chmod 444 file1.txt$ ll-r--r--r--  1 user  user     5KB  Feb  12 22:24 a.c



设置用户及组可读写，其他用户无法写入但可以查看接下来继续把文件 a.c设置为用户 和组可以读写，而其他 用户无法写入但是 可以查看 。
使用符号模式如下：
$ ll-r--r--r--  1 user  user     5KB  Feb  12 22:24 a.c$ chmod ug+rw,o+r,o-w a.c$ ll-rw-rw-r--  1 user  user     5KB  Feb  12 22:26 a.c



使用数字模式如下：
$ ll-r--r--r--  1 user  user     5KB  Feb  12 22:24 b.c$ chmod 664 a.c$ ll-rw-rw-r--  1 user  user     5KB  Feb  12 22:26 b.c



设定为所有人只有可执行权限此时不管文件的权限是什么，因为只具有可执行权限，所以符号模式可以使用**=**，而数字模式只需要1即可，如下：
$ chmod a=x filename#或者$ chmod 111 filename# 无法读取$ cat a.c cat: a.c: Permission denied

所以对于只有可执行权限的文件，是无法执行读取或者写入操作的，这也保证了文件的安全性。
炫技 - TODO其实对于每个文件或者目录而言，除了rwx权限，还有 一个权限位，这个权限为一般为特殊权限。



模式
名字
说明



X
特殊执行权限
只有当文件为目录文件，或者其他类型的用户有可执行权限时，才将文件权限设置可执行


s
setuid/gid
当文件被执行时，根据who参数指定的用户类型设置文件的setuid或者setgid权限


t
粘贴位
设置粘贴位，只有超级用户可以设置该位，只有文件所有者u可以使用该位


若用 chmod 4755 filename 可使此程序具有 root 的权限。
更多说明


命令
说明



chmod 4755 *file*
4设置了设置用户ID位，剩下的相当于 u=rwx (4+2+1),go=rx (4+1 &amp; 4+1)。


find path/ -type d -exec chmod a-x {} \;
删除可执行权限对path/以及其所有的目录（不包括文件）的所有用户，使用’-type f’匹配文件


find path/ -type d -exec chmod a+x {} \;
允许所有用户浏览或通过目录path/


]]></content>
      <categories>
        <category>Linux</category>
        <category>Linux入门</category>
        <category>Linux炫技</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>chmod</tag>
      </tags>
  </entry>
  <entry>
    <title>极具归属感的 - chown</title>
    <url>/2014/01/20/linux-chown-beginner/</url>
    <content><![CDATA[极具归属感的 - chown.. _linux_chown_beginner:
.. note::  常记溪亭日暮，沉醉不知归路。  李清照《如梦令》
Linux chown 命令用于设置文件所有者和文件关联组的命令。
官方的定义为：

chown - change file owner and group

Linux/Unix 的有个理念就是一切皆文件，而对于每个文件也是如chmod所述，均拥有所有者。
此时就可以利用 chown 指定文件的拥有者或者指定的用户或组，用户可以是用户名或者用户 ID，组可以是组名或者组 ID，文件是以空格分开的要改变权限的文件列表，支持通配符。
不过需要注意的是 chown 需要超级用户 root 的权限才能执行此命令，或者使用sudo也可以。
使用语法使用语法如下：
$ chown [option] [user[:group]] file...# 或者$ chown [option] --reference=RFILE file...

其中user为新的文件拥有者的用户名或者ID，group为新的文件拥有者的用户组名或ID****。
并且可以通过--referenc=RFILE选项来设定希望修改的文件和目录。
其他的选项可以为： :

-c : 与-v类似，不过只显示更改的信息
-R : 递归地处理指定的目录以及其子目录下的所有文件

通用实例最简单的使用方式应该就是指定用户和用户组了，如下：
$ ll -rw-rw-r--. 1 user user 5 May   7 14:56 a$ sudo chown user1:group1 a$ ll -rw-rw-r--. 1 user1 group1 5 May   7 14:56 a

上面的命令将把a指定为用户user1，组group1。注意user1和group1必须存在，不然会提示无效的用户或者组。
更新组而不更新用户这个选项一般用在，希望把某个用户的文件共享到一个组，此时的方法如下：
$ sudo chown :newgroup filename

此时的用户所有者不变，而仅仅更改了文件所属组。
提示更新$ sudo chown -c user1 a b c dchanged ownership of "b" from user to user1changed ownership of "c" from user to user1changed ownership of "d" from user to user1$ sudo chown -v user1 a b c dchanged ownership of "a" from user to user1changed ownership of "b" from user to user1changed ownership of "c" from user to user1changed ownership of "d" from user to user1

从这个例子可以看出，对于-c和-v的区别，-v全部显示，而-c仅仅显示更新的部分。
递归处理文件或文件夹$ sudo chown -R user:group file directory

此条命令将递归地将文件file和目录directory及其子目录的文件更新为user用户拥有，group组拥有。
]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>groupadd</tag>
        <tag>usermod</tag>
        <tag>chown</tag>
        <tag>sudo</tag>
      </tags>
  </entry>
  <entry>
    <title>通过其他文件修改模式</title>
    <url>/2011/02/12/linux-chown-misc/</url>
    <content><![CDATA[通过其他文件修改模式如果有1个文件或文件夹的权限是你认为可以参考的，此时可以通过下面的命令直接指定，而不需要指定user:group这个参数了。如下两个命令效果一致：
$ ll -rw-rw-r--. 1 user1 group1 5 May   7 14:56 a-rw-rw-r--. 1 user2 group2 5 May   7 14:56 b# 将b的权限更改为与a一致# Method1$ sudo chown user1:group1 b# Method 2$ sudo chown --reference=a b]]></content>
      <categories>
        <category>Linux炫技</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>chown</tag>
      </tags>
  </entry>
  <entry>
    <title>linux 设置文件所有者命令 chmod</title>
    <url>/2014/01/20/linux-chown/</url>
    <content><![CDATA[Linux chown 命令Linux chown 命令用于设置文件所有者和文件关联组的命令。
官方的定义为：

chown - change file owner and group

Linux/Unix 的有个理念就是一切皆文件，而对于每个文件也是如chmod所述，均拥有所有者。
此时就可以利用 chown 指定文件的拥有者或者指定的用户或组，用户可以是用户名或者用户 ID，组可以是组名或者组 ID，文件是以空格分开的要改变权限的文件列表，支持通配符。
不过需要注意的是 chown 需要超级用户 root 的权限才能执行此命令，或者使用sudo也可以。
使用语法使用语法如下：
$ chown [option] [user[:group]] file...# 或者$ chown [option] --reference=RFILE file...

其中user为新的文件拥有者的用户名或者ID，group为新的文件拥有者的用户组名或ID****。
并且可以通过--referenc=RFILE选项来设定希望修改的文件和目录。
其他的选项可以为： :

-c : 与-v类似，不过只显示更改的信息
-R : 递归地处理指定的目录以及其子目录下的所有文件

通用实例最简单的使用方式应该就是指定用户和用户组了，如下：
$ ll -rw-rw-r--. 1 user user 5 May   7 14:56 a$ sudo chown user1:group1 a$ ll -rw-rw-r--. 1 user1 group1 5 May   7 14:56 a

上面的命令将把a指定为用户user1，组group1。注意user1和group1必须存在，不然会提示无效的用户或者组。
更新组而不更新用户这个选项一般用在，希望把某个用户的文件共享到一个组，此时的方法如下：
$ sudo chown :newgroup filename

此时的用户所有者不变，而仅仅更改了文件所属组。
提示更新$ sudo chown -c user1 a b c dchanged ownership of "b" from user to user1changed ownership of "c" from user to user1changed ownership of "d" from user to user1$ sudo chown -v user1 a b c dchanged ownership of "a" from user to user1changed ownership of "b" from user to user1changed ownership of "c" from user to user1changed ownership of "d" from user to user1

从这个例子可以看出，对于-c和-v的区别，-v全部显示，而-c仅仅显示更新的部分。
递归处理文件或文件夹$ sudo chown -R user:group file directory

此条命令将递归地将文件file和目录directory及其子目录的文件更新为user用户拥有，group组拥有。
炫技 - 通过其他文件指定如果有1个文件或文件夹的权限是你认为可以参考的，此时可以通过下面的命令直接指定，而不需要指定user:group这个参数了。如下两个命令效果一致：
$ ll -rw-rw-r--. 1 user1 group1 5 May   7 14:56 a-rw-rw-r--. 1 user2 group2 5 May   7 14:56 b# 将b的权限更改为与a一致# Method1$ sudo chown user1:group1 b# Method 2$ sudo chown --reference=a b



]]></content>
      <categories>
        <category>Linux</category>
        <category>Linux入门</category>
        <category>Linux炫技</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>groupadd</tag>
        <tag>usermod</tag>
        <tag>chown</tag>
        <tag>sudo</tag>
      </tags>
  </entry>
  <entry>
    <title>清空历史，忘掉从前 - clear</title>
    <url>/2019/05/07/linux-clear-beginner/</url>
    <content><![CDATA[清空历史，忘掉从前 - clear.. _linux_clear_beginner:
.. note::  造物无言却有情，每于寒尽觉春生。  张维屏《新雷》
没有啥说的，就是放空一下自己，也清空一下终端，仅此而已。
$ clear]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>clear</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux命令cmatrix</title>
    <url>/2011/02/12/linux-cmatrix-misc/</url>
    <content><![CDATA[进入数字的魔幻世界：探秘cmatrix来到黑客帝国的命令cmatrix，这不仅仅是一串字符在终端中的运动，它仿佛是数字的舞蹈，变幻着无穷的图案。从绿色的数字雨到模拟Matrix电影的效果，cmatrix让我们进入了数字的奇妙世界。

]]></content>
      <categories>
        <category>Linux炫技</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>cmatrix</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux 入门命令汇总</title>
    <url>/2023/10/08/linux-collection-advanced/</url>
    <content><![CDATA[Linux入门命令汇总从2021年8月19日开始分享以前陆陆续续汇总的一些小技巧，截止到今天（2021年11月29）为止，100天，100个技巧。
Bingo，第一个小汇总顺利完成。
从发送的顺序上来看，100个命令的链接如下所示，PDF汇总文件根据这个顺序，或者字母表顺序，或者分类顺序来进行阅读。具体参考公众号商店。

ls
cd
cat
file
less
more
whatis
apropos
man
mkdir
cp
mv
rm
rmdir
df
du
pwd
ln
chmod
chown
su
sudo
tail
head
free
touch
stat
ping
ifconfig
ip
wall
write
tracepath
date
useradd
userdel
passwd
tty
uname
whoami
who
w
id
top
dd
echo
kill
wget
ps
wc
last
time
find
scp
rsync
grep
uniq
sort
which
tar
history
alias
diff
curl
usermod
cal
sleep
nice–
halt–
login–
logname—
logout–
reboot–
arp–
xargs–
telnet—
netconfig–
nc—
minicom—
mesg—
netstat—
talk—
traceroute—
write—
tcpdump—
chgrp—
split—
join–
whereis—
get–
mcopy—
ftp—
fsck–
hdparm–
mkfs.xfs—
sync–
fdisk–
exit–
finger–
suspend–
groupdel–
groupmod–
rsh–
rlogin–
pstree–
screen–
chsh—-
whois—
skill—
groupadd—
reset–
clear–
bind–
chroot–
clock–
dmesg—
export—
rpm—
set—
resize—
setenv—
ulimit—
chkconfig—
unalias—
ar—
dump–
gzip–
zip—

而从分类来讲，主要包括了大概N个类别
文件管理类
ls
cat
file
less
more
tail
pwd
echo
ln
chmod
chown
chgrp—
split—

时间
date
cal

磁盘管理类
cd
df
du
mkdir
rmdir
pwd
stat
find

文档编辑类
grep
join–
sort
wc
uniq
diff

帮助类
whatis
apropos
man
which
whereis

文件传输类
cp
mv
scp
rsync
rcp—
mcopy—
ftp—
tftp—
ncftp—
ftpshut—
ftpwho–

磁盘维护类
dd
fsck–
hdparm–
mkfs.xfs—
sync–
fdisk–

文件传输
wget
curl

网络通信类
telnet—
netconfig–
nc—
ifconfig
ip
minicom—
wall
netstat—
ping
talk—
traceroute—
tty—
write
tcpdump—

系统管理类
adduser–
useradd
exit–
finger–
sleep
suspend–
groupdel–
groupmod–
kill
last
halt–
login–
logname—
logout–
ps
nice–
top
reboot–
rsh–
rlogin–
pstree–
screen–
shutdown–
sudo
uname
chsh—
userdel
usermod
who
whoami
whois—
su
skill—
w
id
groupadd—
free

系统设置类
reset–
clear–
alias
bind–
chroot–
clock–
crontab–
dmesg—
export—
rpm—
insmod—
lsmod—
set—
passwd
resize—
rmmod—
modinfo—
time—
setup—
setenv—
ulimit—
chkconfig—
hwclock—
unalias—

压缩备份类
ar
cpio–
dump–
gzip–
tar
zip—

炫技类
awk–
xargs–

其他
history


危险命令
rm
chmod
chown

]]></content>
      <categories>
        <category>Linux集锦</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Linux汇总</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux 入门命令汇总</title>
    <url>/2023/10/09/linux-collection-beginner/</url>
    <content><![CDATA[Linux入门命令汇总从2021年8月19日开始分享以前陆陆续续汇总的一些小技巧，截止到今天（2021年11月29）为止，100天，100个技巧。
Bingo，第一个小汇总顺利完成。
从发送的顺序上来看，100个命令的链接如下所示，PDF汇总文件根据这个顺序，或者字母表顺序，或者分类顺序来进行阅读。具体参考公众号商店。

ls
cd
cat
file
less
more
whatis
apropos
man
mkdir
cp
mv
rm
rmdir
df
du
pwd
ln
chmod
chown
su
sudo
tail
head
free
touch
stat
ping
ifconfig
ip
wall
write
tracepath
date
useradd
userdel
passwd
tty
uname
whoami
who
w
id
top
dd
echo
kill
wget
ps
wc
last
time
find
scp
rsync
grep
uniq
sort
which
tar
history
alias
diff
curl
usermod
cal
sleep
ssh
locate
split
hostname
lscpu
lspci
tr
tree
bc
pstree
tac
xargs
pgrep
pkill
env
chgrp
whereis
tee
nice
shutdown
reboot
poweroff
halt
fdisk
join
ulimit
traceroute
zip
unzip
login–
logname—
logout–
arp–
locatedb 
glob(3)
telnet—
netconfig–
nc—
minicom—
mesg—
netstat—
talk—
tcpdump—
get–
mcopy—
ftp—
fsck–
hdparm–
sync–
exit–
finger–
suspend–
rsh–
rlogin–
pstree–
screen–
chsh—-
whois—
skill—
reset–
clear–
bind–
chroot–
clock–
dmesg—
export—
rpm—
set—
resize—
setenv—
chkconfig—
unalias—
ar—
dump–
gzip–

而从分类来讲，主要包括了大概N个类别
文件管理类
ls
cat
tac
file
less
more
tail
pwd
echo
ln
chmod
chown
chgrp
tee

时间
date
cal

磁盘管理类
cd
df
du
mkdir
rmdir
pwd
stat
find
locate

文档编辑类
grep
join
sort
wc
uniq
diff
split
pgrep/pkill

帮助类
whatis
apropos
man
which
whereis

文件传输类
cp
mv
scp
rsync
rcp—
mcopy—
ftp—
tftp—
ncftp—
ftpshut—
ftpwho–

磁盘维护类
dd
fsck–
hdparm–
sync–


fio命令 – 对磁盘进行压力测试
lvscan命令 – 扫描LVM逻辑卷
parted命令 – 磁盘分区工具
partx命令 – 显示内核磁盘上分区情况
mkfs.ext4 命令 – 对磁盘设备进行Ext4格式化
vgchange命令 – 修改卷组属性
quotaon命令 – 激活Linux内核中指定文件系统的磁盘配额功能
lvextend命令 – 扩展逻辑卷设备
pvck命令 – 检测物理卷LVM元数据一致性
mdadm命令 – 管理RAID磁盘阵列组

文件传输
wget
curl

网络通信类
telnet—
netconfig–
nc–
minicom—
wall
netstat—
talk—
traceroute
tty—
write
tcpdump—

系统管理类
adduser–
useradd
exit–
finger–
sleep
suspend–
groupadd—
groupdel–
groupmod–
kill
last
halt
login–
logname—
logout–
ps
nice
top
reboot
poweroff
rsh–
rlogin–
pstree–
screen–
shutdown
sudo
uname
chsh—
userdel
usermod
who
whoami
whois—
su
skill—
w
id
free

系统设置类
reset–
clear–
alias
bind–
chroot–
clock–
crontab–
dmesg—
export—
rpm—
insmod—
lsmod—
set—
passwd
resize—
rmmod—
modinfo—
time—
setup—
setenv—
ulimit
chkconfig—
hwclock—
unalias—

压缩备份类
ar
cpio–
dump–
gzip–
tar
zip
unzip


zip命令 – 压缩文件
unzip命令 – 解压缩zip文件
zipinfo命令 – 查看压缩文件信息
gzip命令 – 压缩和解压文件
unarj命令 – 解压.arj文件

炫技类
awk–
xargs

炫技 - 快速执行上一条命令第一种方法：在终端输入两个感叹号，然后回车就可以快速地执行上一条命令了。
$ !!



其他
history
ssh
tree

危险命令
rm
chmod
chown
hostname
reboot
poweroff
halt
shutdown

硬件
lscpu
lspci
reboot
poweroff
halt
shutdown

]]></content>
      <categories>
        <category>Linux集锦</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Linux汇总</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux最危险的几个命令</title>
    <url>/2023/11/16/linux-collection-dangerous-commands/</url>
    <content><![CDATA[Linux最危险的几个命令
仅个人想法，会持续不间断更新和改进。

Linux系统中的命令最美妙也最危险。
如果几个操作系统（Windows/MacOSX/Linux）的危险水平有段位，那么Linux应该首当其冲。
如若使用不当，轻则伤筋动骨摔键盘，重则历年数据烟消云散。
本文本着大家熟悉其危险性，尽量避免一些误操作。
为什么Linux最危险呢？那主要是因为root 用户对系统具有绝对的操作权限，可以执行任何命令、任何操作，所以会产生任何后果。
所以在以 root 用户身份进行操作时，尤其一定要特别小心。
如果不确定命令的执行结果，可以在虚拟环境线操作一下，再在生产环境执行。
危险命令介绍如果单纯按照熟悉或者段位来讲，rm首当其冲，轻则丢点数据，重则系统崩溃。目前看到的很多删库跑路的程序员大多就因为这个。

 特别是rm -rf /，不要执行，不要执行，不要执行，重要的事情说三遍，这个命令会导致整个系统被毁坏

随后的应该就是chmod和chown，特别是对于重要的数据，一般建议对于新手而言，仅仅具备只读权限即可；
接下来的dd以及mkfs命令，可能不太常见，但是也具备一定的杀伤力。
fork炸弹暂且不表，总之随便来的命令不要随便执行。

风萧萧兮易水寒，壮士一去兮不复还的 rm 命令。

文件一旦通过rm命令删除，则无法恢复，所以必须格外一定切记小心地使用该命令。
因为发生过很多欲哭无泪的故事。。。
主要的痛点就在如果是在root账户权限下，rm无所不能呀

 Linux的 rm 命令
Linux 的 dd 命令dd这个命令一直没有弄明白缩写的含义，这个命令应该归到Linux炫技里面，因为我也是很晚才用到，不过有些功能还可以尝试一下。
官方含义为：

dd - convert and copy a file


从官方含义来看，是不是定义为cc比较合适，^_^

dd命令用于复制文件，转换或者格式化文件，这里也是危险所在，如果使用dd对设备进行低级别的复制和转换操作时，如果命令行参数错误，可能导致数据丢失。
比如 dd if=/dev/random of=/dev/sda：这个命令将设备（例如硬盘）的内容重写为随机数据，导致设备上所有数据的永久丢失。
mkfs 格式化硬盘分区万万不要制定了错误的硬盘，切记切记。
这个命令格式化的很彻底。
shutdown在root账户下，可以直接立即关闭系统，很容易造成数据没有保存，一般需要延迟个1分钟，不要使用shutdown -h now来立即关闭系统。
&gt; file&gt; file：这个命令会清空文件内容。若对关键的系统文件使用这个命令，可能会破坏系统。
]]></content>
      <categories>
        <category>Linux集锦</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>rm</tag>
        <tag>Linux汇总</tag>
        <tag>危险命令</tag>
        <tag>dd</tag>
        <tag>mkfs</tag>
        <tag>shutdown</tag>
      </tags>
  </entry>
  <entry>
    <title>危险命令 集锦</title>
    <url>/2018/10/28/linux-collection-dangerous/</url>
    <content><![CDATA[危险命令 集锦
 低调但大胆的 - dd 命令
 显示管理磁盘分区 fdisk
 精准终止 之 kill
 一个不留 的 killall
 一去不复还的rm 命令
 稍显底层的红帽系软件管理工具 - rpm
 Linux shutdown 命令
 Linux userdel

后记更多信息请阅读原文。
]]></content>
      <categories>
        <category>集锦</category>
      </categories>
      <tags>
        <tag>集锦</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux数据处理的几个命令</title>
    <url>/2023/11/16/linux-collection-data-processing-commands/</url>
    <content><![CDATA[Linux数据处理的几个命令
仅个人想法，会持续不间断更新和改进。

Linux系统中的数据处理，可真假转换，可搜索，需排序、减重复。

真假转换之间 trLinux tr 命令用于转换或删除字符。
tr 命令可以从标准输入读取数据，经过字符串转译后，将结果输出到标准输出。
官方定义为：

tr - translate or delete characters

使用方法为：
$ tr [OPTION]... SET1 [SET2]



其中常用的三个选项为：

-d, --delete：删除指令字符
[:lower:] ：所有小写字母
[:upper:] ：所有大写字母
[:blank:] ：所有空格

a-z小写全部转换为大写默认无参数的显示
$ echo "Hello World, Welcome to Linux!" | tr a-z A-ZHELLO WORLD, WELCOME TO LINUX!# 还有一种方法$ echo "Hello World, Welcome to Linux!" | tr [:lower:] [:upper:]HELLO WORLD!





A-Z大写全部转换为小写默认无参数的显示
$ echo "Hello World, Welcome to Linux!" | tr  A-Z a-zhello world, welcome to linux!# 还有一种方法$ echo "Hello World, Welcome to Linux!" | tr [:upper:] [:lower:]hello world, welcome to linux!



貌似起名可以用这个很多变量或者函数起名字都会移除元音字符，可以考虑使用-d参数，如下：
$ echo "Hello World, Welcome to Linux!" | tr -d a,o,e,iHll Wrld Wlcm t Lnux!




不过感觉删除的多了，也不一定是好事。。。
比如里外看Wlcm不晓得啥意思

移除文件中的所有空格同理，使用-d，结合[:blank:]可以快速删除所有空格。
$ echo "Hello World, Welcome to Linux!" | tr -d [:blank:]HelloWorld,WelcometoLinux!







文件内容搜索利器 - grepLinux grep 命令用于查找文件里符合条件的字符串。
官方定义为：

grep, egrep, fgrep - print lines matching a pattern

grep支持正则表达式，是一个强大的文本搜索工具。
语法语法也挺复杂，因为功能确实很强大。
$ grep [OPTION...] PATTERNS [FILE...]$ grep [OPTION...] -e PATTERNS ... [FILE...]      # 使用egrep$ grep [OPTION...] -f PATTERN_FILE ... [FILE...]  # 使用fgrep

常用的参数为：

-r 或 –recursive : 此参数的效果和指定”-d recurse”参数相同
-v 或 –invert-match : 显示不包含匹配文本的所有行
-i 或 –ignore-case : 忽略字符大小写的差别
-n 或 –line-number : 在显示符合样式的那一行之前，标示出该行的列数编号。

假定有如下3个文件，1个文件夹，内容如下：
a    This is a    Hello a    b     this is b    Hello bc     This is c    Hello cd/d     This is d    Hello d



默认无参数在当前目录搜索包含is字符串，可以看到**a/b/c**三个文件均有输出，而d因为是目录，暂时无输出。
$ grep is *a:This is ab:this is bc:This is cgrep: d: Is a directory



增加文件夹与其他命令类似，增加-r参数，递归搜索
$ grep -r is *a:This is ab:this is bc:This is cd/d:This is d



反向查找在某些情况下，或许正想找到不包含某些字符串的内容，如下：
$ grep -rv is *a:Hello ab:Hello bc:Hello cd/d:Hello d

此时可以看到，不包含is的内容显示了出来。
不区分大小写而某些情况下，或许我们希望找到不区分大小写的内容，比如对于This/this而言：
$ grep -r This *a:This is ac:This is cd/d:This is d$ grep -ri This *a:This is ab:this is bc:This is cd/d:This is d

可以看到此时有可能笔误，或者其他原因的b文件已经被找到了。
显示行数，精准定位   如果文件内容比较多，此时显示内容在哪一行，是很重要的，加上-n参数既可解决。
$ grep -rn This *a:1:This is ac:1:This is cd/d:1:This is d


没有规矩不成方圆 sortLinux sort 命令用于将文本内容进行排序。
官方定义为：

sort - sort lines of text files

语法$ sort [OPTION]... [FILE]...$ sort [OPTION]... --files0-from=F

常用的参数为：

-c 检查文件是否已经按照顺序排序。
-u 意味着是唯一的(unique)，输出的结果是去完重了的。
-r 以相反的顺序来排序。
-k field1[,field2] 按指定的列进行排序。

这里假定测试文件名为testfile：
LiSi            80ZhangSan        70WangWu          90MaLiu           88



默认无参数在使用 sort 命令以默认的式对文件的行进行排序，命令如下：
$ sort testfile LiSi            80MaLiu           88WangWu          90ZhangSan        70

sort 命令默认情况下将第一列以 ASCII 码的次序排列，并将结果输出到标准输出。
根据第N列排序对于测试文件而言，或许我们更希望使用数字来统计排序，此时可以使用-k N参数，其中N为列数
$  sort testfile -k 2ZhangSan        70LiSi            80MaLiu           88WangWu          90



检查是否已经排序在某些情况下，或许只想看看文件是否已经排序，使用-c参数 ：
$  sort -c testfilesort: testfile:2: disorder

如果没有排序会有输出，而排序的话就没有输出。
逆序排列如果希望看一下数字从高到低的培训，使用-r参数：
$  sort testfile -k 2  -rWangWu          90MaLiu           88LiSi            80ZhangSan        70


你是唯一的 uniqLinux uniq 命令用于检查及删除文本文件中重复出现的行列，一般与 sort 命令结合使用。
官方定义为：

uniq - report or omit repeated lines

uniq 可检查文本文件中重复出现的行列。
语法语法比较简单，直接用就可以。
$ uniq [OPTION]... [INPUT [OUTPUT]]

常用的参数为：

-c或--count 在每列旁边显示该行重复出现的次数。

-d或--repeated 仅显示重复出现的行列。

-u或--unique 仅显示出一次的行列。


假定有1个文件为testfile，内容如下：
testfile	Hello 1	Hello 2	Hello 2	Hello 3	Hello 3	Hello 3	Hello 4	Hello 4	Hello 4    Hello 4



默认无参数使用uniq 命令可以删除重复的行，不管有多少重复的行，仅仅显示一行。
$  uniq testfileHello 1Hello 2Hello 3Hello 4



统计出现频次如果希望统计每一行出现的频次，可以使用-c参数，其中第一行输出为出现的次数
$  uniq -c testfile      1 Hello 1      2 Hello 2      3 Hello 3      4 Hello 4



仅仅显示重复的行在某些情况下，或许只想看到有重复的列，使用-d参数 ：
$  uniq -d testfileHello 2Hello 3Hello 4





仅仅显示不重复的行而某些情况下，或许只想看到不重复的列，使用-u参数：
$  uniq -u testfileHello 1


]]></content>
      <categories>
        <category>Linux集锦</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>grep</tag>
        <tag>Linux汇总</tag>
        <tag>sed</tag>
        <tag>awk</tag>
        <tag>sort</tag>
        <tag>uniq</tag>
        <tag>tr</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux最常用的几个时间日期命令</title>
    <url>/2022/10/09/linux-collection-date-commands/</url>
    <content><![CDATA[Linux最常用的几个时间日期命令桃花谢了春红，太匆匆，无奈朝来风雨晚来风。
时光只解催人老，不信多情，长恨离亭，泪滴春衫酒易醒。
时间就在指缝间，悄然的离去了。

一日难再晨及时当勉励 datedate命令可以用来打印显示亦或者更改日期和时间。
看看官方的定义如下：

 date - print or set the system date and time

用法如下：
$ date [OPTION]... [+FORMAT]$ date [-u | --utc| --universal] [MMDDhhmm[[CC]YY][.ss]]



较常用的OPTION为：

-R ： 显示时区
-u, --utc, --universal：打印或者设置世界协调时
-d, --date=STRING：显示STRING的时间

默认输入date 命令默认情况下为CST时区，
$ dateMon Jun  5 15:11:44 CST 2014



显示时区如果加上 -R参数就可以带上时区，比如我们的东八区
$ date -RMon, 05 Jun 2014 15:15:25 +0800



世界协调时选项-u, --utc, --universal可以显示世界协调时
$ date -uMon Jun  5 07:15:46 UTC 2014$ date --utcMon Jun  5 07:15:48 UTC 2014$ date --universalMon Jun  5 07:15:55 UTC 2014





格式化日期可以通过不同的参数来格式化日期，这里需要注意的是：不同的大小写代表的是不同的含义
比较常用的日期和时间如下：
# 显示年月日时分秒$ date  +%Y-%m-%dT%H:%M:%S2013-01-17T18:01:08# 或者 下面一样的效果$ data +%FT%T2013-01-17T18:02:12








时光总是催人老 timeLinux time命令的用途，在于测量指定命令消耗的时间。
最常用的在于大概评估一个程序的运行时间。
这个命令很容易给人的印象是与date混淆起来
官方定义为：

time - time a simple command or give resource usage

可以给出包括系统的粗略时间。
语法$ time [options] command [arguments...]

参数：
​	- 可以认为没有参数
示例会显示程序或命令执行的消耗时间
$ time ls /varaccount  crash  games     lib    log  ......real    0m0.014suser    0m0.003ssys     0m0.010s$ time ps -auxroot     295490  0.0  0.0      0     0 ?        S    Feb20   0:10 [ldlm_cb00_019root     297717  0.0  0.0      0     0 ?        S&lt;   Jan29   0:04 [kworker/58:1Hroot     304801  0.0  0.0      0     0 ?        S    Mar19   0:00 [kworker/1:1]root     311110  0.0  0.0      0     0 ?        S    Mar20   0:00 [kworker/66:0]root     313146  0.0  0.0      0     0 ?        S    Mar20   0:01 [kworker/73:2]root     313461  0.0  0.0      0     0 ?        S&lt;   Jan29   0:00 [kworker/44:2Hroot     313914  0.0  0.0      0     0 ?        S    Feb21   0:10 [kworker/9:2]root     314118  0.0  0.0      0     0 ?        S    Feb21   3:34 [kworker/18:1]root     315801  0.0  0.0      0     0 ?        S    Mar20   0:00 [kworker/79:2]real    0m0.180suser    0m0.019ssys     0m0.114



唯一需要留意的是上面的三个含义：

real : 程序从开始调用到最后终止之间经过的实时时间
user : 程序本身，以及它所调用的库中的子例程使用的CPU 时间
sys : 程序直接或间接调用的系统调用执行的CPU 时间

休息一会 sleepLinux sleep命令可以用来将目前动作延迟一段时间。
sleep的官方定义为：

 sleep - delay for a specified amount of time

或许你觉得计算机太累，让它稍事休息，亦或许过个个把钟头需要喝杯水，此时sleep就有点小作用了。
其用法如下：
$ sleep [--help] [--version] number[smhd]

除了帮助和版本信息，基本没有参数了。
其中的number是必须的，也就是sleep多久的数字，默认为s秒。其他的几个含义为：

s second 秒
m minute分钟
h hour 小时
d day 天

休息5分钟工作太累了，学习太累了，躺着太累了，休息5分钟
$ sleep 5m



1小时后提醒我$ sleep 1h



时分秒搭配使用当然，sleep也是支持时分秒搭配使用的，如下所示：
$ sleep 1h 2m 3s

将会sleep 1个小时2分钟3秒。
倒计时计时器当然也可以做个循环计时器，通过sleep 1
$ echo "five"   &amp;&amp; sleep 1 &amp;&amp; echo "four"   &amp;&amp; sleep 1 &amp;&amp; sleep 1 &amp;&amp; echo "three"   &amp;&amp; sleep 1 &amp;&amp; echo "two" &amp;&amp; sleep 1 &amp;&amp; echo "one" &amp;&amp; echo "Stop"





结合脚本sleep在程序里面使用比较频繁，特别是单片机的走马灯等。而Linux的sleep，也是比较常与bash脚本来配合使用，如下：
#!/bin/bashecho -e "start to sleep 15 seconds......"sleep 15echo -e "continue to run program......"./program


可看黄道吉日的 calcal用于显示当前日历信息或者指定日期的公历信息。
cal的官方定义为：

 cal, ncal — displays a calendar and the date of Easter

cal也是来自于calendar的前三个字母。
其用法有好几种，比如可以为：
$ cal [-31jy] [-A number] [-B number] [-d yyyy-mm] [[month] year]$ cal [-31j] [-A number] [-B number] [-d yyyy-mm] -m month [year]$ ncal [-C] [-31jy] [-A number] [-B number] [-d yyyy-mm] [[month] year]$ ncal [-C] [-31j] [-A number] [-B number] [-d yyyy-mm] -m month [year]$ ncal [-31bhjJpwySM] [-A number] [-B number] [-H yyyy-mm-dd] [-d yyyy-mm] [-s country_code] [[month] year]$ ncal [-31bhJeoSM] [-A number] [-B number] [-d yyyy-mm] [year]



cal可以没有参数，也可以多个参数组合。
[[month] year]的含义是，比如有year这个参数，然后可以出现month year两个参数。
主要使用的参数为：

-3 ：显示前后和当前3个月的日历
-y ：显示一年的日历，此时不要指定月份参数
-j ：显示在当年中的第几天（儒略日）

显示当前月份的日历默认无参数会显示当前的月份等信息
$ cal   February 2011Su Mo Tu We Th Fr Sa       1  2  3  4  5 6  7  8  9 10 11 1213 14 15 16 17 18 1920 21 22 23 24 25 2627 28



显示指定年月的日历比如希望看看2012年12月份，可以运行如下命令：
$ cal 12 2012   December 2012Su Mo Tu We Th Fr Sa                   1 2  3  4  5  6  7  8 9 10 11 12 13 14 1516 17 18 19 20 21 2223 24 25 26 27 28 2930 31



显示3个月的日历-3将显示当前月份、前一个月、后一个月，共计3个月的日历。
$ cal -3                            2011      January               February               MarchSu Mo Tu We Th Fr Sa  Su Mo Tu We Th Fr Sa  Su Mo Tu We Th Fr Sa                   1         1  2  3  4  5         1  2  3  4  5 2  3  4  5  6  7  8   6  7  8  9 10 11 12   6  7  8  9 10 11 12 9 10 11 12 13 14 15  13 14 15 16 17 18 19  13 14 15 16 17 18 1916 17 18 19 20 21 22  20 21 22 23 24 25 26  20 21 22 23 24 25 2623 24 25 26 27 28 29  27 28                 27 28 29 30 3130 31



显示一年的日历使用-y参数，可以查看一年的日历。
$ cal -y                            2011      January               February               MarchSu Mo Tu We Th Fr Sa  Su Mo Tu We Th Fr Sa  Su Mo Tu We Th Fr Sa                   1         1  2  3  4  5         1  2  3  4  5 2  3  4  5  6  7  8   6  7  8  9 10 11 12   6  7  8  9 10 11 12 9 10 11 12 13 14 15  13 14 15 16 17 18 19  13 14 15 16 17 18 1916 17 18 19 20 21 22  20 21 22 23 24 25 26  20 21 22 23 24 25 2623 24 25 26 27 28 29  27 28                 27 28 29 30 3130 31       April                  May                   JuneSu Mo Tu We Th Fr Sa  Su Mo Tu We Th Fr Sa  Su Mo Tu We Th Fr Sa                1  2   1  2  3  4  5  6  7            1  2  3  4 3  4  5  6  7  8  9   8  9 10 11 12 13 14   5  6  7  8  9 10 1110 11 12 13 14 15 16  15 16 17 18 19 20 21  12 13 14 15 16 17 1817 18 19 20 21 22 23  22 23 24 25 26 27 28  19 20 21 22 23 24 2524 25 26 27 28 29 30  29 30 31              26 27 28 29 30        July                 August              SeptemberSu Mo Tu We Th Fr Sa  Su Mo Tu We Th Fr Sa  Su Mo Tu We Th Fr Sa                1  2      1  2  3  4  5  6               1  2  3 3  4  5  6  7  8  9   7  8  9 10 11 12 13   4  5  6  7  8  9 1010 11 12 13 14 15 16  14 15 16 17 18 19 20  11 12 13 14 15 16 1717 18 19 20 21 22 23  21 22 23 24 25 26 27  18 19 20 21 22 23 2424 25 26 27 28 29 30  28 29 30 31           25 26 27 28 29 3031      October               November              DecemberSu Mo Tu We Th Fr Sa  Su Mo Tu We Th Fr Sa  Su Mo Tu We Th Fr Sa                   1         1  2  3  4  5               1  2  3 2  3  4  5  6  7  8   6  7  8  9 10 11 12   4  5  6  7  8  9 10 9 10 11 12 13 14 15  13 14 15 16 17 18 19  11 12 13 14 15 16 1716 17 18 19 20 21 22  20 21 22 23 24 25 26  18 19 20 21 22 23 2423 24 25 26 27 28 29  27 28 29 30           25 26 27 28 29 30 3130 31



显示儒略日-j用于显示儒略日，这里的儒略日的概念为从1月1日开始计算的多少天，这个在倒计时的时候挺好用的。
$ cal -j  cal 02 2011 -j       February 2011 Su  Mo  Tu  We  Th  Fr  Sa         32  33  34  35  36 37  38  39  40  41  42  43 44  45  46  47  48  49  50 51  52  53  54  55  56  57 58  59


]]></content>
      <categories>
        <category>Linux集锦</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Linux汇总</tag>
      </tags>
  </entry>
  <entry>
    <title>linux中最常用的目录导航命令</title>
    <url>/2023/12/17/linux-collection-directory-navigation-commands/</url>
    <content><![CDATA[Linux中最常用的目录导航命令
 仅个人想法，会持续不间断更新和改进。

在Linux世界中，为了更加高效地浏览和定位文件，需要一些常用的目录导航命令。 

探索未知世界的cd.. note::  月桥花院，琐窗朱户，只有春知处。  宋 辛弃疾《青玉案·元夕》
cd 命令应该是除了 ls 命令外用的最多的命令了。除非你大门不出二门不迈，做个大家闺秀。
cd 命令的含义为

 cd - change directory

可以让我们访问不同的文件夹。
最简单的用法为：
$ cd /the/path/you/want/to/go/


 接下来说一些技巧，让效率加倍。

让cd命令对参数大小写不敏感
如果你需要同时显示大写和小写的目录名（即便是你给的参数只是小写的），执行下面的bind命令，此时就可以避免Linux和linux的尴尬。
$ bind "set completion-ignore-case on"



进入刚才的目录想要进入刚才进入的地方（目测没有很多人再用，但是真的很好用）运行：
$ cd –



快速返回家目录需要快速地回到你的家目录，输入cd即可，这里其实不用一级一级的进入
$ cd



进入某用户的家目录这个需要你有root权限
cd ~username

进入username的家目录。

这些是一些比较基础和入门的，还有一些高级一点的，这些技巧可能用的比较少，不过也是很有帮助的。

结合CDPATH的妙用变量CDPATH定义了目录的搜索路径：
$ export CDPATH=/the/path/you/add/:/another/path/

现在，不用输入cd /the/path/you/add/hello/ 这样长了，我可以直接输入下面的命令进入 /the/path/you/add/hello/：
$ cd html



!$这个命令目测，用的人不多，其实比较有用，且有效。
$ cd !$

表明的意思是将上一个命令的参数作为cd的参数来使用。
用shopt –s cdspell自动纠正cd命令的目录名输入错误使用shopt -s cdspell可以自动修正cd时拼写错误的目录名。
如果你在输入时经常犯些错误，这个命令是很有用的。详见以下示例：
# cd /etc/mall-bash: cd: /etc/mall: No such file or directory# shopt -s cdspell# cd /etc/mall# pwd/etc/mail


 注: 当我错误的把mail敲成了mall，用这个命令mall就自动被换成了mail

最常用的且没有之一的  ls.. note::  寻寻觅觅，冷冷清清，凄凄惨惨戚戚。  宋 李清照《声声慢·寻寻觅觅》
如果linux命令来个排名，ls命令应该是最常用的命令，除非你像黄蓉的母亲，有过目不忘的本领，惹得黄药师抱憾终身。
ls命令是list的缩写，通过ls命令，我们可以查看目录的内容，确定各种重要文件和目录的属性。
命令格式ls [参数] [路径]

不加任何参数如果不加任何参数，默认列出当前目录的内容。
$ ls /etc/sysconfig/network-scriptsifcfg-em1ifcfg-em2ifcfg-em3ifcfg-em4   ....



使用-l显示更多细节-l 就是使用long listing format长格式，来显示更多的内容信息。
$ ls -l /etc/sysconfig/network-scriptstotal 264-rw-r--r--. 1 root root   341 Nov 30 10:56 ifcfg-em1-rw-r--r--. 1 root root   294 May 13  2016 ifcfg-em2-rw-r--r--. 1 root root   272 May 10  2016 ifcfg-em3-rw-r--r--. 1 root root   272 May 10  2016 ifcfg-em4......

使用-t按照时间排序如果希望看到最近创建的文件，就需要用到-t参数了。
$ ls -lt /etc/sysconfig/network-scripts/total 264-rw-r--r--. 1 root root   341 Nov 30 10:56 ifcfg-em1-rw-r--r--. 1 root root   294 May 13  2016 ifcfg-em2-rw-r--r--. 1 root root   272 May 10  2016 ifcfg-em4-rw-r--r--. 1 root root   272 May 10  2016 ifcfg-em3...

使用-r按照时间逆序如果希望删除很早以前的文件，看到最早创建的文件，就需要用到-r参数了。
$ ls -ltr /etc/sysconfig/network-scripts/total 264...-rw-r--r--. 1 root root   272 May 10  2016 ifcfg-em3-rw-r--r--. 1 root root   272 May 10  2016 ifcfg-em4-rw-r--r--. 1 root root   294 May 13  2016 ifcfg-em2-rw-r--r--. 1 root root   341 Nov 30 10:56 ifcfg-em1

使用-S根据文件大小排序$ ls -lS /etc/sysconfig/network-scripts/total 264...-rw-r--r--. 1 root root   341 Nov 30 10:56 ifcfg-em1-rw-r--r--. 1 root root   294 May 13  2016 ifcfg-em2-rw-r--r--. 1 root root   272 May 10  2016 ifcfg-em3-rw-r--r--. 1 root root   272 May 10  2016 ifcfg-em4





查看目录命令pwdpwd命令的作用是查看当前目录，没有参数，输入后回车即可显示当前绝对路径。
官方定义为：

pwd - print name of current/working directory

 所以pwd是Print Working  Directory第一个字的缩写。
唯二需要了解的参数如下：

-L, --logical：打印逻辑路径，与pwd一致
-P, --physical：打印物理路径，这里可以从超级链接直达原处

实例展示此时比如我们进入一个目录，然后在打印出来，如下：
$ cd /etc/sysconfig/network-scripts/$ pwd/etc/sysconfig/network-scripts


可以看到pwd将输出完全路径

逻辑与物理路径比如如下：
$ pwd/opt/test$ ls -l总用量 1lrwxrwxrwx  1 root root   14 Jan 15 2012 dir -&gt; source/dirdrwxrwxrwx  1 root root   14 Jan 15 2012 source

可以看到此时的路径在/opt/test/里面有两个目录source和dir，其中dir链接到source里面的dir。
接下来对比一下-L和-P的区别。
$ cd dir$ pwd/opt/test/dir$ pwd -L/opt/test/dir$ pwd -P/opt/test/source/dir



从上面的输出可以发现，-P参数会显示文件最原始的路径；而-L则是逻辑上的路径。
Linux tree命令Linux tree命令以树状图列出目录的内容。
执行tree指令，它会列出指定目录下的所有文件，包括子目录里的文件。
官方定义为：

tree - list contents of directories in a tree-like format.

使用方法为：
$ tree  [-acdfghilnpqrstuvxACDFQNSUX] [-L level [-R]] [-H baseHREF] [-T title] [-o filename] [--nolinks] [-P pattern] [-I pat‐       tern] [--inodes] [--device]  [--noreport]  [--dirsfirst]  [--version]  [--help]  [--filelimit  #]  [--si]  [--prune]  [--du]       [--timefmt format] [--matchdirs] [--fromfile] [--] [directory ...]



参数比较多，也比较复杂。其中常用的选项为：

-d 显示目录名称而非内容。
-D 列出文件或目录的更改时间。

​    
实例 默认显示默认显示当前目录的信息，比如tree和tree .的含义一样。命令有如下输出结果：
$ tree   .├── a├── aa│   ├── aab│   ├── aac│   ├── aad│   └── aae├── b├── bb│   └── bbb├── c├── d├── e└── f2 directories, 11 files





只显示目录$ tree -d         .├── aa└── bb





显示具体的修改时间$ tree -D.├── [Apr 7 22:34]  a├── [Apr 7 22:37]  aa│   ├── [Apr 7 22:35]  aab│   ├── [Apr 7 22:35]  aac│   ├── [Apr 7 22:35]  aad│   └── [Apr 7 22:35]  aae├── [Apr 7 22:34]  b├── [Apr 7 22:39]  bb│   └── [Apr 7 22:39]  bbb├── [Apr 7 22:34]  c├── [Apr 7 22:34]  d├── [Apr 7 22:33]  e└── [Apr 7 22:33]  f2 directories, 11 files




默认情况下tree可能没有安装，可以通过apt/yum install tree来安装。


]]></content>
      <categories>
        <category>Linux集锦</category>
      </categories>
      <tags>
        <tag>cd</tag>
        <tag>pwd</tag>
        <tag>ls</tag>
        <tag>dir</tag>
        <tag>tree</tag>
      </tags>
  </entry>
  <entry>
    <title>linux中最常用的文件管理命令</title>
    <url>/2023/10/17/linux-collection-file-management/</url>
    <content><![CDATA[linux中最常用的文件管理命令
 仅个人想法，会持续不间断更新和改进。

在 Linux 系统中，文件管理是基础且重要。
如何显示，如何查找，如何编辑，如何删除，如何复制，如何移动，如何重命名，如何创建，如何修改，如何查看文件的属性等等，都是我们在日常工作中经常会用到的命令。
Linux的文件管理命令也会帮助你更高效地在终端中操作文件和目录。
而其中最绕不开的当属以下几个。

 已经不能用强大描述的 awk
 查看庐山真面貌的cat
 安全起见，拷贝为先 - cp
 cut todo
 远看高低各不同 diff
 从头开始的head
 最常用的且没有之一的  ls
 Linux的 mkdir 命令
 Linux的 mv 命令
 sed 入门
 反向显示之 tac
 不可狗尾续貂的tail
 你是唯一的 uniq

后记更多信息请阅读原文。
]]></content>
      <categories>
        <category>Linux集锦</category>
      </categories>
      <tags>
        <tag>echo</tag>
        <tag>cat</tag>
        <tag>文件管理</tag>
        <tag>pwd</tag>
        <tag>chgrp</tag>
        <tag>chmod</tag>
        <tag>chown</tag>
        <tag>ls</tag>
        <tag>tac</tag>
        <tag>file</tag>
        <tag>less</tag>
        <tag>more</tag>
        <tag>tail</tag>
        <tag>ln</tag>
        <tag>tee</tag>
      </tags>
  </entry>
  <entry>
    <title>linux中最常用的文件操作命令</title>
    <url>/2023/12/17/linux-collection-file-operation/</url>
    <content><![CDATA[Linux中最常用的文件操作命令
 仅个人想法，会持续不间断更新和改进。

在Linux的庞大世界中，搜索犹如明灯，可以拨开云雾见青天，照亮我们前行大道路。
无论你是在浩瀚的代码库中搜索一个特定的函数，还是在庞大的文件系统中寻找一个文件，搜索命令着实是不可或缺尤为重要的工具。
而其中最绕不开的当属以下几个。

一切皆可查的 findfind命令用来在指定目录下查找文件，功能相当之强大。
官方定义为：

find - search for files in a directory hierarchy

Linux的哲学是一切皆文件，那么find的使命就是一切皆可查。
语法使用语法为：
$ find [-H] [-L] [-P] [-D debugopts] [-Olevel] [path...] [expression]

比较常用的几个参数为：

-exec &lt;执行指令&gt;：假设find指令的回传值为True，就执行该指令；
-size &lt;文件大小&gt;：查找符合指定的文件大小的文件；
-mtime &lt;24小时&gt;：查找在指定时间曾被更改过的文件或目录，单位以24小时计算；-name&lt;范本样式&gt;：指定字符串作为寻找文件或目录的范本样式；
-type &lt;文件类型&gt;：只寻找符合指定的文件类型的文件；

无参数如果使用该命令时，不设置任何参数，则find命令将在当前目录下查找子目录与文件,并且将查找到的子目录和文件全部进行显示。
$ ls -ltotal 310M-rw-rw-r-- 1 user user  10M Mar 21 20:01 adrwxrwxr-x 2 user user   22 Mar 21 20:01 aa-rw-rw-r-- 1 user user 100M Mar 21 20:01 b-rw-rw-r-- 1 user user 200M Mar 21 20:01 c$ find ../a./b./c./test



查找小于，等于和大于100MB的文件通过-size大小来查找文件
$ find . -size -100M../a./aa$ find . -size 100M./b$ find . -size +100M./c./aa/d

查找多长时间修改过可以通过参数-mtime来查找文件的修改时间，比如如下可以查找当前目录下最近60天没有被修改的文件。
$ find . -mtime +60# 最近2天以内未修改$ find . –mtime -2



稍微复杂但是很有用的命令 我经常把 find 命令和他的选项 exec一起使用，比如我想查找一个目录中的所有文件并将其更改其权限。可以通过以下简单命令完成：
$ find /path/ -type f -exec chmod 644 {} \;

这个命令会递归搜索指定目录内/path/下的所有文件，并对找到的文件执行 chmod 命令。
精准快速定位的locate.. note::
  众里寻他千百度，蓦然回首，那人却在灯火阑珊处  -李煜
Linux locate命令用于查找符合条件的文档、程序、目录等等。这个命令会在数据库中查找符合条件的各种信息。
一般情况我们只需要输入 locate name 即可查找。
官方定义为：

locate - list files in databases that match a pattern

使用方法为：
$ locate  [-d  path  |  --database=path]  [-e  | -E | --[non-]existing] [-i | --ignore-case] [-0 | --null] [-c |       --count] [-w | --wholename] [-b | --basename] [-l N | --limit=N] [-S | --statistics] [-r | --regex ] [--regex‐       type  R] [--max-database-age D] [-P | -H | --nofollow] [-L | --follow] [--version] [-A | --all] [-p | --print]       [--help] pattern...

看着很复杂，不过常用的参数倒是不多，基本为：

-n :  至多显示 n个输出。
-i, --ignore-case : 忽略大小写

默认无参数默认情况下，locate直接跟上需要查找的信息就可以了，如下所示：
$ locate set_vis.cpp/home/user/mycode/src/set_vis.cpp# 以查找apropos为例$ locate apropos/usr/bin/apropos/usr/local/difmap/help/apropos.hlp/usr/share/emacs/24.3/lisp/apropos.elc/usr/share/man/de/man1/apropos.1.gz/usr/share/man/es/man1/apropos.1.gz/usr/share/man/fr/man1/apropos.1.gz/usr/share/man/id/man1/apropos.1.gz/usr/share/man/it/man1/apropos.1.gz/usr/share/man/ja/man1/apropos.1.gz/usr/share/man/man1/apropos.1.gz/usr/share/man/nl/man1/apropos.1.gz/usr/share/man/pl/man1/apropos.1.gz/usr/share/man/ru/man1/apropos.1.gz



太多需要简单化如果输出的信息很多，仅仅希望看到前面的几个，使用-n参数既可
# 仅仅查看前的3个$ locate -n 3 apropos/usr/bin/apropos/usr/local/difmap/help/apropos.hlp/usr/share/emacs/24.3/lisp/apropos.elc



不区分大小写部分情况下，可能有大小写混淆的情况，此时使用-i参数既可
$ $ locate -i set_vis.cpp/home/user/mycode/src/set_vis.cpp/home/user/mycode_CPP/src/set_VIS.cpp



说明不过刚按照的系统，这个命令并不一定有输出，主要是因为locate 与 find 不同，  find 直接在硬盘找，而locate 只在数据库中查找。
这个数据库在CentOS系统默认的为 /var/lib/mlocate/mlocate.db 中，所以 locate 的查找会比较快，但并一定是实时的，而是以数据库的更新为准。
可以通过下面的命令手工升级数据库 ，命令为：
$ updatedb

然后就可以使用了。
文件内容搜索利器 - grepLinux grep 命令用于查找文件里符合条件的字符串。
官方定义为：

grep, egrep, fgrep - print lines matching a pattern

grep支持正则表达式，是一个强大的文本搜索工具。
语法语法也挺复杂，因为功能确实很强大。
$ grep [OPTION...] PATTERNS [FILE...]$ grep [OPTION...] -e PATTERNS ... [FILE...]      # 使用egrep$ grep [OPTION...] -f PATTERN_FILE ... [FILE...]  # 使用fgrep

常用的参数为：

-r 或 –recursive : 此参数的效果和指定”-d recurse”参数相同
-v 或 –invert-match : 显示不包含匹配文本的所有行
-i 或 –ignore-case : 忽略字符大小写的差别
-n 或 –line-number : 在显示符合样式的那一行之前，标示出该行的列数编号。

假定有如下3个文件，1个文件夹，内容如下：
a    This is a    Hello a    b     this is b    Hello bc     This is c    Hello cd/d     This is d    Hello d



默认无参数在当前目录搜索包含is字符串，可以看到**a/b/c**三个文件均有输出，而d因为是目录，暂时无输出。
$ grep is *a:This is ab:this is bc:This is cgrep: d: Is a directory



增加文件夹与其他命令类似，增加-r参数，递归搜索
$ grep -r is *a:This is ab:this is bc:This is cd/d:This is d



反向查找在某些情况下，或许正想找到不包含某些字符串的内容，如下：
$ grep -rv is *a:Hello ab:Hello bc:Hello cd/d:Hello d

此时可以看到，不包含is的内容显示了出来。
不区分大小写而某些情况下，或许我们希望找到不区分大小写的内容，比如对于This/this而言：
$ grep -r This *a:This is ac:This is cd/d:This is d$ grep -ri This *a:This is ab:this is bc:This is cd/d:This is d

可以看到此时有可能笔误，或者其他原因的b文件已经被找到了。
显示行数，精准定位   如果文件内容比较多，此时显示内容在哪一行，是很重要的，加上-n参数既可解决。
$ grep -rn This *a:1:This is ac:1:This is cd/d:1:This is d


]]></content>
      <categories>
        <category>Linux集锦</category>
      </categories>
      <tags>
        <tag>search</tag>
        <tag>diff</tag>
        <tag>cat</tag>
        <tag>文件操作</tag>
        <tag>uniq</tag>
        <tag>tac</tag>
        <tag>tail</tag>
        <tag>head</tag>
        <tag>find</tag>
        <tag>locate</tag>
      </tags>
  </entry>
  <entry>
    <title>linux中最常用的文件传输命令</title>
    <url>/2022/12/17/linux-collection-file-transfer/</url>
    <content><![CDATA[linux中最常用的文件传输命令
 仅个人想法，会持续不间断更新和改进。

现在的Linux大抵都是具备图形界面的，特别是个人使用的话，不装个GUI界面那就说不过去了。
不过但是要远程使用服务器，后者超算，或者只能命令行的方式登陆到其他服务器，其他终端的话，那么命令行的文件传输命令就显得尤为重要。
如果仅仅会右键另存为，岂不抓瞎？
此时，我们就需要一些命令行的文件传输命令，比如wget和curl，这两个命令是Linux中最常用的文件传输命令。

超多协议传输的 - curlLinux curl命令是一款用于从一个server端传输的工具。
很强力，支持众多协议，比如：DICT, FILE, FTP, FTPS, GOPHER, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, POP3, POP3S, RTMP, RTSP,  SCP,  SFTP,  SMB,  SMBS,  SMTP,SMTPS, TELNET 和 TFTP. 
说实话，有些协议我也不知道，不过我们只需要知道这个命令设计之初是希望不需要用户的交互和介入，就可以完成数据的传输。
所以这个命令被广泛应用于数据传输、测试、调试和自动化脚本中。
官方定义为：

curl - transfer a URL

语法$ curl [options / URLs]

参数：

-O : 把输出写到该文件中，保留远程文件的文件名
-u : 通过服务端配置的用户名和密码授权访问

默认传输下载文件默认情况下，将下载的数据写入到文件，并且使用服务器上的名字，这里以下载Linux的内核代码为例。
$ curl https://mirrors.edge.kernel.org/pub/linux/kernel/v2.4/linux-2.4.32.tar.gz -O  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current                                 Dload  Upload   Total   Spent    Left  Speed  1 36.7M    1  575k    0     0  17431      0  0:36:50  0:00:33  0:36:17 27222

需要授权的网站部分网站可能需要访问的授权，此时可以使用-u选项提供用户名和密码进行授权：
$ curl -u username https://www.website.com/ Enter host password for user 'username':



批量下载当然，这么强力的工具，肯定是支持批量下载的，并且是正则表达式的支持。
比如：ftp://ftp.example.com/的file1，file5和file7，方法如下：
$ curl ftp://ftp.example.com/file{1,5,7}.txt



如果下载ftp://ftp.example.com/的从file1到file100的100组文件，方法如下：
$ curl ftp://ftp.example.com/file[1-100].txt

非交互的下载工具 wgetLinux系统中的wget是一个下载文件📀的命令行工具，特别普遍 。
对于Linux用户是必不可少的工具，对于经常要下载一些软件或从远程服务器恢复备份到本地服务器，这个命令尤为重要。
wget支持很多协议，比如HTTP，HTTPS和FTP协议，还可以使用HTTP代理。
wget的有诸多特点，比如

自动下载 wget支持自动下载，即wget可以在用户退出系统的之后在后台执行。这意味着你可以登录系统，启动一个wget下载任务，然后退出系统，wget将在后台执行直到任务完成，这是个牛气冲天的功能。
完全重建 wget 可以跟踪HTML页面上的链接依次下载来创建远程服务器的本地版本，完全重建原始站点的目录结构。这又常被称作”递归下载”。在递归下载的时候，wget 遵循Robot Exclusion标准(/robots.txt). wget可以在下载的同时，将链接转换成指向本地文件，以方便离线浏览。
高稳定 wget 非常稳定，它在带宽很窄的情况下和不稳定网络中有很强的适应性.如果是由于网络的原因下载失败，wget会不断地尝试，直到整个文件下载完毕。如果是服务器打断下载过程，它会再次联到服务器上从停止的地方继续下载。这对从那些限定了链接时间的服务器上下载大文件非常有用。

命令格式$ wget [参数] [URL地址]

用于从网络上下载资源，没有指定目录，下载资源会默认为当前目录。wget虽然功能强大，但是使用起来还是比较简单：
使用范例wget的命令参数很多，不过常用的为下面几个，详细的可以看进阶。
使用wget下载单个文件比如，我们下载个Ubuntu的最新版本，试下效果如何
$ wget http://releases.ubuntu.com/16.04/ubuntu-16.04-desktop-amd64.iso

在下载的过程中会显示进度条，包含（下载完成百分比，已经下载的字节，当前下载速度，剩余下载时间）。
使用wget -O下载并以不同的文件名保存这个对于动态链接的下载比较有用，特别是有些文件的名字实在是太……………….长了
$ wget -O wordpress.zip http://www.ubuntu.com/download.aspx?id=1234

使用wget -c断点续传$ wget -c http://releases.ubuntu.com/16.04/ubuntu-16.04-desktop-amd64.iso# or$ wget --continue http://releases.ubuntu.com/16.04/ubuntu-16.04-desktop-amd64.iso

使用wget -c重新启动下载中断的文件，对于我们下载大文件时突然由于网络等原因中断非常有帮助，我们可以继续接着下载而不是重新下载一个文件。需要继续中断的下载时可以使用-c参数。
使用wget -o把下载信息存入日志文件$ wget -o download.log URL

不希望下载信息直接显示在终端而是在一个日志文件，可以使用，特别注意需要与-O来区分开~

]]></content>
      <categories>
        <category>Linux集锦</category>
      </categories>
      <tags>
        <tag>search</tag>
        <tag>wget</tag>
        <tag>curl</tag>
        <tag>文件传输</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux最有趣的几个命令</title>
    <url>/2023/12/06/linux-collection-funny-commands/</url>
    <content><![CDATA[Linux最有趣的几个命令
仅个人想法，会持续不间断更新和改进。

这次介绍一些好玩有趣的命令，不过说实话，实用性倒不是很大，纯粹好玩，给单调的命令行界面增加了一些童趣和欢乐。

命运的小火车sl发现这个命令是在输入ls命令的时候，一不小心敲反了，直接命运的小火车开始跑了起来。
sl 是一个 “Steam Locomotive” 的缩写，它会显示一个老式的蒸汽火车在终端中穿梭。
$ sl  (  ) (@@) ( )  (@)  ()    @@    O     @     O     @      O@)______                ___________      \__I_I_____===__|_________|______/ |   |        =|___ ___|      _________________  |     |   |         ||_| |_||     _|                \_____A__--------------------| [___] |   =|                        |__|_____/[][]~\_______|       |   -|                        |-I_____I [][] []  D   |=======|____|________________________|_=====O=====O\ ____Y___________|__|__________________________|_ ||    ||    |_____/~\___/          |_D__D__D_|  |_D__D__D_|/  \__/  \__/      \_/               \_/   \_/    \_/   \_/



点亮终端的艺术之光figlet在Linux的世界中，figlet是一个神奇的命令，可以将文字艺术化.
特别适合作为标题、口号或者问候语，还有很多软件程序的招呼语，也可以用这个来实现。
比如：
$ figlet HELLO           _   _ _____ _     _     ___  | | | | ____| |   | |   / _ \ | |_| |  _| | |   | |  | | | ||  _  | |___| |___| |__| |_| ||_| |_|_____|_____|_____\___/                               



活灵活现的终端：发掘cowsaycowsay顾名思义就是一头牛为你加持，一款让命令行界面生动有趣的工具。
cowsay 可说话、可思考，与fortune加持更可以变为一头睿智的牛。
该命令接受一个文本字符串，并输出一个牛说话的图形。
下面是一头牛在说它喜欢 Linux：
$  cowsay I love linux. _______________ &lt; I love linux. &gt; ---------------         \   ^__^         \  (oo)\_______            (__)\       )\/\                ||----w |                ||     ||



探索Linux世界的智慧——fortunes命令在Linux中，有一条神奇的命令连接着智慧与幽默，那就是fortunes命令。
看似普通的指令，背后却藏匿着千言万语，无论是名人箴言还是妙趣横生的笑话，在这里都能找到它们的踪迹。
另外最重要的，还可以根据自己的需求进行增删，目前就用基于唐诗宋词的库。
fortune并非只是简单的一句话，而是承载着古今中外智慧的涌泉。
每次执行，它都会带来截然不同的感受。或许是一位哲人的深刻格言，或是一句调皮的笑话，或者唐诗，或者宋词，与先贤对话，岂不快哉。
最简单的方法就是把这个命令，加到.bashrc文件中，每次启动，总会有触动。
$ fortune 何以称英雄？识以领其先　　　　－　清·袁枚$ fortune一件作品的固有力量从来不会被长期地埋没或禁锢。一件艺术品可能被时间遗忘，可能遭到查禁，可能被埋进棺材，但威力强大的东西总要战胜没有过大前途的东西。　　　　－　茨威格$ fortuneYow!  We're going to a new disco!





缤纷绚烂的终端体验：探索lolcatlolcat是一款让终端从黑白灰变得缤纷多彩的神奇工具。
通过将文字渲染成彩虹般的颜色，让你的终端充满欢乐与活力。
可以把这个命令替换掉cat，这样你的内容都灵动了起来
比如lolcat /etc/resolv.conf会生成如下信息：

进入数字的魔幻世界：探秘cmatrix来到黑客帝国的命令cmatrix，这不仅仅是一串字符在终端中的运动，它仿佛是数字的舞蹈，变幻着无穷的图案。从绿色的数字雨到模拟Matrix电影的效果，cmatrix让我们进入了数字的奇妙世界。

显示系统风貌的screenfetch命令screenfetch命令的神奇之处在于其简单而又直观的功能，该命令能够快速地收集系统信息并以一种富有个性的方式展示出来。
从使用的发行版到内核版本，再到处理器和内存，一目了然地展现系统的全貌。
$ screenfetch                          ./+o+-       oper@localhost                  yyyyy- -yyyyyy+      OS: Ubuntu                ://+//////-yyyyyyo      Kernel: aarch64 Linux 6.4.16-linuxkit           .++ .:/++++++/-.+sss/`      Uptime: 33m         .:++o:  /++++++++/:--:/-      Packages: 134        o:+o+:++.`..```.-/oo+++++/     Shell: bash 5.1.16       .:+o:+o/.          `+sssoo+/    Disk: 32G / 59G (57%)  .++/+:+oo+o:`             /sssooo.   CPU: 12x Apple /+++//+:`oo+o               /::--:.   RAM: 877MiB / 7844MiB \+/+o+++`o++o               ++////.    .++.o+++oo+:`             /dddhhh.         .+.o+oo:.          `oddhhhh+           \+.++o+o``-````.:ohdhhhhh+             `:o+++ `ohhhhhhhhyo++os:                .o:`.syhhhhhhh/.oo++o`                    /osyyyyyyo++ooo+++/                       ````` +oo+++o\:                              `oo++.  



]]></content>
      <categories>
        <category>Linux集锦</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>cmatrix</tag>
        <tag>Linux汇总</tag>
        <tag>有趣命令</tag>
        <tag>screenfetch</tag>
        <tag>sl</tag>
        <tag>figlet</tag>
        <tag>cowsay</tag>
        <tag>fortunes</tag>
        <tag>lolcat</tag>
        <tag>toilet</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux最常用的硬件相关的命令</title>
    <url>/2023/11/18/linux-collection-hardware-commands/</url>
    <content><![CDATA[Linux最常用的硬件相关的命令
仅个人想法，会持续不间断更新和改进。

怎么忽然来硬的呢，因为在Linux的世界中，系统是灵活，但是骨架同样重要。
而跟踪确认硬件信息对于我们同样重要。
同时还增加了系统的关机。

查看块设备的lsblk lsblk 命令可以查看系统中的块设备信息
$ lsblk

这个命令会列出系统中所有的块设备（比如硬盘、分区和挂载点）的信息。
默认情况下，它会显示每个设备的名称、大小、类型、挂载点等信息。
如果需要显示更详细的信息，可以使用 -a 或 --all 选项：
$ lsblk -a

这会显示完整的块设备信息，包括未挂载的设备。
当然，还可以根据需求，定制化输出，不过单单这个命令，足矣。
显示管理磁盘分区 fdiskfdisk是用于检查一个磁盘上分区信息最通用的命令。
fdisk可以显示分区信息及一些细节信息，比如文件系统类型等。
设备的名称通常是/dev/sda、/dev/sdb 等。
对于以前的设备有可能还存在设备名为 /dev/hd* (IDE)的设备，这个设备逐步淘汰了。
fdisk也可以用于创建并操控分区表信息，支持主任GPU、MBR、Sun、SGI和BSD。
块设备可以划分为一个或多个称为分区的逻辑磁盘。这种划分的记录会保存在分区表，通常位于磁盘的第 0 扇区。
fdisk的官方解释为：

fdisk - manipulate disk partition table

语法格式为：
$ fdisk [options] device$ fdisk -l [device...]



其中一些常用的参数为：

-l  列出指定的外围设备的分区表状况
-L, --color[=when] ：将输出颜色化，其中when可以指定为auto, never or always. 默认为 auto.

显示当前系统的分区情况这个也是我唯一推荐入门者使用的 命令，仅仅list显示出目前的系统分区。
万万不要输入fdisk执行其他操作，极易格式化硬盘，切记切记。
$ fdisk -lWARNING: fdisk GPT support is currently new, and therefore in an experimental phase. Use at your own discretion.Disk /dev/sda: 256.1 GB, 256060514304 bytes, 500118192 sectors # 磁盘空间及扇区信息Units = sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk label type: gptDisk identifier: FAF37680-0ECE-4BE7-93FC-E87A8F2F6455







显示硬件信息的hwinfohwinfo 又一个用于显示硬件信息的命令。
可以获得 Linux 系统的各种硬件组件（如CPU、内存、显卡、硬盘等）的详细信息。
显示所有硬件信息：   sudo hwinfo

   列出系统上几乎所有可用硬件的详细信息。
指定特定硬件信息：   sudo hwinfo --cpusudo hwinfo --memorysudo hwinfo --gfxcardsudo hwinfo --disk

   通过在命令后添加 --cpu、--memory、--gfxcard、--disk 等参数，获取特定硬件的信息。
列出系统硬件信息的lshwlshw是Hardware Lister 的缩写，直面意思即列出系统硬件信息。
可以显示关于计算机硬件组件（如处理器、内存、硬盘、网卡等）的详细信息，对于系统管理员和用户来说是一个非常有用的工具。
显示所有硬件信息任何参数都不加的话，可用，信息极多，但是可用信息不多。
 sudo lshw

  这将输出系统中所有可用硬件的详细信息，包括硬件组件的制造商、型号、驱动程序等。
查看摘要硬件信息显示摘要信息：相对而言，这个反而好一些，简单的就是有用的
  sudo lshw -short

  这将显示硬件的摘要信息，包括设备名、类别、描述等。
查看特定硬件信息（如网络、内存、硬盘等设备）显示指定类型的硬件信息：
sudo lshw -C network

上述示例将仅显示网络相关的硬件信息。
比如还可以查看memory、cpu、disk等信息。
lshw提供了全面的硬件信息，帮助用户了解系统配置和硬件组件的细节。在查看和诊断硬件问题或了解系统配置时，它是一个非常有用的工具。
放空一下自我  free**free**这个命令在Linux系统监控的工具里面，算是使用的比较多的一个。
使用_man_查看可知，官方含义为：

Display amount of free and used memory in the system

也就是显示可用、易用的系统内存，它直接读取/proc/meminfo文件。
默认的效果先看下不加任何参数的时候，free的效果：
$ free              total        used        free      shared  buff/cache   availableMem:       32664832    15667736      674136      464892    16322960    15803156Swap:      16449532     3039756    13409776

看起来很多的样子，但是不直观，我比较喜欢加上-h参数。
使用易读的参数-h参数，跟前面的df等命令类似，此处的h表示_human being_的含义方便人类阅读。 除了这个还有_-b,-k,-m,-g_，含义分别为按照_字节、KB、MB、GB_的格式来显示。
$ free -h              total        used        free      shared  buff/cache   availableMem:            31G         14G        655M        453M         15G         15GSwap:           15G        2.9G         12G

Wow，此时的显示简直好简洁。
说下其中的含义:

total : 表示总的物理内存大小，比如上面的就表示31GB的内存

used ：表示已经使用的内存大小，比如上面的就是使用了14GB

free ：表示可用多少

shared：表示多个进程共享的内存大小

buff/cache：表示磁盘缓存的大小，这里有两个方面，buff和cache，两个的含义不同

buff ：something that has yet to be ‘writeen’ to disk ,还没有写入磁盘
cache: something that had been ‘read’ from the disk and store for later user，从磁盘读取的方便下一次使用
这里就设计到Linux的设计哲学，比如读取一个100G的文件，第一次所使用的时间总归是后面再次读取的时间的好几倍，当然前提是没有释放掉caches


available：当然含义为可用的内存容量大小


间隔显示内存状态还有一个比较常用的就是，如果你希望过一段时间就看下free的情况，OK，使用参数-s，后面跟的单位是秒，也就是每个几秒，统计一下使用的内存情况，比如我们每个2s，显示一下
$ free -s 2              total        used        free      shared  buff/cache   availableMem:       32664832    15668528      670964      464892    16325340    15802360Swap:      16449532     3039756    13409776              total        used        free      shared  buff/cache   availableMem:       32664832    15669760      669724      464892    16325348    15801124Swap:      16449532     3039756    13409776              total        used        free      shared  buff/cache   availableMem:       32664832    15670220      669248      464892    16325364    15800652Swap:      16449532     3039756    13409776              total        used        free      shared  buff/cache   availableMem:       32664832    15669264      670204      464892    16325364    15801624Swap:      16449532     3039756    13409776



查看meminfo文件$ cat /proc/meminfo



其实free读取的就是这个文件的某些信息，可以通过同步监控这个文件来check free的状态。
显示CPU架构的有关信息 lscpuLinux的CPU设备查看器。lscpu命令用来显示cpu的相关信息。lscpu从sysfs和/proc/cpuinfo收集cpu体系结构信息，命令的输出比较易读 。命令输出的信息包含cpu数量，线程，核数，socket和Nom-Uniform Memeor Access(NUMA)，缓存等等。
官方定义为：

lscpu - display information about the CPU architecture

参数基本用处不大，默认即可，部分参数可以查看offline和online的设备信息。
默认实例$ lscpuArchitecture:          x86_64       		#架构信息 CPU op-mode(s):        32-bit, 64-bitByte Order:            Little EndianCPU(s):                64   				#逻辑cpu颗数 On-line CPU(s) list:   0-63Thread(s) per core:    2 					#每个核心线程Core(s) per socket:    16 					#每个cpu插槽核数/每颗物理cpu核数 Socket(s):             2  					#cpu插槽数NUMA node(s):          2Vendor ID:             GenuineIntel 		#cpu厂商ID CPU family:            6   					#cpu系列 Model:                 63 					#型号 Model name:            Intel(R) Xeon(R) CPU E5-2698 v3 @ 2.30GHzStepping:              2 					#步进 CPU MHz:               1290.335 			#cpu主频BogoMIPS:              4604.47Virtualization:        VT-x  				#cpu支持的虚拟化技术 L1d cache:             32KL1i cache:             32KL2 cache:              256KL3 cache:              40960KNUMA node0 CPU(s):     0-15,32-47NUMA node1 CPU(s):     16-31,48-63

其中几个概念需要理解清楚，基本比较重要的都有了备注。
其中第一个为CPU(s)，这个值为Socket * Core * Thread得出，也就是逻辑的CPU个数。
CPU(s):                64   #逻辑CPU数On-line CPU(s) list:   0-63Thread(s) per core:    2     Core(s) per socket:    16socket：                2



而其他几个概念为：

Socket : 物理上的CPU插槽的数量，也就是物理的实体概念
Core：即平常说的单核、多核、四核等，即每个CPU上的核数
Thread：每个core上的线程数，即超线程。

lspci 显示当前设备的PCI总线信息lspci命令用于显示PCI总线的信息，以及所有已连接的PCI设备信息。
官方定义为：

lspci  - list all PCI devices

默认情况下，lspci会显示一个简短的设备列表。 使用使用一些参数来显示更详细的输出或供其他程序解析的输出。
不过需要注意的是，在许多操作系统上，对 PCI 配置空间的某些部分的访问仅限于 root，因此普通用户可用的 lspci 功能受到限制。
使用方法为：
$ lspci [options]



其中常用的三个选项为：

-n  以数字方式显示PCI厂商和设备代码
-t 以树状结构显示PCI设备的层次关系
-v 显示更详细的输出信息

显示当前主机的所有PCI总线信息：默认无参数的显示
$ lspci00:00.0 Host bridge: Intel Corporation Xeon E7 v3/Xeon E5 v3/Core i7 DMI2 (rev 02)00:01.0 PCI bridge: Intel Corporation Xeon E7 v3/Xeon E5 v3/Core i7 PCI Express Root Port 1 (rev 02)00:02.0 PCI bridge: Intel Corporation Xeon E7 v3/Xeon E5 v3/Core i7 PCI Express Root Port 2 (rev 02)00:03.0 PCI bridge: Intel Corporation Xeon E7 v3/Xeon E5 v3/Core i7 PCI Express Root Port 3 (rev 02)00:03.2 PCI bridge: Intel Corporation Xeon E7 v3/Xeon E5 v3/Core i7 PCI Express Root Port 3 (rev 02)00:04.0 System peripheral: Intel Corporation Xeon E7 v3/Xeon E5 v3/Core i7 DMA Channel 0 (rev 02)00:04.1 System peripheral: Intel Corporation Xeon E7 v3/Xeon E5 v3/Core i7 DMA Channel 1 (rev 02)00:04.2 System peripheral: Intel Corporation Xeon E7 v3/Xeon E5 v3/Core i7 DMA Channel 2 (rev 02)......

以数字方式显示PCI厂商和设备代码以数字形式显示
$ lspci -n00:00.0 0600: 8086:2f00 (rev 02)00:01.0 0604: 8086:2f02 (rev 02)00:02.0 0604: 8086:2f04 (rev 02)00:03.0 0604: 8086:2f08 (rev 02)00:03.2 0604: 8086:2f0a (rev 02)00:04.0 0880: 8086:2f20 (rev 02)00:04.1 0880: 8086:2f21 (rev 02)00:04.2 0880: 8086:2f22 (rev 02)......



同时显示数字方式还有设备代码信息$ lspci -nn00:00.0 Host bridge [0600]: Intel Corporation Xeon E7 v3/Xeon E5 v3/Core i7 DMI2 [8086:2f00] (rev 02)00:01.0 PCI bridge [0604]: Intel Corporation Xeon E7 v3/Xeon E5 v3/Core i7 PCI Express Root Port 1 [8086:2f02] (rev 02)00:02.0 PCI bridge [0604]: Intel Corporation Xeon E7 v3/Xeon E5 v3/Core i7 PCI Express Root Port 2 [8086:2f04] (rev 02)00:03.0 PCI bridge [0604]: Intel Corporation Xeon E7 v3/Xeon E5 v3/Core i7 PCI Express Root Port 3 [8086:2f08] (rev 02)00:03.2 PCI bridge [0604]: Intel Corporation Xeon E7 v3/Xeon E5 v3/Core i7 PCI Express Root Port 3 [8086:2f0a] (rev 02)00:04.0 System peripheral [0880]: Intel Corporation Xeon E7 v3/Xeon E5 v3/Core i7 DMA Channel 0 [8086:2f20] (rev 02)00:04.1 System peripheral [0880]: Intel Corporation Xeon E7 v3/Xeon E5 v3/Core i7 DMA Channel 1 [8086:2f21] (rev 02)00:04.2 System peripheral [0880]: Intel Corporation Xeon E7 v3/Xeon E5 v3/Core i7 DMA Channel 2 [8086:2f22] (rev 02)......

以树状结构显示PCI设备的层次关系：$ lspci -tlspci -t-+-[0000:ff]-+-08.0 |           +-08.2 |           +-1f.0 |           \-1f.2 +-[0000:80]-+-01.0-[81]----00.0 |           +-04.0 |           +-05.1 |           +-05.2 |           \-05.4 +-[0000:7f]-+-08.0 |           +-08.2 |           +-0c.1             \+-0c.2

Linux reboot/poweroff/halt 命令Linux halt, poweroff, reboot 用来挂起、关机或者重启机器，成功后返回0。
这不是一个命令，这是三个命令，只不过三个命令的参数都是一致的。
官方定义为：

halt, poweroff, reboot - Halt, power-off or reboot the machine

其实这三个命令都可以通过shutdown来执行，并且相对而言shutdown的参数还更多一些。
语法使用方法如下：
$ halt [OPTIONS...]$ poweroff [OPTIONS...]    $ reboot [OPTIONS...]



参数如下所示：

--halt 将机器挂起，三个命令均相同
-p, --poweroff  将机器关机，三个命令均相同
--reboot  将机器重启，三个命令均相同
-f, --force 立即执行挂起、关机和重启，一般对于force而言，除非万不得已，否则进来莫用
-n, --no-sync 在挂起、关机或重启前不对硬盘进行同步，这个很危险呀，进来不要用呀
--no-wall 在挂起、关机或重启前不发送警告信息，对于多用户不友好

立即关机接下来的三个命令一致，都是将电脑关机，不过这个用法总归感觉怪怪的，所以还是分开各司其职比较好。比如关机还是poweroff，重启还是reboot吧。
$ halt --poweroff$ poweroff --poweroff$ reboot --poweroff

]]></content>
      <categories>
        <category>Linux集锦</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>rm</tag>
        <tag>Linux汇总</tag>
        <tag>危险命令</tag>
        <tag>dd</tag>
        <tag>mkfs</tag>
        <tag>shutdown</tag>
        <tag>硬件信息</tag>
        <tag>reboot</tag>
        <tag>poweroff</tag>
        <tag>halt</tag>
      </tags>
  </entry>
  <entry>
    <title>linux中最常用的帮助命令</title>
    <url>/2023/12/12/linux-collection-help-commands/</url>
    <content><![CDATA[linux中最常用的帮助命令
仅个人想法，会持续不间断更新和改进。

Linux有好几个关于帮助的命令，可以让我们在不上网的情况下获取一些丰硕的信息。
唯一的要求就是英语好一些，唯二的情况就是不确定的情况下在此确认后再执行。

此man非man的意思
首先，这man是什么意思？
最开始很多人认为是不知道这个什么意思，找man呀。
其实man是manual的缩写，也就是手册的意思。

man命令提供了系统命令的详细帮助信息。
Linux提供了丰富的帮助手册，当你需要查看某个命令的参数时不必到处上网查找，只要man一下即可。这个也是每个程序员必备的功能，在没有网络的情况下，man能解决很多问题和疑惑。
看一下官方定义：

Man - format and display the on-line manual pages

man 的格式如果要读懂并使用man，首先需要了解man命令输出的格式，下面的几个是比较常用且需要注意的：

同时也可以使用man man 查看man的使用方法。




章节
含义



NAME
命令名称及功能简要说明


SYNOPSIS
用法说明，包括可用的选项


DESCRIPTION
命令功能的详细说明，可能包括每一个选项的意义


OPTIONS
每一选项的意义


EXAMPLES
一些使用示例


man的操作  比如输入man ls  后，跳出下面的内容：
LS(1)                                               User Commands                                              LS(1)NAME       ls - list directory contentsSYNOPSIS       ls [OPTION]... [FILE]...DESCRIPTION       List  information about the FILEs (the current directory by default).  Sort entries alphabetically if none of       -cftuvSUX nor --sort is specified.       Mandatory arguments to long options are mandatory for short options too.       -a, --all              do not ignore entries starting with .       -A, --almost-all              do not list implied . and ..       --author              with -l, print the author of each file       -b, --escape              print C-style escapes for nongraphic characters       --block-size=SIZE              scale sizes by SIZE before printing them; e.g., '--block-size=M' prints sizes in  units  of  1,048,576              bytes; see SIZE format below       -B, --ignore-backups Manual page ls(1) line 1 (press h for help or q to quit)



此时可以通过空格键或者回车键来向后翻屏或者翻页，可以使用b或者k向前查看。
　查看关键词时可以使用：
  /关键词    向后查找   n：下一个
  ?关键词   向前查找   N：前一个
可以通过q来退出。

ls后面还有一个（1）,详细的解释可以参考《Linux 安装 man 帮助程序》

类似于whatis命令man有个参数为-f，就是whatis的功能，比如：
$ man -f ls cd file cat more lessls (1)               - list directory contentsls (1p)              - list directory contentscd (1)               - bash built-in commands, see bash(1)cd (1p)              - change the working directorycd (n)               - Change working directoryfile (1)             - determine file typefile (1p)            - determine file typefile (n)             - Manipulate file names and attributescat (1)              - concatenate files and print on the standard outputcat (1p)             - concatenate and print filesmore (1)             - file perusal filter for crt viewingmore (1p)            - display files on a page-by-page basisless (1)             - opposite of moreless (3pm)           - perl pragma to request less of something


与whatis命令完全一致

类似于apropos命令man有个参数为-k，就是apropos的功能，比如：
$ man -k  whoat.allow (5)         - determine who can submit jobs via at or batchat.deny (5)          - determine who can submit jobs via at or batchbtrfs-filesystem (8) - command group of btrfs that usually work on the whole filesystemdocker-trust-signer (1) - Manage entities who can sign Docker imagesipsec_newhostkey (8) - generate a new raw RSA authentication key for a hostipsec_showhostkey (8) - show host's authentication keyw (1)                - Show who is logged on and what they are doing.who (1)              - show who is logged onwho (1p)             - display who is on the systemwhoami (1)           - print effective userid


与apropos命令完全一致

使用man的小技巧 如果遇到一个不熟悉或者完全不知道的命令，此时可以通过下面的3个步骤来了解：

首先用man -k command 查询所有类似帮助文件信息，或许有可能就能找到你需要的信息；
然后man -f command 查询以command开始的相关帮助信息列表
man  N command 通过直接定位N获得详细帮助信息

你是干什么的 whatis其实整个命令已出现，你的脑海里面应该浮现的是：

What is your name?

如题所述，这个命令用于查询一个命令到底执行了什么功能，并将查询的结果输出出来，相当于man的一个选项-f。
whatis的官方定义为：

whatis - display manual page descriptions

仅仅提供一个比较简单的命令描述.
使用方法也比较简单，如下：
$ whatis [options] name


其中的name可以是Linux命令、系统调用、库函数、系统等等内容

以前面的命令为例，执行如下所示：
$ whatis ls cd file cat more lessls (1)               - list directory contentsls (1p)              - list directory contentscd (1)               - bash built-in commands, see bash(1)cd (1p)              - change the working directorycd (n)               - Change working directoryfile (1)             - determine file typefile (1p)            - determine file typefile (n)             - Manipulate file names and attributescat (1)              - concatenate files and print on the standard outputcat (1p)             - concatenate and print filesmore (1)             - file perusal filter for crt viewingmore (1p)            - display files on a page-by-page basisless (1)             - opposite of moreless (3pm)           - perl pragma to request less of something




可以看到whatis是支持同时查询多个命令的

拓展whatis可以通过-w、-r以及-C等选项来设定通配符、正则表达式以及配置文件等等，不过最简单的还是简单查看一个命令的简单描述，其他的可以交给man来处理。
指定目录的定位 whereisLinux whereis 命令用于定位查找一个命令的二进制、源文件或帮助文件。
不过这些文件一般是位于特定目录的。
其他的程序定位可以考虑使用locate命令。
官方的定义为：

whereis - locate the binary, source, and manual page files for a command

使用语法使用语法如下：
$ whereis [options] [-BMS directory... -f] name...



其他的选项可以为： 

-b : 查找二进制文件

-m：查找手册

-s：查找源文件

-B &lt;directory&gt; 　在设置的目录下查找二进制文件。

-M &lt;directory&gt; 　在设置的目录下查找说明文件。

-S &lt;directory&gt; 　在设置的目录下查找原始代码文件。


实例比如查找bash的位置，输入如下命令：
$ whereis bashbash: /usr/bin/bash /etc/bash.bashrc /usr/share/man/man1/bash.1.gz

可以看到，以上的输出信息从左至右分别为程序名、bash路径、bash的man帮助手册路径。
单独查找文件可以通过不同的参数来查找不同的文件，如下：
# 查找二进制文件$ whereis -b bashbash: /usr/bin/bash /etc/bash.bashrc # 查找帮助文件$ whereis -m bashbash: /usr/share/man/man1/bash.1.gz# 查找源文件$ whereis -s bashbash:

刚刚好合适的 apropos 命令apropos的中文含义就是恰好的、合适的，奈何这个单词或者命令确实不好记，当然是可以扩充词汇量的。
什么时候会用到这个命令呢，先看看这个命令的定义。
apropos 命令的官方定义为:

 search the manual page names and descriptions

意思很明显，如果我不记得命令或者不知道该用什么命令的时候，可以通过关键词来索引查找这些命令，比如我们想用linux绘制图像，但是不知道什么命令，测试可以使用：
$ apropos plotbno_plot (1) – generate interactive 3D plot of IO blocks and sizes gnuplot (1) – an interactive plotting program pbmtoplot (1) – convert a PBM image into a Unix 'plot' file


或许每个人的输出不同，这个主要取决于安装的软件包和索引的数据库。以上。

再来一个实例，这个应该大部分的都类似：
$ apropos whoat.allow (5)         - determine who can submit jobs via at or batchat.deny (5)          - determine who can submit jobs via at or batchbtrfs-filesystem (8) - command group of btrfs that usually work on the whole filesystemdocker-trust-signer (1) - Manage entities who can sign Docker imagesipsec_newhostkey (8) - generate a new raw RSA authentication key for a hostipsec_showhostkey (8) - show host's authentication keyw (1)                - Show who is logged on and what they are doing.who (1)              - show who is logged onwho (1p)             - display who is on the systemwhoami (1)           - print effective userid




 这个命令平时用的不多，跟whatis类似，因为这些功能都被加到了包罗万象的man命令。


]]></content>
      <categories>
        <category>Linux集锦</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>apropos</tag>
        <tag>man</tag>
        <tag>whatis</tag>
        <tag>whereis</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux 集锦 之 最常用的几个命令</title>
    <url>/2023/10/11/linux-collection-most-used-commands/</url>
    <content><![CDATA[Linux最常用的几个命令​	Linux系统中的命令那是相当地丰富，不同的版本可能还有不同的命令，不过Linux核心自带的命令大概有几百个，这个不管是什么发行版一般都是共用的。
​	如果希望探索Linux的所有命令，可能不太实际，因为这个数字可能达到惊人的万计。
​	不过还好的是，Linux命令的入门只要掌握不到100个命令即可，而如果相对而言行云流水的话也就200个命令足矣。
​	而如果准备试试Linux，可能只需要下面的几个实用频率最高、功能最关键、也最常用的命令也就基本可以完成日常的工作、学习需要了。
​	忽然想用姓氏排序的方法，不过感觉不太行，索性就大概按照使用率来统计了。
​	仅个人习惯，会持续不间断更新和改进。

ls 列出当前目录下的文件📃和文件夹📁列表​	个人感觉这个命令，属于名副其实用的最多的命令，我们进入Linux的第一个命令，可能除了输入用户名密码就属它了。
​	工欲善其事，必先利其器，你欲使用Linux，必先了解当前的文件和内容。
不加任何参数如果不加任何参数，默认列出当前目录的内容。
$ ls /etc/sysconfig/network-scriptsifcfg-em1ifcfg-em2ifcfg-em3ifcfg-em4   ....



使用-l显示更多细节-l 就是使用long listing format长格式，来显示更多的内容信息。
$ ls -l /etc/sysconfig/network-scriptstotal 264-rw-r--r--. 1 root root   341 Nov 30 10:56 ifcfg-em1-rw-r--r--. 1 root root   294 May 13  2016 ifcfg-em2-rw-r--r--. 1 root root   272 May 10  2016 ifcfg-em3-rw-r--r--. 1 root root   272 May 10  2016 ifcfg-em4......

使用-t按照时间排序如果希望看到最近创建的文件，就需要用到-t参数了。
$ ls -lt /etc/sysconfig/network-scripts/total 264-rw-r--r--. 1 root root   341 Nov 30 10:56 ifcfg-em1-rw-r--r--. 1 root root   294 May 13  2016 ifcfg-em2-rw-r--r--. 1 root root   272 May 10  2016 ifcfg-em4-rw-r--r--. 1 root root   272 May 10  2016 ifcfg-em3...

使用-r按照时间逆序如果希望删除很早以前的文件，看到最早创建的文件，就需要用到-r参数了。
$ ls -ltr /etc/sysconfig/network-scripts/total 264...-rw-r--r--. 1 root root   272 May 10  2016 ifcfg-em3-rw-r--r--. 1 root root   272 May 10  2016 ifcfg-em4-rw-r--r--. 1 root root   294 May 13  2016 ifcfg-em2-rw-r--r--. 1 root root   341 Nov 30 10:56 ifcfg-em1

使用-S根据文件大小排序$ ls -lS /etc/sysconfig/network-scripts/total 264...-rw-r--r--. 1 root root   341 Nov 30 10:56 ifcfg-em1-rw-r--r--. 1 root root   294 May 13  2016 ifcfg-em2-rw-r--r--. 1 root root   272 May 10  2016 ifcfg-em3-rw-r--r--. 1 root root   272 May 10  2016 ifcfg-em4






cd 改变当前的工作目录这个命令可能估计能排在第二，类似于Winows的双击，在不同目录件徜徉。
在各个文件夹遍历是我们的习惯和倔强的证明。
cd命令没有太多参数，但是有一些技巧所在，可以N多人从来没有用过。
cd直接使用即可，技巧是下面几个：
进入刚才的目录想要进入刚才进入的地方（目测没有很多人再用，但是真的很好用）运行：
$ cd –



快速返回家目录需要快速地回到你的家目录，输入cd即可，这里其实不用一级一级的进入
$ cd



进入某用户的家目录这个需要你有root权限
cd ~username

进入username的家目录。
mkdir - 创建目录说到cd到某个目录，就需要提高创建目录，也就新建文件夹。
参数不过，处理默认什么参数也不加，会一个-p递归创建文件夹即可。
创建一个空目录$ mkdir hello

递归创建多个目录$ mkdir -p a/b/c/d/e/f/g






rm - 删除文件rm 命令用于删除文件或者目录。
这个命令其实我不想把它归为最常用的命令，因为它也是最危险⚠️的命令之一，文件一旦通过rm命令删除❌，则无法恢复，所以必须格外一定切记小心地使用该命令。因为发生过很多欲哭无泪的故事。。。
文件如果少，可以使用-i 删除前逐一询问确认，确认时比较好用；
而下面的两个参数十分残暴，除非百分之两百确认，否则慎用：

-f 即使原档案属性设为唯读，也直接删除，无需逐一确认，是force的意思。
-r 将目录及里面的子文件逐一删除。

cp - 复制文件cp可以实现文件和目录的复制，如果你只会cp a b，或者加上-r来递归目录，那么你还需要挖掘很多呀，比如只复制不存在或者更新的文件。
以下就是cp常用的选项如下所示：

i : 覆盖一个已经存在的文件前，提示用户进行确认
r：递归地复制目录及其内容，复制目录的时候必须使用这个参数
u：只复制不存在或者更新的文件
v：复制文件时，显示复制信息

组合rv - 可以拷贝文件或文件夹这个在显示复制信息的时候，也可以复制目录
$ cp -rv dir1/* dir2/‘dir1/a’ -&gt; ‘dir2/a’‘dir1/b’ -&gt; ‘dir2/b’‘dir1/c’ -&gt; ‘dir2/c’‘dir1/d’ -&gt; ‘dir2/d’

拷贝时提示确认这个参数在使用rm的时候已经记得使用，不然就像rm -rf /一样，一个公司没有了。
$ cp -i dir1/* dir2/cp: overwrite ‘dir2/a’? ycp: overwrite ‘dir2/b’? ycp: overwrite ‘dir2/c’? y


这个选项在文件超级多时候，慎用！！

只拷贝不存在或更新的文件u表示update，也就是从一个目录拷贝到另外一个目录时，只会复制那些不存在或者目标目录相应文件的更新文件。
执行下面的命令：
$ cp -u dir1/* dir2/

可以得到：
$ ll *dir1:total 0-rw-rw-r-- 1 user user 0 Jul 20 21:23 a-rw-rw-r-- 1 user user 0 Jul 20 21:23 b-rw-rw-r-- 1 user user 0 Jul 20 21:23 c-rw-rw-r-- 1 user user 0 Jul 20 21:23 ddir2:total 0-rw-rw-r-- 1 user user 0 Jul 20 21:29 a-rw-rw-r-- 1 user user 0 Jul 20 21:25 b-rw-rw-r-- 1 user user 0 Jul 20 21:29 c-rw-rw-r-- 1 user user 0 Jul 20 21:25 d-rw-rw-r-- 1 user user 0 Jul 20 21:25 e



如何用cp拷贝指定序号的文件现在有文件夹filename，内有文档，名字是从1.txt, 2.txt, 3.txt 一直到9999.txt,10000.txt,现在希望从第N组数据即N.txt到第M组数据M.txt的文件拷贝到别的文件夹中，方法如下：
$ cp {N..M}.txt   newfilename/

这个方法可是相当的赞呀(≧▽≦)/，基本可以秒掉大多数的GUI程序了。
mv - 文件移动或者叫重命名如果mv的命令还停留在重命名一个文件或者文件夹，那么就花3分钟看一下。
mv能做的还很多。
比如为了防止误删，mv可以提前做个备份；比如为了防止覆盖，可以考虑只有文件较新的时候才移动。
详细如下：
mv几个比较常用的选项如下：

-b: 当目标文件或目录存在时，在执行覆盖前，会为其创建一个备份，文件后缀用~表示；
-i或–interactive: 如果指定移动的源目录或文件与目标的目录或文件同名，则会先询问是否覆盖旧文件，输入 y 表示直接覆盖，输入 n 表示取消该操作，一般而言，对于不确定的时候可以用此选项，不过文件或文件夹居多时，最好不要用
-f或–force: 如果指定移动的源目录或文件与目标的目录或文件同名，不会询问，直接覆盖旧文件，强制的意思force
-n或–no-clobber: 不要覆盖任何已存在的文件或目录。
-u：当源文件比目标文件新或者目标文件不存在时，才执行移动操作。

常规操作$ lsa.txt$ mv a.txt b.txt$ lsb.txt

直接移动或者叫做重命名，文件夹也类似的操作。
覆盖前备份$ lsa.txt  a.txt~$ cp -b ../a.txt a.txt$ lsa.txt  a.txt~


可以看到此时多了一个备份文件

增量更新$ cp -u a b	


此时的操作为，只有a比b更新或者b不存在的时候，才会进行更新，否则失败。
这个用法多用在：当横向对比两个文价夹有无重要更新的时候才会用到。

交互提示$ cp -i b.txt a.txtcp：是否覆盖"a.txt"？ 




在文件存在的时候，-i选项会进行提示，此时需要输入y才能覆盖，而输入n就会取消这个操作。

pwd - 查看目录所在的命令pwd命令的作用是查看当前目录，没有参数，输入后回车即可显示当前绝对路径， 所以pwd是Print Working  Directory第一个字的缩写。
唯二需要了解的参数如下：

-L, --logical：打印逻辑路径，与pwd一致
-P, --physical：打印物理路径，这里可以从超级链接直达原处

实例展示此时比如我们进入一个目录，然后在打印出来，如下：
$ cd /etc/sysconfig/network-scripts/$ pwd/etc/sysconfig/network-scripts


可以看到pwd将输出完全路径

逻辑与物理路径比如如下：
$ pwd/opt/test$ ls -l总用量 1lrwxrwxrwx  1 root root   14 Jan 15 2012 dir -&gt; source/dirdrwxrwxrwx  1 root root   14 Jan 15 2012 source

可以看到此时的路径在/opt/test/里面有两个目录source和dir，其中dir链接到source里面的dir。
接下来对比一下-L和-P的区别。
$ cd dir$ pwd/opt/test/dir$ pwd -L/opt/test/dir$ pwd -P/opt/test/source/dir



从上面的输出可以发现，-P参数会显示文件最原始的路径；而-L则是逻辑上的路径。

]]></content>
      <categories>
        <category>Linux集锦</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>cd</tag>
        <tag>Linux汇总</tag>
        <tag>ls</tag>
        <tag>常用命令</tag>
        <tag>mkdir</tag>
        <tag>cp</tag>
        <tag>mv</tag>
        <tag>Linux集锦</tag>
      </tags>
  </entry>
  <entry>
    <title>linux中最常用的网络命令</title>
    <url>/2024/01/02/linux-collection-network-commands/</url>
    <content><![CDATA[linux中最常用的网络命令
 仅个人想法，会持续不间断更新和改进。

虚虚假假，真真实实，如何快速的去伪存真，抽丝剥茧。
需要在开放的网络世界掌握一些最基础的命令，让自己知己知彼。

查看网络信息的原初 ifconfigLinux ifconfig命令用于显示或设置网络设备，在调试或调优的时间经常使用。
官方定义为：

ifconfig - configure a network interface

对于这个命令，一般只要掌握如何查看，如何设置IP地址基本就可以了，对于网络钻的比较深的，还需要更多一些参数。
使用方法为：
# 显示$ ifconfig [-v] [-a] [-s] [interface]# 设置$ ifconfig [-v] interface [aftype] options | address ...



一些参数的含义为：

-a ：显示所有网卡的状态，即使是down的状态
-s：显示一个短列表
interface mtu N  设置最大传输单元【需要管理员权限】
netmask addr：设置掩码地址【需要管理员权限】
interface up     激活网卡【需要管理员权限】
interface down   关闭网卡【需要管理员权限】
interface hw ether xx.xx.xx.xx.xx.xx 设置MAC地址【需要管理员权限】

默认无参数使用如果不指定任何参数，直接显示当前活动的接口，如下：
$ ifconfigeth0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500        inet 192.168.1.123  netmask 255.255.255.0  broadcast 192.168.1.255        inet6 xxxx::xxxx:xxxx:xxxx:xxxx  prefixlen 64  scopeid 0x20&lt;link&gt;        inet6 xxxx:xxxx:xxxx:xxxx:xxxx:xxxx:xxxx:xxxx  prefixlen 64  scopeid 0x0&lt;global&gt;        ether xx:xx:xx:xx:xx:xx  txqueuelen 1000  (Ethernet)        RX packets 5634431  bytes 4994127142 (4.6 GiB)        RX errors 0  dropped 0  overruns 0  frame 0        TX packets 858051  bytes 109858013 (104.7 MiB)        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0        device memory 0xc7320000-c733ffff  eth1: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500        inet 192.168.6.123  netmask 255.255.255.0  broadcast 192.168.6.255        inet6 xxxx::xxxx:xxxx:xxxx:xxxx  prefixlen 64  scopeid 0x20&lt;link&gt;        ether xx:xx:xx:xx:xx:xx  txqueuelen 1000  (Ethernet)        RX packets 1547215  bytes 92862867 (88.5 MiB)        RX errors 0  dropped 6  overruns 0  frame 0        TX packets 3230  bytes 922051 (900.4 KiB)        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0lo: flags=73&lt;UP,LOOPBACK,RUNNING&gt;  mtu 65536        inet 127.0.0.1  netmask 255.0.0.0        inet6 ::1  prefixlen 128  scopeid 0x10&lt;host&gt;        loop  txqueuelen 1000  (Local Loopback)        RX packets 219608  bytes 105943591 (101.0 MiB)        RX errors 0  dropped 0  overruns 0  frame 0        TX packets 219608  bytes 105943591 (101.0 MiB)        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0

其中一般希望看到的信息包括：

inet：为IP地址
ether：为MAC地址
MTU：最大传输单元

不加任何参数只会显示已经配置并且活跃的网卡信息，如果使用ifconfig -a就可以显示全部的网卡状态了，即使有些网卡是down的状态。
亦或者指定一个interface，比如上面的eth1，则只输出这个网卡的信息，如下：
$ ifconfig eth1eth1: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500        inet 192.168.6.123  netmask 255.255.255.0  broadcast 192.168.6.255        inet6 xxxx::xxxx:xxxx:xxxx:xxxx  prefixlen 64  scopeid 0x20&lt;link&gt;        ether xx:xx:xx:xx:xx:xx  txqueuelen 1000  (Ethernet)        RX packets 1547215  bytes 92862867 (88.5 MiB)        RX errors 0  dropped 6  overruns 0  frame 0        TX packets 3230  bytes 922051 (900.4 KiB)        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0





-s显示短列表如果只想看到MTU以及数据包的状态，可以用该参数，如下：
$ ifconfig -sIface      MTU    RX-OK RX-ERR RX-DRP RX-OVR    TX-OK TX-ERR TX-DRP TX-OVR Flgeth0     1500   5665450      0      0 0        867639      0      0      0 BMRUeth1     1500   3489187217   0 101054 0      501260400     0      0      0 BMUlo       65536  219708       0      0 0        219708      0      0      0 LRU

输出信息主要包含了MTU值，发送及接收的数据情况。
配置IP地址如下对eth0网卡配置IP地址、掩码以及广播地址，当然可以分布操作
# 给eth0配置IP地址$ ifconfig eth0 192.168.1.123 # 给eth0配置IP地址和子网掩码$ ifconfig eth0 192.168.1.123 netmask 255.255.255.0 # 给eth0配置IP地址、子网掩码还有广播地址$ ifconfig eth0 192.168.1.123 netmask 255.255.255.0 broadcast 192.168.1.255



修改MTU在某些情况下可能需要修改MTU值，比如增到到MTU为9000，如下：
$ ifconfig eth1eth1: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500        inet 192.168.6.123  netmask 255.255.255.0  broadcast 192.168.6.255        inet6 xxxx::xxxx:xxxx:xxxx:xxxx  prefixlen 64  scopeid 0x20&lt;link&gt;        ether xx:xx:xx:xx:xx:xx  txqueuelen 1000  (Ethernet)        RX packets 1547215  bytes 92862867 (88.5 MiB)        RX errors 0  dropped 6  overruns 0  frame 0        TX packets 3230  bytes 922051 (900.4 KiB)        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0# 修改MTU$ ifconfig eth1 MTU 9000$ ifconfig eth1eth1: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 9000        inet 192.168.6.123  netmask 255.255.255.0  broadcast 192.168.6.255        inet6 xxxx::xxxx:xxxx:xxxx:xxxx  prefixlen 64  scopeid 0x20&lt;link&gt;        ether xx:xx:xx:xx:xx:xx  txqueuelen 1000  (Ethernet)        RX packets 1547215  bytes 92862867 (88.5 MiB)        RX errors 0  dropped 6  overruns 0  frame 0        TX packets 3230  bytes 922051 (900.4 KiB)        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0

已经看到输出的信息已经把mtu更新为了9000.

这个值对网络传输影响很大。

启动关闭网卡启动关闭主要的应用场景为重新设置了IP地址，或者暂时对某个网卡进行操作。
# 关闭eth0$ ifconfig eth0 down# 启动eth0$ ifconfig eth0 up


不过需要注意的是

很多的设置操作都需要管理员权限；
很多操作在重启后设置都会还原，如果需要永久设置，需要更改network的一些配置文件；
这个程序基本被淘汰了，已经不在更新，所有的操作或者用法均可以通过ip来搞定。等明天~。

网络中不中，先看ping行不行在linux系统里面如果想判断网络的好坏，脑海中蹦出的第一个命令就是ping了。
官方定义为：

ping - send ICMP ECHO_REQUEST to network hosts

ping命令基本是最常用的网络命令，它可以用来测试与目标主机的连通性。
ping使用ICMP传输协议，通过发送ICMP ECHO_REQUEST数据包到网络主机，并显示返回的相应情况，根据这些信息就可以判断目标主机是否可以访问，在发送的过程中还会有一个时间戳用来计算网络的状态。
不过有些服务器为了防止通过ping探测到，可能会在防火墙或者内核参数中禁止ping命令，这样的话，可能虽然目标主机可以访问，但是无法ping通，所以并不能说ping不通的网络就是不能访问的。

需要注意linux下的ping和windows下的ping稍有区别,linux下ping不会自动终止,需要按ctrl+c终止或者用参数-c指定要求完成的回应次数。

语法ping的使用说实话挺复杂，挺多的，不过常用的这篇短文基本就够了。
详细如下：
# ALL$ ping  [-aAbBdDfhLnOqrRUvV46]  [-c  count]  [-F  flowlabel]  [-i  interval]  [-I interface] [-l preload] [-m mark] [-M pmtudisc_option] [-N node‐info_option] [-w deadline] [-W timeout] [-p pattern] [-Q tos] [-s packetsize] [-S sndbuf] [-t ttl] [-T timestamp option] [hop ...] destination# 较常用的选项如下：$ ping   [-c  count]   [-i  interval]  destination

参数说明：

-c &lt;完成次数&gt; 设置完成要求回应的次数。

-i interval 指定收发信息的间隔时间。


不加任何参数如果不加任何参数，查看是否ping通
$ ping www.baidu.com   PING www.a.shifen.com (115.239.210.27) 56(84) bytes of data.64 bytes from 115.239.210.27: icmp_seq=1 ttl=52 time=6.06 ms64 bytes from 115.239.210.27: icmp_seq=2 ttl=52 time=5.56 ms64 bytes from 115.239.210.27: icmp_seq=3 ttl=52 time=5.67 ms64 bytes from 115.239.210.27: icmp_seq=4 ttl=52 time=5.82 ms64 bytes from 115.239.210.27: icmp_seq=5 ttl=52 time=5.70 ms64 bytes from 115.239.210.27: icmp_seq=6 ttl=52 time=5.79 ms  ^C # 此处输入了Ctrl+C强制退出 --- 192.168.1.123 ping statistics ---5 packets transmitted, 5 received, 0% packet loss, time 3999msrtt min/avg/max/mdev = 0.152/0.159/0.172/0.017 ms



可以看到可以ping通www.baidu.com，时延还算比较OK，几个毫秒量级。

这里看一下几个字段的含义，其中：
56(84) bytes of data：表示默认的数据包长度为56字节；
time=5.56ms：表示响应的时间，值越小，证明连接越快；
TTL=52：TTL是Time To Live的缩写，表示DNS记录在DNS服务器上存在的时间，是IP协议包的一个值，告诉路由器啥时候抛弃这个数据包，（大体上可以通过这个值来判断目标类型的操作系统。）

发送指定数目可以通过 参数-c 来发送指定数目的包后停止
$ ping www.baidu.com -c 5PING www.a.shifen.com (115.239.211.112) 56(84) bytes of data.64 bytes from 115.239.211.112: icmp_seq=1 ttl=52 time=6.03 ms64 bytes from 115.239.211.112: icmp_seq=2 ttl=52 time=5.96 ms64 bytes from 115.239.211.112: icmp_seq=3 ttl=52 time=5.79 ms64 bytes from 115.239.211.112: icmp_seq=4 ttl=52 time=5.79 ms64 bytes from 115.239.211.112: icmp_seq=5 ttl=52 time=6.21 ms --- www.a.shifen.com ping statistics ---5 packets transmitted, 5 received, 0% packet loss, time 4007msrtt min/avg/max/mdev = 5.791/5.958/6.215/0.186 ms



此时将在发送5次数据包以后自动停止，在Linux里面，如果不加这个参数，是会一直发送运行的。
设定发送时间间隔可以通过 参数 -i N指定每个N秒发送一次信息，如下将每隔3秒发送一次ping信息。
$ ping www.baidu.com -i 3PING www.a.shifen.com (14.215.177.38) 56(84) bytes of data.64 bytes from 14.215.177.38 (14.215.177.38): icmp_seq=1 ttl=55 time=28.6 ms64 bytes from 14.215.177.38 (14.215.177.38): icmp_seq=2 ttl=55 time=28.6 ms64 bytes from 14.215.177.38 (14.215.177.38): icmp_seq=3 ttl=55 time=28.6 ms64 bytes from 14.215.177.38 (14.215.177.38): icmp_seq=4 ttl=55 time=28.6 ms64 bytes from 14.215.177.38 (14.215.177.38): icmp_seq=5 ttl=55 time=28.6 ms64 bytes from 14.215.177.38 (14.215.177.38): icmp_seq=6 ttl=55 time=28.6 ms^C --- www.a.shifen.com ping statistics ---6 packets transmitted, 6 received, 0% packet loss, time 15041msrtt min/avg/max/mdev = 28.650/28.670/28.697/0.139 ms



如上，每隔3秒会发送一次，对于需要持续检测或者记录的可以考虑适当加大这个时间间隔。

注意，只有管理员可以设置小于0.2秒的时间间隔。所以这个数值可以是浮点数~

组合使用上面的几个例子是可以配合使用的，比如
$ ping www.baidu.com -c 4 -i 5 PING www.a.shifen.com (14.215.177.39) 56(84) bytes of data.64 bytes from 14.215.177.39 (14.215.177.39): icmp_seq=1 ttl=55 time=29.4 ms64 bytes from 14.215.177.39 (14.215.177.39): icmp_seq=2 ttl=55 time=29.3 ms64 bytes from 14.215.177.39 (14.215.177.39): icmp_seq=3 ttl=55 time=29.4 ms64 bytes from 14.215.177.39 (14.215.177.39): icmp_seq=4 ttl=55 time=29.4 ms --- www.a.shifen.com ping statistics ---5 packets transmitted, 5 received, 0% packet loss, time 20045msrtt min/avg/max/mdev = 29.396/29.428/29.461/0.110 ms

这个例子为：每个5秒查询一次，一共查询4次，然后退出。
Linux ip命令Linux ip 命令与 ifconfig 命令类似，但比 ifconfig 命令更加强大，主要用于显示或设置网络设备。
已经在Linux 2.2 加入到了内核。所以ip是加强版的网络配置工具，用来替代ifconfig并强化其他功能。
官方定义为：

 ip - show / manipulate routing, devices, policy routing and tunnels

对于这个命令，命令集是相当的多。先说一些基础的，其他就要自己摸索了。
使用方法为：
$ ip [ OPTIONS ] OBJECT { COMMAND | help }$ ip [ -force ] -batch filename   # OBJECT的取值   # OBJECT := { link | address | addrlabel | route | rule | neigh | ntable | tunnel | tuntap | maddress | mroute | mrule | monitor | xfrm | netns | l2tp | tcp_metrics | token | macsec }# OPTIONS的取值  # OPTIONS := { -V[ersion] | -h[uman-readable] | -s[tatistics] | -d[etails] | -r[esolve] | -iec | -f[amily] { inet | inet6 | ipx | dnet | link } | -4 | -6 | -I | -D | -B | -0 | -l[oops] { maximum-addr-flush-attempts } | -o[neline] | -rc[vbuf] [size] | -t[imestamp] | -ts[hort] | -n[etns] name | -a[ll] | -c[olor] }



COMMAND的值主要取决于OBJECT，可能有所不同，一般可以使用add，delete和show（或者list），均可以输入help来进行查询。
OBJECT中常用的为：

link 网络设备
address 设备上的协议地址
-s, -stats, -statistics 统计化输出

显示网络设备# 显示网络设备$ ip link show1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:002: eno1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc mq state UP mode DEFAULT group default qlen 1000    link/ether xx:xx:xx:xx:xx:xx brd ff:ff:ff:ff:ff:ff3: eno2: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 9000 qdisc mq state DOWN mode DEFAULT group default qlen 1000    link/ether xx:xx:xx:xx:xx:xx brd ff:ff:ff:ff:ff:ff# 显示IP等更多信息$ ip address show1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00    inet 127.0.0.1/8 scope host lo       valid_lft forever preferred_lft forever    inet6 ::1/128 scope host        valid_lft forever preferred_lft forever2: eno1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc mq state UP group default qlen 1000    link/ether xx:xx:xx:xx:xx:xx brd ff:ff:ff:ff:ff:ff    inet 192.168.1.123/24 brd 192.168.254.255 scope global noprefixroute eno1       valid_lft forever preferred_lft forever    inet6 xxxx:xxxx:xxxx:xxxx:xxxx:xxxx:xxxx:xxxx/64 scope global noprefixroute        valid_lft forever preferred_lft forever3: eno2: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 9000 qdisc mq state DOWN group default qlen 1000    link/ether xx:xx:xx:xx:xx:xx brd ff:ff:ff:ff:ff:ff

命令中的show为默认，也可以直接使用ip link或者ip address，结果一致。
设置IP地址可以通过ip addr add/del xxx.xxx.xxx.xxx dev interface 来设置或者删除IP地址。
如下设置or删除eth0的IP地址。
# 设置IP地址$ ip addr add 192.168.0.1/24 dev eth0 # 删除IP地址$ ip addr del 192.168.0.1/24 dev eth0 



启动关闭网卡与ifconfig类似，也使用up与down来进行启动和关闭，具体如下：
# 开启网卡$ ip link set eth0 up             # 关闭网卡$ ip link set eth0 down           



统计方便阅读选项-s可以统计一些信息方便我们阅读，如下看看网络的情况：
$ ip -s link1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00    RX: bytes  packets  errors  dropped overrun mcast       871883256468 251700492 0       0       0       0           TX: bytes  packets  errors  dropped carrier collsns     871883256468 251700492 0       0       0       0       2: eno1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc mq state UP mode DEFAULT group default qlen 1000    link/ether xx:xx:xx:xx:xx:xx brd ff:ff:ff:ff:ff:ff    RX: bytes  packets  errors  dropped overrun mcast       64930085920632 50955323447 0       613156  0       472190933     TX: bytes  packets  errors  dropped carrier collsns     17534345850354 17448077191 0       0       0       0       3: eno2: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 9000 qdisc mq state DOWN mode DEFAULT group default qlen 1000    link/ether xx:xx:xx:xx:xx:xx brd ff:ff:ff:ff:ff:ff    RX: bytes  packets  errors  dropped overrun mcast       0          0        0       0       0       0           TX: bytes  packets  errors  dropped carrier collsns     0          0        0       0       0       0  

可以看到对输出进行了一些格式化，看起来更直观。
探索网络连接的netstat在Linux系统中，网络是至关重要的部分，而netstat命令是管理和监视网络连接的强大工具之一。
它提供了关于网络接口和路由表的详细信息，有助于了解网络连接状态、统计信息以及网络协议的使用情况。
也更方便我们对网络的管理、故障排除以及安全监控等等。
基本概述netstat命令比较简单，通过简单的参数组合，可以获得各种网络相关的信息。
以下是一些常用的参数及其功能：

-a：显示所有连接和监听端口。
-t：仅显示TCP连接。
-u：仅显示UDP连接。
-n：以数字形式显示地址和端口号。
-p：显示进程标识符和程序名称。
-r：显示路由表。
-s：显示统计信息。

非交互的下载工具 wgetLinux系统中的wget是一个下载文件📀的命令行工具，特别普遍 。
对于Linux用户是必不可少的工具，对于经常要下载一些软件或从远程服务器恢复备份到本地服务器，这个命令尤为重要。
wget支持很多协议，比如HTTP，HTTPS和FTP协议，还可以使用HTTP代理。
wget的有诸多特点，比如

自动下载 wget支持自动下载，即wget可以在用户退出系统的之后在后台执行。这意味着你可以登录系统，启动一个wget下载任务，然后退出系统，wget将在后台执行直到任务完成，这是个牛气冲天的功能。
完全重建 wget 可以跟踪HTML页面上的链接依次下载来创建远程服务器的本地版本，完全重建原始站点的目录结构。这又常被称作”递归下载”。在递归下载的时候，wget 遵循Robot Exclusion标准(/robots.txt). wget可以在下载的同时，将链接转换成指向本地文件，以方便离线浏览。
高稳定 wget 非常稳定，它在带宽很窄的情况下和不稳定网络中有很强的适应性.如果是由于网络的原因下载失败，wget会不断地尝试，直到整个文件下载完毕。如果是服务器打断下载过程，它会再次联到服务器上从停止的地方继续下载。这对从那些限定了链接时间的服务器上下载大文件非常有用。

命令格式$ wget [参数] [URL地址]

用于从网络上下载资源，没有指定目录，下载资源会默认为当前目录。wget虽然功能强大，但是使用起来还是比较简单：
使用范例wget的命令参数很多，不过常用的为下面几个，详细的可以看进阶。
使用wget下载单个文件比如，我们下载个Ubuntu的最新版本，试下效果如何
$ wget http://releases.ubuntu.com/16.04/ubuntu-16.04-desktop-amd64.iso

在下载的过程中会显示进度条，包含（下载完成百分比，已经下载的字节，当前下载速度，剩余下载时间）。
使用wget -O下载并以不同的文件名保存这个对于动态链接的下载比较有用，特别是有些文件的名字实在是太……………….长了
$ wget -O wordpress.zip http://www.ubuntu.com/download.aspx?id=1234

使用wget -c断点续传$ wget -c http://releases.ubuntu.com/16.04/ubuntu-16.04-desktop-amd64.iso# or$ wget --continue http://releases.ubuntu.com/16.04/ubuntu-16.04-desktop-amd64.iso

使用wget -c重新启动下载中断的文件，对于我们下载大文件时突然由于网络等原因中断非常有帮助，我们可以继续接着下载而不是重新下载一个文件。需要继续中断的下载时可以使用-c参数。
使用wget -o把下载信息存入日志文件$ wget -o download.log URL

不希望下载信息直接显示在终端而是在一个日志文件，可以使用，特别注意需要与-O来区分开~

]]></content>
      <categories>
        <category>Linux集锦</category>
      </categories>
      <tags>
        <tag>ifconfig</tag>
        <tag>ip</tag>
        <tag>ping</tag>
        <tag>网络命令</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux最常用的几个软件包管理命令</title>
    <url>/2023/11/18/linux-collection-package-managerment/</url>
    <content><![CDATA[Linux最常用的几个软件包管理命令
仅个人想法，会持续不间断更新和改进。

软件安装，应该算是Linux系统中最常见的操作之一，而软件包管理命令，也是我们在Linux系统中最常用的命令之一。
但凡系统安装好以后，第一件事情就是更新软件包，然后安装自己需要的软件包，这是一个很常见的操作。
Linux不同与Windows，直接下载一个exe文件双击就可以安装，Linux系统需要命令行来安装软件包，这是一个很大的区别。
而用于安装、更新、删除软件包，以及管理系统的软件包又由于不同的Linux发行版，由不同的方式，比如apt、yum、dpkg、rpm等。

软件管理利器  - Debian系的apt对于最常用的命令而言，apt可能排不上号，但是，在新安装的系统中，apt 命令绝对应该是排在前十位的存在，所以apt是管理 Debian 系列系统中软件包的必备工具。

apt - command-line interface

apt是Advanced Package Tool的缩写，恰如字面描述高级包工具，apt 命令是用于 Debian 系列 Linux 发行版的强大工具，比如广为人知的Ubuntu，还有超赞桌面的Linux Mint。
apt使得处理软件包，比如安装、更新和删除软件包的过程特别丝滑，也结合了较早的工具如 apt-get 和 apt-cache 的功能，提供了更友好的交互体验。
更新软件包列表在安装或升级软件包之前，可以更新软件包列表，以确保拥有可用软件包的最新信息。
使用以下命令：
$ sudo apt update

此命令从配置的仓库中获取最新的软件包信息。
升级软件包要将所有已安装的软件包升级到最新版本，可以使用：
$ sudo apt upgrade

要进行更全面的升级，包括删除旧软件包和安装新依赖项，请使用：
$ sudo apt full-upgrade # 特别留意，这个会把老版本给删除

安装软件包apt 命令使得软件包安装变得非常简单。要安装一个软件包，只需要使用：
$ sudo apt install &lt;软件包名称&gt;

例如，要安装文本编辑器瑞士军刀 vim，您可以运行：
$ sudo apt install vim

删除软件包卸载软件包同样简单。要删除一个软件包，使用：
$ sudo apt remove &lt;软件包名称&gt;

如果您想删除软件包及其配置文件，使用：
$ sudo apt purge &lt;软件包名称&gt;

搜索软件包要查找某个软件包，可以使用关键词进行搜索：
$ apt search &lt;关键词&gt;

例如，要搜索与 “python” 相关的软件包，您可以运行：
$ apt search python

显示软件包信息要查看特定软件包的详细信息，使用：
$ apt show &lt;软件包名称&gt;

此命令提供软件包描述、依赖关系和版本信息等详细信息。
清理随着时间的推移，积累过时的软件包和缓存文件。要清理不必要的软件包，使用：
$ sudo apt autoremove

要清除本地存储库中获取的包文件，使用：
$ sudo apt clean

管理仓库apt 获取软件包信息的仓库列表存储在 /etc/apt/sources.list 及 /etc/apt/sources.list.d/ 目录下的文件中。
要添加新的仓库，可以直接编辑这些文件或使用 add-apt-repository 命令：
$ sudo add-apt-repository ppa:&lt;仓库名称&gt;

添加仓库后，需要更新软件包列表才能使用：
$ sudo apt update



红帽系的软件管理利器 - yum.. note::  当年不肯嫁春风，无端却被秋风误。  贺铸《芳心苦·杨柳回塘》
我从ubuntu开始，后面短暂切换到Fedora，然后切换到CentOS，在CentOS断更之前，再无改变，所以最了解的还是yum命令了。
官方定义为：

yum -  Yellowdog Updater Modified

说实话，yum跟yellowdog感觉半毛线关系都没有，那为什么有这个名字呢？
其实曾经有一个基于PowerPC架构的Linux发行版，名为Yellow Dog Linux。
而yum的名字即来源于此，且为其改进版本。
yum是一个强大的包管理工具，常用于 Red Hat 系的 Linux 发行版，如 CentOS、Fedora 和 RHEL。
它简化了安装、更新、删除和管理软件包的过程。
基本其他基于RPM的Linux发行版也使用这个命令。
其他列出了一些常用和不太常用的命令，基本足矣。
安装软件包使用 yum 安装软件包的基本语法是：
$ sudo yum install package_name

例如，要安装 wget 软件包，可以使用以下命令：
$ sudo yum install wget

yum 会自动解决依赖关系，确保所有必需的软件包都被安装。
更新软件包保持系统更新对于安全性和性能非常重要。要更新特定的软件包，使用：
$ sudo yum update package_name

例如，更新 wget：
$ sudo yum update wget

要更新所有已安装的软件包，只需运行：
$ sudo yum update

删除软件包如果需要删除一个软件包，语法如下：
$ sudo yum remove package_name

例如，删除 wget：
$ sudo yum remove wget

yum 将处理指定软件包的删除，并删除不再需要的依赖项。
检查可用更新要检查是否有可用更新而不实际应用它们，使用：
$ yum check-update

此命令会列出所有有可用更新的软件包，帮助您决定哪些需要更新。
列出已安装的软件包要列出系统上所有已安装的软件包，运行：
$ yum list installed

此命令提供了当前已安装的所有软件包的详细列表。
搜索软件包如果不确定软件包的确切名称，可以使用：
$ yum search keyword

例如，搜索与 wget 相关的软件包：
$ yum search wget

此命令会返回与关键字匹配的软件包列表。
显示软件包信息要查看特定软件包的详细信息，使用：
$ yum info package_name

例如，获取 wget 的信息：
$ yum info wget

此命令提供软件包的详细信息，如版本、发布、大小和简短描述。
清理 yum 缓存随着时间推移，yum 的缓存会增长并占用磁盘空间。要清理缓存，使用：
$ sudo yum clean all

此命令会删除缓存数据，释放空间，并确保 yum 获取最新的软件包信息。
管理仓库yum 使用仓库作为软件包的来源。要列出所有配置的仓库，运行：
$ yum repolist

启用特定仓库：
$ sudo yum-config-manager --enable repository_name

禁用特定仓库：
$ sudo yum-config-manager --disable repository_name

高级用法安装特定版本的软件包如果需要安装特定版本的软件包，使用：
$ sudo yum install package_name-version

例如，安装 wget 的 1.20 版本：
$ sudo yum install wget-1.20

降级软件包要将软件包降级到以前的版本，使用：
$ sudo yum downgrade package_name

组安装yum 允许您安装为特定目的而设计的一组软件包。例如，安装开发工具组，使用：
$ sudo yum groupinstall "Development Tools"



稍显底层的红帽系软件管理工具 - rpm如果说yum是高大上的软件安装管理工具，那么rpm就是低调奢华的底层工具。
简洁但略显繁琐。
官方定义为：

rpm - RPM Package Manager

其实rpm也可以看作是Redhat Package Manager的缩写，因为rpm也是基本用于Red Hat 系的 Linux 发行版，如 CentOS、Fedora 和 RHEL。
这个命令命令主要用于安装、卸载、升级、查询和验证软件包。所以重点来了，需要软件包。
安装软件包要使用 RPM 安装软件包，基本语法是：
$ sudo rpm -ivh package_name.rpm

比如，安装 example.rpm 软件包：
$ sudo rpm -ivh example.rpm

其中：

-i 表示安装（install）
-v 表示详细模式（verbose），显示安装过程的详细信息
-h 表示显示进度条（hash），可视化安装进度

升级软件包要升级已安装的软件包，使用：
$ sudo rpm -Uvh package_name.rpm

比如，升级 example.rpm：
$ sudo rpm -Uvh example.rpm

其中 -U 表示升级（upgrade），如果软件包未安装则进行安装。
删除软件包要删除已安装的软件包，语法如下：
$ sudo rpm -e package_name

比如，删除 example 软件包：
$ sudo rpm -e example

其中 -e 表示删除（erase）。
查询软件包查询已安装的软件包要查询系统上已安装的软件包，使用：
rpm -qa

其中 -q 表示查询（query），-a 表示所有（all）。
查询特定软件包信息要查看特定软件包的信息，使用：
$ rpm -qi package_name

比如，查询 example 软件包的信息：
$ rpm -qi example

其中 -i 表示信息（info）。
查询文件属于哪个软件包要查询系统中文件属于哪个软件包，使用：
$ rpm -qf /path/to/file

比如，查询 /usr/bin/example 文件属于哪个软件包：
$ rpm -qf /usr/bin/example

其中 -f 表示文件（file）。
验证软件包要验证已安装的软件包，使用：
$ rpm -V package_name

比如，验证 example 软件包：
$ rpm -V example

其中 -V 表示验证（verify）。
显示软件包内容要显示软件包中的文件列表，使用：
$ rpm -ql package_name

比如，显示 example 软件包的文件列表：
$ rpm -ql example

其中 -l 表示列表（list）。
检查软件包依赖要检查软件包的依赖关系，使用：
$ rpm -qpR package_name.rpm

比如，检查 example.rpm 软件包的依赖关系：
$ rpm -qpR example.rpm

其中：- -p 表示指定包文件（package）。- -R 表示依赖（requires）。]]></content>
      <categories>
        <category>Linux集锦</category>
      </categories>
      <tags>
        <tag>rpm</tag>
        <tag>yum</tag>
        <tag>Linux</tag>
        <tag>apt</tag>
        <tag>Linux汇总</tag>
        <tag>软件包</tag>
      </tags>
  </entry>
  <entry>
    <title>linux中最常用的搜索命令</title>
    <url>/2023/12/27/linux-collection-search-commands/</url>
    <content><![CDATA[Linux中最常用的搜索命令
 仅个人想法，会持续不间断更新和改进。

在Linux的庞大世界中，搜索犹如明灯，可以拨开云雾见青天，照亮我们前行大道路。
无论你是在浩瀚的代码库中搜索一个特定的函数，还是在庞大的文件系统中寻找一个文件，搜索命令着实是不可或缺尤为重要的工具。
而其中最绕不开的当属以下几个。

一切皆可查的 findfind命令用来在指定目录下查找文件，功能相当之强大。
官方定义为：

find - search for files in a directory hierarchy

Linux的哲学是一切皆文件，那么find的使命就是一切皆可查。
语法使用语法为：
$ find [-H] [-L] [-P] [-D debugopts] [-Olevel] [path...] [expression]

比较常用的几个参数为：

-exec &lt;执行指令&gt;：假设find指令的回传值为True，就执行该指令；
-size &lt;文件大小&gt;：查找符合指定的文件大小的文件；
-mtime &lt;24小时&gt;：查找在指定时间曾被更改过的文件或目录，单位以24小时计算；
-name&lt;范本样式&gt;：指定字符串作为寻找文件或目录的范本样式；
-type &lt;文件类型&gt;：只寻找符合指定的文件类型的文件；

无参数如果使用该命令时，不设置任何参数，则find命令将在当前目录下查找子目录与文件,并且将查找到的子目录和文件全部进行显示。
$ ls -ltotal 310M-rw-rw-r-- 1 user user  10M Mar 21 20:01 adrwxrwxr-x 2 user user   22 Mar 21 20:01 aa-rw-rw-r-- 1 user user 100M Mar 21 20:01 b-rw-rw-r-- 1 user user 200M Mar 21 20:01 c$ find ../a./b./c./test



查找小于，等于和大于100MB的文件通过-size大小来查找文件
$ find . -size -100M../a./aa$ find . -size 100M./b$ find . -size +100M./c./aa/d

查找多长时间修改过可以通过参数-mtime来查找文件的修改时间，比如如下可以查找当前目录下最近60天没有被修改的文件。
$ find . -mtime +60# 最近2天以内未修改$ find . –mtime -2



稍微复杂但是很有用的命令 我经常把 find 命令和他的选项 exec一起使用，比如我想查找一个目录中的所有文件并将其更改其权限。可以通过以下简单命令完成：
$ find /path/ -type f -exec chmod 644 {} \;

这个命令会递归搜索指定目录内/path/下的所有文件，并对找到的文件执行 chmod 命令。
精准快速定位的locate.. note::
  众里寻他千百度，蓦然回首，那人却在灯火阑珊处  -李煜
Linux locate命令用于查找符合条件的文档、程序、目录等等。这个命令会在数据库中查找符合条件的各种信息。
一般情况我们只需要输入 locate name 即可查找。
官方定义为：

locate - list files in databases that match a pattern

使用方法为：
$ locate  [-d  path  |  --database=path]  [-e  | -E | --[non-]existing] [-i | --ignore-case] [-0 | --null] [-c |       --count] [-w | --wholename] [-b | --basename] [-l N | --limit=N] [-S | --statistics] [-r | --regex ] [--regex‐       type  R] [--max-database-age D] [-P | -H | --nofollow] [-L | --follow] [--version] [-A | --all] [-p | --print]       [--help] pattern...

看着很复杂，不过常用的参数倒是不多，基本为：

-n :  至多显示 n个输出。
-i, --ignore-case : 忽略大小写

默认无参数默认情况下，locate直接跟上需要查找的信息就可以了，如下所示：
$ locate set_vis.cpp/home/user/mycode/src/set_vis.cpp# 以查找apropos为例$ locate apropos/usr/bin/apropos/usr/local/difmap/help/apropos.hlp/usr/share/emacs/24.3/lisp/apropos.elc/usr/share/man/de/man1/apropos.1.gz/usr/share/man/es/man1/apropos.1.gz/usr/share/man/fr/man1/apropos.1.gz/usr/share/man/id/man1/apropos.1.gz/usr/share/man/it/man1/apropos.1.gz/usr/share/man/ja/man1/apropos.1.gz/usr/share/man/man1/apropos.1.gz/usr/share/man/nl/man1/apropos.1.gz/usr/share/man/pl/man1/apropos.1.gz/usr/share/man/ru/man1/apropos.1.gz



太多需要简单化如果输出的信息很多，仅仅希望看到前面的几个，使用-n参数既可
# 仅仅查看前的3个$ locate -n 3 apropos/usr/bin/apropos/usr/local/difmap/help/apropos.hlp/usr/share/emacs/24.3/lisp/apropos.elc



不区分大小写部分情况下，可能有大小写混淆的情况，此时使用-i参数既可
$ $ locate -i set_vis.cpp/home/user/mycode/src/set_vis.cpp/home/user/mycode_CPP/src/set_VIS.cpp



说明不过刚按照的系统，这个命令并不一定有输出，主要是因为locate 与 find 不同，  find 直接在硬盘找，而locate 只在数据库中查找。
这个数据库在CentOS系统默认的为 /var/lib/mlocate/mlocate.db 中，所以 locate 的查找会比较快，但并一定是实时的，而是以数据库的更新为准。
可以通过下面的命令手工升级数据库 ，命令为：
$ updatedb

然后就可以使用了。
文件内容搜索利器 - grepLinux grep 命令用于查找文件里符合条件的字符串。
官方定义为：

grep, egrep, fgrep - print lines matching a pattern

grep支持正则表达式，是一个强大的文本搜索工具。
语法语法也挺复杂，因为功能确实很强大。
$ grep [OPTION...] PATTERNS [FILE...]$ grep [OPTION...] -e PATTERNS ... [FILE...]      # 使用egrep$ grep [OPTION...] -f PATTERN_FILE ... [FILE...]  # 使用fgrep

常用的参数为：

-r 或 –recursive : 此参数的效果和指定”-d recurse”参数相同
-v 或 –invert-match : 显示不包含匹配文本的所有行
-i 或 –ignore-case : 忽略字符大小写的差别
-n 或 –line-number : 在显示符合样式的那一行之前，标示出该行的列数编号。

假定有如下3个文件，1个文件夹，内容如下：
a    This is a    Hello a    b     this is b    Hello bc     This is c    Hello cd/d     This is d    Hello d



默认无参数在当前目录搜索包含is字符串，可以看到**a/b/c**三个文件均有输出，而d因为是目录，暂时无输出。
$ grep is *a:This is ab:this is bc:This is cgrep: d: Is a directory



增加文件夹与其他命令类似，增加-r参数，递归搜索
$ grep -r is *a:This is ab:this is bc:This is cd/d:This is d



反向查找在某些情况下，或许正想找到不包含某些字符串的内容，如下：
$ grep -rv is *a:Hello ab:Hello bc:Hello cd/d:Hello d

此时可以看到，不包含is的内容显示了出来。
不区分大小写而某些情况下，或许我们希望找到不区分大小写的内容，比如对于This/this而言：
$ grep -r This *a:This is ac:This is cd/d:This is d$ grep -ri This *a:This is ab:this is bc:This is cd/d:This is d

可以看到此时有可能笔误，或者其他原因的b文件已经被找到了。
显示行数，精准定位   如果文件内容比较多，此时显示内容在哪一行，是很重要的，加上-n参数既可解决。
$ grep -rn This *a:1:This is ac:1:This is cd/d:1:This is d


]]></content>
      <categories>
        <category>Linux集锦</category>
      </categories>
      <tags>
        <tag>search</tag>
        <tag>find</tag>
        <tag>locate</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux 炫技收集</title>
    <url>/2022/10/09/linux-collection-tricks/</url>
    <content><![CDATA[Linux 炫技收集点滴技巧，让你的Linux使用更加得心应手。linux中的一些小技巧可以大大提高你的工作效率，本文就细数那些提高效率或者简单却有效的linux技巧。
炫技 - 快速执行上一条命令第一种方法：在终端输入两个感叹号，然后回车就可以快速地执行上一条命令了。
$ !!



!$
上一个命令

这个命令目测，用的人不多，其实比较有用，且有效。
$ cd !$

表明的意思是将上一个命令的参数作为cd的参数来使用。
清空文件内容比如有一个大文件，你想快速删除，或者不想删除，但是想清空内容：
&gt;filenamefilename

将日志同时记录文件并打印到控制台在执行shell脚本，常常会将日志重定向，但是这样的话，控制台就没有打印了，如何使得既能记录日志文件，又能将日志输出到控制台呢？
$ ./test.sh |tee test.log

终止并恢复进程执行我们使用ctrl+z 暂停一个进程的执行，也可以使用fg恢复执行。例如我们使用
$ cat filename

当我们发现文件内容可能很多时，使用ctrl+z暂停程序，而如果又想要从刚才的地方继续执行，则只需要使用fg命令即可恢复执行。或者使用bg使得进程继续在后台执行。
计算程序运行时间我们可能会进程写一些小程序，并且想要知道它的运行时间，实际上我们可以很好的利用time命令帮我们计算，例如：
$ time ./app real    0m0.088suser    0m0.084ssys    0m0.004s

它会显示系统时间，用户时间以及实际使用的总时间。
屏幕冻结程序运行时，终端可能输出大量的日志，你想简单查看一下，又不想记录日志文件，此时可以使用ctrl+s键，冻结屏幕，使得日志不再继续输出，而如果想要恢复，可使用ctrl+q退出冻结。
终端快捷操作删除从光标到结尾处的命令文本ctrl+k
历史命令快速执行我们都知道history记录了执行的历史命令，而使用 !＋历史命令前的数字，可快速执行历史命令。另外，还可以使用ctrl+r搜索执行过的命令。
时间炫技下面这个命令基本就能得到所有的信息了
$ date +%Y年%m月%d日%H时%M分%S秒第%j日%q季度第%U周周%A时区%Z2014年05月06日13时13分14秒第126日2季度第18周周Tuesday时区CST
]]></content>
      <categories>
        <category>Linux集锦</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Linux汇总</tag>
      </tags>
  </entry>
  <entry>
    <title>linux中最常用的用户信息命令</title>
    <url>/2024/01/01/linux-collection-user-information-commands/</url>
    <content><![CDATA[
groups - show group memberships
finger - shows information about users
last - displays most recent user logins

linux中最常用的用户信息命令
 仅个人想法，会持续不间断更新和改进。

用户信息，重中之重。
虽然21世纪最重要的是人才。
但对于我们个人而言，用户信息也是极其重要并特别需要留意的。

还有谁 lastLinux last 命令用于显示用户最近的登录信息。
官方定义为：

 last, lastb - show listing of last logged in users

通过读取/var/log/wtmp文件来获取这些信息。
语法$ last [-R] [-num] [ -n num ] [-adFiowx] [ -f file ] [ -t YYYYMMDDHHMMSS] [name...]  [tty...]

参数：

-R 省略 hostname 的栏位

-n 展示前 num 个

username 展示 username 的登入讯息

tty 限制登入讯息包含终端机代号


一般使用方法$ lastusername2  pts/17       192.168.100.123  Wed Mar 23 22:14   still logged inusername3  pts/20       localhost:11.0   Wed Mar 23 14:26 - 15:48  (01:21)username4  pts/23       localhost:11.0   Wed Mar 23 14:26 - 15:48  (01:21)username4  pts/4        192.168.100.125    Thu Jun 10 18:37 - 22:57  (04:20)username5  pts/4        192.168.100.125    Thu Jun 10 18:21 - 18:21  (00:00)username6  pts/9        192.168.100.126    Thu Jun 10 18:11 - 18:20  (00:09)username7  pts/15       192.168.100.122    Thu Jun 10 18:04 - 23:44 (1+05:40)username8  pts/14       192.168.100.121    Thu Jun 10 17:59 - 07:50  (13:50)username9  pts/9        192.168.100.126    Thu Jun 10 17:59 - 18:03  (00:04)wtmp begins Thu Jun 10 17:33:14 2013




查看最近登陆的三个用户$ last -3username2  pts/17       192.168.100.123  Wed Mar 23 22:14   still logged inusername3  pts/20       localhost:11.0   Wed Mar 23 14:26 - 15:48  (01:21)username4  pts/23       localhost:11.0   Wed Mar 23 14:26 - 15:48  (01:21)wtmp begins Thu Jun 10 17:33:14 2013

省略hostname$ last -3 -Rusername2  pts/17         Wed Mar 23 22:14   still logged inusername3  pts/20         Wed Mar 23 14:26 - 15:48  (01:21)username4  pts/23         Wed Mar 23 14:26 - 15:48  (01:21)wtmp begins Thu Jun 10 17:33:14 2013




显示最后一列显示主机IP地址$ last -n 5 -a -iusername3  pts/17       Wed Mar 23 22:14   still logged in    192.168.100.123username5  pts/20       Wed Mar 23 14:26 - 15:48  (01:21)     0.0.0.0username6  pts/23       Wed Mar 23 14:26 - 15:48  (01:21)     0.0.0.0username7  pts/19       Wed Mar 23 13:46 - 15:48  (02:01)     192.168.100.123username8  pts/17       Wed Mar 23 13:18 - 15:47  (02:29)     192.168.100.123wtmp begins Thu Jun 10 17:33:14 2013





我是谁 whoami我知道你是谁，但我不知道我是谁，此时whoami可以帮助你，哈哈。
whoami将打印当前用户的名字。与id -un类似。
官方定义为：

whoami - print effective userid

用法为：
$ whoami [option] ..

这命令，基本没有参数。
我暂时。。也没有想到为什么会有这个命令。
唯一的可能使你找管理员来配置个啥，然后他需要知道你是谁，不，我是谁。
我看了一下源码，果然简洁：
#include &lt;config.h&gt;#include &lt;stdio.h&gt;#include &lt;sys/types.h&gt;#include &lt;pwd.h&gt;#include "system.h"#include "die.h"#include "error.h"#include "long-options.h"#include "quote.h"/* The official name of this program (e.g., no 'g' prefix).  */#define PROGRAM_NAME "whoami"#define AUTHORS proper_name ("Richard Mlynarik")voidusage (int status){  if (status != EXIT_SUCCESS)    emit_try_help ();  else    {      printf (_("Usage: %s [OPTION]...\n"), program_name);      fputs (_("\Print the user name associated with the current effective user ID.\n\Same as id -un.\n\\n\"), stdout);      fputs (HELP_OPTION_DESCRIPTION, stdout);      fputs (VERSION_OPTION_DESCRIPTION, stdout);      emit_ancillary_info (PROGRAM_NAME);    }  exit (status);}intmain (int argc, char **argv){  struct passwd *pw;  uid_t uid;  uid_t NO_UID = -1;  initialize_main (&amp;argc, &amp;argv);  set_program_name (argv[0]);  setlocale (LC_ALL, "");  bindtextdomain (PACKAGE, LOCALEDIR);  textdomain (PACKAGE);  atexit (close_stdout);  parse_gnu_standard_options_only (argc, argv, PROGRAM_NAME, PACKAGE_NAME,                                   Version, true, usage, AUTHORS,                                   (char const *) NULL);  if (optind != argc)    {      error (0, 0, _("extra operand %s"), quote (argv[optind]));      usage (EXIT_FAILURE);    }  errno = 0;  uid = geteuid ();  pw = (uid == NO_UID &amp;&amp; errno ? NULL : getpwuid (uid));  if (!pw)    die (EXIT_FAILURE, errno, _("cannot find name for user ID %lu"),         (unsigned long int) uid);  puts (pw-&gt;pw_name);  return EXIT_SUCCESS;}



其中使用的即为uid = geteuid ();。
谁？who.. note::  物是人非事事休，欲语泪先流。  李清照《武陵春·春晚》
知道了我是谁，接下来就要知道谁是谁了。
who将显示谁在登录，显示的内容可能包括用户名、终端登录口，登录的时间等等信息。
官方定义为：

who - show who is logged on

用法为：
$ who [OPTION]... [ FILE | ARG1 ARG2 ]

常用的参数为：

-q , --count：只显示登入系统的帐号名称和总人数；
-s：此参数将忽略不予处理，仅负责解决who指令其他版本的兼容性问题；
-a, --all：效果为加上 -b -d --login -p -r -t -T -u
-b, --boot：上一次系统的重启时间
-d, --dead：打印dead进程 
-H, --heading：打印每一列的表头
-q, --count：所有登录的用户名以及用户登录的数量
-s, --short：打印USER/LINE/WHEN（默认为这个参数）

默认使用显示当前登录系统的用户
$ who       user      pts/0  2012-03-02 10:12 user2     pts/1  2012-03-10 09:12



系统的运行时间这个信息显示系统自上一次重启后的运行时间。
$ who -b			system boot 2012-02-16 14:05



显示表头信息使用-H或者--heading可以看到表头信息
$ who -HUSER     LINE     WHEN         user      pts/0  2012-03-02 10:12 user2     pts/1  2012-03-10 09:12



显示登录的人员及总数$ who -quser1 user1 user2 user2 user3 user4# users=6



什么？谁？w (who &amp; what)w可以认为是加强版的who，果然越简洁越强大，就比如less比more是功能更多的。
w不仅可以显示谁在登录，还可以打印他们在做什么。w显示的信息如下：

登录的用户；
运行的程序；
第一行显示的信息：当前时间、系统运行的时间、多少用户登录、系统的负载（分贝为1，5，15分钟）

官方定义为：

 w - Show who is logged on and what they are doing.

用法为：
$ w [options] user [...]



常用的两个选项为：

-h 　不显示各栏位的标题信息列。

-s 　简洁格式列表，不显示用户登入时间，JCPU或者PCPU的时间


默认的显示显示当前用户的登录信息及执行的命令
$ w16:29:03 up 26 days,  2:49, 6 users,  load average: 1.00, 0.97, 0.96USER     TTY      FROM LOGIN@   IDLE   JCPU   PCPU WHATuser     pts/4    :1   07Sep21 20days  9:59   1:53m bashuser     pts/0    :2   08Sep21  6days  0.70s  1:53m zshuser     pts/1    :3   08Sep21 20days  1:13m  1:53m bashuser      :0      :0   15Sep21 6days  27days 21.36s zshuser     pts/2    :0   15Sep21 14days  0.25s  0.25s zshuser     pts/3    :3   16Sep21 24:45m  0.22s  0.22s bash



不显示标题行$ w -h16:29:16 up 26 days,  2:49, 6 users,  load average: 1.20, 0.67, 0.76USER     TTY      FROM  LOGIN@   IDLE   JCPU   PCPU WHATuser     pts/4    :1    07Sep21 20days  9:59   1:53m bashuser     pts/0    :2    08Sep21  6days  0.70s  1:53m zshuser     pts/1    :3    08Sep21 20days  1:13m  1:53m bashuser      :0      :0    15Sep21 6days  27days 21.36s zshuser     pts/2    :0    15Sep21 14days  0.25s  0.25s zshuser     pts/3    :3    16Sep21 24:45m  0.22s  0.22s bash



简洁模式显示$ w -s16:29:26 up 26 days,  2:49, 6 users,  load average: 1.50, 0.67, 0.36USER     TTY      FROM    IDLE   WHATuser     pts/4    :1     20days  bashuser     pts/0    :2      6days  zshuser     pts/1    :3     20days  bashuser      :0      :0     6days   zshuser     pts/2    :0     14days  zshuser     pts/3    :3     24:45m  bash







不要告诉别人的passwdpasswd用于创建或者更新用户密码，是管理员必备的命令之一。
这个命令最终的实现是通过调用Linux-PAM 和Libuser API来实现的。
官方的定义为：

passwd - update user’s authentication tokens

使用的方法为：
$ passwd [-k] [-l] [-u [-f]] [-d] [-e] [-n mindays] [-x maxdays] [-w warndays] [-i inactivedays] [-S] [--stdin] [username]

其中很常用的options为：

-S, --status：显示密码的状态信息
-d, --delete：删除用户密码，此时该用户将处于无密码状态

不太常用的options为：

--stdin：可以通过标准输入，亦可以为一个pipe
-l, --lock：锁定账号，不过也不是完全锁定，因为用户可以通过ssh key来继续访问
-u, --unlock：与上面的-l选项相反，属于解锁用户
-w, --warning DAYS：口令到期前通知用户，具备password lifetime的才支持

修改或更新密码这个是最常用的用法，用于设置或者修改更新用户密码
$ sudo passwd user  		#设置用户user的密码Enter new UNIX password:  	#输入新密码，输入的密码不显示Retype new UNIX password:  	#再次输入确认密码passwd: password updated successfully# 此时设置成功



删除用户密码$ sudo passwd -d user passwd: password expiry information changed.

此时用户处于无密码的状态，很类似最近说的，没有密码就是最安全的密码。
查看密码的状态$ sudo passwd -S user[sudo] password for oper: user PS 2013-02-11 0 99999 7 -1 (Password set, SHA512 crypt.)



​      
说到密码，有两个比较重要的原则：

保护好你的密码，不写下来而是记在脑海里，定时修改；
选择一个很难猜的密码，而不是最容易被攻破的top密码；


]]></content>
      <categories>
        <category>Linux集锦</category>
      </categories>
      <tags>
        <tag>last</tag>
        <tag>passwd</tag>
        <tag>w</tag>
        <tag>who</tag>
        <tag>whoami</tag>
        <tag>用户信息</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux ARG_MAX, maximum length of arguments for a new process</title>
    <url>/2017/03/23/linux-command-line-arg-max/</url>
    <content><![CDATA[
https://www.in-ulm.de/~mascheck/various/argmax/

ARG_MAX, maximum length of arguments for a new processor why do you getcommand: arg list too long2002-06-06 .. 2016-09-07 (see recent changes)
Here you’ll find
More about the nature of this limitThe effectively usable space …and a way to determine it reliably…alternatively: about the GNU autoconf checkHow to avoid the limit in a shellother limits: number of arguments and maximum length of one argumentActual values for ARG_MAX (with some more details in the footnotes)More pagesMore about the nature of this limitYou will see this error message, if you try to call a program with too many arguments, that is,most likely in connection with pattern matching:
$ command *

On some systems the limit is even hit with “grep pattern /usr/include//“ (apart from that using find would be more appropriate).
It’s only the exec() system call and its direct variants, which will yield this error.They return the corresponding error condition E2BIG (&lt;sys/errno.h&gt;).The shell is not to blame, it just delivers this error to you.In fact, shell expansion is not a problem, because here exec() is not needed, yet.Expansion is only limited by the virtual memory system resources [1].
Thus the following commands work smoothly, because instead of handing over too many arguments to a new process,they only make use of a shell built-in (echo) or iterate over the arguments with a control structure (for loop):
/dir-with-many-files$ echo * | wc -c
/dir-with-many-files$ for i in * ; do grep ARG_MAX "$i"; done

There are different ways to learn the upper limit
command: getconf ARG_MAX [2]system call: sysconf(_SC_ARG_MAX) [3]system header: ARG_MAX in e.g. &lt;[sys/]limits.h&gt; [4]try xargs –show-limits[5], if you use GNU xargs(However, on the few system that have no limit for ARG_MAX, these methods wrongly might print a limit.)
From Version 7 on the limit was defined by NCARGS (usually in &lt;[sys/]params.h&gt;),Later, ARG_MAX was introduced with 4.4BSD and System V.
In contrast to the headers, sysconf and getconf tell the limit which is actually in effect.This is relevant on systems which allow to change it at run time (AIX), by reconfiguration (UnixWare, IRIX),by recompiling (e.g. Linux) or by applying patches (HP-UX 10) - see the end notes for more details.(Usually these are solutions for special requirements only, because increasing the limit doesn’t solve the problem.)
[1]	However, in contrast to such expansions (which includes the literal overall command line length in scripts),

shells do have a limit for the interactive command line length (that is, what you may type in after the prompt).But this limit is shell specific and not related to ARG_MAX.Interestingly, putenv(3) is only limited by system resources, too. You just can’t exec() anmymore if you are over the limit.    [2]	4.4BSD BSD and the successors ( NetBSD since 1.0, OpenBSD 2.0, FreeBSD 2.0 ) provide: sysctl kern.argmax.getconf in turn was introduced on BSDs with these versions: NetBSD 1.0, OpenBSD 2.0, FreeBSD 4.8.    [3]	example usage of sysconf():#include &lt;stdio.h&gt;#include &lt;unistd.h&gt;int main() {    return printf(“ARG_MAX: %ld\n”, sysconf(_SC_ARG_MAX));}    [4]	A handy way to find the limits in your headers, if you have cpp(1) installed, which doesn’t abort on file not found,(inspired by Era Eriksson’s page about ARG_MAX):
cpp &lt;&lt;EOF#include &lt;limits.h&gt;#include &lt;param.h&gt;#include &lt;params.h&gt;#include &lt;sys/limits.h&gt;#include &lt;sys/param.h&gt;#include &lt;sys/params.h&gt;arg_max: ARG_MAXncargs: NCARGSEOFIf your cpp doesn’t like non-existent files, you might try
for file in limits.h param.h params.h sys/limits.h sys/param.h sys/params.h linux/limits.h linux/limits.h linux/param.h; docpp &lt;&lt;EOF 2&gt;&amp;1#include &lt;$file&gt;arg_max: ARG_MAXncargs: NCARGSEOFdone|egrep ‘arg_max|ncargs’ |egrep -v ‘ARG_MAX|NCARGS’
[5]	$ xargs --show-limits

environment variables take up 533 bytesPOSIX upper limit on argument length (this system): 2094571POSIX smallest allowable upper limit on argument length (all systems): 4096Maximum length of command we could actually use: 2094038Size of command buffer we are actually using: 131072The effectively usable spaceWhen looking at ARG_MAX/NCARGS, you have to consider the space comsumption by both argv[] and envp[] (arguments and environment).Thus you have to decrease ARG_MAX at least by the results of “env|wc -c” and “env|wc -l * 4” [5] for a good estimation of the currently available space.
[5]	 Every entry in envp is terminated with a null byte. The env utility adds a terminating newline instead, so the result of "wc -c" is the same.

“wc -l” in turn accounts for the number of pointers in envp, i.e., usually 4 bytes each, according to sizeof().Some modern shells allow for exporting functions to the environment. The above slightly miscalculates then,because their definitions tend to contain newlines which are misinterpreted as new envp[].The same applies if variable values contain newlines.You can make wc -l ignore the wrappings and limit it to lines with = at the right place:expr getconf ARG_MAX - env|wc -c - env|egrep '^[^ ]+='|wc -l * 4(thanks to Michael Klement for pointing out the function issue and improving the calculation)
POSIX suggests to subtract 2048 additionally so that the process may savely modify its environment. A quick estimation with the getconf command:(all the calculations inspired by a post from Gunnar Ritter in de.comp.os.unix.shell, 3B70A6AD.3L8115910@bigfoot.de)
 expr getconf ARG_MAX - env|wc -c - env|wc -l * 4 - 2048        or, if you even want to consider wrapped functions or variable values [5],expr getconf ARG_MAX - env|wc -c - env|egrep '^[^ ]+='|wc -l * 4 - 2048,…and a way to determine it reliablyThe most reliable way to get the currently available space is to test the success of an exec() with increasing length of arguments until it fails.This might be expensive, but at least you need to check only once, the length of envp[] is considered automatically, and the result is reliable.…alternatively: about the GNU autoconf checkThere’s an autoconf check “Checking for maximum length of command line arguments…”. It works quite similar.However, it results in a much lower value (it can be a fourth of the actual value only) both by intention and for reasons of simplicity:In a loop with increasing n, the check tries an exec() with an argument length of 2n (but won’t check for n higher than 16, that is 512kB).The maximum is ARG_MAX/2 if ARG_MAX is a power of 2.Finally, the found value is divided by 2 (for safety), with the reason “C++ compilers can tack on massive amounts of additional arguments”.
How to avoid the limit in a shellIf command * fails, then you caniterate with the shell:for i in *; do command “$i”; done     (simple, completely robust and portable, may be very slow)printf ‘%s\0’ *|xargs -0 command     (works only if printf is a built-in, but then it can be much faster on high counts. thanks to Michael Klement)iterate with findfind . -exec command {} ;     (simple, completely robust and portable, may be very slow)find . -exec command {} +       (optimizes speed, quite portable)find . -print0|xargs -0 command      (optimizes speed, if find doesn’t implement “-exec +” but knows “-print0”)find . -print|xargs command     (if there’s no white space in the arguments)
Note: find descends into directories. To avoid that portably, you can use“find . ! -name . -prune […]”If the major part of the arguments consists of long, absolute or relative paths, then try to move your actions into the directory:cd /directory/with/long/path; command *And another quick fix may be to match fewer arguments:command [a-e]; command [f-m]; …Number of arguments and maximum length of one argumentAt least on Linux 2.6, there’s also a limit on the maximum number of arguments in argv[].On Linux 2.6.14 the function do_execve() in fs/exec.c tests if the number exceeds  PAGE_SIZE*MAX_ARG_PAGES-sizeof(void *) / sizeof(void *)On a 32-bit Linux, this is ARGMAX/4-1 (32767). This becomes relevant if the average length of arguments is smaller than 4.Since Linux 2.6.23, this function tests if the number exceeds MAX_ARG_STRINGS in &lt;linux/binfmts.h&gt; (2^32-1 = 4294967296-1).
And as additional limit since 2.6.23, one argument must not be longer than MAX_ARG_STRLEN (131072).This might become relevant if you generate a long call like “sh -c ‘automatically generated with many arguments’”.(pointed out by Xan Lopez and Ralf Wildenhues)
Actual values for ARG_MAX (or NCARGS)The maximum length of arguments for a new process is varying so much among unix flavours, that I had a look at some systems:
System	value	getconfavailable	default value determined bynon-competitive: 1st edition (V1)	255+? [1stEd]		experimentsnon-competitive: V4, V5 and V6	512		documentation of exec(2) in V4, V6 and (no manual) sys1.c in V5Version 7,3 BSD,System III, SVR1,Ultrix 3.1	5120		NCARGS in &lt;sys/param.h&gt;4.0/4.1/4.2 BSD	10240		NCARGS in &lt;sys/param.h&gt;4.3 BSD / and -Tahoe	20480		NCARGS in &lt;sys/syslimits.h&gt;4.3BSD-Reno, 4.3BS-Net24.4 BSD (alpha/lite/encumbered),386BSD*, NetBSD 0.9,BSD/OS 2.0	20480		ARG_MAX in &lt;sys/syslimits.h&gt; (NCARGS in &lt;sys/param.h&gt;)POSIX/SUSv2,v3,v4 [posix]	4096 (minimum)	+	minimum _POSIX_ARG_MAX in &lt;limits.h&gt; , ARG_MAXAIX 3.x, 4.x, 5.1[aix5]	24576	+	ARG_MAX in &lt;sys/limits.h&gt; (NCARGS in &lt;sys/param.h&gt;)AIX 6.1, 7.2	1048576	+	online documentation (FilesReference/HeaderFiles) 6.1, 7.2 (ARG_MAX in &lt;limits.h&gt;)BSD/OS 4.1,NetBSD 1.0+x,OpenBSD x:	262144	+	ARG_MAX(/NCARGS) in &lt;sys/syslimits.h&gt;Cygwin 1.7.7 (win 5.1) [cygwin]	30000		ARG_MAX in &lt;limits.h&gt;Dynix 3.2	12288		ARG_MAX in &lt;(sys/)limits.h&gt; (NCARGS in &lt;sys/param.h&gt;)EP/IX 2.2.1AA:	20480		ARG_MAX in &lt;sys/limits.h&gt;FreeBSD 2.0-5.5	65536	+	ARG_MAX(/NCARGS) in &lt;sys/syslimits.h&gt; [freebsd]FreeBSD 6.0 (PowerPC 6.2, ARM 6.3)	262144	+	ARG_MAX(/NCARGS) in &lt;sys/syslimits.h&gt; [freebsd]GNU Hurd 0.3 Mach 1.3.99	unlimited [hurd](stack size?)	+	Haiku OS (2008-05-14) [haiku]	131072	?	MAX_PROCESS_ARGS_SIZE in &lt;system/user_runtime.h&gt;HP-UX 8(.07), 9, 10	20478	+	ARG_MAX in &lt;limits.h&gt;HP-UX 11.00	2048000 [hpux]	+	ARG_MAX in &lt;limits.h&gt;Interix 3.5	1048576	+	-IRIX 4.0.5	10240		NCARGS in &lt;sys/param.h&gt; (fallback: ARG_MAX in &lt;limits.h&gt;: 5120)IRIX 5.x, 6.x	20480 [irix]	+	(fallback: ARG_MAX in &lt;limits.h&gt;: 5120)Linux -2.6.22	131072	+	ARG_MAX in &lt;linux/limits.h&gt; [linux-pre-2.6.23]Linux 2.6.23	(1/4th of stack size)	+	kernel code [linux-2.6.23]MacOS X 10.6.2 (xnu 1486.2.11)	262144	+	ARG_MAX(/NCARGS) in &lt;sys/syslimits.h&gt;MUNIX 3.2	10240	?	ARG_MAX in &lt;sys/syslimits.h&gt;Minix 3.1.1	16384		ARG_MAX in &lt;limits.h&gt;OSF1/V4, V5	38912	+	ARG_MAX in &lt;sys/syslimits.h&gt;SCO UNIX SysV R3.2 V4.0/4.2SCO Open Desktop R2.0/3.0	5120	?	online documentationSCO OpenServer 5.0.x [osr5]	1048576	+	(fallback: ARG_MAX in &lt;limits.h&gt;: 5120)UnixWare 7.1.4,OpenUnix 8	32768 [uw/osr6]	+	(fallback ARG_MAX in &lt;limits.h&gt;: 10240)SCO OpenServer 6.0.0	32768 [uw/osr6]	+	(fallback: ARG_MAX in &lt;limits.h&gt;: 10240)SINIX V5.2	10240	?	ARG_MAX in &lt;limits.h&gt;SunOS 3.x	10240	?	ARG_MAX in &lt;sys/param.h&gt;SunOS 4.1.4	1048576		NCARGS in &lt;sys/param.h&gt; , sysconf(_SC_ARG_MAX)SunOS 5.x (32bit process)	1048320 [sunos5]	+	ARG_MAX in &lt;limits.h&gt; (NCARGS in &lt;sys/param.h&gt;)SunOS 5.7+ (64bit process)	2096640 [sunos5]	+	ARG_MAX in &lt;limits.h&gt; (NCARGS in &lt;sys/param.h&gt;)SVR4.0 v2.1 (386)	5120		? (no ARG_MAX/NCARGS in in &lt;limits.h&gt;/&lt;sys/param.h&gt;)Ultrix 4.3 (vax / mips)	10240 / 20480		NCARGS in &lt;sys/param.h&gt;Unicos 9,Unicos/mk 2	49999	+	ARG_MAX in &lt;sys/param.h&gt;UnixWare 7: see OpenServer 6UWIN 4.3 AT&amp;T Unix Services for Windows	32768	+	ARG_MAX in &lt;limits.h&gt;[posix]	See the online documentation (please register for access) for getconf and &lt;limits.h&gt;.[osr5]	Bela Lubkin points out:The limit on SCO OpenServer 5.0.x is set by ‘unsigned int maxexecargs = 1024*1024;’in /etc/conf/pack.d/kernel/space.c. It can also be changed on a live system with the scodb kernel debugger:
scodb -w   scodb&gt; maxexecargs=1000000   scodb&gt; q(0x1000000 = 16MiB.) This is the max size of a new temporary allocation during each exec(), so it’s safe to change on the fly.
Exceeding the limit generates a kernel warning:
   WARNING: table_grow - exec data table page limit of 256 pages (MAXEXECARGS) exceeded by 1 pages   WARNING: Reached MAXEXECARGS limit while adding arguments for executable “ls”Some configure scripts trigger this message as they deliberately probe the limit.Raising `maxexecargs’ will not fix this as the probe will simply try harder.
[uw/osr6]	The limit on UnixWare can be increased by changing the kernel parameter ARG_MAX with /etc/conf/bin/idtune,(probably in the range up to 1MB) regenerating the kernel with “etc/conf/bin/idbuild -B” and rebooting.See also the online documentation.On UnixWare 7.1.4, the run time limit for a default install of “Business Edition” is 32768.
Bela Lubkin points out, that, very basically, OpenServer 6 can be described as a UnixWare 714 kernel with the OpenServer 5.0.7 userland running on top of it.
[irix]	The limit on IRIX can be changed by changing the kernel parameter ncargs with systune(in the range defined in /var/sysgen/mtune/kernel, probably varying from 64KB to 256KB),regenerating the kernel with “autoconfig” and rebooting. See also the online documentation of systune(1M) and intro(2).[aix5]	The limit on AIX 5.1 can be changed at run time with “chdev -l sys0 -a ncargs=value”, in the range from 64KB to 10244KB.See also the online documentation for chdev (AIX documentation, Commands reference).[freebsd]	Interesting and everything but academic was the reason for the first of two increases (40960, 65536) on FreeBSD:    “Increase ARG_MAX so that `make clean’ in src/lib/libc works again.    (Adding YP pushed it over the limit.)”quoted from http://www.FreeBSD.org/cgi/cvsweb.cgi/src/sys/sys/syslimits.h[linux-pre-2.6.23]	On Linux, the maximum almost always has been PAGE_SIZEMAX_ARG_PAGES (409632) minus 4.However, in Linux-0.0.1, ARG_MAX was not known yet, E2BIG not used yet and exec() returned -1 instead.With linux-0.10 it returned ENOMEM and with Linux-0.99.8 it returned E2BIG.ARG_MAX was introduced with linux-0.96, but it’s not used in the kernel code itself.See do_execve() in fs/exec.c on http://www.oldlinux.org/Linux.old/.If you want to increase the limit, you might succeed by carefully increasing MAX_ARG_PAGES (link to a discussion on the linux kernel mailing list 03/‘00)
[linux-2.6.23]	With Linux 2.6.23, ARG_MAX is not hardcoded anymore. See the git entry.It is limited to a 1/4-th of the stack size (ulimit -s), which ensures that the program still can run at all.See also the git diff of fs/exec.cgetconf ARG_MAX might still report the former limit (being careful about applications or glibc not catching up, but especially because the kernel &lt;limits.h&gt; still defines it)
[sunos5]	On SunOS 5.5, according to &lt;limits.h&gt;, ARG_MAX is 1M, decreased by the following amount:  “((sizeof(struct arg_hunk ))(0x10000/(sizeof)(struct arg_hunk)))   space for other stuff on initial stack like aux vectors, saved   registers, etc..”On SunOS 5.9 this reads  “ARG_MAX is calculated as follows:   NCARGS - space for other stuff on initial stack   like aux vectors, saved registers, etc..”and &lt;sys/param.h&gt; defines NCARGS32/64 to 0x100000/0x200000 with NCARGS being substited at compile time.ARG_MAX is not calculated in the header files but is set directly in &lt;limits.h&gt;, also substitued at compile time from _ARG_MAX32/64.SunOS 5.7 is the first release to support 64bit processes.
[hpux]	HP-UX 11 can also run programs compiled on HP-UX 10. Programs which have ARG_MAX compiled in as buffer lengthand copy from argv[]/envp[] without boundary checking might crash due to the increased ARG_MAX.See devresource.hp.com[hurd]	NCARGS in contrast is arbitrarily set to INT_MAX (2147483647) in &lt;i386-gnu/sys/param.h&gt;The reason: “ARG_MAX is unlimited, but we define NCARGS for BSD programs that want to compare against some fixed limit.”I don’t know yet, if there are other limits like the stack.[cygwin]	ARG_MAX 32000 was added to &lt;limits.h&gt; on 2006-11-07. It’s a conservative value, having in mind the windows limit of 32k.However, the cygwin internal limit, that is, if you don’t call non-cygwin binaries, is much higher.[haiku]	“Haiku is an open-source operating system […] inspired by the BeOS” (www.haiku-os.org). Thanks to Sylvain Kerjean for this pointer!Note that there is also &lt;posix/limits.h&gt; with ARG_MAX / _POSIX_ARG_MAX for sysconf(), with more a more conservative value of 32768.[1stEd]	By judging from experiments in the simh emulator with 1st edition kernel and 2nd edition shell, the results are somewhat undefined.If the length or number of arguments (there is no environment yet) is too high, data corruption may occur, including a kernel crash.The following may or may not indicate the nature of limits:From the BUGS section in the 3rd edition exec(2) manual:Very high core and very low core are used by exec to construct the argument list for the new core image.If the original copies of the arguments reside in these places, problems can result.and a related information about the placement of the arguments(which is also available in 1st ed manual) reads equivalent:1st edition: The arguments are placed as high as possible incore: just below 60000(8).3rd edition: The arguments are placed as high as possible in core: just below 57000(8).
By calling a script which just echoes its arguments (“sh s arguments”), I found:

command line (script or interactive) not longer than 255 characters
single argument not longer than 82 charactersAs there is no working compiler (B) on that system, I haven’t digged further.

]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>export</tag>
        <tag>PATH</tag>
        <tag>command line</tag>
        <tag>ARG_MAX</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux 命令行快捷键</title>
    <url>/2013/03/05/linux-command-line-shortcut/</url>
    <content><![CDATA[linux命令行快捷键
C-k: 先按住Ctrl键，然后再按k键；
M-k：先单击Esc键，然后再按k键。

移动光标
C-a：移到行首
C-e：移到行尾
C-b：往回(左)移动一个字符
C-f：往后(右)移动一个字符
M-b：往回(左)移动一个单词
M-f：往后(右)移动一个单词

删除字符
C-h：删除光标左方位置的字符
C-d：删除光标右方位置的字符（注意：当前命令行没有任何字符时，会注销系统或结束终端）

删除单词
M-d：由光标位置开始，删除单词，直到该单词结束。
C-w：由光标位置开始，往左删除单词。

删除行
C-k：由光标所在位置开始，删除右方所有的字符，直到该行结束。
C-u：由光标所在位置开始，删除左方所有的字符，直到该行开始。
C-a C-k  或  C-e C-u 或 C-k C-u 组合可删除整行。
C-l：清除屏幕，然后，在最上面重新显示目前光标所在的这一行的内容。

复原操作
C-_：回复之前的状态。撤销操作。

粘贴C-y：把之前删除的字符或字符串，贴到光标所在位置。
重复执行操作动作：
M-操作次数  操作动作： 指定操作次数，重复执行指定的操作。

查找历史命令
C-p：显示当前命令的上一条历史命令
C-n：显示当前命令的下一条历史命令
C-r：搜索历史命令，随着输入会显示历史命令中的一条匹配命令，Enter键执行匹配命令；ESC键在命令行显示而不执行匹配命令。

执行历史命令中的特定命令在下面的例子中，如果你想再次执行第四条命令，执行！4即可
# history | more1 service network restart2 exit3 id4 cat /etc/redhat-release# !4cat /etc/redhat-releaseFedora release 9 (Sulphur)
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Ctrl</tag>
        <tag>Esc</tag>
        <tag>shortcut</tag>
      </tags>
  </entry>
  <entry>
    <title>linux之cowsay命令</title>
    <url>/2014/02/12/linux-cowsay-misc/</url>
    <content><![CDATA[活灵活现的终端：发掘cowsaycowsay顾名思义就是一头牛为你加持，一款让命令行界面生动有趣的工具。
cowsay 可说话、可思考，与fortune加持更可以变为一头睿智的牛。
该命令接受一个文本字符串，并输出一个牛说话的图形。
下面是一头牛在说它喜欢 Linux：
$  cowsay I love linux. _______________ &lt; I love linux. &gt; ---------------         \   ^__^         \  (oo)\_______            (__)\       )\/\                ||----w |                ||     ||



长着古怪眼睛的牛$  cowsay -e @@ I love linux.          _______________ &lt; I love linux. &gt; ---------------         \   ^__^         \  (@@)\_______            (__)\       )\/\                ||----w |                ||     ||



伸出舌头的牛$ cowsay -T U I love linux. _______________ &lt; I love linux. &gt; ---------------         \   ^__^         \  (oo)\_______            (__)\       )\/\             U ||----w |                ||     ||



一头睿智的牛一旦将fortune和cowsay结合起来，那简直是一头及其睿智的牛呀。
$ fortune | cowsay __________________________________ / 贤能不待次而举。         \|                                  |\ 　　　　－　荀况 / ----------------------------------         \   ^__^         \  (oo)\_______            (__)\       )\/\                ||----w |                ||     ||

]]></content>
      <categories>
        <category>Linux炫技</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>cowboy</tag>
      </tags>
  </entry>
  <entry>
    <title>安全起见，拷贝为先 - cp</title>
    <url>/2011/02/12/linux-cp-beginner/</url>
    <content><![CDATA[安全起见，拷贝为先 - cp.. _linux_cp_beginner:
.. note::  昔去雪如花，今来花似雪。  范云《别诗》
cp命令很简单，字面的意思，copy的缩写，意指拷贝数据。
官方含义为：

cp - copy files and directories

– 拷贝文件和文件夹。
命令格式简单的格式如下所示，cp后面跟上选项，然后是SRC，最后是DEST。
$ cp [option]... SOURCE... DIRECTORY

下面说几个最常用的选项实例。

-a：保留链接、文件属性，并复制目录下的所有内容，类似于等于dpr参数组合
-d：复制时保留链接
-f：覆盖已经存在的目标文件而不给出提示
-i：与-f选项相反，要求用户确认是否覆盖
-p：除复制文件的内容外，还把修改时间和访问权限也复制到新文件
-r：若给出的源文件是一个目录文件，此时将复制该目录下所有的子目录和文件

首先假设有两个文件夹dir1和dir2，里面的内容如下所示：
dir1├── a├── b├── c└── ddir2├── b├── d└── e0 directories, 7 files

详细信息如下所示：
$ ll *dir1:total 0-rw-rw-r-- 1 user user 0 Jul 20 21:23 a-rw-rw-r-- 1 user user 0 Jul 20 21:23 b-rw-rw-r-- 1 user user 0 Jul 20 21:23 c-rw-rw-r-- 1 user user 0 Jul 20 21:23 ddir2:total 0-rw-rw-r-- 1 user user 0 Jul 20 21:25 b-rw-rw-r-- 1 user user 0 Jul 20 21:25 d-rw-rw-r-- 1 user user 0 Jul 20 21:25 e

cp最常用的选项如下所示：

i : 覆盖一个已经存在的文件前，提示用户进行确认
r：递归地复制目录及其内容，复制目录的时候必须使用这个参数
u：只复制不存在或者更新的文件
v：复制文件时，显示复制信息

组合rv - 可以拷贝文件或文件夹这个在显示复制信息的时候，也可以复制目录
$ cp -rv dir1/* dir2/‘dir1/a’ -&gt; ‘dir2/a’‘dir1/b’ -&gt; ‘dir2/b’‘dir1/c’ -&gt; ‘dir2/c’‘dir1/d’ -&gt; ‘dir2/d’



拷贝时提示确认这个参数在使用rm的时候已经记得使用，不然就像rm -rf /一样，一个公司没有了。
$ cp -i dir1/* dir2/cp: overwrite ‘dir2/a’? ycp: overwrite ‘dir2/b’? ycp: overwrite ‘dir2/c’? y


这个选项在文件超级多时候，慎用！！

只拷贝不存在或更新的文件u表示update，也就是从一个目录拷贝到另外一个目录时，只会复制那些不存在或者目标目录相应文件的更新文件。
执行下面的命令：
$ cp -u dir1/* dir2/

可以得到：
$ ll *dir1:total 0-rw-rw-r-- 1 user user 0 Jul 20 21:23 a-rw-rw-r-- 1 user user 0 Jul 20 21:23 b-rw-rw-r-- 1 user user 0 Jul 20 21:23 c-rw-rw-r-- 1 user user 0 Jul 20 21:23 ddir2:total 0-rw-rw-r-- 1 user user 0 Jul 20 21:29 a-rw-rw-r-- 1 user user 0 Jul 20 21:25 b-rw-rw-r-- 1 user user 0 Jul 20 21:29 c-rw-rw-r-- 1 user user 0 Jul 20 21:25 d-rw-rw-r-- 1 user user 0 Jul 20 21:25 e



如何用cp拷贝指定序号的文件现在有文件夹filename，内有文档，名字是从1.txt, 2.txt, 3.txt 一直到9999.txt,10000.txt,现在希望从第N组数据即N.txt到第M组数据M.txt的文件拷贝到别的文件夹中，方法如下：
$ cp {N..M}.txt   newfilename/

这个方法可是相当的赞呀(≧▽≦)/，基本可以秒掉大多数的GUI程序了。
]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>文件管理</tag>
        <tag>cp</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux的 cp 命令</title>
    <url>/2011/02/12/linux-cp/</url>
    <content><![CDATA[Linux 的cp命令cp命令很简单，字面的意思，copy的缩写，意指拷贝数据。
官方含义为：

cp - copy files and directories

– 拷贝文件和文件夹。
命令格式简单的格式如下所示，cp后面跟上选项，然后是SRC，最后是DEST。
$ cp [option]... SOURCE... DIRECTORY

下面说几个最常用的选项实例。

-a：保留链接、文件属性，并复制目录下的所有内容，类似于等于dpr参数组合
-d：复制时保留链接
-f：覆盖已经存在的目标文件而不给出提示
-i：与-f选项相反，要求用户确认是否覆盖
-p：除复制文件的内容外，还把修改时间和访问权限也复制到新文件
-r：若给出的源文件是一个目录文件，此时将复制该目录下所有的子目录和文件

首先假设有两个文件夹dir1和dir2，里面的内容如下所示：
dir1├── a├── b├── c└── ddir2├── b├── d└── e0 directories, 7 files

详细信息如下所示：
$ ll *dir1:total 0-rw-rw-r-- 1 user user 0 Jul 20 21:23 a-rw-rw-r-- 1 user user 0 Jul 20 21:23 b-rw-rw-r-- 1 user user 0 Jul 20 21:23 c-rw-rw-r-- 1 user user 0 Jul 20 21:23 ddir2:total 0-rw-rw-r-- 1 user user 0 Jul 20 21:25 b-rw-rw-r-- 1 user user 0 Jul 20 21:25 d-rw-rw-r-- 1 user user 0 Jul 20 21:25 e

cp最常用的选项如下所示：

i : 覆盖一个已经存在的文件前，提示用户进行确认
r：递归地复制目录及其内容，复制目录的时候必须使用这个参数
u：只复制不存在或者更新的文件
v：复制文件时，显示复制信息

组合rv - 可以拷贝文件或文件夹这个在显示复制信息的时候，也可以复制目录
$ cp -rv dir1/* dir2/‘dir1/a’ -&gt; ‘dir2/a’‘dir1/b’ -&gt; ‘dir2/b’‘dir1/c’ -&gt; ‘dir2/c’‘dir1/d’ -&gt; ‘dir2/d’



拷贝时提示确认这个参数在使用rm的时候已经记得使用，不然就像rm -rf /一样，一个公司没有了。
$ cp -i dir1/* dir2/cp: overwrite ‘dir2/a’? ycp: overwrite ‘dir2/b’? ycp: overwrite ‘dir2/c’? y


这个选项在文件超级多时候，慎用！！

只拷贝不存在或更新的文件u表示update，也就是从一个目录拷贝到另外一个目录时，只会复制那些不存在或者目标目录相应文件的更新文件。
执行下面的命令：
$ cp -u dir1/* dir2/

可以得到：
$ ll *dir1:total 0-rw-rw-r-- 1 user user 0 Jul 20 21:23 a-rw-rw-r-- 1 user user 0 Jul 20 21:23 b-rw-rw-r-- 1 user user 0 Jul 20 21:23 c-rw-rw-r-- 1 user user 0 Jul 20 21:23 ddir2:total 0-rw-rw-r-- 1 user user 0 Jul 20 21:29 a-rw-rw-r-- 1 user user 0 Jul 20 21:25 b-rw-rw-r-- 1 user user 0 Jul 20 21:29 c-rw-rw-r-- 1 user user 0 Jul 20 21:25 d-rw-rw-r-- 1 user user 0 Jul 20 21:25 e



如何用cp拷贝指定序号的文件现在有文件夹filename，内有文档，名字是从1.txt, 2.txt, 3.txt 一直到9999.txt,10000.txt,现在希望从第N组数据即N.txt到第M组数据M.txt的文件拷贝到别的文件夹中，方法如下：
$ cp {N..M}.txt   newfilename/

这个方法可是相当的赞呀(≧▽≦)/，基本可以秒掉大多数的GUI程序了。
]]></content>
      <categories>
        <category>Linux</category>
        <category>Linux入门</category>
        <category>文件管理</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>cp</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux查看物理CPU个数、核数、逻辑CPU个数</title>
    <url>/2017/05/07/linux-cpu/</url>
    <content><![CDATA[查看Linux的CPU信息可以通过命令lscpu来查看lscpu用于显示CPU的相关信息，该命令主要从sysfs和/proc/cpuinfo收集CPU体系结构信息
$ lscpuArchitecture:        x86_64 # 架构CPU op-mode(s):      32-bit, 64-bitByte Order:          Little EndianCPU(s):              16 # 逻辑CPU颗数On-line CPU(s) list: 0-15Thread(s) per core:  2 # 每个核的线程Core(s) per socket:  4 # 每个CPU插槽的核数Socket(s):           2 # CPU的插槽数NUMA node(s):        2Vendor ID:           GenuineIntel # CPU厂商IDCPU family:          6 # CPU系列Model:               85 # 型号Model name:          Intel(R) Xeon(R) Gold 5222 CPU @ 3.80GHzStepping:            7 # 步进CPU MHz:             3538.279 # CPU主频CPU max MHz:         3900.0000CPU min MHz:         1200.0000BogoMIPS:            7600.00Virtualization:      VT-x # CPU支持的虚拟化技术L1d cache:           32K # 一级缓存L1i cache:           32K # 一级缓存L2 cache:            1024K # 二级缓存L3 cache:            16896K # 三级缓存NUMA node0 CPU(s):   0,2,4,6,8,10,12,14 # Nom-Uniform Memeory Access(NUMA)NUMA node1 CPU(s):   1,3,5,7,9,11,13,15Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch cpuid_fault epb cat_l3 cdp_l3 invpcid_single intel_ppin ssbd mba ibrs ibpb stibp ibrs_enhanced tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm cqm mpx rdt_a avx512f avx512dq rdseed adx smap clflushopt clwb intel_pt avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local dtherm ida arat pln pts pku ospke avx512_vnni md_clear flush_l1d arch_capabilities

可以加上参数-p来获取比较容易解析的输出
$ lscpu -p# The following is the parsable format, which can be fed to other# programs. Each different item in every column has an unique ID# starting from zero.# CPU,Core,Socket,Node,,L1d,L1i,L2,L30,0,0,0,,0,0,0,01,1,1,1,,1,1,1,12,2,0,0,,2,2,2,03,3,1,1,,3,3,3,14,4,0,0,,4,4,4,05,5,1,1,,5,5,5,16,6,0,0,,6,6,6,07,7,1,1,,7,7,7,18,0,0,0,,0,0,0,09,1,1,1,,1,1,1,110,2,0,0,,2,2,2,011,3,1,1,,3,3,3,112,4,0,0,,4,4,4,013,5,1,1,,5,5,5,114,6,0,0,,6,6,6,015,7,1,1,,7,7,7,1

或者直接读取/proc/cpuinfo文件# 总核数 = 物理CPU个数 X 每颗物理CPU的核数# 总逻辑CPU数 = 物理CPU个数 X 每颗物理CPU的核数 X 超线程数# 查看物理CPU个数cat /proc/cpuinfo| grep "physical id"| sort| uniq| wc -l# 查看每个物理CPU中core的个数(即核数)cat /proc/cpuinfo| grep "cpu cores"| uniq# 查看逻辑CPU的个数cat /proc/cpuinfo| grep "processor"| wc -l


kswapd often uses 100% CPU when swap is in use如果此时的Mem并没有用很多的话，可能需要执行下面的命令来强制关闭：
$ killall -9 kswapd$ echo 1 &gt; /proc/sys/vm/drop_caches]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>grep</tag>
        <tag>sort</tag>
        <tag>uniq</tag>
        <tag>cpu</tag>
        <tag>cpuinfo</tag>
      </tags>
  </entry>
  <entry>
    <title>超多协议传输的 - curl</title>
    <url>/2013/03/06/linux-curl-beginner/</url>
    <content><![CDATA[超多协议传输的 - curl.. _linux_curl_beginner:
.. note::  锦瑟无端五十弦，一弦一柱思华年。  李商隐《锦瑟》
Linux curl命令是一款用于从一个server端传输的工具。
很强力，支持众多协议，比如：DICT, FILE, FTP, FTPS, GOPHER, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, POP3, POP3S, RTMP, RTSP,  SCP,  SFTP,  SMB,  SMBS,  SMTP,SMTPS, TELNET 和 TFTP. 
说实话，有些协议我也不知道，不过我们只需要知道这个命令设计之初是希望不需要用户的交互和介入，就可以完成数据的传输。
所以这个命令被广泛应用于数据传输、测试、调试和自动化脚本中。
官方定义为：

curl - transfer a URL

语法$ curl [options / URLs]

参数：

-O : 把输出写到该文件中，保留远程文件的文件名
-u : 通过服务端配置的用户名和密码授权访问

默认传输下载文件默认情况下，将下载的数据写入到文件，并且使用服务器上的名字，这里以下载Linux的内核代码为例。
$ curl https://mirrors.edge.kernel.org/pub/linux/kernel/v2.4/linux-2.4.32.tar.gz -O  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current                                 Dload  Upload   Total   Spent    Left  Speed  1 36.7M    1  575k    0     0  17431      0  0:36:50  0:00:33  0:36:17 27222

需要授权的网站部分网站可能需要访问的授权，此时可以使用-u选项提供用户名和密码进行授权：
$ curl -u username https://www.website.com/ Enter host password for user 'username':



批量下载当然，这么强力的工具，肯定是支持批量下载的，并且是正则表达式的支持。
比如：ftp://ftp.example.com/的file1，file5和file7，方法如下：
$ curl ftp://ftp.example.com/file{1,5,7}.txt



如果下载ftp://ftp.example.com/的从file1到file100的100组文件，方法如下：
$ curl ftp://ftp.example.com/file[1-100].txt
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>curl</tag>
        <tag>HTTP</tag>
        <tag>HTTPS</tag>
        <tag>FTP</tag>
        <tag>SCP</tag>
        <tag>SFTP</tag>
        <tag>TELNET</tag>
        <tag>TFTP</tag>
      </tags>
  </entry>
  <entry>
    <title>一日难再晨及时当勉励 date</title>
    <url>/2013/01/17/linux-date-beginner/</url>
    <content><![CDATA[一日难再晨及时当勉励 date.. _linux_date_beginner:.. note::
时光只解催人老，不信多情，长恨离亭，泪滴春衫酒易醒。
- 晏殊《采桑子·时光只解催人老》

date命令可以用来打印显示亦或者更改日期和时间。
看看官方的定义如下：

 date - print or set the system date and time

用法如下：
$ date [OPTION]... [+FORMAT]$ date [-u | --utc| --universal] [MMDDhhmm[[CC]YY][.ss]]



较常用的OPTION为：

-R ： 显示时区
-u, --utc, --universal：打印或者设置世界协调时
-d, --date=STRING：显示STRING的时间

默认输入date 命令默认情况下为CST时区，
$ dateMon Jun  5 15:11:44 CST 2014



显示时区如果加上 -R参数就可以带上时区，比如我们的东八区
$ date -RMon, 05 Jun 2014 15:15:25 +0800



世界协调时选项-u, --utc, --universal可以显示世界协调时
$ date -uMon Jun  5 07:15:46 UTC 2014$ date --utcMon Jun  5 07:15:48 UTC 2014$ date --universalMon Jun  5 07:15:55 UTC 2014



格式化日期可以通过不同的参数来格式化日期，这里需要注意的是：不同的大小写代表的是不同的含义
比较常用的日期和时间如下：
# 显示年月日时分秒$ date  +%Y-%m-%dT%H:%M:%S2013-01-17T18:01:08# 或者 下面一样的效果$ data +%FT%T2013-01-17T18:02:12

实例$ date Thu Jan 1 08:19:23 PST 2009 $ date --date="now" Thu Jan 1 08:20:05 PST 2009 $ date --date="today" Thu Jan 1 08:20:12 PST 2009 $ date --date='1970-01-01 00:00:01 UTC +5 hours' +%s 18001$ date '+Current Date: %m/%d/%y%nCurrent Time:%H:%M:%S' Current Date: 01/01/09 Current Time:08:21:41 $ date +"%d-%m-%Y" 01-01-2009$ date +"%d/%m/%Y" 01/01/2009$ date +"%A,%B %d %Y" Thursday,January 01 2009 

以下是date命令的不同的格式选项，各选项所代表含义如下：

%D 日期(月/日/年)

%d 一个月中的第几天 (01..31)

%m 月份 (01..12)

%y 年份的后两位 (00..99)

%a 当前语言下星期的缩写 (Sun..Sat) 

%A 当前语言下星期的全拼 (Sunday..Saturday) 

%b 当前语言下月份的缩写 (Jan..Dec) 

%B 当前语言下的月份的全称 (January..December) 

%H 24小时制小时 (00..23)

%I 12小时制小时 (01..12)

%Y 年份(1970…)


显示过去的日期和时间$date --date=”3 seconds ago”$date --date=”1 day ago”$date --date=”2 year ago”$date --date=”3 seconds ago”$date --date=”yesterday”$date --date=”10 months 2 day ago”

显示未来的日期和时间$date --date=”3 seconds”$date --date=”1 day” $date --date=”1 week”$date --date=”2 year”$date --date=”3 seconds”$date --date=”tomorrow”$date --date=”next day”$date --date=”10 months 2 day”$date --date=”this Wednesday”]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>Linux炫技</tag>
        <tag>date</tag>
        <tag>时间日期</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux shell系统时间</title>
    <url>/2013/01/17/linux-date/</url>
    <content><![CDATA[Linux shell 获取更改系统时间date命令可以用来打印显示亦或者更改日期和时间。
看看官方的定义如下：

 date - print or set the system date and time

用法如下：
$ date [OPTION]... [+FORMAT]$ date [-u | --utc| --universal] [MMDDhhmm[[CC]YY][.ss]]



较常用的OPTION为：

-R ： 显示时区
-u, --utc, --universal：打印或者设置世界协调时
-d, --date=STRING：显示STRING的时间

默认输入date 命令默认情况下为CST时区，
$ dateMon Jun  5 15:11:44 CST 2014



显示时区如果加上 -R参数就可以带上时区，比如我们的东八区
$ date -RMon, 05 Jun 2014 15:15:25 +0800



世界协调时选项-u, --utc, --universal可以显示世界协调时
$ date -uMon Jun  5 07:15:46 UTC 2014$ date --utcMon Jun  5 07:15:48 UTC 2014$ date --universalMon Jun  5 07:15:55 UTC 2014





格式化日期可以通过不同的参数来格式化日期，这里需要注意的是：不同的大小写代表的是不同的含义
比较常用的日期和时间如下：
# 显示年月日时分秒$ date  +%Y-%m-%dT%H:%M:%S2013-01-17T18:01:08# 或者 下面一样的效果$ data +%FT%T2013-01-17T18:02:12



这里注意到有+这个选项，后面的就是格式字符串，常见常用的有下面几个。



格式化参数
含义



%a
星期的缩写，比如Sun


%A
星期的全称，比如Sunday


%b
月份的缩写，比如Jan


%B
月份的全称，比如January


%c
日期和时间，比如Thu Mar  3 23:05:25 2005


%d
日期，比如02


%D
日期，格式为月/日/年，比如：01/17/13，即为2013年1月17日


%F
日期的全写，格式为年-月-日，比如2013-01-17


%H
小时，从00到23，24小时制


%I
小时，从01到12,12小时制


%j
一年中的第几天，从001到366


%m
月份，比如：01


%M
分钟，比如56


%N
纳秒，范围为：(000000000..999999999)


%p
使用AM或PM


%P
使用am或pm


%q
显示季度（范围1到4）


%r
12进制显示，比如：10:23:51 PM


%R
24进制显示时分，类似于%H:%M


%s
自UTC1970-01-01 00:00:00以来的秒数


%S
秒，比如28


%T
显示时间，格式为：%H:%M:%S


%u
一周的第几天，从1到7


%U
一年的第几周，周日为第一天，范围00到53


%V
与%U类似，使用Monday作为第一天，范围01到53


%w
星期，如果结果显示0，则表示周日


%W
一年的第几周，周一为第一天，范围00到53


%x
本地日期，格式mm/dd/yy


%X
本地时间，格式hh:mm:ss


%Y
以四位数字格式打印年份 ，比如 2014


%y
以二位数字格式打印年份 ，比如14


%z
数字时区，格式为+hhmm


%Z
字母时区，比如EDT、CST


还有一些可选的参数，比如：^，使用方法为date +%^b，此时的输出改为大写，如果date +%b输出为Jan，那么加上^的输出为JAN。
转换秒到日期时间下面的方法为将UTC 1970-01-01 00:00:00经过123456789秒以后的日期时间显示出来。
$ date --date='@123456789'Fri Nov 30 05:33:09 CST 1973




–date选项花样多-d, --date=STRING能描述和使用的STRING很多很复杂，比如可以这么用：
$ date --date="next Week"$ date --date="next Month"$ date --date="1 year ago"$ date --date="4 days"$ date --date="4 days ago"

还有很多其他的用法，可以参考info date。
]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>Linux炫技</tag>
        <tag>date</tag>
      </tags>
  </entry>
  <entry>
    <title>低调但大胆的 - dd 命令</title>
    <url>/2013/01/20/linux-dd-beginner/</url>
    <content><![CDATA[低调但大胆的 - dd 命令.. _linux_dd_beginner:
dd这个命令一直没有弄明白缩写的含义，这个命令应该归到Linux炫技里面，因为我也是很晚才用到，不过有些功能还可以尝试一下，比如克隆系统，比如测试磁盘速度等等。
官方含义为：

dd - convert and copy a file


从官方含义来看，是不是定义为cc比较合适，^_^

dd命令可以用于复制文件，转换或者格式化文件。
不过dd命令是很强大的，对于一些比较底层的问题，使用dd命令往往可以得到出人意料的效果。
命令格式命令比较简单：
$ dd 选项

对于刚开始而言，仅仅下面几个掌握下面几个参数就完全够用了。

of=FILE， 将输出定位到FILE，而不是默认的stdout
bs=BYTES，每次读取的字节数，默认为512字节
count=N， 拷贝N个输入块
if=FILE, 从FILE输入，而不是默认的stdin

考虑替换cp命令既然命令第一个说明就是拷贝文件，那么正常情况下基本是可以替换cp的，不过前提是有参数指定，比如：
# 默认cp拷贝，一个1GB的文件，花费1.05秒$ time cp a bcp a b  0.02s user 1.05s system 75% cpu 1.403 total# 默认dd拷贝，一个1GB的文件，竟然花费了29.17秒$ time dd if=a of=b2048000+0 records in2048000+0 records out1048576000 bytes (1.0 GB, 1000 MiB) copied, 34.7214 s, 30.2 MB/sdd if=a of=b  1.31s user 29.17s system 87% cpu 34.996 total

为什么dd这么慢，很简单，在不指定bs的情况下，默认为512字节，dd就会根据512来切分，时间都浪费在了这个上面。
所以简单地加上这个参数，迅速提升效率
$ time dd if=a of=b bs=2M500+0 records in500+0 records out1048576000 bytes (1.0 GB, 1000 MiB) copied, 1.04747 s, 1.0 GB/sdd if=a of=b bs=2M  0.00s user 1.05s system 78% cpu 1.332 total$ time dd if=a of=b bs=4M250+0 records in250+0 records out1048576000 bytes (1.0 GB, 1000 MiB) copied, 1.00866 s, 1.0 GB/sdd if=a of=b bs=4M  0.00s user 1.00s system 76% cpu 1.304 total$ time dd if=a of=b bs=8M125+0 records in125+0 records out1048576000 bytes (1.0 GB, 1000 MiB) copied, 0.937974 s, 1.1 GB/sdd if=a of=b bs=8M  0.00s user 0.92s system 79% cpu 1.164 total$ time dd if=a of=b bs=10M100+0 records in100+0 records out1048576000 bytes (1.0 GB, 1000 MiB) copied, 1.01666 s, 1.0 GB/sdd if=a of=b bs=10M  0.00s user 1.03s system 82% cpu 1.257 total

测试硬盘速度我最常使用的dd命令的用例是，测试硬盘的读写速度，比如很简单地写入1GB、10GB来看一下。
$ dd if=/dev/zero of=tmp bs=1M count=10001000+0 records in1000+0 records out1048576000 bytes (1.0 GB, 1000 MiB) copied, 0.7338 s, 1.4 GB/s$ dd if=/dev/zero of=tmp bs=2M count=500500+0 records in500+0 records out1048576000 bytes (1.0 GB, 1000 MiB) copied, 0.611315 s, 1.7 GB/s$ dd if=/dev/zero of=tmp bs=4M count=250250+0 records in250+0 records out1048576000 bytes (1.0 GB, 1000 MiB) copied, 0.602517 s, 1.7 GB/s

然后根据这些参数，可以简单写一个脚本来评估系统的整体读写速率了。
当然dd系统管理员用的最多的应该是系统备份和克隆了，暂且不表。
]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>Linux炫技</tag>
        <tag>危险命令</tag>
        <tag>dd</tag>
      </tags>
  </entry>
  <entry>
    <title>低调但大胆的 - dd 命令</title>
    <url>/2014/01/20/linux-dd/</url>
    <content><![CDATA[低调但大胆的 - dd 命令除了入门介绍的基本功能，今天再加点干货。
测试写入速度dd if=/dev/zero of=testfile bs=1G count=1 oflag=direct
这个命令增加了一个选项叫做oflag=direct，

oflag=direct：确保数据直接写入磁盘，跳过系统缓存。

这个命令将会输出写入速度。完成测试后，可以删除 testfile 文件。
测试读取速度首先写一个测试文件（可以使用上面的写入命令），然后执行以下读取命令：
dd if=testfile of=/dev/null bs=1G count=1 iflag=direct
同样的增加了iflag=direct，可以加速：

iflag=direct：直接读取数据，跳过系统缓存。

这样可以得到硬盘的读取速度。
#######TODO
backup an entire copy of a hard disk to another hard disk# dd if=/dev/sda of=/dev/sdb conv=sync,noerror



   cbs=BYTES
          convert BYTES bytes at a time

   conv=CONVS
          convert the file as per the comma separated symbol list


   ibs=BYTES
          read up to BYTES bytes at a time (default: 512)


   iflag=FLAGS
          read as per the comma separated symbol list

   obs=BYTES
          write BYTES bytes at a time (default: 512)

   oflag=FLAGS
          write as per the comma separated symbol list

   seek=N skip N obs-sized blocks at start of output

   skip=N skip N ibs-sized blocks at start of input

   status=LEVEL
          The  LEVEL of information to print to stderr; 'none' suppresses everything but error messages, 'noxfer'
          suppresses the final transfer statistics, 'progress' shows periodic transfer statistics

   N and BYTES may be followed by the following multiplicative suffixes: c =1, w =2, b =512, kB =1000,  K  =1024,
   MB =1000*1000, M =1024*1024, xM =M, GB =1000*1000*1000, G =1024*1024*1024, and so on for T, P, E, Z, Y.

   Each CONV symbol may be:

   ascii  from EBCDIC to ASCII

   ebcdic from ASCII to EBCDIC

   ibm    from ASCII to alternate EBCDIC

   block  pad newline-terminated records with spaces to cbs-size

   unblock
          replace trailing spaces in cbs-size records with newline

   lcase  change upper case to lower case

   ucase  change lower case to upper case

   sparse try to seek rather than write the output for NUL input blocks

   swab   swap every pair of input bytes

   sync   pad  every  input  block with NULs to ibs-size; when used with block or unblock, pad with spaces rather
          than NULs

   excl   fail if the output file already exists

   nocreat
          do not create the output file

   notrunc
          do not truncate the output file

   noerror
          continue after read errors

   fdatasync
          physically write output file data before finishing

   fsync  likewise, but also write metadata

   Each FLAG symbol may be:

   append append mode (makes sense only for output; conv=notrunc suggested)

   direct use direct I/O for data

   directory
          fail unless a directory

   dsync  use synchronized I/O for data

   sync   likewise, but also for metadata

   fullblock
          accumulate full blocks of input (iflag only)

   nonblock
          use non-blocking I/O

   noatime
          do not update access time

   nocache
          Request to drop cache.  See also oflag=sync

   noctty do not assign controlling terminal from file

   nofollow
          do not follow symlinks

   count_bytes
          treat 'count=N' as a byte count (iflag only)

   skip_bytes
          treat 'skip=N' as a byte count (iflag only)

   seek_bytes
          treat 'seek=N' as a byte count (oflag only)

   Sending a USR1 signal to a running 'dd' process makes it print I/O statistics to standard error and  then  re‐
   sume copying.

使用dd命令克隆整个系统进入Linux操作系统，打开命令行，执行如下命令：
sudo  fdisk -u -l

可以查看所有磁盘上的所有分区的尺寸和布局情况。

-u，让start和end中数字的单位是512字节，也就是一个sector扇区的大小。

具体步骤找一个U盘，安装UbuntuLive Cd系统。
U盘启动，进入盘上的Ubuntu系统，打开命令行，执行：
sudo  fdisk -u -l /dev/sda

查看硬件的分区情况。
然后执行：
dd   bs=512 count=[fdisk命令中最大的end数+1] if=/dev/sda of=/ghost.img

这样，就可以把我需要的分区数据全部copy到ghost.img文件中。镜像制作完成了！
然后，我们就可以把U盘插到其他系统上，用U盘启动，进入UbuntuLiveCD，打开命令行，执行如下命令：
dd if=/ghost.img of=/dev/sda

完成后，拔掉U盘，启动计算机，就可以看到我们的Linux系统已经安装完毕了！

注意：不要直接在计算机上用本地磁盘启动系统后执行dd命令生成本地磁盘的镜像。而应该使用livecd启动计算机。因此计算机运行时会对系统盘产生大量写操作。 直接对运行中的系统盘生成的镜像，在恢复到其他硬盘上时，很可能会无法启动！

一样适用于非Linux操作系统, 在linux上用dd命令实现系统镜像备份和恢复，是不是很简单呢？
对于Windows系统，甚至Mac等等任意系统，其实都可以用dd命令实现系统镜像的备份和恢复。因为，Linux的fdisk命令能够识别任意系统下的分区格式。fdisk并不关系分区上的文件系统，甚至有无文件系统都不关心。fdisk总是可以报告分区占用了哪些扇区。 dd命令也不关心磁盘的文件系统格式，它只是简单地按照要求从指定的位置，复制多少字节数据而已。dd命令实现镜像备份和恢复，比Ghost软件简单和强大多了。使用ghost软件，依然需要用户进行复杂而危险的磁盘分区操作。而使用fdisk和dd这两条命令，一切都免了！
压缩和解压缩可能我们需要备份的分区很大，使用dd命令生成的镜像文件也就很大。存储和传输这些镜像不太方便。  我们也可以使用压缩程序压缩生成的镜像文件。 这里，我选择使用gzip程序，配合dd命令一起使用。
gzip参数：

-c 表示输出到stdout
-d  表示解压缩
-1 表示最快压缩
-9 表示最好压缩

默认使用的是-6压缩级别。
要使用 dd 和 gzip 生成压缩的镜像文件，可以执行命令：
# dd bs=512 count=[fdisk命令中最大的end数+1] if=/dev/sda | gzip -6 &gt; /ghost.img.gz

还原时，可以执行下列命令： # gzip -dc /ghost.img.gz.gz | dd of=/dev/sda
提醒：如果你把镜像恢复到另一台计算机上，你可能会发现你的网卡是eth1，而不是eth0。这是因为/etc/udev/rules.d/70-persistent-net.rules   文件把你做镜像的计算机的网卡作为eth0登记了。如果你的网络脚本对eth0进行了处理，而没有对eth1进行处理，那么不修改网络脚本，你可能就无法上网了。
也许你会希望在做镜像之前，先删除 /etc/udev/rules.d/70-persistent-net.rules 文件。这样你恢复镜像时，网卡的名字就是eth0。   就不会造成你在恢复后的计算机上无法上网的问题了。
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>Linux进阶</tag>
        <tag>危险命令</tag>
        <tag>dd</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux Debian sources.list</title>
    <url>/2016/05/07/linux-debian-sources-list/</url>
    <content><![CDATA[Debian 镜像更新源镜像更新源做的比较好的有网易163、阿里云还有中科大。
方法为编辑/etc/apt/sources.list文件，替换为下述内容即可。

最好做好备份。

网易提供的源## Jessiedeb http://mirrors.163.com/debian/ jessie main non-free contribdeb http://mirrors.163.com/debian/ jessie-updates main non-free contribdeb http://mirrors.163.com/debian/ jessie-backports main non-free contribdeb-src http://mirrors.163.com/debian/ jessie main non-free contribdeb-src http://mirrors.163.com/debian/ jessie-updates main non-free contribdeb-src http://mirrors.163.com/debian/ jessie-backports main non-free contribdeb http://mirrors.163.com/debian-security/ jessie/updates main non-free contribdeb-src http://mirrors.163.com/debian-security/ jessie/updates main non-free contrib# Wheezydeb http://mirrors.163.com/debian/ wheezy main non-free contribdeb http://mirrors.163.com/debian/ wheezy-updates main non-free contribdeb http://mirrors.163.com/debian/ wheezy-backports main non-free contribdeb-src http://mirrors.163.com/debian/ wheezy main non-free contribdeb-src http://mirrors.163.com/debian/ wheezy-updates main non-free contribdeb-src http://mirrors.163.com/debian/ wheezy-backports main non-free contribdeb http://mirrors.163.com/debian-security/ wheezy/updates main non-free contribdeb-src http://mirrors.163.com/debian-security/ wheezy/updates main non-free contrib# Squeezedeb http://mirrors.163.com/debian/ squeeze main non-free contribdeb http://mirrors.163.com/debian/ squeeze-updates main non-free contribdeb http://mirrors.163.com/debian/ squeeze-lts main non-free contribdeb-src http://mirrors.163.com/debian/ squeeze main non-free contribdeb-src http://mirrors.163.com/debian/ squeeze-updates main non-free contribdeb-src http://mirrors.163.com/debian/ squeeze-lts main non-free contribdeb http://mirrors.163.com/debian-security/ squeeze/updates main non-free contribdeb-src http://mirrors.163.com/debian-security/ squeeze/updates main non-free contribdeb http://mirrors.163.com/debian-backports/ squeeze-backports main contrib non-freedeb-src http://mirrors.163.com/debian-backports/ squeeze-backports main contrib non-free

如果163的无法更新，可以考虑使用中科大的源
中国科技大学源#（1）squeeze版本deb http://ftp.cn.debian.org/debian squeezemaindeb-src http://ftp.cn.debian.org/debiansqueeze maindeb http://ftp.cn.debian.org/debiansqueeze-updates maindeb-src http://ftp.cn.debian.org/debiansqueeze-updates maindebhttp://ftp.cn.debian.org/debian-backports squeeze-backports maindeb-srchttp://ftp.cn.debian.org/debian-backports squeeze-backports maindeb http://security.debian.org/squeeze/updates maindeb-src http://security.debian.org/squeeze/updates main#或：deb http://ftp.cn.debian.org/debian squeeze main non-freedeb-src http://ftp.cn.debian.org/debiansqueeze main non-freedeb http://ftp.cn.debian.org/debiansqueeze-updates main non-freedeb-src http://ftp.cn.debian.org/debiansqueeze-updates main non-freedebhttp://mirrors.ustc.edu.cn/debian-security/ squeeze/updates main non-freedeb-srchttp://mirrors.ustc.edu.cn/debian-security/ squeeze/updates main non-free# wheezy版本deb http://ftp.cn.debian.org/debian/ wheezy main contrib non-free  deb-src http://ftp.cn.debian.org/debian/ wheezy main contrib non-free  deb http://ftp.cn.debian.org/debian/ wheezy-proposed-updates main contrib non-free  deb-src http://ftp.cn.debian.org/debian/ wheezy-proposed-updates main contrib non-free  deb http://ftp.cn.debian.org/debian/ wheezy-backports main contrib non-free  deb-src http://ftp.cn.debian.org/debian/ wheezy-backports main contrib non-free# jessie版本deb http://ftp.cn.debian.org/debian/ jessiemain contrib non-freedeb-src http://ftp.cn.debian.org/debian/ jessiemain contrib non-freedeb http://ftp.cn.debian.org/debian/ jessie-proposed-updates main contrib non-freedeb-src http://ftp.cn.debian.org/debian/ jessie-proposed-updates main contrib non-freedeb-amd64http://ftp.cn.debian.org/debian-security jessie/updates main contrib non-free

阿里云的源deb http://mirrors.aliyun.com/debian/ wheezy main non-free contribdeb http://mirrors.aliyun.com/debian/ wheezy-proposed-updates main non-free contribdeb-src http://mirrors.aliyun.com/debian/ wheezy main non-free contribdeb-src http://mirrors.aliyun.com/debian/ wheezy-proposed-updates main non-free contrib

对于Debian7.8的版本，被归档了，我试了一下只有下面的这个可以用
deb http://archive.debian.org/debian/ wheezy main contrib non-free
]]></content>
      <categories>
        <category>Linux</category>
        <category>Debian</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>debian</tag>
        <tag>update</tag>
        <tag>upgrade</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux debug 程序崩溃处理</title>
    <url>/2012/04/16/linux-debug-crash/</url>
    <content><![CDATA[程序崩溃处理有人说C语言是低级语言，这有一部分原因是因为应用程序的内存管理大部分需要由程序员来实现。虽然这种方法非常有用，但是也给程序员添加了很多的麻烦。
也有人说，C语言是相对较小且容易学习的语言，然而，只有不考虑标准C语言库的典型实现时，C语言才比较小，这个库相当庞大，很多程序员认为C语言是易用语言，那是因为他们还没有遇到指针。
一般而言，程序错误会导致下面两件事情的发生：

导致程序做一些程序员没有打算做的事情；
导致程序崩溃

相信很多调试过程序的兄弟都碰到过段错误即segmentation fault，则合格主要原因是试图在未经允许的情况下访问一个内存单元。硬件会感知这件事并执行对操作系统的跳转。
堆区域调用malloc函数分配的内存；
栈区域用来动态分配数据的空间，函数调用的数据（包括参数、局部变量和返回地址）都存储在栈上。
查看程序在Linux上的精确内存布局情况可以通过使用info proc mappings来详细查看该程序在Linux上的精确内存布局情况，例如：
此时我们还可以看到这个进程号为14455，所以我们还可以通过文件/proc/14455/maps来查看该信息。通过这些信息，我们有可能看到文本和数据区域，以及堆和栈。
分配页策略操作系统不会将不完整的页分配给程序，例如，如果要运行的程序总共大约有10000字节，如果完全加载，会占用3个内存页（一个页占4096个字节），它不会仅占用2.5个页，因为页是虚拟内存系统能够操作的最小内存单元，这是调试时要着重了解的情况，这也导致了程序的一些错误内存访问不会触发段错误，换言之，在调试会话期间，没有引起段错误并不能直接说明代码是没有问题的。
页的角色细节当程序执行时，它会连续访问程序中的各个区域，导致硬件按照以下几种情况所示处理页表：

每次程序使用全局变量时，需要具有对数据区域的读写访问权限；
每次程序访问局部变量时，程序会访问栈，需要对栈区域具有读写访问权限；
每次程序进入或离开函数时，对该栈进行一次或多次访问，需要对栈区具有读写访问权限；
每次程序访问通过调用malloc或者new创建的存储器时，都会发生堆访问，也需要读写访问权限；
程序执行的每个机器指令是从文本区域取出的，因此需要具有读和执行文件；

信号这里需要注意的是，进程抛出的信号，实际上没有任何内容发送给进程。所发生的事情只不过是操作系统将信号记录到进程表中，以便下次进程接收信号时得到CPU上的时间片，执行恰当的信号处理程序。
自定义信号的复杂性使用GDB/DDD/Eclipse调试时，自定义信号处理程序可能会使程序变得复杂，无论是直接使用还是通过DDD GUI，每当发出任何信号时，GDB都会停止进程，所以，有可能意味着GDB会因为与调试无关的工作而频繁的停止，此时可以使用handle命令告诉GDB在某些信号发生时不要停止。
总线错误的原因
访问不存在的物理地址；
在很多架构上，要求访问32位量的机器指令要求字对齐，而导致视图在奇数号地址上访问具有4字节的数的指针错误可能引起总线错误。

总线错误是处理器层的异常，导致在Unix系统上发出SIGBUS信号，默认情况下，SIGBUS会导致转储内存并终止。
核心文件有些信号表示让某个进程继续是不妥当的，甚至是不可能的，在这些情况中，默认动作是提前终止进程，并编写一个名为核心文件core file的文件，俗称转储核心。
核心文件包含程序崩溃时对程序状态的详细描述：栈的内容、CPU寄存器的内容、程序的静态分配变量的值。
我们可以通过file命令来查看文件的详细信息。
为什么需要核心文件
只有在运行了一段长时间后才发生段错误，所以在调试器中无法重新创建该错误；
程序的行为取决于随机的环境事件，因此再次运行程序可能不会再现段错误；
当新手用户运行程序时发生的段错误，需要发送核心文件给开发人员。

重载功能当GDB注意到重新编译了程序后，它会自动加载新的可执行文件，因此不需要退出和重启GDB。
调试设计的内容

确认原则；
使用核心文件进行崩溃进程的“死后”分析；
纠正、编译并重新运行程序后，甚至不需要退出GDB；
Printf()风格调试的不足之处；
利用你的智慧，这是无可替代的；
如果你过去使用printf风格调试的，就会发现使用printf跟踪这些程序错误中的部分错误原来有多难，虽然在调试中使用printf诊断代码有一定的好处，但是作为一种通用目的的工具，它远远不足以用来跟踪实际代码中发生的大部分程序错误。

]]></content>
      <categories>
        <category>Linux</category>
        <category>GDB</category>
      </categories>
      <tags>
        <tag>malloc</tag>
        <tag>free</tag>
        <tag>gdb</tag>
        <tag>eclipse</tag>
        <tag>core file</tag>
        <tag>ddd</tag>
        <tag>debug</tag>
        <tag>fault</tag>
        <tag>segmentation</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux Debian 时区设定</title>
    <url>/2015/05/07/linux-debian-utc-setting/</url>
    <content><![CDATA[Linux Debian 时区设定timezone 是一个文本文件，只需要把自己所在的时区写进去就可以了。比如我的是 Asia/shanghailocaltime 直接从 /usr/share/zoneinfo 把自己所处时区的文件做一个 ln 过去就好了。
$ ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime
]]></content>
      <categories>
        <category>Linux</category>
        <category>Debian</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>date</tag>
        <tag>debian</tag>
        <tag>timezone</tag>
        <tag>UTC</tag>
        <tag>hwclock</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux 调试编译其他工具</title>
    <url>/2012/04/19/linux-debug-other-tools/</url>
    <content><![CDATA[其他工具精通调试代码并不是说学会使用GDB这样的调试器就行了—这只是开端。
为了增强调试技能，初学者程序员最好学会其中的集中调试工具，了解那种工具适合于调试那种程序错误，并识别发生程序错误时使用其中那个工具可以节省时间和精力。
充分利用文本编辑器最好的调试方法是一开始就不要有编程错误，而简单地充分利用一种支持编程的编辑器就可以达到这个效果。因为：

精通强大的编辑器可以缩短编写代码所需的时间，具有自动缩排、单词补充和全文代码查询等特殊功能的编辑器对程序员是非常有利的；
优秀的编辑器确实可以帮到编码者在编写代码时捕获某些类型的程序错误。


Mark：Makefile中可以使用patsubst关键字来进行文本查找和替换命令。

从vim中调用make非常方便，不需要退出编辑器，直接:make 即可，同时vim可以捕获编译器发出的所有消息，编辑器理解GCC输出内容的语法，知道何时发生编辑器警告或错误。发生错误时可以直接定位到第一个错误，然后使用:cnext或者:cprevious来显示下一个或上一个错误或者警告。

在Vim中可以使用K来查询man页面中的函数。

充分利用编译器如果说编辑器是对抗程序错误的第一个武器，那么编译器就是第二个武器了，所有编译器都有能力扫描代码并查找常见错误，但是通常必须通过调用适当的选项来启用这种错误检查。
对于GCC而言，如果不适用-Wall，就几乎没有必要使用GCC了，所以任何编译最好都加上-Wall选项。
C语言中的错误报告C语言中的错误报告是使用名为errno的老式机制完成的。系统与库调用的失败通常是由于设置了名为errno的全局定义整数变量，在大多数GNU/Linux系统上，error是在/usr/include/errno.h上声明的，因此，只要包含了这个头文件，就不必在源代码中声明extern int errno了。
当一个系统或库调用失败时，它将errno设置为一个指示失败类型的值。检查errno的值，并采取适当的动作可以判断错误类型。比如可以使用函数perror或者strerror。
errno可以通过任何库函数或系统调用设置，无论它是成功还是失败。因为即便成功的函数调用能够设置errno，让人不能依赖errno告诉你是否发生了错误。因此使用errno最安全的方式为：

执行对库或者系统函数的调用；
使用函数的返回值判断时候发生了某个错误；
如果发生了某个错误，使用errno确定为什么发生这个错误。

库函数和系统调用的区别库函数是更高级别的，完全在用户空间里运行，并未程序员提供了更方便的做实际工作的函数接口。
系统调用代表用户以内核模式工作，由操作系统本身的内核提供。
库函数printf看上去类似于一般输出函数，但是它实际上只是格式化你提供给字符串的数据，并用低级系统调用write编写字符串数据，然后将数据发送到一个与终端的标准输出关联的文件中。
更好地使用strace和ltracestrace跟踪系统调用而ltrace跟踪库调用，这两个使用程序，有时比深度调试代码还快。
静态代码检查器：lint与其衍生静态代码检查器：扫描代码的工具，不编译代码，仅仅警告错误、可能的错误和与严格C语言编码标准的差距。
衍生版本为splint：该软件的目标是帮助编写大部分有防御性、安全和尽可能少出错的程序，当然，改程序对组成有效代码的内容非常挑剔。
很多程序员将splint没有报告警告看做一种极大的荣誉。当出现这种情况是，代码被声明为无lint的。
调试动态分配的内存动态分配的内存（Dynamically Allocated Memory, DAM）是程序用malloc和calloc这样的函数从堆中请求的内存。
查找DAM问题分麻烦，分为以下几类：

没有释放动态分配的内存；—内存泄漏
对malloc的调用失败；
想DAM段之外的地址执行读写操作；—访问错误
释放DAM段之后对DAM区域中的内存进行读写操作；—访问错误
对动态内存的同一段调用两次free。—重复释放double free

Electric FenceBruce Perens在1988年写的，当EFence链接到代码中时，导致程序在发生下列情况之一时立即发生段错误并转出核心：

在DAM边界之外执行读写操作；
对已经释放的DAM执行读写操作；
对没有指向malloc分配的DAM的指针执行free，包括重复释放的特殊情况。

比如，
$ gcc –g3 –Wall –std=c99 test.c –o test_with_efence outOfBound_with_efence  –lefence

and
$ gcc –g3 –Wall –std=c99 test.c –o test_with_efence outOfBound_without_efence  -lefence

可以对一个内存泄露但是没有编译失败的程序做测试。
用GNU C库工具调试DAM问题
在调用任何与堆有关的函数钱调用函数mcheck；
使用mtrace函数捕获内存泄露和重复释放；

]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>printf</tag>
        <tag>linux</tag>
        <tag>malloc</tag>
        <tag>free</tag>
        <tag>gdb</tag>
        <tag>Wall</tag>
        <tag>DAM</tag>
        <tag>errno</tag>
        <tag>lint</tag>
        <tag>ltrace</tag>
        <tag>make</tag>
        <tag>Makefile</tag>
        <tag>mcheck</tag>
        <tag>mtrace</tag>
        <tag>patsubst</tag>
        <tag>perror</tag>
        <tag>splint</tag>
        <tag>strace</tag>
        <tag>strerror</tag>
        <tag>fwrite</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux 调试预备知识</title>
    <url>/2012/04/13/linux-debug-pre/</url>
    <content><![CDATA[预备知识处于TUI模式的GDB加上-tui选项可以在调用GDB时使用TUI模式运行，或者当处于非TUI模式时在GDB中使用Ctrl+A+X组合键就可以在TUI模式和非TUI模式中跳转。
在GUI模式中，GDB窗口划分为两个子窗口：

用于输入GDB命令的窗口
用于查看源码的窗口

通过使用上下方向键可以在TUI模式中移动到代码的其他部分。如果没有处于TUI模式中，就可以使用箭头键来浏览以前的GBD命令，从而修改或重复执行这些命令。
在TUI模式中，箭头键用于滚动源代码子窗口，可以使用Ctrl+P和Ctrl+N组合键来浏览以前的GDB命令。
常用的命令
backtrace：显示程序的当前位置和表示如何到达当前位置的栈跟踪（同义词：where）。
breakpoint：在程序中设置一个断点。
cd：改变当前工作目录。
clear：删除刚才停止处的断点。
commands：命中断点时，列出将要执行的命令。
continue：从断点处开始继续执行。
delete：删除一个断点或监测点，也可与其他命令一起使用。
display：程序停止时显示变量和表达式。
down：下移栈帧，使得另一个函数成为当前函数。
frame：选择下一条continue命令的帧。
info：显示与该程序有关的各种信息。
info break：显示当前断点清单，包括到达断点处的次数等。
info files：显示被调试文件的详细信息。
info func：显示所有的函数名称。
info local：显示当前函数中的局部变量信息。
info prog：显示被调试程序的执行状态。
info var：显示所有的全局和静态变量名称。
jump：在源程序中的另一点开始运行。
kill：异常终止在gdb 控制下运行的程序。
list：列出相应于正在执行的程序的源文件内容。
next：执行下一个源程序行，从而执行其整体中的一个函数。
print：显示变量或表达式的值。
pwd：显示当前工作目录。
pype：显示一个数据结构（如一个结构或C++类）的内容。
quit：退出gdb。
reverse-search：在源文件中反向搜索正规表达式。
run：执行该程序。
search：在源文件中搜索正规表达式。
set variable：给变量赋值。
signal：将一个信号发送到正在运行的进程。
step：执行下一个源程序行，必要时进入下一个函数。
undisplay display：命令的反命令，不要显示表达式。
until：结束当前循环。
up：上移栈帧，使另一个函数成为当前函数。
watch：在程序中设置一个监测点（即数据断点）。
whatis：显示变量或函数类型。

CGDBCGDB是一个很友好的GDB界面，当然是相对于GDB的TUI界面，CGDB也是GDB的前端，虽然CGDB类似于基于终端的TUI的概念，但其在色彩方面特别有吸引力，而且可以浏览源代码子窗口，并直接在子窗口中设置断点，并且CGDB处理屏幕刷新的能力似乎也比GDB的TUI强。
CGDB的基本命令与约定：

按下ESC键可以从基本命令转到源代码窗口，按下i键返回；
当光标在源代码窗口中时，可以使用箭头键或者类似vi的操作在源码中随意移动，j下k上/查找；
要执行的下一行用箭头标记；
为了在通过光标突出显示的当前代码行上设置断点，只要按下空格键即可；
断点行的行号用红色突出显示

编译：gcc -g -Wall -o gdb_app test.c

Attention：其中的-g选项可以让编译器将符号表（即对应程序的变量和代码行的内存地址列表）保存在生成的可执行文件。这是一个绝对必要的步骤，这样才能在调试会话过程中引用源代码中的变量名和行号。

]]></content>
      <categories>
        <category>GDB</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>gui</tag>
        <tag>gcc</tag>
        <tag>gdb</tag>
        <tag>cgdb</tag>
        <tag>TUI</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux debug 停下来环顾程序</title>
    <url>/2012/04/15/linux-debug-walk-around/</url>
    <content><![CDATA[调试器不仅能够运行程序，还可以通知它暂停程序的运行，暂停以后，调试器提供了检查变量、跟踪执行路径的机会。
暂停机制有3中方式可以通过GDB暂停程序的执行：

断点：通知GDB在程序中的特定位置暂停执行；
监视点：通知GDB当特定内存位置（或者设计一个或多个位置的表达式）的值发生变化时暂停执行；
捕获点：通知GDB当特定事件发生时暂停执行；

在GDB中删除断点
delete breakpoint_list
delete
clear
clear function、clear filename：function、clear line_number、clear filename：line_number

在GDB中禁用断点在调试会话期间，会遇到大量断点，对于经常重复的循环结构或函数，这种情况使得调试极不方便。如果要保留断点以便以后使用，暂时又不希望GDB停止执行，可以禁用它们，在以后需要时再启用。此时我们可以使用disable/enable breakpoint_list来禁用和启用断点。
DDD
可以直接拖拽断点，很方便；

还有一个优秀的功能Undo/Redo；


GDB中恢复执行的方法
使用step和next单步调试程序；
使用continue使GDB无条件地恢复程序的执行，知道它遇到另一个断点或者程序结束；
用finish或until命令恢复。

next和step的区别next执行函数，不会在其中暂停，然后在调用之后的第一条语句处暂停；
step在函数中的第一个语句处暂停；
使用continue恢复程序执行continue与执行一行代码的step和next相反，这个命令使GDB恢复程序的执行，直到触发断点或者程序结束。
continue命令可以接受一个可选的整数参数n，这个数字要求GDB忽略下面n个断点。
使用finish恢复程序执行命令finish指示GDB恢复执行，直到恰好在当前栈帧完成之后位置，这意味着如果你在一个不是main的函数中，finish命令会导致GDB恢复执行，直到恰好在函数返回之后为止，例如：
如果在一个递归函数中，finish只会将你带到递归的上一层，这是因为每次调用都被看做在它自己权限内的函数调用，因为每个函数都有自己的栈帧，如果要在递归层次较高时完全退出递归函数，那么更适合使用临时断点及continue，或者使用until命令。
使用until恢复程序执行命令until执行程序，直到到达当前循环体外的下一行源代码。
设置条件断点的方法break break-args if (condition)
监视点监视点是一种特殊类型的断点，它类似于正常断点，是要求GDB暂停程序执行的指令。区别在于监视点是没有“住在”某一行源码中，取而代之的是，监视点是指示GDB每当某个表达式改变了值就暂停执行的指令。
]]></content>
      <categories>
        <category>Linux</category>
        <category>GDB</category>
      </categories>
      <tags>
        <tag>continue</tag>
        <tag>gdb</tag>
        <tag>ddd</tag>
        <tag>breakpoint</tag>
        <tag>finish</tag>
        <tag>next</tag>
        <tag>set</tag>
        <tag>setup</tag>
        <tag>until</tag>
        <tag>watch</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux 调试预备知识</title>
    <url>/2012/04/12/linux-debug/</url>
    <content><![CDATA[预备知识正确使用恰当的调试工具可以提高发现和改正错误的效率，GDB用于逐行跟踪程序、设置断点、检查变量以及查看特定时间程序的执行情况，DDD是流行的GDB的GUI前端，而eclipse提供完整的集成开发环境。
gdbGNU调试器（GNU Debugger，缩写：GDB），是GNU软件系统中的标准调试器，此外GDB也是个具有移携性的调试器，经过移携需求的调修与重新编译，如今许多的类UNIX操作系统上都可以使用GDB，而现有GDB所能支持除错的编程语言有C、C++、Pascal以及FORTRAN。
DDDGNU DDD(Data Display Debugger)是命令行调试程序，如GDB、DBX、WDB、Ladebug、JDB、XDB、Perl Debugger或Python Debugger的可视化图形前端。它特有的图形数据显示功能（Graphical Data Display）可以把数据结构按照图形的方式显示出来。
DDD最初源于1990年Andreas Zeller编写的VSL结构化语言，后来经过一些程序员的努力，演化成今天的模样。DDD的功能非常强大，可以调试用C/C++ 、Ada、Fortran、Pascal、Modula-2和Modula-3编写的程序；可以超文本方式浏览源代码；能够进行断点设置、回溯调试和历史纪录编辑；具有程序在终端运行的仿真窗口，并在远程主机上进行调试的能力；图形数据显示功能（Graphical Data Display）是创建该调试器的初衷之一，能够显示各种数据结构之间的关系，并由此将数据结构以图形化形式显示；具有GDB/DBX/XDB的命令行界面，包括完全的文本编辑、历史纪录、搜寻引擎。
EclipseEclipse 是一个开放源代码的、基于Java的可扩展开发平台。就其本身而言，它只是一个框架和一组服务，用于通过插件组件构建开发环境。幸运的是，Eclipse 附带了一个标准的插件集，包括Java开发工具（Java Development Kit，JDK）。
为什么要用调试工具，使用printf或者cout不是很好嘛对于打印输出要求我们有策略地持续添加跟踪代码，重新编译程序，运行程序并分析跟踪代码的输出，在修正程序错误之后删除跟踪代码，并且针对发现的每个新的程序错误重复上述这些步骤，很费事，很费力，很容易将我们的注意力转移到排查错误的过程上而不是实际的任务上。
相反，使用调试工具，比如ddd或者eclipse的GUI，我们只需要使用鼠标指针就可以检查变量的值，并显示该变量的当前值，and调试器还可以指出程序错误所在的大概位置。例如，段错误即内存访问错误，调试器会立即指出段错误所在的位置，and调试器还可以设置监视点watchpoint，持续监视某个变量的值。
调试原则：
从简单工作开始调试；
使用自顶向下的方法；
使用调试工具确定段错误的位置；
通过发出中断确定无限循环的位置；
使用二分搜索；

命令行调试 vs GUI调试GUI的优点: GUI界面比GDB提供的GUI界面的外观更加形象，使用起来更加方便；
GDB的优点

GDB的启动速度比DDD快很多；
在某些情况下，通过来自于公共中断的SSH连接远程执行调试，如果没有安装X11，就完全不能使用GUI了，即使有X11，GUI的屏幕刷新操作也会非常缓慢；
当调试彼此之间协同操作的多个程序时，就需要针对每个程序的独立调试窗口，对于GUI窗口操作就比较麻烦；

]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>gui</tag>
        <tag>gdb</tag>
        <tag>eclipse</tag>
        <tag>ddd</tag>
        <tag>dbx</tag>
        <tag>jdb</tag>
        <tag>ladebug</tag>
        <tag>perl</tag>
        <tag>wdb</tag>
        <tag>xdb</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux base64命令</title>
    <url>/2013/03/06/linux-decode/</url>
    <content><![CDATA[linux base64命令可以直接输入base64从标准输入中读取数据，按Ctrl+D结束输入。将输入的内容编码为base64字符串输出。
也可以使用管道符号，比如 echo "str" | base64 ，将字符串str+换行 编码为base64字符串输出。
如果希望省略换行符，可以使用echo -n "str" | base64，同样base64还可以编码文件，比如base64 file，输出编码为base64字符串输出，解码为-d即可。
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>base64</tag>
        <tag>encode</tag>
        <tag>decode</tag>
      </tags>
  </entry>
  <entry>
    <title>删除Linux多余的内核</title>
    <url>/2013/10/30/linux-delete-redundant-linux-kernel/</url>
    <content><![CDATA[删除Linux多余内核还记得曾经一度有个牛人，几百个大大的linux启动项列表，据说从头到尾看一遍就需要10几分钟，哥有洁癖，内核升级完后，如果使用稳定，过个几天就会清理掉（因为有时在安装新系统的时候可能boot分的不是很大，在update的时候，老是提示说boot分区大小不够，清理掉就瞬间OK了），不过最近的grub做的比较人性了，以前都是满屏的内核版本，现在除了最新的，其他的都放在一个Previous Linux Version了，就像微信里面的公众号放到一个文件夹里面，世界瞬间安静了很多。
Debian系列–适用于Ubuntu、LinuxMint等第一种方法找出系统已经安装的内核版本，在终端里输入命令：
dpkg –get-selections | grep linux-image

然后会显示系统中已安装的内核.
卸载旧的内核版本，在终端里输入命令：
sudo apt-get remove linux-image-***
注意不要把最新的内核给删除掉哟，我没有测试过，不知道会出现嘛情况，你可以手一哆嗦小试一下撒。
删除内核后，运行下属命令，直接重启也可以。
update-grub


第二种方法在图像界面下，可以使用新立得软件包管理器删除

点菜单“系统－系统管理－新立得软件包管理器”；
以2.6.32-21版本的内核为例，内核文件里包括：linux-headers-2.6.32-21、linux-headers- 2.6.32-21-generic、linux-image-2.6.32-21-generic、linux-restricted-modules-2.6.32-21-generic、linux-ubuntu-modules-2.6.32-21-generic；
在新立得中，点工具栏上的“搜索”按钮，在出来的搜索框中输入 linux 2.6.32-21 ，注意linux后面有一个空格

Redhat系列–适用于CentOS、Fedora等第一种方法首先列出系统中正在使用的内核:
# uname -a

查询系统中全部的内核:
# rpm -qa | grep kernel

将你想删除的内核删除掉🙁例如,在我的系统中,我要删掉kernel-2.6.32-279.9.1.el6.x86_64的内核,需要把所有含有kernel-2.6.32-279.9.1.el6.x86_64字样的全部删掉)
#yum remove kernel-2.6.32-279.9.1.el6.x86_64

重启后就可以看到,内核被删掉了,同时多余的启动项也自动被删掉了。
第二种方法手动修改/boot/grub/menu.lst 把多余的项删除，但是这个指标不治本哟。
第三种方法  –  力荐查看已经安装的内核命令：
rpm -q kernel
删除旧的内核
安装yum-utls：
sudo install yum-utils

设置你想要保留多少旧的内核，比如我想保留两个：
sudo package-cleanup –oldkernels –count=2

设置永久的内核安装数量，我设置的是两个
sudo gedit /etc/yum.conf#设置installonly_limit=2

重启，就只会看见两个内核启动项了。
第四种方法删除除当前内核外的其他所有内核，一条命令即可解决：
yum remove kernel
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>rpm</tag>
        <tag>yum</tag>
        <tag>CentOS</tag>
        <tag>Linux</tag>
        <tag>kernel</tag>
        <tag>Debian</tag>
        <tag>ubuntu</tag>
        <tag>Fedora</tag>
        <tag>dpkg</tag>
      </tags>
  </entry>
  <entry>
    <title>汇报磁盘空间的df</title>
    <url>/2013/01/20/linux-df-beginner/</url>
    <content><![CDATA[汇报磁盘空间的df.. _linux_df_beginner:
使用man来查看df，官方含义为:

 report file system disk space usage

也就是查看文件系统的磁盘空间占用情况，可以利用该命令来获取硬盘被占用了多少空间，目前还剩下多少空间等信息。
选项这个命令的使用也是中规中矩，df [options]，其中一些比较有用的选项为：

-a, --all，这个用的不多，不过可以把所有的信息，包括无法访问的一一列出来
-B, --block-size=SIZE，以SIZE为单位显示，比如M/T分别按照MB和TB来显示
--total：比较好用的是，提供了一个总的使用比例出来
-h, --human-readable：这个比较友好，也是最常用的一个选项
-H, --si：强迫症必备，如果非要认为1K是1000而不是1024.
-l, --local：对于目前网络挂载NFS等等必须的一个选项
-T, --print-type：打印文件系统的类型，比如xfs，比如zfs等等

不加任何参数的输出如果不加任何选项，输出如下：
$ dfFilesystem            1K-blocks        Used   Available Use% Mounted on/dev/mapper/cl-root   976083292   242281612   733801680  25% /devtmpfs               16315508           0    16315508   0% /devtmpfs                  16332416       18788    16313628   1% /dev/shmtmpfs                  16332416     1643588    14688828  11% /runtmpfs                  16332416           0    16332416   0% /sys/fs/cgroup/dev/sdb2               1038336      407812      630524  40% /boot/dev/sda            93759481856 72887620044 20871861812  78% /data/dev/mapper/cl-home 32210167688 29543283400  2666884288  92% /hometmpfs                   3266484         236     3266248   1% /run/user/1000


其实我比较想知道data目录到底是多大，哈哈

全而杂的-a选项这个选项虽然可以输出所有的信息，但是有些真的不是一般人需要并且想要的。
$ df -aFilesystem            1K-blocks        Used   Available Use% Mounted onrootfs                        -           -           -    - /sysfs                         0           0           0    - /sysproc                          0           0           0    - /procdevtmpfs               16315508           0    16315508   0% /devsecurityfs                    0           0           0    - /sys/kernel/securitytmpfs                  16332416       18788    16313628   1% /dev/shmdevpts                        0           0           0    - /dev/ptstmpfs                  16332416     1643588    14688828  11% /runtmpfs                  16332416           0    16332416   0% /sys/fs/cgroupcgroup                        0           0           0    - /sys/fs/cgroup/systemdpstore                        0           0           0    - /sys/fs/pstorecgroup                        0           0           0    - /sys/fs/cgroup/memorycgroup                        0           0           0    - /sys/fs/cgroup/pidscgroup                        0           0           0    - /sys/fs/cgroup/freezercgroup                        0           0           0    - /sys/fs/cgroup/perf_eventcgroup                        0           0           0    - /sys/fs/cgroup/net_cls,net_priocgroup                        0           0           0    - /sys/fs/cgroup/blkiocgroup                        0           0           0    - /sys/fs/cgroup/cpusetcgroup                        0           0           0    - /sys/fs/cgroup/cpu,cpuacctcgroup                        0           0           0    - /sys/fs/cgroup/devicescgroup                        0           0           0    - /sys/fs/cgroup/hugetlbconfigfs                      0           0           0    - /sys/kernel/config/dev/mapper/cl-root   976083292   242283596   733799696  25% /selinuxfs                     0           0           0    - /sys/fs/selinuxsystemd-1                     -           -           -    - /proc/sys/fs/binfmt_miscdebugfs                       0           0           0    - /sys/kernel/debugmqueue                        0           0           0    - /dev/mqueuehugetlbfs                     0           0           0    - /dev/hugepages/dev/sdb2               1038336      407812      630524  40% /boot/dev/sda            93759481856 72887620044 20871861812  78% /data/dev/mapper/cl-home 32210167688 29543283400  2666884288  92% /homesunrpc                        0           0           0    - /var/lib/nfs/rpc_pipefstmpfs                   3266484         236     3266248   1% /run/user/1000gvfsd-fuse                    0           0           0    - /run/user/1000/gvfsfusectl                       0           0           0    - /sys/fs/fuse/connectionsbinfmt_misc                   0           0           0    - /proc/sys/fs/binfmt_misc



根据TB来显示如果知道硬盘的空间或存储在TB量级就可以用BT了，如果是PB量级的，恭喜你，可以用BP.
$ df -BTFilesystem          1T-blocks  Used Available Use% Mounted on/dev/mapper/cl-root        1T    1T        1T  25% /devtmpfs                   1T    0T        1T   0% /devtmpfs                      1T    1T        1T   1% /dev/shmtmpfs                      1T    1T        1T  11% /runtmpfs                      1T    0T        1T   0% /sys/fs/cgroup/dev/sdb2                  1T    1T        1T  40% /boot/dev/sda                  88T   68T       20T  78% /data/dev/mapper/cl-home       30T   28T        3T  92% /hometmpfs                      1T    1T        1T   1% /run/user/1000





我想知道整个系统一共用了多少此时total发挥出绝佳的作用，在最后一行输出一个总占比
$ df --totalFilesystem             1K-blocks         Used   Available Use% Mounted on/dev/mapper/cl-root    976083292    242283596   733799696  25% /devtmpfs                16315508            0    16315508   0% /devtmpfs                   16332416        18788    16313628   1% /dev/shmtmpfs                   16332416      1643588    14688828  11% /runtmpfs                   16332416            0    16332416   0% /sys/fs/cgroup/dev/sdb2                1038336       407812      630524  40% /boot/dev/sda             93759481856  72887620044 20871861812  78% /data/dev/mapper/cl-home  32210167688  29543283400  2666884288  92% /hometmpfs                    3266484          236     3266248   1% /run/user/1000

我在单独拉出来秀一秀 ：total               127015350412 102675257464 24340092948  81% -
非目力所及，自动判断这个是我用的很多的参数，应该也是最常用的，-h的含义前面也可以看到是human-read的意思，方便我们人类，会使用M、G这样的单位来区别
$ df -hFilesystem           Size  Used Avail Use% Mounted on/dev/mapper/cl-root  931G  232G  700G  25% /devtmpfs              16G     0   16G   0% /devtmpfs                 16G   19M   16G   1% /dev/shmtmpfs                 16G  1.6G   15G  11% /runtmpfs                 16G     0   16G   0% /sys/fs/cgroup/dev/sdb2           1014M  399M  616M  40% /boot/dev/sda              88T   68T   20T  78% /data/dev/mapper/cl-home   30T   28T  2.5T  92% /hometmpfs                3.2G  236K  3.2G   1% /run/user/1000



强迫症患者的福音如果非得说1K是1000，而不是1024，那么这个选项比较合适秀一下。
$ df -HFilesystem           Size  Used Avail Use% Mounted on/dev/mapper/cl-root  1.0T  249G  752G  25% /devtmpfs              17G     0   17G   0% /devtmpfs                 17G   20M   17G   1% /dev/shmtmpfs                 17G  1.7G   16G  11% /runtmpfs                 17G     0   17G   0% /sys/fs/cgroup/dev/sdb2            1.1G  418M  646M  40% /boot/dev/sda              97T   75T   22T  78% /data/dev/mapper/cl-home   33T   31T  2.8T  92% /hometmpfs                3.4G  242k  3.4G   1% /run/user/1000



只显示本地信息在网络发达的今天，各种挂载满天飞，NFS四处连接，如果不跟上l选项，估计已经分不清哪个是哪个了。
$ df -lFilesystem            1K-blocks        Used   Available Use% Mounted on/dev/mapper/cl-root   976083292   242283596   733799696  25% /devtmpfs               16315508           0    16315508   0% /devtmpfs                  16332416       18788    16313628   1% /dev/shmtmpfs                  16332416     1643588    14688828  11% /runtmpfs                  16332416           0    16332416   0% /sys/fs/cgroup/dev/sdb2               1038336      407812      630524  40% /boot/dev/sda            93759481856 72887620044 20871861812  78% /data/dev/mapper/cl-home 32210167688 29543283400  2666884288  92% /hometmpfs                   3266484         236     3266248   1% /run/user/1000



查看系统类型系统类型有很多，可以通过-T选项来查找。
$ df -TFilesystem          Type       1K-blocks        Used   Available Use% Mounted on/dev/mapper/cl-root xfs        976083292   242283596   733799696  25% /devtmpfs            devtmpfs    16315508           0    16315508   0% /devtmpfs               tmpfs       16332416       18788    16313628   1% /dev/shmtmpfs               tmpfs       16332416     1643588    14688828  11% /runtmpfs               tmpfs       16332416           0    16332416   0% /sys/fs/cgroup/dev/sdb2           xfs          1038336      407812      630524  40% /boot/dev/sda            xfs      93759481856 72887620044 20871861812  78% /data/dev/mapper/cl-home xfs      32210167688 29543283400  2666884288  92% /hometmpfs               tmpfs        3266484         236     3266248   1% /run/user/1000

]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>磁盘管理</tag>
        <tag>df</tag>
        <tag>disk space</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux df命令</title>
    <url>/2013/01/20/linux-df/</url>
    <content><![CDATA[df - 查看硬盘大小使用man来查看df，官方含义为:

 report file system disk space usage

也就是查看文件系统的磁盘空间占用情况，可以利用该命令来获取硬盘被占用了多少空间，目前还剩下多少空间等信息。
选项这个命令的使用也是中规中矩，df [options]，其中一些比较有用的选项为：

-a, --all，这个用的不多，不过可以把所有的信息，包括无法访问的一一列出来
-B, --block-size=SIZE，以SIZE为单位显示，比如M/T分别按照MB和TB来显示
--total：比较好用的是，提供了一个总的使用比例出来
-h, --human-readable：这个比较友好，也是最常用的一个选项
-H, --si：强迫症必备，如果非要认为1K是1000而不是1024.
-l, --local：对于目前网络挂载NFS等等必须的一个选项
-T, --print-type：打印文件系统的类型，比如xfs，比如zfs等等

不加任何参数的输出如果不加任何选项，输出如下：
$ dfFilesystem            1K-blocks        Used   Available Use% Mounted on/dev/mapper/cl-root   976083292   242281612   733801680  25% /devtmpfs               16315508           0    16315508   0% /devtmpfs                  16332416       18788    16313628   1% /dev/shmtmpfs                  16332416     1643588    14688828  11% /runtmpfs                  16332416           0    16332416   0% /sys/fs/cgroup/dev/sdb2               1038336      407812      630524  40% /boot/dev/sda            93759481856 72887620044 20871861812  78% /data/dev/mapper/cl-home 32210167688 29543283400  2666884288  92% /hometmpfs                   3266484         236     3266248   1% /run/user/1000


其实我比较想知道data目录到底是多大，哈哈

全而杂的-a选项这个选项虽然可以输出所有的信息，但是有些真的不是一般人需要并且想要的。
$ df -aFilesystem            1K-blocks        Used   Available Use% Mounted onrootfs                        -           -           -    - /sysfs                         0           0           0    - /sysproc                          0           0           0    - /procdevtmpfs               16315508           0    16315508   0% /devsecurityfs                    0           0           0    - /sys/kernel/securitytmpfs                  16332416       18788    16313628   1% /dev/shmdevpts                        0           0           0    - /dev/ptstmpfs                  16332416     1643588    14688828  11% /runtmpfs                  16332416           0    16332416   0% /sys/fs/cgroupcgroup                        0           0           0    - /sys/fs/cgroup/systemdpstore                        0           0           0    - /sys/fs/pstorecgroup                        0           0           0    - /sys/fs/cgroup/memorycgroup                        0           0           0    - /sys/fs/cgroup/pidscgroup                        0           0           0    - /sys/fs/cgroup/freezercgroup                        0           0           0    - /sys/fs/cgroup/perf_eventcgroup                        0           0           0    - /sys/fs/cgroup/net_cls,net_priocgroup                        0           0           0    - /sys/fs/cgroup/blkiocgroup                        0           0           0    - /sys/fs/cgroup/cpusetcgroup                        0           0           0    - /sys/fs/cgroup/cpu,cpuacctcgroup                        0           0           0    - /sys/fs/cgroup/devicescgroup                        0           0           0    - /sys/fs/cgroup/hugetlbconfigfs                      0           0           0    - /sys/kernel/config/dev/mapper/cl-root   976083292   242283596   733799696  25% /selinuxfs                     0           0           0    - /sys/fs/selinuxsystemd-1                     -           -           -    - /proc/sys/fs/binfmt_miscdebugfs                       0           0           0    - /sys/kernel/debugmqueue                        0           0           0    - /dev/mqueuehugetlbfs                     0           0           0    - /dev/hugepages/dev/sdb2               1038336      407812      630524  40% /boot/dev/sda            93759481856 72887620044 20871861812  78% /data/dev/mapper/cl-home 32210167688 29543283400  2666884288  92% /homesunrpc                        0           0           0    - /var/lib/nfs/rpc_pipefstmpfs                   3266484         236     3266248   1% /run/user/1000gvfsd-fuse                    0           0           0    - /run/user/1000/gvfsfusectl                       0           0           0    - /sys/fs/fuse/connectionsbinfmt_misc                   0           0           0    - /proc/sys/fs/binfmt_misc



根据TB来显示如果知道硬盘的空间或存储在TB量级就可以用BT了，如果是PB量级的，恭喜你，可以用BP.
$ df -BTFilesystem          1T-blocks  Used Available Use% Mounted on/dev/mapper/cl-root        1T    1T        1T  25% /devtmpfs                   1T    0T        1T   0% /devtmpfs                      1T    1T        1T   1% /dev/shmtmpfs                      1T    1T        1T  11% /runtmpfs                      1T    0T        1T   0% /sys/fs/cgroup/dev/sdb2                  1T    1T        1T  40% /boot/dev/sda                  88T   68T       20T  78% /data/dev/mapper/cl-home       30T   28T        3T  92% /hometmpfs                      1T    1T        1T   1% /run/user/1000





我想知道整个系统一共用了多少此时total发挥出绝佳的作用，在最后一行输出一个总占比
$ df --totalFilesystem             1K-blocks         Used   Available Use% Mounted on/dev/mapper/cl-root    976083292    242283596   733799696  25% /devtmpfs                16315508            0    16315508   0% /devtmpfs                   16332416        18788    16313628   1% /dev/shmtmpfs                   16332416      1643588    14688828  11% /runtmpfs                   16332416            0    16332416   0% /sys/fs/cgroup/dev/sdb2                1038336       407812      630524  40% /boot/dev/sda             93759481856  72887620044 20871861812  78% /data/dev/mapper/cl-home  32210167688  29543283400  2666884288  92% /hometmpfs                    3266484          236     3266248   1% /run/user/1000

我在单独拉出来秀一秀 ：total               127015350412 102675257464 24340092948  81% -
非目力所及，自动判断这个是我用的很多的参数，应该也是最常用的，-h的含义前面也可以看到是human-read的意思，方便我们人类，会使用M、G这样的单位来区别
$ df -hFilesystem           Size  Used Avail Use% Mounted on/dev/mapper/cl-root  931G  232G  700G  25% /devtmpfs              16G     0   16G   0% /devtmpfs                 16G   19M   16G   1% /dev/shmtmpfs                 16G  1.6G   15G  11% /runtmpfs                 16G     0   16G   0% /sys/fs/cgroup/dev/sdb2           1014M  399M  616M  40% /boot/dev/sda              88T   68T   20T  78% /data/dev/mapper/cl-home   30T   28T  2.5T  92% /hometmpfs                3.2G  236K  3.2G   1% /run/user/1000



强迫症患者的福音如果非得说1K是1000，而不是1024，那么这个选项比较合适秀一下。
$ df -HFilesystem           Size  Used Avail Use% Mounted on/dev/mapper/cl-root  1.0T  249G  752G  25% /devtmpfs              17G     0   17G   0% /devtmpfs                 17G   20M   17G   1% /dev/shmtmpfs                 17G  1.7G   16G  11% /runtmpfs                 17G     0   17G   0% /sys/fs/cgroup/dev/sdb2            1.1G  418M  646M  40% /boot/dev/sda              97T   75T   22T  78% /data/dev/mapper/cl-home   33T   31T  2.8T  92% /hometmpfs                3.4G  242k  3.4G   1% /run/user/1000



只显示本地信息在网络发达的今天，各种挂载满天飞，NFS四处连接，如果不跟上l选项，估计已经分不清哪个是哪个了。
$ df -lFilesystem            1K-blocks        Used   Available Use% Mounted on/dev/mapper/cl-root   976083292   242283596   733799696  25% /devtmpfs               16315508           0    16315508   0% /devtmpfs                  16332416       18788    16313628   1% /dev/shmtmpfs                  16332416     1643588    14688828  11% /runtmpfs                  16332416           0    16332416   0% /sys/fs/cgroup/dev/sdb2               1038336      407812      630524  40% /boot/dev/sda            93759481856 72887620044 20871861812  78% /data/dev/mapper/cl-home 32210167688 29543283400  2666884288  92% /hometmpfs                   3266484         236     3266248   1% /run/user/1000



查看系统类型系统类型有很多，可以通过-T选项来查找。
$ df -TFilesystem          Type       1K-blocks        Used   Available Use% Mounted on/dev/mapper/cl-root xfs        976083292   242283596   733799696  25% /devtmpfs            devtmpfs    16315508           0    16315508   0% /devtmpfs               tmpfs       16332416       18788    16313628   1% /dev/shmtmpfs               tmpfs       16332416     1643588    14688828  11% /runtmpfs               tmpfs       16332416           0    16332416   0% /sys/fs/cgroup/dev/sdb2           xfs          1038336      407812      630524  40% /boot/dev/sda            xfs      93759481856 72887620044 20871861812  78% /data/dev/mapper/cl-home xfs      32210167688 29543283400  2666884288  92% /hometmpfs               tmpfs        3266484         236     3266248   1% /run/user/1000

]]></content>
      <categories>
        <category>Linux</category>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>df</tag>
        <tag>disk space</tag>
      </tags>
  </entry>
  <entry>
    <title>远看高低各不同 diff</title>
    <url>/2013/03/06/linux-diff-beginner/</url>
    <content><![CDATA[远看高低各不同 diff.. _linux_diff_beginner:
.. note::  草色烟光残照里，无言谁会凭阑意  宋代 柳永《蝶恋花·伫倚危楼风细细》
Linux diff 命令用于比较文件的差异。
当然还有很多比较文件的专业工具，但是如果在Linux命令行，这个是最原始最初的，也是开机即用的。
官方定义为：

GNU diff - compare files line by line

diff 会以逐行的方式，比较文本文件的不同。
如果指定要比较目录，则 diff 会比较目录中相同文件名的文件，但不会比较其中子目录。
语法$ diff [OPTION]... FILES

参数：

-c 显示所有内容，并标出不同之处。
-u 以合并的方式来显示文件内容的不同。
-y或--side-by-side 　两列输出显示文件的异同之处。

假定有两个文件a和b，内容分别为：
$ cat aThis is a.Hello a.Hello World.$ cat bThis is b.Hello b.Hello World.



默认比较两个文件默认情况下，直接输入下面命令即可：
$  diff a b1,2c1,2&lt; This is a.&lt; Hello a.---&gt; This is b.&gt; Hello b.3a4&gt; One more line.

可以看到1,2c1,2，中间有一个字母c；3a4，中间有一个字母a。
那么a和c什么含义呢，中间的字母表示需要在第一个文件上做的操作(a=add,c=change,d=delete)，然后才有后面的文件一致。
所以1,2c1,2表示1,2行更换后一致；3a4表示，增加一行后一致。
并排显示方便比较这种方式相对而言，就很亲民了，左右两边两列方便比对。
$ diff a b -yThis is a.                                                    | This is b.Hello a.                                                      | Hello b.Hello World.                                                    Hello World.                                                              &gt; One more line.

那么：

“|”表示前后2个文件内容有不同；

“&lt;”表示后面文件比前面文件少了1行内容

“&gt;”表示后面文件比前面文件多了1行内容


context模式比较这种模式会输出所有的文件内容，并显示不同之处，还包括具体的时间。
如下*** 表示a的内容，--- 表示b的内容。 
$ diff a b -c*** a   2013-03-04 23:20:20.322345200 +0800--- b   2013-03-04 23:26:30.712130000 +0800****************** 1,3 ****! This is a.! Hello a.  Hello World.--- 1,4 ----! This is b.! Hello b.  Hello World.+ One more line.



unified模式比较这种模式会混合输出所有的文件内容，并显示不同之处，还包括具体的时间。
如下--- 表示a的内容，+++ 表示b的内容。
$  diff a b -u--- a   2013-03-04 23:20:20.322345200 +0800--- b   2013-03-04 23:26:30.712130000 +0800@@ -1,3 +1,4 @@-This is a.-Hello a.+This is b.+Hello b. Hello World.+One more line.

对比时忽略空格# diff -w name_list.txt name_list_new.txt2c2,3&lt; John Doe --- &gt; John M Doe&gt; Jason Bourne

快速找出两个目录的不同diff命令会按行比较文件。但是它也可以比较两个目录：
ls -l /tmp/rls -l /tmp/s# 使用 diff 比较两个文件夹diff /tmp/r/ /tmp/s/
]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>diff</tag>
        <tag>文件操作</tag>
        <tag>文件管理</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux diff命令</title>
    <url>/2013/03/06/linux-diff/</url>
    <content><![CDATA[Linux diff 命令Linux diff 命令用于比较文件的差异。
当然还有很多比较文件的专业工具，但是如果在Linux命令行，这个是最原始最初的，也是开机即用的。
官方定义为：

GNU diff - compare files line by line

diff 会以逐行的方式，比较文本文件的不同。
如果指定要比较目录，则 diff 会比较目录中相同文件名的文件，但不会比较其中子目录。
语法$ diff [OPTION]... FILES

参数：

-c 显示所有内容，并标出不同之处。
-u 以合并的方式来显示文件内容的不同。
-y或--side-by-side 　两列输出显示文件的异同之处。

假定有两个文件a和b，内容分别为：
$ cat aThis is a.Hello a.Hello World.$ cat bThis is b.Hello b.Hello World.



默认比较两个文件默认情况下，直接输入下面命令即可：
$  diff a b1,2c1,2&lt; This is a.&lt; Hello a.---&gt; This is b.&gt; Hello b.3a4&gt; One more line.

可以看到1,2c1,2，中间有一个字母c；3a4，中间有一个字母a。
那么a和c什么含义呢，中间的字母表示需要在第一个文件上做的操作(a=add,c=change,d=delete)，然后才有后面的文件一致。
所以1,2c1,2表示1,2行更换后一致；3a4表示，增加一行后一致。
并排显示方便比较这种方式相对而言，就很亲民了，左右两边两列方便比对。
$ diff a b -yThis is a.                                                    | This is b.Hello a.                                                      | Hello b.Hello World.                                                    Hello World.                                                              &gt; One more line.

那么：

“|”表示前后2个文件内容有不同；

“&lt;”表示后面文件比前面文件少了1行内容

“&gt;”表示后面文件比前面文件多了1行内容


context模式比较这种模式会输出所有的文件内容，并显示不同之处，还包括具体的时间。
如下*** 表示a的内容，--- 表示b的内容。 
$ diff a b -c*** a   2013-03-04 20:30:20.322345200 +0800+++ b   2013-03-04 20:26:30.712130000 +0800****************** 1,3 ****! This is a.! Hello a.  Hello World.--- 1,4 ----! This is b.! Hello b.  Hello World.+ One more line.



unified模式比较这种模式会混合输出所有的文件内容，并显示不同之处，还包括具体的时间。
如下--- 表示a的内容，+++ 表示b的内容。
$  diff a b -u--- a   2013-03-04 20:30:20.322345200 +0800+++ b   2013-03-04 20:26:30.712130000 +0800@@ -1,3 +1,4 @@-This is a.-Hello a.+This is b.+Hello b. Hello World.+One more line.










-&lt;行数&gt; 　指定要显示多少行的文本。此参数必须与-c或-u参数一并使用。

-a或–text 　diff预设只会逐行比较文本文件。

-b或–ignore-space-change 　不检查空格字符的不同。

-B或–ignore-blank-lines 　不检查空白行。


-C&lt;行数&gt;或–context&lt;行数&gt; 　与执行”-c-&lt;行数&gt;”指令相同。

-d或–minimal 　使用不同的演算法，以较小的单位来做比较。

-D&lt;巨集名称&gt;或ifdef&lt;巨集名称&gt; 　此参数的输出格式可用于前置处理器巨集。

-e或–ed 　此参数的输出格式可用于ed的script文件。

-f或-forward-ed 　输出的格式类似ed的script文件，但按照原来文件的顺序来显示不同处。

-H或–speed-large-files 　比较大文件时，可加快速度。

-I&lt;字符或字符串&gt;或–ignore-matching-lines&lt;字符或字符串&gt; 　若两个文件在某几行有所不同，而这几行同时都包含了选项中指定的字符或字符串，则不显示这两个文件的差异。

-i或–ignore-case 　不检查大小写的不同。

-l或–paginate 　将结果交由pr程序来分页。

-n或–rcs 　将比较结果以RCS的格式来显示。

-N或–new-file 　在比较目录时，若文件A仅出现在某个目录中，预设会显示：

Only in目录：文件A若使用-N参数，则diff会将文件A与一个空白的文件比较。

-p 　若比较的文件为C语言的程序码文件时，显示差异所在的函数名称。

-P或–unidirectional-new-file 　与-N类似，但只有当第二个目录包含了一个第一个目录所没有的文件时，才会将这个文件与空白的文件做比较。

-r或–recursive 　比较子目录中的文件。

-s或–report-identical-files 　若没有发现任何差异，仍然显示信息。

-S&lt;文件&gt;或–starting-file&lt;文件&gt; 　在比较目录时，从指定的文件开始比较。

-t或–expand-tabs 　在输出时，将tab字符展开。

-T或–initial-tab 　在每行前面加上tab字符以便对齐。

-w或–ignore-all-space 　忽略全部的空格字符。

-W&lt;宽度&gt;或–width&lt;宽度&gt; 　在使用-y参数时，指定栏宽。

-x&lt;文件名或目录&gt;或–exclude&lt;文件名或目录&gt; 　不比较选项中所指定的文件或目录。

-X&lt;文件&gt;或–exclude-from&lt;文件&gt; 　您可以将文件或目录类型存成文本文件，然后在=&lt;文件&gt;中指定此文本文件。

–left-column 　在使用-y参数时，若两个文件某一行内容相同，则仅在左侧的栏位显示该行内容。

–suppress-common-lines 　在使用-y参数时，仅显示不同之处。
 Mandatory arguments to long options are mandatory for short options too.

 --normal
        output a normal diff (the default)

 -q, --brief
        report only when files differ

 -s, --report-identical-files
        report when two files are the same

 -c, -C NUM, --context[=NUM]
        output NUM (default 3) lines of copied context

 -e, --ed
        output an ed script

 -n, --rcs
        output an RCS format diff

 -W, --width=NUM
        output at most NUM (default 130) print columns

 --left-column
        output only the left column of common lines

 --suppress-common-lines
        do not output common lines

 -p, --show-c-function
        show which C function each change is in
         -F, --show-function-line=RE
            show the most recent line matching RE

     --label LABEL
            use LABEL instead of file name and timestamp (can be repeated)

     -t, --expand-tabs
            expand tabs to spaces in output

     -T, --initial-tab
            make tabs line up by prepending a tab

     --tabsize=NUM
            tab stops every NUM (default 8) print columns

     --suppress-blank-empty
            suppress space or tab before empty output lines

     -l, --paginate
            pass output through 'pr' to paginate it

     -r, --recursive
            recursively compare any subdirectories found

     --no-dereference
            don't follow symbolic links

     -N, --new-file
            treat absent files as empty

     --unidirectional-new-file
            treat absent first files as empty

     --ignore-file-name-case
            ignore case when comparing file names

     --no-ignore-file-name-case
            consider case when comparing file names

     -x, --exclude=PAT
            exclude files that match PAT

     -X, --exclude-from=FILE
            exclude files that match any pattern in FILE

     -S, --starting-file=FILE
            start with FILE when comparing directories
            
             --from-file=FILE1
            compare FILE1 to all operands; FILE1 can be a directory

     --to-file=FILE2
            compare all operands to FILE2; FILE2 can be a directory

     -i, --ignore-case
            ignore case differences in file contents

     -E, --ignore-tab-expansion
            ignore changes due to tab expansion

     -Z, --ignore-trailing-space
            ignore white space at line end

     -b, --ignore-space-change
            ignore changes in the amount of white space

     -w, --ignore-all-space
            ignore all white space

     -B, --ignore-blank-lines
            ignore changes where lines are all blank

     -I, --ignore-matching-lines=RE
            ignore changes where all lines match RE

     -a, --text
            treat all files as text

     --strip-trailing-cr
            strip trailing carriage return on input

     -D, --ifdef=NAME
            output merged file with '#ifdef NAME' diffs

     --GTYPE-group-format=GFMT
            format GTYPE input groups with GFMT

     --line-format=LFMT
            format all input lines with LFMT
            
                  These format options provide fine-grained control over the output

            of diff, generalizing -D/--ifdef.

     LTYPE is 'old', 'new', or 'unchanged'.
            GTYPE is LTYPE or 'changed'.

            GFMT (only) may contain:

     %&lt;     lines from FILE1

     %&gt;     lines from FILE2

     %=     lines common to FILE1 and FILE2

     %[-][WIDTH][.[PREC]]{doxX}LETTER
            printf-style spec for LETTER

            LETTERs are as follows for new group, lower case for old group:

     F      first line number

     L      last line number

     N      number of lines = L-F+1

     E      F-1

     M      L+1

     %(A=B?T:E)
            if A equals B then T else E

            LFMT (only) may contain:

     %L     contents of line

     %l     contents of line, excluding any trailing newline

     %[-][WIDTH][.[PREC]]{doxX}n
            printf-style spec for input line number

            Both GFMT and LFMT may contain:

     %%     %
     
      %c'C'  the single character C

     %c'\OOO'
            the character with octal code OOO

     C      the character C (other characters represent themselves)

     -d, --minimal
            try hard to find a smaller set of changes

     --horizon-lines=NUM
            keep NUM lines of the common prefix and suffix

     --speed-large-files
            assume large files and many scattered small changes

     --color[=WHEN]
            colorize the output; WHEN can be 'never', 'always', or 'auto' (the default)

     --palette=PALETTE
            the colors to use when --color is active; PALETTE is a colon-separated list of terminfo capabilities



     FILES  are  'FILE1  FILE2'  or 'DIR1 DIR2' or 'DIR FILE' or 'FILE DIR'.  If --from-file or --to-file is given,
     there are no restrictions on FILE(s).  If a FILE is '-', read standard input.  Exit status is 0 if inputs  are
     the same, 1 if different, 2 if trouble.



]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>diff</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>/2025/06/19/linux-dir-beginner/</url>
    <content><![CDATA[]]></content>
  </entry>
  <entry>
    <title>Linux 十大发行版</title>
    <url>/2011/01/01/linux-distributions/</url>
    <content><![CDATA[Linux 十大发行版 对于Linux新手来说，在各发行版之间困惑得进行选择和不断增加的数量实在令人头晕。
不过随着大浪淘沙和各种变化，曾经的发行版也在悄然发生着变化。
而相对而言最为人所知且应用广泛的，无外乎：

Ubuntu， Linux Mint 和 PCLinuxOS 被认为是对想在熟悉系统的复杂内容之前尽可能早的开始使用的人来说最简单的发行版
Slackware Linux， Gentoo Linux 和 FreeBSD 是高级的多的发行版，在有效使用前需要进行大量的学习
openSUSE， Fedora， Debian GNU/Linux 和 Mandriva Linux 则可以被划分为优秀的“中间路线”版本
CentOS 是企业版本，适合对稳定性、可靠性、在尖端功能和软件的长期支持方面比较看重的用户。【已经停止更新，不过大部分的企业服务器依旧在坚挺】

Ubuntu Ubuntu 于2004年9月首次宣布发行。尽管是 Linux 舞台上的后起之秀，但在接下来的几年里， Ubuntu 成长为最流行的 Linux 桌面发行版而且对既“简单易用”又自由还能够与其它任何在市场上的私有版本有力竞争的操作系统的发展有巨大贡献。
 Ubuntu 取得如此震惊成功的原因，可能还是离不开这个项目的发起人 Mark Shuttleworth。

 一个极有魅力的南非富翁、一个前 Debian 开发员和世界第二个太空游客 – 他注册在马恩岛的 Canonical 公司目前正在资助这个项目；
其次， Ubuntu 从其它类似发行版的错误中汲取教训并且从一开始就避免重蹈覆辙 – 它用 wiki 风格的文档、有创意的错误报告机制和面向终端用户的专业方法创建了一个完美的基于网络的基础结构；
最后，感谢它富有的创始人使得 Ubuntu 有能力向全世界的爱好者免费发送 CD ，这对版本的快速传播很有帮助【我曾经获得过2块系统CD】。

在技术方面， Ubuntu 基于 Debian 的“Sid” （不稳定分支），但是随着一些杰出的软件包比如 GNOME 、 Firefox 和 OpenOffice.org 升级到它们的最新版本， Ubuntu 有固定6个月的发布周期，偶尔还会出现提供3~5年安全升级的长期支持版（LTS)，这取决于版本号（非 LTS 版本提供18个月的支持）。 Ubuntu 的其它特点包括一张可安装的 live CD 、有创意的艺术作品和桌面主题、针对 windows 用户的移民手册、对最新技术的支持比如3D桌面特效、 ATI 和 NVIDIA 显卡以及无线网络的私有设备的驱动的简易安装还有非免费或专利担保的媒体解码器的有求必应的支持。

支持论点：固定的发布周期和支持时间；新手友好；包括官方提供和用户贡献的丰富的文档
反对论点： Ubuntu 自带的某些软件（比如：Rosetta）是私有的；与 Debian 兼容性不佳
软件包管理工具：使用DEB包的高级包工具（APT）
可用版本：Ubuntu, Kubuntu, Xubuntu, Ubuntu Studio, 32位(i386)和64位(x86_64)的Mythbuntu; 用于 SPARC 处理器的 Ubuntu服务器版本
基于Ubuntu的推荐替代版：Linux Mint (桌面版), gOS (带 Google 应用的桌面版), OpenGEU (带 Enlightenemnt 的桌面版), Ultimate Edition (桌面版), CrunchBang Linux (带 Openbox 的桌面版), gNewSense (自由软件)

openSUSE openSUSE 的起源可以追溯到1992年，当时4个德国 Linux 爱好者 – Roland Dyroff ， Thomas Fehr ， Hubert Mantel 和 Burchard Steinbild – 以 SuSE (软件和系统开发) Linux 的名字发起了这个项目。在最初的几年里，这个年轻的公司主要出售德文版 Slackware Linux 的套装软盘，但是不久后在 SuSE Linux 于1996年5月随着4.2版本的发布而成为一个独立的发行版之后就停止了。接下来的年份里，开发者采用了 RPM 软件包管理形式而且也推荐了一个简单易用的图形化的系统管理员工具 – Yast 。频繁的发行，卓越的打印文档，还有遍及欧洲和北美的随店可买导致此版本普及率的不断增长。
 SuSE Linux 在2003年末被 Novell 公司购买，随之很快就在开发、许可证和使用方面产生重大变化 – YaST 在 GPL 许可证下发行， ISO 镜像可以在公共下载服务器上自由下载，还有，最意义重大的，发行版的开发首次向公众开放。从 openSuSE 项目的设立和2005年10月10.0版本的发布以来，这个版本在两种感官世界变的完全自由。 openSuSE 的代码构成了 Novell 的商业产品的底层系统，一开始叫作 Novell Linux ，后来改名为 SUSE Linux 企业桌面版和 SUSE Linux 企业服务器版。
 今天， openSUSE 有着庞大的满意用户群。它在用户中取得如此高分的最主要原因包括友好而绚丽的桌面环境( KDE 和 GNOME )，出色的系统管理工具 (YaST)，以及，对那些购买盒装版本的用户来说，对任何版本都可用的最棒的打印文档。然而， Novell 与微软最近签订的协议明显的承认了微软的有关对 Linux 拥有知识产权的条款，这导致了广大 Linux 人士一系列的谴责并且促使部分用户转向其它发行版。尽管 Novell 低调处理这份协议而且微软也尚未行使任何权利，这件事成为其它非常“社区友好”型 Linux 公司的眼中钉。

支持论点：直观全面的配置工具；库存庞大的软件包；出色的网站基础结构和打印文档
反对论点：Novell 与微软在2006年11月涉及的专利协议似乎将微软对 Linux 的知识产权索赔合法化；极耗资源的桌面系统和图形化的工具有时被认为“瘫肿又迟钝”
软件包管理工具：图形化的 YaST 和用 RPM 包的命令行模式工具
可用版本：可用于32位(i386),64位(x86_64) 和 PowerPC(同样有可安装的 live CD) 处理器的openSUSE; 可用于 i586, IA64, PowerPC, s390, s390x 和 x86_64 结构的SUSE Linux 企业 桌面/服务器 版

Fedora 尽管 Fedora 在2004年9月才正式发布，但它的起源可以追溯到1995年被两个 Linux 空想者 – Bob Young 和 Marc Ewing – 以 Red Hat 之名发起的 Linux 。公司的第一个产品， Red Hat Linux 1.0 “母亲节”，在同年发布并且很快跟着推出一些错误修复的升级。1997年， Red Hat 推出了它的革命性的带有依赖协议的 RPM 软件包管理系统和其它高级功能极大的促进了该发行版在大众中的迅速崛起，并且超过了 Slackware Linux 成为世界上最被广泛使用的 Linux 发行版。接下来的几年里， Red Hat 制定了一个有规律的、6月周期的发行标准。
 2003年，在 Red Hat Linux 9 的发布之后，公司对其产品线进行了激进的改革。公司对其商业产品– 著名的 Red Hat 企业版– 保留了 Red Hat 商标，并且推出了 Fedora Core – 一个 Red Hat 发起但是面向社区的为“ Linux 爱好者”而设计的版本。在对这一改变刚开始的批评之后， Linux 社区便开始接受了这一“新”的版本作为 Red Hat 逻辑上的续版，一些有质量的发行版是为了 Fedora 夺回之前作为市场上最受喜爱的发行版的地位。在同一时间， Red Hat 很快成为了世界上最大最赚钱的 Linux 公司，以它新颖的产品线和其它有趣的提议，比如它的 Red Hat 认证工程师（ RHCE ）认证。
 尽管 Fedora 的方向在很大程度上被 Red Hat 公司所把持，而且其产品有时似乎– 无论对错– 是作为 Red Hat 企业版的试验田，但是无可否认的是 Fedora 是当前可用的最有新意的发行版之一。它对 Linux 内核、 glibc 和 GCC 的贡献广为人知，而且它对 SELinux 功能、 Xen 虚拟技术和其它企业级的功能的综合在企业用户中非常受欢迎。在令一方面， Fedora 仍然缺乏一个清晰的面向桌面的策略来使产品成为对除了“ Linux 爱好者”的用户目标来说更易用的产品。

支持论点：高度的前卫；杰出的安全功能；库存丰富的支持软件；对自由软件理念的严格遵守
反对论点：Fedora 优先倾向于企业功能而不是桌面用户
软件包管理工具：图形化的 YUM 和用 RPM 的命令行模式工具
可用版本：可用于32位(i386),64位(x86_64) 和 PowerPC 处理器的 Fedora;可用于 i386, IA64, PowerPC, s390x 和 x86_64 结构的 Red Hat Linux 企业版; 包括 GNOME 和 KDE 的 live CD 版
基于 Fedora 的推荐替代版：BLAG Linux And GNU (桌面版,自由软件), Berry Linux (live CD), Yellow Dog Linux (基于苹果的 PowerPC 的系统)
基于 Red Hat 的推荐替代版：CentOS, Scientific Linux, StartCom Enterprise Linux

Debian GNU/Linux Debian GNU/Linux 于1993年首次发布。它的发起人， Ian Murdock ，设想通过数百个志愿者开发人员在空余时间创造一个完全的非商业项目。那时的反对者过于乐观的认为，这个项目注定会分裂然后失败；但是事实恰恰相反， Debian 不仅活了下来发展的欣欣向荣而且在不到10年的时间里，它变成了最大的 Linux 发行版甚至可能会成为有史以来最大的软件合作项目。
 Debian GNU/Linux 的成功可以归结为如下几条。它的开发者超过1000名志愿者，它的软件包有超过20000种软件（对11种处理器构架做了编译），并且令人振奋的是它为超过120种基于 Debian 的发行版和 live CD 提供支持，这些数字是其它任何基于 Linux 的发行版所无法比拟的。 Debian 实际的发展根据递增的稳定性有3个分支（或者4个如果再包括一个尖端“体验”分支的话）：“不稳定版”（或者叫“sid”），“测试版”和“稳定版”，这种先进的集成和软件包的稳定性及其功能，再加上这个项目完善的质量控制机制，为 Debian 赢得了当前最佳体验和最少错误的发行版之一的名誉。
 然而，这种冗长而复杂的发展风格也有其不利的一面：稳定版的发布不是特别及时并且会迅速落伍，特别是自从新稳定版每1~3年才发布一次之后。那些喜欢最新软件和技术的用户不得不使用潜在很多错误的测试版或者不稳定版。 Debian 高度民主的组织结构也导致了备受争议的决策并且引起内部人员的对抗，这种状况使其停滞不前并且很难通过激进但可以推动项目发展的决议。

支持论点：非常稳定；引入注目的质量控制体系；包含超过20000种软件的管理包；比其它 Linux 发行版支持更多的处理器构架
反对论点：保守– 因为其对许多处理器构架提供支持使得最新的技术不总是被采用；缓慢的发布周期（每1~3年一个稳定版）；开发者在邮件列表上的争吵以及博客有时会很粗糙
软件包管理工具：使用 DEB 包的先进包管理工具(APT)
可用版本：可用于11种包括 Intel, AMD 和其它的所有32位和64位处理器在内的处理器结构的 CD/DVD 和 live CD 安装镜像文件，
基于 Debian 的推荐发行版：MEPIS Linux, Ubuntu, sidux. Damn Small Linux (用于老式电脑), KNOPPIX (live CD), Dreamlinux (桌面版), Elive (带 Enlightenment 的桌面版), Xandros (商业版), 64 Studio (多媒体版)

Mandriva Linux Mandriva Linux 由 Gaël Duval 在1998年7月以 Mandrake Linux 之名首次发布。开始，它只是一个 Red Hat Linux 加上更为用户友好型的 KDE 桌面的改进版，但随后的发行版又增加了各种用户友好型的应用，比如新的安装软件，高级硬件检测和直观的硬盘分区工具。由于这些改进措施， Mandrake Linux 发展壮大了起来。在吸引到风险投资并且转型为商业项目之后，新成立的 MandrakeSoft 的命运在从2003年初的几近破产到2005年的几项收购中起伏很大。后来，与巴西的 Conectiva 合并之后，公司将名字改为 Mandriva 。
 Mandriva Linux 首先是个桌面发行版，它最受喜爱的特点是尖端的软件，高质量的系统管理套件（Drakconf），64位版本中杰出的执行能力，还有广阔的国际化支持。 Mandriva 在其它许多流行的发行版之前很久就通过广泛的 beta 测试版和频繁的稳定版有了开放的开发模式。最近的几年里， Mandriva 也开发了一系列可安装的 live CD 并且推出了 Mandriva Flash – 存在于可引导的 USB 设备中的一个完整的 Mandriva Linux 系统。同时它也是第一个为上网本比如 ASUS Eee PC 提供开箱即用支持的主流发行版.
 除去出色的技术， Mandriva Linux 在近几年像做过山车一样。这在一定程度上导致了其它超过 Mandriva 的用户友好型的发行版的出现，但是同样也与把公司的一个有关发行版的用户群的部门分离出去的一些有争议的决议相关。 Mandriva 的网络展示只不过是一些不同的网址杂乱的集合，而它的“ Mandriva 俱乐部”，最初为付费用户提供增值服务，变得越来越褒贬不一。尽管公司一直在对一些批评进行改进，它仍然面对着说服新的 Linux 用户或者其他 Linux 用户尝试（或购买）它们的产品的越来越艰难的问题。

支持论点：新手友好，尤其是商业版本；杰出的中央配置套件；对几十种语言都非常棒的开箱即用支持；可安装的 live CD
反对论点：缺乏对其它主流发行版的综合性市场策略，不存在的 Mandriva 手册显示出在出版社中缺乏“精神占有率”
软件包管理工具：使用 RPM 包的带 Rpmdrake (一个图形化的 URPMI 前端) 的 URPMI；“SMART”也是一个可用的方法
可用发行版：可用于32位(i586)和64位(x86_64)处理器可自由下载的 Mandriva “自由”安装介质; 可用于32位(i586)处理器的可自由下载的 Mandriva 一次性现场安装介质; 可用于32位(i586)和64位(x86_64)处理器的商业 Mandriva PowerPack 版; 带有长期支持选项可用于桌面和服务器的高端“团体”方案
基于 Mandriva 的推荐发行版：PCLinuxOS (桌面版)

Linux Mint Linux Mint，一个基于 Ubuntu 的发行版，于2006年被 Clement Lefebvre – 一个法国出生爱尔兰工作和生活的 IT 专家首次发布。开始时维护着一个网站致力于提供帮助、建议和给 Linux 用户使用的文档，作者看到了开发一个解决掉通用的主流产品的诸多使用缺陷的 Linux 发行版的潜在价值。在向他网站上的用户求得反馈意见之后，他着手建立当今人们更愿意称作的“ Ubuntu 改进版”。
 但 Linux Mint 不仅仅是一个增加了一系列应用程序和改进的桌面主题的 Ubuntu 。自从它诞生以来，开发者一直在添加各种图形化的“ Mint ”工具来增强使用性。这包括 mint桌面 – 一个设置桌面环境的套件；mint菜单 – 为了更方便的导航而做的新的优美的菜单； mint安装 – 一个易用的软件安装工具，还有 mint更新 – 一个软件更新工具，仅从一些其它工具和数百个附加改进中挑出若干杰出者。这个项目同样设计了它自己的艺术作品，而它易用性的名声通过添加其它大的发行版因为担心潜在的法律制裁而空缺的私有的和专利保护的多媒体解码器而大振。然而， Linux Mint 最大的优点之一的开发者听从于用户并且总是很快采纳好的建议。
 在 Linux Mint 可以免费下载的同时，项目组从捐助、广告和专业服务支持中获得收益。Linux Mint 没有固定的发布周期或者一张计划好的功能单，但是在每个 Ubuntu 的稳定发行版发布出来之后的几个星期之后就可以期待着新的 Linux Mint 。除了提供 GNOME 桌面的“主”版本之外，项目组也出品了使用其它桌面环境比如 KDE , Xfce 和 Fluxbox 的半正规的“社区”版。然而，这些通常要在使用 GNOME 的“主”版本发布几个月之后才推出而且很多时候缺少“ minty ”工具和其它旗舰版产品拥有的功能。 Linux Mint 不依附自由软件的条款而且不发布安全劝告。

支持论点：内部开发的优秀的“ minty ”工具，数以百计的用户友好性改进，包含多媒体解码器，开放的用户建议
反对论点：替代的“社区”版常常不含最新功能，项目组不发布安全公告
软件包管理工具：带使用 DEB 包的 mintInstall 的APT（与 Ubuntu 的软件库兼容）
可用版本：可用于32位和64位计算机的“主”版本(GNOME)，可用于32位计算机的丰富的“社区”版本
可能的替代版：Ubuntu, SimplyMEPIS

PCLinux OS PCLinuxOS 于2003年由被称为“ Texstar ” 的 Bill Reynolds 首次发布，。在创造自己的发行版之前， Texstar 就因给流行版本建立及时更新的 RPM 软件包并且提供免费下载而在 Mandrake 的用户社区中成为广为人知的开发员。在2003年他决定创建一个新的发行版，最初基于 Mnadrake Linux ，但随着一些意义重大的可用性改进，目标？应该是新手友好型，为私有的内核模块、浏览器补丁和媒体解码器提供开箱即用支持，并且应该有个简单直观的图形化安装界面就像 live CD 一样。
 多年的发展之后， PCLinuxOS 迅速的接近它预期状态。在可用性方面，项目组提供了 windows 到 Linux 的移民用户希望从他们新操作系统得到的开箱即用的支持。在软件方面， PCLinuxOS 是一个面向 KDE 的发行版，有一个可定制的而且总是及时更新的流行桌面环境。它不断增长的软件库也包含其它桌面，甚至，也为其它许多通用任务提供大量的桌面软件。关于系统配置， PCLinuxOS 保留了 Mandrake 的优秀控制中心的许多东西，但用 APT 和 Synaptic （一个图形化的软件包管理工具前端）替换了它的软件包管理系统。
 另一方面， PCLinuxOS 没有任何形式的路线图或发展目标。除去项目中不断增长的社区参与，大部分的开发和决定仍归 Texstar 所有，在权衡发行版的稳定性时他总趋于保守。结果， PCLinuxOS 的开发进程很漫长甚至直到所有已知的错误都解决了之后才发布一个新版本。 PCLinuxOS 至今没有发布64位版本的计划。

支持论点：图形化驱动安装、浏览器补丁和媒体解码器的开箱即用支持；快速启动；软件的及时更新
反对论点：无64位版本；对非英语语言无开箱即用支持；缺乏发展目标
软件包管理工具：使用 RPM 包的高级包管理工具(APT)
可用版本：MiniMe, Junior 和可用于32位(i586)处理器结构的 BigDaddy 发行版
基于 PCLinuxOS 的推荐替代版：Mandriva Linux, SAM Linux 桌面版, Granular Linux

Slackware Linux Slackware Linux，由 Patrick Volkerding 于1992年首次发布，是现今存在的最古老的 Linux 发行版。在最顶级的 Linux 内核版本 0.99pl11-alpha 之上建立并被载以24张软盘的 Slackware 由现以破产的 SLS 项目分离出来。它迅速发展为最流行的 Linux 版本，一些评估认为它的的市场占有率高达1995年安装的 Linux 的80%。它的普及率随着 Red Hat 和其它更用户友好型的发行版的出现而戏剧性的下降，但 Slackware 仍然是个在更面向技术的系统管理员和桌面用户中备受赞赏的操作系统。
 Slackware 是个高端干净的发行版，只有极少数量的自定义工具。它使用一个简单的文本模式的系统安装软件和一个相对原始的无法解决软件依赖问题的软件包管理系统。结果， Slackware 被认为是当今最干净且错误最少的发行版之一 – 没有为 Slackware 进行特定的改进减少了将新的错误带入系统的可能性。所有的配置通过编写文件来实现。在 Linux 社区中有一个说法是如果你学 Red Hat ，你将只会 Red Hat ；但如果你学 Slackware ，你将会 Linux 。在当今许多 Linux 发行版坚持为缺乏技术的用户开发高定制性的产品时这句话尤为正确。
 尽管这个简单的哲学有其拥护者，但事实是今天的世界， Slackware 越来越变得像一个为其它新的有定制方案的系统做基础的“核系统”，而不是一个完整的有广泛的支持软件的发行版。唯一的例外是在服务器市场，那里 Slackware 仍然很流行，但尽管是这样，这个版本复杂的升级步骤以及缺乏官方支持的自动安全升级工具让它越来越没有竞争力。 Slackware 对系统基础组件的保守态度意味着在它成为一个现代的桌面系统前还需大量手工的安装后工作。

支持论点：高稳定性、清洁和无错误；对 UNIX 条例的坚定信奉
反对论点：极为有限的官方支持应用软件；在基础软件包选择上的保守；复杂的升级步骤
软件包管理工具：用 TXZ 包的 “pkgtools”
可用版本：可用于32位(i486)和64位(x86_64)处理器安装 CD 和 DVD
基于 Slackware 的推荐替代版：Zenwalk Linux (桌面版), VectorLinux (桌面版), SLAX (live CD), Slamd64 Linux (64位), Bluewhite64 Linux (64位), Wolvix (桌面版, live CD), GoblinX (桌面版, live CD)
持相同理念的其它发行版：Arch Linux, Frugalware Linux

Gentoo Linux Gentoo Linux 的理念是被一个前 Stampede Linux 和 FreeBSD 开发员 Daniel Robbins 于2000年前后提出的。这是作者对 FreeBSD 和它的被叫做“ ports ”的“自建”功能的展露，这东西激励着他把一些 FreeBSD 的软件管理原则以“ portage ”之名带入 Gentoo 。这个主意是开发一个 Linux 发行版允许用户直接在他们自己的电脑上从源代码编译 Linux 内核和应用软件，这将保证一个高度优化和及时更新的系统。在这个项目于2002年三月发布了它的1.0版本的时候， Gentoo 的包管理工具被认为会是一些二进制包管理系统的高级替代品，尤其是后来被广泛使用的 RPM 。
 Gentoo Linux 是为超级用户设计。一开始，其安装是笨重和单调的，需要在命令行模式进行数小时甚至数天的编译来建造一个完整的 Linux 发行版；然而，2006年项目组通过一个可安装的 live CD 和鼠标安装工具简化了安装步骤。除了为单命令模式安装提供一个总是及时更新的软件包，发行版的其它重要功能有杰出的安全性、广泛的配置选项、对许多构架的支持和不用重新安装就可保持系统及时更新。 Gentoo 的文档也被作为所有发行版中最棒的在线文档而多次标记。
 Gentoo Linux 在最近几年里失去了许多原有的赞誉。一些用户已经证实了这种费时的软件包编译只能带来微小的速度和优化效益。自从 Gentoo 的创立者和仁慈的独裁者的辞职以来，新成立的 Gentoo 基金一直困顿于缺乏清晰的指引和频繁的开发者之间的冲突，这导致了数位著名的 Gentoo 人员的高调离职。目前仍有待观察是否 Gentoo 可以重夺其原来创新性的品质抑或慢慢得分裂为缺乏清晰目标的若干私人性的子项目的集合。

支持论点：杰出的软件管理体系，无以伦比的定制性和调整方案，优秀的在线文档
反对论点：偶尔的不稳定或崩溃的危险，项目挣扎于缺乏指导和开发人员之间的内部斗争之中
软件包管理工具：使用源代码包(SRC)的“ portage ”
可用版本：可用于Alpha, AMD64, HPPA, IA64, MIPS, PPC, SPARC 和 x86 处理器的最小化安装 CD 和 live CD (GNOME); 提供用于命令行模式手工安装的 “stages”
基于 Gentoo 的推荐替代版：SabayonLinux (桌面版, live CD/DVD), Ututo (桌面版, 仅自由软件)
其它基于源码的发行版：Lunar Linux, Source Mage GNU/Linux, Sorcerer, Linux From Scratch

FreeBSD FreeBSD ，一个 AT&amp;T UNIX 通过伯克利软件分发（ BSD ）的间接继承版，有一个漫长而动荡的可以追溯到1993年的历史。与包含 Linux 内核与数千种应用软件被定义为完整软件方案的 Linux 发行版不同， FreeBSD 是一个建立在 BSD 内核和所谓的“ userland ”（因此在没有额外软件时也可用）的基础上的紧凑整合起来的操作系统。可一旦安装在普通的计算机系统上这种差别基本上就消失了 – 像许多 Linux 发行版，一大批易于安装的、（绝大多数）开源的应用软件可用来拓展 FreeBSD 内核，但这些通常由第三方开发者提供而且不是严格意义上的 FreeBSD 的一部分。
 FreeBSD 赢得了一个迅速、高性能和极为稳定的操作系统的赞誉，特别适合于网络服务器和类似任务。许多大型搜索引擎和配有关键任务的计算基础设备的组织已经在他们的计算机系统上部署和使用 FreeBSD 好几年了。与 Linux 相比， FreeBSD 是在一个限制性更少的许可证下建立的，这个许可证允许几乎毫无限制的对源代码进行任何目的的使用和修改。甚至苹果的 Mac OS X 都被得知是由 BSD 衍生出来的。除了操作系统内核，项目组也提供了超过15000种软件应用的二进制格式和源代码来在 FreeBSD 核上进行简易安装。
 尽管 FreeBSD 毫无疑问的可用用作桌面操作系统，但它在这部分与流行的 Linux 发行版相比并不出色。不算安装后对用户来说大量繁重的工作，命令行模式的系统安装软件就提供了太少的硬件识别和系统配置项目。在支持现代硬件方面， FreeBSD 通常落后于 Linux ，特别是对流行台式机或笔记本的小配件的支持，比如无线网卡或者数码相机。那些在桌面环境或工作站寻求开拓 FreeBSD 的速度和稳定性的使用者应该考虑一个可用的桌面 FreeBSD 项目，而不是 FreeBSD 本身。

支持论点：迅速、稳定；超过15000种软件应用（或者叫作“ ports ”）可用来安装；出色的文档

反对论点：在对外来硬件的支持方面落后于 Linux ，可用的商业软件很少；缺乏图形化的配置工具

软件包管理工具：完全命令行模式的包管理工具 – 使用二进制包或者基于源代码的“ ports ”（ TBZ ）的底层结构

可用版本：可用于 Alpha, AMD64, i386, IA64, PC98 and SPARC64 处理器的安装 CD

基于 FreeBSD 的推荐替代版：PC-BSD (桌面版), DesktopBSD (桌面版), FreeSBIE (live CD)

其它可选 BSD ：OpenBSD, NetBSD, DragonFly BSD, MidnightBSD


CentOS
最后一个也是我最常用的一个。

 发布于2003年的 CentOS 是一个社区项目，目标是将 Red Hat Enterprise Linux （RHEL）的源代码重建为可安装的 Linux 发行版并且为所有包含在软件包中的软件提供及时的安全更新。直言不讳的说， CentOS 只不过是 RHEL 的一个克隆版。两者间唯一技术上的差别是商标 – CentOS 把所有 Red Hat 的标志标记都换成了自己的。但是 CentOS 的网站上并没有明显标示 CentOS 和 Red Hat 之间的链接，因为商标法的缘故。 Red Hat 被叫做“北美杰出的企业 Linux 商”来代替它本来的名字。不过， Red Hat 和 CentOS 的关系很和睦而且许多 CentOS 的开发员与 Red Hat 的工程师联系密切。
 CentOS 常被看做是可靠的服务器版本。它有着和 Red Hat 企业版 Linux 同样的一套经过完善测试而且稳定的 Linux 内核以及来自其出处的基本组件的软件包。尽管是由志愿者维护的社区项目， CentOS 还是获得了良好的赞誉作为市场上许多付费服务器产品一个可靠而又免费的替代品，特别是在有经验的 Linux 系统管理员之中。 CentOS 也是合适的企业桌面方案，尤其在更需要稳定、可靠和长期支持而不是最新软件和功能的地方。和 RHEL 一样， CentOS 也提供最少5年的安全更新支持。
 尽管有诸多优势， CentOS 并不是所有部署方案的最佳选择。那些更喜欢带最新 Linux 技术和软件包的发行版的用户就应该到别处去寻找。 CentOS 跟随 RHEL 版本发行的主版本，每2 – 3年才发布一次，而“子”版本（比如5.1）则尽量保证6 – 9个月的发行间隔。子发行版不总是包含所有的主流功能（尽管有时会为更多的新硬件提供支持）而且只有少数的软件包会更新到新的版本； Linux 内核、底层系统和大多数的应用软件版本保持不变，但偶尔在试验基础上会有一些重要软件（比如 OpenOffice 或者 Firefox）的新版本提供。作为一个辅助项目，CentOS 也为其用户建立更新包，但是软件库默认不包含这些因为它们会破坏向上的兼容性。

支持论点：极度的完善测试、稳定和可靠；免费下载和使用；5年的免费安全更新；快速的发布和安全更新
反对论点：缺乏最新的 Linux 技术；在发布的时候，大部分的软件已经落伍了
软件包管理工具：图形化的 YUM 和使用 RPM 包的命令行工具
可用版本：可用于i386和x86_64处理器的安装 DVD 和 CD (GNOME); 可用于 Alpha, IA64 and IBM z-series (s390, s390x)处理器的老式版本 (3.x and 4.x)
其它 RHEL 克隆版和基于 CentOS 的发行版：Scientific Linux, SME Server, StartCom 企业 Linux, Fermi Linux, Rocks Cluster 发行版, Oracle 企业 Linux

目前主流和常用的Linux版本主要有：RedhatRedhat应该说是在国内使用人群最多的Linux版本，甚至有人将Redhat等同于Linux，而有些老鸟更是只用这一个版本的Linux。所以这个版本的特点就是使用人群数量大，资料非常多，言下之意就是如果你有什么不明白的地方，很容易找到人来问，而且网上的一般Linux教程都是以Redhat为例来讲解的。Redhat系列的包管理方式采用的是基于RPM包的YUM包管理方式，包分发方式是编译好的二进制文件。稳定性方面RHEL和CentOS的稳定性非常好，适合于服务器使用，但是Fedora Core的稳定性较差，最好只用于桌面应用。。
DebianDebian系列，包括Debian和Ubuntu等。Debian是社区类Linux的典范，是迄今为止最遵循GNU规范的Linux系统。Debian最早由Ian Murdock于1993年创建，分为三个版本分支（branch）： stable, testing 和 unstable。其中，unstable为最新的测试版本，其中包括最新的软件包，但是也有相对较多的bug，适合桌面用户。testing的版本都经过unstable中的测试，相对较为稳定，也支持了不少新技术（比如SMP等）。而stable一般只用于服务器，上面的软件包大部分都比较过时，但是稳定和安全性都非常的高。Debian最具特色的是apt-get / dpkg包管理方式，其实Redhat的YUM也是在模仿Debian的APT方式，但在二进制文件发行方式中，APT应该是最好的了。Debian的资料也很丰富，有很多支持的社区，有问题求教也有地方可去🙂。
SuSe最华丽的Linux发行版，很多人都这样说，X windows和程序应用方面做的确实不错。尤其与Microsoft的合作关系，应该是在所有的Linux发行版本中最亲密的。Ubuntu
Ubuntu严格来说不能算一个独立的发行版本，Ubuntu是基于Debian的unstable版本加强而来，可以这么说，Ubuntu就是一个拥有Debian所有的优点，以及自己所加强的优点的近乎完美的 Linux桌面系统。根据选择的桌面系统不同，有三个版本可供选择，基于Gnome的Ubuntu，基于KDE的Kubuntu以及基于Xfc的Xubuntu。特点是界面非常友好，容易上手，对硬件的支持非常全面，是最适合做桌面系统的Linux发行版本。。
Centos版本5.4和6.0最新；这个发行版主要是Redhat企业版的社区版，基本上跟redhat是兼容的，相对来说局限性教少。很多人都喜欢使用。
至少gentoo、mandriva、Slackware、redflag等可以暂时不考虑。虽然各自均有特点，但市场占有率和应用相对较少。
Gentoo伟大的Gentoo是Linux世界最年轻的发行版本，正因为年轻，所以能吸取在她之前的所有发行版本的优点，这也是Gentoo被称为最完美的Linux发行版本的原因之一。Gentoo最初由Daniel Robbins（FreeBSD的开发者之一）创建，首个稳定版本发布于2002年。由于开发者对FreeBSD的熟识，所以Gentoo拥有媲美FreeBSD的广受美誉的ports系统 ——Portage包管理系统。不同于APT和YUM等二进制文件分发的包管理系统，Portage是基于源代码分发的，必须编译后才能运行，对于大型软件而言比较慢，不过正因为所有软件都是在本地机器编译的，在经过各种定制的编译参数优化后，能将机器的硬件性能发挥到极致。Gentoo是所有Linux发行版本里安装最复杂的，但是又是安装完成后最便于管理的版本，也是在相同硬件环境下运行最快的版本。
FreeBSD并不是一个Linux系统！但FreeBSD与Linux的用户群有相当一部分是重合的，二者支持的硬件环境也比较一致，所采用的软件也比较类似，所以可以将FreeBSD视为一个Linux版本来比较。FreeBSD拥有两个分支：stable和current。顾名思义，stable是稳定版，而 current则是添加了新技术的测试版。FreeBSD采用Ports包管理系统，与Gentoo类似，基于源代码分发，必须在本地机器编后后才能运行，但是Ports系统没有Portage系统使用简便，使用起来稍微复杂一些。FreeBSD的最大特点就是稳定和高效，是作为服务器操作系统的最佳选择，但对硬件的支持没有Linux完备，所以并不适合作为桌面系统。
做开发如何选择如果作为php、jsp等开发平台使用，最好选择Redhat或Centos，原因主要是硬件和软件兼容性方面应该是所有Linux发行版本中较好的。最主要的原因是国内的多数游戏运营商和大型网站，使用这两个版本的较多。如果是作为asp.net等开发平台使用，最好使用suse，原因是与Microsoft的合作关系。同时也说明下，移动运营商好像很多使用suse的操作系统平台。如果是作为c或c++等开发平台使用，而且对应用程序开发要求较高，建议使用debian版本的Linux，毕竟这个版本的Linux限制性是最小的。自由度较大如果你需要一个桌面系统，而且还想非常灵活的定制自己的Linux系统，想让自己的机器跑得更欢，不介意在Linux系统安装方面浪费一点时间，那么你的唯一选择就是Gentoo，尽情享受Gentoo带来的自由快感吧！如果你需要的是一个服务器系统，而且你已经非常厌烦各种Linux的配置，只是想要一个比较稳定的服务器系统而已，那么你最好的选择就是CentOS了，安装完成后，经过简单的配置就能提供非常稳定的服务了。
如果你需要的是一个坚如磐石的非常稳定的服务器系统，那么你的唯一选择就是FreeBSD。
如果你需要一个稳定的服务器系统，而且想深入摸索一下Linux的各个方面的知识，想自己定制许多内容，那么我推荐你使用Gentoo。
服务器选择：Redhat、CentOS、Debian桌面环境：Ubuntu、Fedora、
Linux发行版各种Linux发行版一般可以分为3种类型：
核心Linux发行版核心Linux发行版包括内核、一个或多个图形桌面环境，以及几乎所有的Linux应用程序，它针对内核进行了预编译。只需要该发行版即可安装完整的Linux。
特定发行版该版本通常以一个主要的发行版为基础，但是只包含对特定领域有用的应用程序子集。除了提供专门的软件，定制的Linux发行版还试图为Linux初级用户提供帮助–自动检测和自动配置常用的硬件设备，这使得安装Linux的过程变得更加轻松。
许多特定Linux发行版以Debian Linux发行版为基础，它们使用的安装文件与Debian相同，但是软件包只是完整Debian系统的一小部分。
LiveCD测试发行版LiveCD是最近才出现的东东，无需安装即可了解Linux系统的全貌。除了标准的硬盘启动之外，现在的大部分PC都可以从CD启动，利用这一点，很多Linux发行版创建了可引导的CD，其中包含一个示例Linux系统即为LiveCD。
这是测试各种Linux发行版的很好方法，它丝毫不会弄乱你的PC。只需要放入CD然后启动就可以体验该系统，当然有个缺点，因为是在CD上，所以你做的任何更改在重启后都会丢失。另外由于在CD运行，速度可能会运行的较慢，但是现在也加入了一些新的技术来改进，比如：

将Linux系统文件从CD复制到内存；
将系统文件复制到硬盘中；
在USB记忆棒中存储系统设置；
在USB记忆棒中存储用户设置；

]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>CentOS</tag>
        <tag>Debian</tag>
        <tag>Fedora</tag>
        <tag>FreeBSD</tag>
        <tag>Gentoo</tag>
        <tag>Mint</tag>
        <tag>Mandriva</tag>
        <tag>openSUSE</tag>
        <tag>PCLinuxOS</tag>
        <tag>Slackware</tag>
        <tag>Ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux查看内存信息（型号、大小、速率等）</title>
    <url>/2018/02/12/linux-dmidecode/</url>
    <content><![CDATA[Linux查看内存信息（型号、大小、速率等）安装工具dmidecode
1.查看内存槽及内存条
$ sudo dmidecode -t memory

2.查看内存的插槽数,已经使用多少插槽.每条内存多大
$ sudo dmidecode -t memory | grep Size


3.查看服务器型号、序列号
$ sudo dmidecode | grep "System Information" -A9 | egrep "Manufacturer|Product|Serial"]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>dmidecode</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux dos2unix命令</title>
    <url>/2014/03/06/linux-dos2unit/</url>
    <content><![CDATA[linux dos2unix命令有时碰到unix换行符转换为windows换行符的问题，特别是脚本，会报错syntax error near unexpected token `$’in\r’’，需要使用dos2unix命令将文件转换为unix格式。
dos2unix命令用来将DOS格式的文本文件转换成UNIX格式的（DOS/MAC to UNIX text file format converter）。DOS下的文本文件是以\r\n作为断行标志的，表示成十六进制就是0D 0A。而Unix下的文本文件是以\n作为断行标志的，表示成十六进制就是0A。DOS格式的文本文件在Linux底下，用较低版本的vi打开时行尾会显示^M，而且很多命令都无法很好的处理这种格式的文件，如果是个shell脚本，。而Unix格式的文本文件在Windows下用Notepad打开时会拼在一起显示。因此产生了两种格式文件相互转换的需求，对应的将UNIX格式文本文件转成成DOS格式的是unix2dos命令。
dos2unix [-hkqV] [-c convmode] [-o file ...] [-n infile outfile ...]

选项
1. -k：保持输出文件的日期不变 2. -q：安静模式，不提示任何警告信息3. -V：查看版本4. -c：转换模式，模式有：ASCII, 7bit, ISO, Mac, 默认是：ASCII5. -o：写入到源文件6. -n：写入到新文件


 最简单的用法就是dos2unix直接跟上文件名：
dos2unix filename


如果一次转换多个文件，把这些文件名直接跟在dos2unix之后。（注：也可以加上-o参数，也可以不加，效果一样）
dos2unix filename1 filename2 filename3 dos2unix -o filename1 filename2 filename3 

上面在转换时，都会直接在原来的文件上修改，如果想把转换的结果保存在别的文件，而源文件不变，则可以使用-n参数。
dos2unix oldfilename newfilename 

如果要保持文件时间戳不变，加上-k参数。所以上面几条命令都是可以加上-k参数来保持文件时间戳的。
dos2unix -k filenamedos2unix -k filename1 filename2 filename3dos2unix -k -o filename1 filename2 filename3dos2unix -k -n oldfilename newfilename]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>base64</tag>
      </tags>
  </entry>
  <entry>
    <title>磁盘使用几何的 du</title>
    <url>/2014/06/22/linux-du-beginner/</url>
    <content><![CDATA[磁盘使用几何的 du.. _linux_du_beginner:
使用man来查看du，我们知道这个命令的含义为estimate file space usage。 
也就是查看文件系统的磁盘空间占用情况，可以利用该命令来获取硬盘被占用了多少空间，目前还剩下多少空间等信息。
选项命令的使用方法为：
$ du [options]... [FILE]...



其中一些比较有用的命令选项为：

-0, --null ： 这个只是对输出有效果，把所有的输出放在一行

-a, --all：这个选项会统计所有的信息，而不只是文件夹

-B, --block-size=SIZE：类似于df命令

-c, --total：最后一行，显示一个统计信息

-d, --max-depth=N：指定统计目录的层级，只有在层级大于N时有效

-h, --human-readable：同df命令，自动优化显示

-l, --count-links：如果是硬链接，则计入大小

-s, --summarize：显示统计信息


最常用组合$ du -sh4.0G	.


显示当前文件夹的总大小

默认输出$ du 2048000	./original4096000	.



不换行输出$ du -02048000	./original4096000	.



统计所有信息$ du -a204800	./xaa204800	./xab204800	./xac204800	./xad204800	./xae204800	./xaf204800	./xag204800	./xah204800	./xai204800	./xaj2048000	./original/dat12048000	./original0	./tsta4096000	.



指定显示容量单位$ du -BG2G	./original4G	.



显示总容量$ du -c2048000	./original4096000	.4096000	总用量



自动显示大小单位$ du -h2.0G	./original4.0G	.





汇总显示$ du -s4096000	.



有时间展示的信息组合上面的几个参数，显示汇总信息，以及时间信息等等。
$ du -a --time --time-style=full-iso200M  2014-06-21 22:18:45.551076154 +0800	./xaa200M	2014-06-21 22:18:45.752074291 +0800	./xab200M	2014-06-21 22:18:45.951072446 +0800	./xac200M	2014-06-21 22:18:46.149070610 +0800	./xad200M	2014-06-21 22:18:46.348068766 +0800	./xae200M	2014-06-21 22:18:46.563066772 +0800	./xaf200M	2014-06-21 22:18:46.762064928 +0800	./xag200M	2014-06-21 22:18:46.961063083 +0800	./xah200M	2014-06-21 22:18:47.167061173 +0800	./xai200M	2014-06-21 22:18:47.366059329 +0800	./xaj2.0G	2014-06-21 22:17:48.740602788 +0800	./original/dat12.0G	2014-06-21 22:19:01.134931691 +0800	./original0	2014-06-21 22:17:46.501499784 +0800	./tsta4.0G	2014-06-21 22:15:57:46.501499784 +0800	.

]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>磁盘管理</tag>
        <tag>disk space</tag>
        <tag>du</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux du命令</title>
    <url>/2014/06/22/linux-du/</url>
    <content><![CDATA[du - 估计文件空间的使用使用man来查看du，我们知道这个命令的含义为estimate file space usage。 
也就是查看文件系统的磁盘空间占用情况，可以利用该命令来获取硬盘被占用了多少空间，目前还剩下多少空间等信息。
选项命令的使用方法为：
$ du [options]... [FILE]...



其中一些比较有用的命令选项为：

-0, --null ： 这个只是对输出有效果，把所有的输出放在一行

-a, --all：这个选项会统计所有的信息，而不只是文件夹

-B, --block-size=SIZE：类似于df命令

-c, --total：最后一行，显示一个统计信息

-d, --max-depth=N：指定统计目录的层级，只有在层级大于N时有效

-h, --human-readable：同df命令，自动优化显示

-l, --count-links：如果是硬链接，则计入大小

-s, --summarize：显示统计信息


最常用组合$ du -sh4.0G	.


显示当前文件夹的总大小

默认输出$ du 2048000	./original4096000	.



不换行输出$ du -02048000	./original4096000	.



统计所有信息$ du -a204800	./xaa204800	./xab204800	./xac204800	./xad204800	./xae204800	./xaf204800	./xag204800	./xah204800	./xai204800	./xaj2048000	./original/dat12048000	./original0	./tsta4096000	.



指定显示容量单位$ du -BG2G	./original4G	.



显示总容量$ du -c2048000	./original4096000	.4096000	总用量



自动显示大小单位$ du -h2.0G	./original4.0G	.





汇总显示$ du -s4096000	.



有时间展示的信息组合上面的几个参数，显示汇总信息，以及时间信息等等。
$ du -a --time --time-style=full-iso200M  2014-06-21 22:18:45.551076154 +0800	./xaa200M	2014-06-21 22:18:45.752074291 +0800	./xab200M	2014-06-21 22:18:45.951072446 +0800	./xac200M	2014-06-21 22:18:46.149070610 +0800	./xad200M	2014-06-21 22:18:46.348068766 +0800	./xae200M	2014-06-21 22:18:46.563066772 +0800	./xaf200M	2014-06-21 22:18:46.762064928 +0800	./xag200M	2014-06-21 22:18:46.961063083 +0800	./xah200M	2014-06-21 22:18:47.167061173 +0800	./xai200M	2014-06-21 22:18:47.366059329 +0800	./xaj2.0G	2014-06-21 22:17:48.740602788 +0800	./original/dat12.0G	2014-06-21 22:19:01.134931691 +0800	./original0	2014-06-21 22:17:46.501499784 +0800	./tsta4.0G	2014-06-21 22:15:57:46.501499784 +0800	.

]]></content>
      <categories>
        <category>Linux</category>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>disk space</tag>
        <tag>du</tag>
        <tag>baobab</tag>
      </tags>
  </entry>
  <entry>
    <title>复制文件描述符的`dup2` 函数</title>
    <url>/2013/02/12/linux-dup2/</url>
    <content><![CDATA[复制文件描述符的dup2 函数dup2 是 Unix/Linux 系统中用于复制文件描述符的函数，它允许将一个文件描述符复制到另一个文件描述符上，实现输入输出流的重定向操作，比如将stdout重定向到一个文件，亦或者是把一个文件作为输入来对待。
函数原型与头文件#include &lt;unistd.h&gt;int dup2(int oldfd, int newfd);



参数说明
**oldfd**：需要复制的源文件描述符（比如已经打开的文件、管道、套接字等）。
**newfd**：目标文件描述符，用于接收oldfd的副本或者重定向的描述符。若newfd已打开，系统会先关闭它，再进行复制。

返回值
成功时：返回新的文件描述符（即newfd，若newfd之前已关闭则可能返回其他值）。
失败时：返回-1，并设置errno错误码（如EBADF表示oldfd无效，EMFILE表示文件描述符耗尽）。

核心功能与原理dup2 的核心作用是让newfd成为oldfd的副本，即让两个文件描述符指向同一个文件表项，从而共享文件偏移量和状态标志。例如：

将newfd重定向为oldfd的副本后，对newfd的读写操作等同于对oldfd的操作。
常见场景是重定向标准输入（STDIN_FILENO=0）、标准输出（STDOUT_FILENO=1）、标准错误（STDERR_FILENO=2）。

示例1：重定向标准输出到文件下面的这个程序会将原本输出到终端的重定向输出到一个文件。
/** * @file linux-dup2-to-file.c * @brief redirect stdout to file */#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;#include &lt;fcntl.h&gt;int main() {    int fd, old_stdout;    char *filename = "dup2-to-file-output.txt";        // keep the original stdout for restore    old_stdout = dup(STDOUT_FILENO);    if (old_stdout == -1) {        perror("dup failed");        exit(EXIT_FAILURE);    }        // open the file for writing    fd = open(filename, O_CREAT | O_WRONLY | O_TRUNC, 0644);    if (fd == -1) {        perror("open failed");        exit(EXIT_FAILURE);    }        // redirect stdout to file    if (dup2(fd, STDOUT_FILENO) == -1) {        perror("dup2 failed");        exit(EXIT_FAILURE);    }    close(fd);  // close fd, because STDOUT_FILENO is now pointing to it        // now printf's output will be written to file    printf("This text will be written to %s\n", filename);    printf("Another line for testing...\n");    // Remember to flush the buffer otherwise the output will be buffered    fflush(stdout);        // restore original stdout    if (dup2(old_stdout, STDOUT_FILENO) == -1) {        perror("dup2 restore failed");        exit(EXIT_FAILURE);    }    // close the backup descriptor    close(old_stdout);          // after restore, output to terminal    printf("Now back to terminal output\n");        return 0;}

编译使用的方法如下所示：
$ gcc -o linux-dup2-to-file linux-dup2-to-file.c$ ./linux-dup2-to-file       Now back to terminal output$ cat dup2-to-file-output.txtThis text will be written to dup2-to-file-output.txtAnother line for testing...


需要注意的是，在执行完操作后，需要调用fflush(stdout)强制刷新，不然可能不是你希望的现象。

示例2：重定向标准输入从文件下面的这个程序会将文件的内容作为终端输入的信息。
/** * @file linux-dup2-from-file.c * @brief redirect stdin from file */#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;#include &lt;fcntl.h&gt;#include &lt;string.h&gt;int main() {    int fd, old_stdin;    char *filename = "dup2-from-file-input.txt";    char buffer[1024];        // keep the original stdin for restore    old_stdin = dup(STDIN_FILENO);    if (old_stdin == -1) {        perror("dup failed");        exit(EXIT_FAILURE);    }        // open the file for reading    fd = open(filename, O_RDONLY);    if (fd == -1) {        perror("open failed");        exit(EXIT_FAILURE);    }        // redirect stdin to file    if (dup2(fd, STDIN_FILENO) == -1) {        perror("dup2 failed");        exit(EXIT_FAILURE);    }    close(fd);  // close fd, because STDIN_FILENO is now pointing to it        // now scanf will read data from file    printf("Reading from %s:\n", filename);    while (fgets(buffer, sizeof(buffer), stdin) != NULL) {        printf("[Read] : %s", buffer);    }    fflush(stdin);        // restore original stdin    if (dup2(old_stdin, STDIN_FILENO) == -1) {        perror("dup2 restore failed");        exit(EXIT_FAILURE);    }    close(old_stdin);        // after restore, input from terminal    printf("\n\n[Terminal] Enter something: ");    strcpy(buffer, "hello world");    printf("\n[Terminal] You entered: %s\n", buffer);    fflush(stdout);        return 0;}

编译使用的方法如下所示：
$ cat dup2-from-file-input.txt Roses are red,Violets are blue,Testing dup2,And stdin too.%     $ gcc -o linux-dup2-from-file  linux-dup2-from-file.c$ ./linux-dup2-from-file      Reading from dup2-from-file-input.txt:[Read] : Roses are red,[Read] : Violets are blue,[Read] : Testing dup2,[Read] : And stdin too.[Terminal] Enter something: [Terminal] You entered: hello world





与dup函数的区别dup 函数（int dup(int oldfd)）也是用于复制文件描述符，但两者还是有一些区别的。比如dup 返回最小的未使用文件描述符，而dup2可以指定目标描述符newfd。

dup2(newfd, oldfd)
 ```cclose(newfd);return dup(oldfd);



应用场景这个函数主要用在比如，IO重定向（类似于shell的&gt; file）、管道通信（父子进程的通信）、日志系统（同时写到终端和日志文件）或者网络编程中（将网络套接字重定向到输入和输出）。
注意事项
文件描述符关闭顺序：重定向时若newfd已打开，dup2会先关闭它，可能导致数据丢失。
原子性：dup2是原子操作，无需担心多线程环境下的竞争条件。
资源管理：复制的描述符共享文件表项，需确保正确关闭（避免文件描述符泄漏）。
错误处理：始终检查dup2的返回值，处理可能的错误（如文件不存在、权限不足）。

通过合理使用dup2，可以灵活控制程序的输入输出流向，实现复杂的系统编程需求。
在实际开发中，它常与管道、套接字等结合使用，是构建进程间通信和重定向机制的核心工具。
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>dup</tag>
        <tag>dup2</tag>
        <tag>STDIN</tag>
        <tag>STDOUT</tag>
        <tag>STDERR</tag>
      </tags>
  </entry>
  <entry>
    <title>念念不忘，必有回响 的 echo</title>
    <url>/2011/01/26/linux-echo-beginner/</url>
    <content><![CDATA[念念不忘，必有回响 的 echo.. _linux_echo_beginner:
echo命令用于在终端设备上输出字符串或变量的值，类似于Python的print和C语言的printf，是Linux系统中最常用的命令之一。
其中输出字符串主要在shell脚本中使用，常用的还是输出变量的值。
命令格式为：echo [参数] [字符串]
其中常用的参数为：

-n	不输出结尾的换行符
-e “\a”发出警告音
-e “\n”换行，光标移至行首
-e “\r”光标移至行首，但不换行、主用用在打印循环的情况下

几个示例输出一段字符串：
$  echo "Hello Linux" Hello Linux

输出变量提取后的值：
$ echo $PATH/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin
一般使用在变量前加上 $ 符号的方式提取出变量的值，例如：$ PATH，然后再用echo命令予以输出。或者直接使用echo命令输出一段字符串到屏幕上，起到给用户提示的作用。

其中的PATH与Windows的环境变量类似

几个Linux命令来输出：
$ echo `date`Sat 12 Feb 2011 22:19:03 PM CST


查询上一次的执行结果
$echo $?

$?是Shell中的一个特殊变量，表示上一条命令的退出状态，0表示成功。
]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>echo</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux echo命令</title>
    <url>/2011/01/26/linux-echo/</url>
    <content><![CDATA[Linux 的 echo 命令echo命令用于在终端设备上输出字符串或变量的值，类似于Python的print和C语言的printf，是Linux系统中最常用的命令之一。
其中输出字符串主要在shell脚本中使用，常用的还是输出变量的值。
命令格式为：echo [参数] [字符串]
其中常用的参数为：

-n	不输出结尾的换行符
-e “\a”发出警告音
-e “\n”换行，光标移至行首
-e “\r”光标移至行首，但不换行、主用用在打印循环的情况下

几个示例输出一段字符串：
$  echo "Hello Linux" Hello Linux

输出变量提取后的值：
$ echo $PATH/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin
一般使用在变量前加上$符号的方式提取出变量的值，例如：$PATH，然后再用echo命令予以输出。或者直接使用echo命令输出一段字符串到屏幕上，起到给用户提示的作用。

其中的PATH与Windows的环境变量类似

几个Linux命令来输出：
$ echo `date`Sat 12 Feb 2011 22:19:03 PM CST


查询上一次的执行结果
$echo $?

$?是Shell中的一个特殊变量，表示上一条命令的退出状态，0表示成功。
]]></content>
      <categories>
        <category>Linux</category>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>echo</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux 編輯器</title>
    <url>/2012/01/20/linux-editors/</url>
    <content><![CDATA[Linux 下的编辑器[TOC]
遍寻编辑器那么多，最爱的还是VIM
geditgedit无需多言，Linux各个发行版默认都有的编辑器，类似于Windows的记事本，不过可以根据代码类型着色，这点可比记事本NB。
Sublime Text最后一个神器就是Sublime Text 2，一个基本上可以称得上是IDE的编辑器，最先看到是在前公司的前端工程师的Mac上，看官方的介绍感觉又是一款类似于Vim的神器，但是比Vim界面更好看，功能更全面，非常适合PHP、Python、JavaScript这些Web开发。
下载/安装：http://www.sublimetext.com。
Notepad++(Windows)Notepad++ 是很多Windows用户寻找的比记事本更优秀的文本编辑器。它拥有很多丰富先进的特性，例如语法高亮显示，代码折叠和宏，但不同于大多数其他的基于GUI的文本编辑器功能，Notepad++是完全自由而且开放源代码。它和其他的编辑器相比可能并非性感如起飞的蝙蝠。但它完全定制，因此只受限于您的时间和想象力。作为一个编辑器，它的强大是不言而喻的。
Emacs (适合所有平台)高级程序员的主要文本编辑器。在Emacs（编辑宏）最受欢迎的是内置宏和清大的键盘命令，使编辑的文本文件，尤其是代码很好高兴。常说：您可能不会完全明白Emacs的，直到您花一些时间去了解它。该程序已经被移植到几乎所有的平台，并有多个发行版，其中最流行的可能是GNU Emacs和XEmacs，它们都是免费、跨平台和开放源码。
UltraEdit (Windows)共享软件UltraEdit（$49.95）用户感觉很友好的编辑器，支持语法高亮显示，代码折叠宏和和同类软件相比拥有大量的可用功能。UltraEdit是一个很好的WEB开发平台，提供很多高级特性用来构建HTML,PHP，JavaScript和更多其它的网络编程语言。
TextMate (Mac OS X)强大而且更具吸引力，TextMate ($63)出现在视野中仅仅几年时间而且因有吸引力的界面、功能强大的宏、以及可下载和可编辑的束，迅速的获得了狂热的追捧。Windows用户要是喜欢TextMate可以试一下E Text Editor（一个类似于TextMate且支持TextMate宏束的文本编辑器）。
Vim(所有平台)Vim的强大就不用多说了，非常熟练Vim的话所有的工作都可以使用Vim去完成，Vim也称为编辑器的瑞士军刀，是高级程序员的一个强大工具。也类似于Emacs，Vim也有不同的口味，除了原来的，还有Windows平台的gVim 和 gVim Portable，Mac平台的MacVim，如果你认为你可能的兴趣在Vim中已经提供，但尚未准备好一步一步深入这款功能强大而又有点不易用的编辑器，
EditPlusEditPlus(文字编辑器)汉化版一套功能强大，可取代记事本的文字编辑器，EditPlus拥有无限制的撤消与重做、英文拼字检查、自动换行、列数标记、搜寻取代、同时编辑多文件、全屏幕浏览功能。而它还有一个好用的功能，就是它有监视剪贴板的功能，能够同步于剪贴板自动将文字粘贴进 EditPlus 的编辑窗口中，让你省去粘贴的步骤。另外它也是一个非常好用的HTML编辑器，它除了支持颜色标记、HTML 标记，同时支持C、C++、Perl、Java，另外，它还内建完整的HTML &amp; CSS1 指令功能，对于习惯用记事本编辑网页的朋友，它可帮你节省一半以上的网页制作时间，若你有安装IE3.0 以上版本，它还会结合IE浏览器于 EditPlus 窗口中，让你可以直接预览编辑好的网页(若没安装IE，也可指定浏览器路径)。因此，它是一个相当棒又多用途多状态的编辑软件。
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>gedit</tag>
        <tag>Vim</tag>
        <tag>Komode Edit</tag>
        <tag>UltraEdit</tag>
        <tag>Geany</tag>
        <tag>Bluefish</tag>
        <tag>Sublime Text</tag>
        <tag>Notepad ++</tag>
        <tag>Emacs</tag>
        <tag>EditPlus</tag>
      </tags>
  </entry>
  <entry>
    <title>换一种环境 的 env</title>
    <url>/2015/08/20/linux-env-beginner/</url>
    <content><![CDATA[换一种环境 的 env.. _linux_env_beginner:
env其实就是environment的缩写，用来查看或者修改当前的环境。
Linux是多用户的平台，为了每个用户都有自己的设置，env使用了比较多的环境变量，比如echo $HOME后不同的用户可以看到不同的路径。
修改则可以用env命令进行管理。
官方定义为：

 env - run a program in a modified environment

语法语法如下所示：
$ env [OPTION]... [-] [NAME=VALUE]... [COMMAND [ARG]...]

常用的参数为：

-i  开始一个新的空的环境

-u  取消设置的的变量

-C 更改工作目录

-S 分割输入参数


默认无参数默认情况下，输入env会给出当前设置的环境和系统默认的环境。
$ envHOSTTYPE=x86_64LANG=en_US.utf8PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:NAME=LOCALHOSTHOME=/home/usernameUSER=usernameLOGNAME=usernameSHELL=/usr/bin/bashSHLVL=1PWD=/home/username/mycode/cOLDPWD=/home/username/mycode/pythonPAGER=lessLESS=-R...



设置环境变量当然env最重要的还是设置环境变量，一般使用为：
$ env NAME=what-you-want-to-set

接下来使用echo $NAME就可以看到效果了。
全新的环境如果希望运行程序的过程中，不受到原来环境的影响，可以使用-i参数，直接开启一个全新的环境。
$ env -i program



取消某些环境变量通过-u来取消某些设置的环境变量，比如：
$ env -u PWDHOSTTYPE=x86_64LANG=en_US.utf8PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:NAME=LOCALHOSTHOME=/home/usernameUSER=usernameLOGNAME=usernameSHELL=/usr/bin/bashSHLVL=1OLDPWD=/home/username/mycode/pythonPAGER=lessLESS=-R...



可以看到与env相比，PWD变量已经不存在了。
更改工作路径可以通过-C来更改工作的路径。
$ pwd/home/username/linux/scripts$ env -C .. pwd/home/username/linux



进阶的传递多个参数这个参数较多用在脚本中，-S后面可以跟多个参数，如果没有这个参数，则只能跟一个参数，比如以脚本为例：
#!/usr/bin/env perl -w -T

会报错
/usr/bin/env: 'perl -w -T': No such file or directory



此时加上-S就可以解决了，如下：
#!/usr/bin/env -S perl -w -T

]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>evn</tag>
      </tags>
  </entry>
  <entry>
    <title>使用Linux环境变量</title>
    <url>/2012/01/06/linux-enviroment/</url>
    <content><![CDATA[使用Linux环境变量什么是环境变量bash shell使用一种称为环境变量的特性来存储关于shell会话和工作环境的信息（环境变量的名称由此而来）。该特性还允许你将数据存储在内存中，以便于在shell中运行的程序和脚本访问它们。这是一种便捷的、用于存储持久性数据的方式，这些数据可以标示用户账户、系统、shell或任何需要存储的内容的特性。
bash shell中共有两种类型的环境变量：

全局变量；
本地变量；

全局环境变量要查看全局变量，可以使用printenv命令。
通过该命令的输出，我们可以看到bash shell已经设置了许多全局环境变量，其中大多数由系统在登录过程中设置。
本地环境变量本地环境变量只在定义它们的本地进程中可见。可以通过set命令显示特定进程的所有环境变量集。这其中包含了全局环境变量和本地环境变量。
设置环境变量设置本地环境变量为环境变量分配一个数值或者字符串，方法是使用等号将变量指定为具体值。
例如
$ test=hello，

那么我们使用
$ echo $test

就可以输出hello。
当然如果赋值为一个字符串，需要用单引号括起来，否则空格后的字符会被认为是命令而出错。
如果创建新环境变量，建议（但不要求）使用小写字母。这用助于区分个人环境变量与系统环境变量。
设置全局环境变量创建全局变量的方法是创建一个本地环境变量，然后使用export将它导出到全局环境中。
移除环境变量可以使用unset命令来移除环境变量，在unset命令中引用环境变量时，不要使用美元符号。
默认的shell环境变量
BASH ：记录当前bash shell的路径。

[root@localhost awK]# echo $BASH/bin/bash

BASH_SUBSHELL  ：记录当前子shell的层次。BASH_SUBSHELL是从0开始计数的整数。
BASH_VERSINFO  ：是一个数组包含六个元素，这六个元素显示bash的版本信息。
BASH_VERSION  ：显示shell版本的信息。
DIRSTACK  ：记录了栈顶的目录值，初值为空。
GLOBLGNORE ：是由冒号分割的模式列表，表示通配时忽略的文件名集合。
GROUPS   ：记录当前用户所属的组。
HOME ：记录当前用户的家目录，由/etc/passwd的倒数第二个域决定。
HOSTNAME  ：记录主机名。
HOSTTYPE和MACHTYPE ：都是记录系统的硬件架构。
IFS  ：用于设置指定shell域分隔符，默认情况下为空格。

[root@localhost awK]# export IFS=:[root@localhost awK]# echo $PATH/usr/local/sbin /usr/local/bin /sbin /bin/usr/sbin /usr/bin /root/bin


OLDPWD   ：记录旧的工作目录。
OSTYPE  :记录操作系统类型。
PATH  :环境变量，显示当前PATH环境变量的内容。
PPID ：是创建当前进程的进程号，即当前进程的父进程号
PS1  ：提示符变量，用于设置提示符格式，用于设置一级shell提示符环境变量。
PS2  ：用于设置二级shell提示符环境变量。
PWD ：记录当前路径
REPLY  ：REPLY变量与read和select有关。
SECONDS：记录脚本从开始到结束耗费的时间。
SHELL ：显示当前所用的shell
SHELLOPTS  ：记录了处于“开”状态的shell选项列表，它只是一个只读变量。
SHLVL   ：记录了bash嵌套的层次，一般来说，我们启动第一个Shell时。  $SHLVL=1。如果在这个Shell中执行脚本，脚本中的$SHLVL=2 。
TMOUT  ：用来设置脚本过期的时间，比如TMOUT=3，表示该脚本3秒后过期。
UID : 已登用户的ID
USER ：显示当前用户名字

注意：使用set命令时，并非所有的默认环境变量都会显示出来，因为有些默认的环境变量时不需要赋值的。
设置PATH环境变量增加环境变量的方法为export PATH=$PTAH:/the/path/you/want/to/add；
有时我们可以使用PATH=$PATH:. 临时让当前目录添加到PATH变量中，可以执行当前目录的程序而不用添加./。 ，不错哟。
定位系统环境变量Bash shell将查找下面的文件用来处理登录shell的设置：

/etc/profile :   是系统上的主默认启动文件，系统上的每一个用户在登录时都将执行此启动文件，比如安装了什么软件，需要每个人都使用，那么需要将环境变量设置在该文件。
$HOME/.bash_profile
$HOME/.bash_login
$HOME/.profile 上面的3个启动文件主要特定于各个用户，这应该叫井水不犯河水。
$HOME/.bashrc 该文件为交互式shell启动时处理的。

变量数组可以使用
$ mytest=(one two three four five)

为某个环境变量设置多个值，但是在显示的时候，如果使用
$echo $mytest

那么只会出现one，而是用$echo ${mytest[1]}，则显示two，可以使用 $echo ${mytest[*]}显示所有的值。
使用命令别名命名别名允许您为公共命令以及它们的参数创建别名，以尽可能减少录入工作。
因为我们知道，在启动新的交互式的shell时，bash shell始终会读取.bashrc启动文件，所以我们可以把别名放在该文件中。
]]></content>
      <categories>
        <category>Shell</category>
      </categories>
      <tags>
        <tag>bashrc</tag>
        <tag>linux</tag>
        <tag>echo</tag>
        <tag>shell</tag>
        <tag>alias</tag>
        <tag>PATH</tag>
        <tag>enviroment</tag>
        <tag>printenv</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux 强大的网络工具 ethtool</title>
    <url>/2015/01/20/linux-ethtool/</url>
    <content><![CDATA[Linux 强大的网络工具 ethtoolethtool 命令主要用于查询配置网卡参数， 但是它的功能超出你的想象。
比如有很多网口，不知道哪个对应哪一个，so easy，直接
$ ethtool -p ethN # Show visible port identification (e.g. blinking)

此时就可以看到ethN的灯在闪了
而具体的查看网卡类型，可以使用
$ ethtool -i ethNdriver: bnxt_enversion: 1.10.0firmware-version: 214.0.253.1/pkg 21.40.25.31expansion-rom-version:bus-info: 0000:18:00.0supports-statistics: yessupports-test: yessupports-eeprom-access: yessupports-register-dump: nosupports-priv-flags: no

此时可以通过modinfo来查看网卡驱动的详细信息
$ modinfo bnxt_enilename:       /lib/modules/4.18.0-147.5.1.el8_1.x86_64/kernel/drivers/net/ethernet/broadcom/bnxt/bnxt_en.ko.xzversion:        1.10.0description:    Broadcom BCM573xx network driverlicense:        GPLrhelversion:    8.1srcversion:     2E74274561578E7E250F661alias:          pci:v000014E4d0000D800sv*sd*bc*sc*i*alias:          pci:v000014E4d00001807sv*sd*bc*sc*i*......depends:intree:         Yname:           bnxt_envermagic:       4.18.0-147.5.1.el8_1.x86_64 SMP mod_unload modversionssig_id:         PKCS#7signer:         CentOS Linux kernel signing keysig_key:        6C:E4:44:06:AD:56:56:1C:FE:E9:7E:99:45:F8:69:0F:DF:1E:EA:FAsig_hashalgo:   sha256signature:      39:1D:A1:0F:56:8A:BB:20:44:2B:B0:6B:6E:6D:89:DD:15:BC:A2:19:...
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>ethtool</tag>
      </tags>
  </entry>
  <entry>
    <title>执行以特定字开头的历史命令</title>
    <url>/2014/01/20/linux-execute-history-command/</url>
    <content><![CDATA[输入！和你要重新执行的命令的前几个字母。
例如！ps，回车，就会执行最近历史命令中以“ps”开头的比如“ps aux | grep kernel”的命令。
# !ps
]]></content>
      <categories>
        <category>Shell</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title>显示管理磁盘分区 fdisk</title>
    <url>/2016/01/16/linux-fdisk-beginner/</url>
    <content><![CDATA[显示管理磁盘分区 fdisk.. _linux_fdisk_beginner:
.. note::  浮云一别后，流水十年间。

韦应物《淮上喜会梁川故人 》

fdisk是用于检查一个磁盘上分区信息最通用的命令。
fdisk可以显示分区信息及一些细节信息，比如文件系统类型等。
设备的名称通常是/dev/sda、/dev/sdb 等。
对于以前的设备有可能还存在设备名为 /dev/hd* (IDE)的设备，这个设备逐步淘汰了。
fdisk也可以用于创建并操控分区表信息，支持主任GPU、MBR、Sun、SGI和BSD。
块设备可以划分为一个或多个称为分区的逻辑磁盘。这种划分的记录会保存在分区表，通常位于磁盘的第 0 扇区。
fdisk的官方解释为：

fdisk - manipulate disk partition table

语法格式为：
$ fdisk [options] device$ fdisk -l [device...]



其中一些常用的参数为：

-l  列出指定的外围设备的分区表状况
-L, --color[=when] ：将输出颜色化，其中when可以指定为auto, never or always. 默认为 auto.

显示当前系统的分区情况这个也是我唯一推荐入门者使用的 命令，仅仅list显示出目前的系统分区。
万万不要输入fdisk执行其他操作，极易格式化硬盘，切记切记。
$ fdisk -lWARNING: fdisk GPT support is currently new, and therefore in an experimental phase. Use at your own discretion.Disk /dev/sda: 256.1 GB, 256060514304 bytes, 500118192 sectors # 磁盘空间及扇区信息Units = sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk label type: gptDisk identifier: FAF37680-0ECE-4BE7-93FC-E87A8F2F6455

]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>危险命令</tag>
        <tag>硬件信息</tag>
        <tag>fdisk</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux fdisk</title>
    <url>/2013/01/16/linux-fdisk/</url>
    <content><![CDATA[Linux fdisk 命令Fdisk is the most commonly used command to check the partitions on a disk. The fdisk command can display the partitions and details like file system type. However it does not report the size of each partitions.
$ fdisk -l #显示所有的分区表]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>fdisk</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux Fedora安装gnome-gtk开发环境</title>
    <url>/2011/12/11/linux-fedora-install-gnome/</url>
    <content><![CDATA[fedora安装gnome-gtk开发环境Gnome开发环境为：
yum groupinstall development-libs development-tools gnome-software-development

gtk支持为：
yum install gtk3-devel gtk3-devel-docs gtk+-devel
]]></content>
      <categories>
        <category>Linux</category>
        <category>Fedora</category>
      </categories>
      <tags>
        <tag>yum</tag>
        <tag>gtk</tag>
        <tag>gnome</tag>
        <tag>groupinstall</tag>
        <tag>development-libs</tag>
        <tag>development-tools</tag>
        <tag>gnome-software-development</tag>
        <tag>gtk3-devel</tag>
        <tag>gtk3-devel-doc</tag>
        <tag>gtk+-devel</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux Fedora 升级</title>
    <url>/2013/01/16/linux-fedora-upgrade/</url>
    <content><![CDATA[fedora17升级到18fedora 18的升级工具不再是pre-upgrade了，而是换成了fedup。
先安装fedup，使用fedup升级的方法：
sudo fedup –network 18
]]></content>
      <categories>
        <category>Linux</category>
        <category>Fedora</category>
      </categories>
      <tags>
        <tag>sudo</tag>
        <tag>fedup</tag>
        <tag>network</tag>
      </tags>
  </entry>
  <entry>
    <title>YUM已死，DNF永生</title>
    <url>/2015/05/19/linux-fedora-yum-is-dead-use-dnf/</url>
    <content><![CDATA[YUM已死，DNF永生这个应该是从Fedora22开始的……
DNF从yum分支出来，使用专注于性能的C语言库hawkey进行依赖关系解析工作，大幅度提升包管理操作效率并降低内存消耗，按原先的节奏本应该是Fedora 22实现这一替代方案，随着DNF 1.0版本的发布，这一刻终于到来。
　　这样的激进更新是不可避免的，主要是由于yum不能“Python 3 as default”，而DNF支持Python 2和Python3。（Python 3分支自2008年发布以来积极开发了五年，已经成熟和稳定，而目前仍在维护的Python 2分支不增加新特性，只接受bug和安全修正，它最早的版本是在2000年发布的。）与此同时，DNF Python API和yum是完全不同的，这两个项目中所有已知的不兼容问题也都被记录。

在Fedora 22 Core中只有DNF而yum项目正式宣告死亡。

yum依然可以下载到，也可同样调用软件包，以及Python API照旧。只是**yum可执行文件被重新命名为yum-deprecated，以及yum调用的命令行被重新定向至DNF。这样你就可以在一个系统上同时保有yum和DNF。**
　　启动DNF项目的原因是yum的三个陷阱：

undocumented API
broken dependency solving algorithm
inability to refactor internal functions。

最后被提及的问题是缺少文件链接。yum插件可以在yum代码中使用任何method，这会造成yum utility因一些细小变化而突然崩溃。
　　DNF目标是为了避免yum执行的错误。从一开始所有暴露的API都被适当的记录，且测试几乎包含了每一次新的提交。这个项目采用了敏捷开发，会提供用户一些优先级功能实现。
　　DNF现在也在极力推进yum迁移至DNF，并改善用户体验。为了实现轻松迁移，已经将DNF迁移插件导入了包、组和事务元数据，实现从yum至新的Fedora包管理器。
]]></content>
      <categories>
        <category>Linux</category>
        <category>Fedora</category>
      </categories>
      <tags>
        <tag>yum</tag>
        <tag>Linux</tag>
        <tag>Fedora</tag>
        <tag>Python</tag>
        <tag>dnf</tag>
      </tags>
  </entry>
  <entry>
    <title>Fedora17初始配置</title>
    <url>/2012/06/01/linux-fedora17-initial-configuration/</url>
    <content><![CDATA[Fedora17初始配置系统基本配置刚刚安装完毕的系统无法在命令直接添加 sudo 执行。可以使用 su 或 su –c ‘cmd’ 来执行需要管理员权限的命令。
启用 sudo在终端下输入vi /etc/sudoers 或visudo命令：搜索文件，找到下面而2行内容：
## Allow root to run any commands anywhereroot ALL=(ALL) ALL

然后，在第二行下面添加如下内容
‘username’ ALL=(ALL) ALL
提示：将换成你的用户名即可。
检查、安装系统更新检查系统更新：
$ sudo yum check-update

安装系统更新：
$ sudo yum update
安装快速打开终端
$ sudo yum nautilus-open-terminal

设置中文输入法安装Fcitx 小企鹅输入法$ sudo yum install fcitx ibus-sunpinyin
在应用里面查找“Input Method selector”(输入法切换器)，打开后选择“Showall”（显示所有输入法），选择“Chinese”，添加“Pinyin输入法”即可。
GNOME 3.2 配置安装Gnome-tweak-tool$ sudo yum install gnome-tweak-tool    —对于不是很习惯Gnome3的可以事先缓解一下

GNOME Shell Extension扩展列表：
$ sudo yum install gnome-shell-extension-alternate-tab.noarch gnome-shell-extension-apps-menu.noarch gnome-shell-extension-auto-move-windows.noarch gnome-shell-extension-common.noarch gnome-shell-extension-cpu-temperature.noarch gnome-shell-extension-dock.noarch gnome-shell-extension-drive-menu.noarch gnome-shell-extension-gpaste.noarch gnome-shell-extension-icon-manager.noarch gnome-shell-extension-mediaplayers.noarch gnome-shell-extension-noim.noarch gnome-shell-extension-noripple.noarch gnome-shell-extension-pidgin.i686 gnome-shell-extension-places-menu.noarch gnome-shell-extension-pomodoro.noarch gnome-shell-extension-presentation-mode.noarch gnome-shell-extension-remove-volume-icon.noarch gnome-shell-extension-righthotcorner.noarch gnome-shell-extension-systemMonitor.noarch gnome-shell-extension-theme-selector.noarch gnome-shell-extension-user-theme.noarch gnome-shell-extension-windowsNavigator.noarch gnome-shell-extension-workspace-indicator.noarch gnome-shell-extension-workspacesmenu.noarch gnome-shell-extension-xrandr-indicator.noarch gnome-shell-theme-atolm.noarch gnome-shell-theme-dark-glass.noarch gnome-shell-theme-gaia.noarch gnome-shell-theme-orta.noarch gnome-shell-theme-smooth-inset.noarch
扩展安装完毕后，需重启GNOME Shell（按住Alt+F2,输入 r） 。打开gnome-tweak-tool，激活安装的扩展即可。
安装编译开发环境$ yum install curl-devel gcc glibc-devel gcc-gfortran gcc-c++ python perl erlang vim gedit tcl tk

安装X11图形库$ sudo yum install libX11-devel

安装auto libtoolsautoconf automake libtool flex pkgconfig
安装分布式文件管理工具git$ yum install git-core

集成工具与常用软件优秀集成工具推荐：Ailurus小熊猫
yum install ailurus:著名的系统设置、软件工具
Autoplus
简介：可用Autoplus进行安装/卸载 Adobe Flash, codecs, Google Earth,Skype, Sun Java, VirtualBox, WinFF, Imagination, Cinelerra, Hugin Panorama Creator, Lightscribe, Dropbox等操作。
su -c ‘yum -y -–nogpgcheck install http://dnmouse.org/autoplus-1.4-5.noarch.rpm’
如果有必要，可导入签名（可选项）：
su -c ‘rpm –import http://dnmouse.org/RPM-GPG-KEY-dnmouse’Fedora Utils应用安装与系统设置脚本，可安装Adobe Flash, codecs, Sun Java, Adobe Air,Wine, Google Earth, GTalk plugin, MS Truetype Fonts 等其他常用应用。```bashsu -c “curl http://master.dl.sourceforge.net/project/fedorautils/fedorautils.repo -o /etc/yum.repos.d/fedorautils.repo &amp;&amp; yum install fedorautils”

常用应用邮件
$ sudo yum install thunderbird
文件分享
Transmission(BT客户端)
$ sudo yum install transmission
Filezilla(FTP客户端)：
$ sudo yum install filezilla
即时通讯IM
Pidgin（同Empathy）：
$ sudo yum install pidgin
Emesene（MSN客户端）：
$ sudo yum install emesene
Gwibber（微博客户端）：
$ sudo yum install gwibber
Pino（Twitter 客户端）:$ sudo yum install pino
Hotot(傲兔,Twitter客户端)：```bashyum install hotot
图形图像
shutter(截图、截屏)：
$ sudo yum install shutter
Gimp：
$ sudo yum install gimp
Dia（流程图）:
$ sudo yum install dia
Inkscape（矢量做图）：
$ sudo yum install inkscape
Gthumb（图像浏览器）：
$ sudo yum install gthumb
Pinta（小Gimp）：
$ sudo yum install pinta
播放器
vlc：
$ sudo yum install vlc
Banshee(音乐播放器)：
$ sudo yum install banshee
音视频编辑
Pitivi（视频编辑）：
$ sudo yum install pitivi
Audacity（音频编辑）：
$ sudo yum install audacity
系统类工具
Gnome Do（快速文件搜索）：
$ sudo yum install gnome-do
p7zip （解压缩工具）：
$ sudo yum install p7zip
Terminator（优秀命令终端）：
$ sudo yum install terminator
办公
Stardict（星际词典）：
$ sudo yum install stardict
Chmsee（CHM文件阅读器）：$ sudo yum install chmsee
LibreOffice（Office套件）：```bash$ sudo yum install libreoffice
IDE
Anjuta：
$ sudo yum install anjuta
Code::Blocks：
$ sudo yum install codeblocks
Eclipse:
$ sudo yum install eclipse-platform

版本控制$ sudo yum install svn git bzr cvs

yum查看更新的软件
$ yum list upgrades]]></content>
      <categories>
        <category>Linux</category>
        <category>Fedora</category>
      </categories>
      <tags>
        <tag>install</tag>
        <tag>fedora</tag>
      </tags>
  </entry>
  <entry>
    <title>linux之figlet命令</title>
    <url>/2014/02/12/linux-figlet-misc/</url>
    <content><![CDATA[点亮终端的艺术之光figlet在Linux的世界中，figlet是一个神奇的命令，可以将文字艺术化.
特别适合作为标题、口号或者问候语，还有很多软件程序的招呼语，也可以用这个来实现。
比如：
$ figlet HELLO           _   _ _____ _     _     ___  | | | | ____| |   | |   / _ \ | |_| |  _| | |   | |  | | | ||  _  | |___| |___| |__| |_| ||_| |_|_____|_____|_____\___/                               
]]></content>
      <categories>
        <category>Linux炫技</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>figlet</tag>
      </tags>
  </entry>
  <entry>
    <title>识别文件类型的file</title>
    <url>/2012/05/06/linux-file-beginner/</url>
    <content><![CDATA[识别文件类型的file.. _linux_file_beginner:
file鉴别大神, file的官方解释为：
$ file - determine file type

也就是说可以识别文件类型的意思，也可用来辨别一些文件的编码格式。它是通过查看文件的头部信息来获取文件类型，而不是像Windows通过扩展名来确定文件类型的，所以加不加后缀真的无所谓，谁会爱上谁，说起Windows吗，啥也不说了。
下面看几个比较使用的例子。
实例一 ：默认file后直接跟文件，得到如下所示信息
$ file book.pdfdelete.pdf: PDF document, version 1.3➜   file bookdelete: PDF document, version 1.3


可以看出加不加后缀都是没有关系的。

实例二：不显示名称$ file -b book.pdfPDF document, version 1.3

加上-b参数，是brief的含义，将只显示文件辨识结果，不显示文件名称了，这个其实对于很多文件而言，不是很友好。
实例三：输出易懂信息$ file -i  delete.pdfdelete.pdf: application/pdf; charset=binary

加上-i参数，是mime类型的含义，我也不懂是啥意思，但是我能刚方便地读懂我想知道的文件类型的含义。这就够了，不是吗，毕竟我们是来是用file命令的。
实例四：查看文件中的文件名的文件信息$ cat hello.txtsunset.jpg$ file -f hello.txtsunset.jpg: JPEG image data, JFIF standard 1.01

这个咋听着这么拗口，其实很简单，其实并不难，加上·-f·参数，是file-from类型的含义，到底是几个意思呢，也就是你想查看文件的类型信息的文件名在一个文件里面，从这个文件里面读取文件的信息。
实例五：好看的鸡肋$ file -F " === " sunset.jpgsunset.jpg ===  JPEG image data, JFIF standard 1.01

这个功能说实话，没搞明白有什么作用，默认的:感觉挺好用的，当然这个应该属于定制型的，就是默认替换掉一些提示信息。
实例六：查看软链接的文件信息$ file a.jpga.jpg: symbolic link to `sunset.jpg'$ file -L a.jpga.jpg: JPEG image data, JFIF standard 1.01

默认情况下，如果没有-L参数，只能得到这个文件是软链接的信息，如果加上这个参数，就能看到源文件的文件信息，这个功能还是很赞的。
]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>file</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux的file命令</title>
    <url>/2012/05/06/linux-file/</url>
    <content><![CDATA[识别文件类型的filefile的官方解释为：
file - determine file type

也就是说可以识别文件类型的意思，也可用来辨别一些文件的编码格式。它是通过查看文件的头部信息来获取文件类型，而不是像Windows通过扩展名来确定文件类型的，所以加不加后缀真的无所谓，谁会爱上谁，说起Windows吗，啥也不说了。
下面看几个比较使用的例子。
实例一 ：默认file后直接跟文件，得到如下所示信息
➜   file book.pdfdelete.pdf: PDF document, version 1.3➜   file bookdelete: PDF document, version 1.3


可以看出加不加后缀都是没有关系的。

实例二：不显示名称➜ file -b book.pdfPDF document, version 1.3

加上-b参数，是brief的含义，将只显示文件辨识结果，不显示文件名称了，这个其实对于很多文件而言，不是很友好。
实例三：输出易懂信息➜  file -i  delete.pdfdelete.pdf: application/pdf; charset=binary

加上-i参数，是mime类型的含义，我也不懂是啥意思，但是我能刚方便地读懂我想知道的文件类型的含义。这就够了，不是吗，毕竟我们是来是用file命令的。
实例四：查看文件中的文件名的文件信息➜  cat hello.txtsunset.jpg➜  file -f hello.txtsunset.jpg: JPEG image data, JFIF standard 1.01

这个咋听着这么拗口，其实很简单，其实并不难，加上·-f·参数，是file-from类型的含义，到底是几个意思呢，也就是你想查看文件的类型信息的文件名在一个文件里面，从这个文件里面读取文件的信息。
实例五：好看的鸡肋➜  file -F " === " sunset.jpgsunset.jpg ===  JPEG image data, JFIF standard 1.01

这个功能说实话，没搞明白有什么作用，默认的:感觉挺好用的，当然这个应该属于定制型的，就是默认替换掉一些提示信息。
实例六：查看软链接的文件信息➜  file a.jpga.jpg: symbolic link to `sunset.jpg'➜  file -L a.jpga.jpg: JPEG image data, JFIF standard 1.01

默认情况下，如果没有-L参数，只能得到这个文件是软链接的信息，如果加上这个参数，就能看到源文件的文件信息，这个功能还是很赞的。
]]></content>
      <categories>
        <category>CentOS</category>
        <category>Fedora</category>
        <category>Linux</category>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>file</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux 我知道的一些文件系统</title>
    <url>/2012/08/03/linux-filesystems/</url>
    <content><![CDATA[Linux文件系统


Name
简介



ext2
老牌 Linux 文件系统，不支援 journaling。


ext3
当今各大 Linux 预设使用的文件系统。支援 journaling。


ext3 (data)
加上 journal_data 功能的 ext3。


ext4
ext3 的下一版本。已正式进入 kernel 2.6.28 中。


reiserfs
号称最快的 FS。Linux 上第一个支援 journaling 的文件系统。


reiserfs (data)
加上 journal_data 功能的 reiserfs。


reiser4
reiserfs 的下一版。（尚未进入 kernel 中）


jfs
由 IBM 所开发的 journaling 型文件系统。已停止开发。


xfs
由 SGI 所开发的 journaling 型文件系统。


vfat
古老 DOS/Windows 文件系统，不支援 journaling。


ntfs
现今 Windows 的主流文件系统。在 Linux 上是经由 fuse 来支援 ntfs。


zfs
由 Sun 所开发的终极文件系统。在 Linux 上是经由 fuse 来支援 zfs。


btrfs
下一代 Linux 预设使用的文件系统。已进入 kernel 2.6.29 RC1 的测试分支中。


ext3，ext4，xfs和btrfs文件系统性能对比详情参考 : http://www.cnblogs.com/tommyli/p/3201047.html
应为原文：
http://www.ilsistemista.net/index.php/linux-a-unix/6-linux-filesystems-benchmarked-ext3-vs-ext4-vs-xfs-vs-btrfs.html?start=1
还有一篇相关介绍：
http://www.phoronix.com/scan.php?page=article&amp;item=ext4_benchmarks&amp;num=2
另一篇：http://tetralet.luna.com.tw/index.php?op=ViewArticle&amp;articleId=214&amp;blogId=1
以下部分主要关于ext4：
Linux kernel 自 2.6.28开 始正式支持新的文件系统 Ext4。 Ext4 是 Ext3 的改进版，修改了 Ext3 中部分重要的数据结构，而不仅仅像 Ext3 对Ext2 那样，只是增加了一个日志功能而已。Ext4 可以提供更佳的性能和可靠性，还有更为丰富的功能：

与 Ext3 兼容。执行若干条命令，就能从 Ext3 在线迁移到 Ext4，而无须重新格式化磁盘或重新安装系统。原有 Ext3 数据结构照样保留，Ext4 作用于新数据，当然，整个文件系统因此也就获得了 Ext4 所支持的更大容量。
更大的文件系统和更大的文件。较之 Ext3 目前所支持的最大 16TB 文件系统和最大2TB 文件，Ext4 分别支持 1EB（1,048,576TB， 1EB=1024PB， 1PB=1024TB）的文件系统，以及 16TB 的文件。
无限数量的子目录。Ext3 目前只支持 32,000 个子目录，而 Ext4 支持无限数量的子目录。
Extents。Ext3 采用间接块映射，当操作大文件时，效率极其低下。比如一个 100MB大小的文件，在 Ext3 中要建立 25,600 个数据块（每个数据块大小 为 4KB）的映射表。而 Ext4 引入了现代文件系统中流行的 extents 概念，每个 extent 为一组连续的数据块，上述文件则表示为“ 该文件数据保存在接下来的 25,600 个数据块中”，提高了不少效率。
多块分配。当写 入数据到 Ext3 文件系统中时，Ext3 的数据块分配器每次只能分配一个 4KB 的块，写一个 100MB 文件就要调用 25,600 次数据 块分配器，而 Ext4 的多块分配器“multiblock allocator”（mballoc） 支持一次调用分配多个数据块。
延迟分配。Ext3 的数据块分配策略是尽快分配，而 Ext4 和其它现代文件操作系统的策略是尽可能地延迟分配，直到文件在 cache 中写完才开始分配数据块并写入磁盘，这样就能优化整个文件的数据块分配，与前两种特性搭配起来可以显著提升性能。
快速 fsck。以前执行 fsck 第一步就会很慢，因为它要检查所有的 inode，现在 Ext4 给每个组的 inode 表中都添加了一份未使用 inode 的列表，今后 fsck Ext4 文件系统就可以跳过它们而只去检查那些在用的 inode 了。
日志校验。日志是最常用的部分，也极易导致磁盘硬件故障，而从损坏的日志中恢复数据会导致更多的数据损坏。Ext4 的日志校验功能可以很方便地判断日志数据是否损坏，而且它将 Ext3 的两阶段日志机制合并成一个阶段，在增加安全性的同时提高了性能。
“无日志”（No Journaling）模式。日志总归有一些开销，Ext4 允许关闭日志，以便某些有特殊需求的用户可以借此提升性能。
在线碎片整理。尽管延迟分配、多块分配和 extents 能有效减少文件系统碎片，但碎片还是不可避免会产生。Ext4 支持在线碎片整理，并将提供 e4defrag 工具进行个别文件或整个文件系统的碎片整理。
inode 相关特性。Ext4 支持更大的 inode，较之 Ext3 默认的 inode 大小 128 字节，Ext4 为了在 inode 中容纳更多的扩展属性（如纳秒时间戳 或 inode 版本），默认 inode 大小为 256 字节。Ext4 还支持快速扩展属性（fast extended attributes） 和 inode 保留（inodes reservation）。
持久预分配（Persistent preallocation）。P2P 软件为了保证下载文件有足够的空间存放，常常会预先创建一个与所下载文件大小相同的空文件，以免未来的数小时或数天之内磁盘空间不足导致下载失 败。Ext4 在文件系统层面实现了持久预分配并提供相应的API（libc 中的 posix_fallocate()），比应用软件自己实现更有效率。
默认启用 barrier。磁盘 上配有内部缓存，以便重新调整批量数据的写操作顺序，优化写入性能，因此文件系统必须在日志数据写入磁盘之后才能写 commit 记录， 若 commit 记录写入在先，而日志有可能损坏，那么就会影响数据完整性。Ext4 默认启用barrier，只有当 barrier 之前的数据全部写入磁盘，才能写 barrier 之后的数据。（可通过 “mount -o barrier=0” 命令禁用该特性。）

]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>ntfs</tag>
        <tag>ext2</tag>
        <tag>ext3</tag>
        <tag>ext4</tag>
        <tag>reiserfs</tag>
        <tag>reiser4</tag>
        <tag>jfs</tag>
        <tag>xfs</tag>
        <tag>vfat</tag>
        <tag>zfs</tag>
        <tag>btrfs</tag>
      </tags>
  </entry>
  <entry>
    <title>一切皆可查的 find</title>
    <url>/2012/05/07/linux-find-beginner/</url>
    <content><![CDATA[一切皆可查的 find.. _linux_find_beginner:
find命令用来在指定目录下查找文件，功能相当之强大。
官方定义为：

find - search for files in a directory hierarchy

Linux的哲学是一切皆文件，那么find的使命就是一切皆可查。
语法使用语法为：
$ find [-H] [-L] [-P] [-D debugopts] [-Olevel] [path...] [expression]

比较常用的几个参数为：

-exec &lt;执行指令&gt;：假设find指令的回传值为True，就执行该指令；
-size &lt;文件大小&gt;：查找符合指定的文件大小的文件；
-mtime &lt;24小时&gt;：查找在指定时间曾被更改过的文件或目录，单位以24小时计算；-name&lt;范本样式&gt;：指定字符串作为寻找文件或目录的范本样式；
-type &lt;文件类型&gt;：只寻找符合指定的文件类型的文件；

无参数如果使用该命令时，不设置任何参数，则find命令将在当前目录下查找子目录与文件,并且将查找到的子目录和文件全部进行显示。
$ ls -ltotal 310M-rw-rw-r-- 1 user user  10M Mar 21 20:01 adrwxrwxr-x 2 user user   22 Mar 21 20:01 aa-rw-rw-r-- 1 user user 100M Mar 21 20:01 b-rw-rw-r-- 1 user user 200M Mar 21 20:01 c$ find ../a./b./c./test



查找小于，等于和大于100MB的文件通过-size大小来查找文件
$ find . -size -100M../a./aa$ find . -size 100M./b$ find . -size +100M./c./aa/d

查找多长时间修改过可以通过参数-mtime来查找文件的修改时间，比如如下可以查找当前目录下最近60天没有被修改的文件。
$ find . -mtime +60# 最近2天以内未修改$ find . –mtime -2



如何删除扩展名为.tar.gz并且大于100M的压缩文件？当你不想意外删除文件时，那么当执行下列命令要小心点。最好的方法是利用ls -l去执行下列相同命令以确保当执行rm命令时，你知道什么文件会被删除。 
$ find / -type f -name *.tar.gz -size +100M -exec ls -l {} \; $ find / -type f -name *.tar.gz -size +100M -exec rm -f {} \;




稍微复杂但是很有用的命令 我经常把 find 命令和他的选项 exec一起使用，比如我想查找一个目录中的所有文件并将其更改其权限。可以通过以下简单命令完成：
$ find /path/ -type f -exec chmod 644 {} \;

这个命令会递归搜索指定目录内/path/下的所有文件，并对找到的文件执行 chmod 命令。
]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>rm</tag>
        <tag>Linux炫技</tag>
        <tag>ls</tag>
        <tag>find</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux 的 find 命令</title>
    <url>/2012/05/07/linux-find-beginnner/</url>
    <content><![CDATA[Linux 之 find 命令find命令用来在指定目录下查找文件，功能相当之强大。
官方定义为：

find - search for files in a directory hierarchy

Linux的哲学是一切皆文件，那么find的使命就是一切皆可查。
语法使用语法为：
$ find [-H] [-L] [-P] [-D debugopts] [-Olevel] [path...] [expression]

比较常用的几个参数为：

-exec &lt;执行指令&gt;：假设find指令的回传值为True，就执行该指令；
-size &lt;文件大小&gt;：查找符合指定的文件大小的文件；
-mtime &lt;24小时&gt;：查找在指定时间曾被更改过的文件或目录，单位以24小时计算；-name&lt;范本样式&gt;：指定字符串作为寻找文件或目录的范本样式；
-type &lt;文件类型&gt;：只寻找符合指定的文件类型的文件；

1⃣ 无参数如果使用该命令时，不设置任何参数，则find命令将在当前目录下查找子目录与文件,并且将查找到的子目录和文件全部进行显示。
$ ls -ltotal 310M-rw-rw-r-- 1 user user  10M Mar 21 20:01 adrwxrwxr-x 2 user user   22 Mar 21 20:01 aa-rw-rw-r-- 1 user user 100M Mar 21 20:01 b-rw-rw-r-- 1 user user 200M Mar 21 20:01 c$ find ../a./b./c./test



2⃣ 查找小于，等于和大于100MB的文件通过-size大小来查找文件
$ find . -size -100M../a./aa$ find . -size 100M./b$ find . -size +100M./c./aa/d

3⃣ 查找多长时间修改过可以通过参数-mtime来查找文件的修改时间，比如如下可以查找当前目录下最近60天没有被修改的文件。
$ find . -mtime +60# 最近2天以内未修改$ find . –mtime -2



4⃣ 稍微复杂但是很有用的命令 我经常把 find 命令和他的选项 exec一起使用，比如我想查找一个目录中的所有文件并将其更改其权限。可以通过以下简单命令完成：
$ find /path/ -type f -exec chmod 644 {} \;

这个命令会递归搜索指定目录内/path/下的所有文件，并对找到的文件执行 chmod 命令。
]]></content>
      <categories>
        <category>CentOS</category>
        <category>Fedora</category>
        <category>Linux</category>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>find</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux find命令print0和xargs命令-0</title>
    <url>/2011/05/07/linux-find-print/</url>
    <content><![CDATA[find中的-print0和xargs中-0的奥妙默认情况下, find 每输出一个文件名, 后面都会接着输出一个换行符 (‘\n’), 因此我们看到的 find 的输出都是一行一行的:
$ ls -ltotal 0-rw-r--r-- 1 root root 0 2010-08-02 18:09 file1.log-rw-r--r-- 1 root root 0 2010-08-02 18:09 file2.log$ find -name '*.log'./file2.log./file1.log

比如我想把所有的 .log 文件删掉, 可以这样配合 xargs 一起用:
$ find -name '*.log'./file2.log./file1.log$ find -name '*.log' | xargs rm$ find -name '*.log'

嗯, 不错, find+xargs 真的很强大. 然而:
$ ls -ltotal 0-rw-r--r-- 1 root root 0 2010-08-02 18:12 file 1.log-rw-r--r-- 1 root root 0 2010-08-02 18:12 file 2.log$ find -name '*.log'./file 1.log./file 2.log$ find -name '*.log' | xargs rmrm: cannot remove `./file': No such file or directoryrm: cannot remove `1.log': No such file or directoryrm: cannot remove `./file': No such file or directoryrm: cannot remove `2.log': No such file or directory

原因其实很简单, xargs 默认是以空白字符 (空格, TAB, 换行符) 来分割记录的, 因此文件名 ./file 1.log 被解释成了两个记录 ./file 和 1.log, 不幸的是 rm 找不到这两个文件.
为了解决此类问题, 聪明的人想出了一个办法, 让 find 在打印出一个文件名之后接着输出一个 NULL 字符 (‘\0’) 而不是换行符, 然后再告诉 xargs 也用 NULL 字符来作为记录的分隔符. 这就是 ** find 的 -print0 和 xargs 的 -0 **的来历吧.
$ ls -ltotal 0-rw-r--r-- 1 root root 0 2010-08-02 18:12 file 1.log-rw-r--r-- 1 root root 0 2010-08-02 18:12 file 2.log$ find -name '*.log' -print0 | xargs -0 rm$ find -name '*.log'

你可能要问了, 为什么要选 ‘\0’ 而不是其他字符做分隔符呢? 这个也容易理解: 一般的编程语言中都用 ‘\0’ 来作为字符串的结束标志, 文件的路径名中不可能包含 ‘\0’ 字符.
]]></content>
      <categories>
        <category>Linux</category>
        <category>Shell</category>
      </categories>
      <tags>
        <tag>find</tag>
        <tag>print</tag>
        <tag>xargs</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux 的 find 命令</title>
    <url>/2012/05/07/linux-find/</url>
    <content><![CDATA[Linux 之 find 命令find命令用来在指定目录下查找文件，功能相当之强大。
官方定义为：

find - search for files in a directory hierarchy

Linux的哲学是一切皆文件，那么find的使命就是一切皆可查。
语法使用语法为：
$ find [-H] [-L] [-P] [-D debugopts] [-Olevel] [path...] [expression]

比较常用的几个参数为：

-exec &lt;执行指令&gt;：假设find指令的回传值为True，就执行该指令；
-size &lt;文件大小&gt;：查找符合指定的文件大小的文件；
-mtime &lt;24小时&gt;：查找在指定时间曾被更改过的文件或目录，单位以24小时计算；-name&lt;范本样式&gt;：指定字符串作为寻找文件或目录的范本样式；
-type &lt;文件类型&gt;：只寻找符合指定的文件类型的文件；

无参数如果使用该命令时，不设置任何参数，则find命令将在当前目录下查找子目录与文件,并且将查找到的子目录和文件全部进行显示。
$ ls -ltotal 310M-rw-rw-r-- 1 user user  10M Mar 21 20:01 adrwxrwxr-x 2 user user   22 Mar 21 20:01 aa-rw-rw-r-- 1 user user 100M Mar 21 20:01 b-rw-rw-r-- 1 user user 200M Mar 21 20:01 c$ find ../a./b./c./test



查找小于，等于和大于100MB的文件通过-size大小来查找文件
$ find . -size -100M../a./aa$ find . -size 100M./b$ find . -size +100M./c./aa/d

查找多长时间修改过可以通过参数-mtime来查找文件的修改时间，比如如下可以查找当前目录下最近60天没有被修改的文件。
$ find . -mtime +60# 最近2天以内未修改$ find . –mtime -2



稍微复杂但是很有用的命令 我经常把 find 命令和他的选项 exec一起使用，比如我想查找一个目录中的所有文件并将其更改其权限。可以通过以下简单命令完成：
$ find /path/ -type f -exec chmod 644 {} \;

这个命令会递归搜索指定目录内/path/下的所有文件，并对找到的文件执行 chmod 命令。
一个搜索文件的好例子是：
# find /home/user -type f

这个命令会搜索 /home/user 目录下的所有文件。find 命令真的很强大，你可以传递更多选项给它使得你的搜索更加详细。如果你想搜索超过特定大小的文件，可以使用：
# find . -type f -size 10M

上面的命令会搜索当前目录中所有大于 10M 的文件。确保不要在你 Linux 系统的根目录运行该命令，因为这可能导致你的机器 I/O 瓶颈。
选项-amin&lt;分钟&gt;：查找在指定时间曾被存取过的文件或目录，单位以分钟计算；-anewer&lt;参考文件或目录&gt;：查找其存取时间较指定文件或目录的存取时间更接近现在的文件或目录；-atime&lt;24小时数&gt;：查找在指定时间曾被存取过的文件或目录，单位以24小时计算；-cmin&lt;分钟&gt;：查找在指定时间之时被更改过的文件或目录；-cnewer&lt;参考文件或目录&gt;查找其更改时间较指定文件或目录的更改时间更接近现在的文件或目录；-ctime&lt;24小时数&gt;：查找在指定时间之时被更改的文件或目录，单位以24小时计算；-daystart：从本日开始计算时间；-depth：从指定目录下最深层的子目录开始查找；-expty：寻找文件大小为0 Byte的文件，或目录下没有任何子目录或文件的空目录；-false：将find指令的回传值皆设为False；-fls&lt;列表文件&gt;：此参数的效果和指定ls参数类似，但会把结果保存为指定的列表文件；-follow：排除符号连接；-fprint&lt;列表文件&gt;：此参数的效果和指定-print参数类似，但会把结果保存成指定的列表文件；-fprint0&lt;列表文件&gt;：此参数的效果和指定-print0参数类似，但会把结果保存成指定的列表文件；-fprintf&lt;列表文件&gt;&lt;输出格式&gt;：此参数的效果和指定-printf参数类似，但会把结果保存成指定的列表文件；-fstype&lt;文件系统类型&gt;：只寻找该文件系统类型下的文件或目录；-gid&lt;群组识别码&amp;gt;：查找符合指定之群组识别码的文件或目录；-group&lt;群组名称&gt;：查找符合指定之群组名称的文件或目录；-ilname&lt;范本样式&gt;：此参数的效果和指定-lname参数类似，但忽略字符大小写的差别；-iname&lt;范本样式&gt;：此参数的效果和指定-name参数类似，但忽略字符大小写的差别；-inum&lt;inode编号&gt;：查找符合指定的inode编号的文件或目录；-ipath&lt;范本样式&gt;：此参数的效果和指定-path参数类似，但忽略字符大小写的差别；-iregex&lt;范本样式&gt;：此参数的效果和指定-regexe参数类似，但忽略字符大小写的差别；-links&lt;连接数目&gt;：查找符合指定的硬连接数目的文件或目录；-iname&lt;范本样式&gt;：指定字符串作为寻找符号连接的范本样式；-ls：假设find指令的回传值为Ture，就将文件或目录名称列出到标准输出；-maxdepth&lt;目录层级&gt;：设置最大目录层级；-mindepth&lt;目录层级&gt;：设置最小目录层级；-mmin&lt;分钟&gt;：查找在指定时间曾被更改过的文件或目录，单位以分钟计算；-mount：此参数的效果和指定-xdev相同；-newer&lt;参考文件或目录&gt;：查找其更改时间较指定文件或目录的更改时间更接近现在的文件或目录；-nogroup：找出不属于本地主机群组识别码的文件或目录；-noleaf：不去考虑目录至少需拥有两个硬连接存在；-nouser：找出不属于本地主机用户识别码的文件或目录；-ok&lt;执行指令&gt;：此参数的效果和指定-exec类似，但在执行指令之前会先询问用户，若回答y或Y，则放弃执行命令；-path&lt;范本样式&gt;：指定字符串作为寻找目录的范本样式；-perm&lt;权限数值&gt;：查找符合指定的权限数值的文件或目录；-print：假设find指令的回传值为Ture，就将文件或目录名称列出到标准输出。格式为每列一个名称，每个名称前皆有&amp;ldquo;./&amp;rdquo;字符串；-print0：假设find指令的回传值为Ture，就将文件或目录名称列出到标准输出。格式为全部的名称皆在同一行；-printf&lt;输出格式&gt;：假设find指令的回传值为Ture，就将文件或目录名称列出到标准输出。格式可以自行指定；-prune：不寻找字符串作为寻找文件或目录的范本样式;-regex&lt;范本样式&gt;：指定字符串作为寻找文件或目录的范本样式；-true：将find指令的回传值皆设为True；-uid&lt;用户识别码&gt;：查找符合指定的用户识别码的文件或目录；-used&lt;日数&gt;：查找文件或目录被更改之后在指定时间曾被存取过的文件或目录，单位以日计算；-user&lt;拥有者名称&gt;：查找符和指定的拥有者名称的文件或目录；-xdev：将范围局限在先行的文件系统中；-xtype&lt;文件类型&gt;：此参数的效果和指定type参数类似，差别在于它针对符号连接检查。





如何查找在最近几天没有被修改过的文件？
下面这条命令会列出在当前目录下在最近60天没有被修改过文件
# find . -mtime +60
如何查找在最近几天被修改的文件？
下面这条命令会列出在当前目录下在最近2天被修改过文件
# find . –mtime -2
所以+-可以查找未被修改和修改过的文件。
如何删除目录/home/aaa/test中扩展名为.tar.gz并且大于100M的压缩文件？先来一个例子：
我想查找后缀为tar.gz的，大于100M的文件，并详细查看，可以使用
find /home/aaa/test -type f -name *.tar.gz -size +100M -exec ls -l {} ;
find / home/aaa/test -type f -name *.tar.gz -size +100M -exec rm -f {} ;
find
◦find [搜索范围] [匹配条件] 
◦1. find /etc –name passwd 
◦2. 
◦3. find / -user yourname 
◦4. find / -amin/-cmin/-mmin 
amin – access访问时间 
cmin – change 文件属性
mmin – modify 文件内容 
◦ 5. find / -type f/d/l 文件/目录/软链接
locate
◦locate filename 
◦/var/lib/mlocate/mlocate.db &amp;&amp; updated 
which &amp;&amp; whereis 查找命令
在home目录查找以.txt结尾的文件名find /home -name "*.txt"

在home目录查找以.txt结尾的文件名，但是忽略大小写find /home -iname "*.txt"

在home目录查找以.txt和.pdf结尾的文件名，但是忽略大小写find /home -name "*.txt" -o -name ".pdf"

匹配文件路径或者文件find . -path "*path*"

否定参数找出home目录下不是以.txt结尾的文件
find /home ! -name "*.txt"

根据文件类型进行搜索find . -type 类型参数

其中类型参数如下：

f 普通文件
l 符号链接
d 目录
c 字符设备
b 块设备
s 套接字
p FIFO

在home目录查找以.txt结尾的文件名，但是忽略大小写向下最大深度限制为3
find . -maxdepth 3 -type f

根据文件时间戳进行搜索find . -type f 时间戳

每个文件都有3个时间戳

访问时间 -atime 天 -amin 分钟 ：用户最后一次访问时间
修改时间 -mtime 天 -mmin 分钟 ：文件最后一次修改时间
变化时间 -ctime 天 -cmin 分钟 ：文件数据元（如权限）最后一次修改时间

搜索最近7天内访问过的文件find . -type f -atime -7

搜索恰好7天访问过的文件find . -type f -atime 7

搜索超过7天内访问过的文件find . -type f -atime +7
]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>find</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux下 修正GDBus 错误</title>
    <url>/2014/06/09/linux-fix-GDBusError/</url>
    <content><![CDATA[简介How to fix GDBus Error org freedesktop PolicyKit1 Error Failed An authentication agent
On XFCE DesktopTo fix this go to Application Menu &gt; Settings &gt; Session and Startup
uncheck  the LXPolKit in Application Autostart TAB.
On MATE Desktop:System –&gt; Control Center –&gt; Startup Applications –&gt; Startup Programs
The same way to uncheck the LXPolKit.
]]></content>
      <categories>
        <category>MATE</category>
        <category>Fedora</category>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>GDBus</tag>
        <tag>PolicyKit</tag>
        <tag>Mate</tag>
        <tag>Xfce</tag>
      </tags>
  </entry>
  <entry>
    <title>好看的字体</title>
    <url>/2013/06/09/linux-font/</url>
    <content><![CDATA[好看的字体inconsolata这个字体个人非常推崇，安装方法也很简单。
Fedorasudo dnf install levien-inconsolata-fonts

Ubuntusudo apt-get install ttf-inconsolata


中文输入法Fedora中安装中文输入法安装中文输入法的过程如下：1）安装输入法  yum install fcitx 安装完小企鹅输入法2）安装支持包：yum install fcitx-table-chinese3）【也可以去软件管理工具界面，手动安装 fedora开始菜单-&gt;computer-&gt;System Setting-&gt;Softwaer Manage-&gt;Get and Remove Software里面fcitx-table-chinese chinese table of FCITX】4）logout 开始菜单-&gt;Applications-&gt;Settings-&gt;InputMethod Selector -&gt; 双击Use FCITX，等LOGOUT按钮变亮，点击Logout。即将注销系统。 重新登录后，ctrl+space即可切换至中文输入法。
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>font</tag>
      </tags>
  </entry>
  <entry>
    <title>VirtualBox虚拟机Linux忘记密码</title>
    <url>/2014/05/06/linux-forget-passed/</url>
    <content><![CDATA[
重启ubuntu，随即长按shirft进入grub菜单；
选择recovery mode，按”e”键进入编辑页面；
将ro single替换为rw single init=/bin/bash；
按ctrl+x进入单用户模式，当前用户即为root；
到/etc目录下修改sudoers权限：chmod 0440 sudoers，搞定；
按ctrl+alt+del重启；

]]></content>
      <categories>
        <category>ubuntu</category>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>ubuntu</tag>
        <tag>passwd</tag>
        <tag>recovery</tag>
        <tag>single</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux命令fortune</title>
    <url>/2011/02/12/linux-fortunes-misc/</url>
    <content><![CDATA[探索Linux世界的智慧——Fortunes命令在Linux中，有一条神奇的命令连接着智慧与幽默，那就是fortunes命令。
看似普通的指令，背后却藏匿着千言万语，无论是名人箴言还是妙趣横生的笑话，在这里都能找到它们的踪迹。
另外最重要的，还可以根据自己的需求进行增删，目前就用基于唐诗宋词的库。
fortune并非只是简单的一句话，而是承载着古今中外智慧的涌泉。
每次执行，它都会带来截然不同的感受。或许是一位哲人的深刻格言，或是一句调皮的笑话，或者唐诗，或者宋词，与先贤对话，岂不快哉。
最简单的方法就是把这个命令，加到.bashrc文件中，每次启动，总会有触动。
$ fortune 何以称英雄？识以领其先　　　　－　清·袁枚$ fortune一件作品的固有力量从来不会被长期地埋没或禁锢。一件艺术品可能被时间遗忘，可能遭到查禁，可能被埋进棺材，但威力强大的东西总要战胜没有过大前途的东西。　　　　－　茨威格$ fortuneYow!  We're going to a new disco!



]]></content>
      <categories>
        <category>Linux炫技</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>fortune</tag>
      </tags>
  </entry>
  <entry>
    <title>放空一下自我  free</title>
    <url>/2011/03/19/linux-free-beginner/</url>
    <content><![CDATA[放空一下自我  free.. _linux_free_beginner:
**free**这个命令在Linux系统监控的工具里面，算是使用的比较多的一个。
使用_man_查看可知，官方含义为：

Display amount of free and used memory in the system

也就是显示可用、易用的系统内存，它直接读取/proc/meminfo文件。
默认的效果先看下不加任何参数的时候，free的效果：
$ free              total        used        free      shared  buff/cache   availableMem:       32664832    15667736      674136      464892    16322960    15803156Swap:      16449532     3039756    13409776

看起来很多的样子，但是不直观，我比较喜欢加上-h参数。
使用易读的参数-h参数，跟前面的df等命令类似，此处的h表示human being的含义方便人类阅读。 除了这个还有-b,-k,-m,-g，含义分别为按照字节、KB、MB、GB的格式来显示。
$ free -h              total        used        free      shared  buff/cache   availableMem:            31G         14G        655M        453M         15G         15GSwap:           15G        2.9G         12G

WoW，此时的显示简直好简洁。
说下其中的含义:

total : 表示总的物理内存大小，比如上面的就表示31GB的内存
used ：表示已经使用的内存大小，比如上面的就是使用了14GB
free ：表示可用多少
shared：表示多个进程共享的内存大小
buff/cache：表示磁盘缓存的大小，这里有两个方面，buff和cache，两个的含义不同
buff ：还没有写入磁盘
cache：从磁盘读取的方便下一次使用
这里就设计到Linux的设计哲学，比如读取一个100G的文件，第一次所使用的时间总归是后面再次读取的时间的好几倍，当然前提是没有释放掉caches


available：当然含义为可用的内存容量大小

间隔显示内存状态还有一个比较常用的就是，如果你希望过一段时间就看下free的情况，OK，使用参数-s，后面跟的单位是秒，也就是每个几秒，统计一下使用的内存情况，比如我们每个2s，显示一下
$ free -s 2              total        used        free      shared  buff/cache   availableMem:       32664832    15668528      670964      464892    16325340    15802360Swap:      16449532     3039756    13409776              total        used        free      shared  buff/cache   availableMem:       32664832    15669760      669724      464892    16325348    15801124Swap:      16449532     3039756    13409776              total        used        free      shared  buff/cache   availableMem:       32664832    15670220      669248      464892    16325364    15800652Swap:      16449532     3039756    13409776              total        used        free      shared  buff/cache   availableMem:       32664832    15669264      670204      464892    16325364    15801624Swap:      16449532     3039756    13409776



查看meminfo文件$ cat /proc/meminfo



其实free读取的就是这个文件的某些信息，可以通过同步监控这个文件来check free的状态。
]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>free</tag>
        <tag>硬件信息</tag>
        <tag>RAM</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux下清理缓存，以释放内存</title>
    <url>/2013/06/09/linux-free-memory/</url>
    <content><![CDATA[今天查看开发使用的机器，内存使用了接近90%，清理一下缓存，效果立竿见影，按如下顺序操作即可：

当前内存使用情况：free
sync（一定要在第三部之前运行这个命令）
echo 3 &gt; /proc/sys/vm/drop_caches

]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>caches</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux free命令</title>
    <url>/2011/03/19/linux-free/</url>
    <content><![CDATA[Linux 查看系统内存**free**这个命令在Linux系统监控的工具里面，算是使用的比较多的一个。
使用_man_查看可知，官方含义为：

Display amount of free and used memory in the system

也就是显示可用、易用的系统内存，它直接读取/proc/meminfo文件。
默认的效果先看下不加任何参数的时候，free的效果：
$ free              total        used        free      shared  buff/cache   availableMem:       32664832    15667736      674136      464892    16322960    15803156Swap:      16449532     3039756    13409776

看起来很多的样子，但是不直观，我比较喜欢加上-h参数。
使用易读的参数-h参数，跟前面的df等命令类似，此处的h表示_human being_的含义方便人类阅读。 除了这个还有_-b,-k,-m,-g_，含义分别为按照_字节、KB、MB、GB_的格式来显示。
$ free -h              total        used        free      shared  buff/cache   availableMem:            31G         14G        655M        453M         15G         15GSwap:           15G        2.9G         12G

Wow，此时的显示简直好简洁。
说下其中的含义:

total : 表示总的物理内存大小，比如上面的就表示31GB的内存

used ：表示已经使用的内存大小，比如上面的就是使用了14GB

free ：表示可用多少

shared：表示多个进程共享的内存大小

buff/cache：表示磁盘缓存的大小，这里有两个方面，buff和cache，两个的含义不同

buff ：something that has yet to be ‘writeen’ to disk ,还没有写入磁盘
cache: something that had been ‘read’ from the disk and store for later user，从磁盘读取的方便下一次使用
这里就设计到Linux的设计哲学，比如读取一个100G的文件，第一次所使用的时间总归是后面再次读取的时间的好几倍，当然前提是没有释放掉caches


available：当然含义为可用的内存容量大小


间隔显示内存状态还有一个比较常用的就是，如果你希望过一段时间就看下free的情况，OK，使用参数-s，后面跟的单位是秒，也就是每个几秒，统计一下使用的内存情况，比如我们每个2s，显示一下
$ free -s 2              total        used        free      shared  buff/cache   availableMem:       32664832    15668528      670964      464892    16325340    15802360Swap:      16449532     3039756    13409776              total        used        free      shared  buff/cache   availableMem:       32664832    15669760      669724      464892    16325348    15801124Swap:      16449532     3039756    13409776              total        used        free      shared  buff/cache   availableMem:       32664832    15670220      669248      464892    16325364    15800652Swap:      16449532     3039756    13409776              total        used        free      shared  buff/cache   availableMem:       32664832    15669264      670204      464892    16325364    15801624Swap:      16449532     3039756    13409776



查看meminfo文件$ cat /proc/meminfo



其实free读取的就是这个文件的某些信息，可以通过同步监控这个文件来check free的状态。
]]></content>
      <categories>
        <category>Linux</category>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>free</tag>
        <tag>RAM</tag>
      </tags>
  </entry>
  <entry>
    <title>GLib 编译应用程序</title>
    <url>/2011/12/18/linux-glib/</url>
    <content><![CDATA[编译Glib应用程序为了编译一个使用了Glib的应用程序，需要保证编译程序所用的包含保存Glib头文件的目录，还需要链接Glib库本身。
程序代码
#include &lt;glib.h&gt;gint main(gint argc,gchar *argv[]){    g_print("Hello, we will compiled and linked with GLibn");    return 0;}

程序说明

g_print函数是Glib自己的printf版本，但是进行了灵巧的变化，你可以用自己的代码覆盖调用g_print时执行的缺省Glib代码；
关于gint都是为了以后真正用的时候好习惯；
编译使用gcc，当然也可以使用cc（最开始发明和发布c语言时使用的名称），对于多个操作系统转换时，cc总体上更好一些。

程序编译
gcc -o main main.c `pkg-config glib-2.0 –cflags –libs`
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>gtk</tag>
        <tag>glib</tag>
        <tag>pkg-config</tag>
        <tag>gtk-config</tag>
      </tags>
  </entry>
  <entry>
    <title>GNU 实用程序Shell</title>
    <url>/2012/01/15/linux-gnu-shell/</url>
    <content><![CDATA[GNU实用程序除了使用内核控制硬件设备外，计算机操作系统还需要使用程序执行标准功能，所以，除了Linux系统内核，我们还需要一些系统实用程序。
GNU组织（GNU代表GNU’s Not Unix）开发了一个完整的Unix使用程序集，这些实用程序的开发基于一种新的软件思想，成为开源软件（OSS）。
Linus的Linux内核与GNU操作系统实用程序的结合诞生了一个完整的、功能强大的免费操作系统。所有Linux实际上应该是GNU/Linux。
核心GNU实用程序成为coreutils软件包，主要包括：

处理文件的实用程序；
操作文本的实用程序；
管理进程的实用程序；

Shell是一个特殊的交互式使用程序，它为用户提供了一种启动程序、管理文件系统中的文件和管理运行在Linux系统上的进程的方式。Shell的核心是命令提示符，命令提示符是shell用于交互的组成部分，它允许输入文本命令，解释命令，然后再内核中执行命令。
目前大部分发行版默认的是Bash shell，当然还有很多shell版本。



Shell
描述



ash
ash shell是由Kenneth Almquist编写的，Linux中占用系统资源最少的一个小shell，它只包含24个内部命令，因而使用起来很不方便。


bash
bash是Linux系统默认使用的shell，它由Brian Fox和Chet Ramey共同完成，是Bourne Again Shell的缩写，内部命令一共有40个（可使用help命令查看）。Linux使用它作为默认的shell是因为它有诸如以下的特色： 可以使用类似DOS下面的doskey的功能，用方向键查阅和快速输入并修改命令; 自动通过查找匹配的方式给出以某字符串开头的命令; 包含了自身的帮助功能，你只要在提示符下面键入help就可以得到相关的帮助。


ksh
ksh是Korn shell的缩写，由Eric Gisin编写，共有42条内部命令。该shell最大的优点是几乎和商业发行版的ksh完全兼容，这样就可以在不用花钱购买商业版本的情况下尝试商业版本的性能了。


csh
csh是Linux比较大的内核，它由以William Joy为代表的共计47位作者编成，共有52个内部命令。该shell其实是指向/bin/tcsh这样的一个shell，也就是说，csh其实就是tcsh


zsh
zch是Linux最大的shell之一，由Paul Falstad完成，共有84个内部命令。如果只是一般的用途，是没有必要安装这样的shell的。


]]></content>
      <categories>
        <category>Linux</category>
        <category>Shell</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>shell</tag>
        <tag>ash</tag>
        <tag>bash</tag>
        <tag>csh</tag>
        <tag>GNU</tag>
        <tag>ksh</tag>
        <tag>zsh</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux gnuplot安装与启动</title>
    <url>/2013/03/20/linux-gnuplot-0-install-startup/</url>
    <content><![CDATA[安装gnuplot或许是这个世界上用来分析和可视化数据的最强劲的工具，主要用来绘制2D/3D的数据或者函数图像，但是也包含数学计算、拟合等功能。
gnuplot全名应该读作 “new plot”。
所有的主流 Linux 发行版都包含 gnuplot，因此在 Linux 上安装很简单，比如在Redhat系列输入yum install gnuplot即可，而Debian系列输入apt install gnuplot即可。
对于MacOSX系统，可以通过MacPorts和Homebrew来进行安装。
在 Windows 下，可以直接到 gnuplot 在 sourceforge 的下载网页Download下载新版本（选择包含win64的exe文件即可），下载后即可安装使用。
启动gnuplot是基于命令行的交互式绘图软件。打 一个终端，输入 gnuplot，随着程序启动，会出 现下面的信息：（如果是在 Windows 电脑上，双击 gnuplot.exe 后会自动打 一个命令行窗口）
$ gnuplot	G N U P L O T	Version 5.2 patchlevel 7    last modified 2019-05-29	Copyright (C) 1986-1993, 1998, 2004, 2007-2018	Thomas Williams, Colin Kelley and many others	gnuplot home:     http://www.gnuplot.info	faq, bugs, etc:   type "help FAQ"	immediate help:   type "help"  (plot window: hit 'h')Terminal type is now 'qt'gnuplot&gt;

欢迎信息包括gnuplot的版本，修改日期，版权等信息。此时就可以开始输入命令绘图了，或者输入quit和exit退出交互环境。
参考主要参考《Gnuplot In Action》和《使用 gnuplot 科学作图》，请支持正版。
]]></content>
      <categories>
        <category>Linux</category>
        <category>gnuplot</category>
        <category>gnuplot in action</category>
        <category>understanding data with graphs</category>
      </categories>
      <tags>
        <tag>gnuplot</tag>
        <tag>gnu</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux gnuplot的数学表达式</title>
    <url>/2013/03/20/linux-gnuplot-0-prepare-math/</url>
    <content><![CDATA[数学表达式在gnuplot 里面表达数学公式是很简单的，很多与C语言类似，比如

加、减、乘、除、乘方 用 +，-，，/，* 表示
整数和浮点数 和 C 语 类似
复数用包含在花括号内的 对实数表示，例如{3,5}表示 3 + 5i
gnuplot 含有丰富的数学函数，格式和 C 语 几乎相同。对于实数和复数，函数名是一样的。 下面的链接可以看到预定义的函数列表： http://www.gnuplot.info/docs_4.2/gnuplot.html#x1-5300013.1
自定义函数 自定义函数很容易，例如 f(x)=x+1 定义一个一元函数，f(x,y)=x+y 定义一个二元函数。
π（圆周率） π 在 gnuplot 里用 pi 表示。

代码如下所示：
gnuplot&gt; print 3+811gnuplot&gt; print 9/42gnuplot&gt; print 9.0/42.25gnuplot&gt; f(x) = x**3gnuplot&gt; print f(4)64gnuplot&gt; f(x,y) = x**3+y**2gnuplot&gt; print f(3,4)43gnuplot&gt;

其中print命令用于把结果输出到屏幕上。
参考主要参考《Gnuplot In Action》和《使用 gnuplot 科学作图》，请支持正版。
]]></content>
      <categories>
        <category>Linux</category>
        <category>gnuplot</category>
        <category>gnuplot in action</category>
        <category>understanding data with graphs</category>
      </categories>
      <tags>
        <tag>gnuplot</tag>
        <tag>gnu</tag>
      </tags>
  </entry>
  <entry>
    <title>使用gnuplot来理解数据</title>
    <url>/2013/03/20/linux-gnuplot-1-basic-1-understanding-data-with-gnuplot/</url>
    <content><![CDATA[使用gnuplot来理解数据gnuplot或许是这个世界上用来分析和可视化数据的最强劲的工具。
gnuplot绘制的图形不仅可以自己使用，还可以用于出版和演示。
gnuplot 的优点
稳定、成熟、积极维护中
自由的开源代码
适用于很多平台Windows、Linux 、Mac OS X
生成抛光性很好的图像
支持大多数通用的图像格式
可以直接读取文件作为输入
有处理大数据集的能力（轻松处理百万级数据点），且速度很快
资源消耗少

一些有用的库
The data set collection and the Data and Story Library (DASL) at StatLib(http://lib.stat.cmu.edu)
The UCI Machine Learning Repository at UC Irvine (http://www.ics.uci.edu/~mlearn/MLRepository.html)
R. J. Hyndman’s Time Series Data Library (http://www-personal.buseco.monash.edu.au/~hyndman/TSDL)
The Exploring Data site at Central Queensland University (http://exploringdata.cqu.edu.au)

使用gnuplotgnuplot &gt; plot "datafile" using 1:2 with boxes

在终端输入gnuplot后，就会进入一个交互环境，在该环境就可以输入命令了。
绘制正弦曲线gnuplot &gt; plot sin(x) with line linetype 3 linewidth 2


同时绘制多条曲线
gnuplot &gt; plot sin(x) title 'sin(x)' with line linetype 3 linewidth 2, cos(x) title 'cos(x)' with line linetype 2 linewidth 2


参考主要参考《Gnuplot In Action》和《使用 gnuplot 科学作图》，请支持正版。
]]></content>
      <categories>
        <category>Linux</category>
        <category>gnuplot</category>
        <category>gnuplot in action</category>
        <category>understanding data with graphs</category>
      </categories>
      <tags>
        <tag>gnuplot</tag>
        <tag>gnu</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux GNUplot</title>
    <url>/2013/03/20/linux-gnuplot-1-basic-2-essential-gunplot/</url>
    <content><![CDATA[Chapter 2 is a quick start tutorial on gnuplot—you will learn everything tobecome productive with gnuplot right here
参考主要参考《Gnuplot In Action》，请支持正版。
]]></content>
      <categories>
        <category>Linux</category>
        <category>gnuplot</category>
        <category>gnuplot in action</category>
        <category>understanding data with graphs</category>
      </categories>
      <tags>
        <tag>gnuplot</tag>
        <tag>gnu</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux GNUplot</title>
    <url>/2013/03/20/linux-gnuplot-1-basic-3-working-with-data/</url>
    <content><![CDATA[Chapter 3 goes into more depth on the way gnuplot handles data. We willtalk about file handling, data transformations, and math.
参考主要参考《Gnuplot In Action》，请支持正版。
]]></content>
      <categories>
        <category>Linux</category>
        <category>gnuplot</category>
        <category>gnuplot in action</category>
        <category>understanding data with graphs</category>
      </categories>
      <tags>
        <tag>gnuplot</tag>
        <tag>gnu</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux GNUplot</title>
    <url>/2013/03/20/linux-gnuplot-1-basic-4-practical-matters/</url>
    <content><![CDATA[Chapter 4 discusses a variety of practical matters, from string handling tognuplot’s help feature.
参考主要参考《Gnuplot In Action》，请支持正版。
]]></content>
      <categories>
        <category>Linux</category>
        <category>gnuplot</category>
        <category>gnuplot in action</category>
        <category>understanding data with graphs</category>
      </categories>
      <tags>
        <tag>gnuplot</tag>
        <tag>gnu</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux gnuplot的坐标取值范围及刻度</title>
    <url>/2013/03/20/linux-gnuplot-1-plot-simple-data/</url>
    <content><![CDATA[坐标取值范围及刻度gnuplot 默认的x取值范围为[-10,10]，对于正弦函数而言，我们比较希望是+-π。此时可以使用xrange参数来指定。
gnuplot &gt; plot sin(6*x)gnuplot&gt; set xrange [-pi:pi]gnuplot&gt; replot

xrange用来指定横坐标的取值范围。

此时我们看到横坐标还是用数字表示，我们希望用π的来表示，如下：
gnuplot&gt; set xtics pignuplot&gt; set mxtics 2gnuplot&gt; replot



此时的坐标我们看到是按照3.1415来显示的，其中xtics表示主刻度，mxtics(minor xtics)表示分刻度，每个主刻度之间分两个刻度显示。
此时我们希望3.1415用π来显示，如下还是使用xtics参数来调整。
gnuplot&gt; set xtics ("-π" -pi, "-π/2" -pi/2.0,"π/2" pi/2.0,"π" pi)gnuplot&gt; replot


此时的横坐标轴就比较完美了。

set xtics 命令直接规定了每个刻度的位置和显示的字符。每一个刻度对应三个参数：显示字 符、刻度位置、刻度等级。刻度等级为 0 时表示主刻度，等级为 1 时表示分刻度。对于主刻度 （等级为 0 时），表示等级的参数也可以省略不写。各个刻度的参数之间用逗号隔 。从上面的例 子我们还看出，显示字符可以为空，也就是只标刻度，不显示字符。

然后把纵坐标也修改一下，如下：
gnuplot&gt; set ytics -1,0.5,1gnuplot&gt; replot


总结本节新增了基本命令：

plot 绘制2D图形
replot 重绘图形
set 设置参数
unset 取消设置
key 表示图例
samples 表示采样数
xlabe/ylabel/title 设置x轴、y轴和title的参数

参考主要参考《Gnuplot In Action》和《使用 gnuplot 科学作图》，请支持正版。
]]></content>
      <categories>
        <category>Linux</category>
        <category>gnuplot</category>
        <category>gnuplot in action</category>
        <category>understanding data with graphs</category>
      </categories>
      <tags>
        <tag>gnuplot</tag>
        <tag>gnu</tag>
        <tag>xrange</tag>
        <tag>yrange</tag>
        <tag>replot</tag>
        <tag>xtics</tag>
        <tag>mxtics</tag>
        <tag>ytics</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux gnuplot的坐标取值范围及刻度</title>
    <url>/2013/03/20/linux-gnuplot-1-set-axis/</url>
    <content><![CDATA[坐标取值范围及刻度gnuplot 默认的x取值范围为[-10,10]，对于正弦函数而言，我们比较希望是+-π。此时可以使用xrange参数来指定。
gnuplot &gt; plot sin(6*x)gnuplot&gt; set xrange [-pi:pi]gnuplot&gt; replot

xrange用来指定横坐标的取值范围。

此时我们看到横坐标还是用数字表示，我们希望用π的来表示，如下：
gnuplot&gt; set xtics pignuplot&gt; set mxtics 2gnuplot&gt; replot



此时的坐标我们看到是按照3.1415来显示的，其中xtics表示主刻度，mxtics(minor xtics)表示分刻度，每个主刻度之间分两个刻度显示。
此时我们希望3.1415用π来显示，如下还是使用xtics参数来调整。
gnuplot&gt; set xtics ("-π" -pi, "-π/2" -pi/2.0,"π/2" pi/2.0,"π" pi)gnuplot&gt; replot


此时的横坐标轴就比较完美了。

set xtics 命令直接规定了每个刻度的位置和显示的字符。每一个刻度对应三个参数：显示字 符、刻度位置、刻度等级。刻度等级为 0 时表示主刻度，等级为 1 时表示分刻度。对于主刻度 （等级为 0 时），表示等级的参数也可以省略不写。各个刻度的参数之间用逗号隔 。从上面的例 子我们还看出，显示字符可以为空，也就是只标刻度，不显示字符。

然后把纵坐标也修改一下，如下：
gnuplot&gt; set ytics -1,0.5,1gnuplot&gt; replot


总结本节新增了基本命令：

plot 绘制2D图形
replot 重绘图形
set 设置参数
unset 取消设置
key 表示图例
samples 表示采样数
xlabe/ylabel/title 设置x轴、y轴和title的参数

参考主要参考《Gnuplot In Action》和《使用 gnuplot 科学作图》，请支持正版。
]]></content>
      <categories>
        <category>Linux</category>
        <category>gnuplot</category>
        <category>gnuplot in action</category>
        <category>understanding data with graphs</category>
      </categories>
      <tags>
        <tag>gnuplot</tag>
        <tag>gnu</tag>
        <tag>xrange</tag>
        <tag>yrange</tag>
        <tag>replot</tag>
        <tag>xtics</tag>
        <tag>mxtics</tag>
        <tag>ytics</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux gnuplot的第一幅绘图</title>
    <url>/2013/03/20/linux-gnuplot-1-simple-plot/</url>
    <content><![CDATA[开始绘图了OK，万事俱备开始画图。
gnuplot应该是最简单的绘图工具了，我指的是刚开始，一条命令就出来一个正弦图像。不需要打开臃肿的Matlab，不需要在python里面调用matplotlib，不需要C语言调用第三方库。仅仅一个命令：
gnuplot &gt; plot sin(x)


gnuplot里面的plot用来绘制2D图像，我们注意到正弦波的波峰和波底貌似不是很平滑，我们把周期缩小一点再看看。
gnuplot &gt; plot sin(6*x)


此时看着更明显，可以看到不是我们想象的正弦函数，这里主要是因为周期小，震荡快，而gnuplot默认取样为100个点，此时我们加大取样点为600，如下命令，再画一下，可以看到就比较完美了。
gnuplot &gt; set samples 600gnuplot &gt; replot


此时我们看到右上角的上标可有可无，因为我们只绘制了一条曲线，所以可以通过key来取消，如下：
gnuplot &gt; unset keygnuplot &gt; replot


现在可以看到图形一览无余，但是如果发送给别人，其他人是看不懂表示什么意思的，此时我们就需要加上x轴、y轴和题目。
gnuplot &gt; set title "sin(6*x)"gnuplot &gt; set xlabel "X"gnuplot &gt; set ylabel "Y"gnuplot &gt; replot


总结本节新增了基本命令：

plot 绘制2D图形
replot 重绘图形
set 设置参数
unset 取消设置
key 表示图例
samples 表示采样数
xlabe/ylabel/title 设置x轴、y轴和title的参数

参考主要参考《Gnuplot In Action》和《使用 gnuplot 科学作图》，请支持正版。
]]></content>
      <categories>
        <category>Linux</category>
        <category>gnuplot</category>
        <category>gnuplot in action</category>
        <category>understanding data with graphs</category>
      </categories>
      <tags>
        <tag>gnuplot</tag>
        <tag>set</tag>
        <tag>gnu</tag>
        <tag>replot</tag>
        <tag>plot</tag>
        <tag>unset</tag>
        <tag>xlabel</tag>
        <tag>ylabel</tag>
        <tag>title</tag>
        <tag>key</tag>
        <tag>samples</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux GNUplot</title>
    <url>/2013/03/20/linux-gnuplot-2-polishing-5-doing-it-with-style/</url>
    <content><![CDATA[参考主要参考《Gnuplot In Action》，请支持正版。
]]></content>
      <categories>
        <category>Linux</category>
        <category>gnuplot</category>
        <category>gnuplot in action</category>
        <category>understanding data with graphs</category>
      </categories>
      <tags>
        <tag>gnuplot</tag>
        <tag>gnu</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux GNUplot</title>
    <url>/2013/03/20/linux-gnuplot-2-polishing-6-decorations/</url>
    <content><![CDATA[参考主要参考《Gnuplot In Action》，请支持正版。
]]></content>
      <categories>
        <category>Linux</category>
        <category>gnuplot</category>
        <category>gnuplot in action</category>
        <category>understanding data with graphs</category>
      </categories>
      <tags>
        <tag>gnuplot</tag>
        <tag>gnu</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux GNUplot</title>
    <url>/2013/03/20/linux-gnuplot-2-polishing-7-all-about-axes/</url>
    <content><![CDATA[参考主要参考《Gnuplot In Action》，请支持正版。
]]></content>
      <categories>
        <category>Linux</category>
        <category>gnuplot</category>
        <category>gnuplot in action</category>
        <category>understanding data with graphs</category>
      </categories>
      <tags>
        <tag>gnuplot</tag>
        <tag>gnu</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux GNUplot</title>
    <url>/2013/03/20/linux-gnuplot-3-advanced-gnuplot-10-advanced-plotting-concepts/</url>
    <content><![CDATA[参考主要参考《Gnuplot In Action》，请支持正版。
]]></content>
      <categories>
        <category>Linux</category>
        <category>gnuplot</category>
        <category>gnuplot in action</category>
        <category>understanding data with graphs</category>
      </categories>
      <tags>
        <tag>gnuplot</tag>
        <tag>gnu</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux GNUplot</title>
    <url>/2013/03/20/linux-gnuplot-3-advanced-gnuplot-11-terminals-in-depth/</url>
    <content><![CDATA[参考主要参考《Gnuplot In Action》，请支持正版。
]]></content>
      <categories>
        <category>Linux</category>
        <category>gnuplot</category>
        <category>gnuplot in action</category>
        <category>understanding data with graphs</category>
      </categories>
      <tags>
        <tag>gnuplot</tag>
        <tag>gnu</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux GNUplot</title>
    <url>/2013/03/20/linux-gnuplot-3-advanced-gnuplot-12-macors-scripting-and-batch-operations/</url>
    <content><![CDATA[参考主要参考《Gnuplot In Action》，请支持正版。
]]></content>
      <categories>
        <category>Linux</category>
        <category>gnuplot</category>
        <category>gnuplot in action</category>
        <category>understanding data with graphs</category>
      </categories>
      <tags>
        <tag>gnuplot</tag>
        <tag>gnu</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux GNUplot</title>
    <url>/2013/03/20/linux-gnuplot-3-advanced-gnuplot-8-three-dimensional-plots/</url>
    <content><![CDATA[参考主要参考《Gnuplot In Action》，请支持正版。
]]></content>
      <categories>
        <category>Linux</category>
        <category>gnuplot</category>
        <category>gnuplot in action</category>
        <category>understanding data with graphs</category>
      </categories>
      <tags>
        <tag>gnuplot</tag>
        <tag>gnu</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux GNUplot</title>
    <url>/2013/03/20/linux-gnuplot-3-advanced-gnuplot-9-color/</url>
    <content><![CDATA[参考主要参考《Gnuplot In Action》，请支持正版。
]]></content>
      <categories>
        <category>Linux</category>
        <category>gnuplot</category>
        <category>gnuplot in action</category>
        <category>understanding data with graphs</category>
      </categories>
      <tags>
        <tag>gnuplot</tag>
        <tag>gnu</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux GNUplot</title>
    <url>/2013/03/20/linux-gnuplot-4-graphical-analysis-with-gnuplot-13-fundamental-graphical-methods/</url>
    <content><![CDATA[参考主要参考《Gnuplot In Action》，请支持正版。
]]></content>
      <categories>
        <category>Linux</category>
        <category>gnuplot</category>
        <category>gnuplot in action</category>
        <category>understanding data with graphs</category>
      </categories>
      <tags>
        <tag>gnuplot</tag>
        <tag>gnu</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux GNUplot</title>
    <url>/2013/03/20/linux-gnuplot-4-graphical-analysis-with-gnuplot-14-techniques-of-graphical-analysis/</url>
    <content><![CDATA[参考主要参考《Gnuplot In Action》，请支持正版。
]]></content>
      <categories>
        <category>Linux</category>
        <category>gnuplot</category>
        <category>gnuplot in action</category>
        <category>understanding data with graphs</category>
      </categories>
      <tags>
        <tag>gnuplot</tag>
        <tag>gnu</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux GNUplot</title>
    <url>/2013/03/20/linux-gnuplot-4-graphical-analysis-with-gnuplot-15-coda-understanding-data-with-graphs/</url>
    <content><![CDATA[参考主要参考《Gnuplot In Action》，请支持正版。
]]></content>
      <categories>
        <category>Linux</category>
        <category>gnuplot</category>
        <category>gnuplot in action</category>
        <category>understanding data with graphs</category>
      </categories>
      <tags>
        <tag>gnuplot</tag>
        <tag>gnu</tag>
      </tags>
  </entry>
  <entry>
    <title>Installing Google Chrome on CentOS</title>
    <url>/2011/12/18/linux-google/</url>
    <content><![CDATA[Installing Google Chrome on CentOS
Start by opening your terminal and downloading the latest Google Chrome .rpm package with the following wget command
wget https://dl.google.com/linux/direct/google-chrome-stable_current_x86_64.rpm

Once the file is downloaded, install Google Chrome on your CentOS 7 system by typing:
sudo yum localinstall google-chrome-stable_current_x86_64.rpm

The command above will prompt you to enter your user password and then it will install Chrome and all other required packages.


Starting Google ChromeNow that you have Google Chrome installed on your CentOS system, you can start it either from the command line by typing google-chrome &amp; or by clicking on the Google Chrome icon (Applications → Internet → Google Chrome):
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>gtk</tag>
        <tag>glib</tag>
        <tag>pkg-config</tag>
        <tag>gtk-config</tag>
      </tags>
  </entry>
  <entry>
    <title>linux grafana使用教程</title>
    <url>/2014/01/20/linux-grafana/</url>
    <content><![CDATA[grafana使用教程安装参考 https://grafana.com/docs/grafana/latest/installation/rpm/
$ sudo vim /etc/yum.repos.d/grafana.repo



对于开源而言，内容如下：
[grafana]name=grafanabaseurl=https://packages.grafana.com/oss/rpmrepo_gpgcheck=1enabled=1gpgcheck=1gpgkey=https://packages.grafana.com/gpg.keysslverify=1sslcacert=/etc/pki/tls/certs/ca-bundle.crt

对于商用版本，内容如下：
[grafana]name=grafanabaseurl=https://packages.grafana.com/enterprise/rpmrepo_gpgcheck=1enabled=1gpgcheck=1gpgkey=https://packages.grafana.com/gpg.keysslverify=1sslcacert=/etc/pki/tls/certs/ca-bundle.crt



然后开始安装
$ sudo yum update$ sudo yum install grafana# or$ sudo yum install grafana-enterprise



安装插件使用grafana-cli工具安装#获取可用插件列表$ grafana-cli plugins list-remote  #修改图形为饼状$ grafana-cli plugins install grafana-piechart-panel#安装其他图形插件$ grafana-cli plugins install grafana-clock-panel#钟表形展示$ grafana-cli plugins install briangann-gauge-panel#字符型展示$ grafana-cli plugins install natel-discrete-panel#服务器状态$ grafana-cli plugins install vonage-status-panel



启动、重启、关闭#启动：$ service grafana-server start# 停止：$service grafana-server stop# 重启：$ service grafana-server restart#加入开机自启动： $chkconfig --add grafana-server on### Or later$ sudo systemctl daemon-reload$ sudo systemctl start grafana-server$ sudo systemctl status grafana-server#Configure the Grafana server to start at boot:$ sudo systemctl enable grafana-server



创建Dashboard首先选定一个数据库，添加一个数据源。
登录Grafana Protal在浏览器中输入：http://GRAFANA_HOST_IP:3000默认账号/密码：admin/admin
进入Plugins界面，选择“Zabbix”开始面板（左上角图标） -&gt; Plugins -&gt; Apps -&gt; Zabbix
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>groupadd</tag>
        <tag>usermod</tag>
        <tag>chgrp</tag>
        <tag>chmod</tag>
      </tags>
  </entry>
  <entry>
    <title>文件内容搜索利器 - grep</title>
    <url>/2011/12/27/linux-grep-beginner/</url>
    <content><![CDATA[文件内容搜索利器 - grep.. _linux_grep_beginner:
.. note::  相见时难别亦难，东风无力百花残。

李商隐《无题》

Linux grep 命令用于查找文件里符合条件的字符串。
官方定义为：

grep, egrep, fgrep - print lines matching a pattern

grep支持正则表达式，是一个强大的文本搜索工具。
语法语法也挺复杂，因为功能确实很强大。
$ grep [OPTION...] PATTERNS [FILE...]$ grep [OPTION...] -e PATTERNS ... [FILE...]      # 使用egrep$ grep [OPTION...] -f PATTERN_FILE ... [FILE...]  # 使用fgrep

常用的参数为：

-r 或 –recursive : 此参数的效果和指定-d recurse参数相同
-v 或 –invert-match : 显示不包含匹配文本的所有行
-i 或 –ignore-case : 忽略字符大小写的差别
-n 或 –line-number : 在显示符合样式的那一行之前，标示出该行的列数编号。

假定有如下3个文件，1个文件夹，内容如下：
a    This is a    Hello a    b     this is b    Hello bc     This is c    Hello cd/d     This is d    Hello d



默认无参数在当前目录搜索包含is字符串，可以看到**a/b/c**三个文件均有输出，而d因为是目录，暂时无输出。
$ grep is *a:This is ab:this is bc:This is cgrep: d: Is a directory



增加文件夹与其他命令类似，增加-r参数，递归搜索
$ grep -r is *a:This is ab:this is bc:This is cd/d:This is d



反向查找在某些情况下，或许正想找到不包含某些字符串的内容，如下：
$ grep -rv is *a:Hello ab:Hello bc:Hello cd/d:Hello d

此时可以看到，不包含is的内容显示了出来。
不区分大小写而某些情况下，或许我们希望找到不区分大小写的内容，比如对于This/this而言：
$ grep -r This *a:This is ac:This is cd/d:This is d$ grep -ri This *a:This is ab:this is bc:This is cd/d:This is d

可以看到此时有可能笔误，或者其他原因的b文件已经被找到了。
显示行数，精准定位   如果文件内容比较多，此时显示内容在哪一行，是很重要的，加上-n参数既可解决。
$ grep -rn This *a:1:This is ac:1:This is cd/d:1:This is d
]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>grep</tag>
        <tag>egrep</tag>
        <tag>fgrep</tag>
        <tag>文本处理</tag>
        <tag>数据处理</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux的 grep 命令</title>
    <url>/2011/12/27/linux-grep/</url>
    <content><![CDATA[grep 文件内容搜索利器Linux grep 命令用于查找文件里符合条件的字符串。
官方定义为：

grep, egrep, fgrep - print lines matching a pattern

grep支持正则表达式，是一个强大的文本搜索工具。
语法语法也挺复杂，因为功能确实很强大。
$ grep [OPTION...] PATTERNS [FILE...]$ grep [OPTION...] -e PATTERNS ... [FILE...]      # 使用egrep$ grep [OPTION...] -f PATTERN_FILE ... [FILE...]  # 使用fgrep

常用的参数为：

-r 或 –recursive : 此参数的效果和指定”-d recurse”参数相同
-v 或 –invert-match : 显示不包含匹配文本的所有行
-i 或 –ignore-case : 忽略字符大小写的差别
-n 或 –line-number : 在显示符合样式的那一行之前，标示出该行的列数编号。

假定有如下3个文件，1个文件夹，内容如下：
a    This is a    Hello a    b     this is b    Hello bc     This is c    Hello cd/d     This is d    Hello d



默认无参数在当前目录搜索包含is字符串，可以看到**a/b/c**三个文件均有输出，而d因为是目录，暂时无输出。
$ grep is *a:This is ab:this is bc:This is cgrep: d: Is a directory



增加文件夹与其他命令类似，增加-r参数，递归搜索
$ grep -r is *a:This is ab:this is bc:This is cd/d:This is d



反向查找在某些情况下，或许正想找到不包含某些字符串的内容，如下：
$ grep -rv is *a:Hello ab:Hello bc:Hello cd/d:Hello d

此时可以看到，不包含is的内容显示了出来。
不区分大小写而某些情况下，或许我们希望找到不区分大小写的内容，比如对于This/this而言：
$ grep -r This *a:This is ac:This is cd/d:This is d$ grep -ri This *a:This is ab:this is bc:This is cd/d:This is d

可以看到此时有可能笔误，或者其他原因的b文件已经被找到了。
显示行数，精准定位   如果文件内容比较多，此时显示内容在哪一行，是很重要的，加上-n参数既可解决。
$ grep -rn This *a:1:This is ac:1:This is cd/d:1:This is d



















参数：

-a 或 –text : 不要忽略二进制的数据。
-A&lt;显示行数&gt; 或 –after-context=&lt;显示行数&gt; : 除了显示符合范本样式的那一列之外，并显示该行之后的内容。
-b 或 –byte-offset : 在显示符合样式的那一行之前，标示出该行第一个字符的编号。
-B&lt;显示行数&gt; 或 –before-context=&lt;显示行数&gt; : 除了显示符合样式的那一行之外，并显示该行之前的内容。
-c 或 –count : 计算符合样式的列数。
-C&lt;显示行数&gt; 或 –context=&lt;显示行数&gt;或-&lt;显示行数&gt; : 除了显示符合样式的那一行之外，并显示该行之前后的内容。
-d &lt;动作&gt; 或 –directories=&lt;动作&gt; : 当指定要查找的是目录而非文件时，必须使用这项参数，否则grep指令将回报信息并停止动作。
-e&lt;范本样式&gt; 或 –regexp=&lt;范本样式&gt; : 指定字符串做为查找文件内容的样式。
-E 或 –extended-regexp : 将样式为延伸的正则表达式来使用。
-f&lt;规则文件&gt; 或 –file=&lt;规则文件&gt; : 指定规则文件，其内容含有一个或多个规则样式，让grep查找符合规则条件的文件内容，格式为每行一个规则样式。
-F 或 –fixed-regexp : 将样式视为固定字符串的列表。
-G 或 –basic-regexp : 将样式视为普通的表示法来使用。
-h 或 –no-filename : 在显示符合样式的那一行之前，不标示该行所属的文件名称。
-H 或 –with-filename : 在显示符合样式的那一行之前，表示该行所属的文件名称。
-l 或 –file-with-matches : 列出文件内容符合指定的样式的文件名称。
-L 或 –files-without-match : 列出文件内容不符合指定的样式的文件名称。
-o 或 –only-matching : 只显示匹配PATTERN 部分。
-q 或 –quiet或–silent : 不显示任何信息。
-s 或 –no-messages : 不显示错误信息。
-w 或 –word-regexp : 只显示全字符合的列。
-x –line-regexp : 只显示全列符合的列。
-y : 此参数的效果和指定”-i”参数相同。

命令格式：grep [option] pattern file
grep的常用选项：
-E： 解释PATTERN作为扩展正则表达式，也就相当于使用egrep。 或操作
-F :   解释PATTERN作为固定字符串的列表，由换行符分隔，其中任何一个都要匹配。也就相当于使用fgrep。
-G:   将范本样式视为普通的表示法来使用。这是默认值。加不加都是使用grep。
匹配控制选项：
-e :  使用PATTERN作为模式。这可以用于指定多个搜索模式，或保护以连字符（ - ）开头的图案。指定字符串做为查找文件内容的样式。   
-f :  指定规则文件，其内容含有一个或多个规则样式，让grep查找符合规则条件的文件内容，格式为每行一个规则样式。
-w：匹配整词，精确地单词,单词的两边必须是非字符符号(即不能是字母数字或下划线)
-x：仅选择与整行完全匹配的匹配项。精确匹配整行内容(包括行首行尾那些看不到的空格内容都要完全匹配)
-y：此参数的效果和指定“-i”参数相同。
一般输出控制选项：
-c： 抑制正常输出;而是为每个输入文件打印匹配线的计数。
–color [= WHEN]：让关键字高亮显示，如–color=auto
-L：列出文件内容不符合指定的范本样式的文件名称
-l : 列出文件内容符合指定的范本样式的文件名称。
-m num：当匹配内容的行数达到num行后,grep停止搜索,并输出停止前搜索到的匹配内容
-o: 只输出匹配的具体字符串,匹配行中其他内容不会输出
-q：安静模式,不会有任何输出内容,查找到匹配内容会返回0,未查找到匹配内容就返回非0
-s：不会输出查找过程中出现的任何错误消息，-q和-s选项因为与其他系统的grep有兼容问题，shell脚本应该避免使用-q和-s，并且应该将标准和错误输出重定向到/dev/null 代替。
输出线前缀控制：
-b：输出每一个匹配行(或匹配的字符串)时在其前附加上偏移量(从文件第一个字符到该匹配内容之间的字节数)
-H：在每一个匹配行之前加上文件名一起输出(针对于查找单个文件),当查找多个文件时默认就会输出文件名
-h：禁止输出上的文件名的前缀。无论查找几个文件都不会在匹配内容前输出文件名
–label = LABEL：显示实际来自标准输入的输入作为来自文件LABEL的输入。这是特别在实现zgrep等工具时非常有用，例如gzip -cd foo.gz | grep –label = foo -H的东西。看到 也是-H选项。
-T：初始标签确保实际行内容的第一个字符位于制表位上，以便对齐标签看起来很正常。在匹配信息和其前的附加信息之间加入tab以使格式整齐。
上下文线控制选项：
-A num：匹配到搜索到的行以及该行下面的num行
-B num：匹配到搜索到的行以及该行上面的num行
-C num：匹配到搜索到的行以及上下各num行
文件和目录选择选项：
-a： 处理二进制文件，就像它是文本;这相当于–binary-files = text选项。不忽略二进制的数据。  
 –binary-files = TYPE：如果文件的前几个字节指示文件包含二进制数据，则假定该文件为类型TYPE。默认情况下，TYPE是二进制的，grep通常输出一行消息二进制文件匹配，或者如果没有匹配则没有消息。如果TYPE不匹配，grep假定二进制文件不匹配;这相当于-I选项。如果TYPE是文本，则grep处理a二进制文件，如果它是文本;这相当于-a选项。警告：grep –binary-files = text可能会输出二进制的垃圾，如果输出是一个终端和如果可能有讨厌的副作用终端驱动程序将其中的一些解释为命令。
-D：如果输入文件是设备，FIFO或套接字，请使用ACTION处理。默认情况下，读取ACTION，这意味着设备被读取，就像它们是普通文件一样。如果跳过ACTION，设备为 默默地跳过。
-d:  如果输入文件是目录，请使用ACTION处理它。默认情况下，ACTION是读的，这意味着目录被读取，就像它们是普通文件一样。如果跳过ACTION，目录将静默跳过。如果ACTION是recurse，grep将递归读取每个目录下的所有文件;这是相当于-r选项。
–exclude=GLOB：跳过基本名称与GLOB匹配的文件（使用通配符匹配）。文件名glob可以使用，？和[…]作为通配符，和\引用通配符或反斜杠字符。搜索其文件名和GLOB通配符相匹配的文件的内容来查找匹配使用方法:grep -H –exclude=c “old” ./*  c是通配文件名的通配符./ 指定需要先通配文件名的文件的范围,必须要给*,不然就匹配不出内容,(如果不给*,带上-r选项也可以匹配)
–exclude-from = FILE：在文件中编写通配方案,grep将不会到匹配方案中文件名的文件去查找匹配内容
–exclude-dir = DIR：匹配一个目录下的很多内容同时还要让一些子目录不接受匹配,就使用此选项。
 –include = GLOB：仅搜索其基本名称与GLOB匹配的文件（使用–exclude下所述的通配符匹配）。
-R ,-r :以递归方式读取每个目录下的所有文件; 这相当于-d recurse选项。
其他选项：
–line-buffered： 在输出上使用行缓冲。这可能会导致性能损失。
–mmap：启用mmap系统调用代替read系统调用
-U：将文件视为二进制。
-z：将输入视为一组行，每一行由一个零字节（ASCII NUL字符）而不是a终止新队。与-Z或–null选项一样，此选项可以与排序-z等命令一起使用来处理任意文件名。
简述
-a   --text   #不要忽略二进制的数据。 将 binary 文件以 text 文件的方式搜寻数据 -A&lt;显示行数&gt;   --after-context=&lt;显示行数&gt;   #除了显示符合范本样式的那一列之外，并显示该行之后的内容。   -b   --byte-offset   #在显示符合样式的那一行之前，标示出该行第一个字符的编号。   -B&lt;显示行数&gt;   --before-context=&lt;显示行数&gt;   #除了显示符合样式的那一行之外，并显示该行之前的内容。   -c    --count   #计算符合样式的行数。   -C&lt;显示行数&gt;    --context=&lt;显示行数&gt;或-&lt;显示行数&gt;   #除了显示符合样式的那一行之外，并显示该行之前后的内容。   -d &lt;动作&gt;      --directories=&lt;动作&gt;   #当指定要查找的是目录而非文件时，必须使用这项参数，否则grep指令将回报信息并停止动作。   -e&lt;范本样式&gt;  --regexp=&lt;范本样式&gt;   #指定字符串做为查找文件内容的样式。   -E      --extended-regexp   #将样式为延伸的普通表示法来使用。   -f&lt;规则文件&gt;  --file=&lt;规则文件&gt;   #指定规则文件，其内容含有一个或多个规则样式，让grep查找符合规则条件的文件内容，格式为每行一个规则样式。   -F   --fixed-regexp   #将样式视为固定字符串的列表。   -G   --basic-regexp   #将样式视为普通的表示法来使用。   -h   --no-filename   #在显示符合样式的那一行之前，不标示该行所属的文件名称。   -H   --with-filename   #在显示符合样式的那一行之前，表示该行所属的文件名称。   -i    --ignore-case   #忽略字符大小写的差别。   -l    --file-with-matches   #列出文件内容符合指定的样式的文件名称。   -L   --files-without-match   #列出文件内容不符合指定的样式的文件名称。   -n   --line-number   #在显示符合样式的那一行之前，标示出该行的列数编号。   -q   --quiet或--silent   #不显示任何信息。   -r   --recursive   #此参数的效果和指定“-d recurse”参数相同。   -s   --no-messages   #不显示错误信息。   -v   --revert-match   #显示不包含匹配文本的所有行。   -V   --version   #显示版本信息。   -w   --word-regexp   #只显示全字符合的列。   -x    --line-regexp   #只显示全列符合的列。   -y   #此参数的效果和指定“-i”参数相同。--color=auto ：可以将找到的关键词部分加上颜色的显示

一、常用用法
grep -i pattern files ：不区分大小写地搜索。默认情况区分大小写，grep -l pattern files ：只列出匹配的文件名，grep -L pattern files ：列出不匹配的文件名，grep -w pattern files ：只匹配整个单词，而不是字符串的一部分（如匹配‘magic’，而不是‘magical’），grep -C number pattern files ：匹配的上下文分别显示[number]行，grep pattern1 | pattern2 files ：显示匹配 pattern1 或 pattern2 的行，grep pattern1 files | grep pattern2 ：显示既匹配 pattern1 又匹配 pattern2 的行。
这里还有些用于搜索的特殊符号：&lt; 和 &gt; 分别标注单词的开始与结尾。例如：grep man * 会匹配 ‘Batman’、‘manic’、‘man’等，grep '&lt;man' * 匹配‘manic’和‘man’，但不是‘Batman’，grep '' 只匹配‘man’，而不是‘Batman’或‘manic’等其他的字符串。'^'：指匹配的字符串在行首，'$'：指匹配的字符串在行尾，如果您不习惯命令行参数，可以试试图形界面的‘grep’，如 reXgrep 。这个软件提供 AND、OR、NOT 等语法，还有漂亮的按钮 :-) 。如果您只是需要更清楚的输出，不妨试试 fungrep 。
.grep 搜索字符串命令格式:grep string filename寻找字串的方法很多，比如说我想找所有以M开头的行.此时必须引进pattern的观念.以下是一些简单的□例，以及说明：^M 以M开头的行，^表示开始的意思M$ 以M结尾的行，$表示结束的意思^[0-9] 以数字开始的行，[]内可列举字母^[124ab] 以1,2,4,a,或b开头的行^b.503 句点表示任一字母

星号表示0个以上的字母(可以没有)


加号表示1个以上的字母. 斜线可以去掉特殊意义 cat passwd | grep ^b 列出大学部有申请帐号者名单cat passwd | grep ^s 列出交换学生申请帐号者名单cat passwd | grep '^b.503' 列出电机系各年级…grep '^.' myfile.txt 列出所有以句点开头的行

1、查找指定进程
命令：ps -ef|grep java
2、查找指定进程个数
命令：ps -ef|grep -c java
或ps -ef|grep java -c
3、从文件中读取关键词进行搜索，默认是显示的是行 
命令1：cat test.txt | grep -f test2.txt
命令2（显示行号）：cat test.txt | grep -nf test2.txt
作用：输出test.txt文件中含有从test2.txt文件中读取出的关键词的内容行，可用于按指定关键词（放到一个文件中）搜索日志文件。
另一种用法：将多个文件之间相同的行输出来
cd /etc/sysconfig/network-scripts/grep  “IPADDR” ifcfg-eth0  ifcfg-lo      #默认不加参数指定过滤关键字，外加多个文件，只是将多个文件里面有匹配的行输出ifcfg-eth0:IPADDR=192.168.1.108
ifcfg-lo:IPADDR=127.0.0.1
grep -f ifcfg-eth0  ifcfg-lo  #grep -f 文件1 文件2 ,会将多个文件之间相同的行输出出来ONBOOT=yes
-o:只显示被模式匹配到的字符串，而不是整个行
命令：grep -o “you” ab.log 
grep “root”  /etc/passwd  #先看下正常的过滤，会将整个一行过滤出来root❌0:0:root:/root:/bin/bash
operator❌11:0:operator:/root:/sbin/nologin
grep -o “root” /etc/passwd  #加o之后的操作，只过滤关键字出来root
root
root
root
grep -o “root:.*0” /etc/passwd    #加上正则表达式，这样才是正确的用法，不用输出一整行，只是输出一小段root❌0:0
grep -o “root” -b   /etc/passwd-b和-o一般是配合使用的，一行中字符串的字符是从该行的第一个字符开始计算，起始值为0。这里左边的数字就是此关键字在此文件中的起始位置，第一个root出现在0位置，然后字符字母有一个算一个，你就一个个的向右数吧，下一个root出现在11位置以此类推。
0:root
11:root
17:root
414:root
4、从文件中查找关键词，忽略大小写，默认情况区分大小写
命令1：grep ‘linux’ test.txt
命令2（从多个文件中查找）：grep ‘linux’ test.txt test2.txt
　　多文件时，输出查询到的信息内容行时，会把文件的命名在行最前面输出并且加上”:”作为标示符
命令3（忽略大小写）：grep -i  ‘linux’ test.txt
命令：find . -name “.log” | grep -i error | grep -vi “info”
1）使用find -name 来列出所有log文件，重定向给grep2）使用grep -i 来查找包含error的行3）使用grep -vi 来查找不包含info的行
5、grep不显示本身
命令：
ps aux|grep [s]sh
ps aux | grep ssh | grep -v “grep”      #不包含grep ssh这条命令
grep -v root /etc/passwd | grep -v nologin  #将/etc/passwd，将没有出现 root 和nologin的行取出来
6、-r 递归查找子目录 查找当前目录及其子目录下面包含匹配字符的文件
grep ‘ab’ * #在当前目录搜索带’ab’行的文件grep -r ‘ab’ * #在当前目录及其子目录下搜索’ab’行的文件grep -l -r ‘ab’ * #在当前目录及其子目录下搜索’ab’行的文件，但是不显示匹配的行，只显示匹配的文件grep -nr BLOG* . # 查找子目录，匹配后输出行号，这里的点表示当前目录grep -lr BLOG* . #查找子目录，匹配后只输出文件名查询不包含某个目录
#grep -R –exclude-dir=node_modules ‘some pattern’ /path/to/search   #不包含txt目录 
7、列出关键字所在行的前几行与后几行也一起显示
  -A -B -C
很多时候，我们并关心匹配行而是关心匹配行的上下文。这时候-A -B -C就有用了-A n 后n行，A记忆为(After)-B n 前n行，B记忆为(Before)-C n 前n行，后n行，C记忆为(Center)
[root@www ~]# dmesg | grep -n -A3 -B2 –color=auto ‘eth’245-PCI: setting IRQ 10 as level-triggered246-ACPI: PCI Interrupt 0000:00:0e.0[A] -&gt; Link [LNKB] …247:eth0: RealTek RTL8139 at 0xee846000, 00:90:cc:a6:34:84, IRQ 10248:eth0: Identified 8139 chip type ‘RTL-8139C’249-input: PC Speaker as /class/input/input2250-ACPI: PCI Interrupt 0000:00:01.4[B] -&gt; Link [LNKB] …251-hdb: ATAPI 48X DVD-ROM DVD-R-RAM CD-R/RW drive, 2048kB Cache, UDMA(66)
如上所示，你会发现关键字 247 所在的前两行及 248 后三行也都被显示出来！8、–line-buffered 打开buffering 模式
有一个文件是动态的，它不断地添加信息到文件的尾部，而你想要输出包含某些信息的行。即持续的grep一个动态的流
9、e与E区别
grep想同时过滤多个条件或操作
错误写法：
netstat -an|grep “ESTABLISHED|WAIT”      #默认grep不支持多条件匹配正确写法：
netstat -an|grep -E “ESTABLISHED|WAIT”     #加上-E 多条件用””包起来，然后多条件之间用|管道符分开tcp        0     52 192.168.1.108:22            192.168.1.104:54127         ESTABLISHED 
ps -aux|grep -e udevd -e master|awk {‘print $(NF-1)’}|sort|uniq    #而-e呢不用””包起来，-e 指定一个匹配条件/sbin/udevd
/usr/bin/salt-master
  grep -E ‘123|abc’ filename  // 找出文件（filename）中包含123或者包含abc的行  egrep ‘123|abc’ filename    // 用egrep同样可以实现  awk ‘/123|abc/‘ filename   // awk 的实现方式
与操作
 grep pattern1 files | grep pattern2 ：显示既匹配 pattern1 又匹配 pattern2 的行。
10、-c 统计行数
grep -i “abc” test.txt|wc -l  #不分大小写。test.txt里面包含abc过滤条件的为2行2
grep -yc “abc” test.txt  #-c呢，就是不显示行的内容，直接显示有几行2
cat  /etc/passwd|wc -l55
grep  -c “^.*$” /etc/passwd  #那么我们除了wc -l用来统一一个文件有多少行以外，又多了一种统计文件多少行的方法55
11、 -m的使用
cat test2.txt  #这是测试文件abc 1
abc 2
abc 3
abc 4
abc 5
grep -m 3 “abc” test2.txt  #只匹配到了第三行就退出了abc 1
abc 2
abc 3
二、与正则表达式结合
grep的规则表达式:\     反义字符：如”""“表示匹配””[ - ] 匹配一个范围，[0-9a-zA-Z]匹配所有数字和字母

所有字符，长度可为0


前面的字符出现了一次或者多次^  #匹配行的开始 如：’^grep’匹配所有以grep开头的行。

$  #匹配行的结束 如：’grep$’匹配所有以grep结尾的行。.  #匹配一个非换行符的字符 如：’gr.p’匹配gr后接一个任意字符，然后是p。    

#匹配零个或多个先前字符 如：’*grep’匹配所有一个或多个空格后紧跟grep的行。

.*   #一起用代表任意字符。[]   #匹配一个指定范围内的字符，如’[Gg]rep’匹配Grep和grep。[^]  #匹配一个不在指定范围内的字符，如：’[^A-FH-Z]rep’匹配不包含A-R和T-Z的一个字母开头，紧跟rep的行。(..)  #标记匹配字符，如’(love)‘，love被标记为1。&lt;      #到匹配正则表达式的行开始，如:’&lt;grep’匹配包含以grep开头的单词的行。&gt;      #到匹配正则表达式的行结束，如’grep&gt;‘匹配包含以grep结尾的单词的行。x{m}  #重复字符x，m次，如：’0{5}‘匹配包含5个o的行。x{m,}  #重复字符x,至少m次，如：’o{5,}‘匹配至少有5个o的行。x{m,n}  #重复字符x，至少m次，不多于n次，如：’o{5,10}‘匹配5–10个o的行。\w    #匹配文字和数字字符，也就是[A-Za-z0-9]，如：’G\w*p’匹配以G后跟零个或多个文字或数字字符，然后是p。\W    #\w的反置形式，匹配一个或多个非单词字符，如点号句号等。\b    #单词锁定符，如: ‘\bgrep\b’只匹配grep。  
POSIX字符:为了在不同国家的字符编码中保持一至，POSIX(The Portable Operating System Interface)增加了特殊的字符类，如[:alnum:]是[A-Za-z0-9]的另一个写法。要把它们放到[]号内才能成为正则表达式，如[A- Za-z0-9]或[[:alnum:]]。在linux下的grep除fgrep外，都支持POSIX的字符类。[:alnum:]    #文字数字字符[:alpha:]    #文字字符[:digit:]    #数字字符[:graph:]    #非空字符（非空格、控制字符）[:lower:]    #小写字符[:cntrl:]    #控制字符[:print:]    #非空字符（包括空格）[:punct:]    #标点符号[:space:]    #所有空白字符（新行，空格，制表符）[:upper:]    #大写字符[:xdigit:]   #十六进制数字（0-9，a-f，A-F） 
例：通过管道过滤ls -l输出的内容，只显示以a开头的行。
首与行尾字节 ^ $，^ 符号，在字符类符号(括号[])之内与之外是不同的！ 在 [] 内代表『反向选择』，在 [] 之外则代表定位在行首的意义！
$ ls -l | grep '^a'
$ ls -l | grep  ^a
$ ls -l | grep  ^[^a]      #输出非a开头的行，反向选择
$ grep -n ‘^$’ express.txt      #找出空白行，因为只有行首跟行尾 (^$)
例：显示所有以d开头的文件中包含test的行。
$ grep 'test' d*
例：输出以hat结尾的行内容
$ cat test.txt |grep hat$
例：显示在aa，bb，cc文件中匹配test的行。
$ grep 'test' aa bb cc
例：显示所有包含每个字符串至少有5个连续小写字符的字符串的行。
在一组集合字节中，如果该字节组是连续的，例如大写英文/小写英文/数字等等，就可以使用[a-z],[A-Z],[0-9]等方式来书写，那么如果我们的要求字串是数字与英文呢？就将他全部写在一起，变成：[a-zA-Z0-9]。
$ grep '[a-z]{5}' aa
$ grep -n ‘[0-9]’ regular_express.txt  　　#取得有数字的那一行
$ grep -n ‘^[a-z]’ regular_express.txt 　　 #只输出开头是小写字母的那一行
$ grep -n ‘^[^a-zA-Z]’ regular_express.txt   #不输出开头是英文的
$ grep -n ‘.$’ regular_express.txt   　　　　 #只输出行尾结束为小数点 (.) 的那一行
注意：小数点具有其他意义，所以必须要使用转义字符()来加以解除其特殊意义！
例：显示包含ed或者at字符的内容行
命令：cat test.txt |grep -E “ed|at”
例：如果west被匹配，则es就被存储到内存中，并标记为1，然后搜索任意个字符（.*），这些字符后面紧跟着另外一个es（1），找到就显示该行。如果用egrep或grep -E，就不用””号进行转义，直接写成'w(es)t.*1'就可以了。
$ grep 'w(es)t.*1' aa
例：显示当前目录下面以.txt 结尾的文件中的所有包含每个字符串至少有7个连续小写字符的字符串的行
命令：grep ‘[a-z]{7}‘ *.txt
例：查询IP地址、邮箱、手机号
这里用到了-o和-P命令man grep查看-o, –only-matching：              Show only the part of a matching line that matches PATTERN.-P, –perl-regexp：              Interpret PATTERN as a Perl regular expression.
也就是说-o，只显示匹配行中匹配正则表达式的那部分，-P，作为Perl正则匹配
192.168.0.1
abc@163.com
匹配ABC类IP地址即 1.0.0.1—223.255.255.254
命令（IP）：grep -oP “([0-9]{1,3}.){3}[0-9]{1,3}” file.txt
或grep -E –color “&lt;([1-9]|[1-9][0-9]|1[0-9][0-9]|2[0-1][0-9]|22[0-3]).([0-9]|[1-9][0-9]|1[0-9][0-9]|2[0-4][0-9]|25[0-5]).([0-9]|[1-9][0-9]|1[0-9][0-9]|2[0-4][0-9]|25[0-5]).([1-9]|[1-9][0-9]|1[0-9][0-9]|2[0-4][0-9]|25[0-4])&gt;“ file.txt
邮箱是任意长度数字字母@任意长度数字字母
命令（邮箱）：grep -oP “[a-zA-Z0-9_-]+@[a-zA-Z0-9_-]+(.[a-zA-Z0-9_-]+)+” file.txt
手机号码是1[3|4|5|8]后面接9位数字的
命令（手机号）：grep -E “&lt;1[3|4|5|8][0-9]{9}&gt;“  file.txt
例：任意一个字节 . 与重复字节 *
. (小数点)：代表『一定有一个任意字节』的意思；

(星号)：代表『重复前一个字符， 0 到无穷多次』的意思，为组合形态$ grep -n ‘[0-9][0-9]*’ regular_express.txt     #找出『任意数字』的行

$ grep -n ‘g.*g’ regular_express.txt       #找出以g行首与行尾的行，当中的字符可有可无
这个 .* 的 RE 表示任意字符是很常见的.
例：限定连续 RE 字符范围 {}
利用 . 与 RE 字符及 * 来配置 0 个到无限多个重复字节
打算找出两个到五个 o 的连续字串，该如何作？这时候就得要使用到限定范围的字符 {} 了。 但因为 { 与 } 的符号在 shell 是有特殊意义的，因此， 我们必须要使用字符   \ 来让他失去特殊意义才行。 
$ grep -n ‘o{2}‘ regular_express.txt
$ grep -n ‘go{2,5}g’ regular_express.txt  #要找出 g 后面接 2 到 5 个 o ，然后再接一个 g 的字串
$ grep -n ‘go{2,}g’ regular_express.txt    #想要的是 2 个 o 以上的 goooo….g 呢？除了可以是 gooo*g
NOTE 还有一些衍生命令，比如egrep和fgrep。
]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>grep</tag>
      </tags>
  </entry>
  <entry>
    <title>ubuntu10.04后不支持gtk-config</title>
    <url>/2011/12/12/linux-gtk-config/</url>
    <content><![CDATA[ubuntu10.04后不支持gtk-config从http://manpages.ubuntu.com/知道，对于gtk-config，8.04是支持的，后面的几个版本已经不再支持了。所以在编译gtk程序的时候，我们需要使用pkg-config命令。
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>gtk</tag>
        <tag>pkg-config</tag>
        <tag>gtk-config</tag>
      </tags>
  </entry>
  <entry>
    <title>Glib数据类型</title>
    <url>/2011/12/12/linux-gtk-glib/</url>
    <content><![CDATA[Glib数据类型Glib提供了自己的一组在GTK+和GNOME开发中使用的替代标准C数据类型的数据类型。这样做的原因不仅是便于阅读和使用，而且还便于移植。不管在何种平台上编译应用程序，许多平台对数据的尺寸和运算都会具有许多相同的限制。Glib数据类型保证不管什么样的系统和平台，都是相同的大小。
Glib的数据类型


数据类型
说明



gboolean
真假或开关的值，一般与Glib定义的TRUE和FALSE常量使用


gpointer
对应与void *，但是可读性更强


gchar、guchar
对应一个字符和一个无符号字符


gint、guint、gshort
取代标准c的相应类型


glong、gulong
长度根据硬件和操作系统体系结构的不同而变化


gint8、guint8、gint16、



guint16、gint32、guint32、



gint64、guint64
具有已知长度的有符号和无符号整数数据类型。对于64位有符号和无符号整数值，仅在范围有限的机器上支持


gfloat、gdouble
取代c语言提供的float和double


gsize
用来保存数据结构和数据类型尺寸的无符号数据类型


gssize
用来保存数据结构和数据类型尺寸的有符号数据类型


​       上述这些类型，可以保证一致性和可读性。不管编译应用程序的平台是什么，定义一组具有可保证长度的数据类型将是一种很好的想法，同时笔记guchar减少了击键次数（unsigned char）。​       测试了一下每种数据类型所占的字节数：
#include &lt;glib.h&gt;gint main(gint argc,gchar *argv[]){​    g_print("The length of gboolean is %dn",sizeof(gboolean));​    g_print("The length of gpointer is %dn",sizeof(gpointer));​    g_print("The length of gchar    is %dn",sizeof(gchar));​    g_print("The length of guchar   is %dn",sizeof(guchar));​    g_print("The length of gint     is %dn",sizeof(gint));​    g_print("The length of guint    is %dn",sizeof(guint));​    g_print("The length of gshort   is %dn",sizeof(gshort));​    g_print("The length of glong    is %dn",sizeof(glong));​    g_print("The length of gulong   is %dn",sizeof(gulong));​    g_print("The length of gint8    is %dn",sizeof(gint8));​    g_print("The length of guint8   is %dn",sizeof(guint8));​    g_print("The length of gint16   is %dn",sizeof(gint16));​    g_print("The length of guint16  is %dn",sizeof(guint16));​    g_print("The length of gint32   is %dn",sizeof(gint32));​    g_print("The length of guint32  is %dn",sizeof(guint32));​    g_print("The length of gint64   is %dn",sizeof(gint64));​    g_print("The length of guint64  is %dn",sizeof(guint64));​    g_print("The length of gfloat   is %dn",sizeof(gfloat));​    g_print("The length of gdouble  is %dn",sizeof(gdouble));​    g_print("The length of gsize    is %dn",sizeof(gsize));​    g_print("The length of gssize   is %dn",sizeof(gssize));​    return 0;}
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>gtk</tag>
        <tag>glib</tag>
      </tags>
  </entry>
  <entry>
    <title>GTK 创建最简单的一个创建窗口的示例</title>
    <url>/2011/12/18/linux-gtk-simple/</url>
    <content><![CDATA[GTK 创建最简单的一个创建窗口的示例程序代码：
#include &lt;gtk/gtk.h&gt;//PROTOTYPESvoid CloseRequest(GtkWidget *theWindow, gpointer data);gint main(gint argc,gchar *argv[]){    GtkWidget *window;    //get GTK+ to process the startup arguments    gtk_init(&amp;argc,&amp;argv);    //create the app’s main window    window = gtk_window_new(GTK_WINDOW_TOPLEVEL);    //connect a window’s signal to a signal function    gtk_signal_connect(GTK_OBJECT(window),“destroy”,GTK_SIGNAL_FUNC(CloseRequest),NULL);    gtk_widget_show(window);    gtk_main();    return 0;}//function to handle a close signal on the windowvoid CloseRequest(GtkWidget *theWindow,gpointer data){    gtk_main_quit();}


程序编译：
gcc –Wall –o test main.c `pkg-config gtk+-2.0 –libs –cflags`
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>gtk</tag>
        <tag>pkg-config</tag>
        <tag>libs</tag>
        <tag>cflags</tag>
      </tags>
  </entry>
  <entry>
    <title>undefined reference to GTK_TEXT</title>
    <url>/2011/12/27/linux-gtk-text%20copy/</url>
    <content><![CDATA[undefined reference to GTK_TEXT出错信息：
 undefined reference to GTK_TEXT
解决方法：
在#include前定义：#define GTK_ENABLE_BROKEN
原因：现在的Gtk+中默认不支持GtkText构件，而使用GtkTextView构件来代替。如果要使用GtkText构件，则必须在包含gtk.h头文件前定义GTK_ENABLE_BROKEN（#define GTK_ENABLE_BROKEN）
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>gtk</tag>
        <tag>GDK</tag>
        <tag>GTK_TEXT</tag>
        <tag>GTK_ENABLE_BROKEN</tag>
      </tags>
  </entry>
  <entry>
    <title>undefined reference to GTK_TEXT</title>
    <url>/2011/12/27/linux-gtk-text/</url>
    <content><![CDATA[undefined reference to GTK_TEXT出错信息：
 undefined reference to GTK_TEXT
解决方法：
在#include前定义：#define GTK_ENABLE_BROKEN
原因：现在的Gtk+中默认不支持GtkText构件，而使用GtkTextView构件来代替。如果要使用GtkText构件，则必须在包含gtk.h头文件前定义GTK_ENABLE_BROKEN（#define GTK_ENABLE_BROKEN）
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>gtk</tag>
        <tag>GDK</tag>
        <tag>GTK_TEXT</tag>
        <tag>GTK_ENABLE_BROKEN</tag>
      </tags>
  </entry>
  <entry>
    <title>解压命令之一 gunzip</title>
    <url>/2019/03/07/linux-gunzip-beginner/</url>
    <content><![CDATA[解压命令之一 gunzip.. _linux-beginner-gunzip:
官方的定义为：

gzip, gunzip, zcat – compression/decompression tool using Lempel-Ziv coding (LZ77)

参考gunzip命令
使用的方法为：
$ uname [OPTION]...

常用的一些选项为：

-a, --all：打印全部的信息
-s, --kernel-name：打印内核名
-n, --nodename：打印网络节点hostnme，即主机名
-r, --kernel-release：打印内核发行版
-v, --kernel-version：打印内核版本
-m, --machine：打印机器的硬件名字
-p, --processor：打印processor或者unknown
-i, --hardware-platform：打印硬件平台或者“unknown”
-o, --operating-system：打印操作系统

语法$ unzip [-cflptuvz][-agCjLMnoqsVX][-P &lt;密码&gt;][.zip文件][文件][-d &lt;目录&gt;][-x &lt;文件&gt;] 或 unzip [-Z]

参数：

-c 将解压缩的结果显示到屏幕上，并对字符做适当的转换。
-f 更新现有的文件。
-l 显示压缩文件内所包含的文件。
-p 与-c参数类似，会将解压缩的结果显示到屏幕上，但不会执行任何的转换。
-t 检查压缩文件是否正确。
-u 与-f参数类似，但是除了更新现有的文件外，也会将压缩文件中的其他文件解压缩到目录中。
-v 执行是时显示详细的信息。
-z 仅显示压缩文件的备注文字。
-a 对文本文件进行必要的字符转换。
-b 不要对文本文件进行字符转换。
-C 压缩文件中的文件名称区分大小写。
-j 不处理压缩文件中原有的目录路径。
-L 将压缩文件中的全部文件名改为小写。
-M 将输出结果送到more程序处理。
-n 解压缩时不要覆盖原有的文件。
-o 不必先询问用户，unzip执行后覆盖原有文件。
-P&lt;密码&gt; 使用zip的密码选项。
-q 执行时不显示任何信息。
-s 将文件名中的空白字符转换为底线字符。
-V 保留VMS的文件版本信息。
-X 解压缩时同时回存文件原来的UID/GID。
[.zip文件] 指定.zip压缩文件。
[文件] 指定要处理.zip压缩文件中的哪些文件。
-d&lt;目录&gt; 指定文件解压缩后所要存储的目录。
-x&lt;文件&gt; 指定不要处理.zip压缩文件中的哪些文件。
-Z unzip -Z等于执行zipinfo指令。

实例查看压缩文件中包含的文件：
# unzip -l abc.zip Archive: abc.zip Length   Date  Time  Name--------  ----  ----  ----  94618 05-21-10 20:44  a11.jpg  202001 05-21-10 20:44  a22.jpg    16 05-22-10 15:01  11.txt  46468 05-23-10 10:30  w456.JPG  140085 03-14-10 21:49  my.asp--------          -------  483188          5 files

-v 参数用于查看压缩文件目录信息，但是不解压该文件。
# unzip -v abc.zip Archive: abc.zipLength  Method  Size Ratio  Date  Time  CRC-32  Name-------- ------ ------- -----  ----  ----  ------  ----  94618 Defl:N  93353  1% 05-21-10 20:44 9e661437 a11.jpg 202001 Defl:N  201833  0% 05-21-10 20:44 1da462eb a22.jpg   16 Stored    16  0% 05-22-10 15:01 ae8a9910 ? +-|￥+-? (11).txt  46468 Defl:N  39997 14% 05-23-10 10:30 962861f2 w456.JPG 140085 Defl:N  36765 74% 03-14-10 21:49 836fcc3f my.asp--------     ------- ---              ------- 483188      371964 23%              5 files
]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>gunzip</tag>
        <tag>解压命令</tag>
        <tag>gzip</tag>
        <tag>压缩命令</tag>
        <tag>zcat</tag>
      </tags>
  </entry>
  <entry>
    <title>解压命令之一 gzip</title>
    <url>/2018/03/07/linux-gzip-beginner/</url>
    <content><![CDATA[解压命令之一 gzip.. _linux-beginner-gzip:
gzip用于对后缀为gz文件进行解压：
$ gzip -d data.gz

这个命令将解压examplefile.gz，并且在当前目录下生成一个名为data的解压后的文件。
但特别需要留意的是，这个操作会删除源文件，会删除源文件，会删除源文件。
所以如果你想保留原始压缩文件，一定记得使用-k选项：
$ gzip -dk data.gz

这会保留原始的data.gz文件，并生成一个解压后的data文件。
参考
:ref:unzip &lt;linux-beginner-unzip&gt;

]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>gunzip</tag>
        <tag>解压命令</tag>
        <tag>压缩命令</tag>
        <tag>zcat</tag>
        <tag>zip</tag>
        <tag>unzip</tag>
        <tag>zipcloak</tag>
        <tag>zipnote</tag>
        <tag>zipsplit</tag>
        <tag>归档压缩命令</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux reboot/poweroff/halt 命令</title>
    <url>/2013/02/07/linux-halt-beginner/</url>
    <content><![CDATA[优雅地关机 - halt.. _linux_halt_beginner:
.. note::  一曲新词酒一杯，去年天气旧亭台。 

晏殊 浣溪沙

Linux halt, poweroff, reboot 用来挂起、关机或者重启机器，成功后返回0。
这不是一个命令，这是三个命令，只不过三个命令的参数都是一致的。
参考 Linux reboot 命令。
:ref:Reboot &lt;linux_reboot_beginner&gt;
]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>shutdown</tag>
        <tag>reboot</tag>
        <tag>poweroff</tag>
        <tag>halt</tag>
        <tag>系统管理</tag>
      </tags>
  </entry>
  <entry>
    <title>从头开始的head</title>
    <url>/2012/02/12/linux-head-beginner/</url>
    <content><![CDATA[从头开始的head.. note::  待从头、收拾旧山河，朝天阙。  宋代 岳飞《满江红·写怀》
head命令用来查看文件头部的n行，如果没有指定的n，默认显示10行。
官方定义：

head - output the first part of files

命令格式$ head [option] [filename]  

参数option比较常用的如下所示：

-c &lt;数目&gt; 显示的字节数
-n &lt;行数&gt; 显示文件的头部 n 行内容

常规使用假定文件 text.txt 有 20 行，从 1-20 ，默认情况下的使用如下，显示前面的10行：
$ head text.txt12345678910





显示 前 N 行显示 text.txt 文件的开头 5 行，可以输入以下命令：
$ head -n 5 text.txt



按照字节显示显示文件前 20 个字节:
$ head -c 20 text.txt123456789





]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>文档查看</tag>
        <tag>文件操作</tag>
        <tag>文件管理</tag>
        <tag>head</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux的 head 命令</title>
    <url>/2012/02/12/linux-head/</url>
    <content><![CDATA[查看文件头部命令headhead命令用来查看文件头部的n行，如果没有指定的n，默认显示10行。
官方定义：

head - output the first part of files

命令格式：
$ head [option] [filename]  

参数option比较常用的如下所示：

-c &lt;数目&gt; 显示的字节数
-n &lt;行数&gt; 显示文件的头部 n 行内容

常规使用假定文件 text.txt 有 20 行，从 1-20 ，默认情况下的使用如下，显示前面的10行：
$ head text.txt12345678910





显示 前 N 行显示 text.txt 文件的开头 5 行，可以输入以下命令：
$ head -n 5 text.txt



按照字节显示显示文件前 20 个字节:
$ head -c 20 text.txt123456789





]]></content>
      <categories>
        <category>Linux</category>
        <category>Linux入门</category>
        <category>文档查看</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>head</tag>
      </tags>
  </entry>
  <entry>
    <title>雁过留痕的 history</title>
    <url>/2013/02/08/linux-history-beginner/</url>
    <content><![CDATA[雁过留痕的 history.. _linux_history_beginner:
.. note::  雁过留痕，人过留名。

晏殊 《浣溪沙》

history命令用于显示用户以前执行过的历史命令，并且能对历史命令进行追加和删除等操作。
如果你经常使用Linux命令，那么使用history命令可以有效地提升你的效率。
语法比较简单：
$ history [OPTIONS] [..]

常用参数：

-a    将当前shell会话的历史命令追加到命令历史文件中,命令历史文件是保存历史命令的配置文件 
-c    清空当前历史命令列表                                         
-d    删除历史命令列表中指定序号的命令                             
-n    从命令历史文件中读取本次Shell会话开始时没有读取的历史命令

显示所有的历史命令$ history 	1  sudo apt get update    2  sudo apt update    3  sudo apt upgrade    4  sudo apt install vim    5  ls    6  pwd    7  cd    8  ls    9  sudo apt install vim   10  sudo apt search pgplot   11  bash go.sh   12  sudo apt install zsh   13  bash down.sh   14  exit   15  echo $PS1   16  bash   17  exit   18  sh test.sh   19  bash   20  exit   21  rsync -rv --progress user@192.168.1.123:~/data1/ .   22  rsync -rv --progress user@192.168.1.123:~/src/ .    ......



列出最近的几条命令history后面跟上数字，就可以列出最近的几条命令：
$ history 3   8540  pwd   8541  echo $PATH   8542  git status



删除部分命令可以通过-d参数来删除某一条或者某些历史命令，支持正则表达式
# 删除第35条历史命令$ history -d 35# 删除第31到39条历史命令$ histor -d 3{1..9}

删除全部命令如果登陆某些调试机器，后面将不在使用，考虑到安全性，可以删除操作过的所有历史，通过-c参数，即clear的意思。
$ history -c



此时将没有任何历史操作。
炫技 - 如何获取使用的命令及频率$ history | awk 'BEGIN {FS="[ \t]+|\\|"} {print $3}' | sort | uniq -c | sort –nr    967 ls    507 cd    199 vim    199 python    165 cp    152 less    105 mv     95 rm     94 ll     90 echo     85 bash     72 cat     66 apt     59 pwd     51 mkdir     ...]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>history</tag>
        <tag>export</tag>
        <tag>pwd</tag>
        <tag>ignoredups</tag>
        <tag>linux炫技</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux history命令</title>
    <url>/2013/02/08/linux-history/</url>
    <content><![CDATA[history命令 – 显示与操纵历史命令history命令用于显示用户以前执行过的历史命令，并且能对历史命令进行追加和删除等操作。
如果你经常使用Linux命令，那么使用history命令可以有效地提升你的效率。
语法格式: history [参数] [目录]
常用参数：



-a
将当前shell会话的历史命令追加到命令历史文件中,命令历史文件是保存历史命令的配置文件



-c
清空当前历史命令列表


-d
删除历史命令列表中指定序号的命令


-n
从命令历史文件中读取本次Shell会话开始时没有读取的历史命令


-r
读取命令历史文件到当前的Shell历史命令内存缓冲区


-s
将指定的命令作为单独的条目加入命令历史内存缓冲区。在执行添加之前先删除命令历史内存缓冲区中最后一条命令


-w
把当前的shell历史命令内存缓冲区的内容写入命令历史文件


参考实例
显示最近的10条命令：
[root@linuxcool ~]# history 10  

将本次登录的命令写入历史文件中：
[root@linuxcool ~]# history -w

将命令历史文件中的内容读入到目前shell的history记忆中 ：
[root@linuxcool ~]# history -r  

将当前Shell会话的历史命令追加到命令历史文件中：
[root@linuxcool ~]# history -a  

清空当前历史命令列表：
[root@linuxcool ~]# history -c 



使用HISTCONTROL来消除命令历史中的连续重复条目在下面的例子中pwd被输入了三次，当你使用history的时候，你会看到这三条命令连续出现。设置HISTCONTROL为ignoredups,来消除重复命令：
# pwd# pwd# pwd# history | tail -444 pwd45 pwd46 pwd47 history | tail -4

[注: 上面pwd被执行了三次之后，历史中有三条pwd命令]
# export HISTCONTROL=ignoredups# pwd# pwd# pwd# history | tail -356 export HISTCONTROL=ignoredups57 pwd58 history | tail -4 [注：即使上面pwd被执行了三次，历史中也只有一条pwd命令]




用HISTIGNORE让history在存储时忽略某些指令有时你不想在记录里看到诸如pwd,ls之类的基本指令，可以用HISTIGNORE忽略这些指令。
注意在HISTIGNORE中添加ls，只忽略“ls”不忽略ls –l。一定要准确的写出要忽略的的指令。
# export HISTIGNORE=”pwd:ls:ls –ltr:”
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>history</tag>
        <tag>export</tag>
        <tag>pwd</tag>
        <tag>ignoredups</tag>
      </tags>
  </entry>
  <entry>
    <title>阁下贵姓 的 hostname</title>
    <url>/2013/12/01/linux-hostname-beginner/</url>
    <content><![CDATA[阁下贵姓 的 hostname.. _linux_hostname_beginner:
.. note::  主人何处去，暮雨相留。

晏殊 《浣溪沙》

正常情况下，系统启动的时候我们就会设置hostname。
不过大部分哥们在安装的时候估计不会特别在意。不过如果在管理或者登录的计算机比较多的情况下，设置主机名就是一件特别需要留意的事情了。
至少在设置了主机名后你就会知道ssh登录的是那台系统。
官方定义为：

hostname - show or set the system’s host name

hostname命令用于显示和设置系统的主机名称。环境变量HOSTNAME 或者 HOST 保存了当前的主机名。
使用方法为：
$ hostname [-b|--boot] [-F|--file filename] [hostname]

基本的使用为查看和修改。
临时更改运行系统的主机名系统如果正在运行，可以直接使用hostname来临时更改主机名，在系统重启前，都会保证有效。
命令如下：
$ hostname NEW_HOSTNAME


 注意这个命令话系统并不会永久保存新的主机名，重新启动机器之后还是原来的主机名。

永久更改主机名这里分为两种情况，主要为基于两种不同的主流发行版，需要修改文件，需要管理员权限。
Debian系列基于Debian系统的设置在文件/etc/hostname，系统启动时会读取该文件并调用初始化脚本/etc/init.d/hostname.sh
所以对于这类系统可以通过修改编辑文件/etc/hostname来更改。
/etc/init.d/hostname.sh start

修改完毕后，这个命令可以立即更改。
Redhat系列基于RedHat的系统使用文件 /etc/sysconfig/network来设置。可以通过修改该文件并使用hostname命令来设置。
还有其他的方法，你知道吗？
]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>ssh</tag>
        <tag>hostname</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux的hostname</title>
    <url>/2013/12/01/linux-hostname/</url>
    <content><![CDATA[Linux 的 Hostname命令正常情况下，系统启动的时候我们就会设置hostname。
不过大部分哥们在安装的时候估计不会特别在意。不过如果在管理或者登录的计算机比较多的情况下，设置主机名就是一件特别需要留意的事情了。
至少在设置了主机名后你就会知道ssh登录的是那台系统。
官方定义为：

hostname - show or set the system’s host name

hostname命令用于显示和设置系统的主机名称。环境变量HOSTNAME 或者 HOST 保存了当前的主机名。
使用方法为：
$ hostname [-b|--boot] [-F|--file filename] [hostname]

基本的使用为查看和修改。
临时更改运行系统的主机名系统如果正在运行，可以直接使用hostname来临时更改主机名，在系统重启前，都会保证有效。
命令如下：
$ hostname NEW_HOSTNAME


 注意这个命令话系统并不会永久保存新的主机名，重新启动机器之后还是原来的主机名。

永久更改主机名这里分为两种情况，主要为基于两种不同的主流发行版，需要修改文件，需要管理员权限。
Debian系列基于Debian系统的设置在文件/etc/hostname，系统启动时会读取该文件并调用初始化脚本/etc/init.d/hostname.sh
所以对于这类系统可以通过修改编辑文件/etc/hostname来更改。
/etc/init.d/hostname.sh start

修改完毕后，这个命令可以立即更改。
Redhat系列基于RedHat的系统使用文件 /etc/sysconfig/network来设置。可以通过修改该文件并使用hostname命令来设置。
还有其他的方法，你知道吗？
]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>ssh</tag>
        <tag>hostname</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux的 HPC</title>
    <url>/2019/02/12/linux-hpc/</url>
    <content><![CDATA[HPC 相关FLOPS is floating point operations per second. This is used as a measurement because historically floating point operations has been very expensive operations compared to other operations. 每秒浮点运算次数，亦称每秒峰值速度，（英语：Floating-point operations per second；缩写：FLOPS），即每秒所运行的浮点运算次数。浮点（floating-point）指的是带有小数的数值，浮点运算即是小数的四则运算，常用来测量电脑运算速度或被用来估算电脑性能，尤其是在使用到大量浮点运算的科学计算领域中。因为FLOPS后缀的那个S代表秒，而不是复数，所以不能够省略。在多数情况下，测算FLOPS比测算每秒指令数（IPS）要准确。
浮点运算实际上包括了所有涉及浮点数的运算，在某类应用软件中常常出现，比较整数运算更用时间。现今大部分的处理器中都有浮点运算器。因此每秒浮点运算次数所量测的实际上就是浮点运算器的运行速度。而最常用来测量每秒浮点运算次数的基准程序（benchmark）之一，是Linpack。
FLOPS在高性能计算机集群（超算）上可以使用这一公式得出：${\displaystyle {\text{FLOPS}}={\text{racks}}\times {\frac {\text{nodes}}{\text{rack}}}\times {\frac {\text{sockets}}{\text{node}}}\times {\frac {\text{cores}}{\text{socket}}}\times {\frac {\text{cycles}}{\text{second}}}\times {\frac {\text{FLOPs}}{\text{cycle}}}}$
简化到计算机只拥有一块CPU的情况时，可以使用以下公式：
${\displaystyle {\text{FLOPS}}={\text{cores}}\times {\frac {\text{cycles}}{\text{second}}}\times {\frac {\text{FLOPs}}{\text{cycle}}}}$
]]></content>
      <categories>
        <category>Linux</category>
        <category>HPC</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>hpc</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux的 htop 命令</title>
    <url>/2016/02/12/linux-htop/</url>
    <content><![CDATA[Linux 的htop命令htop可以查看每个进行的内存负载。htop提供的信息与top类似，不过htop提供了更好的交互、彩色显示以及控制。
]]></content>
      <categories>
        <category>Linux炫技</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>htop</tag>
      </tags>
  </entry>
  <entry>
    <title>显示硬件信息的hwinfo</title>
    <url>/2019/03/17/linux-hwinfo-beginner/</url>
    <content><![CDATA[显示硬件信息的hwinfo.. _linux_hwinfo_beginner:
.. note::  相见时难别亦难，东风无力百花残。

李商隐 《无题》

hwinfo 又一个用于显示硬件信息的命令。
可以获得 Linux 系统的各种硬件组件（如CPU、内存、显卡、硬盘等）的详细信息。
显示所有硬件信息：   sudo hwinfo

   列出系统上几乎所有可用硬件的详细信息。
指定特定硬件信息：   sudo hwinfo --cpusudo hwinfo --memorysudo hwinfo --gfxcardsudo hwinfo --disk

   通过在命令后添加 --cpu、--memory、--gfxcard、--disk 等参数，获取特定硬件的信息。
]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>硬件信息</tag>
        <tag>lsblk</tag>
      </tags>
  </entry>
  <entry>
    <title>我也是有身份...证的人 之 id</title>
    <url>/2013/02/12/linux-id-beginner/</url>
    <content><![CDATA[我也是有身份…证的人 之 idid命令用于显示用户的以及其所属群组的ID。
官方定义为：

id - print real and effective user and group IDs

语法$ id [OPTION]... [USER]

参数说明：

-g, --group：仅仅显示组的ID
-G, --groups：显示所有组的IDs
-u, --user：打印用户的ID

默认使用显示当前用户信息
$ id uid=1000(user) gid=1000(user) groups=1000(user),980(data),1006(monitor)

可以看到用户user的ID及组ID均为1000，该用户还属于data和monitor组。
显示用户群组的ID$ id -g1000

仅显示用户组的ID  
]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>id</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux的 whoami命令</title>
    <url>/2013/02/12/linux-id/</url>
    <content><![CDATA[id 我也是有身份…证的人id命令用于显示用户的以及其所属群组的ID。
官方定义为：

id - print real and effective user and group IDs

语法$ id [OPTION]... [USER]

参数说明：

-g, --group：仅仅显示组的ID
-G, --groups：显示所有组的IDs
-u, --user：打印用户的ID

默认使用显示当前用户信息
$ id uid=1000(user) gid=1000(user) groups=1000(user),980(data),1006(monitor)

可以看到用户user的ID及组ID均为1000，该用户还属于data和monitor组。
显示用户群组的ID$ id -g1000

仅显示用户组的ID  
]]></content>
      <categories>
        <category>Linux</category>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>id</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux IDE</title>
    <url>/2013/03/04/linux-ide/</url>
    <content><![CDATA[开发IDE环境xwpexwpe：Fred Kruse开发的一个基于字符的文件管理器和文件编辑器，网址为：http://www.identicalsoftware.com/xwpe/ ，
c-Forge IDEC-Forge是一个集成的开发工具，支持多种语言开发环境，能够为你提供完善的开发环境，支持的语言包括C、C++、HTML、QT、GTK等等。
KdevelopKDevelop，是一个支持多程序设计语言的集成开发环境。它运行于Linux和其它类Unix环境。它本身不包含编译器，而是调用其它编译器来编译程序。目前的版本4.3.0。它建立在 KDE 4 技术之上，并有良好的 C、C++ 和 PHP 开发支援。KDevelop 3.5.5已支持Ada、Bash、C、C++、Fortran、Haskell、Java、Pascal、Perl、Python、Ruby、SQL等程序设计语言。gbuilder
anjutaAnjuta是一个建立在GNU/Linux下为C、C++提供编译的集成开发环境。它最初旨在为GTK/GNOME设计，并且自身具有很好的编程属性。这其中包括项目管理、应用开发、交互调试以及强大的代码编辑和语法增彩的性质。Anjuta成为Gnome环境下最理想的开发工具，其主要功能和KDE下的Kdevelop相似，目前最新的版本是3.2.0。
KylixKylix是Borland公司推出的GNU/Linux版的开发环境，相对于Windows下的Delphi以及C＋＋ Builder。通过Kylix，程序员可以在GNU/Linux下使用Object Pascal、C++或者C语言，进行软件开发
EclipseEclipse是著名的跨平台开源集成开发环境（IDE）。最初主要用来Java语言开发，目前亦有人通过插件使其作为C++、Python、PHP等其他语言的开发工具。Eclipse的本身只是一个框架平台，但是众多插件的支持，使得Eclipse拥有较佳的灵活性。许多软件开发商以Eclipse为框架开发自己的IDE。
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>IDE</tag>
        <tag>anjuta</tag>
        <tag>xwpe</tag>
        <tag>c-Forge</tag>
        <tag>KDevelop</tag>
        <tag>Kylix</tag>
        <tag>Eclipse</tag>
      </tags>
  </entry>
  <entry>
    <title>查看网络信息的原初 ifconfig</title>
    <url>/2010/08/26/linux-ifconfig-beginner/</url>
    <content><![CDATA[查看网络信息的原初 ifconfigLinux ifconfig命令用于显示或设置网络设备，在调试或调优的时间经常使用。
官方定义为：

ifconfig - configure a network interface

对于这个命令，一般只要掌握如何查看，如何设置IP地址基本就可以了，对于网络钻的比较深的，还需要更多一些参数。
使用方法为：
# 显示$ ifconfig [-v] [-a] [-s] [interface]# 设置$ ifconfig [-v] interface [aftype] options | address ...



一些参数的含义为：

-a ：显示所有网卡的状态，即使是down的状态
-s：显示一个短列表
interface mtu N  设置最大传输单元【需要管理员权限】
netmask addr：设置掩码地址【需要管理员权限】
interface up     激活网卡【需要管理员权限】
interface down   关闭网卡【需要管理员权限】
interface hw ether xx.xx.xx.xx.xx.xx 设置MAC地址【需要管理员权限】

默认无参数使用如果不指定任何参数，直接显示当前活动的接口，如下：
$ ifconfigeth0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500        inet 192.168.1.123  netmask 255.255.255.0  broadcast 192.168.1.255        inet6 xxxx::xxxx:xxxx:xxxx:xxxx  prefixlen 64  scopeid 0x20&lt;link&gt;        inet6 xxxx:xxxx:xxxx:xxxx:xxxx:xxxx:xxxx:xxxx  prefixlen 64  scopeid 0x0&lt;global&gt;        ether xx:xx:xx:xx:xx:xx  txqueuelen 1000  (Ethernet)        RX packets 5634431  bytes 4994127142 (4.6 GiB)        RX errors 0  dropped 0  overruns 0  frame 0        TX packets 858051  bytes 109858013 (104.7 MiB)        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0        device memory 0xc7320000-c733ffff  eth1: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500        inet 192.168.6.123  netmask 255.255.255.0  broadcast 192.168.6.255        inet6 xxxx::xxxx:xxxx:xxxx:xxxx  prefixlen 64  scopeid 0x20&lt;link&gt;        ether xx:xx:xx:xx:xx:xx  txqueuelen 1000  (Ethernet)        RX packets 1547215  bytes 92862867 (88.5 MiB)        RX errors 0  dropped 6  overruns 0  frame 0        TX packets 3230  bytes 922051 (900.4 KiB)        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0lo: flags=73&lt;UP,LOOPBACK,RUNNING&gt;  mtu 65536        inet 127.0.0.1  netmask 255.0.0.0        inet6 ::1  prefixlen 128  scopeid 0x10&lt;host&gt;        loop  txqueuelen 1000  (Local Loopback)        RX packets 219608  bytes 105943591 (101.0 MiB)        RX errors 0  dropped 0  overruns 0  frame 0        TX packets 219608  bytes 105943591 (101.0 MiB)        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0

其中一般希望看到的信息包括：

inet：为IP地址
ether：为MAC地址
MTU：最大传输单元

不加任何参数只会显示已经配置并且活跃的网卡信息，如果使用ifconfig -a就可以显示全部的网卡状态了，即使有些网卡是down的状态。
亦或者指定一个interface，比如上面的eth1，则只输出这个网卡的信息，如下：
$ ifconfig eth1eth1: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500        inet 192.168.6.123  netmask 255.255.255.0  broadcast 192.168.6.255        inet6 xxxx::xxxx:xxxx:xxxx:xxxx  prefixlen 64  scopeid 0x20&lt;link&gt;        ether xx:xx:xx:xx:xx:xx  txqueuelen 1000  (Ethernet)        RX packets 1547215  bytes 92862867 (88.5 MiB)        RX errors 0  dropped 6  overruns 0  frame 0        TX packets 3230  bytes 922051 (900.4 KiB)        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0





-s显示短列表如果只想看到MTU以及数据包的状态，可以用该参数，如下：
$ ifconfig -sIface      MTU    RX-OK RX-ERR RX-DRP RX-OVR    TX-OK TX-ERR TX-DRP TX-OVR Flgeth0     1500   5665450      0      0 0        867639      0      0      0 BMRUeth1     1500   3489187217   0 101054 0      501260400     0      0      0 BMUlo       65536  219708       0      0 0        219708      0      0      0 LRU

输出信息主要包含了MTU值，发送及接收的数据情况。
配置IP地址如下对eth0网卡配置IP地址、掩码以及广播地址，当然可以分布操作
# 给eth0配置IP地址$ ifconfig eth0 192.168.1.123 # 给eth0配置IP地址和子网掩码$ ifconfig eth0 192.168.1.123 netmask 255.255.255.0 # 给eth0配置IP地址、子网掩码还有广播地址$ ifconfig eth0 192.168.1.123 netmask 255.255.255.0 broadcast 192.168.1.255



修改MTU在某些情况下可能需要修改MTU值，比如增到到MTU为9000，如下：
$ ifconfig eth1eth1: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500        inet 192.168.6.123  netmask 255.255.255.0  broadcast 192.168.6.255        inet6 xxxx::xxxx:xxxx:xxxx:xxxx  prefixlen 64  scopeid 0x20&lt;link&gt;        ether xx:xx:xx:xx:xx:xx  txqueuelen 1000  (Ethernet)        RX packets 1547215  bytes 92862867 (88.5 MiB)        RX errors 0  dropped 6  overruns 0  frame 0        TX packets 3230  bytes 922051 (900.4 KiB)        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0# 修改MTU$ ifconfig eth1 MTU 9000$ ifconfig eth1eth1: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 9000        inet 192.168.6.123  netmask 255.255.255.0  broadcast 192.168.6.255        inet6 xxxx::xxxx:xxxx:xxxx:xxxx  prefixlen 64  scopeid 0x20&lt;link&gt;        ether xx:xx:xx:xx:xx:xx  txqueuelen 1000  (Ethernet)        RX packets 1547215  bytes 92862867 (88.5 MiB)        RX errors 0  dropped 6  overruns 0  frame 0        TX packets 3230  bytes 922051 (900.4 KiB)        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0

已经看到输出的信息已经把mtu更新为了9000.

这个值对网络传输影响很大。

启动关闭网卡启动关闭主要的应用场景为重新设置了IP地址，或者暂时对某个网卡进行操作。
# 关闭eth0$ ifconfig eth0 down# 启动eth0$ ifconfig eth0 up


不过需要注意的是

很多的设置操作都需要管理员权限；
很多操作在重启后设置都会还原，如果需要永久设置，需要更改network的一些配置文件；
这个程序基本被淘汰了，已经不在更新，所有的操作或者用法均可以通过ip来搞定。等明天~。

]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>Linux炫技</tag>
        <tag>ifconfig</tag>
        <tag>网络命令</tag>
        <tag>系统管理</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux 之 ifconfig 命令</title>
    <url>/2010/08/26/linux-ifconfig/</url>
    <content><![CDATA[Linux ifconfig命令Linux ifconfig命令用于显示或设置网络设备，在调试或调优的时间经常使用。
官方定义为：

ifconfig - configure a network interface

对于这个命令，一般只要掌握如何查看，如何设置IP地址基本就可以了，对于网络钻的比较深的，还需要更多一些参数。
使用方法为：
# 显示$ ifconfig [-v] [-a] [-s] [interface]# 设置$ ifconfig [-v] interface [aftype] options | address ...



一些参数的含义为：

-a ：显示所有网卡的状态，即使是down的状态
-s：显示一个短列表
interface mtu N  设置最大传输单元【需要管理员权限】
netmask addr：设置掩码地址【需要管理员权限】
interface up     激活网卡【需要管理员权限】
interface down   关闭网卡【需要管理员权限】
interface hw ether xx.xx.xx.xx.xx.xx 设置MAC地址【需要管理员权限】

默认无参数使用如果不指定任何参数，直接显示当前活动的接口，如下：
$ ifconfigeth0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500        inet 192.168.1.123  netmask 255.255.255.0  broadcast 192.168.1.255        inet6 xxxx::xxxx:xxxx:xxxx:xxxx  prefixlen 64  scopeid 0x20&lt;link&gt;        inet6 xxxx:xxxx:xxxx:xxxx:xxxx:xxxx:xxxx:xxxx  prefixlen 64  scopeid 0x0&lt;global&gt;        ether xx:xx:xx:xx:xx:xx  txqueuelen 1000  (Ethernet)        RX packets 5634431  bytes 4994127142 (4.6 GiB)        RX errors 0  dropped 0  overruns 0  frame 0        TX packets 858051  bytes 109858013 (104.7 MiB)        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0        device memory 0xc7320000-c733ffff  eth1: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500        inet 192.168.6.123  netmask 255.255.255.0  broadcast 192.168.6.255        inet6 xxxx::xxxx:xxxx:xxxx:xxxx  prefixlen 64  scopeid 0x20&lt;link&gt;        ether xx:xx:xx:xx:xx:xx  txqueuelen 1000  (Ethernet)        RX packets 1547215  bytes 92862867 (88.5 MiB)        RX errors 0  dropped 6  overruns 0  frame 0        TX packets 3230  bytes 922051 (900.4 KiB)        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0lo: flags=73&lt;UP,LOOPBACK,RUNNING&gt;  mtu 65536        inet 127.0.0.1  netmask 255.0.0.0        inet6 ::1  prefixlen 128  scopeid 0x10&lt;host&gt;        loop  txqueuelen 1000  (Local Loopback)        RX packets 219608  bytes 105943591 (101.0 MiB)        RX errors 0  dropped 0  overruns 0  frame 0        TX packets 219608  bytes 105943591 (101.0 MiB)        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0

其中一般希望看到的信息包括：

inet：为IP地址
ether：为MAC地址
MTU：最大传输单元

不加任何参数只会显示已经配置并且活跃的网卡信息，如果使用ifconfig -a就可以显示全部的网卡状态了，即使有些网卡是down的状态。
亦或者指定一个interface，比如上面的eth1，则只输出这个网卡的信息，如下：
$ ifconfig eth1eth1: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500        inet 192.168.6.123  netmask 255.255.255.0  broadcast 192.168.6.255        inet6 xxxx::xxxx:xxxx:xxxx:xxxx  prefixlen 64  scopeid 0x20&lt;link&gt;        ether xx:xx:xx:xx:xx:xx  txqueuelen 1000  (Ethernet)        RX packets 1547215  bytes 92862867 (88.5 MiB)        RX errors 0  dropped 6  overruns 0  frame 0        TX packets 3230  bytes 922051 (900.4 KiB)        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0





-s显示短列表如果只想看到MTU以及数据包的状态，可以用该参数，如下：
$ ifconfig -sIface      MTU    RX-OK RX-ERR RX-DRP RX-OVR    TX-OK TX-ERR TX-DRP TX-OVR Flgeth0     1500   5665450      0      0 0        867639      0      0      0 BMRUeth1     1500   3489187217   0 101054 0      501260400     0      0      0 BMUlo       65536  219708       0      0 0        219708      0      0      0 LRU

输出信息主要包含了MTU值，发送及接收的数据情况。
配置IP地址如下对eth0网卡配置IP地址、掩码以及广播地址，当然可以分布操作
# 给eth0配置IP地址$ ifconfig eth0 192.168.1.123 # 给eth0配置IP地址和子网掩码$ ifconfig eth0 192.168.1.123 netmask 255.255.255.0 # 给eth0配置IP地址、子网掩码还有广播地址$ ifconfig eth0 192.168.1.123 netmask 255.255.255.0 broadcast 192.168.1.255



修改MTU在某些情况下可能需要修改MTU值，比如增到到MTU为9000，如下：
$ ifconfig eth1eth1: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500        inet 192.168.6.123  netmask 255.255.255.0  broadcast 192.168.6.255        inet6 xxxx::xxxx:xxxx:xxxx:xxxx  prefixlen 64  scopeid 0x20&lt;link&gt;        ether xx:xx:xx:xx:xx:xx  txqueuelen 1000  (Ethernet)        RX packets 1547215  bytes 92862867 (88.5 MiB)        RX errors 0  dropped 6  overruns 0  frame 0        TX packets 3230  bytes 922051 (900.4 KiB)        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0# 修改MTU$ ifconfig eth1 MTU 9000$ ifconfig eth1eth1: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 9000        inet 192.168.6.123  netmask 255.255.255.0  broadcast 192.168.6.255        inet6 xxxx::xxxx:xxxx:xxxx:xxxx  prefixlen 64  scopeid 0x20&lt;link&gt;        ether xx:xx:xx:xx:xx:xx  txqueuelen 1000  (Ethernet)        RX packets 1547215  bytes 92862867 (88.5 MiB)        RX errors 0  dropped 6  overruns 0  frame 0        TX packets 3230  bytes 922051 (900.4 KiB)        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0

已经看到输出的信息已经把mtu更新为了9000.

这个值对网络传输影响很大。

启动关闭网卡启动关闭主要的应用场景为重新设置了IP地址，或者暂时对某个网卡进行操作。
# 关闭eth0$ ifconfig eth0 down# 启动eth0$ ifconfig eth0 up



修改MAC地址#关闭网卡$ ifconfig eth0 down #修改MAC地址$ ifconfig eth0 hw ether 01:02:02:04:05:06 #启动网卡$ ifconfig eth0 up 

一般什么情况下来修改MAC地址呢，大多数是在做网络测试还有就LICENSE的时候。
启用和关闭ARP协议# 开启ARP$ ifconfig eth0 arp# 关闭ARP$ ifconfig eth0 -arp







不过需要注意的是

很多的设置操作都需要管理员权限；
很多操作在重启后设置都会还原，如果需要永久设置，需要更改network的一些配置文件；
这个程序基本被淘汰了，已经不在更新，所有的操作或者用法均可以通过ip来搞定。等明天~。

]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>Linux炫技</tag>
        <tag>ifconfig</tag>
        <tag>网络</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux的 info 命令</title>
    <url>/2011/02/12/linux-info/</url>
    <content><![CDATA[系统帮助命令 info和man命令类似，info也提供了系统命令的详细帮助信息。
区别为man是linux系统标准帮助手册，而info手册通常是自由软件的帮助手册。一般而言info的内容比man的内容丰富和精确。
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>info</tag>
      </tags>
  </entry>
  <entry>
    <title>在文件开头插入一行或一段文本</title>
    <url>/2020/03/07/linux-insert-content-at-header/</url>
    <content><![CDATA[在文件开头插入一行或一段文本假定文件hello.txt的内容如下所示：
Hello World!



源文件为：
.. literalinclude:: ../../src/hello.txt
现在有一个诉求就是，如果在文件的行首增加一行文本，比如Hello letsProgramming!
解决方法有两个，如下：
通过sed进行便捷操作$ sed  '1s/^/hello letsProgramming! /' hello.txt &gt; hello_new.txt



执行完后的内容如下所示：
此时文件hello_new.txt的内容如下所示：
Hello letsProgramming!Hello World!





源文件为：
.. literalinclude:: ../../src/hello_new.txt
增加多行内容的方法假定希望把一下的内容增加到行首：
Hello letsProgramming! 1Hello letsProgramming! 2Hello letsProgramming! 3Hello letsProgramming! 4Hello letsProgramming! 5Hello letsProgramming! 6Hello letsProgramming! 7Hello letsProgramming! 8



.. literalinclude:: ../../src/content.txt
此时可以使用如下的方式：
{ cat content.txt ; cat hello.txt; } &gt; hello_multi.txt



$ cat hello_multi.txt Hello letsProgramming! 1Hello letsProgramming! 2Hello letsProgramming! 3Hello letsProgramming! 4Hello letsProgramming! 5Hello letsProgramming! 6Hello letsProgramming! 7Hello letsProgramming! 8Hello World!



.. literalinclude:: ../../src/hello_multi.txt
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>sed</tag>
        <tag>Command Grouping</tag>
      </tags>
  </entry>
  <entry>
    <title>网络配置的大拿 ip</title>
    <url>/2016/08/26/linux-ip-beginner/</url>
    <content><![CDATA[网络配置的大拿 ipLinux ip 命令与 ifconfig 命令类似，但比 ifconfig 命令更加强大，主要用于显示或设置网络设备。
已经在Linux 2.2 加入到了内核。所以ip是加强版的网络配置工具，用来替代ifconfig并强化其他功能。
官方定义为：

 ip - show / manipulate routing, devices, policy routing and tunnels

对于这个命令，命令集是相当的多。先说一些基础的，其他就要自己摸索了。
使用方法为：
$ ip [ OPTIONS ] OBJECT { COMMAND | help }$ ip [ -force ] -batch filename   # OBJECT的取值   # OBJECT := { link | address | addrlabel | route | rule | neigh | ntable | tunnel | tuntap | maddress | mroute | mrule | monitor | xfrm | netns | l2tp | tcp_metrics | token | macsec }# OPTIONS的取值  # OPTIONS := { -V[ersion] | -h[uman-readable] | -s[tatistics] | -d[etails] | -r[esolve] | -iec | -f[amily] { inet | inet6 | ipx | dnet | link } | -4 | -6 | -I | -D | -B | -0 | -l[oops] { maximum-addr-flush-attempts } | -o[neline] | -rc[vbuf] [size] | -t[imestamp] | -ts[hort] | -n[etns] name | -a[ll] | -c[olor] }



COMMAND的值主要取决于OBJECT，可能有所不同，一般可以使用add，delete和show（或者list），均可以输入help来进行查询。
OBJECT中常用的为：

link 网络设备
address 设备上的协议地址
-s, -stats, -statistics 统计化输出

显示网络设备# 显示网络设备$ ip link show1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:002: eno1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc mq state UP mode DEFAULT group default qlen 1000    link/ether xx:xx:xx:xx:xx:xx brd ff:ff:ff:ff:ff:ff3: eno2: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 9000 qdisc mq state DOWN mode DEFAULT group default qlen 1000    link/ether xx:xx:xx:xx:xx:xx brd ff:ff:ff:ff:ff:ff# 显示IP等更多信息$ ip address show1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00    inet 127.0.0.1/8 scope host lo       valid_lft forever preferred_lft forever    inet6 ::1/128 scope host        valid_lft forever preferred_lft forever2: eno1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc mq state UP group default qlen 1000    link/ether xx:xx:xx:xx:xx:xx brd ff:ff:ff:ff:ff:ff    inet 192.168.1.123/24 brd 192.168.254.255 scope global noprefixroute eno1       valid_lft forever preferred_lft forever    inet6 xxxx:xxxx:xxxx:xxxx:xxxx:xxxx:xxxx:xxxx/64 scope global noprefixroute        valid_lft forever preferred_lft forever3: eno2: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 9000 qdisc mq state DOWN group default qlen 1000    link/ether xx:xx:xx:xx:xx:xx brd ff:ff:ff:ff:ff:ff

命令中的show为默认，也可以直接使用ip link或者ip address，结果一致。
设置IP地址可以通过ip addr add/del xxx.xxx.xxx.xxx dev interface 来设置或者删除IP地址。
如下设置or删除eth0的IP地址。
# 设置IP地址$ ip addr add 192.168.0.1/24 dev eth0 # 删除IP地址$ ip addr del 192.168.0.1/24 dev eth0 



启动关闭网卡与ifconfig类似，也使用up与down来进行启动和关闭，具体如下：
# 开启网卡$ ip link set eth0 up             # 关闭网卡$ ip link set eth0 down           



统计方便阅读选项-s可以统计一些信息方便我们阅读，如下看看网络的情况：
$ ip -s link1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00    RX: bytes  packets  errors  dropped overrun mcast       871883256468 251700492 0       0       0       0           TX: bytes  packets  errors  dropped carrier collsns     871883256468 251700492 0       0       0       0       2: eno1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc mq state UP mode DEFAULT group default qlen 1000    link/ether xx:xx:xx:xx:xx:xx brd ff:ff:ff:ff:ff:ff    RX: bytes  packets  errors  dropped overrun mcast       64930085920632 50955323447 0       613156  0       472190933     TX: bytes  packets  errors  dropped carrier collsns     17534345850354 17448077191 0       0       0       0       3: eno2: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 9000 qdisc mq state DOWN mode DEFAULT group default qlen 1000    link/ether xx:xx:xx:xx:xx:xx brd ff:ff:ff:ff:ff:ff    RX: bytes  packets  errors  dropped overrun mcast       0          0        0       0       0       0           TX: bytes  packets  errors  dropped carrier collsns     0          0        0       0       0       0  

可以看到对输出进行了一些格式化，看起来更直观。
]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>Linux炫技</tag>
        <tag>ip</tag>
        <tag>网络命令</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux 之 ip 命令</title>
    <url>/2016/08/26/linux-ip/</url>
    <content><![CDATA[Linux ip命令Linux ip 命令与 ifconfig 命令类似，但比 ifconfig 命令更加强大，主要用于显示或设置网络设备。
已经在Linux 2.2 加入到了内核。所以ip是加强版的网络配置工具，用来替代ifconfig并强化其他功能。
官方定义为：

 ip - show / manipulate routing, devices, policy routing and tunnels

对于这个命令，命令集是相当的多。先说一些基础的，其他就要自己摸索了。
使用方法为：
$ ip [ OPTIONS ] OBJECT { COMMAND | help }$ ip [ -force ] -batch filename   # OBJECT的取值   # OBJECT := { link | address | addrlabel | route | rule | neigh | ntable | tunnel | tuntap | maddress | mroute | mrule | monitor | xfrm | netns | l2tp | tcp_metrics | token | macsec }# OPTIONS的取值  # OPTIONS := { -V[ersion] | -h[uman-readable] | -s[tatistics] | -d[etails] | -r[esolve] | -iec | -f[amily] { inet | inet6 | ipx | dnet | link } | -4 | -6 | -I | -D | -B | -0 | -l[oops] { maximum-addr-flush-attempts } | -o[neline] | -rc[vbuf] [size] | -t[imestamp] | -ts[hort] | -n[etns] name | -a[ll] | -c[olor] }



COMMAND的值主要取决于OBJECT，可能有所不同，一般可以使用add，delete和show（或者list），均可以输入help来进行查询。
OBJECT中常用的为：

link 网络设备
address 设备上的协议地址
-s, -stats, -statistics 统计化输出

显示网络设备# 显示网络设备$ ip link show1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:002: eno1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc mq state UP mode DEFAULT group default qlen 1000    link/ether xx:xx:xx:xx:xx:xx brd ff:ff:ff:ff:ff:ff3: eno2: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 9000 qdisc mq state DOWN mode DEFAULT group default qlen 1000    link/ether xx:xx:xx:xx:xx:xx brd ff:ff:ff:ff:ff:ff# 显示IP等更多信息$ ip address show1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00    inet 127.0.0.1/8 scope host lo       valid_lft forever preferred_lft forever    inet6 ::1/128 scope host        valid_lft forever preferred_lft forever2: eno1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc mq state UP group default qlen 1000    link/ether xx:xx:xx:xx:xx:xx brd ff:ff:ff:ff:ff:ff    inet 192.168.1.123/24 brd 192.168.254.255 scope global noprefixroute eno1       valid_lft forever preferred_lft forever    inet6 xxxx:xxxx:xxxx:xxxx:xxxx:xxxx:xxxx:xxxx/64 scope global noprefixroute        valid_lft forever preferred_lft forever3: eno2: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 9000 qdisc mq state DOWN group default qlen 1000    link/ether xx:xx:xx:xx:xx:xx brd ff:ff:ff:ff:ff:ff

命令中的show为默认，也可以直接使用ip link或者ip address，结果一致。
设置IP地址可以通过ip addr add/del xxx.xxx.xxx.xxx dev interface 来设置或者删除IP地址。
如下设置or删除eth0的IP地址。
# 设置IP地址$ ip addr add 192.168.0.1/24 dev eth0 # 删除IP地址$ ip addr del 192.168.0.1/24 dev eth0 



启动关闭网卡与ifconfig类似，也使用up与down来进行启动和关闭，具体如下：
# 开启网卡$ ip link set eth0 up             # 关闭网卡$ ip link set eth0 down           



统计方便阅读选项-s可以统计一些信息方便我们阅读，如下看看网络的情况：
$ ip -s link1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00    RX: bytes  packets  errors  dropped overrun mcast       871883256468 251700492 0       0       0       0           TX: bytes  packets  errors  dropped carrier collsns     871883256468 251700492 0       0       0       0       2: eno1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc mq state UP mode DEFAULT group default qlen 1000    link/ether xx:xx:xx:xx:xx:xx brd ff:ff:ff:ff:ff:ff    RX: bytes  packets  errors  dropped overrun mcast       64930085920632 50955323447 0       613156  0       472190933     TX: bytes  packets  errors  dropped carrier collsns     17534345850354 17448077191 0       0       0       0       3: eno2: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 9000 qdisc mq state DOWN mode DEFAULT group default qlen 1000    link/ether xx:xx:xx:xx:xx:xx brd ff:ff:ff:ff:ff:ff    RX: bytes  packets  errors  dropped overrun mcast       0          0        0       0       0       0           TX: bytes  packets  errors  dropped carrier collsns     0          0        0       0       0       0  

可以看到对输出进行了一些格式化，看起来更直观。
#TODO
OBJECT 取值含义如下：

addrlabel：协议地址选择的标签配置
route：路由表条目
rule：路由策略数据库中的规则

OPTIONS 为常用选项，值可以是以下几种：
实例ip link set eth0 promisc on      # 开启网卡的混合模式ip link set eth0 promisc offi    # 关闭网卡的混个模式ip link set eth0 txqueuelen 1200 # 设置网卡队列长度ip link set eth0 mtu 1400        # 设置网卡最大传输单元ip route show # 显示系统路由ip route add default via 192.168.1.254   # 设置系统默认路由ip route list                 # 查看路由信息ip route add 192.168.4.0/24  via  192.168.0.254 dev eth0 # 设置192.168.4.0网段的网关为192.168.0.254,数据走eth0接口ip route add default via  192.168.0.254  dev eth0        # 设置默认网关为192.168.0.254ip route del 192.168.4.0/24   # 删除192.168.4.0网段的网关ip route del default          # 删除默认路由ip route delete 192.168.1.0/24 dev eth0 # 删除路由

用 ip 命令显示网络设备的运行状态：
[root@localhost ~]# ip link list1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 16436 qdisc noqueue    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:002: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast qlen 1000    link/ether 00:16:3e:00:1e:51 brd ff:ff:ff:ff:ff:ff3: eth1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast qlen 1000    link/ether 00:16:3e:00:1e:52 brd ff:ff:ff:ff:ff:ff

显示核心路由表：
[root@localhost ~]# ip route list 112.124.12.0/22 dev eth1  proto kernel  scope link  src 112.124.15.13010.160.0.0/20 dev eth0  proto kernel  scope link  src 10.160.7.81192.168.0.0/16 via 10.160.15.247 dev eth0172.16.0.0/12 via 10.160.15.247 dev eth010.0.0.0/8 via 10.160.15.247 dev eth0default via 112.124.15.247 dev eth1

显示邻居表：
[root@localhost ~]# ip neigh list112.124.15.247 dev eth1 lladdr 00:00:0c:9f:f3:88 REACHABLE10.160.15.247 dev eth0 lladdr 00:00:0c:9f:f2:c0 STALE

获取主机所有网络接口炫技：
ip link | grep -E '^[0-9]' | awk -F: '{print $2}'







   -h, -human, -human-readable
          output statistics with human readable values followed by suffix.

   -b, -batch &lt;FILENAME&gt;
          Read commands from provided file or standard input and invoke them.  First failure will cause termination of ip.

   -force Don't terminate ip on errors in batch mode.  If there were any errors during execution of the commands, the application return code will be non zero.

​​​       -d, -details              Output more detailed information.
   -l, -loops &lt;COUNT&gt;
          Specify maximum number of loops the 'ip address flush' logic will attempt before giving up. The default is 10.  Zero (0) means loop until all addresses are
          removed.

   -f, -family &lt;FAMILY&gt;
          Specifies the protocol family to use. The protocol family identifier can be one of inet, inet6, bridge, ipx, dnet, mpls or link.  If this option is not present,
          the protocol family is guessed from other arguments. If the rest of the command line does not give enough information to guess the family, ip falls back to the
          default one, usually inet or any.  link is a special family identifier meaning that no networking protocol is involved.

​​       -o, -oneline​              output each record on a single line, replacing line feeds with the ‘' character. This is convenient when you want to count records with wc(1) or to grep(1) the​              output.​       -r, -resolve use the system’s name resolver to print DNS names instead of host addresses.
​​           -n, -netns ​                  switches ip to the specified network namespace NETNS.  Actually it just simplifies executing of:​                  ip netns exec NETNS ip [ OPTIONS ] OBJECT { COMMAND | help }
              to

              ip -n[etns] NETNS [ OPTIONS ] OBJECT { COMMAND | help }

       -a, -all
              executes specified command over all objects, it depends if command supports this option.

       -c, -color
              Use color output.

       -t, -timestamp
              display current time when using monitor option.

       -ts, -tshort
              Like -timestamp, but use shorter format.

       -rc, -rcvbuf&lt;SIZE&gt;
              Set the netlink socket receive buffer size, defaults to 1MB.

       -iec   print human readable rates in IEC units (e.g. 1Ki = 1024).

IP - COMMAND SYNTAX
   OBJECT

       addrlabel
              - label configuration for protocol address selection.

       l2tp   - tunnel ethernet over IP (L2TPv3).

       maddress
              - multicast address.

       monitor
              - watch for netlink messages.

       mroute - multicast routing cache entry.

       mrule  - rule in multicast routing policy database.

       neighbour
              - manage ARP or NDISC cache entries.

       netns  - manage network namespaces.

       ntable - manage the neighbor cache's operation.

​​       route  - routing table entry.​       rule   - rule in routing policy database.
   tcp_metrics/tcpmetrics
          - manage TCP Metrics

   token  - manage tokenized interface identifiers.

   tunnel - tunnel over IP.

   tuntap - manage TUN/TAP devices.

   xfrm   - manage IPSec policies.

   The names of all objects may be written in full or abbreviated form, for example address can be abbreviated as addr or just a.

​      
]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>Linux炫技</tag>
        <tag>ip</tag>
        <tag>网络</tag>
      </tags>
  </entry>
  <entry>
    <title>使用iperf测试网络性能</title>
    <url>/2018/01/29/linux-iperf/</url>
    <content><![CDATA[使用iperf测试网络性能Iperf是美国伊利诺斯大学（University of Illinois）开发的一种开源的网络性能测试工具。可以用来测试网络节点间（也包括回环）TCP或UDP连接的性能，包括带宽、抖动以及丢包率，其中抖动和丢包率适应于UDP测试，而带宽测试适应于TCP和UDP。
TCP支持：

Measure bandwidth
Report MSS/MTU size and observed read sizes.
Support for TCP window size via socket buffers.
Multi-threaded if pthreads or Win32 threads are available. Client and server can have multiple simultaneous connections.

UDP支持：

Client can create UDP streams of specified bandwidth.
Measure packet loss
Measure delay jitter
Multicast capable
Multi-threaded if pthreads are available. Client and server can have multiple simultaneous connections.

所以，服务端通过-u来区分监听协议，而TCP协议不能计算时延与丢包率，而且不能指定发送带宽。
服务端$ iperf3 -s

客户端$ iperf3 -c IP$ iperf3 --client IP --bandwidth 900M --window 1M

需要使用TCP来测试带宽的时候，需要指定TCP的窗口大小，
窗口的大小即网络通道的容量 capacity = bandwidth x round-trip-time
其中round-trip-time可以通过ping来得到。
参数-c --client 标记客户端-i --interval 设定输出值间隔-u --udp 使用传输协议为UDP-t --time 设定传输时间-F --file 指定传输文件-P --parallel 指定进程数-b --bandwidth 指定带宽-w --window 指定window大小,For TCP, this sets the TCP window size;For UDP it is just the buffer which data
]]></content>
      <categories>
        <category>Network</category>
      </categories>
      <tags>
        <tag>TCP</tag>
        <tag>UDP</tag>
        <tag>network</tag>
        <tag>iperf</tag>
        <tag>iperf3</tag>
        <tag>MTU</tag>
        <tag>bandwidth</tag>
      </tags>
  </entry>
  <entry>
    <title>存同求异 join</title>
    <url>/2016/01/16/linux-join-beginner/</url>
    <content><![CDATA[存同求异  join.. note::  劝君莫惜金缕衣，劝君惜取少年时。

杜秋娘《金缕衣》

Linux join命令用于将两个文件中指定栏位内容相同的行连接起来。
找出两个文件中，指定栏位内容相同的行，并加以合并，再输出到标准输出设备。
类似于SQL的JOIN操作
官方解释为：

 join - join lines of two files on a common field

语法为：
$  join [OPTION]... FILE1 FILE2

​      
这个命令的参数还是有一些的，不过基本默认的足够使用了。
join实例最简单的连接两个文件。
首先看一下两个文件的内容，然后进行join操作。
# 查看file1、file2 的文件内容：$ cat file1 Zhangsan age 14Lisi     age 15Wangwu   age 16$ cat file2Zhangsan score 80Lisi     score 90Wangwu   score 85# 使用join命令$ join file1 file2Zhangsan age 14 score 80Lisi age 15 score 90Wangwu age 16 score 85# 交互两个文件的顺序$ join file2 file1Zhangsan score 80 age 14Lisi score 90  age 15Wangwu score 85 age 16



可以看到交换顺序对输出是有影响的，会影响到最终的输出内容。
不同的栏内容进行join操作而如果两个文件的内容不同，那么在进行join操作时会有警告信息输出，如下所示：
$ cat file1       Jialiu   age 15Zhangsan age 14Lisi     age 15Wangwu   age 16$ cat file2       Zhangsan score 80Lisi     score 90Wangwu   score 85Jialiu   score 88$ join file1 file2join: file1:3: is not sorted: Lisi     age 15join: file2:2: is not sorted: Lisi     score 90Zhangsan age 14 score 80Lisi age 15 score 90Wangwu age 16 score 85$ join file2 file1join: file2:2: is not sorted: Lisi     score 90 join: file1:3: is not sorted: Lisi     age 15Zhangsan score 80 age 14Lisi score 90  age 15Wangwu score 85 age 16







TODO语法join [-i][-a&lt;1或2&gt;][-e&lt;字符串&gt;][-o&lt;格式&gt;][-t&lt;字符&gt;][-v&lt;1或2&gt;][-1&lt;栏位&gt;][-2&lt;栏位&gt;][--help][--version][文件1][文件2]

参数：

-a&lt;1或2&gt; 除了显示原来的输出内容之外，还显示指令文件中没有相同栏位的行。
-e&lt;字符串&gt; 若[文件1]与[文件2]中找不到指定的栏位，则在输出中填入选项中的字符串。
-i或–igore-case 比较栏位内容时，忽略大小写的差异。
-o&lt;格式&gt; 按照指定的格式来显示结果。
-t&lt;字符&gt; 使用栏位的分隔字符。
-v&lt;1或2&gt; 跟-a相同，但是只显示文件中没有相同栏位的行。
-1&lt;栏位&gt; 连接[文件1]指定的栏位。
-2&lt;栏位&gt; 连接[文件2]指定的栏位。

-a FILENUM          also print unpairable lines from file FILENUM, where FILENUM is 1 or 2, corresponding to FILE1 or FILE2
   -e EMPTY          replace missing input fields with EMPTY
   -i, –ignore-case          ignore differences in case when comparing fields
   -j FIELD          equivalent to ‘-1 FIELD -2 FIELD’
   -o FORMAT          obey FORMAT while constructing output line
   -t CHAR          use CHAR as input and output field separator
   -v FILENUM          like -a FILENUM, but suppress joined output lines
   -1 FIELD          join on this FIELD of file 1
   -2 FIELD          join on this FIELD of file 2
   –check-order          check that the input is correctly sorted, even if all input lines are pairable
   –nocheck-order          do not check that the input is correctly sorted
   –header          treat the first line in each file as field headers, print them without trying to pair them
   -z, –zero-terminated          line delimiter is NUL, not newline
   Unless -t CHAR is given, leading blanks separate fields and are ignored, else fields are separated by CHAR.  Any FIELD is a  field
   number counted from 1.  FORMAT is one or more comma or blank separated specifications, each being 'FILENUM.FIELD' or '0'.  Default
   FORMAT outputs the join field, the remaining fields from FILE1, the remaining fields from FILE2, all separated by CHAR.  If FORMAT
   is the keyword 'auto', then the first line of each file determines the number of fields output for each line.

   Important:  FILE1 and FILE2 must be sorted on the join fields.  E.g., use "sort -k 1b,1" if 'join' has no options, or use "join -t
   ''" if 'sort' has no options.  Note, comparisons honor the rules specified by 'LC_COLLATE'.  If the input is not sorted  and  some
   lines cannot be joined, a warning message will be given.

​       comm(1), uniq(1)
]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>join</tag>
      </tags>
  </entry>
  <entry>
    <title>深入研究Linux内核</title>
    <url>/2012/01/15/linux-kernal-study/</url>
    <content><![CDATA[深入研究Linux内核Linux系统的核心成为内核kernel，内核控制计算机上的所有硬件和软件，并在必要的时候分配硬件，在需要时执行软件。
内核主要有以下4中功能：
系统内存管理内存管理是操作系统内核的主要功能之一，内核不仅可以管理服务器上可用的物理内存，而且能够创建并管理虚拟内存，或者说非实际存在的内存。内存管理必须要使用硬盘空间，该空间成为交换空间swap space，内核不断地在交换空间和实际物理内存之间交换虚拟内存位置的内容，这样系统认为可用的内存比实际存在的内存多。使用ipcs可以查看系统当前的共享内存分页。
软件程序管理Linux操作系统将正在运行的程序成为进程，进程可以在前台运行，也可以在后台运行，内核控制Linux系统如何管理在系统中运行的所有进程。内核创建的第一个进程，成为初始进程init process，该进程可在系统上启动所有其他进程，内核启动时，它将初始进程加载到虚拟内存中。内核每启动一个其他进程，都将在虚拟内存中为其分配一个唯一的空间，用于存储该进程使用的数据和代码。
硬件管理Linux系统需要与之通信的设备都必须在内核代码中插入驱动程序代码、驱动程序代码使内核能够向设备传输数据，它的作用就像是应用程序与硬件之间的中间人、在Linux内核中插入设备驱动程序代码有两种方法：

在内核中编译驱动程序；
向内核添加驱动程序模块；

目前Linux系统将硬件设备标示为特殊文件，成为设备文件，大致分为3类：

字符设备
主要用于哪些一次仅处理一个字符的设备，比如调制解调器和终端类型
块设备
主要用于哪些一次可以处理大量数据块的设备，比如磁盘驱动器
网络设备
主要用于使用数据包发送和接收数据的设备，包括网卡和特殊的回路设备，允许Linux系统使用通用网络编程协议与自身通信。

文件系统管理Linux内核可以使用不同类型的文件系统与硬盘传输数据，Linux内核使用虚拟文件系统（Virtual File System，VFS）与每个文件系统进行连接。这为内核与其他文件系统类型的通信提供了一个标准接口。
]]></content>
      <categories>
        <category>Linux</category>
        <category>Kernel</category>
      </categories>
      <tags>
        <tag>kernel</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title>精准终止 之 kill</title>
    <url>/2011/03/12/linux-kill-beginner/</url>
    <content><![CDATA[精准终止 之 kill.. _linux-beginner-kill:
Linux kill 命令用于删除执行中的程序或工作。
官方含义为：

kill - send a signal to a process

kill 命令可将指定的信号发送给相应的进程或工作。 kill 命令默认使用的信号为15（SIGTERM），用于结束进程或工作。如果进程或工作忽略此信号，则可以使用信号9（SIGKILL），强制杀死进程或作业。程序或工作的编号可利用 ps 指令或 jobs 指令查看。
语法$ kill [option] &lt;pid&gt; [...]

参数说明：

-l &lt;信息编号&gt; 　若不加&lt;信息编号&gt;选项，则 -l 参数会列出全部的信息名称。
-s &lt;信息名称或编号&gt; 　指定要送出的信息。

所有可用的信号使用 kill -l 命令列出所有可用信号。
$  kill -lHUP INT QUIT ILL TRAP ABRT BUS FPE KILL USR1 SEGV USR2 PIPE ALRM TERM STKFLT CHLD CONT STOP TSTP TTIN TTOU URG XCPU XFSZ VTALRM PROF WINCH POLL PWR SYS

其中最常用的信号为：

1 (HUP)：重新加载进程。
9 (KILL)：杀死一个进程。
15 (TERM)：正常停止一个进程。

几个实例杀死进程
$ kill 12345

强制杀死进程
$ kill -KILL 123456# 或者$ kill -9 123456

那么如何kill某个用户的所有进程呢，比如用户为user，可以通过下面的命令执行：
$ kill -9 $(ps -ef | grep user) # 或者$ kill -u user

]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>kill</tag>
        <tag>危险命令</tag>
        <tag>系统管理</tag>
        <tag>bash内建指令</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux 之 kill 命令</title>
    <url>/2011/03/12/linux-kill/</url>
    <content><![CDATA[Linux 之 kill 命令Linux kill 命令用于删除执行中的程序或工作。
官方含义为：

kill - send a signal to a process

kill命令可将指定的信号发送给相应的进程或工作。 kill命令默认使用的信号为15（SIGTERM），用于结束进程或工作。如果进程或工作忽略此信号，则可以使用信号9（SIGKILL），强制杀死进程或作业。程序或工作的编号可利用 ps 指令或 jobs 指令查看。
语法$ kill [option] &lt;pid&gt; [...]

参数说明：

-l &lt;信息编号&gt; 　若不加&lt;信息编号&gt;选项，则 -l 参数会列出全部的信息名称。
-s &lt;信息名称或编号&gt; 　指定要送出的信息。
[程序] 　[程序]可以是程序的PID或是PGID，也可以是工作编号。

所有可用的信号使用 kill -l 命令列出所有可用信号。
$  kill -lHUP INT QUIT ILL TRAP ABRT BUS FPE KILL USR1 SEGV USR2 PIPE ALRM TERM STKFLT CHLD CONT STOP TSTP TTIN TTOU URG XCPU XFSZ VTALRM PROF WINCH POLL PWR SYS

其中最常用的信号为：

1 (HUP)：重新加载进程。
9 (KILL)：杀死一个进程。
15 (TERM)：正常停止一个进程。

几个实例杀死进程
$ kill 12345

强制杀死进程
$ kill -KILL 123456# 或者$ kill -9 123456

那么如何kill某个用户的所有进程呢，比如用户为user，可以通过下面的命令执行：
$ kill -9 $(ps -ef | grep user) # 或者$ kill -u user

]]></content>
      <categories>
        <category>Linux</category>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>kill</tag>
      </tags>
  </entry>
  <entry>
    <title>一个不留 的 killall</title>
    <url>/2013/03/12/linux-killall-beginner/</url>
    <content><![CDATA[一个不留 的 killall.. _linux-beginner-killall:
.. note::  及时当勉励，岁月不待人。  陶渊明《杂诗·人生无根蒂》
命令概述在Linux系统中，有许多命令可用于进程管理和控制。
其中一个常用的命令是killall，它允许用户通过进程名字来终止运行中的进程。
官方定义为：

 killall – kill processes by name

killall命令用于向操作系统发送信号以终止指定进程。与kill命令不同，killall根据进程名字而不是进程ID来选择要终止的进程。这对于同时终止多个同名进程非常有用。
超级管理员可以kill掉任何进程。
基本语法killall命令的基本语法如下：
$ killall [选项] 进程名

可以使用以下选项对killall命令进行调整：

-i：交互式模式，要求用户确认终止每个进程。
-e：精确匹配进程名，不匹配进程名的任何子串。
-s：指定要发送的信号类型，如-s HUP。
-v：显示详细的终止进程的输出。

使用示例终止单个进程要终止单个进程，可以使用以下命令：
$ killall 进程名

比如：
$ killall firefox



这将终止所有名为firefox的进程。
终止多个进程要同时终止多个同名进程，可以使用以下命令：
$ killall -r 进程名

示例：
$ killall -r chrome

这将终止所有以chrome为名的进程，包括chrome和chromium等等。
交互式模式使用-i选项可以在终止每个进程之前要求用户确认。示例：
$ killall -i firefox

在执行此命令时，系统将逐个显示要终止的进程，并要求用户确认是否继续，这个对于不确定是否一定中止的优点用哟。
指定信号类型可以使用-s选项来指定要发送的信号类型。示例：
$ killall -s HUP nginx

这将向所有名为nginx的进程发送HUP信号，以重新加载配置。
综上killall命令是一个强大的进程管理工具，可帮助用户终止指定名称的进程。它简化了终止多个同名进程的操作，并提供了一些有用的选项，如交互式模式和指定信号类型。在日常的系统管理和故障排除中，killall是一个重要的工具，
]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>危险命令</tag>
        <tag>killall</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux的语言设置</title>
    <url>/2013/04/15/linux-language/</url>
    <content><![CDATA[Linux的语言设置Ubuntu配置文件在/etc/default/locale中。
CentOS配置文件在/etc/sysconfig/i18n。
修改方法将 LANG=”zh_CN.UTF-8″ LANGUAGE=”zh_CN:zh”修改为：LANG=”en_US.UTF-8″ LANGUAGE=”en_US:en”或者相反。如果在ssh中中文乱码，可以讲UTF-8改为GB18030。
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>CentOS</tag>
        <tag>linux</tag>
        <tag>locale</tag>
        <tag>GB18030</tag>
        <tag>UTF-8</tag>
        <tag>LANG</tag>
      </tags>
  </entry>
  <entry>
    <title>还有谁 last</title>
    <url>/2015/02/11/linux-last-beginner/</url>
    <content><![CDATA[还有谁 last.. note::
  夕阳无限好，只是近黄昏。  李商隐《乐游原 / 登乐游原》
Linux last 命令用于显示用户最近的登录信息。
官方定义为：

 last, lastb - show listing of last logged in users

通过读取/var/log/wtmp文件来获取这些信息。
语法$ last [-R] [-num] [ -n num ] [-adFiowx] [ -f file ] [ -t YYYYMMDDHHMMSS] [name...]  [tty...]

参数：

-R 省略 hostname 的栏位

-n 展示前 num 个

username 展示 username 的登入讯息

tty 限制登入讯息包含终端机代号


一般使用方法$ lastusername2  pts/17       192.168.100.123  Wed Mar 23 22:14   still logged inusername3  pts/20       localhost:11.0   Wed Mar 23 14:26 - 15:48  (01:21)username4  pts/23       localhost:11.0   Wed Mar 23 14:26 - 15:48  (01:21)username4  pts/4        192.168.100.125    Thu Jun 10 18:37 - 22:57  (04:20)username5  pts/4        192.168.100.125    Thu Jun 10 18:21 - 18:21  (00:00)username6  pts/9        192.168.100.126    Thu Jun 10 18:11 - 18:20  (00:09)username7  pts/15       192.168.100.122    Thu Jun 10 18:04 - 23:44 (1+05:40)username8  pts/14       192.168.100.121    Thu Jun 10 17:59 - 07:50  (13:50)username9  pts/9        192.168.100.126    Thu Jun 10 17:59 - 18:03  (00:04)wtmp begins Thu Jun 10 17:33:14 2013




查看最近登陆的三个用户$ last -3username2  pts/17       192.168.100.123  Wed Mar 23 22:14   still logged inusername3  pts/20       localhost:11.0   Wed Mar 23 14:26 - 15:48  (01:21)username4  pts/23       localhost:11.0   Wed Mar 23 14:26 - 15:48  (01:21)wtmp begins Thu Jun 10 17:33:14 2013

省略hostname$ last -3 -Rusername2  pts/17         Wed Mar 23 22:14   still logged inusername3  pts/20         Wed Mar 23 14:26 - 15:48  (01:21)username4  pts/23         Wed Mar 23 14:26 - 15:48  (01:21)wtmp begins Thu Jun 10 17:33:14 2013




显示最后一列显示主机IP地址$ last -n 5 -a -iusername3  pts/17       Wed Mar 23 22:14   still logged in    192.168.100.123username5  pts/20       Wed Mar 23 14:26 - 15:48  (01:21)     0.0.0.0username6  pts/23       Wed Mar 23 14:26 - 15:48  (01:21)     0.0.0.0username7  pts/19       Wed Mar 23 13:46 - 15:48  (02:01)     192.168.100.123username8  pts/17       Wed Mar 23 13:18 - 15:47  (02:29)     192.168.100.123wtmp begins Thu Jun 10 17:33:14 2013

]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>last</tag>
        <tag>用户信息</tag>
        <tag>系统管理</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux的 last 命令</title>
    <url>/2015/02/11/linux-last/</url>
    <content><![CDATA[Linux 之 last 登陆信息Linux last 命令用于显示用户最近的登录信息。
官方定义为：

 last, lastb - show listing of last logged in users

通过读取/var/log/wtmp文件来获取这些信息。
语法$ last [-R] [-num] [ -n num ] [-adFiowx] [ -f file ] [ -t YYYYMMDDHHMMSS] [name...]  [tty...]

参数：

-R 省略 hostname 的栏位

-n 展示前 num 个

username 展示 username 的登入讯息

tty 限制登入讯息包含终端机代号


一般使用方法$ lastusername2  pts/17       192.168.100.123  Wed Mar 23 22:14   still logged inusername3  pts/20       localhost:11.0   Wed Mar 23 14:26 - 15:48  (01:21)username4  pts/23       localhost:11.0   Wed Mar 23 14:26 - 15:48  (01:21)username4  pts/4        192.168.100.125    Thu Jun 10 18:37 - 22:57  (04:20)username5  pts/4        192.168.100.125    Thu Jun 10 18:21 - 18:21  (00:00)username6  pts/9        192.168.100.126    Thu Jun 10 18:11 - 18:20  (00:09)username7  pts/15       192.168.100.122    Thu Jun 10 18:04 - 23:44 (1+05:40)username8  pts/14       192.168.100.121    Thu Jun 10 17:59 - 07:50  (13:50)username9  pts/9        192.168.100.126    Thu Jun 10 17:59 - 18:03  (00:04)wtmp begins Thu Jun 10 17:33:14 2013




查看最近登陆的三个用户$ last -3username2  pts/17       192.168.100.123  Wed Mar 23 22:14   still logged inusername3  pts/20       localhost:11.0   Wed Mar 23 14:26 - 15:48  (01:21)username4  pts/23       localhost:11.0   Wed Mar 23 14:26 - 15:48  (01:21)wtmp begins Thu Jun 10 17:33:14 2013

省略hostname$ last -3 -Rusername2  pts/17         Wed Mar 23 22:14   still logged inusername3  pts/20         Wed Mar 23 14:26 - 15:48  (01:21)username4  pts/23         Wed Mar 23 14:26 - 15:48  (01:21)wtmp begins Thu Jun 10 17:33:14 2013




显示最后一列显示主机IP地址$ last -n 5 -a -iusername3  pts/17       Wed Mar 23 22:14   still logged in    192.168.100.123username5  pts/20       Wed Mar 23 14:26 - 15:48  (01:21)     0.0.0.0username6  pts/23       Wed Mar 23 14:26 - 15:48  (01:21)     0.0.0.0username7  pts/19       Wed Mar 23 13:46 - 15:48  (02:01)     192.168.100.123username8  pts/17       Wed Mar 23 13:18 - 15:47  (02:29)     192.168.100.123wtmp begins Thu Jun 10 17:33:14 2013








​       Last searches back through the file /var/log/wtmp (or the  file  desig‐​       nated  by  the -f flag) and displays a list of all users logged in (and​       out) since that file was created.  Names of  users  and  tty’s  can  be​       given,  in  which  case  last will show only those entries matching the​       arguments.  Names of ttys can be abbreviated, thus last 0 is  the  same​       as last tty0.
 When last catches a SIGINT signal (generated by the interrupt key, usu‐       ally control-C) or a SIGQUIT signal (generated by the quit key, usually       control-), last will show how far it has searched through the file; in       the case of the SIGINT signal last will then terminate.
   The pseudo user reboot logs in each time the system is rebooted.   Thus
   last  reboot will show a log of all reboots since the log file was cre‐
   ated.

   Lastb is the same as last, except that by default it shows a log of the
   file /var/log/btmp, which contains all the bad login attempts.

OPTIONS       -f file              Tells last to use a specific file instead of /var/log/wtmp.
   -num   This is a count telling last how many lines to show.

   -n num The same.

   -t YYYYMMDDHHMMSS
          Display  the  state of logins as of the specified time.  This is
          useful, e.g., to determine easily who was logged in at a partic‐
          ular  time  --  specify  that  time  with -t and look for "still
          logged in".

   -f file
          Specifies a file to search other than /var/log/wtmp.

   -R     Suppresses the display of the hostname field.

   -a     Display the hostname in the last column. Useful  in  combination           with the next flag.

   -d     For non-local logins, Linux stores not only the host name of the
          remote host but its IP number as well.  This  option  translates
          the IP number back into a hostname.

   -F     Print full login and logout times and dates.

   -i     This  option is like -d in that it displays the IP number of the
          remote host, but it displays the IP number  in  numbers-and-dots
          notation.

   -o     Read  an  old-type  wtmp  file  (written by linux-libc5 applica‐
          tions).

   -w     Display full user and domain names in the output.

   -x     Display the system shutdown entries and run level changes.

NOTES       The files wtmp and btmp might not be found. The system only logs infor‐       mation  in  these files if they are present. This is a local configura‐       tion issue. If you want the files to be used, they can be created  with       a simple touch(1) command (for example, touch /var/log/wtmp).
FILES       /var/log/wtmp       /var/log/btmp
AUTHOR       Miquel van Smoorenburg, miquels@cistron.nl
SEE ALSO       login(1), init(8)
]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>last</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux的 /usr/bin/ld  cannot find -lxxx 的解决办法</title>
    <url>/2013/02/04/linux-ld/</url>
    <content><![CDATA[Linux的 /usr/bin/ld  cannot find -lxxx 的解决办法在软件编译过程中，经常会碰到类似这样的编译错误：
$ /usr/bin/ld: cannot find -lxxx

这表示找不到库文件 libxxx.so，其中 xxx 是库文件的名字。
解决方法有：
安装此库文件和相关软件一般库文件属于某个软件，google搜索该软件并安装，或者使用 yum 安装dev包，或者apt按照devel包即可解决。
将库文件所在路径添加到gcc的搜索路径使用以下命令查询gcc能否搜寻到指定的库文件:
$ gcc -lxxx --verbose

查询库文件 libxxx.so 是否能在搜索路径中找到。
若安装了软件，找到了库文件的路径。但是依然会提示上述错误。则表示gcc的搜索路径不包含该库文件所在的路径。将库文件所在的路径加入到搜寻路径中的方法为：
使用 /etc/ld.so.conf 配置文件将库文件所在的路径加入到 /etc/ld.so.conf 尾部，并使之生效：
$ sudo echo '/the/path/of/xxx/lib/' &gt;&gt; /etc/ld.so.conf$ sudo ldconfig
运行该命令，重新载入 /etc/ld.so.conf 中的路径，使修改生效。
修改环境变量$ export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/the/path/of/xxx/lib# 配置之后最好运行一下：$ ldconfig

修改环境变量 LD_LIBRARY_PATH，加入库文件所在路径。使用 export 命令使修改生效。
$ echo 'export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/opt/biosoft/xxx-1.8.15-patch1/lib/' &gt;&gt; ~/.bashrc$ source ~/.bashrc

将上述 export 命令加入到配置文件 ~/.bashrc，使之永久生效。
$ export LIBRARY_PATH=/opt/biosoft/xxx-1.8.15-patch1/lib/:$LIBRARY_PATH
若修改变量 LD_LIBRARY_PATH 不奏效，则修改变量 LIBRARY_PATH 。
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>ld</tag>
      </tags>
  </entry>
  <entry>
    <title>少就是多的 less</title>
    <url>/2012/05/07/linux-less-beginner/</url>
    <content><![CDATA[少就是多的 less.. note::
  买下一张永久车票，登上一列永无终点的火车。  加西亚马尔克斯 《百年孤独》
在Linux系统如果希望查阅文件，有三个命令，是在命令行里面，如果GUI界面，请自行绕过，选择太多了。

cat 入门级的
more 文件内容一屏幕装不下的时候使用的
less 可以简单地认为是more的升级版 , 首推

我首推less命令的原因是该命令可以往回卷动浏览已经看过的部分，但是more是不可以的。或者可以认为less是查看模式下的vim。
首先看看为什么用less命令吧。

If the file is longer than the size of Terminal window then it will be not easy to read or view all the content of the file easily. But there is a tweak, you can use less with cat command. It will give user an ability to scroll forward and backward through the content of the files using PgUp and PgDn keys or Up and Down Arrow keys on the keyboard.

如题，在文件内容足够多的时候，屏幕足够不大的时候，就会出现上面描述的问题，这就出现了less命令。
Linux系统可以说把少就是多这个哲学用到了极致，恰如小巧优美的C语言，不该有的功能坚决不给你提供，应该有的也不给你提供，哈哈，比如内存的管理，程序员就是神，你就是神。
命令简介
less - opposite of more # 我觉得这是废话

我嘞个去，什么鬼？这是什么意思，我也知道少的反义词是多，大的反义词是小。
别急，那就看看more的含义吧，不会是 opposite of less 吧。OMG

more - file perusal filter for crt viewing

什么意思，淡定，听我说，在Linux系统中有三种命令可以用来查阅全部的文件，分别是cat、more和less命令，关于more的解释主要针对在上古年代的计算机，你不理解crt也没有关系，毕竟现在已经是Retina的年代了。
一起看看下面的实例吧。
命令格式$ less [参数] 文件


与其他命令类似，直接跟上文件名即可。

接下来依旧使用/etc/services来进行示例。
-m 显示类似more命令的百分比这个是more命令比较好用的一个功能，可以显示目前浏览的百分比。
$ less -m /etc/servicesauditd          48/udp                  # Digital Audit Daemonla-maint        51/tcp                  # IMP Logical Address Maintenancela-maint        51/udp                  # IMP Logical Address Maintenancexns-time        52/tcp                  # XNS Time Protocolxns-time        52/udp                  # XNS Time Protocolxns-ch          54/tcp                  # XNS Clearinghousexns-ch          54/udp                  # XNS Clearinghouseisi-gl          55/tcp                  # ISI Graphics Languageisi-gl          55/udp                  # ISI Graphics Languagexns-auth        56/tcp                  # XNS Authenticationxns-auth        56/udp                  # XNS Authenticationxns-mail        58/tcp                  # XNS Mailxns-mail        58/udp                  # XNS Mailni-mail         61/tcp                  # NI MAILni-mail         61/udp                  # NI MAIL5%


此时可以在左下角看到，有个百分比。

-N 显示行号使用-N可以实现cat中-n的效果，显示行号
 $ less -N /etc/services 1 # /etc/services: 2 # $Id: services,v 1.55 2013/04/14 ovasik Exp $ 3 # 4 # Network services, Internet style 5 # IANA services version: last updated 2013-04-10 6 # 7 # Note that it is presently the policy of IANA to assign a single well-known 8 # port number for both TCP and UDP; hence, most entries here have two entries 9 # even if the protocol doesn't support UDP operations.10 # Updated from RFC 1700, ``Assigned Numbers'' (October 1994).  Not all ports11 # are included, only the more common ones.12 #13 # The latest IANA port assignments can be gotten from14 #       http://www.iana.org/assignments/port-numbers15 # The Well Known Ports are those from 0 through 1023.16 # The Registered Ports are those from 1024 through 49151



搜索字符串在less中，可以比较容易的搜索字符串，比如可以：

/ 字符串：向下搜索“字符串”的功能
? 字符串：向上搜索“字符串”的功能
n：重复前一个搜索（与 / 或 ? 有关）
N：反向重复前一个搜索（与 / 或 ? 有关）


其实这些功能或者热键与vim相同。

在用less打开文件后，可以直接输入/number来搜索nubmer这个字符串，回车后可以看到该字符串高亮显示，这个也是优于more的一点；同样?number可以反向搜索number字符串。

可以通过-i选项来忽略搜索时的大小写

设置缓冲区的大小可以通过-b &lt;缓冲区大小&gt; 设置缓冲区的大小，这个一般用于文件很大、巨大、不是一般大的时候，此时你的内容可能不足以承载打开整个文件，比如4G的内存，而你却要打开10G的文件，此时可以通过该选项来设置，默认单位为KB，比如
$ less -b 1024 filename


即打开1024KB的文件缓冲

编辑less浏览的文件要编辑一个正在用 less 浏览的文件，可以按下v。你就可以用变量$EDITOR所指定的编辑器来编辑了： 按下v键来编辑文件,退出编辑器后，你可以继续用less浏览了。
移动我比较喜欢less的原因是对于该命令的很多操作都是与vim相同，而我是一个重度vimer，so 推荐less。
说几个比较简单的移动：

j 向下移动
k 向上移动
g 移动到第一行
G 移动到最后一行
b 向后翻一页
d 向后翻半页
u 向前滚动半页
y 向前滚动一行
空格键 滚动一行
回车键 滚动一页

]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>cat</tag>
        <tag>文档查看</tag>
        <tag>less</tag>
        <tag>more</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux的 less 命令</title>
    <url>/2012/05/07/linux-less/</url>
    <content><![CDATA[less - 少就是多在Linux系统如果希望查阅文件，有三个命令，是在命令行里面，如果GUI界面，请自行绕过，选择太多了。

cat 入门级的
more 文件内容一屏幕装不下的时候使用的
less 可以简单地认为是more的升级版 , 首推

我首推less命令的原因是该命令可以往回卷动浏览已经看过的部分，但是more是不可以的。或者可以认为less是查看模式下的vim。
首先看看为什么用less命令吧。

If the file is longer than the size of Terminal window then it will be not easy to read or view all the content of the file easily. But there is a tweak, you can use less with cat command. It will give user an ability to scroll forward and backward through the content of the files using PgUp and PgDn keys or Up and Down Arrow keys on the keyboard.

如题，在文件内容足够多的时候，屏幕足够不大的时候，就会出现上面描述的问题，这就出现了less命令。
Linux系统可以说把少就是多这个哲学用到了极致，恰如小巧优美的C语言，不该有的功能坚决不给你提供，应该有的也不给你提供，哈哈，比如内存的管理，程序员就是神，你就是神。
命令简介
less - opposite of more # 我觉得这是废话

我嘞个去，什么鬼？这是什么意思，我也知道少的反义词是多，大的反义词是小。
别急，那就看看more的含义吧，不会是 opposite of less 吧。OMG

more - file perusal filter for crt viewing

什么意思，淡定，听我说，在Linux系统中有三种命令可以用来查阅全部的文件，分别是cat、more和less命令，关于more的解释主要针对在上古年代的计算机，你不理解crt也没有关系，毕竟现在已经是Retina的年代了。
一起看看下面的实例吧。
命令格式less [参数] 文件


与其他命令类似，直接跟上文件名即可。

接下来依旧使用/etc/services来进行示例。
-m 显示类似more命令的百分比这个是more命令比较好用的一个功能，可以显示目前浏览的百分比。
$ less -m /etc/servicesauditd          48/udp                  # Digital Audit Daemonla-maint        51/tcp                  # IMP Logical Address Maintenancela-maint        51/udp                  # IMP Logical Address Maintenancexns-time        52/tcp                  # XNS Time Protocolxns-time        52/udp                  # XNS Time Protocolxns-ch          54/tcp                  # XNS Clearinghousexns-ch          54/udp                  # XNS Clearinghouseisi-gl          55/tcp                  # ISI Graphics Languageisi-gl          55/udp                  # ISI Graphics Languagexns-auth        56/tcp                  # XNS Authenticationxns-auth        56/udp                  # XNS Authenticationxns-mail        58/tcp                  # XNS Mailxns-mail        58/udp                  # XNS Mailni-mail         61/tcp                  # NI MAILni-mail         61/udp                  # NI MAIL5%


此时可以在左下角看到，有个百分比。

-N 显示行号使用-N可以实现cat中-n的效果，显示行号
 $ less -N /etc/services 1 # /etc/services: 2 # $Id: services,v 1.55 2013/04/14 ovasik Exp $ 3 # 4 # Network services, Internet style 5 # IANA services version: last updated 2013-04-10 6 # 7 # Note that it is presently the policy of IANA to assign a single well-known 8 # port number for both TCP and UDP; hence, most entries here have two entries 9 # even if the protocol doesn't support UDP operations.10 # Updated from RFC 1700, ``Assigned Numbers'' (October 1994).  Not all ports11 # are included, only the more common ones.12 #13 # The latest IANA port assignments can be gotten from14 #       http://www.iana.org/assignments/port-numbers15 # The Well Known Ports are those from 0 through 1023.16 # The Registered Ports are those from 1024 through 49151



搜索字符串在less中，可以比较容易的搜索字符串，比如可以：

/字符串：向下搜索“字符串”的功能
?字符串：向上搜索“字符串”的功能
n：重复前一个搜索（与 / 或 ? 有关）
N：反向重复前一个搜索（与 / 或 ? 有关）


其实这些功能或者热键与vim相同。

在用less打开文件后，可以直接输入/number来搜索nubmer这个字符串，回车后可以看到该字符串高亮显示，这个也是优于more的一点；同样?number可以反向搜索number字符串。

可以通过-i选项来忽略搜索时的大小写

设置缓冲区的大小可以通过-b &lt;缓冲区大小&gt; 设置缓冲区的大小，这个一般用于文件很大、巨大、不是一般大的时候，此时你的内容可能不足以承载打开整个文件，比如4G的内存，而你却要打开10G的文件，此时可以通过该选项来设置，默认单位为KB，比如
$ less -b 1024 filename


即打开1024KB的文件缓冲

编辑less浏览的文件要编辑一个正在用less浏览的文件，可以按下v。你就可以用变量$EDITOR所指定的编辑器来编辑了： 按下v键来编辑文件,退出编辑器后，你可以继续用less浏览了。
移动我比较喜欢less的原因是对于该命令的很多操作都是与vim相同，而我是一个重度vimer，so 推荐less。
说几个比较简单的移动：

j 向下移动
k 向上移动
g 移动到第一行
G 移动到最后一行
b 向后翻一页
d 向后翻半页
u 向前滚动半页
y 向前滚动一行
空格键 滚动一行
回车键 滚动一页

]]></content>
      <categories>
        <category>CentOS</category>
        <category>Fedora</category>
        <category>Linux</category>
        <category>Linux入门</category>
        <category>文档查看</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>cat</tag>
        <tag>less</tag>
        <tag>more</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux的静态库和动态库</title>
    <url>/2012/07/07/linux-library/</url>
    <content><![CDATA[Linux的静态库和动态库编写库如果有很多的函数要连接，这些函数可能来自不同的源文件，而且这些函数对于将来要编写的程序可能有用，那么可以直接创建一个库（就是一个存档文件）。库文件分为两种：当编译调用静态库中函数的代码时，那些函数编程最终可执行文件的一部分，另一方面，如果库是动态的，那么直到实际执行了程序，这些函数才会真正附加到调用代码上。
创建静态库$gcc –g –c a.c$ar rc liba.a a.o

这样就可以创建一个库文件liba.a，编译主程序时：
$gcc –g main.c –la

其中-la即为liba.a的缩写，两者含义相同。如果该库文件与源码不在一个目录，比如在lib目录，则需要L选项，即-Llib就可以将lib文件夹添加到搜索库文件的环境变量中。
这种方法的缺点就是如果很多程序使用同一个库，那么每个程序都会在磁盘上包含该库的独立副本，这样比较浪费空间。可以使用动态库解决这个问题（代价是需要一点额外的加载时间）。
创建动态链接库$gcc –fPIC –c a.c$gcc –shared –o liba.so a.o

这段代码创建了动态库liba.so，（Unix中命名动态库的惯例是使用后缀so，表示shared object，后面可能会跟着版本号。）与连接静态库一样地连接到这个动态库。（其中选项fpic：产生位置无关码
解释一下，位置无关码就是可以在进程的任意内存位置执行的目标码，动态链接库必须使用。）
$gcc –g main.c –la
开源软件中库的用法开源软件现在很流行，尤其是在Linux用户之间。然而有时会出现一个问题，即与源代码配套的构建脚本（通常称为配置文件）找不到某些必须的库。试图通过设置LD_LIBRARY_PATH环境变量可能会失败。
这种问题的根源常常在于配置文件调用的名为pkgconfig的程序，这个程序会从某些元数据文件处接收库的信息，这样的文件爱你后缀为.pc，前缀是库的名称，例如，文件爱你libabc.pc中包含库文件libabc.so*的位置。
curses库这个库简单到很多人根本没有把它当成GUI。
程序员可以使用curses库编写让光标在屏幕上移动的代码，改变字符的颜色，或者改成反白显示，插入以及删除文本等。
例如，像Vim和Emacs这样的文本编辑器就是用curses编写的。
通过直接添加或者手动编译添加库，解决 library not found for -lxxx 等的问题本文基本上能完美解决这种库文件无法找到问题，一般保存为library not found for -llxxx。
这个问题是说链接器在链接的时候找不到 Ixxx 这个库，那我们就告诉它（添加库的路径），让它找到就好啦！
扩展：

静态库无法链接报错：

library not found for -lxxx


动态库无法装载报错：

dyld: library not loaded …/libxxx.dylib

解决办法方法一：直接添加库通常解决办法是：库存在，直接添加路径。
也就是通常遇到这个问题的时候，库是已经编译安装好了的，但是 IED 不能找到。这样的话就直接添加库的路径就好了。
第一步：找库第一步，自己找到这个库。
库一般放在系统默认处或者安装到特定地方。
Linux 系统默认库放在：
/lib/usr/lib/usr/local/lib...安装到特定地方，如我 Mac 的用 Homebrew 安装到：

/usr/local/Cellar/ice/3.7.0/lib

第二步：添加路径添加库一般以下三种方法任选其一：

系统环境变量添加

系统级：修改/etc/profile或者/etc/bashrc

用户级：修改~/.bashrc或者~/.bash_profile


###添加库的bin文件夹路径export PATH =$PATH:$HOME/bin###添加到gcc头文件export C_INCLUDE_PATH=$C_INCLUDE_PATH:/MyLib###添加到g++头文件路径export CPLUS_INCLUDE_PATH=$CPLUS_INCLUDE_PATH:/MyLib###添加到动态库export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/MyLib###添加到静态库export LIBRARY_PATH=$LIBRARY_PATH:/MyLib1234567891011121314


IED 编译环境添加
因 IDE 不同而不同，如 Qt 在项目-构建设置-构建环境处添加

代码添加


 # 如 Qt pro 文件添加 LIBS += -L/the/library/path/ -llxx12

这样，IDE就能找到库啦！
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>emacs</tag>
        <tag>gcc</tag>
        <tag>so</tag>
        <tag>pkg-config</tag>
        <tag>shared</tag>
        <tag>ar</tag>
        <tag>fPIC</tag>
        <tag>curses</tag>
      </tags>
  </entry>
  <entry>
    <title>快捷方式 ln</title>
    <url>/2013/04/15/linux-ln-beginner/</url>
    <content><![CDATA[快捷方式 lnln 命令是一个非常重要的命令，可以为某一个文件或目录在其他不同的位置建立一个同步的链接。部分功能与Windows的快捷方式类似。但更加强大。
官方解释为：

ln - make links between files

当我们需要在不同的目录，或者不同的工程，甚至是不同的人员需要用到同一个文件的时候，此时不需要每个位置都通过cp来拷贝一份，因为在源文件更新的时候，这个文件是不会同步更新的 。而此时ln命令就不一样了，通过该命令链接到源文件或目录，不仅可以不用占用重复的更多的磁盘空间，还可以同步更新。NICE。
使用格式$ ln [参数][源文件或目录][目标文件或目录]

其中参数的格式为

-b ，或   like –backup but does not accept an argument
-f,或 --force : 强制执行，这个在链接已经存在的情况下必用
-s,或 --symbolic:创建符号链接

在Linux文件系统中，又有两种链接类型：

硬链接(hard link)
软链接(symbolic link)：又称符号链接，类似于Windows的快捷方式

硬链接会复制一份相同大小的源文件，而软链接是一种特殊的文件，占用很小的磁盘空间。
创建硬链接默认情况下，不加任何参数，创建的是硬链接，如下，创建源文件a.log的硬链接a1.log：
$ ln a.log a1.log$ ll-rw-rw-r--. 3 user user 85710 Apr  5 21:29 a.log-rw-rw-r--. 3 user user 85710 Apr  5 21:29 a1.log

这个时候修改源文件a.log的部分内容，可以看到硬链接也同步更新。
$ vim a.log$ ll-rw-rw-r--. 3 user user 85716 Apr  5 21:34 a.log-rw-rw-r--. 3 user user 85716 Apr  5 21:34 a1.log



创建软链接如果需要创建软链接，就需要参数-s，如下，创建源文件a.log的软链接a1.log：
$ ln -s a.log a1.log$ ll-rw-rw-r--. 3 user user 85710 Apr  5 21:29 a.loglrwxrwxrwx. 1 user user     5 Apr  5 21:30 a1.log -&gt; a.log

这个时候修改源文件a.log的部分内容，可以看到软链接没有更新，不过其指向的内容依然更新了。
$ vim a.log$ ll-rw-rw-r--. 3 user user 85716 Apr  5 21:34 a.loglrwxrwxrwx. 1 user user     5 Apr  5 21:30 a1.log -&gt; a.log

此时可以看到，对于软链接a1.log而言，其仅为一个符号链接，用file看一下：
$ file a1.loga1.log: symbolic link to `a.log'



删除源文件后的情况此时通过ln创建a.log的硬链接ah.log和软链接as.log，然后看一下如果删除源文件会发生什么情况。
# 创建软硬链接$ ln a.log ah.log$ ln -s a.log as.log$ ll-rw-rw-r--. 2 user user 85716 Apr  5 21:34 a.loglrwxrwxrwx. 1 user user     5 Apr  5 21:30 as.log -&gt; a.log-rw-rw-r--. 2 user user 85716 Apr  5 21:34 ah.log# 删除源文件$ rm a.log# 此时如果有颜色显示，as.log应该会是红色的警告色$ lllrwxrwxrwx. 1 user user     5 Apr  5 21:30 as.log -&gt; a.log-rw-rw-r--. 2 user user 85716 Apr  5 21:34 ah.log# 此时看一下as.log的状态$ file as.logas.log: broken symbolic link to `a.log'



可以看到如果删除了源文件，硬链接不受影响，但是软链接已经提示链接损坏了。
强制更新软链接在软链接存在的情况下，如果再创建一个同名的，会报错，此时就需要强制创建了，加上-f参数即可。
$ ln -s b.log as.logln: failed to create symbolic link 'as.log': File exists# 强制创建$ ln -sf b.log as.log$ ll-rw-rw-r--. 1 user user 85716 Apr  5 22:16 a.log-rw-rw-r--. 2 user user 85716 Apr  5 21:34 ah.loglrwxrwxrwx. 1 user user     5 Apr  5 22:21 as.log -&gt; b.log-rw-rw-r--. 1 user user 85716 Apr  5 22:17 b.log


]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>ln</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux的快捷方式的创建ln</title>
    <url>/2013/04/15/linux-ln/</url>
    <content><![CDATA[Linux ln 命令ln 命令是一个非常重要的命令，可以为某一个文件或目录在其他不同的位置建立一个同步的链接。部分功能与Windows的快捷方式类似。但更加强大。
官方解释为：

ln - make links between files

当我们需要在不同的目录，或者不同的工程，甚至是不同的人员需要用到同一个文件的时候，此时不需要每个位置都通过cp来拷贝一份，因为在源文件更新的时候，这个文件是不会同步更新的 。而此时ln命令就不一样了，通过该命令链接到源文件或目录，不仅可以不用占用重复的更多的磁盘空间，还可以同步更新。NICE。
使用格式$ ln [参数][源文件或目录][目标文件或目录]

其中参数的格式为

-b ，或   like –backup but does not accept an argument
-f,或 --force : 强制执行，这个在链接已经存在的情况下必用
-s,或 --symbolic:创建符号链接

在Linux文件系统中，又有两种链接类型：

硬链接(hard link)
软链接(symbolic link)：又称符号链接，类似于Windows的快捷方式

硬链接会复制一份相同大小的源文件，而软链接是一种特殊的文件，占用很小的磁盘空间。
创建硬链接默认情况下，不加任何参数，创建的是硬链接，如下，创建源文件a.log的硬链接a1.log：
$ ln a.log a1.log$ ll-rw-rw-r--. 3 user user 85710 Apr  5 21:29 a.log-rw-rw-r--. 3 user user 85710 Apr  5 21:29 a1.log

这个时候修改源文件a.log的部分内容，可以看到硬链接也同步更新。
$ vim a.log$ ll-rw-rw-r--. 3 user user 85716 Apr  5 21:34 a.log-rw-rw-r--. 3 user user 85716 Apr  5 21:34 a1.log



创建软链接如果需要创建软链接，就需要参数-s，如下，创建源文件a.log的软链接a1.log：
$ ln -s a.log a1.log$ ll-rw-rw-r--. 3 user user 85710 Apr  5 21:29 a.loglrwxrwxrwx. 1 user user     5 Apr  5 21:30 a1.log -&gt; a.log

这个时候修改源文件a.log的部分内容，可以看到软链接没有更新，不过其指向的内容依然更新了。
$ vim a.log$ ll-rw-rw-r--. 3 user user 85716 Apr  5 21:34 a.loglrwxrwxrwx. 1 user user     5 Apr  5 21:30 a1.log -&gt; a.log

此时可以看到，对于软链接a1.log而言，其仅为一个符号链接，用file看一下：
$ file a1.loga1.log: symbolic link to `a.log'



删除源文件后的情况此时通过ln创建a.log的硬链接ah.log和软链接as.log，然后看一下如果删除源文件会发生什么情况。
# 创建软硬链接$ ln a.log ah.log$ ln -s a.log as.log$ ll-rw-rw-r--. 2 user user 85716 Apr  5 21:34 a.loglrwxrwxrwx. 1 user user     5 Apr  5 21:30 as.log -&gt; a.log-rw-rw-r--. 2 user user 85716 Apr  5 21:34 ah.log# 删除源文件$ rm a.log# 此时如果有颜色显示，as.log应该会是红色的警告色$ lllrwxrwxrwx. 1 user user     5 Apr  5 21:30 as.log -&gt; a.log-rw-rw-r--. 2 user user 85716 Apr  5 21:34 ah.log# 此时看一下as.log的状态$ file as.logas.log: broken symbolic link to `a.log'



可以看到如果删除了源文件，硬链接不受影响，但是软链接已经提示链接损坏了。
强制更新软链接在软链接存在的情况下，如果再创建一个同名的，会报错，此时就需要强制创建了，加上-f参数即可。
$ ln -s b.log as.logln: failed to create symbolic link 'as.log': File exists# 强制创建$ ln -sf b.log as.log$ ll-rw-rw-r--. 1 user user 85716 Apr  5 22:16 a.log-rw-rw-r--. 2 user user 85716 Apr  5 21:34 ah.loglrwxrwxrwx. 1 user user     5 Apr  5 22:21 as.log -&gt; b.log-rw-rw-r--. 1 user user 85716 Apr  5 22:17 b.log


]]></content>
      <categories>
        <category>Linux</category>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>ln</tag>
      </tags>
  </entry>
  <entry>
    <title>精准快速定位的locate</title>
    <url>/2014/01/24/linux-locate-beginner/</url>
    <content><![CDATA[精准快速定位的locate.. note::
  众里寻他千百度，蓦然回首，那人却在灯火阑珊处  -李煜
Linux locate命令用于查找符合条件的文档、程序、目录等等。这个命令会在数据库中查找符合条件的各种信息。
一般情况我们只需要输入 locate name 即可查找。
官方定义为：

locate - list files in databases that match a pattern

使用方法为：
$ locate  [-d  path  |  --database=path]  [-e  | -E | --[non-]existing] [-i | --ignore-case] [-0 | --null] [-c |       --count] [-w | --wholename] [-b | --basename] [-l N | --limit=N] [-S | --statistics] [-r | --regex ] [--regex‐       type  R] [--max-database-age D] [-P | -H | --nofollow] [-L | --follow] [--version] [-A | --all] [-p | --print]       [--help] pattern...

看着很复杂，不过常用的参数倒是不多，基本为：

-n :  至多显示 n个输出。
-i, --ignore-case : 忽略大小写

默认无参数默认情况下，locate直接跟上需要查找的信息就可以了，如下所示：
$ locate set_vis.cpp/home/user/mycode/src/set_vis.cpp# 以查找apropos为例$ locate apropos/usr/bin/apropos/usr/local/difmap/help/apropos.hlp/usr/share/emacs/24.3/lisp/apropos.elc/usr/share/man/de/man1/apropos.1.gz/usr/share/man/es/man1/apropos.1.gz/usr/share/man/fr/man1/apropos.1.gz/usr/share/man/id/man1/apropos.1.gz/usr/share/man/it/man1/apropos.1.gz/usr/share/man/ja/man1/apropos.1.gz/usr/share/man/man1/apropos.1.gz/usr/share/man/nl/man1/apropos.1.gz/usr/share/man/pl/man1/apropos.1.gz/usr/share/man/ru/man1/apropos.1.gz



太多需要简单化如果输出的信息很多，仅仅希望看到前面的几个，使用-n参数既可
# 仅仅查看前的3个$ locate -n 3 apropos/usr/bin/apropos/usr/local/difmap/help/apropos.hlp/usr/share/emacs/24.3/lisp/apropos.elc



不区分大小写部分情况下，可能有大小写混淆的情况，此时使用-i参数既可
$ $ locate -i set_vis.cpp/home/user/mycode/src/set_vis.cpp/home/user/mycode_CPP/src/set_VIS.cpp



📖 说明不过刚按照的系统，这个命令并不一定有输出，主要是因为locate 与 find 不同，  find 直接在硬盘找，而locate 只在数据库中查找。
这个数据库在CentOS系统默认的为 /var/lib/mlocate/mlocate.db 中，所以 locate 的查找会比较快，但并一定是实时的，而是以数据库的更新为准。
可以通过下面的命令手工升级数据库 ，命令为：
$ updatedb

然后就可以使用了。
]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>CentOS</tag>
        <tag>linux</tag>
        <tag>find</tag>
        <tag>locate</tag>
        <tag>updatedb</tag>
      </tags>
  </entry>
  <entry>
    <title>锁定Linux文件夹</title>
    <url>/2011/02/12/linux-lock-dir-misc/</url>
    <content><![CDATA[锁定Linux文件夹为了我的数据隐私，我想要锁定我文件服务器下的/downloads文件夹。因此我运行了：
$ chmod 0000 /downloads

root用户仍旧可以访问，而ls和cd命令则不工作。要还原它用：
$ chmod 0755 /downloads
]]></content>
      <categories>
        <category>Linux炫技</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>cal</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux命令lolcat</title>
    <url>/2011/02/12/linux-lolcat-misc/</url>
    <content><![CDATA[缤纷绚烂的终端体验：探索lolcatlolcat是一款让终端从黑白灰变得缤纷多彩的神奇工具。
通过将文字渲染成彩虹般的颜色，让你的终端充满欢乐与活力。
可以把这个命令替换掉cat，这样你的内容都灵动了起来
比如lolcat /etc/resolv.conf会生成如下信息：

]]></content>
      <categories>
        <category>Linux炫技</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>lolcat</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux的 loop循环</title>
    <url>/2012/02/04/linux-loop/</url>
    <content><![CDATA[得到随机数的代码：
srand(time(NULL)); //use clock value as starting seed。这个保证每次出来的随机数都不同int number = 0;number = rand();

在做for循环的时候，循环控制变量也可以是一个浮点类型的变量。例如：
for(double x = 1.0; x &lt; 11; x += 1.0)，但是由于浮点类型在计算机内部的表示形式，决定了分数值通常没有浮点数形式的精确表示，所以不应该把相等判断作为结束循环的条件，比如x != 2.0，就可能一直打不到要求。

goto语句可以用在有多层循环时，想跳出循环的时候设置一个label就可以了，没有必要逐层break。
do-while循环与for循环和while循环的不同之处在于，这个循环语句或语句块至少会执行一次。
continue：不结束循环，但是要跳过目前的迭代，继续执行下一个迭代。

三种循环
for循环：一般用于计算循环的次数，在该循环中，控制变量的值在每次迭代时递增或递减指定的值，直到到达某个最终值为止；
while循环：只要给定的条件为true就继续执行。如果循环条件一开始就是false，循环语句块就根本不执行；
do-while循环类似于while循环，但其循环条件在循环语句块执行后检查。

编写程序的规则和建议
开始编写程序前，先规划好过程和计算的逻辑，将它写下来，最好采用流程图的形式；
理解运算符的优先级，以正确计算复杂的表达式，如果不能确定运算符的优先级，就应使用括号。确保表达式完成预期的操作，使用括号更便于理解复杂的表达式；
给程序加上注释，全面解释它们的操作和使用。要假设这些注释为为了方便别人阅读这个程序，并加以扩展与修改，声明变量时应说明它们的作用；
程序的可读性是最重要的；
在复杂的逻辑表达式中尽量避免使用!运算符；
使用缩进格式，可视化地表达出程序的结构；

]]></content>
      <categories>
        <category>Linux</category>
        <category>C</category>
      </categories>
      <tags>
        <tag>for</tag>
        <tag>continue</tag>
        <tag>goto</tag>
        <tag>while</tag>
        <tag>loop</tag>
      </tags>
  </entry>
  <entry>
    <title>最常用的且没有之一的  ls</title>
    <url>/2012/07/07/linux-ls-beginner/</url>
    <content><![CDATA[最常用的且没有之一的  ls.. note::  寻寻觅觅，冷冷清清，凄凄惨惨戚戚。  宋 李清照《声声慢·寻寻觅觅》
如果linux命令来个排名，ls命令应该是最常用的命令，除非你像黄蓉的母亲，有过目不忘的本领，惹得黄药师抱憾终身。
ls命令是list的缩写，通过ls命令，我们可以查看目录的内容，确定各种重要文件和目录的属性。
命令格式$ ls [参数] [路径]

不加任何参数如果不加任何参数，默认列出当前目录的内容。
$ ls /etc/sysconfig/network-scriptsifcfg-em1ifcfg-em2ifcfg-em3ifcfg-em4   ....



使用-l显示更多细节-l 就是使用long listing format长格式，来显示更多的内容信息。
$ ls -l /etc/sysconfig/network-scriptstotal 264-rw-r--r--. 1 root root   341 Nov 30 10:56 ifcfg-em1-rw-r--r--. 1 root root   294 May 13  2016 ifcfg-em2-rw-r--r--. 1 root root   272 May 10  2016 ifcfg-em3-rw-r--r--. 1 root root   272 May 10  2016 ifcfg-em4......

使用-t按照时间排序如果希望看到最近创建的文件，就需要用到-t参数了。
$ ls -lt /etc/sysconfig/network-scripts/total 264-rw-r--r--. 1 root root   341 Nov 30 10:56 ifcfg-em1-rw-r--r--. 1 root root   294 May 13  2016 ifcfg-em2-rw-r--r--. 1 root root   272 May 10  2016 ifcfg-em4-rw-r--r--. 1 root root   272 May 10  2016 ifcfg-em3...

使用-r按照时间逆序如果希望删除很早以前的文件，看到最早创建的文件，就需要用到-r参数了。
$ ls -ltr /etc/sysconfig/network-scripts/total 264...-rw-r--r--. 1 root root   272 May 10  2016 ifcfg-em3-rw-r--r--. 1 root root   272 May 10  2016 ifcfg-em4-rw-r--r--. 1 root root   294 May 13  2016 ifcfg-em2-rw-r--r--. 1 root root   341 Nov 30 10:56 ifcfg-em1

使用-S根据文件大小排序$ ls -lS /etc/sysconfig/network-scripts/total 264...-rw-r--r--. 1 root root   341 Nov 30 10:56 ifcfg-em1-rw-r--r--. 1 root root   294 May 13  2016 ifcfg-em2-rw-r--r--. 1 root root   272 May 10  2016 ifcfg-em3-rw-r--r--. 1 root root   272 May 10  2016 ifcfg-em4

使用-a显示所有文件$ ls -la test/.vs/.vscode/.git/.gitignoretest.txt]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>文件管理</tag>
        <tag>目录导航</tag>
        <tag>ls</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux的 ls 命令</title>
    <url>/2012/07/07/linux-ls/</url>
    <content><![CDATA[Linux的 ls 命令如果linux命令来个排名，ls命令应该是最常用的命令，除非你像黄蓉的母亲，有过目不忘的本领，惹得黄药师抱憾终身。
ls命令是list的缩写，通过ls命令，我们可以查看目录的内容，确定各种重要文件和目录的属性。
命令格式ls [参数] [路径]

不加任何参数如果不加任何参数，默认列出当前目录的内容。
➜  ~ ls /etc/sysconfig/network-scriptsifcfg-em1ifcfg-em2ifcfg-em3ifcfg-em4   ....



使用-l显示更多细节-l 就是使用long listing format长格式，来显示更多的内容信息。
➜  ~ ls -l /etc/sysconfig/network-scriptstotal 264-rw-r--r--. 1 root root   341 Nov 30 10:56 ifcfg-em1-rw-r--r--. 1 root root   294 May 13  2016 ifcfg-em2-rw-r--r--. 1 root root   272 May 10  2016 ifcfg-em3-rw-r--r--. 1 root root   272 May 10  2016 ifcfg-em4......

使用-t按照时间排序如果希望看到最近创建的文件，就需要用到-t参数了。
➜  ~ ls -lt /etc/sysconfig/network-scripts/total 264-rw-r--r--. 1 root root   341 Nov 30 10:56 ifcfg-em1-rw-r--r--. 1 root root   294 May 13  2016 ifcfg-em2-rw-r--r--. 1 root root   272 May 10  2016 ifcfg-em4-rw-r--r--. 1 root root   272 May 10  2016 ifcfg-em3...

使用-r按照时间逆序如果希望删除很早以前的文件，看到最早创建的文件，就需要用到-r参数了。
➜  ~ ls -ltr /etc/sysconfig/network-scripts/total 264...-rw-r--r--. 1 root root   272 May 10  2016 ifcfg-em3-rw-r--r--. 1 root root   272 May 10  2016 ifcfg-em4-rw-r--r--. 1 root root   294 May 13  2016 ifcfg-em2-rw-r--r--. 1 root root   341 Nov 30 10:56 ifcfg-em1

使用-S根据文件大小排序➜  ~ ls -lS /etc/sysconfig/network-scripts/total 264...-rw-r--r--. 1 root root   341 Nov 30 10:56 ifcfg-em1-rw-r--r--. 1 root root   294 May 13  2016 ifcfg-em2-rw-r--r--. 1 root root   272 May 10  2016 ifcfg-em3-rw-r--r--. 1 root root   272 May 10  2016 ifcfg-em4
]]></content>
      <categories>
        <category>CentOS</category>
        <category>Fedora</category>
        <category>Linux</category>
        <category>Linux入门</category>
        <category>文件管理</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>ls</tag>
      </tags>
  </entry>
  <entry>
    <title>查看块设备的lsblk</title>
    <url>/2019/04/07/linux-lsblk-beginner/</url>
    <content><![CDATA[查看块设备的lsblk lsblk 命令可以查看系统中的块设备信息
$ lsblk

这个命令会列出系统中所有的块设备（比如硬盘、分区和挂载点）的信息。
默认情况下，它会显示每个设备的名称、大小、类型、挂载点等信息。
如果需要显示更详细的信息，可以使用 -a 或 --all 选项：
$ lsblk -a

这会显示完整的块设备信息，包括未挂载的设备。
当然，还可以根据需求，定制化输出，不过单单这个命令，足矣。

lsblk命令 – 查看系统的磁盘

]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>磁盘管理</tag>
        <tag>硬件信息</tag>
        <tag>lsblk</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux的 lsblk 命令</title>
    <url>/2019/07/07/linux-lsblk/</url>
    <content><![CDATA[Linux的 lsblk 命令 lsblk - 列出块设备信息
lsblk命令 用于列出所有可用块设备的信息，而且还能显示他们之间的依赖关系，但是它不会列出RAM盘的信息。块设备有硬盘，闪存盘，cd-ROM等等。lsblk命令包含在util-linux-ng包中，现在该包改名为util-linux。这个包带了几个其它工具，如dmesg。要安装lsblk，请在此处下载util-linux包。Fedora用户可以通过命令sudo yum install util-linux-ng来安装该包。
选项-a, --all            显示所有设备。-b, --bytes          以bytes方式显示设备大小。-d, --nodeps         不显示 slaves 或 holders。-D, --discard        print discard capabilities。-e, --exclude &lt;list&gt; 排除设备 (default: RAM disks)。-f, --fs             显示文件系统信息。-h, --help           显示帮助信息。-i, --ascii          use ascii characters only。-m, --perms          显示权限信息。-l, --list           使用列表格式显示。-n, --noheadings     不显示标题。-o, --output &lt;list&gt;  输出列。-P, --pairs          使用key="value"格式显示。-r, --raw            使用原始格式显示。-t, --topology       显示拓扑结构信息。

实例lsblk命令默认情况下将以树状列出所有块设备。打开终端，并输入以下命令：
lsblkNAME    MAJ:MIN RM   SIZE RO TYPE MOUNTPOINTsda       8:0    0 278.5G  0 disk |-sda4    8:4    0 261.9G  0 part /|-sda2    8:2    0   500M  0 part /boot|-sda3    8:3    0    16G  0 part [SWAP]`-sda1    8:1    0   100M  0 part /boot/efinvme0n1 259:0    0   1.8T  0 disk 

7个栏目名称如下：

NAME ：这是块设备名。
MAJ:MIN ：本栏显示主要和次要设备号。
RM ：本栏显示设备是否可移动设备。0为不可移动，1为可移动设备。
SIZE ：本栏列出设备的容量大小信息。例如278.5GG表明该设备大小为278.5GGB，而500M表明该设备大小为500MB。
RO ：该项表明设备是否为只读。在本案例中，所有设备的RO值为0，表明他们不是只读的。
TYPE ：本栏显示块设备是否是磁盘或磁盘上的一个分区。在本例中，sda和sdb是磁盘。
MOUNTPOINT ：本栏指出设备挂载的挂载点。

默认选项不会列出所有空设备。要查看这些空设备，请使用以下命令：
lsblk -a

lsblk命令也可以用于列出一个特定设备的拥有关系，同时也可以列出组和模式。可以通过以下命令来获取这些信息：
lsblk -m

该命令也可以只获取指定设备的信息。这可以通过在提供给lsblk命令的选项后指定设备名来实现。例如，你可能对了解以字节显示你的磁盘驱动器大小比较感兴趣，那么你可以通过运行以下命令来实现：
lsblk -b /dev/sda等价于lsblk --bytes /dev/sda

你也可以组合几个选项来获取指定的输出。例如，你也许想要以列表格式列出设备，而不是默认的树状格式。你可能也对移除不同栏目名称的标题感兴趣。可以将两个不同的选项组合，以获得期望的输出，命令如下：
lsblk -nl

要获取SCSI设备的列表，你只能使用-S选项。该选项是大写字母S，不能和-s选项混淆，该选项是用来以颠倒的顺序打印依赖的。
lsblk -S

lsblk列出SCSI设备，而-s是逆序选项（将设备和分区的组织关系逆转过来显示），其将给出如下输出。输入命令：
lsblk -s]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>lsblk</tag>
      </tags>
  </entry>
  <entry>
    <title>显示CPU架构的有关信息lscpu</title>
    <url>/2017/07/07/linux-lscpu-beginner/</url>
    <content><![CDATA[显示CPU架构的有关信息 lscpuLinux的CPU设备查看器。lscpu命令用来显示cpu的相关信息。lscpu从sysfs和/proc/cpuinfo收集cpu体系结构信息，命令的输出比较易读 。命令输出的信息包含cpu数量，线程，核数，socket和Nom-Uniform Memeor Access(NUMA)，缓存等等。
官方定义为：

lscpu - display information about the CPU architecture

参数基本用处不大，默认即可，部分参数可以查看offline和online的设备信息。
默认实例$ lscpuArchitecture:          x86_64       		#架构信息 CPU op-mode(s):        32-bit, 64-bitByte Order:            Little EndianCPU(s):                64   				#逻辑cpu颗数 On-line CPU(s) list:   0-63Thread(s) per core:    2 					#每个核心线程Core(s) per socket:    16 					#每个cpu插槽核数/每颗物理cpu核数 Socket(s):             2  					#cpu插槽数NUMA node(s):          2Vendor ID:             GenuineIntel 		#cpu厂商ID CPU family:            6   					#cpu系列 Model:                 63 					#型号 Model name:            Intel(R) Xeon(R) CPU E5-2698 v3 @ 2.30GHzStepping:              2 					#步进 CPU MHz:               1290.335 			#cpu主频BogoMIPS:              4604.47Virtualization:        VT-x  				#cpu支持的虚拟化技术 L1d cache:             32KL1i cache:             32KL2 cache:              256KL3 cache:              40960KNUMA node0 CPU(s):     0-15,32-47NUMA node1 CPU(s):     16-31,48-63

其中几个概念需要理解清楚，基本比较重要的都有了备注。
其中第一个为CPU(s)，这个值为Socket * Core * Thread得出，也就是逻辑的CPU个数。
CPU(s):                64   #逻辑CPU数On-line CPU(s) list:   0-63Thread(s) per core:    2     Core(s) per socket:    16socket：                2



而其他几个概念为：

Socket : 物理上的CPU插槽的数量，也就是物理的实体概念
Core：即平常说的单核、多核、四核等，即每个CPU上的核数
Thread：每个core上的线程数，即超线程。

]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>硬件信息</tag>
        <tag>lshw</tag>
        <tag>lscpu</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux的 lscpu 命令</title>
    <url>/2017/07/07/linux-lscpu/</url>
    <content><![CDATA[lscpu 显示CPU架构的有关信息Linux的CPU设备查看器。lscpu命令用来显示cpu的相关信息。lscpu从sysfs和/proc/cpuinfo收集cpu体系结构信息，命令的输出比较易读 。命令输出的信息包含cpu数量，线程，核数，socket和Nom-Uniform Memeor Access(NUMA)，缓存等等。
官方定义为：

lscpu - display information about the CPU architecture

参数基本用处不大，默认即可，部分参数可以查看offline和online的设备信息。
默认实例$ lscpuArchitecture:          x86_64       		#架构信息 CPU op-mode(s):        32-bit, 64-bitByte Order:            Little EndianCPU(s):                64   				#逻辑cpu颗数 On-line CPU(s) list:   0-63Thread(s) per core:    2 					#每个核心线程Core(s) per socket:    16 					#每个cpu插槽核数/每颗物理cpu核数 Socket(s):             2  					#cpu插槽数NUMA node(s):          2Vendor ID:             GenuineIntel 		#cpu厂商ID CPU family:            6   					#cpu系列 Model:                 63 					#型号 Model name:            Intel(R) Xeon(R) CPU E5-2698 v3 @ 2.30GHzStepping:              2 					#步进 CPU MHz:               1290.335 			#cpu主频BogoMIPS:              4604.47Virtualization:        VT-x  				#cpu支持的虚拟化技术 L1d cache:             32KL1i cache:             32KL2 cache:              256KL3 cache:              40960KNUMA node0 CPU(s):     0-15,32-47NUMA node1 CPU(s):     16-31,48-63

其中几个概念需要理解清楚，基本比较重要的都有了备注。
其中第一个为CPU(s)，这个值为Socket * Core * Thread得出，也就是逻辑的CPU个数。
CPU(s):                64   #逻辑CPU数On-line CPU(s) list:   0-63Thread(s) per core:    2     Core(s) per socket:    16socket：                2



而其他几个概念为：

Socket : 物理上的CPU插槽的数量，也就是物理的实体概念
Core：即平常说的单核、多核、四核等，即每个CPU上的核数
Thread：每个core上的线程数，即超线程。

什么是NUMA nodeNUMA体系结构中多了Node的概念，Node是一个逻辑上的概念，这个概念其实是用来解决core的分组的问题。每个node有自己的内部CPU，总线和内存，同时还可以访问其他node内的内存。即Node用来将core分组，每个Node拥有一个对应的本地内存。
node 和socket没有必然的联系，一般是一个socket上的core属于同一个node。
对操作系统来说，其逻辑CPU的数量就是Socket * Core * Thread
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>lshw</tag>
        <tag>lscpu</tag>
      </tags>
  </entry>
  <entry>
    <title>列出系统硬件信息的lshw</title>
    <url>/2019/03/07/linux-lshw-beginner/</url>
    <content><![CDATA[列出系统硬件信息的lshwlshw是Hardware Lister 的缩写，直面意思即列出系统硬件信息。
可以显示关于计算机硬件组件（如处理器、内存、硬盘、网卡等）的详细信息，对于系统管理员和用户来说是一个非常有用的工具。
显示所有硬件信息任何参数都不加的话，可用，信息极多，但是可用信息不多。
 sudo lshw
  这将输出系统中所有可用硬件的详细信息，包括硬件组件的制造商、型号、驱动程序等。
查看摘要硬件信息显示摘要信息：相对而言，这个反而好一些，简单的就是有用的
  sudo lshw -short
  这将显示硬件的摘要信息，包括设备名、类别、描述等。
查看特定硬件信息（如网络、内存、硬盘等设备）显示指定类型的硬件信息：
sudo lshw -C network
上述示例将仅显示网络相关的硬件信息。
比如还可以查看memory、cpu、disk等信息。
lshw提供了全面的硬件信息，帮助用户了解系统配置和硬件组件的细节。在查看和诊断硬件问题或了解系统配置时，它是一个非常有用的工具。
]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>硬件信息</tag>
        <tag>系统管理</tag>
        <tag>lsblk</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux的 lshw 命令</title>
    <url>/2019/07/07/linux-lshw/</url>
    <content><![CDATA[Linux的 lshw 命令lshw - list hardware
可以使用 lshw -class disk -class storage 来查看具体的硬盘和存储信息。
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>lshw</tag>
      </tags>
  </entry>
  <entry>
    <title>遍历总线设备 lspci</title>
    <url>/2018/07/07/linux-lspci-beginner/</url>
    <content><![CDATA[遍历总线设备 lspci.. note::  东风夜放花千树。更吹落、星如雨  辛弃疾 - 青玉案·元夕
lspci命令用于显示PCI总线的信息，以及所有已连接的PCI设备信息。
官方定义为：

lspci  - list all PCI devices

默认情况下，lspci会显示一个简短的设备列表。 使用使用一些参数来显示更详细的输出或供其他程序解析的输出。
不过需要注意的是，在许多操作系统上，对 PCI 配置空间的某些部分的访问仅限于 root，因此普通用户可用的 lspci 功能受到限制。
使用方法为：
$ lspci [options]



其中常用的三个选项为：

-n  以数字方式显示PCI厂商和设备代码
-t 以树状结构显示PCI设备的层次关系
-v 显示更详细的输出信息

显示当前主机的所有PCI总线信息：默认无参数的显示
$ lspci00:00.0 Host bridge: Intel Corporation Xeon E7 v3/Xeon E5 v3/Core i7 DMI2 (rev 02)00:01.0 PCI bridge: Intel Corporation Xeon E7 v3/Xeon E5 v3/Core i7 PCI Express Root Port 1 (rev 02)00:02.0 PCI bridge: Intel Corporation Xeon E7 v3/Xeon E5 v3/Core i7 PCI Express Root Port 2 (rev 02)00:03.0 PCI bridge: Intel Corporation Xeon E7 v3/Xeon E5 v3/Core i7 PCI Express Root Port 3 (rev 02)00:03.2 PCI bridge: Intel Corporation Xeon E7 v3/Xeon E5 v3/Core i7 PCI Express Root Port 3 (rev 02)00:04.0 System peripheral: Intel Corporation Xeon E7 v3/Xeon E5 v3/Core i7 DMA Channel 0 (rev 02)00:04.1 System peripheral: Intel Corporation Xeon E7 v3/Xeon E5 v3/Core i7 DMA Channel 1 (rev 02)00:04.2 System peripheral: Intel Corporation Xeon E7 v3/Xeon E5 v3/Core i7 DMA Channel 2 (rev 02)......

以数字方式显示PCI厂商和设备代码以数字形式显示
$ lspci -n00:00.0 0600: 8086:2f00 (rev 02)00:01.0 0604: 8086:2f02 (rev 02)00:02.0 0604: 8086:2f04 (rev 02)00:03.0 0604: 8086:2f08 (rev 02)00:03.2 0604: 8086:2f0a (rev 02)00:04.0 0880: 8086:2f20 (rev 02)00:04.1 0880: 8086:2f21 (rev 02)00:04.2 0880: 8086:2f22 (rev 02)......



同时显示数字方式还有设备代码信息$ lspci -nn00:00.0 Host bridge [0600]: Intel Corporation Xeon E7 v3/Xeon E5 v3/Core i7 DMI2 [8086:2f00] (rev 02)00:01.0 PCI bridge [0604]: Intel Corporation Xeon E7 v3/Xeon E5 v3/Core i7 PCI Express Root Port 1 [8086:2f02] (rev 02)00:02.0 PCI bridge [0604]: Intel Corporation Xeon E7 v3/Xeon E5 v3/Core i7 PCI Express Root Port 2 [8086:2f04] (rev 02)00:03.0 PCI bridge [0604]: Intel Corporation Xeon E7 v3/Xeon E5 v3/Core i7 PCI Express Root Port 3 [8086:2f08] (rev 02)00:03.2 PCI bridge [0604]: Intel Corporation Xeon E7 v3/Xeon E5 v3/Core i7 PCI Express Root Port 3 [8086:2f0a] (rev 02)00:04.0 System peripheral [0880]: Intel Corporation Xeon E7 v3/Xeon E5 v3/Core i7 DMA Channel 0 [8086:2f20] (rev 02)00:04.1 System peripheral [0880]: Intel Corporation Xeon E7 v3/Xeon E5 v3/Core i7 DMA Channel 1 [8086:2f21] (rev 02)00:04.2 System peripheral [0880]: Intel Corporation Xeon E7 v3/Xeon E5 v3/Core i7 DMA Channel 2 [8086:2f22] (rev 02)......

以树状结构显示PCI设备的层次关系：$ lspci -tlspci -t-+-[0000:ff]-+-08.0 |           +-08.2 |           +-1f.0 |           \-1f.2 +-[0000:80]-+-01.0-[81]----00.0 |           +-04.0 |           +-05.1 |           +-05.2 |           \-05.4 +-[0000:7f]-+-08.0 |           +-08.2 |           +-0c.1             \+-0c.2]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>lspci</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux CentOS修改MAC地址</title>
    <url>/2013/07/17/linux-mac/</url>
    <content><![CDATA[首先要查看网卡的MAC地址在终端上输入命令：#ifconfig或者#ifconfig -a，就可以查看到网卡的信息，其中的HWaddr后面的XX:XX:XX:XX:XX:XX就是我们网卡MAC地址。
如何修改Linux/Centos下的MAC地址linux/Centos下如何临时修改MAC地址1）闭网卡设备        [root@localhost ~]# ifconfig eth0 down       2）修改MAC地址　　[root@localhost ~]#ifconfig eth0 hw ether MAC地址（此处添加你要修改的MAC地址）       3）重启网卡        [root@localhost ~]#ifconfig eth0 up       4）查看修改是否生效：        [root@localhost ~]#ifconfig eth0 | grep HWaddr

​       

 注意:上述修改MAC地址只是暂时的,系统重启后，系统会恢复原物理MAC地址。

Linux/Centos下如何永久的修改MAC地址永久修改MAC信息，在每次系统启动的时候自动更新MAC地址：
 打开/etc/rc.d/rc.local ，追加三行内容：
ifconfig eth0 downifconfig eth0 hw ether XX:XX:XX:XX:XX:XXifconfig eth0 up

 然后重启电脑就可以完成修改。
]]></content>
      <categories>
        <category>Linux</category>
        <category>CentOS</category>
      </categories>
      <tags>
        <tag>ifconfig</tag>
        <tag>up</tag>
        <tag>down</tag>
        <tag>rc.local</tag>
      </tags>
  </entry>
  <entry>
    <title>此man非man的意思</title>
    <url>/2011/03/12/linux-man-beginner/</url>
    <content><![CDATA[此man非man的意思
首先，这man是什么意思？
最开始很多人认为是不知道这个什么意思，找man呀。
其实man是manual的缩写，也就是手册的意思。

man命令提供了系统命令的详细帮助信息。
Linux提供了丰富的帮助手册，当你需要查看某个命令的参数时不必到处上网查找，只要man一下即可。这个也是每个程序员必备的功能，在没有网络的情况下，man能解决很多问题和疑惑。
看一下官方定义：

Man - format and display the on-line manual pages

man 的格式如果要读懂并使用man，首先需要了解man命令输出的格式，下面的几个是比较常用且需要注意的：

同时也可以使用man man 查看man的使用方法。




章节
含义



NAME
命令名称及功能简要说明


SYNOPSIS
用法说明，包括可用的选项


DESCRIPTION
命令功能的详细说明，可能包括每一个选项的意义


OPTIONS
每一选项的意义


EXAMPLES
一些使用示例


man的操作  比如输入man ls  后，跳出下面的内容：
LS(1)                                               User Commands                                              LS(1)NAME       ls - list directory contentsSYNOPSIS       ls [OPTION]... [FILE]...DESCRIPTION       List  information about the FILEs (the current directory by default).  Sort entries alphabetically if none of       -cftuvSUX nor --sort is specified.       Mandatory arguments to long options are mandatory for short options too.       -a, --all              do not ignore entries starting with .       -A, --almost-all              do not list implied . and ..       --author              with -l, print the author of each file       -b, --escape              print C-style escapes for nongraphic characters       --block-size=SIZE              scale sizes by SIZE before printing them; e.g., '--block-size=M' prints sizes in  units  of  1,048,576              bytes; see SIZE format below       -B, --ignore-backups Manual page ls(1) line 1 (press h for help or q to quit)



此时可以通过空格键或者回车键来向后翻屏或者翻页，可以使用b或者k向前查看。
　查看关键词时可以使用：
  /关键词    向后查找   n：下一个
  ?关键词   向前查找   N：前一个
可以通过q来退出。

ls后面还有一个（1）,详细的解释可以参考《Linux 安装 man 帮助程序》

类似于whatis命令man有个参数为-f，就是whatis的功能，比如：
$ man -f ls cd file cat more lessls (1)               - list directory contentsls (1p)              - list directory contentscd (1)               - bash built-in commands, see bash(1)cd (1p)              - change the working directorycd (n)               - Change working directoryfile (1)             - determine file typefile (1p)            - determine file typefile (n)             - Manipulate file names and attributescat (1)              - concatenate files and print on the standard outputcat (1p)             - concatenate and print filesmore (1)             - file perusal filter for crt viewingmore (1p)            - display files on a page-by-page basisless (1)             - opposite of moreless (3pm)           - perl pragma to request less of something


与whatis命令完全一致

类似于apropos命令man有个参数为-k，就是apropos的功能，比如：
$ man -k  whoat.allow (5)         - determine who can submit jobs via at or batchat.deny (5)          - determine who can submit jobs via at or batchbtrfs-filesystem (8) - command group of btrfs that usually work on the whole filesystemdocker-trust-signer (1) - Manage entities who can sign Docker imagesipsec_newhostkey (8) - generate a new raw RSA authentication key for a hostipsec_showhostkey (8) - show host's authentication keyw (1)                - Show who is logged on and what they are doing.who (1)              - show who is logged onwho (1p)             - display who is on the systemwhoami (1)           - print effective userid


与apropos命令完全一致

使用man的小技巧 如果遇到一个不熟悉或者完全不知道的命令，此时可以通过下面的3个步骤来了解：

首先用man -k command 查询所有类似帮助文件信息，或许有可能就能找到你需要的信息；
然后man -f command 查询以command开始的相关帮助信息列表
man  N command 通过直接定位N获得详细帮助信息

]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>apropos</tag>
        <tag>man</tag>
        <tag>帮助命令</tag>
        <tag>whatis</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux 安装 man 帮助程序</title>
    <url>/2013/07/17/linux-man-pages/</url>
    <content><![CDATA[Linux 安装 manualman 命令提供有关主题的参考信息，例如命令、子例程和文件。man 命令提供由名称指定的对命令的单行描述。man 命令也提供所有命令的信息，这些命令的描述包含用户指定的关键字集合。

大部分系统都会预装相关的程序，如果使用docker来pull的系统，并一定具备，此时需要安装一下即可。

对于Debian系列的，可以使用
$ sudo apt-get install manpages-dev

对于Redhat系列的，可以使用
$ sudo yum install man-pages



在Redhat系列中，有一个Development Tools组包，特别适合开发运维人员，可以通过下面的命令来安装
$ sudo yum groupinstall "Development Tools"



man不同的数字man 命令格式化指定的手册页面集合。如果为 Section 参数指定一个段，那么 man 命令在手册页面的该段中搜索 Title 参数指定的标题。Section 参数的值可以是 1 到 8 的阿拉伯数字或字母。
Section 数字是：

1 表示用户命令和守护进程。 
2 表示系统调用和内核服务。 
3 表示函数或者函数库。
4 表示特殊文件、设备驱动程序和硬件。 
5 表示配置文件。 
6 表示游戏。 
7 表示杂项命令。 
8 表示管理命令和守护进程。
9 表示和内核相关的文件

此时使用whatis命令，参考whatis命令，
$ whatis readread (1)             - bash built-in commands, see bash(1)read (1p)            - read a line from standard inputread (2)             - read from a file descriptorread (3p)            - read from a fileread (n)             - Read from a channel


此时可以看到搜索到很多read的命令，而此时可以通过在man命令的后面跟上数字来搜索相关的内容，默认显示1，及bash内建的命令。

比如此时希望了解系统调用和内核服务，即2，此时的命令为：
$ man 2 readREAD(2)                                       Linux Programmer's Manual                                      READ(2)NAME       read - read from a file descriptorSYNOPSIS       #include &lt;unistd.h&gt;       ssize_t read(int fd, void *buf, size_t count);DESCRIPTION       read() attempts to read up to count bytes from file descriptor fd into the buffer starting at buf.       On  files  that support seeking, the read operation commences at the current file offset, and the file offset       is incremented by the number of bytes read.  If the current file offset is at or past the  end  of  file,  no       bytes are read, and read() returns zero.       If  count  is zero, read() may detect the errors described below.  In the absence of any errors, or if read()       does not check for errors, a read() with a count of 0 returns zero and has no other effects.       If count is greater than SSIZE_MAX, the result is unspecified.

]]></content>
      <categories>
        <category>Linux</category>
        <category>CentOS</category>
        <category>Fedora</category>
        <category>Redhat</category>
        <category>Ubuntu</category>
      </categories>
      <tags>
        <tag>apt-get</tag>
        <tag>yum</tag>
        <tag>linux</tag>
        <tag>man</tag>
        <tag>ubuntu</tag>
        <tag>centos</tag>
        <tag>redhat</tag>
        <tag>fedora</tag>
        <tag>man-pages</tag>
        <tag>grouplist</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux 之 man 命令</title>
    <url>/2011/03/12/linux-man/</url>
    <content><![CDATA[man 系统帮助命令
首先，这man是什么意思？
最开始很多人认为是不知道这个什么意思，找man呀。
其实man是manual的缩写，也就是手册的意思。

man命令提供了系统命令的详细帮助信息。
Linux提供了丰富的帮助手册，当你需要查看某个命令的参数时不必到处上网查找，只要man一下即可。这个也是每个程序员必备的功能，在没有网络的情况下，man能解决很多问题和疑惑。
看一下官方定义：

Man - format and display the on-line manual pages

man 的格式如果要读懂并使用man，首先需要了解man命令输出的格式，下面的几个是比较常用且需要注意的：

同时也可以使用man man 查看man的使用方法。




章节
含义



NAME
命令名称及功能简要说明


SYNOPSIS
用法说明，包括可用的选项


DESCRIPTION
命令功能的详细说明，可能包括每一个选项的意义


OPTIONS
每一选项的意义


EXAMPLES
一些使用示例


man的操作  比如输入man ls  后，跳出下面的内容：
LS(1)                                               User Commands                                              LS(1)NAME       ls - list directory contentsSYNOPSIS       ls [OPTION]... [FILE]...DESCRIPTION       List  information about the FILEs (the current directory by default).  Sort entries alphabetically if none of       -cftuvSUX nor --sort is specified.       Mandatory arguments to long options are mandatory for short options too.       -a, --all              do not ignore entries starting with .       -A, --almost-all              do not list implied . and ..       --author              with -l, print the author of each file       -b, --escape              print C-style escapes for nongraphic characters       --block-size=SIZE              scale sizes by SIZE before printing them; e.g., '--block-size=M' prints sizes in  units  of  1,048,576              bytes; see SIZE format below       -B, --ignore-backups Manual page ls(1) line 1 (press h for help or q to quit)



此时可以通过空格键或者回车键来向后翻屏或者翻页，可以使用b或者k向前查看。
　查看关键词时可以使用：
  /关键词    向后查找   n：下一个
  ?关键词   向前查找   N：前一个
可以通过q来退出。

ls后面还有一个（1）,详细的解释可以参考《Linux 安装 man 帮助程序》

类似于whatis命令man有个参数为-f，就是whatis的功能，比如：
$ man -f ls cd file cat more lessls (1)               - list directory contentsls (1p)              - list directory contentscd (1)               - bash built-in commands, see bash(1)cd (1p)              - change the working directorycd (n)               - Change working directoryfile (1)             - determine file typefile (1p)            - determine file typefile (n)             - Manipulate file names and attributescat (1)              - concatenate files and print on the standard outputcat (1p)             - concatenate and print filesmore (1)             - file perusal filter for crt viewingmore (1p)            - display files on a page-by-page basisless (1)             - opposite of moreless (3pm)           - perl pragma to request less of something


与whatis命令完全一致

类似于apropos命令man有个参数为-k，就是apropos的功能，比如：
$ man -k  whoat.allow (5)         - determine who can submit jobs via at or batchat.deny (5)          - determine who can submit jobs via at or batchbtrfs-filesystem (8) - command group of btrfs that usually work on the whole filesystemdocker-trust-signer (1) - Manage entities who can sign Docker imagesipsec_newhostkey (8) - generate a new raw RSA authentication key for a hostipsec_showhostkey (8) - show host's authentication keyw (1)                - Show who is logged on and what they are doing.who (1)              - show who is logged onwho (1p)             - display who is on the systemwhoami (1)           - print effective userid


与apropos命令完全一致

使用man的小技巧 如果遇到一个不熟悉或者完全不知道的命令，此时可以通过下面的3个步骤来了解：

首先用man -k command 查询所有类似帮助文件信息，或许有可能就能找到你需要的信息；
然后man -f command 查询以command开始的相关帮助信息列表
man  N command 通过直接定位N获得详细帮助信息

]]></content>
      <categories>
        <category>Linux</category>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>apropos</tag>
        <tag>man</tag>
        <tag>whatis</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux的 mkdir 命令</title>
    <url>/2011/02/12/linux-mkdir/</url>
    <content><![CDATA[mkdir 创建文件夹mkdir 命令用来创建指定的名称的目录，看看官方定义：

make directories

所以mkdir是这两个单词的缩写。mkdir要求创建目录的用户在当前目录中具有_写权限_，并且指定的目录名不能是当前目录中已有的目录，参数-p可以指定建立多级目录，这个参数也是用的最多的。
命令格式mkdir [可选项] 目录



命令参数-m, --mode=模式，设定权限&lt;模式&gt; (类似 chmod)-p, --parents  可以是一个路径名称。此时若路径中的某些目录尚不存在,加上此选项后,系统将自动建立好那些尚不存在的目录,即一次可以建立多个目录



命令实例创建一个空目录$ mkdir hello

递归创建多个目录$ mkdir -p a/b/c/d/e/f/g

创建权限为777的目录$ mkdir -m 777 test

小技巧下面的一个命令可以创建一个项目的目录结构，如下：
mkdir -vp project/{src/,include/,lib/,bin/,doc/{info,product},logs/{info,product},service/deploy/{info,product}}mkdir: created directory ‘project’mkdir: created directory ‘project/src/’mkdir: created directory ‘project/include/’mkdir: created directory ‘project/lib/’mkdir: created directory ‘project/bin/’mkdir: created directory ‘project/doc’mkdir: created directory ‘project/doc/info’mkdir: created directory ‘project/doc/product’mkdir: created directory ‘project/logs’mkdir: created directory ‘project/logs/info’mkdir: created directory ‘project/logs/product’mkdir: created directory ‘project/service’mkdir: created directory ‘project/service/deploy’mkdir: created directory ‘project/service/deploy/info’mkdir: created directory ‘project/service/deploy/product’$ tree project/project├── bin├── doc│   ├── info│   └── product├── include├── lib├── logs│   ├── info│   └── product├── service│   └── deploy│       ├── info│       └── product└── src14 directories, 0 files
]]></content>
      <categories>
        <category>Linux</category>
        <category>Linux入门</category>
        <category>文件管理</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>tree</tag>
        <tag>mkdir</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux的 mkdir 命令</title>
    <url>/2011/02/12/linux-mkdir-beginner/</url>
    <content><![CDATA[mkdir 创建文件夹mkdir 命令用来创建指定的名称的目录，看看官方定义：

make directories

所以mkdir是这两个单词的缩写。mkdir要求创建目录的用户在当前目录中具有_写权限_，并且指定的目录名不能是当前目录中已有的目录，参数-p可以指定建立多级目录，这个参数也是用的最多的。
命令格式$ mkdir [可选项] 目录



命令参数
-m, –mode=模式，设定权限&lt;模式&gt; (类似 chmod)
-p, –parents  可以是一个路径名称。此时若路径中的某些目录尚不存在,加上此选项后,系统将自动建立好那些尚不存在的目录,即一次可以建立多个目录

创建一个空目录$ mkdir hello

递归创建多个目录$ mkdir -p a/b/c/d/e/f/g

创建权限为777的目录$ mkdir -m 777 test


小技巧 - 创建目录树下面的一个命令可以创建一个项目的目录结构，如下：
$ mkdir -vp project/{src/,include/,lib/,bin/,doc/{info,product},logs/{info,product},service/deploy/{info,product}}mkdir: created directory ‘project’mkdir: created directory ‘project/src/’mkdir: created directory ‘project/include/’mkdir: created directory ‘project/lib/’mkdir: created directory ‘project/bin/’mkdir: created directory ‘project/doc’mkdir: created directory ‘project/doc/info’mkdir: created directory ‘project/doc/product’mkdir: created directory ‘project/logs’mkdir: created directory ‘project/logs/info’mkdir: created directory ‘project/logs/product’mkdir: created directory ‘project/service’mkdir: created directory ‘project/service/deploy’mkdir: created directory ‘project/service/deploy/info’mkdir: created directory ‘project/service/deploy/product’$ tree project/project├── bin├── doc│   ├── info│   └── product├── include├── lib├── logs│   ├── info│   └── product├── service│   └── deploy│       ├── info│       └── product└── src14 directories, 0 files
]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>文件管理</tag>
        <tag>tree</tag>
        <tag>mkdir</tag>
      </tags>
  </entry>
  <entry>
    <title>Environment Modules</title>
    <url>/2019/02/12/linux-module/</url>
    <content><![CDATA[Environment ModulesEnvironment Modules 给用户提供了一个通过modulefiles动态的修改环境变量的方法。
什么是 Environment Modules?通常，用户在登录时通过为会话期间要引用的每个应用程序设置环境信息来初始化其环境。Environment Modules包是一个简化shell初始化的工具，它允许用户在使用modulefile进行会话期间轻松地修改环境。
每个modulefile包含为应用程序配置shell所需的信息。初始化Modules包后，可以使用modulefiles的module命令在每个模块的基础上修改环境。通常，modulefiles 可以使用module命令更改或设置shell环境变量，如PATH、MANPATH等。modulefile可以由系统上的许多用户共享，用户可以有自己的集合来补充或替换共享的modulefile。
模块可以使用 loaded 和 unloaded 动态操作。支持所有主流的shell，比如 bash, ksh, zsh, sh, csh, tcsh, fish, 还有一些其他的脚本语言，如 perl, ruby, tcl, python, cmake 和 R.
模块在管理不同版本的应用程序时非常有用。模块也可以绑定到元模块中，元模块将加载一整套不同的应用程序。
快速示例Here is an example of loading a module on a Linux machine under bash.
$ module load gcc/8.3$ which gcc/usr/local/gcc/8.3/linux-x86_64/bin/gcc

Now we’ll switch to a different version of the module
$ module switch gcc gcc/9.2$ which gcc/usr/local/gcc/9.2/linux-x86_64/bin/gcc

And now we’ll unload the module altogether
$ module unload gcc$ which gccgcc not found

Now we’ll log into a different machine, using a different shell (tcsh).
% module load gcc/9.2% which gcc/usr/local/gcc/9.2/linux-aarch64/bin/gcc

Note that the command line is exactly the same, but the path has automatically configured to the correct architecture.
开始使用 ModulesDownload latest version of Modules. Learn how to install it on Unix or how to install it on Windows. You may alternatively automatically retrieve and install Modules with your preferred package manager as Environment Modules is widely available. If you are upgrading from an older version of Modules, read the MIGRATING guide to learn all new features recently introduced.
Reference manual page for the module(1) and ml(1) commands and for modulefile(4) script provide details on all supported options. If you have questions, comments or development suggestions for the Modules community, please read the CONTRIBUTING guide.
搜索路径问题#这个是关于引用博主和我自己的使用情况的一些总结：#查看MODULEPATHecho $MODULEPATH #修改路径#在默认的/usr/share/module/init/bash中添加最后一行export MODULEPATH=/YOUR/PATH/:$MODULEPATH

modulefiles文件的书写
文件的开头一定是#%Module1.0开始
有几个命令
prepend 要修改的环境变量 路径
setenv 修改环境变量的值
conflict modulefile 如果这个modulefile已经被加载，则当前的modulefile不能被加载



一个模板#%Module1.0proc ModulesHelp { } {global version prefix puts stderr "\t Loads the environment for my installed home folder HOME/local"} module-whatis   "Loads the environment for my installed home folder HOME/local" set     HOME    /home/svu/a0081742 prepend-path    PATH            $HOME/local/binprepend-path    LIBRARY_PATH    $HOME/local/libprepend-path    LD_LIBRARY_PATH $HOME/local/libprepend-path    LD_INCLUDE_PATH $HOME/local/includeprepend-path    MANPATH         $HOME/local/share/man

使用方法
module avail 显示可以使用的模块
module load 加载模块
module unload 卸载模块
module list 显示已经加载的模块

]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>module</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux 的 more 命令</title>
    <url>/2012/02/07/linux-more-beginner/</url>
    <content><![CDATA[more - 多多益善more功能类似 cat ，cat命令是整个文件的内容从上到下显示在屏幕上。 more会以一页一页的显示方便使用者逐页阅读，而最基本的指令就是按空白键（space）就往下一页显示，按 b 键就会往回（back）一页显示，而且还有搜寻字串的功能 。more命令从前向后读取文件，因此在启动时就加载整个文件。
在查阅文件的时候，我们说过可以用cat命令，不过这个是入门级别的，但凡用了几天Linux的，基本不太会再使用cat，而是另外两个指令，more或者less。这次说一下more，more是在文件的内容一个屏幕装不小的时候使用的。而less是more的升级版本，稍后会介绍。

 more : 文件内容一屏幕装不下的时候使用的

看看为什么用less命令吧。

more - file perusal filter for crt viewing

看不懂，什么是CRT，莫慌，关于more的解释主要针对在上古年代的计算机，你不理解crt也没有关系，毕竟现在已经是Retina的年代了。
命令格式less的命令格式与cat一样，可以直接跟上文件名，如下：
less [参数] 文件

其中的参数如下所示：

+n   从笫n行开始显示
-n    定义屏幕大小为n行
+/pattern 在每个档案显示前搜寻该字串（pattern），然后从该字串前两行之后开始显示 
-c    从顶部清屏，然后显示
-d    提示“Press space to continue，’q’ to quit（按空格键继续，按q键退出）”，禁用响铃功能
-l    忽略Ctrl+l（换页）字符
-p    通过清除窗口而不是滚屏来对文件进行换页，与-c选项相似
-s    把连续的多个空行显示为一行
-u    把文件内容中的下画线去掉

一起看看下面的实例吧，这里以文件/etc/services为例：
这个文件的开始信息如下：
# /etc/services:# $Id: services,v 1.55 2013/04/14 ovasik Exp $## Network services, Internet style# IANA services version: last updated 2013-04-10## Note that it is presently the policy of IANA to assign a single well-known# port number for both TCP and UDP; hence, most entries here have two entries# even if the protocol doesn't support UDP operations.# Updated from RFC 1700, ``Assigned Numbers'' (October 1994).  Not all ports# are included, only the more common ones.## The latest IANA port assignments can be gotten from#       http://www.iana.org/assignments/port-numbers# The Well Known Ports are those from 0 through 1023.# The Registered Ports are those from 1024 through 49151# The Dynamic and/or Private Ports are those from 49152 through 65535## Each line describes one service, and is of the form:## service-name  port/protocol  [aliases ...]   [# comment]tcpmux          1/tcp                           # TCP port service multiplexertcpmux          1/udp                           # TCP port service multiplexerrje             5/tcp                           # Remote Job Entryrje             5/udp                           # Remote Job Entryecho            7/tcp





+n 从第n行开始显示接下来的命令从第10行开始显示：
$ more +10 /etc/service# Updated from RFC 1700, ``Assigned Numbers'' (October 1994).  Not all ports# are included, only the more common ones.## The latest IANA port assignments can be gotten from#       http://www.iana.org/assignments/port-numbers# The Well Known Ports are those from 0 through 1023.# The Registered Ports are those from 1024 through 49151# The Dynamic and/or Private Ports are those from 49152 through 65535## Each line describes one service, and is of the form:## service-name  port/protocol  [aliases ...]   [# comment]tcpmux          1/tcp                           # TCP port service multiplexertcpmux          1/udp                           # TCP port service multiplexerrje             5/tcp                           # Remote Job Entryrje             5/udp                           # Remote Job Entryecho            7/tcpecho            7/udpdiscard         9/tcp           sink nulldiscard         9/udp           sink nullsystat          11/tcp          userssystat          11/udp          usersdaytime         13/tcpdaytime         13/udpqotd            17/tcp          quoteqotd            17/udp          quote


可以看到前面的10行是没有显示的。

-n 定义屏幕大小为n行这里的含义为定义输出的内容为10行，你的屏幕可能足够大，不过显示的内容只有n行，如下：只显示10行的内容，此时终端可能还会残留以前的内容：
$ more -10 /etc/services# /etc/services:# $Id: services,v 1.55 2013/04/14 ovasik Exp $## Network services, Internet style# IANA services version: last updated 2013-04-10## Note that it is presently the policy of IANA to assign a single well-known# port number for both TCP and UDP; hence, most entries here have two entries# even if the protocol doesn't support UDP operations.# Updated from RFC 1700, ``Assigned Numbers'' (October 1994).  Not all ports


可以关注一下，此时每次显示的只有10行。

+/pattern 搜寻字符串（pattern）这个参数用于在文件中搜索字符串pattern，然后在该字符串的前两行之前开始显示。比如搜索number，会显示以下内容：
$ more +/number /etc/services## Note that it is presently the policy of IANA to assign a single well-known# port number for both TCP and UDP; hence, most entries here have two entries# even if the protocol doesn't support UDP operations.# Updated from RFC 1700, ``Assigned Numbers'' (October 1994).  Not all ports# are included, only the more common ones.## The latest IANA port assignments can be gotten from#       http://www.iana.org/assignments/port-numbers# The Well Known Ports are those from 0 through 1023.# The Registered Ports are those from 1024 through 49151# The Dynamic and/or Private Ports are those from 49152 through 65535## Each line describes one service, and is of the form:## service-name  port/protocol  [aliases ...]   [# comment]tcpmux          1/tcp                           # TCP port service multiplexertcpmux          1/udp                           # TCP port service multiplexerrje             5/tcp                           # Remote Job Entryrje             5/udp                           # Remote Job Entryecho            7/tcpecho            7/udpdiscard         9/tcp           sink nulldiscard         9/udp           sink nullsystat          11/tcp          userssystat          11/udp          usersdaytime         13/tcp......


可以留意，此时显示的内容，第三行即包含搜索的字符串。

其他除以上介绍的以外，还有比较容易理解的以下参数：

-c    从顶部清屏，然后显示
-p    通过清除窗口而不是滚屏来对文件进行换页，与-c选项相似
-s    把连续的多个空行显示为一行
-u    把文件内容中的下画线去掉

]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>CentOS</tag>
        <tag>Linux</tag>
        <tag>linux</tag>
        <tag>Fedora</tag>
        <tag>more</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux mount挂载nfs</title>
    <url>/2012/10/31/linux-mount/</url>
    <content><![CDATA[mount挂载执行umount 的时候却提示:device is busy 的处理方法# 查询占用挂载点的PID$ fuser -m /mount/point//mount/point/: 1234c 5678c //占用进程pid# 查询并杀死占用挂载点的PID#fuser -m -k /mnt/cdrom/

# 查询具体的进程信息# ps aux |grep 1234/5678 

或者使用
$ lsof /mount/point

来查找具体的使用进程及用户信息
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>CentOS</tag>
        <tag>linux</tag>
        <tag>磁盘管理</tag>
        <tag>Fedora</tag>
        <tag>ntfs</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux 的 more 命令</title>
    <url>/2012/02/07/linux-more/</url>
    <content><![CDATA[more - 多多益善more功能类似 cat ，cat命令是整个文件的内容从上到下显示在屏幕上。 more会以一页一页的显示方便使用者逐页阅读，而最基本的指令就是按空白键（space）就往下一页显示，按 b 键就会往回（back）一页显示，而且还有搜寻字串的功能 。more命令从前向后读取文件，因此在启动时就加载整个文件。
在查阅文件的时候，我们说过可以用cat命令，不过这个是入门级别的，但凡用了几天Linux的，基本不太会再使用cat，而是另外两个指令，more或者less。这次说一下more，more是在文件的内容一个屏幕装不小的时候使用的。而less是more的升级版本，稍后会介绍。

 more : 文件内容一屏幕装不下的时候使用的

看看为什么用less命令吧。

more - file perusal filter for crt viewing

看不懂，什么是CRT，莫慌，关于more的解释主要针对在上古年代的计算机，你不理解crt也没有关系，毕竟现在已经是Retina的年代了。
命令格式less的命令格式与cat一样，可以直接跟上文件名，如下：
less [参数] 文件

其中的参数如下所示：

+n   从笫n行开始显示
-n    定义屏幕大小为n行
+/pattern 在每个档案显示前搜寻该字串（pattern），然后从该字串前两行之后开始显示 
-c    从顶部清屏，然后显示
-d    提示“Press space to continue，’q’ to quit（按空格键继续，按q键退出）”，禁用响铃功能
-l    忽略Ctrl+l（换页）字符
-p    通过清除窗口而不是滚屏来对文件进行换页，与-c选项相似
-s    把连续的多个空行显示为一行
-u    把文件内容中的下画线去掉

一起看看下面的实例吧，这里以文件/etc/services为例：
这个文件的开始信息如下：
# /etc/services:# $Id: services,v 1.55 2013/04/14 ovasik Exp $## Network services, Internet style# IANA services version: last updated 2013-04-10## Note that it is presently the policy of IANA to assign a single well-known# port number for both TCP and UDP; hence, most entries here have two entries# even if the protocol doesn't support UDP operations.# Updated from RFC 1700, ``Assigned Numbers'' (October 1994).  Not all ports# are included, only the more common ones.## The latest IANA port assignments can be gotten from#       http://www.iana.org/assignments/port-numbers# The Well Known Ports are those from 0 through 1023.# The Registered Ports are those from 1024 through 49151# The Dynamic and/or Private Ports are those from 49152 through 65535## Each line describes one service, and is of the form:## service-name  port/protocol  [aliases ...]   [# comment]tcpmux          1/tcp                           # TCP port service multiplexertcpmux          1/udp                           # TCP port service multiplexerrje             5/tcp                           # Remote Job Entryrje             5/udp                           # Remote Job Entryecho            7/tcp





+n 从第n行开始显示接下来的命令从第10行开始显示：
$ more +10 /etc/service# Updated from RFC 1700, ``Assigned Numbers'' (October 1994).  Not all ports# are included, only the more common ones.## The latest IANA port assignments can be gotten from#       http://www.iana.org/assignments/port-numbers# The Well Known Ports are those from 0 through 1023.# The Registered Ports are those from 1024 through 49151# The Dynamic and/or Private Ports are those from 49152 through 65535## Each line describes one service, and is of the form:## service-name  port/protocol  [aliases ...]   [# comment]tcpmux          1/tcp                           # TCP port service multiplexertcpmux          1/udp                           # TCP port service multiplexerrje             5/tcp                           # Remote Job Entryrje             5/udp                           # Remote Job Entryecho            7/tcpecho            7/udpdiscard         9/tcp           sink nulldiscard         9/udp           sink nullsystat          11/tcp          userssystat          11/udp          usersdaytime         13/tcpdaytime         13/udpqotd            17/tcp          quoteqotd            17/udp          quote


可以看到前面的10行是没有显示的。

-n 定义屏幕大小为n行这里的含义为定义输出的内容为10行，你的屏幕可能足够大，不过显示的内容只有n行，如下：只显示10行的内容，此时终端可能还会残留以前的内容：
$ more -10 /etc/services# /etc/services:# $Id: services,v 1.55 2013/04/14 ovasik Exp $## Network services, Internet style# IANA services version: last updated 2013-04-10## Note that it is presently the policy of IANA to assign a single well-known# port number for both TCP and UDP; hence, most entries here have two entries# even if the protocol doesn't support UDP operations.# Updated from RFC 1700, ``Assigned Numbers'' (October 1994).  Not all ports


可以关注一下，此时每次显示的只有10行。

+/pattern 搜寻字符串（pattern）这个参数用于在文件中搜索字符串pattern，然后在该字符串的前两行之前开始显示。比如搜索number，会显示以下内容：
$ more +/number /etc/services## Note that it is presently the policy of IANA to assign a single well-known# port number for both TCP and UDP; hence, most entries here have two entries# even if the protocol doesn't support UDP operations.# Updated from RFC 1700, ``Assigned Numbers'' (October 1994).  Not all ports# are included, only the more common ones.## The latest IANA port assignments can be gotten from#       http://www.iana.org/assignments/port-numbers# The Well Known Ports are those from 0 through 1023.# The Registered Ports are those from 1024 through 49151# The Dynamic and/or Private Ports are those from 49152 through 65535## Each line describes one service, and is of the form:## service-name  port/protocol  [aliases ...]   [# comment]tcpmux          1/tcp                           # TCP port service multiplexertcpmux          1/udp                           # TCP port service multiplexerrje             5/tcp                           # Remote Job Entryrje             5/udp                           # Remote Job Entryecho            7/tcpecho            7/udpdiscard         9/tcp           sink nulldiscard         9/udp           sink nullsystat          11/tcp          userssystat          11/udp          usersdaytime         13/tcp......


可以留意，此时显示的内容，第三行即包含搜索的字符串。

其他除以上介绍的以外，还有比较容易理解的以下参数：

-c    从顶部清屏，然后显示
-p    通过清除窗口而不是滚屏来对文件进行换页，与-c选项相似
-s    把连续的多个空行显示为一行
-u    把文件内容中的下画线去掉

]]></content>
      <categories>
        <category>CentOS</category>
        <category>Fedora</category>
        <category>Linux</category>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>more</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux的 mv 命令</title>
    <url>/2011/02/12/linux-mv-beginner/</url>
    <content><![CDATA[mv文件移动或更名命令mv命令用于移动文件或者重命名文件及文件夹。官方定义为：

mv : move files

语法mv的语法与cp等其他语法类似，如下：
$ mv [options] source dest$ mv [options] source ... directory

几个比较常用的选项如下：

-b: 当目标文件或目录存在时，在执行覆盖前，会为其创建一个备份，文件后缀用~表示；
-i或–interactive: 如果指定移动的源目录或文件与目标的目录或文件同名，则会先询问是否覆盖旧文件，输入 y 表示直接覆盖，输入 n 表示取消该操作，一般而言，对于不确定的时候可以用此选项，不过文件或文件夹居多时，最好不要用
-f或–force: 如果指定移动的源目录或文件与目标的目录或文件同名，不会询问，直接覆盖旧文件，强制的意思force
-n或–no-clobber: 不要覆盖任何已存在的文件或目录。
-u：当源文件比目标文件新或者目标文件不存在时，才执行移动操作。

常规操作$ lsa.txt$ mv a.txt b.txt$ lsb.txt

直接移动或者叫做重命名，文件夹也类似的操作。
覆盖前备份$ lsa.txt  a.txt~$ cp -b ../a.txt a.txt$ lsa.txt  a.txt~


可以看到此时多了一个备份文件

增量更新$ cp -u a b	


此时的操作为，只有a比b更新或者b不存在的时候，才会进行更新，否则失败。
这个用法多用在：当横向对比两个文价夹有无重要更新的时候才会用到。

交互提示$ cp -i b.txt a.txtcp：是否覆盖"a.txt"？ 




在文件存在的时候，-i选项会进行提示，此时需要输入y才能覆盖，而输入n就会取消这个操作。

]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>文件管理</tag>
        <tag>mv</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux的 mv 命令</title>
    <url>/2011/02/12/linux-mv/</url>
    <content><![CDATA[mv文件移动或更名命令mv命令用于移动文件或者重命名文件及文件夹。官方定义为：

mv : move files

语法mv的语法与cp等其他语法类似，如下：
$ mv [options] source dest$ mv [options] source ... directory

几个比较常用的选项如下：

-b: 当目标文件或目录存在时，在执行覆盖前，会为其创建一个备份，文件后缀用~表示；
-i或–interactive: 如果指定移动的源目录或文件与目标的目录或文件同名，则会先询问是否覆盖旧文件，输入 y 表示直接覆盖，输入 n 表示取消该操作，一般而言，对于不确定的时候可以用此选项，不过文件或文件夹居多时，最好不要用
-f或–force: 如果指定移动的源目录或文件与目标的目录或文件同名，不会询问，直接覆盖旧文件，强制的意思force
-n或–no-clobber: 不要覆盖任何已存在的文件或目录。
-u：当源文件比目标文件新或者目标文件不存在时，才执行移动操作。

常规操作$ lsa.txt$ mv a.txt b.txt$ lsb.txt

直接移动或者叫做重命名，文件夹也类似的操作。
覆盖前备份$ lsa.txt  a.txt~$ cp -b ../a.txt a.txt$ lsa.txt  a.txt~


可以看到此时多了一个备份文件

增量更新$ cp -u a b	


此时的操作为，只有a比b更新或者b不存在的时候，才会进行更新，否则失败。
这个用法多用在：当横向对比两个文价夹有无重要更新的时候才会用到。

交互提示$ cp -i b.txt a.txtcp：是否覆盖"a.txt"？ 




在文件存在的时候，-i选项会进行提示，此时需要输入y才能覆盖，而输入n就会取消这个操作。

]]></content>
      <categories>
        <category>Linux</category>
        <category>Linux入门</category>
        <category>文件管理</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>mv</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux的 mysql数据库安装和配置</title>
    <url>/2015/02/12/linux-mysql/</url>
    <content><![CDATA[mysql数据库安装和配置安装指令为：
$ yum install mysql$ yum install mysql-server$ yum install mysql-devel



自从CentOS7之后，mysql更改为mariadb
安装命令为：
$ yum install mariadb$ yum install mariadb-server$ yum install mariadb-devel



数据库的相关指令：
systemctl start mariadb  #启动MariaDBsystemctl stop mariadb  #停止MariaDBsystemctl restart mariadb  #重启MariaDBsystemctl enable mariadb  #设置开机启动

]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux 解决lnurses库问题之/usr/bin/ld:can not find -lncurses</title>
    <url>/2012/07/07/linux-ncurses/</url>
    <content><![CDATA[ncurses是字符终端下屏幕控制的基本库，在编译grub时出现如下错误：
/usr/bin/ld:can not find -lncursescollect2: ld returned 1 exit status

首先安装ncurses。
Fedora/CentOS/RedHat$ yum install ncurses-devel ncurses-static

Ubuntu：$ apt-get install libncurses5-dev
]]></content>
      <categories>
        <category>CentOS</category>
        <category>Fedora</category>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>apt-get</tag>
        <tag>yum</tag>
        <tag>linux</tag>
        <tag>ncurses</tag>
        <tag>ubuntu</tag>
        <tag>centos</tag>
        <tag>fedora</tag>
        <tag>ld</tag>
      </tags>
  </entry>
  <entry>
    <title>探索网络连接的netstat</title>
    <url>/2020/08/26/linux-netstat-beginner/</url>
    <content><![CDATA[探索网络连接的netstat在Linux系统中，网络是至关重要的部分，而netstat命令是管理和监视网络连接的强大工具之一。
它提供了关于网络接口和路由表的详细信息，有助于了解网络连接状态、统计信息以及网络协议的使用情况。
也更方便我们对网络的管理、故障排除以及安全监控等等。
基本概述netstat命令比较简单，通过简单的参数组合，可以获得各种网络相关的信息。
以下是一些常用的参数及其功能：

-a：显示所有连接和监听端口。
-t：仅显示TCP连接。
-u：仅显示UDP连接。
-n：以数字形式显示地址和端口号。
-p：显示进程标识符和程序名称。
-r：显示路由表。
-s：显示统计信息。

]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>Linux炫技</tag>
        <tag>ip</tag>
        <tag>网络命令</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux NFS 配置</title>
    <url>/2013/08/27/linux-nfs/</url>
    <content><![CDATA[NFS 配置nfs原理：通过网络，将远程主机共享的文件系统，挂载到本机。
双方在进行nfs通讯时，必须启动portmap(F8中是rpcbind)服务。
1）在主机上启动portmap服务(F8为rpcbind，默认都为开启)
service rpcbind start

可以用service rpcbind status 进行检查是否开启。

2)对nfs进行配置（/etc/exports）
   修改配置文件/etc/exports
   添加如下代码
/shared/path    *(rw,sync,no_root_squash)

要共享的目录    允许使用的用户，*表示允许任意用户使用，也可以使用具体的ip，如本机可用192.168.1.168,括号中rw代表可读写，sync未知，no_root_suqash意思是以root权限访问该共享文件夹。
修改完之后，输入：
[root@localhost etc]# exportfs -rv

使配置文件生效。   
3)在主机上启动nfs服务
service nfs start

4）挂载mount
mount -t nfs IP:/shared/path /mnt

建议：在配置完nfs后，可以本机挂载自己，试试看，是否配置正确
其间遇到的问题：
1）mount: IP:/sharedpath failed, reason given by server: Permission denied
查看配置文件exports,是否为允许挂载的客户。
2）mount: RPC: Unable to receive; errno = No route to host
首先看是否在同一网段
再者输入：
[root@localhost etc]# service iptables status

看防火墙是否开启，有则将其关闭
[root@localhost etc]# service iptables stop

3)mount: RPC: Unable to receive; errno = Connection refused
首先看nfs服务是否开启，其次看rpcbind是否开启，如果rpcbind没有运行，那在重新开启rpcbind后，要再restart nfs服务，因为重启rpcbind已对nfs的一些配置造成影响，需要restart。
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>service</tag>
        <tag>rpcbind</tag>
        <tag>portmap</tag>
        <tag>nfs</tag>
        <tag>exportfs</tag>
        <tag>iptables</tag>
        <tag>mount</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux nice 命令</title>
    <url>/2012/02/07/linux-nice-beginner/</url>
    <content><![CDATA[Linux nice命令.. note::
  桃李春风一杯酒，江湖夜雨十年灯。

黄庭坚· 《寄黄几复》

Linux nice命令可以通过修改优先级来执行程序，如果单纯输入nice，未指定程序，则会打印出目前的排程优先序，默认的数值为0，范围为最高优先级的 -20到 最低优先级的19。
所谓的优先序就是优先执行的概念，优先级越高，获得CPU的时间和顺序也会越提前。
官方定义为：

nice - run a program with modified scheduling priority

语法使用方法如下：
$ nice [OPTION] [COMMAND [ARG]...]



参数的话，只有一个，如下：

-n, --adjustment=N  调整执行的优先序 (默认为 10)

实例设置ls的优先级，如下将设置ls的优先级加10
$ nice ls



下面的就是把ls命令的优先级加5
$ nice -n 5 ls





设置程序运行时的优先级实例下面通过几个操作来看一下nice的效果
$ vim &amp;$ nice vi$ nice vim &amp;$ nice -n 5 vim &amp;# 查看进程状态 其中PRI即为优先级情况，可以看到几个进程是不同的。$ ps -l F S   UID   PID  PPID  C PRI  NI ADDR SZ WCHAN  TTY          TIME CMD0 S  1000     8     7  0  80   0 -  6406 -      tty1     00:00:02 bash0 T  1000   251     8  0  75 42967291 - 15927 - tty1     00:00:00 vim0 T  1000   319     8  0  65 42967281 - 15927 - tty1     00:00:00 vi0 T  1000   374     8  0  65 42967281 - 15927 - tty1     00:00:00 vim0 T  1000   415     8  2  70 42967286 - 15927 - tty1     00:00:00 vim0 R  1000   456     8  0  80   0 -  4983 -      tty1     00:00:00 ps


]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>nice</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux No such device eth0</title>
    <url>/2013/07/12/linux-no-such-device-eth/</url>
    <content><![CDATA[在配置网络的时候出现No such device eth0，可能的原因是可能更换了网卡或者硬盘，而系统记录还保留在原来的网卡配置信息上，导致无法判断到相应的网卡。
解决方法为：
rm /etc/udev/rules.d/70-persistent-net.rules

然后重启即可解决。
此时在使用service network restart应该就可以了。
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>service</tag>
        <tag>network</tag>
        <tag>70-persistent-net</tag>
        <tag>eth0</tag>
        <tag>udev</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux nohup 命令</title>
    <url>/2018/01/31/linux-nohup/</url>
    <content><![CDATA[linux后台执行命令：&amp;和nohup当我们在终端或控制台工作的时候，如果希望同时进行另外一个工作，那么此时就希望将当前的工作放在后台运行，特别是如果当前的命令执行时间会很长的情况下。
那么下面就说下两种方法。
&amp;命令后面加上&amp;相信很多人都用过，比较适合一些费时的命令或脚本，不过注意不要讲有交互的命令放在后台执行，因为这样你的机器就会一直等待输入。使用方法为
$ command &amp;

如果放在后台的作业会产生大量的输出，那么此时最好可以将输出重定向到某个文件中，使用方法为
$ command &gt; out.file 2&gt;&amp;1 &amp;


其中2&gt;&amp;1 表示将标准出错重定向到标准输出

不过使用&amp;有的弊端，就是一旦把当前的控制台关掉或者账号退出时就会停止作业。
此时就需要下面的这个命令了。
nohupnohup命令可以在退出账户后继续执行相应的命令，意思为不挂起no hang up。
命令的使用方法如下：
$ nohup command &amp;

默认情况下作业的所有输出被重定向到一个nohup.out文件中，也可以指定输出文件，如下所示：
$ nohup command &gt; mynohup.file 2&gt;&amp;1 &amp;


不过这里还是有需要注意的事项，非正常退出可能会导致命令失效，所以需要使用exit正常退出当前账户。

]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>nohup</tag>
      </tags>
  </entry>
  <entry>
    <title>关于NTP及ntpdate</title>
    <url>/2012/01/06/linux-ntp-ntpdate/</url>
    <content><![CDATA[关于NTP 对于执行ntpdate而没有这个命令的，估计是ntp的相关包没有安装，在fedora下，使用下述命令即可将ntp和ntpdate安装上
yum install ntp

同步不过，注意使用它ntpdate的时候需要在root账户下。
[root@localhost]# ntpdate 129.7.1.6629 Aug 21:38:13 ntpdate[822]: adjust time server 129.7.1.66 offset –0.011426 sec

看来偶的机器与国家授时中心的就差了11ms，看来哥也是一个授时的人，哈哈。
NTP时间服务器 下面是几个通用的NTP时间服务器：

129.7.1.66ntp-sop.inria.frserver 210.72.145.44(中国国家授时中心服务器IP地址)
ntp.sjtu.edu.cn (上海交通大学网络中心NTP服务器地址）
202.120.2.101 (上海交通大学网络中心NTP服务器地址）
time.nist.gov
ntp.fudan.edu.cn (复旦)
timekeeper.isi.edu
subitaneous.cpsc.ucalgary.ca
usno.pa-x.dec.com
time.twc.weather.com
swisstime.ethz.ch
ntp0.fau.de
ntp3.fau.de
time-a.nist.gov
time-b.nist.gov
time-nw.nist.gov
nist1-sj.glassey.com
ntp.aliyun.com

具体的操作步骤就是ntpdate 加上上面的随笔一个NTP时间服务器就OK了。
Linux时间简介在Windwos中，系统时间的设置很简单，界面操作，通俗易懂。而且设置后，重启，关机都没关系。系统时间会自动保存在Bios的时钟里面，启动计算机的时候，系统会自动在Bios里面取硬件时间，以保证时间的不间断。
但在Linux下，默认情况下，系统时间和硬件时间，并不会自动同步。在Linux运行过程中，系统时间和硬件时间以异步的方式运行，互不干扰。硬件时间的运行，是靠Bios电池来维持，而系统时间，是用CPU tick来维持的。
在系统开机的时候，会自动从Bios中取得硬件时间，设置为系统时间。  
为了将系统时间写入BIOS，可以使用hwclock或者clock命令。其中，clock和hwclock用法相近，只用一个就行，只不过clock命令除了支持x86硬件体系外，还支持Alpha硬件体系。
系统时间和硬件时间的同步//以系统时间为基准，修改硬件时间[root@localhost ~]# hwclock –systohc  &lt;== sys（系统时间）to（写到）hc（Hard Clock）[root@localhost ~]# hwclock -w//以硬件时间为基准，修改系统时间[root@localhost ~]# hwclock –hctosys[root@localhost ~]# hwclock -s

ntpd和ntpdate的区别 为了避免主机时间因为长期运作下所导致的时间偏差，进行时间同步(synchronize)的工作是非常必要的。Linux系统下，一般使用ntp服务器来同步不同机器的时间。一台机器，可以同时是ntp服务器和ntp客户机。在网络中，推荐使用像DNS服务器一样分层的时间服务器来同步时间。      
 同步时间，可以使用ntpdate命令，也可以使用ntpd服务。     
使用ntpdate比较简单。格式如下：
[root@linux ~]# ntpdate [-nv] [NTP IP/hostname][root@linux ~]# ntpdate 192.168.0.2[root@linux ~]# ntpdate time.ntp.org

但这样的同步，只是强制性的将系统时间设置为ntp服务器时间。如果cpu tick有问题，只是治标不治本。所以，一般配合cron命令，来进行定期同步设置。
比如，在crontab中添加：  
0 12 * * * * /usr/sbin/ntpdate 192.168.0.1
这样，会在每天的12点整，同步一次时间。ntp服务器为192.168.0.1。
使用ntpd服务，要好于ntpdate加cron的组合。因为，ntpdate同步时间，会造成时间的跳跃，对一些依赖时间的程序和服务会造成影响。比如sleep，timer等。而且，ntpd服务可以在修正时间的同时，修正cpu tick。理想的做法为，在开机的时候，使用ntpdate强制同步时间，在其他时候使用ntpd服务来同步时间。

要注意的是，ntpd 有一个自我保护设置: 如果本机与上源时间相差太大, ntpd 不运行. 所以新设置的时间服务器一定要先 ntpdate 从上源取得时间初值, 然后启动 ntpd服务。ntpd服务 运行后, 先是每64秒与上源服务器同步一次, 根据每次同步时测得的误差值经复杂计算逐步调整自己的时间, 随着误差减小, 逐步增加同步的间隔. 每次跳动, 都会重复这个调整的过程.


所以：ntpd不仅仅是时间同步服务器，他还可以做客户端与标准时间服务器进行同步时间，而且是平滑同步，并非ntpdate立即同步，在生产环境中慎用ntpdate，也正如此两者不可同时运行。

时钟的跃变，对于某些程序会导致很严重的问题。许多应用程序依赖连续的时钟——毕竟，这是一项常见的假定，即，取得的时间是线性的，一些操作，例如数据库事务，通常会地依赖这样的事实：时间不会往回跳跃。不幸的是，ntpdate调整时间的方式就是我们所说的”跃变“：在获得一个时间之后，ntpdate使用settimeofday(2)设置系统时间，这有几个非常明显的问题：

这样做不安全。ntpdate的设置依赖于ntp服务器的安全性，攻击者可以利用一些软件设计上的缺陷，拿下ntp服务器并令与其同步的服务器执行某些消耗性的任务。由于ntpdate采用的方式是跳变，跟随它的服务器无法知道是否发生了异常（时间不一样的时候，唯一的办法是以服务器为准）。
这样做不精确。一旦ntp服务器宕机，跟随它的服务器也就会无法同步时间。与此不同，ntpd不仅能够校准计算机的时间，而且能够校准计算机的时钟。
这样做不够优雅。由于是跳变，而不是使时间变快或变慢，依赖时序的程序会出错（例如，如果ntpdate发现你的时间快了，则可能会经历两个相同的时刻，对某些应用而言，这是致命的）。


因而，唯一一个可以令时间发生跳变的点，是计算机刚刚启动，但还没有启动很多服务的那个时候。其余的时候，理想的做法是使用ntpd来校准时钟，而不是调整计算机时钟上的时间。

NTPD 在和时间服务器的同步过程中，会把 BIOS 计时器的振荡频率偏差——或者说 Local Clock 的自然漂移(drift)——记录下来。这样即使网络有问题，本机仍然能维持一个相当精确的走时。
]]></content>
      <categories>
        <category>Linux</category>
        <category>CentOS</category>
        <category>Fedora</category>
      </categories>
      <tags>
        <tag>yum</tag>
        <tag>ntp</tag>
        <tag>BIOS</tag>
        <tag>hwclock</tag>
        <tag>clock</tag>
        <tag>ntpdate</tag>
        <tag>crontab</tag>
        <tag>ntpd</tag>
        <tag>settimeofday</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux的 od 命令</title>
    <url>/2012/07/07/linux-od/</url>
    <content><![CDATA[Linux的 od 命令od - dump files in octal and other formats顾名思义是查看八进制，可以通过指定参数为查看十六进制

-A 指定左边侧栏显示的地址基数，默认为八进制
-t 指定输出单元的进制格式和字节数
-x = -t x2 输出单元为双字节（注意：每单元内排列顺序从左到右为 [高字节｜低字节]）

例：
$  od -t x1 filename | less0000000    ed  de  ad  ab  76  00  00  00  76  89  00  59  e6  f3  75  140000020    f9  37  34  1b  f7  b8  d3  4d  ab  2d  f1  ef  f0  66  f5  120000040    2f  33  cf  40  e4  c2  cd  3f  5e  30  00  93  41  a1  0b  0c$ od -A d -t x2 filename| less0000000      deed    abad    0076    0000    8976    5900    f3e6    14750000016      37f9    1b34    b8f7    4dd3    2dab    eff1    66f0    12f50000032      332f    40cf    c2e4    3fcd    305e    9300    a141    0c0b
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>od</tag>
      </tags>
  </entry>
  <entry>
    <title>OpenCL</title>
    <url>/2017/03/22/linux-opencl/</url>
    <content><![CDATA[OpenCLOpenCL (Open Computing Language，开放计算语言) 是一个为异构平台编写程序的框架，此异构平台可由CPU，GPU或其他类型的处理器组成。OpenCL由一门用于编写kernels （在OpenCL设备上运行的函数）的语言（基于[C99]）和一组用于定义并控制平台的API组成。OpenCL提供了基于任务分区和数据分区的并行计算机制。OpenCL类似于另外两个开放的工业标准OpenGL(跨平台图形API)和OpenAL(跨平台音效API)，这两个标准分别用于三维图形和计算机音频方面。OpenCL扩充了GPU图形生成之外的能力。OpenCL由非盈利性技术组织Khronos Group掌管。
]]></content>
      <categories>
        <category>API</category>
      </categories>
      <tags>
        <tag>OpenCV</tag>
        <tag>OpenCL</tag>
        <tag>OpenGL</tag>
      </tags>
  </entry>
  <entry>
    <title>OpenCV</title>
    <url>/2017/03/22/linux-opencv/</url>
    <content><![CDATA[OpenCVOpenCV的全称是Open Source Computer Vision Library，是一个跨平台的计算机视觉库(主要操作对象是图像)。OpenCV是由英特尔公司发起并参与开发，以BSD许可证授权发行，可以在商业和研究领域中免费使用。OpenCV可用于开发实时的图像处理、计算机视觉以及模式识别程序。该程序库也可以使用英特尔公司的IPP进行加速处理。
]]></content>
      <categories>
        <category>API</category>
      </categories>
      <tags>
        <tag>OpenCV</tag>
        <tag>OpenCL</tag>
        <tag>OpenGL</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux OpenGL</title>
    <url>/2011/08/23/linux-opengl/</url>
    <content><![CDATA[OpenGLOpenGL（全写Open Graphics Library）是个定义了一个跨编程语言、跨平台的应用程序接口（API）的规格，它用于生成二维、三维图像。这个接口由近三百五十个不同的函数调用组成，用来从简单的图形比特绘制复杂的三维景象。而另一种程序接口系统是仅用于Microsoft Windows上的[Direct3D。OpenGL常用于CAD、虚拟实境)、科学可视化程序和[电子游戏开发
用OpenGL绘制图形/** File: main.c* Author: leo** Drawing a simple 3D rectangle program with GLUT* OpenGL ~~*/#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;GL/gl.h&gt;#include &lt;GL/glu.h&gt;#include &lt;GL/glut.h&gt;//called to draw scenevoid RenderScene(void){//clear the window with current clearing colorglClear(GL_COLOR_BUFFER_BIT);//set current drawing color to readglColor3f(1.0f,0.0f,0.0f); //设置以后绘制操作所用的颜色//draw a filled rectangle with current colorglRectf(100.f,150.0f,150.0f,100.0f); //绘制一个填充的矩形//flush drawing commandsglFlush();}//set up the rendering statevoid SetupRC(void){glClearColor(0.0f,0.0f,1.0f,1.0f);}//called by GLUT library when the window has changed sizevoid ChangeSize(GLsizei w, GLsizei h){//prevent a divide by zeroif(h == 0)h = 1;//set viewport to window dimensionsglViewport(0,0,w,h);//reset coordinate systemglMatrixMode(GL_PROJECTION);glLoadIdentity();//在每次进行任何矩阵处理之前都“复位”坐标系//establish clipping volumn(left,right,bottom,top,near,far)if(w &lt;= h)glOrtho(0.0f,250.0f,0.0f,250.0f*h/w,1.0,-1.0);elseglOrtho(0.0f,250.0f*w/h,0.0f,250.0f,1.0,-1.0);glMatrixMode(GL_MODELVIEW);glLoadIdentity();}int main(int argc, char** argv) {glutInit(&amp;argc,argv);glutInitDisplayMode(GLUT_SINGLE | GLUT_RGB);glutCreateWindow("Plot Rect. using GLUT");glutDisplayFunc(RenderScene);glutReshapeFunc(ChangeSize);//窗口大小发生变化，就重新设置坐标系SetupRC();glutMainLoop();return (EXIT_SUCCESS);}
]]></content>
      <categories>
        <category>Linux</category>
        <category>Qt</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>OpenGL</tag>
        <tag>Qt</tag>
      </tags>
  </entry>
  <entry>
    <title>不要告诉别人的passwd</title>
    <url>/2013/03/07/linux-passwd-beginner/</url>
    <content><![CDATA[不要告诉别人的passwdpasswd用于创建或者更新用户密码，是管理员必备的命令之一。
这个命令最终的实现是通过调用Linux-PAM 和Libuser API来实现的。
官方的定义为：

passwd - update user’s authentication tokens

使用的方法为：
$ passwd [-k] [-l] [-u [-f]] [-d] [-e] [-n mindays] [-x maxdays] [-w warndays] [-i inactivedays] [-S] [--stdin] [username]

其中很常用的options为：

-S, --status：显示密码的状态信息
-d, --delete：删除用户密码，此时该用户将处于无密码状态

不太常用的options为：

--stdin：可以通过标准输入，亦可以为一个pipe
-l, --lock：锁定账号，不过也不是完全锁定，因为用户可以通过ssh key来继续访问
-u, --unlock：与上面的-l选项相反，属于解锁用户
-w, --warning DAYS：口令到期前通知用户，具备password lifetime的才支持

修改或更新密码这个是最常用的用法，用于设置或者修改更新用户密码
$ sudo passwd user  		#设置用户user的密码Enter new UNIX password:  	#输入新密码，输入的密码不显示Retype new UNIX password:  	#再次输入确认密码passwd: password updated successfully# 此时设置成功



删除用户密码$ sudo passwd -d user passwd: password expiry information changed.

此时用户处于无密码的状态，很类似最近说的，没有密码就是最安全的密码。
查看密码的状态$ sudo passwd -S user[sudo] password for oper: user PS 2013-02-11 0 99999 7 -1 (Password set, SHA512 crypt.)



​      
说到密码，有两个比较重要的原则：

保护好你的密码，不写下来而是记在脑海里，定时修改；
选择一个很难猜的密码，而不是最容易被攻破的top密码；

]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>系统设置</tag>
        <tag>passwd</tag>
        <tag>用户信息</tag>
        <tag>系统管理</tag>
        <tag>管理员</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux passwd</title>
    <url>/2013/03/07/linux-passwd/</url>
    <content><![CDATA[linux中创建或更新用户密码passwd用于创建或者更新用户密码，是管理员必备的命令之一。
这个命令最终的实现是通过调用Linux-PAM 和Libuser API来实现的。
官方的定义为：

passwd - update user’s authentication tokens

使用的方法为：
$ passwd [-k] [-l] [-u [-f]] [-d] [-e] [-n mindays] [-x maxdays] [-w warndays] [-i inactivedays] [-S] [--stdin] [username]

其中很常用的options为：

-S, --status：显示密码的状态信息
-d, --delete：删除用户密码，此时该用户将处于无密码状态

不太常用的options为：

--stdin：可以通过标准输入，亦可以为一个pipe
-l, --lock：锁定账号，不过也不是完全锁定，因为用户可以通过ssh key来继续访问
-u, --unlock：与上面的-l选项相反，属于解锁用户
-w, --warning DAYS：口令到期前通知用户，具备password lifetime的才支持

修改或更新密码这个是最常用的用法，用于设置或者修改更新用户密码
$ sudo passwd user  		#设置用户user的密码Enter new UNIX password:  	#输入新密码，输入的密码不显示Retype new UNIX password:  	#再次输入确认密码passwd: password updated successfully# 此时设置成功



删除用户密码$ sudo passwd -d user passwd: password expiry information changed.

此时用户处于无密码的状态，很类似最近说的，没有密码就是最安全的密码。
查看密码的状态$ sudo passwd -S user[sudo] password for oper: user PS 2013-02-11 0 99999 7 -1 (Password set, SHA512 crypt.)



​      
说到密码，有两个比较重要的原则：

保护好你的密码，不写下来而是记在脑海里，定时修改；
选择一个很难猜的密码，而不是最容易被攻破的top密码；

]]></content>
      <categories>
        <category>Linux</category>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>passwd</tag>
        <tag>管理员</tag>
        <tag>System Management Commands</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux的 pgrep/pkill 命令</title>
    <url>/2016/11/20/linux-pgrep-beginner/</url>
    <content><![CDATA[pgrep/pkill 检索终止当前正在运行的程序鉴于用man pgrep 和man pkill的时候出来的同一个释义，所以要一次说两个命令了。
Linux pgrep和pkill 命令根据名称和其他属性来查找或发送处理的信号。
官方定义为：

 pgrep, pkill - look up or signal processes based on name and other attributes

pgrep将查找当前运行的进程中满足条件的并打印到stdout中。
语法语法如下所示：
$ pgrep [options] pattern$ pkill [options] pattern

常用的参数为：

-u  选择仅匹配指定有效用户ID进程
-I  列出进程名及进程ID
-a  列出进程的详细命令行

默认无参数默认情况下，仅仅列出包含关键词的进程ID。
$ pgrep ssh307338334475578659551130113654...



 而pkill刚好相反，直接发送终止信号（默认为SIGTERM）给这些进程。 
指定用户可以通过-u来指定用户
$ pgrep ssh -u username44752208427695...



列出进程名仅仅看到ID是崩溃的，因为不知道具体的进程，可以通过-l来查看进程名
$ pgrep ssh -l3073 sshd3833 ssh-agent4475 ssh-agent5786 ssh-agent5955 sshd...



更详细的进程信息或许知道的进程名，还不足以了解具体信息，此时-a选项就爬上用场了。
$ pgrep ssh -a3073 /usr/sbin/sshd -D3833 /usr/bin/ssh-agent /etc/X11/xinit/Xclients5955 sshd: /usr/sbin/sshd -D -f /assets/sshd_config -e [listener] 0 of 100-200 startups...
]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>pgrep</tag>
        <tag>pkill</tag>
      </tags>
  </entry>
  <entry>
    <title>网络中不中，先看ping行不行</title>
    <url>/2012/07/07/linux-ping-beginner/</url>
    <content><![CDATA[网络中不中，先看ping行不行在linux系统里面如果想判断网络的好坏，脑海中蹦出的第一个命令就是ping了。
官方定义为：

ping - send ICMP ECHO_REQUEST to network hosts

ping命令基本是最常用的网络命令，它可以用来测试与目标主机的连通性。
ping使用ICMP传输协议，通过发送ICMP ECHO_REQUEST数据包到网络主机，并显示返回的相应情况，根据这些信息就可以判断目标主机是否可以访问，在发送的过程中还会有一个时间戳用来计算网络的状态。
不过有些服务器为了防止通过ping探测到，可能会在防火墙或者内核参数中禁止ping命令，这样的话，可能虽然目标主机可以访问，但是无法ping通，所以并不能说ping不通的网络就是不能访问的。

需要注意linux下的ping和windows下的ping稍有区别,linux下ping不会自动终止,需要按ctrl+c终止或者用参数-c指定要求完成的回应次数。

语法ping的使用说实话挺复杂，挺多的，不过常用的这篇短文基本就够了。
详细如下：
# ALL$ ping  [-aAbBdDfhLnOqrRUvV46]  [-c  count]  [-F  flowlabel]  [-i  interval]  [-I interface] [-l preload] [-m mark] [-M pmtudisc_option] [-N node‐info_option] [-w deadline] [-W timeout] [-p pattern] [-Q tos] [-s packetsize] [-S sndbuf] [-t ttl] [-T timestamp option] [hop ...] destination# 较常用的选项如下：$ ping   [-c  count]   [-i  interval]  destination

参数说明：

-c &lt;完成次数&gt; 设置完成要求回应的次数。

-i interval 指定收发信息的间隔时间。


不加任何参数如果不加任何参数，查看是否ping通
$ ping www.baidu.com   PING www.a.shifen.com (115.239.210.27) 56(84) bytes of data.64 bytes from 115.239.210.27: icmp_seq=1 ttl=52 time=6.06 ms64 bytes from 115.239.210.27: icmp_seq=2 ttl=52 time=5.56 ms64 bytes from 115.239.210.27: icmp_seq=3 ttl=52 time=5.67 ms64 bytes from 115.239.210.27: icmp_seq=4 ttl=52 time=5.82 ms64 bytes from 115.239.210.27: icmp_seq=5 ttl=52 time=5.70 ms64 bytes from 115.239.210.27: icmp_seq=6 ttl=52 time=5.79 ms  ^C # 此处输入了Ctrl+C强制退出--- 192.168.1.123 ping statistics ---5 packets transmitted, 5 received, 0% packet loss, time 3999msrtt min/avg/max/mdev = 0.152/0.159/0.172/0.017 ms



可以看到可以ping通www.baidu.com，时延还算比较OK，几个毫秒量级。

这里看一下几个字段的含义，其中：
56(84) bytes of data：表示默认的数据包长度为56字节；
time=5.56ms：表示响应的时间，值越小，证明连接越快；
TTL=52：TTL是Time To Live的缩写，表示DNS记录在DNS服务器上存在的时间，是IP协议包的一个值，告诉路由器啥时候抛弃这个数据包，（大体上可以通过这个值来判断目标类型的操作系统。）

发送指定数目可以通过 参数-c 来发送指定数目的包后停止
$ ping www.baidu.com -c 5PING www.a.shifen.com (115.239.211.112) 56(84) bytes of data.64 bytes from 115.239.211.112: icmp_seq=1 ttl=52 time=6.03 ms64 bytes from 115.239.211.112: icmp_seq=2 ttl=52 time=5.96 ms64 bytes from 115.239.211.112: icmp_seq=3 ttl=52 time=5.79 ms64 bytes from 115.239.211.112: icmp_seq=4 ttl=52 time=5.79 ms64 bytes from 115.239.211.112: icmp_seq=5 ttl=52 time=6.21 ms--- www.a.shifen.com ping statistics ---5 packets transmitted, 5 received, 0% packet loss, time 4007msrtt min/avg/max/mdev = 5.791/5.958/6.215/0.186 ms



此时将在发送5次数据包以后自动停止，在Linux里面，如果不加这个参数，是会一直发送运行的。
设定发送时间间隔可以通过 参数 -i N指定每个N秒发送一次信息，如下将每隔3秒发送一次ping信息。
$ ping www.baidu.com -i 3PING www.a.shifen.com (14.215.177.38) 56(84) bytes of data.64 bytes from 14.215.177.38 (14.215.177.38): icmp_seq=1 ttl=55 time=28.6 ms64 bytes from 14.215.177.38 (14.215.177.38): icmp_seq=2 ttl=55 time=28.6 ms64 bytes from 14.215.177.38 (14.215.177.38): icmp_seq=3 ttl=55 time=28.6 ms64 bytes from 14.215.177.38 (14.215.177.38): icmp_seq=4 ttl=55 time=28.6 ms64 bytes from 14.215.177.38 (14.215.177.38): icmp_seq=5 ttl=55 time=28.6 ms64 bytes from 14.215.177.38 (14.215.177.38): icmp_seq=6 ttl=55 time=28.6 ms^C--- www.a.shifen.com ping statistics ---6 packets transmitted, 6 received, 0% packet loss, time 15041msrtt min/avg/max/mdev = 28.650/28.670/28.697/0.139 ms



如上，每隔3秒会发送一次，对于需要持续检测或者记录的可以考虑适当加大这个时间间隔。

注意，只有管理员可以设置小于0.2秒的时间间隔。所以这个数值可以是浮点数~

组合使用上面的几个例子是可以配合使用的，比如
$ ping www.baidu.com -c 4 -i 5 PING www.a.shifen.com (14.215.177.39) 56(84) bytes of data.64 bytes from 14.215.177.39 (14.215.177.39): icmp_seq=1 ttl=55 time=29.4 ms64 bytes from 14.215.177.39 (14.215.177.39): icmp_seq=2 ttl=55 time=29.3 ms64 bytes from 14.215.177.39 (14.215.177.39): icmp_seq=3 ttl=55 time=29.4 ms64 bytes from 14.215.177.39 (14.215.177.39): icmp_seq=4 ttl=55 time=29.4 ms--- www.a.shifen.com ping statistics ---5 packets transmitted, 5 received, 0% packet loss, time 20045msrtt min/avg/max/mdev = 29.396/29.428/29.461/0.110 ms

这个例子为：每个5秒查询一次，一共查询4次，然后退出。
]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>ping</tag>
        <tag>网络命令</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux的 ping 命令</title>
    <url>/2012/07/07/linux-ping/</url>
    <content><![CDATA[Linux网络入门ping在linux系统里面如果想判断网络的好坏，脑海中蹦出的第一个命令就是ping了。
官方定义为：

ping - send ICMP ECHO_REQUEST to network hosts

ping命令基本是最常用的网络命令，它可以用来测试与目标主机的连通性。
ping使用ICMP传输协议，通过发送ICMP ECHO_REQUEST数据包到网络主机，并显示返回的相应情况，根据这些信息就可以判断目标主机是否可以访问，在发送的过程中还会有一个时间戳用来计算网络的状态。
不过有些服务器为了防止通过ping探测到，可能会在防火墙或者内核参数中禁止ping命令，这样的话，可能虽然目标主机可以访问，但是无法ping通，所以并不能说ping不通的网络就是不能访问的。

需要注意linux下的ping和windows下的ping稍有区别,linux下ping不会自动终止,需要按ctrl+c终止或者用参数-c指定要求完成的回应次数。

语法ping的使用说实话挺复杂，挺多的，不过常用的这篇短文基本就够了。
详细如下：
# ALL$ ping  [-aAbBdDfhLnOqrRUvV46]  [-c  count]  [-F  flowlabel]  [-i  interval]  [-I interface] [-l preload] [-m mark] [-M pmtudisc_option] [-N node‐info_option] [-w deadline] [-W timeout] [-p pattern] [-Q tos] [-s packetsize] [-S sndbuf] [-t ttl] [-T timestamp option] [hop ...] destination# 较常用的选项如下：$ ping   [-c  count]   [-i  interval]  destination

参数说明：

-c &lt;完成次数&gt; 设置完成要求回应的次数。

-i interval 指定收发信息的间隔时间。


不加任何参数如果不加任何参数，查看是否ping通
$ ping www.baidu.com   PING www.a.shifen.com (115.239.210.27) 56(84) bytes of data.64 bytes from 115.239.210.27: icmp_seq=1 ttl=52 time=6.06 ms64 bytes from 115.239.210.27: icmp_seq=2 ttl=52 time=5.56 ms64 bytes from 115.239.210.27: icmp_seq=3 ttl=52 time=5.67 ms64 bytes from 115.239.210.27: icmp_seq=4 ttl=52 time=5.82 ms64 bytes from 115.239.210.27: icmp_seq=5 ttl=52 time=5.70 ms64 bytes from 115.239.210.27: icmp_seq=6 ttl=52 time=5.79 ms  ^C # 此处输入了Ctrl+C强制退出--- 192.168.1.123 ping statistics ---5 packets transmitted, 5 received, 0% packet loss, time 3999msrtt min/avg/max/mdev = 0.152/0.159/0.172/0.017 ms



可以看到可以ping通www.baidu.com，时延还算比较OK，几个毫秒量级。

这里看一下几个字段的含义，其中：
56(84) bytes of data：表示默认的数据包长度为56字节；
time=5.56ms：表示响应的时间，值越小，证明连接越快；
TTL=52：TTL是Time To Live的缩写，表示DNS记录在DNS服务器上存在的时间，是IP协议包的一个值，告诉路由器啥时候抛弃这个数据包，（大体上可以通过这个值来判断目标类型的操作系统。）

发送指定数目可以通过 参数-c 来发送指定数目的包后停止
$ ping www.baidu.com -c 5PING www.a.shifen.com (115.239.211.112) 56(84) bytes of data.64 bytes from 115.239.211.112: icmp_seq=1 ttl=52 time=6.03 ms64 bytes from 115.239.211.112: icmp_seq=2 ttl=52 time=5.96 ms64 bytes from 115.239.211.112: icmp_seq=3 ttl=52 time=5.79 ms64 bytes from 115.239.211.112: icmp_seq=4 ttl=52 time=5.79 ms64 bytes from 115.239.211.112: icmp_seq=5 ttl=52 time=6.21 ms--- www.a.shifen.com ping statistics ---5 packets transmitted, 5 received, 0% packet loss, time 4007msrtt min/avg/max/mdev = 5.791/5.958/6.215/0.186 ms



此时将在发送5次数据包以后自动停止，在Linux里面，如果不加这个参数，是会一直发送运行的。
设定发送时间间隔可以通过 参数 -i N指定每个N秒发送一次信息，如下将每隔3秒发送一次ping信息。
$ ping www.baidu.com -i 3PING www.a.shifen.com (14.215.177.38) 56(84) bytes of data.64 bytes from 14.215.177.38 (14.215.177.38): icmp_seq=1 ttl=55 time=28.6 ms64 bytes from 14.215.177.38 (14.215.177.38): icmp_seq=2 ttl=55 time=28.6 ms64 bytes from 14.215.177.38 (14.215.177.38): icmp_seq=3 ttl=55 time=28.6 ms64 bytes from 14.215.177.38 (14.215.177.38): icmp_seq=4 ttl=55 time=28.6 ms64 bytes from 14.215.177.38 (14.215.177.38): icmp_seq=5 ttl=55 time=28.6 ms64 bytes from 14.215.177.38 (14.215.177.38): icmp_seq=6 ttl=55 time=28.6 ms^C--- www.a.shifen.com ping statistics ---6 packets transmitted, 6 received, 0% packet loss, time 15041msrtt min/avg/max/mdev = 28.650/28.670/28.697/0.139 ms



如上，每隔3秒会发送一次，对于需要持续检测或者记录的可以考虑适当加大这个时间间隔。

注意，只有管理员可以设置小于0.2秒的时间间隔。所以这个数值可以是浮点数~

组合使用上面的几个例子是可以配合使用的，比如
$ ping www.baidu.com -c 4 -i 5 PING www.a.shifen.com (14.215.177.39) 56(84) bytes of data.64 bytes from 14.215.177.39 (14.215.177.39): icmp_seq=1 ttl=55 time=29.4 ms64 bytes from 14.215.177.39 (14.215.177.39): icmp_seq=2 ttl=55 time=29.3 ms64 bytes from 14.215.177.39 (14.215.177.39): icmp_seq=3 ttl=55 time=29.4 ms64 bytes from 14.215.177.39 (14.215.177.39): icmp_seq=4 ttl=55 time=29.4 ms--- www.a.shifen.com ping statistics ---5 packets transmitted, 5 received, 0% packet loss, time 20045msrtt min/avg/max/mdev = 29.396/29.428/29.461/0.110 ms

这个例子为：每个5秒查询一次，一共查询4次，然后退出。
]]></content>
      <categories>
        <category>Linux</category>
        <category>Linux入门</category>
        <category>网络</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>ping</tag>
      </tags>
  </entry>
  <entry>
    <title>pkg-config 自动解决依赖</title>
    <url>/2013/01/01/linux-pkg-config/</url>
    <content><![CDATA[简介pkg-config 主要解决软件库的依赖问题，特别是在不同的平台，安装的软件目录不同的情况下，可以很优雅地解决。这一切都是自动的，不用担心库文件放在什么地方。
pkg-config - Return metainformation about installed libraries

比如对于同样安装了gtk的系统而言，使用下来命令
pkg-config --libs --cflags gtk+-2.0

MacOSX输出为：
-D_REENTRANT -I/usr/local/Cellar/gtk+/2.24.31_1/include/gtk-2.0 -I/usr/local/Cellar/gtk+/2.24.31_1/lib/gtk-2.0/include -I/usr/local/Cellar/pango/1.40.14/include/pango-1.0 -I/usr/local/Cellar/harfbuzz/1.7.5/include/harfbuzz -I/usr/local/Cellar/graphite2/1.3.10/include -I/usr/local/Cellar/pango/1.40.14/include/pango-1.0 -I/usr/local/Cellar/atk/2.26.1/include/atk-1.0 -I/usr/local/Cellar/cairo/1.14.12/include/cairo -I/usr/local/Cellar/pixman/0.34.0_1/include/pixman-1 -I/usr/local/Cellar/fontconfig/2.12.6/include -I/usr/local/opt/freetype/include/freetype2 -I/usr/local/Cellar/libpng/1.6.34/include/libpng16 -I/usr/local/Cellar/gdk-pixbuf/2.36.11/include/gdk-pixbuf-2.0 -I/usr/local/Cellar/libpng/1.6.34/include/libpng16 -I/usr/local/Cellar/glib/2.54.3/include/glib-2.0 -I/usr/local/Cellar/glib/2.54.3/lib/glib-2.0/include -I/usr/local/opt/gettext/include -I/usr/local/Cellar/pcre/8.41/include -L/usr/local/Cellar/gtk+/2.24.31_1/lib -L/usr/local/Cellar/pango/1.40.14/lib -L/usr/local/Cellar/atk/2.26.1/lib -L/usr/local/Cellar/cairo/1.14.12/lib -L/usr/local/Cellar/gdk-pixbuf/2.36.11/lib -L/usr/local/Cellar/glib/2.54.3/lib -L/usr/local/opt/gettext/lib -lgtk-quartz-2.0 -lgdk-quartz-2.0 -lpangocairo-1.0 -lpango-1.0 -latk-1.0 -lcairo -lgdk_pixbuf-2.0 -lgio-2.0 -lgobject-2.0 -lglib-2.0 -lintl -Wl,-framework -Wl,CoreFoundation

CentOS输出为：
-pthread -I/usr/include/gtk-2.0 -I/usr/lib64/gtk-2.0/include -I/usr/include/atk-1.0 -I/usr/include/cairo -I/usr/include/gdk-pixbuf-2.0 -I/usr/include/pango-1.0 -I/usr/include/glib-2.0 -I/usr/lib64/glib-2.0/include -I/usr/include/harfbuzz -I/usr/include/freetype2 -I/usr/include/pixman-1 -I/usr/include/libpng15 -I/usr/include/libdrm  -lgtk-x11-2.0 -lgdk-x11-2.0 -latk-1.0 -lgio-2.0 -lpangoft2-1.0 -lpangocairo-1.0 -lgdk_pixbuf-2.0 -lcairo -lpango-1.0 -lfontconfig -lgobject-2.0 -lglib-2.0 -lfreetype

可以看出还是有很大差别的，所以对于下面的示例程序：
```编译的时候，直接使用下面的命令即可，而不用关注操作系统。
gcc -o test main.c pkg-config --libs --cflags gtk+-2.0


]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>gtk</tag>
        <tag>pkg-config</tag>
        <tag>libs</tag>
        <tag>cflags</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux的 pkill 命令</title>
    <url>/2016/11/20/linux-pkill-beginner/</url>
    <content><![CDATA[pkill 终止当前正在运行的程序参考 Linux pgrep 命令。
]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>pgrep</tag>
        <tag>pkill</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux poweroff 命令</title>
    <url>/2013/02/07/linux-poweroff-beginner/</url>
    <content><![CDATA[Linux poweroff 命令参考 Linux reboot 命令。
]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>shutdown</tag>
        <tag>poweroff</tag>
        <tag>halt</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux 权限设置</title>
    <url>/2017/05/06/linux-privilege/</url>
    <content><![CDATA[在linux下修改权限chmod g+r path/file 加读权限 当前目录chmod -R g+r path/file 加读权限 当前目录以及子目录g-r 减读权限g+w 加写权限g-wg+x 加执行权限g-x

chgrp修改文件所属组简单使用，将文本test.txt所属组改为gourp1
chgrp gourp1 test.txt

2.chown修改文件拥有者##将test.txt文件所属用户修改为user1
chown user1 test.txt

##同时修改test.txt的所属用户和所属组
chown user1:group1 test.txt

3.chmod修改文件属性
chmod 755 testchmod u+x testchmod u-x testchmod g+x test

4.usrmod修改用户所属组一般的话只是将当前用户添加到其它组中去
usrmod -a -G group1 user1

如果要彻底更改用户所属的组的话使用
usrmod -g group1 user1



使用Linux时，需要以一个用户的身份登陆，从而限制一个使用者能够访问的资源；而组则是用来方便组织管理用户。
用户与组•每个用户拥有一个UserID•每个用户属于一个主组，属于一个或多个附属组•每个组拥有一个GroupID•每个进程以一个用户身份运行，并受该用户可访问的资源限制•每个可登陆用户有一个指定的SHELL
系统中的文件都有一个所属用户及所属组，用户、组信息保存在以下三个文件中：
/etc/passwd   用户信息/etc/shadow  用户密码/edc/group 　组信息

命令id用以显示当前用户的信息，命令passwd可以修改当前用户的密码；以下命令可以显示登陆用户信息：
whoami   显示当前用户who       显示当前登陆的用户信息w          显示登陆用户的详细信息

命令usermod修改一个用户的信息：
usermod 参数　用户名-l 　修改用户名-u   修改uid-g   修改用户主组-G   修改用户附属组-L   锁定用户-U  解锁用户
命令userdel用户删除一个用户：
userdel　用户名userdel -l 用户名　删除用户的同时删除该用户家目录
命令groupadd、groupmod用以创建、修改一个组：groupadd 组名
groupmod -n 新组名　旧组名groupmod -g 新组ID　旧组ID
例如：
userdel -r sam此命令删除用户sam在系统文件（主要是/etc/passwd，/etc/shadow，/etc/group等）中的记录，同时删除用户的主目录。
删除一个组
同样的，我们有时会需要删除一个组，命令groupde用以删除一个组
Linux文件特殊权限：SUID、SGID和SBITSUID当s这个标志出现在 文件所有者的x权限上时，例如文件权限状态“-rwsr-xr-x”，此时就称为 Set UID，简称为SUID的特殊权限。SUID有这样的限制和功能：
（1）SUID权限仅对 二进制程序有效；
（2）执行者对于该程序需要 具有x的可执行权限；
（3）本权限仅在 执行该程序的过程中有效；
（4）执行者将具有该程序所有者的权限。
举个例子，在Linux中，所有账号的密码记录在/etc/shadow这个文件中，并且只有root可以读和强制写入这个文件。那么，如果另一个账号vbird需要修改自己的密码，就需要访问/etc/shadow这个文件，但是上面明明说了只有root能访问/etc/shadow这个文件，是不是矛盾？但事实上，vbird是可以修改/etc/shadow这个文件内的密码的，这就是SUID的功能。
通过上述的功能说明，我们知道，
（1）vbird对于/usr/bin/passwd这个程序具有x权限，表明vbird可以执行passwd；
（2）passwd的所有者为root；
（3）vbird执行passwd的过程中会暂时获得root的权限；
（4）/etc/shadow因此可以被vbird所执行的passwd所修改。
 但是vbird如果使用cat去读取/etc/shadow这个文件时，是不能读取的。
 
（SUID只能用在文件上，不能用在目录）
SGID当s标志出现在文件所有者的x权限时称为SUID，那么s出现在用户组的x权限时称为SGID。（U表示user，G表示group）。SGID有如下功能：
（1）SGID对二进制程序有用；
（2）程序执行者对该程序需具备x权限；
（3）执行者在执行过程中会获得该程序用户组的支持。
举个例子，/usr/bin/locate这个程序可以去查询/var/lib/mlocate/mlocate.db这个文件的内容，mlocate.db的权限如下：
-rwx–s–x root  slocate /usr/bin/locate
-rw-r—–  root slocate /var/lib/mlocate/mlocate.db
若使用vbird这个账号执行locate时，vbird就会获得用户组slocate支持，又由于用户组slocate对mlocate.db具有r权限，所以vbird就可以读取mlocate.db了。
 
除二进制程序外，SGID也可以用目录上。当一个目录设置了SGID权限后，它具有如下功能：
（1）用户若对此目录具有r和x权限，该用户能够进入该目录；
（2）用户在此目录下的有效用户组将变成该目录的用户组；
（3）若用户在此目录下拥有w权限，则用户所创建的新文件的用户组与该目录的用户组相同。
SBITSBIT目前只对目录有效。
SBIT对目录的作用是：
（1）当用户对此目录具有w和x权限时，即具有写入权限时；
（2）当用户在该目录下创建新文件或目录时，仅有自己和root才有权力删除。
SUID\SGID\SBIT权限设置先将其转换成数字：
SUID-&gt;4
SGID-&gt;2
SBIT-&gt;1
假设要将一个文件权限修改为“-rwsr-xr-x”，由于s在用户权限中，所以是SUID，因此，原先的755前面还要加上4，也就是4755，所以，
用命令chmod 4755 filename 设置就可以了。此外，还可能出现S和T的情况。
我们知道，s和t是替代x这个权限的，但是，如果它本身没有x这个权限，修改为s或t时就会变成大S或大T，例如：
执行chmod 7666 filename。 因为666表示“-rw-rw-rw”，均没有x权限，所以最后变成“-rwSrwSrwT”。
Linux中的特殊权限粘滞位(sticky bit)详解在linux下每一个文件和目录都有自己的访问权限，访问权限确定了用户能否访问文件或者目录和怎样进行访问。最为我们熟知的一个文件或目录可能拥有三种权限，分别是读、写、和执行操作。我们创建一个文件后系统会默认地赋予所有者读和写权限。当然我们也可以自己修改它，添加自己需要的权限。 
除了通用的这些权限，我们来说说在linux下的另一个特殊权限。首先我们来看看在根目录下的一个目录tmp，可以看到tmp目录的other权限是rwt，那么这里的t又是什么权限呢，有什么意义。 
t就是粘滞位（粘着位） 
上面所说的t权限就是我们在这里要讲的粘滞位(sticky bit),我们给刚刚的cur目录采用chmod o+t的方式给other用户设置粘滞位。 
可以看到此时我们是没有权限删除root用户创建的文件了，这也就是粘滞位的作用。 
粘滞位权限便是针对此种情况设置，当⽬录被设置了粘滞位权限以后，即便⽤户对该⽬录有写⼊权限，也不能删除该⽬录中其他⽤户的⽂件数据，⽽是只有该⽂件的所有者和root⽤户才有权将其删除。设置了粘滞位之后，正好可以保持⼀种动态的平衡：允许各⽤户在⽬录中任意写⼊、删除数据，但是禁⽌随意删除其他⽤户的数据。 
如果去掉了other的执行权限，可以看到本来’t’的位置变成了’T’，，那么原来的执行标志x到哪里去了呢? 系统是这样规定的, 假如本来在该位上有x, 则这些特别标志 (suid, sgid, sticky) 显示为小写字母 (s, s, t).否则, 显示为大写字母 (S, S, T) 。  

 粘滞位权限是针对目录的，对文件无效 

]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>usermod</tag>
        <tag>chgrp</tag>
        <tag>chmod</tag>
        <tag>chown</tag>
        <tag>whoami</tag>
        <tag>useradd</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux 进程和线程</title>
    <url>/2015/10/23/linux-process-threads/</url>
    <content><![CDATA[进程与线程进程　　我们都知道计算机的核心是CPU，它承担了所有的计算任务，而操作系统是计算机的管理者，它负责任务的调度，资源的分配和管理，
统领整个计算机硬件；应用程序是具有某种功能的程序，程序是运行于操作系统之上的。
　　进程是一个具有一定独立功能的程序在一个数据集上的一次动态执行的过程，是操作系统进行资源分配和调度的一个独立单位，是应用
程序运行的载体。进程是一种抽象的概念，从来没有统一的标准定义。进程一般由程序，数据集合和进程控制块三部分组成。程序用于描述
进程要完成的功能，是控制进程执行的指令集；数据集合是程序在执行时所需要的数据和工作区；程序控制块包含进程的描述信息和控制信息
是进程存在的唯一标志
进程具有的特征：
动态性：进程是程序的一次执行过程，是临时的，有生命期的，是动态产生，动态消亡的；
并发性：任何进程都可以同其他进行一起并发执行；
独立性：进程是系统进行资源分配和调度的一个独立单位；
结构性：进程由程序，数据和进程控制块三部分组成
线程　　在早期的操作系统中并没有线程的概念，进程是拥有资源和独立运行的最小单位，也是程序执行的最小单位。任务调度采用的是时间片
轮转的抢占式调度方式，而进程是任务调度的最小单位，每个进程有各自独立的一块内存，使得各个进程之间内存地址相互隔离。
　　后来，随着计算机的发展，对CPU的要求越来越高，进程之间的切换开销较大，已经无法满足越来越复杂的程序的要求了。于是就发明
了线程，线程是程序执行中一个单一的顺序控制流程，是程序执行流的最小单元，是处理器调度和分派的基本单位。一个进程可以有一个或
多个线程，各个线程之间共享程序的内存空间(也就是所在进程的内存空间)。一个标准的线程由线程ID，当前指令指针PC，寄存器和堆栈组
成。而进程由内存空间(代码，数据，进程空间，打开的文件)和一个或多个线程组成。
进程与线程的区别
线程是程序执行的最小单位，而进程是操作系统分配资源的最小单位；

一个进程由一个或多个线程组成，线程是一个进程中代码的不同执行路线

进程之间相互独立，但同一进程下的各个线程之间共享程序的内存空间(包括代码段，数据集，堆等)及一些进程级的资源(如打开文件和信


号等)，某进程内的线程在其他进程不可见；

调度和切换：线程上下文切换比进程上下文切换要快得多

线程和进程关系示意图
　　

　　总之，线程和进程都是一种抽象的概念，线程是一种比进程还小的抽象，线程和进程都可用于实现并发。
在早期的操作系统中并没有线程的概念，进程是能拥有资源和独立运行的最小单位，也是程序执行的最小单位，它相当于
一个进程里只有一个线程，进程本身就是线程。所以线程有时被称为轻量级进程
　　后来，随着计算机的发展，对多个任务之间上下文切换的效率要求越来越高，就抽象出一个更小的概念-线程，一般一个进程会有多个
(也可以是一个)线程。
 　
任务调度
　　大部分操作系统的任务调度是采用时间片轮转的抢占式调度方式，也就是说一个任务执行一小段时间后强制暂停去执行下一个任务，每个
任务轮流执行。任务执行的一小段时间叫做时间片，任务正在执行时的状态叫运行状态，任务执行一段时间后强制暂停去执行下一个任务，被
暂停的任务就处于就绪状态，等待下一个属于它的时间片的到来。这样每个任务都能得到执行，由于CPU的执行效率非常高，时间片
非常短，在各个任务之间快速地切换，给人的感觉就是多个任务在“同时进行”，这也就是我们所说的并发
　　　　
为何不使用多进程而是使用多线程？
　　　　线程廉价，线程启动比较快，退出比较快，对系统资源的冲击也比较小。而且线程彼此分享了大部分核心对象(File Handle)的拥有权
　　　　如果使用多重进程，但是不可预期，且测试困难
进程是资源分配的最小单位，线程是CPU调度的最小单位
线程和进程有什么区别？可以说是程序员必须准备的一道高频面试题。
相信不少程序员在面试算法或开发岗位时都遇到过这个问题。尽管这个问题似乎每个接触过计算机操作系统的人都应该懂，但是如何能回答好这个问题却十分考验程序员的水平。
为了能够给出一个全面而深入的答案，首先我们要理解线程的概念，以及为什么需要线程编程。
什么是线程呢？网上一般是这样定义的：线程（thread）是操作系统能够进行运算调度的最小单位，它被包含在进程之中，是进程中的实际运作单位。
这么说，你听懂了吗？我觉得这样的定义纯粹是自说自话：新手看完了一脸懵，老鸟看完了不以为然。我们还是用“非专业”的外行话来解释一下吧。

假设你经营着一家物业管理公司。最初，业务量很小，事事都需要你亲力亲为。给老张家修完暖气管道，立马再去老李家换电灯泡——这叫单线程，所有的工作都得顺序执行。
后来业务拓展了，你雇佣了几个工人，这样，你的物业公司就可以同时为多户人家提供服务了——这叫多线程，你是主线程。

工人们使用的工具，是物业管理公司提供的，这些工具由大家共享，并不专属于某一个人——这叫多线程资源共享。
工人们在工作中都需要管钳，可是管钳只有一把——这叫冲突。解决冲突的办法有很多，比如排队等候、等同事用完后的微信通知等——这叫线程同步。
你给工人布置任务——这叫创建线程。之后你还得要告诉他，可以开始了，不然他会一直停在那儿不动——这叫启动线程（start）。
如果某个工人（线程）的工作非常重要，你（主线程）也许会亲自监工一段时间，如果不指定时间，则表示你会一直监工到该项工作完成——这叫线程参与（join）。
业务不忙的时候，你就在办公室喝喝茶。下班时间一到，你群发微信，所有的工人不管手头的工作是否完成，都立马撂下工具，跟你走人。因此如果有必要，你得避免不要在工人正忙着的时候发下班的通知——这叫线程守护属性设置和管理（daemon）。
再后来，你的公司规模扩大了，同时为很多生活社区服务，你在每个生活社区设置了分公司，分公司由分公司经理管理，运营机制和你的总公司几乎一模一样——这叫多进程，总公司叫主进程，分公司叫子进程。
总公司和分公司，以及各个分公司之间，工具都是独立的，不能借用、混用——这叫进程间不能共享资源。各个分公司之间可以通过专线电话联系——这叫管道。各个分公司之间还可以通过公司公告栏交换信息——这叫进程间共享内存。另外，各个分公司之间还有各种协同手段，以便完成更大规模的作业——这叫进程间同步。分公司可以跟着总公司一起下班，也可以把当天的工作全部做完之后再下班——这叫守护进程设置。
进程有什么用？进程可以说是一个“执行中的程序”。程序是指令、数据及其组织形式的描述，是一个没有生命的实体，只有处理器赋予程序生命时（操作系统执行之），它才能成为一个活动的实体，我们称其为进程。
有了线程技术，我们就可以在一个进程中创建多个线程，让它们在“同一时刻”分别去做不同的工作了。这些线程共享同一块内存，线程之间可以共享对象、资源，如果有冲突或需要协同，还可以随时沟通以解决冲突或保持同步。

不过，多线程技术不是万金油，它有一个致命的缺点：在一个进程内，不管你创建了多少线程，它们总是被限定在一颗CPU内，或者多核CPU的一个核内。这意味着，多线程在宏观上是并行的，在微观上则是分时切换串行的，多线程编程无法充分发挥多核计算资源的优势。这也是使用多线程做任务并行处理时，线程数量超过一定数值后，线程越多速度反倒越慢的原因。

多进程技术正好弥补了多线程编程的不足，我们可以在每一颗CPU上，或者多核CPU的每一个核上启动一个进程，如果有必要，还可以在每个进程内再创建适量的线程，最大限度地使用计算资源解决问题。因为不在同一块内存区域内，和线程相比，进程间的资源共享、通信、同步等，都要麻烦得多，受到的限制也更多。
协程子程序调用总是一个入口，一次返回，调用顺序是明确的。而协程的调用和子程序不同。
协程看上去也是子程序，但执行过程中，在子程序内部可中断，然后转而执行别的子程序，在适当的时候再返回来接着执行。
多进程要让Python程序实现多进程（multiprocessing），我们先了解操作系统的相关知识。
Unix/Linux操作系统提供了一个fork()系统调用，它非常特殊。普通的函数调用，调用一次，返回一次，但是fork()调用一次，返回两次，因为操作系统自动把当前进程（称为父进程）复制了一份（称为子进程），然后，分别在父进程和子进程内返回。
子进程永远返回0，而父进程返回子进程的ID。这样做的理由是，一个父进程可以fork出很多子进程，所以，父进程要记下每个子进程的ID，而子进程只需要调用getppid()就可以拿到父进程的ID。
Python的os模块封装了常见的系统调用，其中就包括fork，可以在Python程序中轻松创建子进程：
# multiprocessing.pyimport osprint 'Process (%s) start...' % os.getpid()pid = os.fork()if pid==0:    print 'I am child process (%s) and my parent is %s.' % (os.getpid(), os.getppid())else:    print 'I (%s) just created a child process (%s).' % (os.getpid(), pid)

运行结果如下：
Process (876) start...I (876) just created a child process (877).I am child process (877) and my parent is 876.

由于Windows没有fork调用，上面的代码在Windows上无法运行。由于Mac系统是基于BSD（Unix的一种）内核，所以，在Mac下运行是没有问题的，推荐大家用Mac学Python！
有了fork调用，一个进程在接到新任务时就可以复制出一个子进程来处理新任务，常见的Apache服务器就是由父进程监听端口，每当有新的http请求时，就fork出子进程来处理新的http请求。
multiprocessing如果你打算编写多进程的服务程序，Unix/Linux无疑是正确的选择。由于Windows没有fork调用，难道在Windows上无法用Python编写多进程的程序？
由于Python是跨平台的，自然也应该提供一个跨平台的多进程支持。multiprocessing模块就是跨平台版本的多进程模块。
multiprocessing模块提供了一个Process类来代表一个进程对象，下面的例子演示了启动一个子进程并等待其结束：
from multiprocessing import Processimport os# 子进程要执行的代码def run_proc(name):    print 'Run child process %s (%s)...' % (name, os.getpid())if __name__=='__main__':    print 'Parent process %s.' % os.getpid()    p = Process(target=run_proc, args=('test',))    print 'Process will start.'    p.start()    p.join()    print 'Process end.'

执行结果如下：
Parent process 928.Process will start.Run child process test (929)...Process end.

创建子进程时，只需要传入一个执行函数和函数的参数，创建一个Process实例，用start()方法启动，这样创建进程比fork()还要简单。
join()方法可以等待子进程结束后再继续往下运行，通常用于进程间的同步。
Pool如果要启动大量的子进程，可以用进程池的方式批量创建子进程：
from multiprocessing import Poolimport os, time, randomdef long_time_task(name):    print 'Run task %s (%s)...' % (name, os.getpid())    start = time.time()    time.sleep(random.random() * 3)    end = time.time()    print 'Task %s runs %0.2f seconds.' % (name, (end - start))if __name__=='__main__':    print 'Parent process %s.' % os.getpid()    p = Pool()    for i in range(5):        p.apply_async(long_time_task, args=(i,))    print 'Waiting for all subprocesses done...'    p.close()    p.join()    print 'All subprocesses done.'

执行结果如下：
Parent process 669.Waiting for all subprocesses done...Run task 0 (671)...Run task 1 (672)...Run task 2 (673)...Run task 3 (674)...Task 2 runs 0.14 seconds.Run task 4 (673)...Task 1 runs 0.27 seconds.Task 3 runs 0.86 seconds.Task 0 runs 1.41 seconds.Task 4 runs 1.91 seconds.All subprocesses done.

代码解读：
对Pool对象调用join()方法会等待所有子进程执行完毕，调用join()之前必须先调用close()，调用close()之后就不能继续添加新的Process了。
请注意输出的结果，task 0，1，2，3是立刻执行的，而task 4要等待前面某个task完成后才执行，这是因为Pool的默认大小在我的电脑上是4，因此，最多同时执行4个进程。这是Pool有意设计的限制，并不是操作系统的限制。如果改成：
p = Pool(5)

就可以同时跑5个进程。
由于Pool的默认大小是CPU的核数，如果你不幸拥有8核CPU，你要提交至少9个子进程才能看到上面的等待效果。
进程间通信Process之间肯定是需要通信的，操作系统提供了很多机制来实现进程间的通信。Python的multiprocessing模块包装了底层的机制，提供了Queue、Pipes等多种方式来交换数据。
我们以Queue为例，在父进程中创建两个子进程，一个往Queue里写数据，一个从Queue里读数据：
from multiprocessing import Process, Queueimport os, time, random# 写数据进程执行的代码:def write(q):    for value in ['A', 'B', 'C']:        print 'Put %s to queue...' % value        q.put(value)        time.sleep(random.random())# 读数据进程执行的代码:def read(q):    while True:        value = q.get(True)        print 'Get %s from queue.' % valueif __name__=='__main__':    # 父进程创建Queue，并传给各个子进程：    q = Queue()    pw = Process(target=write, args=(q,))    pr = Process(target=read, args=(q,))    # 启动子进程pw，写入:    pw.start()    # 启动子进程pr，读取:    pr.start()    # 等待pw结束:    pw.join()    # pr进程里是死循环，无法等待其结束，只能强行终止:    pr.terminate()

运行结果如下：
Put A to queue...Get A from queue.Put B to queue...Get B from queue.Put C to queue...Get C from queue.

在Unix/Linux下，multiprocessing模块封装了fork()调用，使我们不需要关注fork()的细节。由于Windows没有fork调用，因此，multiprocessing需要“模拟”出fork的效果，父进程所有Python对象都必须通过pickle序列化再传到子进程去，所有，如果multiprocessing在Windows下调用失败了，要先考虑是不是pickle失败了。
小结在Unix/Linux下，可以使用fork()调用实现多进程。
要实现跨平台的多进程，可以使用multiprocessing模块。
进程间通信是通过Queue、Pipes等实现的。
多线程多任务可以由多进程完成，也可以由一个进程内的多线程完成。
我们前面提到了进程是由若干线程组成的，一个进程至少有一个线程。
由于线程是操作系统直接支持的执行单元，因此，高级语言通常都内置多线程的支持，Python也不例外，并且，Python的线程是真正的Posix Thread，而不是模拟出来的线程。
Python的标准库提供了两个模块：thread和threading，thread是低级模块，threading是高级模块，对thread进行了封装。绝大多数情况下，我们只需要使用threading这个高级模块。
启动一个线程就是把一个函数传入并创建Thread实例，然后调用start()开始执行：
import time, threading# 新线程执行的代码:def loop():    print 'thread %s is running...' % threading.current_thread().name    n = 0    while n &lt; 5:        n = n + 1        print 'thread %s &gt;&gt;&gt; %s' % (threading.current_thread().name, n)        time.sleep(1)    print 'thread %s ended.' % threading.current_thread().nameprint 'thread %s is running...' % threading.current_thread().namet = threading.Thread(target=loop, name='LoopThread')t.start()t.join()print 'thread %s ended.' % threading.current_thread().name

执行结果如下：
thread MainThread is running...thread LoopThread is running...thread LoopThread &gt;&gt;&gt; 1thread LoopThread &gt;&gt;&gt; 2thread LoopThread &gt;&gt;&gt; 3thread LoopThread &gt;&gt;&gt; 4thread LoopThread &gt;&gt;&gt; 5thread LoopThread ended.thread MainThread ended.

由于任何进程默认就会启动一个线程，我们把该线程称为主线程，主线程又可以启动新的线程，Python的threading模块有个current_thread()函数，它永远返回当前线程的实例。主线程实例的名字叫MainThread，子线程的名字在创建时指定，我们用LoopThread命名子线程。名字仅仅在打印时用来显示，完全没有其他意义，如果不起名字Python就自动给线程命名为Thread-1，Thread-2……
Lock多线程和多进程最大的不同在于，多进程中，同一个变量，各自有一份拷贝存在于每个进程中，互不影响，而多线程中，所有变量都由所有线程共享，所以，任何一个变量都可以被任何一个线程修改，因此，线程之间共享数据最大的危险在于多个线程同时改一个变量，把内容给改乱了。
来看看多个线程同时操作一个变量怎么把内容给改乱了：
import time, threading# 假定这是你的银行存款:balance = 0def change_it(n):    # 先存后取，结果应该为0:    global balance    balance = balance + n    balance = balance - ndef run_thread(n):    for i in range(100000):        change_it(n)t1 = threading.Thread(target=run_thread, args=(5,))t2 = threading.Thread(target=run_thread, args=(8,))t1.start()t2.start()t1.join()t2.join()print balance

我们定义了一个共享变量balance，初始值为0，并且启动两个线程，先存后取，理论上结果应该为0，但是，由于线程的调度是由操作系统决定的，当t1、t2交替执行时，只要循环次数足够多，balance的结果就不一定是0了。
原因是因为高级语言的一条语句在CPU执行时是若干条语句，即使一个简单的计算：
balance = balance + n

也分两步：

计算balance + n，存入临时变量中；
将临时变量的值赋给balance。

也就是可以看成：
x = balance + nbalance = x

由于x是局部变量，两个线程各自都有自己的x，当代码正常执行时：
初始值 balance = 0t1: x1 = balance + 5 # x1 = 0 + 5 = 5t1: balance = x1     # balance = 5t1: x1 = balance - 5 # x1 = 5 - 5 = 0t1: balance = x1     # balance = 0t2: x2 = balance + 8 # x2 = 0 + 8 = 8t2: balance = x2     # balance = 8t2: x2 = balance - 8 # x2 = 8 - 8 = 0t2: balance = x2     # balance = 0结果 balance = 0

但是t1和t2是交替运行的，如果操作系统以下面的顺序执行t1、t2：
初始值 balance = 0t1: x1 = balance + 5  # x1 = 0 + 5 = 5t2: x2 = balance + 8  # x2 = 0 + 8 = 8t2: balance = x2      # balance = 8t1: balance = x1      # balance = 5t1: x1 = balance - 5  # x1 = 5 - 5 = 0t1: balance = x1      # balance = 0t2: x2 = balance - 5  # x2 = 0 - 5 = -5t2: balance = x2      # balance = -5结果 balance = -5

究其原因，是因为修改balance需要多条语句，而执行这几条语句时，线程可能中断，从而导致多个线程把同一个对象的内容改乱了。
两个线程同时一存一取，就可能导致余额不对，你肯定不希望你的银行存款莫名其妙地变成了负数，所以，我们必须确保一个线程在修改balance的时候，别的线程一定不能改。
如果我们要确保balance计算正确，就要给change_it()上一把锁，当某个线程开始执行change_it()时，我们说，该线程因为获得了锁，因此其他线程不能同时执行change_it()，只能等待，直到锁被释放后，获得该锁以后才能改。由于锁只有一个，无论多少线程，同一时刻最多只有一个线程持有该锁，所以，不会造成修改的冲突。创建一个锁就是通过threading.Lock()来实现：
balance = 0lock = threading.Lock()def run_thread(n):    for i in range(100000):        # 先要获取锁:        lock.acquire()        try:            # 放心地改吧:            change_it(n)        finally:            # 改完了一定要释放锁:            lock.release()

当多个线程同时执行lock.acquire()时，只有一个线程能成功地获取锁，然后继续执行代码，其他线程就继续等待直到获得锁为止。
获得锁的线程用完后一定要释放锁，否则那些苦苦等待锁的线程将永远等待下去，成为死线程。所以我们用try...finally来确保锁一定会被释放。
锁的好处就是确保了某段关键代码只能由一个线程从头到尾完整地执行，坏处当然也很多，首先是阻止了多线程并发执行，包含锁的某段代码实际上只能以单线程模式执行，效率就大大地下降了。其次，由于可以存在多个锁，不同的线程持有不同的锁，并试图获取对方持有的锁时，可能会造成死锁，导致多个线程全部挂起，既不能执行，也无法结束，只能靠操作系统强制终止。
多核CPU如果你不幸拥有一个多核CPU，你肯定在想，多核应该可以同时执行多个线程。
如果写一个死循环的话，会出现什么情况呢？
打开Mac OS X的Activity Monitor，或者Windows的Task Manager，都可以监控某个进程的CPU使用率。
我们可以监控到一个死循环线程会100%占用一个CPU。
如果有两个死循环线程，在多核CPU中，可以监控到会占用200%的CPU，也就是占用两个CPU核心。
要想把N核CPU的核心全部跑满，就必须启动N个死循环线程。
试试用Python写个死循环：
import threading, multiprocessingdef loop():    x = 0    while True:        x = x ^ 1for i in range(multiprocessing.cpu_count()):    t = threading.Thread(target=loop)    t.start()

启动与CPU核心数量相同的N个线程，在4核CPU上可以监控到CPU占用率仅有160%，也就是使用不到两核。
即使启动100个线程，使用率也就170%左右，仍然不到两核。
但是用C、C++或Java来改写相同的死循环，直接可以把全部核心跑满，4核就跑到400%，8核就跑到800%，为什么Python不行呢？
因为Python的线程虽然是真正的线程，但解释器执行代码时，有一个GIL锁：Global Interpreter Lock，任何Python线程执行前，必须先获得GIL锁，然后，每执行100条字节码，解释器就自动释放GIL锁，让别的线程有机会执行。这个GIL全局锁实际上把所有线程的执行代码都给上了锁，所以，多线程在Python中只能交替执行，即使100个线程跑在100核CPU上，也只能用到1个核。
GIL是Python解释器设计的历史遗留问题，通常我们用的解释器是官方实现的CPython，要真正利用多核，除非重写一个不带GIL的解释器。
所以，在Python中，可以使用多线程，但不要指望能有效利用多核。如果一定要通过多线程利用多核，那只能通过C扩展来实现，不过这样就失去了Python简单易用的特点。
不过，也不用过于担心，Python虽然不能利用多线程实现多核任务，但可以通过多进程实现多核任务。多个Python进程有各自独立的GIL锁，互不影响。
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>aio</tag>
        <tag>aio_read</tag>
        <tag>aio_write</tag>
      </tags>
  </entry>
  <entry>
    <title>显示进程状态 ps</title>
    <url>/2015/07/28/linux-ps-beginner/</url>
    <content><![CDATA[显示进程状态 psps命令是“process status”的缩写，类似于 windows 的任务管理器ps命令用于显示当前系统的进程状态。通常搭配kill指令随时中断、删除不必要的程序。
同时呢，ps命令是非常强大的进程查看命令，可以确定有哪些进程正在运行和运行的状态、进程是否结束、进程有没有僵死、哪些进程占用了过多的资源等等，总之大部分【Windows】任务管理器的信息都是可以通过执行该命令得到的。
语法$ ps [参数]

常用参数

-A 列出所有的行程
-w 显示加宽可以显示较多的资讯
-au显示较详细的资讯
-aux显示所有包含其他使用者的行程

其中aux的输出信息如下所示：
USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND


USER: 行程拥有者
PID: pid
%CPU: 占用的 CPU 使用率
%MEM: 占用的内存使用率
VSZ: 占用的虚拟内存大小
RSS: 占用的内存大小
TTY: 终端的minor装置号码
STAT: 该行程的状态:
D: 无法中断的休眠状态 (通常 IO 的进程)
R: 正在执行中
S: 静止状态
T: 暂停执行
Z: 不存在但暂时无法消除
W: 没有足够的内存分页可分配
&lt;: 高优先序的行程
N: 低优先序的行程
L: 有内存分页分配并锁在内存内 (实时系统或捱A I/O)


START: 行程开始时间
TIME: 执行的时间
COMMAND:所执行的指令

几个实例默认情况$ ps  PID TTY          TIME CMD44965 pts/0    00:00:00 bash56519 pts/0    00:00:00 ps

什么参数都不跟的话，基本输出没啥用处。
显示所有进程通常情况下，最常用的为把所有进程显示出来：
$ ps -aux$ ps -A    

把所有进程显示出来，并输出到ps.txt文件：
$ ps -aux &gt; ps.txt

查找特定进程信息大部分情况下，希望查找有问题的进程或者感兴趣的进程，使用管道如下：
$ ps -aux | grep sshroot       1303  0.0  0.0  82468  1204 ?        Ss   Apr17   0:00 /usr/sbin/sshdroot       3260  0.0  0.0  52864   572 ?        Ss   Apr17   0:00 /usr/bin/ssh-agent /bin/sh -c exec -l /bin/bash -c "env GNOME_SHELL_SESSION_MODE=classic gnome-session --session gnome-classic"root      24188  0.0  0.0 112652   956 pts/0    S+   11:39   0:00 grep --color=auto ssh

]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>kill</tag>
        <tag>系统管理</tag>
        <tag>ps</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux PS1参数</title>
    <url>/2011/03/23/linux-ps1/</url>
    <content><![CDATA[PS1默认提示符可以通过修改Linux下的默认提示符，使其更加实用。
默认的PS1的值是“\s-\v$”,显示出了shell的名称的版本。我们通过修改，可以使其显示用户名、主机名和当前工作目录。  export PS1=”\u@\h \w&gt;”
PS1使用的一些代码如下：

\u — 用户名
\h — 主机名
\w — 当前目录的完整路径。

请注意当你在主目录下的时候，如上面所示只会显示～ 注意，在PS1值之后有一个空格。从个人角度来讲，使用这个空格可以增加一定的可读性。
将export PS1=”\u@\h \w&gt;” 添加到.bash_profile 或者 .bashrc中，则可以保证其永久有效。
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>bashrc</tag>
        <tag>export</tag>
        <tag>PS1</tag>
        <tag>bash_profile</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux的 pstree 命令</title>
    <url>/2015/04/07/linux-pstree-beginner/</url>
    <content><![CDATA[Linux pstree命令Linux pstree命令是processes tree的简称，用于将所有的进行以树状图进行显示。
可以说是结合了ps和tree两个命令。
官方定义为：

pstree - display a tree of processes

使用方法为：
$ pstree [-a, --arguments] [-c, --compact-not] [-C, --color attr] [-g, --show-pgids] [-h, --highlight-all, -Hpid, --high‐light-pid pid] [-l, --long] [-n, --numeric-sort] [-N, --ns-sort ns] [-p, --show-pids] [-s, --show-parents] [-S, --ns-changes] [-t, --thread-names] [-T, --hide-threads] [-u, --uid-changes] [-Z, --security-context] [-A, --ascii, -G, --vt100, -U, --uni‐code] [pid, user]  



参数比较多，也比较复杂。其中常用的选项为：

-a 显示整个命令的完整路径。
-G 有时可以使用这个选项，输出好看一些。

实例 默认显示默认显示当前的进程：
$ pstree   systemd─┬─SIMU.EXE───STARTPMON        ├─NetworkManager───2*[{NetworkManager}]        ├─abrt-dbus───3*[{abrt-dbus}]        ├─2*[abrt-watch-log]        ├─abrtd        ├─accounts-daemon───2*[{accounts-daemon}]        ├─agetty        ├─10*[at-spi-bus-laun─┬─dbus-daemon]        │                     └─3*[{at-spi-bus-laun}]]        ├─10*[at-spi2-registr───2*[{at-spi2-registr}]]        ├─atd        ├─auditd─┬─audispd─┬─sedispatch        │        │         └─{audispd}        │        └─{auditd}        ├─avahi-daemon───avahi-daemon        ├─boltd───2*[{boltd}]        ├─chrome─┬─2*[cat]        │        ├─chrome───chrome─┬─chrome        │        │                 └─5*[{chrome}]        │        ├─chrome───8*[{chrome}]        │        ├─chrome-sandbox───chrome─┬─chrome─┬─chrome───4*[{chrome}]        │        │                         │        └─2*[chrome───12*[{chrome}]+        │        │                         └─chrome-sandbox───nacl_helper        │        └─21*[{chrome}]        ├─chronyd        ├─colord───2*[{colord}]        ├─crashpad_handle───2*[{crashpad_handle}]        ├─crond        ├─cupsd        ├─11*[dbus-daemon]        ├─10*[dbus-launch]        ├─10*[dconf-service───2*[{dconf-service}]]        ├─dnsmasq───dnsmasq...



显示完成路径使用-a参数可以看到各个进程的详细信息
$ pstree -a...  |-at-spi-bus-laun  |   |-dbus-daemon --config-file=/usr/share/defaults/at-spi2/accessibility.conf --nofork --print-address 3  |   `-3*[{at-spi-bus-laun}]  |-at-spi-bus-laun  |   |-dbus-daemon --config-file=/usr/share/defaults/at-spi2/accessibility.conf --nofork --print-address 3  |   `-3*[{at-spi-bus-laun}]...

]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>pstree</tag>
      </tags>
  </entry>
  <entry>
    <title>查看目录命令pwd</title>
    <url>/2012/01/15/linux-pwd-beginner/</url>
    <content><![CDATA[查看目录命令pwdpwd命令的作用是查看当前目录，没有参数，输入后回车即可显示当前绝对路径。
官方定义为：

pwd - print name of current/working directory

 所以pwd是Print Working  Directory第一个字的缩写。
唯二需要了解的参数如下：

-L, --logical：打印逻辑路径，与pwd一致
-P, --physical：打印物理路径，这里可以从超级链接直达原处

实例展示此时比如我们进入一个目录，然后在打印出来，如下：
$ cd /etc/sysconfig/network-scripts/$ pwd/etc/sysconfig/network-scripts


可以看到pwd将输出完全路径

逻辑与物理路径比如如下：
$ pwd/opt/test$ ls -l总用量 1lrwxrwxrwx  1 root root   14 Jan 15 2012 dir -&gt; source/dirdrwxrwxrwx  1 root root   14 Jan 15 2012 source

可以看到此时的路径在/opt/test/里面有两个目录source和dir，其中dir链接到source里面的dir。
接下来对比一下-L和-P的区别。
$ cd dir$ pwd/opt/test/dir$ pwd -L/opt/test/dir$ pwd -P/opt/test/source/dir



从上面的输出可以发现，-P参数会显示文件最原始的路径；而-L则是逻辑上的路径。
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>pwd</tag>
        <tag>目录导航</tag>
        <tag>linux入门</tag>
      </tags>
  </entry>
  <entry>
    <title>linux 命令 pwd 查看目录命令</title>
    <url>/2012/01/15/linux-pwd/</url>
    <content><![CDATA[查看目录命令pwdpwd命令的作用是查看当前目录，没有参数，输入后回车即可显示当前绝对路径。
官方定义为：

pwd - print name of current/working directory

 所有pwd是Print Working  Directory第一个字的缩写。
唯二需要了解的参数如下：

-L, --logical：打印逻辑路径，与pwd一致
-P, --physical：打印物理路径，这里可以从超级链接直达原处

实例展示此时比如我们进入一个目录，然后在打印出来，如下：
$ cd /etc/sysconfig/network-scripts/$ pwd/etc/sysconfig/network-scripts


可以看到pwd将输出完全路径

逻辑与物理路径比如如下：
$ pwd/opt/test$ ls -l总用量 1lrwxrwxrwx  1 root root   14 Jan 15 2012 dir -&gt; source/dirdrwxrwxrwx  1 root root   14 Jan 15 2012 source

可以看到此时的路径在/opt/test/里面有两个目录source和dir，其中dir链接到source里面的dir。
接下来对比一下-L和-P的区别。
$ cd dir$ pwd/opt/test/dir$ pwd -L/opt/test/dir$ pwd -P/opt/test/source/dir



从上面的输出可以发现，-P参数会显示文件最原始的路径；而-L则是逻辑上的路径。
]]></content>
      <categories>
        <category>Linux</category>
        <category>Linux入门</category>
        <category>目录导航</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>pwd</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux的 RAID 冗余磁盘阵列</title>
    <url>/2011/12/28/linux-raid/</url>
    <content><![CDATA[RAID 冗余磁盘阵列RAID就是廉价冗余磁盘阵列，比LVM简单多了 ，常用的级别是： 

RAID0 提高读写速度
RAID1 数据安全考虑
RAID5 存储性能、数据安全和存储成本兼顾

RAID 0又称为Stripe或Striping，中文译为集带工作方式。它是将要存取的数据以条带状形式尽量平均分配到多个硬盘上，读写时多个硬盘同时进行读写，从而提高数据的读写速度。RAID 0另一目的是获得更大的“单个”磁盘容量从而提高数据的读写速度。这是他的优点，我觉得最重要是提高读写速度 
RAID 1又称为Mirror或Mirroring，中文译为镜像方式。这种工作方式的出现完全是为了数据安全考虑的，它是把用户写入硬盘的数据百分之百地自动复制到另外一个硬盘上或硬盘的不同地方（镜像）。当读取数据时，系统先从RAID 1的源盘读取数据，如果读取数据成功，则系统不去管备份盘上的数据；如果读取源盘数据失败，则系统自动转而读取备份盘上的数据，不会造成用户工作任务的中 断。由于对存储的数据进行百分之百的备份，在所有RAID级别中，RAID 1提供最高的数据安全保障。同样，由于数据的百分之百备份，备份数据占了总存储空间的一半，因而，Mirror的磁盘空间利用率低，存储成本高。 
RAID 5是一种存储性能、数据安全和存储成本兼顾的存储解决方案，也是目前应用最广泛的RAID技术。各块独立硬盘进行条带化分割，相同的条带区进行奇偶校验 （异或运算），校验数据平均分布在每块硬盘上。以n块硬盘构建的RAID 5阵列可以有2/3块硬盘的容量，存储空间利用率非常高。RAID 5不对存储的数据进行备份，而是把数据和相对应的奇偶校验信息存储到组成RAID5的各个磁盘上，并且奇偶校验信息和相对应的数据分别存储于不同的磁盘 上。当RAID 5的任何一块硬盘上的数据丢失，均可以通过校验数据推算出来 
具体算法就让学存储的技术搞吧，我们知道RAID5有这个功能就行了 
RAID分为软RAID和硬件RAID软件RAID是基于系统的软件工作 优点：廉价 缺点：不稳定，如果系统坏了，RAID整列也就损坏，容易造成数据丢失 
硬件RAID，这就是各大厂商提供的，存储解决方案。有专门的设备负责处理磁盘间的数据流。 相对于软件RAID 优点：可靠性高，易管理。稳定 缺点：成本过高 
基于LINUX系统的软件RAID在LINUX下管理RAID阵列的工具是mdadm工具 
mdadm程序是一个独立的程序，能完成所有的软RAID管理功能
主要有7种使用模式： 
Create 使用空闲的设备创建一个新的阵列，每个设备具有元数据块
Assemble 将原来属于一个阵列的每个块设备组装为阵列
Build 创建或组装不需要元数据的阵列，每个设备没有元数据块
Manage 管理已经存储阵列中的设备，比如增加热备磁盘或者设置某个磁盘失效，然后从阵列中删除这个磁盘
Misc 报告或者修改阵列中相关设备的信息，比如查询阵列或者设备的状态信息
Grow 改变阵列中每个设备被使用的容量或阵列中的设备的数目
Monitor 监控一个或多个阵列，上报指定的事件 
由于这个工具太强大，不能一一为大家讲解 
题目：建立一个RAID5 级别的分区使用一个分区给这个RAID做热备份，并挂在到本地的/mnt/raid 目录， 
第一步创建物理分区因为RAID5至少需要3个或者更多的硬盘，我们就要分3个分区，然后再加一个热备份的分区，就是4个分区 
$ fdisk /dev/sda$ fdisk -l    $ fdisk /dev/sda   $ partprobe     $partprobe  


我们还是要使用#partprobe 使分区马上生效 
第二步：创建阵列设备系统默认有个md0可以给我们用，如果我要多个raid的话，就需要自己创建设备了，所以在这里我教大家怎么创建raid设备 
#mknod /dev/md1 b 9 1 
创建md1这个raid设备 
mknod是命令
/dev/md1 是设备名字，设备必须是/dev/md开始的
后面的b代表创建的是块设备 
9是主设备号，1代表从设备号 
主设备号不能改，从设备号在系统内唯一 
创建好以后，可以使用ls /dev/md1 看看有没有这个设备了 
第三步：创建RAID阵列使用MDADM工具 
#mdadm -C /dev/md1 -l 5 -n 3 -x 1 /dev/sda7 /dev/sda8 /dev/sda9 /dev/sda10 
OK以后，可以使用命令 #mdadm –detail /dev/md1 查看RAID状态
  [root@rhel5 ~]# mdadm -C /dev/md1 -l 5 -n 3 -x 1  /dev/sda7 /dev/sda8 /dev/sda9 /dev/sda10      
[root@rhel5 ~]# mdadm –detail /dev/md1   
[root@rhel5 ~]# mdadm -C /dev/md1 -l 5 -n 3 -x 1 /dev/sda7 /dev/sda8 /dev/sda9 /dev/sda10
-C 代表创建 
-l 代表创建的级别 
-n 代表活动的分区，也就是你要给这个级别多少个分区 
-x 就是热备份的分区 
后面就跟设备就OK了 
软RAID就可以使用分区来替代硬盘，如果你有真实的硬盘，这里也可以跟上硬盘 
第四步：格式化raid设备#mkfs.ext3 /dev/md1 
第五步：创建目录并挂载#mkdir /mnt/raid #mount -t ext3 /dev/md1 /mnt/raid 
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>RAID</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux reboot/poweroff/halt 命令</title>
    <url>/2013/02/07/linux-reboot-beginner/</url>
    <content><![CDATA[Linux reboot/poweroff/halt 命令.. _linux_reboot_beginner:
.. note::
  世事漫随流水，算来一梦浮生。

李煜《乌夜啼·昨夜风兼雨》

Linux halt, poweroff, reboot 用来挂起、关机或者重启机器，成功后返回0。
这不是一个命令，这是三个命令，只不过三个命令的参数都是一致的。
官方定义为：

halt, poweroff, reboot - Halt, power-off or reboot the machine

其实这三个命令都可以通过shutdown来执行，并且相对而言shutdown的参数还更多一些。
语法使用方法如下：
$ halt [OPTIONS...]$ poweroff [OPTIONS...]    $ reboot [OPTIONS...]



参数如下所示：

--halt 将机器挂起，三个命令均相同
-p, --poweroff  将机器关机，三个命令均相同
--reboot  将机器重启，三个命令均相同
-f, --force 立即执行挂起、关机和重启，一般对于force而言，除非万不得已，否则进来莫用
-n, --no-sync 在挂起、关机或重启前不对硬盘进行同步，这个很危险呀，进来不要用呀
--no-wall 在挂起、关机或重启前不发送警告信息，对于多用户不友好

立即关机接下来的三个命令一致，都是将电脑关机，不过这个用法总归感觉怪怪的，所以还是分开各司其职比较好。比如关机还是poweroff，重启还是reboot吧。
$ halt --poweroff$ poweroff --poweroff$ reboot --poweroff





​      
]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>shutdown</tag>
        <tag>poweroff</tag>
        <tag>halt</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux Redhat配置网络</title>
    <url>/2013/01/15/linux-redhat-configure-network/</url>
    <content><![CDATA[IF you can not find the network configure.
May be you should TYPE:
system-config-network

to setting IP info.
]]></content>
      <categories>
        <category>Linux</category>
        <category>Redhat</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>network</tag>
        <tag>system-config-network</tag>
      </tags>
  </entry>
  <entry>
    <title>一去不复还的rm 命令</title>
    <url>/2011/02/12/linux-rm-beginner/</url>
    <content><![CDATA[一去不复还的 rm.. note::  风萧萧兮易水寒，壮士一去兮不复还。  先秦-荆轲《易水歌》
如果Linux命令按照危险性来个排行榜，rm绝对一骑绝尘，名列第一。
因为发生过太多太多无奈、无辜、无法挽回的事情。
所谓风萧萧兮易水寒，壮士一去兮不复还，还得是rm命令
rm 命令用于删除文件或者目录。官方定义为：

remove files or directories

语法$ rm [options] name...

参数：

-i 删除前逐一询问确认，确认时比较好用。
-f 即使原档案属性设为唯读，也直接删除，无需逐一确认，是force的意思。
-r 将目录及里面的子文件逐一删除。

几个示例删除文件可以直接使用rm命令，若删除目录则必须配合选项”-r”，例如：
$ rm  a.txt rm：是否删除 一般文件 "test.txt"? y  $ rm  test  rm: 无法删除目录"test": 是一个目录  $ rm  -r  test  rm：是否删除 目录 "test"? y 

删除当前目录下的所有文件及目录，命令行为：
$ rm  -r  * 


文件一旦通过rm命令删除，则无法恢复，所以必须格外一定切记小心地使用该命令。
因为发生过很多欲哭无泪的故事。。。
主要的痛点就在如果是在root账户权限下，rm无所不能呀

/bin/rm Argument list too long – Linux”这种情况主要在大批量删除居多文件的情况下发生，也是因为删除的命令参数超过了shell参数的个数导致的，可以通过getconf ARG_MAX来确认，解决方法好几种
配合find与xargs完成删除海量文件可以通过find和xargs命令配合的方式，比如删除当前目录所有的png文件，
$ find . -name "*.png" -print0 | xargs -0 rm

上面的这个命令会删除当前目录及子目录下所有的png文件，如果不想遍历，仅仅是当前目录，可以采用如下的方式：
$ find . -maxdepth 1 -name "*.png" -print0 | xargs -0 rm

使用find的delete选项还有一种方法是使用如下：
$ find . -name "*.png" -delete




切记，需要再三确认。

快速删除大文件有时候文件可能会变得很大，非常非常大。比如有些log文件动辄几十GB，而通常情况下可能会用rm来删除，可能要产生比较大的IO消耗，一个比较简单的方法可以这么来操作：
$ echo '' &gt; big_file

当然这个big_file需要替换为大文件的路径和文件名字。
会写一个空格到这个文件，随后即可删除。
]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>rm</tag>
        <tag>危险命令</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux的 rm 命令</title>
    <url>/2011/02/12/linux-rm/</url>
    <content><![CDATA[删除文件和目录命令rmrm 命令用于删除文件或者目录。官方定义为：

remove files or directories

语法$ rm [options] name...

参数：

-i 删除前逐一询问确认，确认时比较好用。
-f 即使原档案属性设为唯读，也直接删除，无需逐一确认，是force的意思。
-r 将目录及里面的子文件逐一删除。

几个示例删除文件可以直接使用rm命令，若删除目录则必须配合选项”-r”，例如：
$ rm  a.txt rm：是否删除 一般文件 "test.txt"? y  $ rm  test  rm: 无法删除目录"test": 是一个目录  $ rm  -r  test  rm：是否删除 目录 "test"? y 

删除当前目录下的所有文件及目录，命令行为：
$ rm  -r  * 


文件一旦通过rm命令删除，则无法恢复，所以必须格外一定切记小心地使用该命令。
因为发生过很多欲哭无泪的故事。。。

]]></content>
      <categories>
        <category>Linux</category>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>rm</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux的 rmdir 命令</title>
    <url>/2011/02/12/linux-rmdir-beginner/</url>
    <content><![CDATA[rmdir简介rmdir 相对于 mkdir ，rmdir 是用来将一个“空的“目录删掉。
如果一个目录下面没有任何文件或文件夹，你就可以用 rmdir 指令将其除去。
而如果一个目录底下有其他的内容， rmdir 将无法将这个目录杀掉，除非使用那么就加上**-r** 选项就ok了。

这个命令比较鸡肋，基本都可以通过rm来搞定解决。

官方定义为：

remove directory

使用方法很简单，基本如下：
$ rmdir directory



如果说出彩的话，只有-p选项还可以说道说道。
详细的解释为：

Each directory argument is treated as a pathname of which all components will be removed, if they are empty, starting with the last most component. 

如果在删除子目录以后，主目录也是空目录的话，则一并删除之。
用法如下：
$ rmdir -p directory	



其他的还是使用rm吧。
]]></content>
      <categories>
        <category>Linux</category>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>mkdir</tag>
        <tag>rmdir</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux的 rmdir 命令</title>
    <url>/2011/02/12/linux-rmdir/</url>
    <content><![CDATA[rmdir简介rmdir 相对于 mkdir ，rmdir 是用来将一个“空的“目录删掉。
如果一个目录下面没有任何文件或文件夹，你就可以用 rmdir 指令将其除去。
而如果一个目录底下有其他的内容， rmdir 将无法将这个目录杀掉，除非使用那么就加上**-r** 选项就ok了。

这个命令比较鸡肋，基本都可以通过rm来搞定解决。

官方定义为：

remove directory

使用方法很简单，基本如下：
$ rmdir directory



如果说出彩的话，只有-p选项还可以说道说道。
详细的解释为：

Each directory argument is treated as a pathname of which all components will be removed, if they are empty, starting with the last most component. 

如果在删除子目录以后，主目录也是空目录的话，则一并删除之。
用法如下：
$ rmdir -p directory	



其他的还是使用rm吧。
]]></content>
      <categories>
        <category>Linux</category>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>mkdir</tag>
        <tag>rmdir</tag>
      </tags>
  </entry>
  <entry>
    <title>稍显底层的红帽系软件管理工具 - rpm</title>
    <url>/2015/03/12/linux-rpm-beginner/</url>
    <content><![CDATA[稍显底层的红帽系软件管理工具 - rpm.. note::  伤心桥下春波绿，曾是惊鸿照影来。  陆游《沈园二首》
创建 RPM 软件包要创建 RPM 软件包，通常需要编写一个规范文件（spec file），然后使用 rpmbuild 命令进行构建。以下是一个简单的示例规范文件：
Name:           exampleVersion:        1.0Release:        1%{?dist}Summary:        An example packageLicense:        GPLSource0:        example-1.0.tar.gz%descriptionThis is an example package.%prep%setup -q%buildmake %{?_smp_mflags}%installrm -rf $RPM_BUILD_ROOTmake install DESTDIR=$RPM_BUILD_ROOT%files%{_bindir}/example%changelog* Wed May 15 2024 Your Name &lt;your.email@example.com&gt; - 1.0-1- Initial package

然后运行以下命令创建软件包：
rpmbuild -ba example.spec
]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>rpm</tag>
        <tag>linux</tag>
        <tag>software</tag>
        <tag>dangerous</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux RPM 软件包</title>
    <url>/2013/04/10/linux-rpm/</url>
    <content><![CDATA[Linux RPM软件包软件包比较通用的有两种，如下：

Redhat系列的rpm包
Debian系列的软件包格式dpkg，即deb包


可以使用工具alien（不是异形，^_^）来转换rpm包和deb包

RPM软件包的优点
使用广泛
允许你只用一条命令来安装软件
只需要处理一个文件
RPM自动处理软件包之间的依赖性检查
RPM软件包被设计为由“最干净”的源代码而来从而允许你对它重新进行编译

创建RPM包
收集需要打包的软件
创建SPEC文件，该文件描述了如何建立软件包
用rpmbuild命令创建软件包

]]></content>
      <categories>
        <category>Linux</category>
        <category>CentOS</category>
        <category>Debian</category>
      </categories>
      <tags>
        <tag>rpm</tag>
        <tag>linux</tag>
        <tag>redhat</tag>
        <tag>dpkg</tag>
        <tag>rpmbuild</tag>
        <tag>spec</tag>
        <tag>deb</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux rsync</title>
    <url>/2012/04/10/linux-rsync-beginner/</url>
    <content><![CDATA[Linux rsync 命令rsync也是远程（或本地）复制和同步文件最常用的命令。
与scp类似。
官方定义为：

rsync - a fast, versatile, remote (and local) file-copyint tool

从定义看，比scp要强一些。
借助rsync命令，可以跨目录，跨磁盘和跨网络远程与本地数据进行复制和同步。比如最常用的就是在两台Linux主机之间进行数据的备份。
语法语法相对而言，比较简单，不过用法其实挺多的。
$ rsync [OPTION...] SRC... [DEST]

常用的参数为：

-v : 详细模式输出
-r : 递归拷贝数据，但是传输数据时不保留时间戳和权限
-a : 归档模式, 归档模式总是递归拷贝，而且保留符号链接、权限、属主、属组时间戳
-z : 压缩传输
-h : human-readable
--progress： 显示传输过程
--exclude=PATTERN 指定排除传输的文件模式
--include=PATTERN 指定需要传输的文件模式

无参数传输默认情况下，传输一个文件不需要任何参数：
$ rsync user@192.168.100.123:~/dest_file dir/

命令执行后，会提示输入远程机器的密码，不过成功后不会显示任何信息，需要自行确认。
常用传输所以默认情况下，会使用rv参数，不仅可以传输一个目录，也可以是文件：
$ rsync -rv user@192.168.100.123:~/dest_file dir/user@192.168.100.123's password:receiving file list ... doneabc



显示详细进度对于小文件而言，没有问题，但是如果文件比较大，比如有几个GB，那么此时--progress参数就会比较有帮助：
$ rsync -rv --progress user@192.168.100.123:~/dest_file dir/user@192.168.100.123's password:receiving file list ... done30 files to considera  100%   278.25MB/s  0:02:00   (xfer#1, to-check=28/30)b  100%   289.25MB/s  0:02:00   (xfer#1, to-check=27/30)c  100%   277.45MB/s  0:02:00   (xfer#1, to-check=26/30)

会实时更新传输的进度。
此时对比scp，可以看到多了一些提示信息，比如会提示：

receiving file list … done30 files to consider

另外，在实时更新的进度里面也有了一些多出来的信息。
不传输一些文件比如做软件开发，不希望传输一些编译过程中产生的.o文件，测试的--exclude参数就很完美，如下：
$ rsync -rv --progress --exclude "*.o" user@192.168.100.123:~/dest_file dir/user@192.168.100.123's password:receiving file list ... done25 files to considera  100%   278.25MB/s  0:02:00   (xfer#1, to-check=28/30)b  100%   289.25MB/s  0:02:00   (xfer#1, to-check=27/30)c  100%   277.45MB/s  0:02:00   (xfer#1, to-check=26/30)

此时就看到，本来该传输30组的数据，去掉了部分.o文件。
]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>rsync</tag>
        <tag>数据传输</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux rsync</title>
    <url>/2012/04/10/linux-rsync/</url>
    <content><![CDATA[Linux rsync 命令rsync也是远程（或本地）复制和同步文件最常用的命令。
与scp类似。
官方定义为：

rsync - a fast, versatile, remote (and local) file-copyint tool

从定义看，比scp要强一些。
借助rsync命令，可以跨目录，跨磁盘和跨网络远程与本地数据进行复制和同步。比如最常用的就是在两台Linux主机之间进行数据的备份。
语法语法相对而言，比较简单，不过用法其实挺多的。
$ rsync [OPTION...] SRC... [DEST]

常用的参数为：

-v : 详细模式输出
-r : 递归拷贝数据，但是传输数据时不保留时间戳和权限
-a : 归档模式, 归档模式总是递归拷贝，而且保留符号链接、权限、属主、属组时间戳
-z : 压缩传输
-h : human-readable
--progress： 显示传输过程
--exclude=PATTERN 指定排除传输的文件模式
--include=PATTERN 指定需要传输的文件模式

无参数传输默认情况下，传输一个文件不需要任何参数：
$ rsync user@192.168.100.123:~/dest_file dir/

命令执行后，会提示输入远程机器的密码，不过成功后不会显示任何信息，需要自行确认。
常用传输所以默认情况下，会使用rv参数，不仅可以传输一个目录，也可以是文件：
$ rsync -rv user@192.168.100.123:~/dest_file dir/user@192.168.100.123's password:receiving file list ... doneabc



显示详细进度对于小文件而言，没有问题，但是如果文件比较大，比如有几个GB，那么此时--progress参数就会比较有帮助：
$ rsync -rv --progress user@192.168.100.123:~/dest_file dir/user@192.168.100.123's password:receiving file list ... done30 files to considera  100%   278.25MB/s  0:02:00   (xfer#1, to-check=28/30)b  100%   289.25MB/s  0:02:00   (xfer#1, to-check=27/30)c  100%   277.45MB/s  0:02:00   (xfer#1, to-check=26/30)

会实时更新传输的进度。
此时对比scp，可以看到多了一些提示信息，比如会提示：

receiving file list … done30 files to consider

另外，在实时更新的进度里面也有了一些多出来的信息。
不传输一些文件比如做软件开发，不希望传输一些编译过程中产生的.o文件，测试的--exclude参数就很完美，如下：
$ rsync -rv --progress --exclude "*.o" user@192.168.100.123:~/dest_file dir/user@192.168.100.123's password:receiving file list ... done25 files to considera  100%   278.25MB/s  0:02:00   (xfer#1, to-check=28/30)b  100%   289.25MB/s  0:02:00   (xfer#1, to-check=27/30)c  100%   277.45MB/s  0:02:00   (xfer#1, to-check=26/30)

此时就看到，本来该传输30组的数据，去掉了部分.o文件。
rsync特性高效地复制同步数据到对端，或者对端到本地支持复制链接、设备、属主、属组、权限比scp（Secure Copy）更快。rsync使用远程更新协议（ remote-update protocol ），这允许仅仅传输两组文件之间的差异。对于首次传输，它将文件或目录的全部内容从源复制到目标，但是从下次起，它仅将变化部分复制到目标。Rsync消耗较少的带宽，因为它使用压缩和解压缩方法，同时发送和接收数据两端。HTTP压缩技术
基本语法--delete 同步时，删除那些DST中有，而SRC没有的文件--max-size：限定传输文件大小的上限--dry-run：显示那些文件将被传输，并不会实际传输--bwlimit：限制传输带宽-W：拷贝文件，不进行增量检测



使用范例：本地拷贝到远程$ rsync -avz localfile user@ip:/the/path/


传输数据时显示传输过程使用–progress参数
使用–exclude和–include传输dat开头的文件、目录，排除其他情况的文件、目录
$ rsync -avz --include 'dat*' --exclude '*' /local/path/ user@ip:/the/path

使用–delete–delete用于同步时，删除那些DST中有，而SRC没有的文件
传输完毕后自动删除源文件、目录, 可以使用–remove-source-files选项完成此自动删除。
使用–dry-run如果你对rsync不熟悉，贸然使用rsync可能会搞乱对端文件、目录。借助–dry-run可以让你知道会传输些什么东西，但实际上并没有传输任何东西。如果输出结果与你的预期吻合，可以去掉–dry-run，进行实际的传输工作。
同步整个文件rsync由于采用远程更新协议（ remote-update protocol ），默认是同步变化的字节或块。使用-W可以取消这种机制，整个文件同步
指定端口下个示例通过指定12345端口进行数据传输。
rsync -e 'ssh -p 12345'  -avz localfile user@ip:/the/path/

]]></content>
      <categories>
        <category>Linux</category>
        <category>Linux入门</category>
        <category>数据传输</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>rsync</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux 的 scp 命令</title>
    <url>/2017/01/24/linux-scp-beginner/</url>
    <content><![CDATA[Linux scp命令linux scp命令主要用于远程复制传输文件。
官方定义为：

scp — secure copy (remote file copy program)

是安全拷贝的缩写，主要是因为scp使用了ssh的安全机制。
scp应该是接触Linux的第一个用于在2台以上的服务器上做数据传输的不二命选，当然，ftp除外了。
语法语法看着挺复杂：
$ scp [-12346BCpqrv] [-c cipher] [-F ssh_config] [-i identity_file] [-l limit] [-o ssh_option] [-P port] [-S program] [[user@]host1:]file1 ... [[user@]host2:]file2

其实简化下来就是：
$ scp [options] file_source file_target 

差不多有20个参数，不过常用的有如下几个：

-p：保留原文件的修改时间，访问时间和访问权限。
-r： 递归复制整个目录。
-v：详细方式显示输出。scp和ssh(1)会显示出整个过程的调试信息。这些信息用于调试连接，验证和配置问题。

无参数传输默认情况下，传输一个文件不需要任何参数：
$ scp src_file user@192.168.100.123:~/dest_fileuser@192.168.100.123's password:src_file                     100%   44  20.0KB/s   00:00

命令执行后，会提示输入远程机器的密码，后面会显示传输成功的文件。
目录传输而传输一个目录不加任何参数的话，会报错如下：
$ scp src_dir user@192.168.100.123:~/dest_diruser@192.168.100.123's password:src_dir: not a regular file

提示要传输的不是常规的文件，需要加上参数-r递归传输如下：
$ scp src_dir user@192.168.100.123:~/dest_diruser@192.168.100.123's password:a        100%   75    35.1KB/s   00:00    b        100%   48KB  14.7MB/s   00:00    c        100%  581   326.4KB/s   00:00    d        100%   48KB  15.3MB/s   00:00 e        100%   278MB 130.7MB/s  00:02



显示详细进度对于小文件而言，没有问题，但是如果文件比较大，比如有几个GB，那么此时-v参数就会比较有帮助：
$ scp a user@192.168.100.123:~/buser@192.168.100.123's password:a        0%          0 0.0KMB/s  --:-- ETAa        30%    110MB 130.7MB/s  00:02a        100%   278MB 130.7MB/s  00:02

会实时更新传输的进度。
保持初始状态加上-p参数就会保留文件的修改时间，访问时间和访问权限：
$ scp -p a user@192.168.100.123:~/b

这个对于有些对时间很有控制欲的人很有帮助。
所以最常用的用法是（文件和文件夹均适用）：
$ scp -rvp filename/directory user@192.168.100.123:~/
]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>数据传输</tag>
        <tag>scp</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux 的 scp 命令</title>
    <url>/2017/01/24/linux-scp/</url>
    <content><![CDATA[Linux scp命令linux scp命令主要用于远程复制传输文件。
官方定义为：

scp — secure copy (remote file copy program)

是安全拷贝的缩写，主要是因为scp使用了ssh的安全机制。
scp应该是接触Linux的第一个用于在2台以上的服务器上做数据传输的不二命选，当然，ftp除外了。
语法语法看着挺复杂：
$ scp [-12346BCpqrv] [-c cipher] [-F ssh_config] [-i identity_file] [-l limit] [-o ssh_option] [-P port] [-S program] [[user@]host1:]file1 ... [[user@]host2:]file2

其实简化下来就是：
$ scp [options] file_source file_target 

差不多有20个参数，不过常用的有如下几个：

-p：保留原文件的修改时间，访问时间和访问权限。
-r： 递归复制整个目录。
-v：详细方式显示输出。scp和ssh(1)会显示出整个过程的调试信息。这些信息用于调试连接，验证和配置问题。

无参数传输默认情况下，传输一个文件不需要任何参数：
$ scp src_file user@192.168.100.123:~/dest_fileuser@192.168.100.123's password:src_file                     100%   44  20.0KB/s   00:00

命令执行后，会提示输入远程机器的密码，后面会显示传输成功的文件。
目录传输而传输一个目录不加任何参数的话，会报错如下：
$ scp src_dir user@192.168.100.123:~/dest_diruser@192.168.100.123's password:src_dir: not a regular file

提示要传输的不是常规的文件，需要加上参数-r递归传输如下：
$ scp src_dir user@192.168.100.123:~/dest_diruser@192.168.100.123's password:a        100%   75    35.1KB/s   00:00    b        100%   48KB  14.7MB/s   00:00    c        100%  581   326.4KB/s   00:00    d        100%   48KB  15.3MB/s   00:00 e        100%   278MB 130.7MB/s  00:02



显示详细进度对于小文件而言，没有问题，但是如果文件比较大，比如有几个GB，那么此时-v参数就会比较有帮助：
$ scp a user@192.168.100.123:~/buser@192.168.100.123's password:a        0%          0 0.0KMB/s  --:-- ETAa        30%    110MB 130.7MB/s  00:02a        100%   278MB 130.7MB/s  00:02

会实时更新传输的进度。
保持初始状态加上-p参数就会保留文件的修改时间，访问时间和访问权限：
$ scp -p a user@192.168.100.123:~/b

这个对于有些对时间很有控制欲的人很有帮助。
所以最常用的用法是（文件和文件夹均适用）：
$ scp -rvp filename/directory user@192.168.100.123:~/









指定端口进行远程拷贝基于安全考虑，可能需要指定端口进行传输，比如12345
$ scp -P 12345 source_file username@ipaddr:/the/path/of/dest_file









参数说明：

-1： 强制scp命令使用协议ssh1
-2： 强制scp命令使用协议ssh2
-4： 强制scp命令只使用IPv4寻址
-6： 强制scp命令只使用IPv6寻址
-B： 使用批处理模式（传输过程中不询问传输口令或短语）
-C： 允许压缩。（将-C标志传递给ssh，从而打开压缩功能）
-q： 不显示传输进度条。
-c cipher： 以cipher将数据传输进行加密，这个选项将直接传递给ssh。
-F ssh_config： 指定一个替代的ssh配置文件，此参数直接传递给ssh。
-i identity_file： 从指定文件中读取传输时使用的密钥文件，此参数直接传递给ssh。
-l limit： 限定用户所能使用的带宽，以Kbit/s为单位。
-o ssh_option： 如果习惯于使用ssh_config(5)中的参数传递方式，
-P port：注意是大写的P, port是指定数据传输用到的端口号
-S program： 指定加密传输时所使用的程序。此程序必须能够理解ssh(1)的选项。

实例1、从本地复制到远程命令格式：
scp local_file remote_username@remote_ip:remote_folder 或者 scp local_file remote_username@remote_ip:remote_file 或者 scp local_file remote_ip:remote_folder 或者 scp local_file remote_ip:remote_file 




第1,2个指定了用户名，命令执行后需要再输入密码，第1个仅指定了远程的目录，文件名字不变，第2个指定了文件名；
第3,4个没有指定用户名，命令执行后需要输入用户名和密码，第3个仅指定了远程的目录，文件名字不变，第4个指定了文件名；

应用实例：
scp /home/space/music/1.mp3 root@www.runoob.com:/home/root/others/music scp /home/space/music/1.mp3 root@www.runoob.com:/home/root/others/music/001.mp3 scp /home/space/music/1.mp3 www.runoob.com:/home/root/others/music scp /home/space/music/1.mp3 www.runoob.com:/home/root/others/music/001.mp3 

复制目录命令格式：
scp -r local_folder remote_username@remote_ip:remote_folder 或者 scp -r local_folder remote_ip:remote_folder 


第1个指定了用户名，命令执行后需要再输入密码；
第2个没有指定用户名，命令执行后需要输入用户名和密码；

应用实例：
scp -r /home/space/music/ root@www.runoob.com:/home/root/others/ scp -r /home/space/music/ www.runoob.com:/home/root/others/ 

上面命令将本地 music 目录复制到远程 others 目录下。
2、从远程复制到本地从远程复制到本地，只要将从本地复制到远程的命令的后2个参数调换顺序即可，如下实例
应用实例：
scp root@www.runoob.com:/home/root/others/music /home/space/music/1.mp3 scp -r www.runoob.com:/home/root/others/ /home/space/music/

说明1.如果远程服务器防火墙有为scp命令设置了指定的端口，我们需要使用 -P 参数来设置命令的端口号，命令格式如下：
#scp 命令使用端口号 4588scp -P 4588 remote@www.runoob.com:/usr/local/sin.sh /home/administrator

2.使用scp命令要确保使用的用户具有可读取远程服务器相应文件的权限，否则scp命令是无法起作用的。
scp是 secure copy的缩写, scp是linux系统下基于ssh登陆进行安全的远程文件拷贝命令。linux的scp命令可以在linux服务器之间复制文件和目录。 scp命令用于在Linux下进行远程拷贝文件的命令，和它类似的命令有cp，不过cp只是在本机进行拷贝不能跨服务器，而且scp传输是加密的。可能会稍微影响一下速度。
当你服务器硬盘变为只读read only system时，用scp可以帮你把文件移出来。另外，scp还非常不占资源，不会提高多少系统负荷，在这一点上，rsync就远远不及它了。虽然 rsync比scp会快一点，但当小文件众多的情况下，rsync会导致硬盘I/O非常高，而scp基本不影响系统正常使用。
常用参数：



-1
使用ssh协议版本1-2



-2
使用ssh协议版本2


-4
使用ipv4


-6
使用ipv6


-B
以批处理模式运行


-C
使用压缩


-F
指定ssh配置文件


-l
指定宽带限制


-o
指定使用的ssh选项


-P
指定远程主机的端口号


-p
保留文件的最后修改时间，最后访问时间和权限模式


-q
不显示复制进度






参考实例
从远程复制文件到本地目录：
[root@linuxcool ~]# scp root@192.168.10.10:/opt/soft/rhel-server-7.3-x86_64.tar.gz /opt/soft/

从远程复制目录到本地：
[root@linuxcool ~]# scp -r root@10.10.10.10:/opt/soft/mysql /opt/soft/

上传本地文件到远程机器指定目录：
[root@linuxcool ~]# scp /opt/soft/rhel-server-7.3-x86_64.tar.gz root@192.168.10.10:/opt/soft/scptest

上传本地目录到远程机器指定目录：
[root@linuxcool ~]# scp -r /opt/soft/mysql root@192.168.10.10:/opt/soft/scptest

保留文件的最后修改时间，最后访问时间和权限模式：
[root@linuxcool ~]# scp -p /root/install.log root@192.168.10.10:/tmp  
]]></content>
      <categories>
        <category>Linux</category>
        <category>Linux入门</category>
        <category>数据传输</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>scp</tag>
      </tags>
  </entry>
  <entry>
    <title>linux之screenfetch命令</title>
    <url>/2014/02/12/linux-screenfetch-misc/</url>
    <content><![CDATA[显示系统风貌的screenfetch命令screenfetch命令的神奇之处在于其简单而又直观的功能，该命令能够快速地收集系统信息并以一种富有个性的方式展示出来。
从使用的发行版到内核版本，再到处理器和内存，一目了然地展现系统的全貌。
$ screenfetch                          ./+o+-       oper@localhost                  yyyyy- -yyyyyy+      OS: Ubuntu                ://+//////-yyyyyyo      Kernel: aarch64 Linux 6.4.16-linuxkit           .++ .:/++++++/-.+sss/`      Uptime: 33m         .:++o:  /++++++++/:--:/-      Packages: 134        o:+o+:++.`..```.-/oo+++++/     Shell: bash 5.1.16       .:+o:+o/.          `+sssoo+/    Disk: 32G / 59G (57%)  .++/+:+oo+o:`             /sssooo.   CPU: 12x Apple /+++//+:`oo+o               /::--:.   RAM: 877MiB / 7844MiB \+/+o+++`o++o               ++////.    .++.o+++oo+:`             /dddhhh.         .+.o+oo:.          `oddhhhh+           \+.++o+o``-````.:ohdhhhhh+             `:o+++ `ohhhhhhhhyo++os:                .o:`.syhhhhhhh/.oo++o`                    /osyyyyyyo++ooo+++/                       ````` +oo+++o\:                              `oo++.  

]]></content>
      <categories>
        <category>Linux炫技</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>screenfetch</tag>
      </tags>
  </entry>
  <entry>
    <title>sed 入门</title>
    <url>/2022/07/07/linux-sed-beginner/</url>
    <content><![CDATA[sed command examplesWhen you copy a DOS file to Unix, you could find \r\n in the end of each line. This example converts the DOS file format to Unix file format using sed command.
$sed 's/.$//' filename

Print file content in reverse order
$ sed -n '1!G;h;$p' thegeekstuff.txt

Add line number for all non-empty-lines in a file
$ sed '/./=' thegeekstuff.txt | sed 'N; s/\n/ /'

More sed examples: Advanced Sed Substitution Examples
]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>文件管理</tag>
        <tag>目录导航</tag>
        <tag>ls</tag>
        <tag>文档编辑</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux sed命令</title>
    <url>/2016/07/07/linux-sed/</url>
    <content><![CDATA[Linux sedgrep和sed替换文件中的字符串sed -i s/"str1"/"str2"/g `grep "str1" -rl --include="*.[ch]" ./`

将当前目录下的所有.c、.h文件中的str1字符串替换为str2字符串。
参数解释:sed:

-i 表示操作的是文件，``括起来的grep命令，表示将grep命令的的结果作为操作文件s/“str1”/“str2”/表示查找str1并替换为str2，后面跟g表示一行中有多个str1的时候，都替换，而不是仅替换第一个

grep

-r表示查找当前目录以及所有子目录
-l表示仅列出符合条件的文件名，传给sed命令做替换操作
–include=”*.[ch]” 表示仅查找.c、.h文件

注：如果不需要查找子目录，仅需要在当前目录替换，可直接用sed命令：
sed -i s/"str1"/"str2"/g ./*.[ch]

使用sed删除文件前N行
删除首行: sed -i '1d' filename.txt
删除1到100行: sed -i '1,100d' filename.txt
删除尾行: sed -i '$d' filename.txt

使用sed删除文件中包含字符hello的行sed ‘/hello/d’ filename.txt
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>grep</tag>
        <tag>sed</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux 语义化版本</title>
    <url>/2018/01/10/linux-semantic-version/</url>
    <content><![CDATA[
参考https://semver.org/

语义化版本 2.0.0摘要版本格式：主版本号.次版本号.修订号，版本号递增规则如下：

主版本号：当你做了不兼容的 API 修改，
次版本号：当你做了向下兼容的功能性新增，
修订号：当你做了向下兼容的问题修正。

先行版本号及版本编译元数据可以加到“主版本号.次版本号.修订号”的后面，作为延伸。
简介在软件管理的领域里存在着被称作“依赖地狱”的死亡之谷，系统规模越大，加入的包越多，你就越有可能在未来的某一天发现自己已深陷绝望之中。
在依赖高的系统中发布新版本包可能很快会成为噩梦。如果依赖关系过高，可能面临版本控制被锁死的风险（必须对每一个依赖包改版才能完成某次升级）。而如果依赖关系过于松散，又将无法避免版本的混乱（假设兼容于未来的多个版本已超出了合理数量）。当你专案的进展因为版本依赖被锁死或版本混乱变得不够简便和可靠，就意味着你正处于依赖地狱之中。
作为这个问题的解决方案之一，我提议用一组简单的规则及条件来约束版本号的配置和增长。这些规则是根据（但不局限于）已经被各种封闭、开放源码软件所广泛使用的惯例所设计。为了让这套理论运作，你必须先有定义好的公共 API 。这可以透过文件定义或代码强制要求来实现。无论如何，这套 API 的清楚明了是十分重要的。一旦你定义了公共 API，你就可以透过修改相应的版本号来向大家说明你的修改。考虑使用这样的版本号格式：X.Y.Z （主版本号.次版本号.修订号）修复问题但不影响API 时，递增修订号；API 保持向下兼容的新增及修改时，递增次版本号；进行不向下兼容的修改时，递增主版本号。
我称这套系统为“语义化的版本控制”，在这套约定下，版本号及其更新方式包含了相邻版本间的底层代码和修改内容的信息。
语义化版本控制规范（SemVer）以下关键词 MUST、MUST NOT、REQUIRED、SHALL、SHALL NOT、SHOULD、SHOULD NOT、 RECOMMENDED、MAY、OPTIONAL 依照 RFC 2119 的叙述解读。（译注：为了保持语句顺畅， 以下文件遇到的关键词将依照整句语义进行翻译，在此先不进行个别翻译。）
1. 
   使用语义化版本控制的软件必须（MUST）定义公共 API。该 API 可以在代码中被定义或出现于严谨的文件内。无论何种形式都应该力求精确且完整。
2. 
   标准的版本号必须（MUST）采用 X.Y.Z 的格式，其中 X、Y 和 Z 为非负的整数，且禁止（MUST NOT）在数字前方补零。X 是主版本号、Y 是次版本号、而 Z 为修订号。每个元素必须（MUST）以数值来递增。例如：1.9.1 -&gt; 1.10.0 -&gt; 1.11.0。
3. 
   标记版本号的软件发行后，禁止（MUST NOT）改变该版本软件的内容。任何修改都必须（MUST）以新版本发行。
4. 
   主版本号为零（0.y.z）的软件处于开发初始阶段，一切都可能随时被改变。这样的公共 API 不应该被视为稳定版。
5. 
   1.0.0 的版本号用于界定公共 API 的形成。这一版本之后所有的版本号更新都基于公共 API 及其修改内容。
6. 
   修订号 Z（x.y.Z | x &gt; 0）必须（MUST）在只做了向下兼容的修正时才递增。这里的修正指的是针对不正确结果而进行的内部修改。
7. 
   次版本号 Y（x.Y.z | x &gt; 0）必须（MUST）在有向下兼容的新功能出现时递增。在任何公共 API 的功能被标记为弃用时也必须（MUST）递增。也可以（MAY）在内部程序有大量新功能或改进被加入时递增，其中可以（MAY）包括修订级别的改变。每当次版本号递增时，修订号必须（MUST）归零。
8. 
   主版本号 X（X.y.z | X &gt; 0）必须（MUST）在有任何不兼容的修改被加入公共 API 时递增。其中可以（MAY）包括次版本号及修订级别的改变。每当主版本号递增时，次版本号和修订号必须（MUST）归零。
9. 
   先行版本号可以（MAY）被标注在修订版之后，先加上一个连接号再加上一连串以句点分隔的标识符来修饰。标识符必须（MUST）由 ASCII 字母数字和连接号 [0-9A-Za-z-] 组成，且禁止（MUST NOT）留白。数字型的标识符禁止（MUST NOT）在前方补零。先行版的优先级低于相关联的标准版本。被标上先行版本号则表示这个版本并非稳定而且可能无法满足预期的兼容性需求。范例：1.0.0-alpha、1.0.0-alpha.1、1.0.0-0.3.7、1.0.0-x.7.z.92。
10. 
版本编译元数据可以（MAY）被标注在修订版或先行版本号之后，先加上一个加号再加上一连串以句点分隔的标识符来修饰。标识符必须（MUST）由 ASCII 字母数字和连接号 [0-9A-Za-z-] 组成，且禁止（MUST NOT）留白。当判断版本的优先层级时，版本编译元数据可（SHOULD）被忽略。因此当两个版本只有在版本编译元数据有差别时，属于相同的优先层级。范例：1.0.0-alpha+001、1.0.0+20130313144700、1.0.0-beta+exp.sha.5114f85。

11. 
版本的优先层级指的是不同版本在排序时如何比较。判断优先层级时，必须（MUST）把版本依序拆分为主版本号、次版本号、修订号及先行版本号后进行比较（版本编译元数据不在这份比较的列表中）。由左到右依序比较每个标识符，第一个差异值用来决定优先层级：主版本号、次版本号及修订号以数值比较，例如：1.0.0 &lt; 2.0.0 &lt; 2.1.0 &lt; 2.1.1。当主版本号、次版本号及修订号都相同时，改以优先层级比较低的先行版本号决定。例如：1.0.0-alpha &lt; 1.0.0。有相同主版本号、次版本号及修订号的两个先行版本号，其优先层级必须（MUST）透过由左到右的每个被句点分隔的标识符来比较，直到找到一个差异值后决定：只有数字的标识符以数值高低比较，有字母或连接号时则逐字以 ASCII 的排序来比较。数字的标识符比非数字的标识符优先层级低。若开头的标识符都相同时，栏位比较多的先行版本号优先层级比较高。范例：1.0.0-alpha &lt; 1.0.0-alpha.1 &lt; 1.0.0-alpha.beta &lt; 1.0.0-beta &lt; 1.0.0-beta.2 &lt; 1.0.0-beta.11 &lt; 1.0.0-rc.1 &lt; 1.0.0。

为什么要使用语义化的版本控制？这并不是一个新的或者革命性的想法。实际上，你可能已经在做一些近似的事情了。问题在于只是“近似”还不够。如果没有某个正式的规范可循，版本号对于依赖的管理并无实质意义。将上述的想法命名并给予清楚的定义，让你对软件使用者传达意向变得容易。一旦这些意向变得清楚，弹性（但又不会太弹性）的依赖规范就能达成。
举个简单的例子就可以展示语义化的版本控制如何让依赖地狱成为过去。假设有个名为“救火车”的函式库，它需要另一个名为“梯子”并已经有使用语义化版本控制的包。当救火车创建时，梯子的版本号为 3.1.0。因为救火车使用了一些版本 3.1.0 所新增的功能， 你可以放心地指定依赖于梯子的版本号大等于 3.1.0 但小于 4.0.0。这样，当梯子版本 3.1.1 和 3.2.0 发布时，你可以将直接它们纳入你的包管理系统，因为它们能与原有依赖的软件兼容。
作为一位负责任的开发者，你理当确保每次包升级的运作与版本号的表述一致。现实世界是复杂的，我们除了提高警觉外能做的不多。你所能做的就是让语义化的版本控制为你提供一个健全的方式来发行以及升级包，而无需推出新的依赖包，节省你的时间及烦恼。
如果你对此认同，希望立即开始使用语义化版本控制，你只需声明你的函式库正在使用它并遵循这些规则就可以了。请在你的 README 文件中保留此页连结，让别人也知道这些规则并从中受益。
FAQ在 0.y.z 初始开发阶段，我该如何进行版本控制？最简单的做法是以 0.1.0 作为你的初始化开发版本，并在后续的每次发行时递增次版本号。
如何判断发布 1.0.0 版本的时机？当你的软件被用于正式环境，它应该已经达到了 1.0.0 版。如果你已经有个稳定的 API 被使用者依赖，也会是 1.0.0 版。如果你很担心向下兼容的问题，也应该算是 1.0.0 版了。
这不会阻碍快速开发和迭代吗？主版本号为零的时候就是为了做快速开发。如果你每天都在改变 API，那么你应该仍在主版本号为零的阶段（0.y.z），或是正在下个主版本的独立开发分支中。
对于公共 API，若即使是最小但不向下兼容的改变都需要产生新的主版本号，岂不是很快就达到 42.0.0 版？这是开发的责任感和前瞻性的问题。不兼容的改变不应该轻易被加入到有许多依赖代码的软件中。升级所付出的代价可能是巨大的。要递增主版本号来发行不兼容的改版，意味着你必须为这些改变所带来的影响深思熟虑，并且评估所涉及的成本及效益比。
为整个公共 API 写文件太费事了！为供他人使用的软件编写适当的文件，是你作为一名专业开发者应尽的职责。保持专案高效一个非常重要的部份是掌控软件的复杂度，如果没有人知道如何使用你的软件或不知道哪些函数的调用是可靠的，要掌控复杂度会是困难的。长远来看，使用语义化版本控制以及对于公共 API 有良好规范的坚持，可以让每个人及每件事都运行顺畅。
万一不小心把一个不兼容的改版当成了次版本号发行了该怎么办？一旦发现自己破坏了语义化版本控制的规范，就要修正这个问题，并发行一个新的次版本号来更正这个问题并且恢复向下兼容。即使是这种情况，也不能去修改已发行的版本。可以的话，将有问题的版本号记录到文件中，告诉使用者问题所在，让他们能够意识到这是有问题的版本。
如果我更新了自己的依赖但没有改变公共 API 该怎么办？由于没有影响到公共 API，这可以被认定是兼容的。若某个软件和你的包有共同依赖，则它会有自己的依赖规范，作者也会告知可能的冲突。要判断改版是属于修订等级或是次版等级，是依据你更新的依赖关系是为了修复问题或是加入新功能。对于后者，我经常会预期伴随着更多的代码，这显然会是一个次版本号级别的递增。
如果我变更了公共 API 但无意中未遵循版本号的改动怎么办呢？（意即在修订等级的发布中，误将重大且不兼容的改变加到代码之中）自行做最佳的判断。如果你有庞大的使用者群在依照公共 API 的意图而变更行为后会大受影响，那么最好做一次主版本的发布，即使严格来说这个修复仅是修订等级的发布。记住， 语义化的版本控制就是透过版本号的改变来传达意义。若这些改变对你的使用者是重要的，那就透过版本号来向他们说明。
我该如何处理即将弃用的功能？弃用现存的功能是软件开发中的家常便饭，也通常是向前发展所必须的。当你弃用部份公共 API 时，你应该做两件事：（1）更新你的文件让使用者知道这个改变，（2）在适当的时机将弃用的功能透过新的次版本号发布。在新的主版本完全移除弃用功能前，至少要有一个次版本包含这个弃用信息，这样使用者才能平顺地转移到新版 API。
语义化版本对于版本的字串长度是否有限制呢？没有，请自行做适当的判断。举例来说，长到 255 个字元的版本已过度夸张。再者，特定的系统对于字串长度可能会有他们自己的限制。
关于语义化版本控制的规范是由 Gravatars 创办者兼 GitHub 共同创办者 Tom Preston-Werner 所建立。
如果您有任何建议，请到 GitHub 上提出您的问题。
许可证知识共享 署名 3.0 (CC BY 3.0)
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>patch</tag>
        <tag>major</tag>
        <tag>minor</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux shell系统时间</title>
    <url>/2013/01/17/linux-shell-date/</url>
    <content><![CDATA[Linux shell获取系统时间#!/bin/bashecho "time now is:"read hoursif [ $hours -lt 12 ]thenecho "good morning"elif [ $hours -ge 12 ] &amp;&amp; [ $hours -lt 20 ]thenecho "good afternoon"elseecho "good night"fi

调用系统时后：
#!/bin/bashecho "time now is:"echo `date`#read hourshours=`date +%H`echo "Hours : $hours"if [ $hours -lt 12 ]thenecho "good morning"elif [ $hours -ge 12 ] &amp;&amp; [ $hours -lt 20 ]thenecho "good afternoon"elseecho "good night"fi
这里注意的地方是 等号两边不要空格
获取系统时间之当前小时的语句是
hours=`date +%H`

如果想系统时间按格式显示，则可改为
echo `date +"%Y-%m-%d-%H:%M:%S"`

运行结果为：
2013-01-17-18:01:08

这里需要注意的是：不同的大小写代表的是不同的含义
date +%Y 以四位数字格式打印年份 eg: 2018date +%y 以二位数字格式打印年份 eg: 18date +%m 月份date +%d 日期date +%H 小时date +%M 分钟date +%S 秒date +%w 星期，如果结果显示0，则表示周日]]></content>
      <categories>
        <category>Linux</category>
        <category>Shell</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>shell</tag>
        <tag>date</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux shell中的for循环用法详解</title>
    <url>/2012/01/17/linux-shell-for-loop/</url>
    <content><![CDATA[Linux shell中的for循环用法详解for循环有多用用法，比如：

for i in “file1” “file2” “file3”
for i in /boot/*
for i in /etc/*.conf
for i in $(seq -w 10) –》等宽的01-10
for i in {1…10}
for i in $( ls )
for I in $(&lt; file)
for i in “$@” –》取所有位置参数，可简写为for i


注意：bash shell支持C式for循环

]]></content>
      <categories>
        <category>Linux</category>
        <category>Shell</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux的几种可选shell</title>
    <url>/2012/01/17/linux-shell-shelltype/</url>
    <content><![CDATA[Shellash shellAsh shell是一种低预算的shell，体型较小，提供基本特性。尤其适合低内存应用，例如嵌入式Linux系统。
Dash shell是Debian Linux发型的ash shell，及Debian ash shell的缩写。
对于Ubuntu这里需要注意，Ubuntu Linux使用bash shell作为默认的交互式shell，但是使用dash shell作为默认的/bin/sh shell。这个特性很容易让shell编程人员感到混乱，甚至是有时脚本无法运行。
我们一般编写脚本的时候通常使用#!/bin/sh，但是由上面可以知道ubuntu会把这个指向dash，所以还是写成#!/bin/bash吧，这样比较保险。
tcsh shellLinux世界中另一种流行的shell是C shell，C shell是将C编程语言中的特性合并到shell脚本中，最流行的开源C shell是tcsh shell。
C shell的目的是提供一个适合C编程人员的命令行和脚本编写环境。
20世纪70年代后期Ken Greer对C shell进行扩展，添加了TENEX操作系统的命令行编程特性，这就是tcsh的由来。
tcsh shell环境变量可能有点混淆、Bourne shell及其派生的bash、ash和dash都只是使用一种环境变量来存储系统信息。而tcsh shell包含两种环境变量：

shell变量；
系统环境变量； 系统环境变量由大写字母组成，提供标准系统信息。Tcsh shell变量是小写变量，对shell具有特殊含义。

对于shell变量，可以使用set命令设置shell变量值。或者@也可以。
Korn shellKorn shell在Unix世界中很流行，但是在Linux世界中并不同样流行。Korn shell提供了Bourne shell和c shell世界的混合特性。
原始Korn shell是David Korn于20世纪80年代在AT&amp;T贝尔实验室工作期间开发的。
Korn shell分两种不同的路线：

Ksh88
Ksh93

大多数实现使用的是ksh93 shell。
Ksh93 shell的一个很棒的特性是可以轻松的使用数学运算。
执行数学运算的方法有两种；

let命令；
双圆括号；

对于许多编程人员来说，ksh93 shell的卖点就是它对浮点数的完全支持。
zsh shellZsh shell提供一些神奇的特性，并将shell未来发展的门槛提高到相当高的高度。
Zsh是Paul Falstad开发的开源Unix Shell。它是集合了Bourne、bash、ash和tcsh等shell的特性，这句话很NB呀，并加入了许多特有的特性，以编程人员使用为目的而创建的一种成熟的高级shell。
其中一些特性使得zsh独具特色：

改良的shell选项控制；
Shell兼容性的模式；
可载入模块。

在这些特色中，可载入模块在shell设计中思想最先进。
zsh shell提供一个核心内置命令集，还提供添加附加命令模块（command modules）的功能。
Zsh是目前自定义功能最强的shell。
可以使用zmodload命令添加ash的模块，如果不加任何参数，可以显示zsh中的模块。
要删除一个模块可以使用-u参数，例如zmodload –u zsh/net/tcp就可以删除tcp模块了。
]]></content>
      <categories>
        <category>Linux</category>
        <category>Shell</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>shell</tag>
        <tag>ash</tag>
        <tag>zsh</tag>
        <tag>tcsh</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux shell 编写规范化、标准化</title>
    <url>/2012/01/17/linux-shell-standard/</url>
    <content><![CDATA[Linux shell 编写规范化、标准化脚本中多写注释作注释不仅方便自己还能帮助别人在翻阅你的脚本时了解脚本的不同部分所做的工作。
注释用 # 号来定义。
当运行失败时使脚本退出有时即使某些命令运行失败，bash 可能继续去执行脚本，这样就影响到脚本的其余部分(会最终导致逻辑错误)。
此时可以把下面的内容写在脚本的前面在遇到命令失败时来退出脚本执行：
# 如果命令运行失败让脚本退出执行 set -o  errexit  # 或者set -e

当 Bash 用未声明变量时使脚本退出Bash 也可能会使用能导致起逻辑错误的未声明的变量。因此用下面行的方式去通知 bash 
当它尝试去用一个未声明变量时就退出脚本执行：
# 若有用未设置的变量即让脚本退出执行 set -o nounset #或者set -u

使用双引号来引用变量用双引号有助于防止由于空格导致单词分割开和由于识别和扩展了通配符而导致的不必要匹配。
在脚本中使用函数除了非常小的脚本(只有几行代码)，总是记得用函数来使代码模块化且使得脚本更可读和可重用。

写函数的语法如下所示：

function  demo(){       command1;        command2;  }  # 或  demo(){        command1;         command2;  }

如果写成单行代码时，每个命令后要用终止符号：
demo(){ command1; command2; }

字符串比较时用 = 而不是 ==注意： == 是 = 的同义词，因此仅用个单 = 来做字符串比较，
用 $(command)  来做代换命令代换是用这个命令的输出结果取代命令本身。用 $(command) 而不是引号 command 来做命令代换。
这种做法也是 shellcheck tool (可针对 shell 脚本显示警告和建议)所建议的。例如：
user=`echo “$UID”` user=$(echo “$UID”)

用 readonly 来声明静态变量静态变量不会改变;它的值一旦在脚本中定义后不能被修改：
readonly mycountry=”China” 

环境变量用大写字母命名，而自定义变量用小写所有的 bash 环境变量用大写字母去命名，因此用小写字母来命名你的自定义变量以避免变量名冲突：
其他需要注意的
变量名，函数名要有实际意义，函数名以动名词形式，第二个单词首字母要大写。例如：updateConfig()
取变量值使用大括号，如${varname}
删除文件时，如果路径有变量的，要判断变量有值，如rm -f ${abc}/* 如果变量abc没有值，则会把根目录下的文件删除
脚本中尽量不要使用cd变换目录
函数中也要有功能描述，使用依法，版本，日期等
函数的功能要单一，不要太复杂
$()比 更好
尽量不要使用多层if语句，而应该以case语句替代
如果需要执行确定次数的循环，应该用for语句替代while语句
输入的参数要有正确性判断

]]></content>
      <categories>
        <category>Linux</category>
        <category>Shell</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux shell变量</title>
    <url>/2012/01/17/linux-shell-variable/</url>
    <content><![CDATA[Linux shell中的变量检查变量是否存在if [ -z "$a" ]then    echo "not defined"else     echo "defined"fi]]></content>
      <categories>
        <category>Linux</category>
        <category>Shell</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux的几种可选shell</title>
    <url>/2012/01/17/linux-shells/</url>
    <content><![CDATA[Shellash shellAsh shell是一种低预算的shell，体型较小，提供基本特性。尤其适合低内存应用，例如嵌入式Linux系统。
Dash shell是Debian Linux发型的ash shell，及Debian ash shell的缩写。
对于Ubuntu这里需要注意，Ubuntu Linux使用bash shell作为默认的交互式shell，但是使用dash shell作为默认的/bin/sh shell。这个特性很容易让shell编程人员感到混乱，甚至是有时脚本无法运行。
我们一般编写脚本的时候通常使用#!/bin/sh，但是由上面可以知道ubuntu会把这个指向dash，所以还是写成#!/bin/bash吧，这样比较保险。
tcsh shellLinux世界中另一种流行的shell是C shell，C shell是将C编程语言中的特性合并到shell脚本中，最流行的开源C shell是tcsh shell。
C shell的目的是提供一个适合C编程人员的命令行和脚本编写环境。
20世纪70年代后期Ken Greer对C shell进行扩展，添加了TENEX操作系统的命令行编程特性，这就是tcsh的由来。
tcsh shell环境变量可能有点混淆、Bourne shell及其派生的bash、ash和dash都只是使用一种环境变量来存储系统信息。而tcsh shell包含两种环境变量：

shell变量；
系统环境变量； 系统环境变量由大写字母组成，提供标准系统信息。Tcsh shell变量是小写变量，对shell具有特殊含义。

对于shell变量，可以使用set命令设置shell变量值。或者@也可以。
Korn shellKorn shell在Unix世界中很流行，但是在Linux世界中并不同样流行。Korn shell提供了Bourne shell和c shell世界的混合特性。
原始Korn shell是David Korn于20世纪80年代在AT&amp;T贝尔实验室工作期间开发的。
Korn shell分两种不同的路线：

Ksh88
Ksh93

大多数实现使用的是ksh93 shell。
Ksh93 shell的一个很棒的特性是可以轻松的使用数学运算。
执行数学运算的方法有两种；

let命令；
双圆括号；

对于许多编程人员来说，ksh93 shell的卖点就是它对浮点数的完全支持。
zsh shellZsh shell提供一些神奇的特性，并将shell未来发展的门槛提高到相当高的高度。
Zsh是Paul Falstad开发的开源Unix Shell。它是集合了Bourne、bash、ash和tcsh等shell的特性，这句话很NB呀，并加入了许多特有的特性，以编程人员使用为目的而创建的一种成熟的高级shell。
其中一些特性使得zsh独具特色：

改良的shell选项控制；
Shell兼容性的模式；
可载入模块。

在这些特色中，可载入模块在shell设计中思想最先进。
zsh shell提供一个核心内置命令集，还提供添加附加命令模块（command modules）的功能。
Zsh是目前自定义功能最强的shell。
可以使用zmodload命令添加ash的模块，如果不加任何参数，可以显示zsh中的模块。
要删除一个模块可以使用-u参数，例如zmodload –u zsh/net/tcp就可以删除tcp模块了。
]]></content>
      <categories>
        <category>Linux</category>
        <category>Shell</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>shell</tag>
        <tag>ash</tag>
        <tag>zsh</tag>
        <tag>tcsh</tag>
      </tags>
  </entry>
  <entry>
    <title>linux技巧</title>
    <url>/2013/10/08/linux-shortcut/</url>
    <content><![CDATA[Linux 技巧快捷键
搜索历史命令的快捷键：Ctrl + r
Ctrl + f– 向右移动一个字符，当然多数人用→
Ctrl + b– 向左移动一个字符， 多数人用←
ESC + f– 向右移动一个单词，MAC下建议用ALT + →
ESC + b– 向左移动一个单词，MAC下建议用ALT + ←
Ctrl + a– 跳到行首
Ctrl + e– 跳到行尾
Ctrl + d– 向右删除一个字符
Ctrl + h– 向左删除一个字符
Ctrl + u– 删除当前位置字符至行首（输入密码错误的时候多用下这个）
Ctrl + k– 删除当前位置字符至行尾
Ctrl + w– 删除从光标到当前单词开头
Ctrl + p– 上一个命令，也可以用↑
Ctrl + n– 下一个命令，也可以用↓
Ctrl + y– 插入最近删除的单词
Ctrl + c– 终止操作
Ctrl + d– 当前操作转到后台
Ctrl + l– 清屏 （有时候为了好看）

]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>shortcut</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux shutdown 命令</title>
    <url>/2013/02/07/linux-shutdown-beginner/</url>
    <content><![CDATA[Linux shutdown 命令.. note::
  青山依旧在，几度夕阳红。

杨慎《临江仙·滚滚长江东逝水》

Linux shutdown 命令可以用来挂起、关机或者重启设备，执行成功的话会返回0。
官方定义为：

shutdown - Halt, power-off or reboot the machine

语法使用方法如下：
$ shutdown [OPTIONS...] [TIME] [WALL...]



第一个参数可能是一个时间字符串 (通常是 now)，一般而言，后面可以跟上一个提示消息来通知登陆的用户系统马上进行的操作。
时间字符串的一般为hh:mm，表示经过多长时间进行关机，当然比较常用的为+m，也就是m分钟后执行操作。
参数如下所示：

-H, --halt 挂起机器
-P, --poweroff 关机（默认选项）
-r, --reboot 重启机器
-h 等效于–poweroff，出发专门指定 –halt选项
-k不进行挂起、关机或者重启，仅仅发送通知信息
--no-wall ： 挂起、关机或者重启前，不发送信息
-c 取消当前正在进行的关机动作，前提是参数不是now

立即关机$ shutdown -h now



十分钟后关机$ shutdown -h 10# 增加提示信息$ shutdown -h 10 "The system will shutdown in 10 minutes, save your work immediately"

17:30关机$ shutdown -h 17:30# 增加提示信息$ shutdown -h 10 "The system will shutdown in 17:30 , remember to save your work"


重新启动计算机$ shutdown -r now
]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>危险命令</tag>
        <tag>shutdown</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux 进程信号</title>
    <url>/2011/01/06/linux-signal/</url>
    <content><![CDATA[Linux进程信号


Signal
Meaning
Mark



SIGHUP
终止进程
终端线路挂断


SIGINT
终止进程
中断进程


SIGQUIT
建立CORE文件
终止进程，并且生成core文件


SIGILL
建立CORE文件
非法指令


SIGTRAP
建立CORE文件
跟踪自陷


SIGBUS
建立CORE文件
总线错误


SIGSEGV
建立CORE文件
段非法错误


SIGFPE
建立CORE文件
浮点异常


SIGIOT
建立CORE文件
执行I/O自陷


SIGKILL
终止进程
杀死进程


SIGPIPE
终止进程
向一个没有读进程的管道写数据


SIGALARM
终止进程
计时器到时


SIGTERM
终止进程
软件终止信号


SIGSTOP
停止进程
非终端来的停止信号


SIGTSTP
停止进程



SIGCONT
忽略信号
继续执行一个停止的进程


SIGURG
忽略信号
I/O紧急信号


SIGIO
忽略信号
描述符上可以进行I/O


SIGCHLD
忽略信号
当子进程停止或退出时通知父进程


SIGTTOU
停止进程
后台进程写终端


SIGTTIN
停止进程
后台进程读终端


SIGXGPU
终止进程
CPU时限超时


SIGXFSZ
终止进程
文件长度过长


SIGWINCH
忽略信号
窗口大小发生变化


SIGPROF
终止进程
统计分布图用计时器到时


SIGUSR1
终止进程
用户定义信号1


SIGUSR2
终止进程
用户定义信号2


SIGVTALRM
终止进程
虚拟计时器到时


]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>signal</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux 之 skill 命令</title>
    <url>/2015/03/12/linux-skill-beginner/</url>
    <content><![CDATA[Linux 之 skill 命令..note::  江山代有才人出，各领风骚数百年。  赵翼《论诗五首·其二》
Linux skill命令送个讯号给正在执行的程序，预设的讯息为 TERM (中断)，较常使用的讯息为 HUP、INT、KILL、STOP、CONT 和 0。
讯息有三种写法：分别为 -9、-SIGKILL、-KILL，可以使用 -l 或 -L 已列出可使用的讯息。
官方含义为：

skill, snice - send a signal or report process status

语法$ skill [signal] [options] expression$ snice [new priority] [options] expression


一般参数：
-i, --interactive ：交互模式,每个动作将要被确认
-l, --list ： 列出所有的信号
-L, --table ： 列出所有的信号名

列出所有的信号$ skill -lHUP INT QUIT ILL TRAP ABRT BUS FPE KILL USR1 SEGV USR2 PIPE ALRM TERM STKFLTCHLD CONT STOP TSTP TTIN TTOU URG XCPU XFSZ VTALRM PROF WINCH POLL PWR SYS


用漂亮的表格列出所有的信号$ skill -L 1 HUP      2 INT      3 QUIT     4 ILL      5 TRAP     6 ABRT     7 BUS 8 FPE      9 KILL    10 USR1    11 SEGV    12 USR2    13 PIPE    14 ALRM15 TERM    16 STKFLT  17 CHLD    18 CONT    19 STOP    20 TSTP    21 TTIN22 TTOU    23 URG     24 XCPU    25 XFSZ    26 VTALRM  27 PROF    28 WINCH29 POLL    30 PWR     31 SYS



kill掉用户users在PTY的进程$ skill -KILL -t /dev/pts/*

停止三个使用者 user1、user2、user3$ skill -STOP -u user1 -u user2 -u  user3




相关命令
:ref:kill&lt;linux-beginner-kill&gt; 
:ref:killall&lt;linux-beginner-killall&gt; 
:ref:nice&lt;linux-beginner-nice&gt; 
:ref:pkill&lt;linux-beginner-pkill&gt; 
:ref:renice&lt;linux-beginner-renice&gt; 
:ref:signal&lt;linux-beginner-signal&gt;

OPTIONS
PROCESS SELECTION OPTIONS       Selection criteria can be: terminal, user, pid, command.  The options below may be used to ensure correct interpretation.
   -t, --tty tty
          The next expression is a terminal (tty or pty).

   -u, --user user
          The next expression is a username.

   -p, --pid pid
          The next expression is a process ID number.

   -c, --command command
          The next expression is a command name.

   --ns pid
          Match the processes that belong to the same namespace as pid.

   --nslist ns,...
          list which namespaces will be considered for the --ns option.  Available namespaces: ipc,  mnt,  net,  pid,  user,
          uts.

SIGNALS       The behavior of signals is explained in signal(7) manual page.
EXAMPLES       snice -c seti -c crack +7              Slow down seti and crack commands.
]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>bash内建指令</tag>
        <tag>skill</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux slurm 作业提交系统</title>
    <url>/2019/01/06/linux-slurm/</url>
    <content><![CDATA[slurm作业提交系统常用命令查看有哪些分区 sinfo命令$ sinfoPARTITION      AVAIL  TIMELIMIT  NODES  STATE NODELISTarm               up   infinite      9   idle taishan-arm-cpu[01-09]gpu               up   infinite      8   idle sugon-gpu[01-08]cpu 							up   infinite      10  idle x86-cpu[01-10]

指定节点跑程序srun比如这里我有一个test.py的文件，内容如下：
#!/usr/bin/env pythonimport timefor i in range(10):	time.sleep(1)	print(i)

执行如下命令：
srun -p cpu -w x86-cpu01 python ./test.py 

slurm最基本的命令是srun，比如上面一行的参数如下：

-p：指定分区PARTITION
-w：指定NODELIST

查看自己任务squeuesqueue -u +用户
~&gt; squeue -u name            JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)            32236 cpu       test.py      name  R       2:08      1 x86-cpu01]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>slurm</tag>
      </tags>
  </entry>
  <entry>
    <title>休息一会 sleep</title>
    <url>/2011/02/12/linux-sleep-beginner/</url>
    <content><![CDATA[休息一会 sleep.. note::  莫听穿林打叶声，何妨吟啸且徐行。  苏轼
Linux sleep命令可以用来将目前动作延迟一段时间。
sleep的官方定义为：

 sleep - delay for a specified amount of time

或许你觉得计算机太累，让它稍事休息，亦或许过个个把钟头需要喝杯水，此时sleep就有点小作用了。
其用法如下：
$ sleep [--help] [--version] number[smhd]

除了帮助和版本信息，基本没有参数了。
其中的number是必须的，也就是sleep多久的数字，默认为s秒。其他的几个含义为：

s second 秒
m minute分钟
h hour 小时
d day 天

休息5分钟工作太累了，学习太累了，躺着太累了，休息5分钟
$ sleep 5m



1小时后提醒我$ sleep 1h



时分秒搭配使用当然，sleep也是支持时分秒搭配使用的，如下所示：
$ sleep 1h 2m 3s

将会sleep 1个小时2分钟3秒。
倒计时计时器当然也可以做个循环计时器，通过sleep 1
$ echo "five"   &amp;&amp; sleep 1 &amp;&amp; echo "four"   &amp;&amp; sleep 1 &amp;&amp; sleep 1 &amp;&amp; echo "three"   &amp;&amp; sleep 1 &amp;&amp; echo "two" &amp;&amp; sleep 1 &amp;&amp; echo "one" &amp;&amp; echo "Stop"





结合脚本sleep在程序里面使用比较频繁，特别是单片机的走马灯等。而Linux的sleep，也是比较常与bash脚本来配合使用，如下：
#!/bin/bashecho -e "start to sleep 15 seconds......"sleep 15echo -e "continue to run program......"./program

]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>sleep</tag>
        <tag>日期时间</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux的 socket.gaierror</title>
    <url>/2019/07/07/linux-socket-gaierror/</url>
    <content><![CDATA[Socket gaierror : Name or Service not known今天编译软件的时候碰到这个问题。
最后发现的问题是在修改hostname的时候没有同步修改/etc/hosts文件，只要把127.0.0.1对应的hostname更改过来即可。
]]></content>
      <categories>
        <category>Linux</category>
        <category>Network</category>
      </categories>
      <tags>
        <tag>socket</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux的 socket 相关</title>
    <url>/2016/07/07/linux-socket/</url>
    <content><![CDATA[sockaddr 与 sockaddr_in在linux环境下，结构体struct sockaddr在/usr/include/linux/socket.h中定义，具体如下：
typedef unsigned short sa_family_t;struct sockaddr {        sa_family_t     sa_family;    /* address family, AF_xxx       */        char            sa_data[14];    /* 14 bytes of protocol address */}

在linux环境下，结构体struct sockaddr_in在/usr/include/netinet/in.h中定义，具体如下：
/* Structure describing an Internet socket address. */struct sockaddr_in{    __SOCKADDR_COMMON (sin_);    in_port_t sin_port;                     /* Port number. */    struct in_addr sin_addr;            /* Internet address. */    /* Pad to size of `struct sockaddr'. */    unsigned char sin_zero[sizeof (struct sockaddr) -                           __SOCKADDR_COMMON_SIZE -                           sizeof (in_port_t) -                           sizeof (struct in_addr)];                                /* 字符数组sin_zero[8]的存在是为了保证结构体struct sockaddr_in的大小和结构体struct sockaddr的大小相等 */};

struct sockaddr是通用的套接字地址，而struct sockaddr_in则是internet环境下套接字的地址形式，二者长度一样，都是16个字节。二者是并列结构，指向sockaddr_in结构的指针也可以指向sockaddr。
一般情况下，需要把sockaddr_in结构强制转换成sockaddr结构再传入系统调用函数中。
下面是struct sockaddr_in中用到两个数据类型，具体定义如下：
/* Type to represent a port. */typedef uint16_t in_port_t;struct in_addr其实就是32位IP地址struct in_addr {        unsigned long s_addr;};

BSD网络软件中包含了两个函数，用来在二进制地址格式和点分十进制字符串格式之间相互转换，但是这两个函数仅仅支持IPv4。
in_addr_t inet_addr(const char *cp);char *inet_ntoa(struct in_addr in);

功能相似的两个函数同时支持IPv4和IPv6
const char *inet_ntop(int domain, const void *addr, char *str, socklen_t size);int inet_pton(int domain, const char *str, void *addr);

通常的用法是：
int sockfd;struct sockaddr_in my_addr;sockfd = socket(AF_INET, SOCK_STREAM, 0);my_addr.sin_family = AF_INET; /* 主机字节序 */my_addr.sin_port = htons(MYPORT); /* short, 网络字节序 */my_addr.sin_addr.s_addr = inet_addr("192.168.0.1");bzero(&amp;(my_addr.sin_zero), 8); /* zero the rest of the struct *///memset(&amp;my_addr.sin_zero, 0, 8);bind(sockfd, (struct sockaddr *)&amp;my_addr, sizeof(struct sockaddr));
]]></content>
      <categories>
        <category>Linux</category>
        <category>Network</category>
      </categories>
      <tags>
        <tag>socket</tag>
      </tags>
  </entry>
  <entry>
    <title>没有规矩不成方圆 sort</title>
    <url>/2012/12/27/linux-sort-beginner/</url>
    <content><![CDATA[没有规矩不成方圆 sortLinux sort 命令用于将文本内容进行排序。
官方定义为：

sort - sort lines of text files

语法$ sort [OPTION]... [FILE]...$ sort [OPTION]... --files0-from=F

常用的参数为：

-c 检查文件是否已经按照顺序排序。
-u 意味着是唯一的(unique)，输出的结果是去完重了的。
-r 以相反的顺序来排序。
-k field1[,field2] 按指定的列进行排序。

这里假定测试文件名为testfile：
LiSi            80ZhangSan        70WangWu          90MaLiu           88



默认无参数在使用 sort 命令以默认的式对文件的行进行排序，命令如下：
$ sort testfile LiSi            80MaLiu           88WangWu          90ZhangSan        70

sort 命令默认情况下将第一列以 ASCII 码的次序排列，并将结果输出到标准输出。
根据第N列排序对于测试文件而言，或许我们更希望使用数字来统计排序，此时可以使用-k N参数，其中N为列数
$  sort testfile -k 2ZhangSan        70LiSi            80MaLiu           88WangWu          90



指定分隔符，进行排列此时默认的分隔符为空格，如果是其他分隔符，比如分毫
检查是否已经排序在某些情况下，或许只想看看文件是否已经排序，使用-c参数 ：
$  sort -c testfilesort: testfile:2: disorder

如果没有排序会有输出，而排序的话就没有输出。
逆序排列如果希望看一下数字从高到低的培训，使用-r参数：
$  sort testfile -k 2  -rWangWu          90MaLiu           88LiSi            80ZhangSan        70









对一个使用冒号分隔的文件的第二项进行排序
$ sort -t: -k 2 names.txt
对使用tab分隔的第三项进行排序**(department_id),**并去掉重复项 
$ sort -t: -u -k 3 names.txt
对passwd文件的第三项进行排序**(userid)**
$ sort -t: -k 3n /etc/passwd | more
基于ip地址对**/etc/hosts**文件排序 
$ sort -t . -k 1,1n -k 2,2n -k 3,3n -k 4,4n /etc/hosts
与其它命令组合在一起使用 
ps –ef | sort : 对进程列表进行排序
ls -al | sort +4n : 使用升序对ls -al的输出以文件大小进行排序(第5项) 
ls -al | sort +4nr : 使用降序对ls -al的输出以文件大小进行排序(第5项)
]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>sort</tag>
        <tag>数据处理</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux的 uniq 命令</title>
    <url>/2012/12/27/linux-sort/</url>
    <content><![CDATA[Linux的 sort 命令Linux sort 命令用于将文本内容进行排序。
官方定义为：

sort - sort lines of text files

语法$ sort [OPTION]... [FILE]...$ sort [OPTION]... --files0-from=F

常用的参数为：

-c 检查文件是否已经按照顺序排序。
-u 意味着是唯一的(unique)，输出的结果是去完重了的。
-r 以相反的顺序来排序。
-k field1[,field2] 按指定的列进行排序。

这里假定测试文件名为testfile：
LiSi            80ZhangSan        70WangWu          90MaLiu           88



默认无参数在使用 sort 命令以默认的式对文件的行进行排序，命令如下：
$ sort testfile LiSi            80MaLiu           88WangWu          90ZhangSan        70

sort 命令默认情况下将第一列以 ASCII 码的次序排列，并将结果输出到标准输出。
根据第N列排序对于测试文件而言，或许我们更希望使用数字来统计排序，此时可以使用-k N参数，其中N为列数
$  sort testfile -k 2ZhangSan        70LiSi            80MaLiu           88WangWu          90



检查是否已经排序在某些情况下，或许只想看看文件是否已经排序，使用-c参数 ：
$  sort -c testfilesort: testfile:2: disorder

如果没有排序会有输出，而排序的话就没有输出。
逆序排列如果希望看一下数字从高到低的培训，使用-r参数：
$  sort testfile -k 2  -rWangWu          90MaLiu           88LiSi            80ZhangSan        70








-b 忽略每行前面开始出的空格字符。

-d 排序时，处理英文字母、数字及空格字符外，忽略其他的字符。

-f 排序时，将小写字母视为大写字母。
-i 排序时，除了040至176之间的ASCII字符外，忽略其他的字符。

-m 将几个排序好的文件进行合并。

-M 将前面3个字母依照月份的缩写进行排序。

-n 依照数值的大小排序。

-o&lt;输出文件&gt; 将排序后的结果存入指定的文件。

-t&lt;分隔字符&gt; 指定排序时所用的栏位分隔字符。

+&lt;起始栏位&gt;-&lt;结束栏位&gt; 以指定的栏位来排序，范围由起始栏位到结束栏位的前一栏位。


]]></content>
      <categories>
        <category>Linux</category>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>uniq</tag>
      </tags>
  </entry>
  <entry>
    <title>阅后不即焚的source</title>
    <url>/2011/05/06/linux-source-beginner/</url>
    <content><![CDATA[阅后不即焚的source.. note::  去年今日此门中，人面桃花相映红。  崔护《题都城南庄》
在 shell 中执行程序时，shell 会提供一组环境变量。source命令是shell的内建指定，用的最多的还是配置参数的读取和设置。
source命令的功能是用于从指定文件中读取和执行命令，通常用于被修改过的文件，使之新参数能够立即生效，而不必重启整台服务器。
较常与export等结合使用。export 可以新增，修改或删除环境变量，供后续执行的程序使用。不过export 在终端退出后就失效了。
如果需要一直有效，可以考虑写入配置文件。
类似阅后即焚的export命令Linux export 命令用于设置或显示环境变量。比如如下所示：
$ export MYNAME='HELLOWORLD'$ echo $MYNAMEHELLOWORLD

不过在终端退出后，这个变量定义就不复存在了。
登陆即可使用的source指令source的用法一般如下所示：
$ source filename

比如最常用的：
$ source ~/.bash_profile

而对于第一个的设置，可以考虑将export MYNAME='HELLOWORLD'写入文件~/.bash_profile，这样每次登陆或者打开终端的时候都会自动载入了。
]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>export</tag>
        <tag>source</tag>
        <tag>bash内建命令</tag>
      </tags>
  </entry>
  <entry>
    <title>split - 精准快速定位</title>
    <url>/2014/01/15/linux-split-beginner/</url>
    <content><![CDATA[split - 精准划分Linux split命令用于将一个文件切分开，一般用于将大文件切分为多个小文件，方便数据传输、保持和校验等。
默认情况下将按照每1000行切割成一个小文件。
官方定义为：

 split - split a file into pieces

使用方法为：
$ split [OPTION]... [INPUT [PREFIX]]

常用的参数为：

-b, --bytes=SIZE : 指定每多少字节切成一个小文件

默认无参数默认情况下，split 会将原来的大文件aa 切割成多个以x开头的小文件，可以看到其实为xaa，xab，一致到xaz，递增为xba以此类推。
$ split aa$ ls -rw-rw-r-- 1 user user 611037792 Jan 15 22:09 aa-rw-rw-r-- 1 user user    356533 Jan 15 22:10 xaa-rw-rw-r-- 1 user user    377414 Jan 15 22:10 xab-rw-rw-r-- 1 user user    346342 Jan 15 22:10 xac-rw-rw-r-- 1 user user    358728 Jan 15 22:10 xad-rw-rw-r-- 1 user user    391466 Jan 15 22:10 xae-rw-rw-r-- 1 user user    368786 Jan 15 22:10 xaf-rw-rw-r-- 1 user user    377274 Jan 15 22:10 xag-rw-rw-r-- 1 user user    393500 Jan 15 22:10 xah-rw-rw-r-- 1 user user    362512 Jan 15 22:10 xai-rw-rw-r-- 1 user user    365170 Jan 15 22:10 xaj-rw-rw-r-- 1 user user    362878 Jan 15 22:10 xak-rw-rw-r-- 1 user user    387394 Jan 15 22:10 xal-rw-rw-r-- 1 user user    355614 Jan 15 22:10 xam-rw-rw-r-- 1 user user    366420 Jan 15 22:10 xan-rw-rw-r-- 1 user user    368912 Jan 15 22:10 xao-rw-rw-r-- 1 user user    350226 Jan 15 22:10 xap-rw-rw-r-- 1 user user    386102 Jan 15 22:10 xaq-rw-rw-r-- 1 user user    377292 Jan 15 22:10 xar-rw-rw-r-- 1 user user    376416 Jan 15 22:10 xas-rw-rw-r-- 1 user user    347584 Jan 15 22:10 xat-rw-rw-r-- 1 user user    376586 Jan 15 22:10 xau-rw-rw-r-- 1 user user    352778 Jan 15 22:10 xav-rw-rw-r-- 1 user user    380608 Jan 15 22:10 xaw-rw-rw-r-- 1 user user    356634 Jan 15 22:10 xax-rw-rw-r-- 1 user user    377414 Jan 15 22:10 xay-rw-rw-r-- 1 user user    346342 Jan 15 22:10 xaz



切分为1MB的文件可以使用-b参数，切分为准确字节的文件，如下：
$ split aa -b 1024000$ ll-rw-rw-r-- 1 user user 611037792 Jan 15 22:09 aa-rw-rw-r-- 1 user user   1024000 Jan 15 22:15 xaa-rw-rw-r-- 1 user user   1024000 Jan 15 22:15 xab-rw-rw-r-- 1 user user   1024000 Jan 15 22:15 xac-rw-rw-r-- 1 user user   1024000 Jan 15 22:15 xad-rw-rw-r-- 1 user user   1024000 Jan 15 22:15 xae-rw-rw-r-- 1 user user   1024000 Jan 15 22:15 xaf



指定前缀这个参数直接跟在输入的文件后面即可，如下：
$ split aa DAT$ lsaaDATaaDATabDATacDATadDATaeDATaf]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>split</tag>
      </tags>
  </entry>
  <entry>
    <title>远程登陆利器 ssh</title>
    <url>/2013/01/24/linux-ssh-beginner/</url>
    <content><![CDATA[远程登陆利器 sshssh命令是openssh套件中的客户端连接工具，使用加密协议实现安全的远程登录服务器，实现对服务器的远程管理。
官方定义为：

ssh — OpenSSH remote login client

使用方法为：
$ ssh [-46AaCfGgKkMNnqsTtVvXxYy] [-B bind_interface] [-b bind_address] [-c cipher_spec] [-D [bind_address:]port]         [-E log_file] [-e escape_char] [-F configfile] [-I pkcs11] [-i identity_file] [-J destination] [-L address]         [-l login_name] [-m mac_spec] [-O ctl_cmd] [-o option] [-p port] [-Q query_option] [-R address]         [-S ctl_path] [-W host:port] [-w local_tun[:remote_tun]] destination [command]

看着很复杂，确实也很复杂。
不过常用的参数倒是不多，基本为：

-l login_name  指定连接远程服务器的登录用户名
-p port  指定远程服务器上的端口

登陆远程服务器默认情况下，ssh直接跟上IP就可以，不过此时的登陆账户为本机的账户名，可以通过whoami得到，所以能登陆的前提是localname与服务器的username是一致的。
$ ssh 192.168.1.123localname@192.168.1.123's password:

此时输入密码即可登陆。
指定用户名大部分情况下，除非自己是管理员，可能远程登录名与本机名均不一致，此时需要指定登录名，参数-l即可搞定
$ ssh 192.168.1.123 -l usernameusername@192.168.1.123's password:

此时输入密码即可登陆。
多数情况的登陆方式我最初使用的当然就是这种方式了，username@IP地址。
$ ssh username@192.168.1.123username@192.168.1.123's password:Last login: Thu Jan 24 19:14:48 2013 from 192.168.111



查看服务器的时间有些时候可能登陆到服务器仅仅希望执行一些命令，比如看看服务器的时间是正确，服务器的负载如何，服务器的用户谁正在使用，此时可以在最后直接跟上命令，如下，单纯地看看服务器的时间：
$ ssh username@192.168.1.123 dateusername@192.168.1.123's password:Thu Jan 24 21:14:48 2013



指定端口还有一些服务器登陆是开放的并不是默认的22端口，有可能是12345端口，此时就需要指定该端口进行登陆，如下：
$ ssh username@192.168.1.123 -p 12345username@192.168.1.123's password:
]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>ssh</tag>
        <tag>known_hosts</tag>
        <tag>StrictHostKeyChecking</tag>
        <tag>fg</tag>
        <tag>hostkeys</tag>
        <tag>ssh-keygen</tag>
      </tags>
  </entry>
  <entry>
    <title>远程登录不需要密码</title>
    <url>/2016/02/12/linux-ssh-nopasswd-misc/</url>
    <content><![CDATA[远程登录不需要密码
在本机上操作ssh-keygen
ssh-copy-id -i .ssh/id_rsa.pub remote_username@remote_ipaddress
ssh remote_username@remote_ipaddress

背景最近参加了一个培训，分配了很多的账号，随便找个账号的密码，如下所示gyDYKdf39dk*dfs@&amp;，关键操作的过程中，你还需要打开多个终端。
那么问题来了，如何才能缩短这个浪费生命的无聊过程呢，方法很简单，只有3步。
远程登录不需要密码1 在本机上操作ssh-keygen，会在目录.ssh种生成一个id_rsa.pub文件 2 ssh-copy-id -i .ssh/id_rsa.pub remote_username@remote_ipaddress 3 ssh remote_username@remote_ipaddress
比如，来个实际操作：

打开一个终端 $ ssh-keygen 拷贝 $ ssh-copy-id -i .ssh/id_rsa.pub hero@192.168.2.3 愉快登录 $ ssh hero@192.168.2.3

此时即可无密码登陆remote了
在.ssh/config中输入下述信息，即可快捷将ssh remote_username@remote_ipaddress精简为ssh remote了
Host   remote    HostName 192.168.254.123    Port    22    User    hero    IdentityFile    ~/.ssh/id_rsa







The Ultimate Guide to SSH - Setting Up SSH Keys
Welcome to our ultimate guide to setting up SSH (Secure Shell) keys. This tutorial will walk you through the basics of creating SSH keys, and also how to manage multiple keys and key pairs.
Create a New SSH Key PairOpen a terminal and run the following command:
ssh-keygen

You will see the following text:
Generating public/private rsa key pair.Enter file in which to save the key (/home/username/.ssh/id_rsa):

Press enter to save your keys to the default /home/username/.ssh directory.
Then you’ll be prompted to enter a password:
Enter passphrase (empty for no passphrase):

It’s recommended to enter a password here for an extra layer of security. By setting a password, you could prevent unauthorized access to your servers and accounts if someone ever gets a hold of your private SSH key or your machine.
After entering and confirming your password, you’ll see the following:
Your identification has been saved in /home/username/.ssh/id_rsa.Your public key has been saved in /home/username/.ssh/id_rsa.pub.The key fingerprint is:SHA256:/qRoWhRcIBTw0D4KpTUyK6YepyL6RQ2CQrtWsaicCb4 username@871e129f767bThe key's randomart image is:+---[RSA 2048]----+| .o=+....        ||+.*o+o .         ||+X.=o o          ||@.=.oo .         ||=O ...o S        ||o.oo . .         ||.E+ . . . .      ||oo . ... +       ||=.. .o. . .      |+----[SHA256]-----+

You now have a public and private SSH key pair you can use to access remote servers and to handle authentication for command line programs like Git.
Manage Multiple SSH KeysThough it’s considered good practice to have only one public-private key pair per device, sometimes you need to use multiple keys or you have unorthodox key names. For example, you might be using one SSH key pair for working on your company’s internal projects, but you might be using a different key for accessing a client’s servers. On top of that, you might be using a different key pair for accessing your own private server.
Managing SSH keys can become cumbersome as soon as you need to use a second key. Traditionally, you would use ssh-add to store your keys to ssh-agent, typing in the password for each key. The problem is that you would need to do this every time you restart your computer, which can quickly become tedious.
A better solution is to automate adding keys, store passwords, and to specify which key to use when accessing certain servers.
SSH configEnter SSH config, which is a per-user configuration file for SSH communication. Create a new file: ~/.ssh/config and open it for editing:
nano ~/.ssh/config

Managing Custom Named SSH keyThe first thing we are going to solve using this config file is to avoid having to add custom-named SSH keys using ssh-add. Assuming your private SSH key is named ~/.ssh/id_rsa, add following to the config file:
Host github.com  HostName github.com  User git  IdentityFile ~/.ssh/id_rsa  IdentitiesOnly yes

Next, make sure that ~/.ssh/id_rsa is not in ssh-agent by opening another terminal and running the following command:
ssh-add -D

This command will remove all keys from currently active ssh-agent session.
Now if you try closing a GitHub repository, your config file will use the key at ~/.ssh/ida_rsa.
Here are some other useful configuration examples:
Host bitbucket-corporate        HostName bitbucket.org        User git        IdentityFile ~/.ssh/id_rsa_corp        IdentitiesOnly yes

Now you can use git clone git@bitbucket-corporate:company/project.git
Host bitbucket-personal        HostName bitbucket.org        User git        IdentityFile ~/.ssh/id_rsa_personal        IdentitiesOnly yes

Now you can use git clone git@bitbucket-personal:username/other-pi-project.git
Host myserver        HostName ssh.username.com        Port 1111        IdentityFile ~/.ssh/id_rsa_personal        IdentitiesOnly yes        User username        IdentitiesOnly yes

Now you can SSH into your server using ssh myserver. You no longer need to enter a port and username every time you SSH into your private server.
Password managementThe last piece of the puzzle is managing passwords. It can get very tedious entering a password every time you initialize an SSH connection. To get around this, we can use the password management software that comes with macOS and various Linux distributions.
For this tutorial we will use macOS’s Keychain Access program. Start by adding your key to the Keychain Access by passing -K option to the ssh-add command:
ssh-add -K ~/.ssh/id_rsa_whatever

Now you can see your SSH key in Keychain Access:
But if you remove the keys from ssh-agent with ssh-add -D or restart your computer, you will be prompted for password again when you try to use SSH. Turns out there’s one more hoop to jump through. Open your SSH config file by running nano ~/.ssh/config and add the following:
Host *  AddKeysToAgent yes  UseKeychain yes

With that, whenever you run ssh it will look for keys in Keychain Access. If it finds one, you will no longer be prompted for a password. Keys will also automatically be added to ssh-agent every time you restart your machine.
Now that you know the basics of creating new SSH keys and managing multiple keys, go out and ssh to your heart’s content!
]]></content>
      <categories>
        <category>Linux炫技</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>ssh</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux ssh命令</title>
    <url>/2013/01/24/linux-ssh/</url>
    <content><![CDATA[ssh远程登录必备神器接着ssh的入门操作 继续ssh的大杂烩。
官方定义为：

ssh — OpenSSH remote login client

使用方法为：
$ ssh [-46AaCfGgKkMNnqsTtVvXxYy] [-B bind_interface] [-b bind_address] [-c cipher_spec] [-D [bind_address:]port]         [-E log_file] [-e escape_char] [-F configfile] [-I pkcs11] [-i identity_file] [-J destination] [-L address]         [-l login_name] [-m mac_spec] [-O ctl_cmd] [-o option] [-p port] [-Q query_option] [-R address]         [-S ctl_path] [-W host:port] [-w local_tun[:remote_tun]] destination [command]



除了前面说的参数外，还有下面的一些参数：
取消使用ssh时需要输入密码的方法有些时候，我们在复制/移动文件到另一台机器时会用到scp，因为它比较安全，但对于远端服务器如果每次都要输入密码，就比较烦了，尤其是在脚本里面，3、5个文件还能接受，如果传输1000个文件就需要输入1000遍密码。
所以此时ssh就有了有另一种用密钥对来验证的方式，具体方式如下：

第一步：生成密匙对，我用的是rsa密钥。使用命令 ssh-keygen -t rsa，直接回车就可以；
修改目录的权限chmod 755 ~/.ssh；
将公共密钥复制的远程机器scp ~/.ssh/id_rsa.pub  remoteIP:/home/username/
将公共密钥添加到cat ~/.ssh/id_rsa.pub &gt;&gt; /home/username/.ssh/authorized_keys

看着蛮复杂的，其实就是把本机的公钥告诉远程服务器，就可以不用输入秘钥就可以登陆了。
还有一种简单的方法，如下：

第一步：生成密匙对，我用的是rsa密钥。使用命令 ssh-keygen -t rsa，直接回车就可以；
然后使用ssh-copy-id username@IP既可完成。

此时即可在使用ssh、scp、sftp的时候不用输入密码了。
使用自定义名来取代用户名@IP的方法当前的情况是，远程登陆还需要输入诸如ssh username@192.168.111.123，每次都敲又臭又长的IP地址十分难以忍受，很难想象如果使用IPv6，会是多么崩溃的情况。
所以如果可以使用ssh work登陆工作机，ssh school登陆学校机，将是一件十分幸福的事情。
方法很简单，创建文件~./ssh/config，内容如下：
Host work  User username  HostName 192.168.0.120  Host school  User username  HostName 192.168.0.110  



在设定好上面的配置文件后，在搭配免密输入，那么此时的
$ ssh work

将等效于
$ ssh username@192.168.0.120

以下类似。
Enjoy~
#####待分享
ssh中“Host key verification failed.“的解决方案前面说过有个比较简单的方式是直接删除ssh的记录文件即可，即：
mv ~/.ssh/known_hosts /tmp

而对于比较永久的考虑，可以修改ssh的配置文件，即：
SSH对主机的public_key的检查等级是根据StrictHostKeyChecking变量来配置的。默认情况下，StrictHostKeyChecking=ask。简单所下它的三种配置值：

StrictHostKeyChecking=no  #最不安全的级别，当然也没有那么多烦人的提示了，相对安全的内网测试时建议使用。如果连接server的key在本地不存在，那么就自动添加到文件中（默认是known_hosts），并且给出一个警告。
StrictHostKeyChecking=ask  #默认的级别，就是出现刚才的提示了。如果连接和key不匹配，给出提示，并拒绝登录。
StrictHostKeyChecking=yes  #最安全的级别，如果连接与key不匹配，就拒绝连接，不会提示详细信息。

我们可以设置：StrictHostKeyChecking=no这样就不会出现这个问题了。
用SSH退出符切换SSH会话这个技巧非常实用。尤其是远程登陆到一台主机A，然后从A登陆到B，如果希望在A上做一些操作，还得再开一个终端，很是麻烦。
当你已经登录到了远程主机时，你可能想要回到本地主机进行一些操作，然后又继续回到远程主机。在这种情况下，没有必要断开远程主机的会话，你可以用下面的办法来完成：

登入远程主机：



$ ssh remote1@remotehost


已连接远程主机：



remotehost$

要临时回到本地主机，输入退出符号：“~”与“Control-Z”组合


现在你已经退回到了本地主机，ssh远程客户端会话就在UNIX后台中运行，你可以向下面那样查看它：



localhost$ jobs[1]+ Stopped ssh -l remote1 remotehost


你可以将后台运行的ssh会话进程切换到前台，重新回到远程主机，而无需输入密码



localhost$ fg %1ssh remote1@remotehost remotehost$

调试SSH客户端会话当ssh连接出现问题时，我们需要通过查看调试信息来定位这些错误。一般来讲使用v选项(注意：是小写的v)，即可查看调试信息。
不加调试的使用方法为：
$ssh -l  username remotehost.example.com

增加调试的使用方法为：
$ssh –v -l  username remotehost.example.com

如此这般，机会出现比较详细的debug信息了。
用SSH登录到远程主机当你第一次使用ssh登录远程主机时，会出现没有找到主机密钥的提示信息。输入“yes”后，系统会将远程主机的密钥加入到你的主目录下的 .ssh/hostkeys下，这样你就可以继续操作了。
使用方法为：
$ssh -l  username remotehost.example.com

因为远程主机的密钥已经加入到ssh客户端的已知主机列表中，当你第二次登陆远程主机时，只需要你输入远程主机的登录密码即可。
由于各种原因，可能在你第一次登陆远程主机后，该主机的密钥发生改变，你将会看到一些警告信息。出现这种情况，可能有两个原因：

系统管理员在远程主机上升级或者重新安装了SSH服务器
有人在进行一些恶意行为，等等。

此时你可以通过删除hostkeys来解决。
解决SSH一段时间不操作就退出的问题在CentOS系统上，SSH登录后，一段时间如果不操作，SSH就会自动退出。
解决这个问题的办法，可以修改SSH服务器端的配置，也可以修改SSH客户端的配置。
修改SSH服务端的配置$ sudo vim /etc/ssd/sshd_config

把下面这两行的注册打开，然后修改参数：
ClientAliveInterval 30 # 表示每30秒服务器向客户端发起一次心跳，如果客户端响应就保持连接ClientAliveCountMax 5 # 如果连续5服务器收不到心跳，就断开连接

以上两个参数，可以根据自己的情况来设置。
最后，配置要生效，需要重启sshd服务：
$ service sshd restart

正常情况，客户端不会不响应服务器的心跳，因此SSH客户端就不会再自动退出了。
修改SSH客户端的配置修改客户端的配置的好处是，不需要重启服务端，如果你没有权限修改SSH服务器，也只能修改客户端的配置了。
$ sudo vim /etc/ssh/ssh_config

增加如下内容：
TCPKeepAlive yes # 据说这个配置项默认是开启的ServerAliveInterval 30  #客户端主动向服务端请求响应的间隔ServerAliveCountMax 5 # 连续5此客户端收不到服务器的响应，就是退出链接

好像大家都不太喜欢修改客户端的配置，而更新换直接在ssh命令行上输入这些配置项：
$ ssh -o TCPKeepAlive=yes -o ServerAliveInterval=30 -o ServerAliveCountMax=5 username@serverip

使用的是-o参数。
描述
ssh (ssh client)旨在促进在不安全的网络上提供两个不受信任的主机之间的安全加密通信。
支持多种协议。
如果指定了命令，它将在远程主机上执行，而不是在登录shell上执行。
 -4      强制ssh只使用IPv4地址
 -6      强制ssh仅使用IPv6地址
 -A      允许从认证代理(如ssh-agent)转发连接，慎用，有风险。最好使用下面的跳转主机方法(参见-J)
 -a      禁止转发认证代理连接
 -B bind_interface 在连接到目标主机之前，绑定到bind_interface地址，在系统有多个IP地址时有用。
 -b bind_address 在本地机器上使用bind_address作为连接的源地址，在系统有多个IP地址时有用。
 -E log_file  将调试日志追加到log_file文件而不是标准错误

​​​​​​​     -e escape_char             Sets the escape character for sessions with a pty (default: ‘~’).  The escape character is only recognized at the beginning of             a line.  The escape character followed by a dot (‘.’) closes the connection; followed by control-Z suspends the connection; and             followed by itself sends the escape character once.  Setting the character to “none” disables any escapes and makes the session   fully transparent.
 -F configfile
         Specifies an alternative per-user configuration file.  If a configuration file is given on the command line, the system-wide
         configuration file (/etc/ssh/ssh_config) will be ignored.  The default for the per-user configuration file is ~/.ssh/config.

 -f      Requests ssh to go to background just before command execution.  This is useful if ssh is going to ask for passwords or
         passphrases, but the user wants it in the background.  This implies -n.  The recommended way to start X11 programs at a remote  site is with something like ssh -f host xterm.

         If the ExitOnForwardFailure configuration option is set to “yes”, then a client started with -f will wait for all remote port  forwards to be successfully established before placing itself in the background.

 -G      Causes ssh to print its configuration after evaluating Host and Match blocks and exit.

 -g      Allows remote hosts to connect to local forwarded ports.  If used on a multiplexed connection, then this option must be specified on the master process.

 -I pkcs11
         Specify the PKCS#11 shared library ssh should use to communicate with a PKCS#11 token providing keys for user authentication.

 -i identity_file
         Selects a file from which the identity (private key) for public key authentication is read.  The default is ~/.ssh/id_dsa,
         ~/.ssh/id_ecdsa, ~/.ssh/id_ecdsa_sk, ~/.ssh/id_ed25519, ~/.ssh/id_ed25519_sk and ~/.ssh/id_rsa.  Identity files may also be
         specified on a per-host basis in the configuration file.  It is possible to have multiple -i options (and multiple identities
         specified in configuration files).  If no certificates have been explicitly specified by the CertificateFile directive, ssh
         will also try to load certificate information from the filename obtained by appending -cert.pub to identity filenames.

 -J destination
         Connect to the target host by first making a ssh connection to the jump host described by destination and then establishing a
         TCP forwarding to the ultimate destination from there.  Multiple jump hops may be specified separated by comma characters.
         This is a shortcut to specify a ProxyJump configuration directive.  Note that configuration directives supplied on the command-
         line generally apply to the destination host and not any specified jump hosts.  Use ~/.ssh/config to specify configuration for
         jump hosts.

 -K      Enables GSSAPI-based authentication and forwarding (delegation) of GSSAPI credentials to the server.

 -k      Disables forwarding (delegation) of GSSAPI credentials to the server.

 -L [bind_address:]port:host:hostport
 -L [bind_address:]port:remote_socket
 -L local_socket:host:hostport
 -L local_socket:remote_socket
         Specifies that connections to the given TCP port or Unix socket on the local (client) host are to be forwarded to the given   host and port, or Unix socket, on the remote side.  This works by allocating a socket to listen to either a TCP port on the local side, optionally bound to the specified bind_address, or to a Unix socket.  Whenever a connection is made to the local port or socket, the connection is forwarded over the secure channel, and a connection is made to either host port hostport, or the   Unix socket remote_socket, from the remote machine.

         Port forwardings can also be specified in the configuration file.  Only the superuser can forward privileged ports.  IPv6 addresses can be specified by enclosing the address in square brackets.

         By default, the local port is bound in accordance with the GatewayPorts setting.  However, an explicit bind_address may be used  to bind the connection to a specific address.  The bind_address of “localhost” indicates that the listening port be bound for
         local use only, while an empty address or ‘*’ indicates that the port should be available from all interfaces.


 -M      Places the ssh client into “master” mode for connection sharing.  Multiple -M options places ssh into “master” mode but with   confirmation required using ssh-askpass(1) before each operation that changes the multiplexing state (e.g. opening a new session).  Refer to the description of ControlMaster in ssh_config(5) for details.

 -m mac_spec
         A comma-separated list of MAC (message authentication code) algorithms, specified in order of preference.  See the MACs keyword
         for more information.

 -N      Do not execute a remote command.  This is useful for just forwarding ports.

 -n      Redirects stdin from /dev/null (actually, prevents reading from stdin).  This must be used when ssh is run in the background.
         A common trick is to use this to run X11 programs on a remote machine.  For example, ssh -n shadows.cs.hut.fi emacs &amp; will
         start an emacs on shadows.cs.hut.fi, and the X11 connection will be automatically forwarded over an encrypted channel.  The ssh
         program will be put in the background.  (This does not work if ssh needs to ask for a password or passphrase; see also the -f
         option.)

 -O ctl_cmd
         Control an active connection multiplexing master process.  When the -O option is specified, the ctl_cmd argument is interpreted
         and passed to the master process.  Valid commands are: “check” (check that the master process is running), “forward” (request
         forwardings without command execution), “cancel” (cancel forwardings), “exit” (request the master to exit), and “stop” (request
         the master to stop accepting further multiplexing requests).

 -o option
         Can be used to give options in the format used in the configuration file.  This is useful for specifying options for which
         there is no separate command-line flag.  For full details of the options listed below, and their possible values, see
         ssh_config(5).

               AddKeysToAgent
               AddressFamily
               BatchMode
               BindAddress
               CanonicalDomains
               CanonicalizeFallbackLocal
               CanonicalizeHostname
               CanonicalizeMaxDots
               CanonicalizePermittedCNAMEs
               CASignatureAlgorithms
               CertificateFile
               ChallengeResponseAuthentication
               CheckHostIP
               Ciphers
               ClearAllForwardings
               Compression
               ConnectionAttempts
               ConnectTimeout
               ControlMaster
               ControlPath
               ControlPersist
               DynamicForward
               EscapeChar
               ExitOnForwardFailure
               FingerprintHash
               ForwardAgent
               ForwardX11
               ForwardX11Timeout
               ForwardX11Trusted
               GatewayPorts
               GlobalKnownHostsFile
               GSSAPIAuthentication
               GSSAPIKeyExchange
               GSSAPIClientIdentity
               GSSAPIDelegateCredentials
               GSSAPIKexAlgorithms
               GSSAPIRenewalForcesRekey
               GSSAPIServerIdentity
               GSSAPITrustDns
               HashKnownHosts
               Host
               HostbasedAuthentication
               HostbasedKeyTypes
               HostKeyAlgorithms
               HostKeyAlias
               Hostname
               IdentitiesOnly
               IdentityAgent
               IdentityFile
               IPQoS
               KbdInteractiveAuthentication
               KbdInteractiveDevices
               KexAlgorithms
               LocalCommand
               LocalForward
               LogLevel
               MACs
               Match
               NoHostAuthenticationForLocalhost
               NumberOfPasswordPrompts
               PasswordAuthentication
               PermitLocalCommand
               PKCS11Provider
               Port
               PreferredAuthentications
               ProxyCommand
               ProxyJump
               ProxyUseFdpass
               PubkeyAcceptedKeyTypes
               PubkeyAuthentication
               RekeyLimit
               RemoteCommand
               RemoteForward
               RequestTTY
               SendEnv
               ServerAliveInterval
               ServerAliveCountMax
               SetEnv
               StreamLocalBindMask
               StreamLocalBindUnlink
               StrictHostKeyChecking
               TCPKeepAlive
               Tunnel
               TunnelDevice
               UpdateHostKeys
               User
               UserKnownHostsFile
               VerifyHostKeyDNS
               VisualHostKey
               XAuthLocation

 -Q query_option
         Queries ssh for the algorithms supported for the specified version 2.  The available features are: cipher (supported symmetric
         ciphers), cipher-auth (supported symmetric ciphers that support authenticated encryption), help (supported query terms for use
         with the -Q flag), mac (supported message integrity codes), kex (key exchange algorithms), kex-gss (GSSAPI key exchange algo‐
         rithms), key (key types), key-cert (certificate key types), key-plain (non-certificate key types), key-sig (all key types and
         signature algorithms), protocol-version (supported SSH protocol versions), and sig (supported signature algorithms).  Alterna‐
         tively, any keyword from ssh_config(5) or sshd_config(5) that takes an algorithm list may be used as an alias for the corre‐
         sponding query_option.

 -q      Quiet mode.  Causes most warning and diagnostic messages to be suppressed.

 -R [bind_address:]port:host:hostport
 -R [bind_address:]port:local_socket
 -R remote_socket:host:hostport
 -R remote_socket:local_socket
 -R [bind_address:]port
         Specifies that connections to the given TCP port or Unix socket on the remote (server) host are to be forwarded to the local
         side.

         This works by allocating a socket to listen to either a TCP port or to a Unix socket on the remote side.  Whenever a connection
         is made to this port or Unix socket, the connection is forwarded over the secure channel, and a connection is made from the lo‐
         cal machine to either an explicit destination specified by host port hostport, or local_socket, or, if no explicit destination
         was specified, ssh will act as a SOCKS 4/5 proxy and forward connections to the destinations requested by the remote SOCKS
         client.

         Port forwardings can also be specified in the configuration file.  Privileged ports can be forwarded only when logging in as
         root on the remote machine.  IPv6 addresses can be specified by enclosing the address in square brackets.

         By default, TCP listening sockets on the server will be bound to the loopback interface only.  This may be overridden by speci‐
         fying a bind_address.  An empty bind_address, or the address ‘*’, indicates that the remote socket should listen on all inter‐
         faces.  Specifying a remote bind_address will only succeed if the server's GatewayPorts option is enabled (see sshd_config(5)).

         If the port argument is ‘0’, the listen port will be dynamically allocated on the server and reported to the client at run
         time.  When used together with -O forward the allocated port will be printed to the standard output.

 -S ctl_path
         Specifies the location of a control socket for connection sharing, or the string “none” to disable connection sharing.  Refer
         to the description of ControlPath and ControlMaster in ssh_config(5) for details.

 -s      May be used to request invocation of a subsystem on the remote system.  Subsystems facilitate the use of SSH as a secure trans‐
         port for other applications (e.g. sftp(1)).  The subsystem is specified as the remote command.

 -T      Disable pseudo-terminal allocation.

 -t      Force pseudo-terminal allocation.  This can be used to execute arbitrary screen-based programs on a remote machine, which can
         be very useful, e.g. when implementing menu services.  Multiple -t options force tty allocation, even if ssh has no local tty.

 -V      Display the version number and exit.

 -v      Verbose mode.  Causes ssh to print debugging messages about its progress.  This is helpful in debugging connection, authentica‐
         tion, and configuration problems.  Multiple -v options increase the verbosity.  The maximum is 3.

 -W host:port
         Requests that standard input and output on the client be forwarded to host on port over the secure channel.  Implies -N, -T,
         ExitOnForwardFailure and ClearAllForwardings, though these can be overridden in the configuration file or using -o command line
         options.

 -w local_tun[:remote_tun]
         Requests tunnel device forwarding with the specified tun(4) devices between the client (local_tun) and the server (remote_tun).

         The devices may be specified by numerical ID or the keyword “any”, which uses the next available tunnel device.  If remote_tun
         is not specified, it defaults to “any”.  See also the Tunnel and TunnelDevice directives in ssh_config(5).

         If the Tunnel directive is unset, it will be set to the default tunnel mode, which is “point-to-point”.  If a different Tunnel
         forwarding mode it desired, then it should be specified before -w.

 -X      Enables X11 forwarding.  This can also be specified on a per-host basis in a configuration file.

         X11 forwarding should be enabled with caution.  Users with the ability to bypass file permissions on the remote host (for the
         user's X authorization database) can access the local X11 display through the forwarded connection.  An attacker may then be
         able to perform activities such as keystroke monitoring.

         For this reason, X11 forwarding is subjected to X11 SECURITY extension restrictions by default.  Please refer to the ssh -Y op‐
         tion and the ForwardX11Trusted directive in ssh_config(5) for more information.

         (Debian-specific: X11 forwarding is not subjected to X11 SECURITY extension restrictions by default, because too many programs
         currently crash in this mode.  Set the ForwardX11Trusted option to “no” to restore the upstream behaviour.  This may change in
         future depending on client-side improvements.)

 -x      Disables X11 forwarding.

 -Y      Enables trusted X11 forwarding.  Trusted X11 forwardings are not subjected to the X11 SECURITY extension controls.

         (Debian-specific: In the default configuration, this option is equivalent to -X, since ForwardX11Trusted defaults to “yes” as
         described above.  Set the ForwardX11Trusted option to “no” to restore the upstream behaviour.  This may change in future de‐
         pending on client-side improvements.)

 -y      Send log information using the syslog(3) system module.  By default this information is sent to stderr.

 ssh may additionally obtain configuration data from a per-user configuration file and a system-wide configuration file.  The file for‐
 mat and configuration options are described in ssh_config(5).

AUTHENTICATION     The OpenSSH SSH client supports SSH protocol 2.
 The methods available for authentication are: GSSAPI-based authentication, host-based authentication, public key authentication, chal‐
 lenge-response authentication, and password authentication.  Authentication methods are tried in the order specified above, though
 PreferredAuthentications can be used to change the default order.

 Host-based authentication works as follows: If the machine the user logs in from is listed in /etc/hosts.equiv or /etc/ssh/shosts.equiv
 on the remote machine, and the user names are the same on both sides, or if the files ~/.rhosts or ~/.shosts exist in the user's home
 directory on the remote machine and contain a line containing the name of the client machine and the name of the user on that machine,
 the user is considered for login.  Additionally, the server must be able to verify the client's host key (see the description of
 /etc/ssh/ssh_known_hosts and ~/.ssh/known_hosts, below) for login to be permitted.  This authentication method closes security holes
 due to IP spoofing, DNS spoofing, and routing spoofing.  [Note to the administrator: /etc/hosts.equiv, ~/.rhosts, and the rlogin/rsh
 protocol in general, are inherently insecure and should be disabled if security is desired.]

 Public key authentication works as follows: The scheme is based on public-key cryptography, using cryptosystems where encryption and
 decryption are done using separate keys, and it is unfeasible to derive the decryption key from the encryption key.  The idea is that
 each user creates a public/private key pair for authentication purposes.  The server knows the public key, and only the user knows the
 private key.  ssh implements public key authentication protocol automatically, using one of the DSA, ECDSA, Ed25519 or RSA algorithms.
 The HISTORY section of ssl(8) (on non-OpenBSD systems, see http://www.openbsd.org/cgi-bin/man.cgi?query=ssl&amp;sektion=8#HISTORY) contains
 a brief discussion of the DSA and RSA algorithms.

 The file ~/.ssh/authorized_keys lists the public keys that are permitted for logging in.  When the user logs in, the ssh program tells
 the server which key pair it would like to use for authentication.  The client proves that it has access to the private key and the
 server checks that the corresponding public key is authorized to accept the account.

 The server may inform the client of errors that prevented public key authentication from succeeding after authentication completes us‐
 ing a different method.  These may be viewed by increasing the LogLevel to DEBUG or higher (e.g. by using the -v flag).

 The user creates his/her key pair by running ssh-keygen(1).  This stores the private key in ~/.ssh/id_dsa (DSA), ~/.ssh/id_ecdsa
 (ECDSA), ~/.ssh/id_ecdsa_sk (authenticator-hosted ECDSA), ~/.ssh/id_ed25519 (Ed25519), ~/.ssh/id_ed25519_sk (authenticator-hosted
 Ed25519), or ~/.ssh/id_rsa (RSA) and stores the public key in ~/.ssh/id_dsa.pub (DSA), ~/.ssh/id_ecdsa.pub (ECDSA),
 ~/.ssh/id_ecdsa_sk.pub (authenticator-hosted ECDSA), ~/.ssh/id_ed25519.pub (Ed25519), ~/.ssh/id_ed25519_sk.pub (authenticator-hosted
 Ed25519), or ~/.ssh/id_rsa.pub (RSA) in the user's home directory.  The user should then copy the public key to ~/.ssh/authorized_keys
 in his/her home directory on the remote machine.  The authorized_keys file corresponds to the conventional ~/.rhosts file, and has one
 key per line, though the lines can be very long.  After this, the user can log in without giving the password.

 A variation on public key authentication is available in the form of certificate authentication: instead of a set of public/private
 keys, signed certificates are used.  This has the advantage that a single trusted certification authority can be used in place of many
 public/private keys.  See the CERTIFICATES section of ssh-keygen(1) for more information.

 The most convenient way to use public key or certificate authentication may be with an authentication agent.  See ssh-agent(1) and (op‐
 tionally) the AddKeysToAgent directive in ssh_config(5) for more information.

 Challenge-response authentication works as follows: The server sends an arbitrary "challenge" text, and prompts for a response.  Exam‐
 ples of challenge-response authentication include BSD Authentication (see login.conf(5)) and PAM (some non-OpenBSD systems).

 Finally, if other authentication methods fail, ssh prompts the user for a password.  The password is sent to the remote host for check‐
 ing; however, since all communications are encrypted, the password cannot be seen by someone listening on the network.

 ssh automatically maintains and checks a database containing identification for all hosts it has ever been used with.  Host keys are
 stored in ~/.ssh/known_hosts in the user's home directory.  Additionally, the file /etc/ssh/ssh_known_hosts is automatically checked
 for known hosts.  Any new hosts are automatically added to the user's file.  If a host's identification ever changes, ssh warns about
 this and disables password authentication to prevent server spoofing or man-in-the-middle attacks, which could otherwise be used to
 circumvent the encryption.  The StrictHostKeyChecking option can be used to control logins to machines whose host key is not known or
 has changed.

 When the user's identity has been accepted by the server, the server either executes the given command in a non-interactive session or,
 if no command has been specified, logs into the machine and gives the user a normal shell as an interactive session.  All communication
 with the remote command or shell will be automatically encrypted.

 If an interactive session is requested ssh by default will only request a pseudo-terminal (pty) for interactive sessions when the
 client has one.  The flags -T and -t can be used to override this behaviour.

 If a pseudo-terminal has been allocated the user may use the escape characters noted below.

 If no pseudo-terminal has been allocated, the session is transparent and can be used to reliably transfer binary data.  On most sys‐
 tems, setting the escape character to “none” will also make the session transparent even if a tty is used.

 The session terminates when the command or shell on the remote machine exits and all X11 and TCP connections have been closed.

ESCAPE CHARACTERS     When a pseudo-terminal has been requested, ssh supports a number of functions through the use of an escape character.
 A single tilde character can be sent as ~~ or by following the tilde by a character other than those described below.  The escape char‐
 acter must always follow a newline to be interpreted as special.  The escape character can be changed in configuration files using the
 EscapeChar configuration directive or on the command line by the -e option.

 The supported escapes (assuming the default ‘~’) are:

 ~.      Disconnect.

 ~^Z     Background ssh.

 ~#      List forwarded connections.

 ~&amp;      Background ssh at logout when waiting for forwarded connection / X11 sessions to terminate.

 ~?      Display a list of escape characters.

 ~B      Send a BREAK to the remote system (only useful if the peer supports it).

 ~C      Open command line.  Currently this allows the addition of port forwardings using the -L, -R and -D options (see above).  It
         also allows the cancellation of existing port-forwardings with -KL[bind_address:]port for local, -KR[bind_address:]port for re‐
         mote and -KD[bind_address:]port for dynamic port-forwardings.  !command allows the user to execute a local command if the
         PermitLocalCommand option is enabled in ssh_config(5).  Basic help is available, using the -h option.

 ~R      Request rekeying of the connection (only useful if the peer supports it).

 ~V      Decrease the verbosity (LogLevel) when errors are being written to stderr.

 ~v      Increase the verbosity (LogLevel) when errors are being written to stderr.

TCP FORWARDING     Forwarding of arbitrary TCP connections over a secure channel can be specified either on the command line or in a configuration file.     One possible application of TCP forwarding is a secure connection to a mail server; another is going through firewalls.
 In the example below, we look at encrypting communication for an IRC client, even though the IRC server it connects to does not di‐
 rectly support encrypted communication.  This works as follows: the user connects to the remote host using ssh, specifying the ports to
 be used to forward the connection.  After that it is possible to start the program locally, and ssh will encrypt and forward the con‐
 nection to the remote server.

 The following example tunnels an IRC session from the client to an IRC server at “server.example.com”, joining channel “#users”, nick‐
 name “pinky”, using the standard IRC port, 6667:

     $ ssh -f -L 6667:localhost:6667 server.example.com sleep 10
     $ irc -c '#users' pinky IRC/127.0.0.1

 The -f option backgrounds ssh and the remote command “sleep 10” is specified to allow an amount of time (10 seconds, in the example) to
 start the program which is going to use the tunnel.  If no connections are made within the time specified, ssh will exit.

X11 FORWARDING     If the ForwardX11 variable is set to “yes” (or see the description of the -X, -x, and -Y options above) and the user is using X11 (the     DISPLAY environment variable is set), the connection to the X11 display is automatically forwarded to the remote side in such a way     that any X11 programs started from the shell (or command) will go through the encrypted channel, and the connection to the real X     server will be made from the local machine.  The user should not manually set DISPLAY.  Forwarding of X11 connections can be configured     on the command line or in configuration files.
 The DISPLAY value set by ssh will point to the server machine, but with a display number greater than zero.  This is normal, and hap‐
 pens because ssh creates a “proxy” X server on the server machine for forwarding the connections over the encrypted channel.

 ssh will also automatically set up Xauthority data on the server machine.  For this purpose, it will generate a random authorization
 cookie, store it in Xauthority on the server, and verify that any forwarded connections carry this cookie and replace it by the real
 cookie when the connection is opened.  The real authentication cookie is never sent to the server machine (and no cookies are sent in
 the plain).

 If the ForwardAgent variable is set to “yes” (or see the description of the -A and -a options above) and the user is using an authenti‐
 cation agent, the connection to the agent is automatically forwarded to the remote side.

VERIFYING HOST KEYS     When connecting to a server for the first time, a fingerprint of the server’s public key is presented to the user (unless the option     StrictHostKeyChecking has been disabled).  Fingerprints can be determined using ssh-keygen(1):
       $ ssh-keygen -l -f /etc/ssh/ssh_host_rsa_key

 If the fingerprint is already known, it can be matched and the key can be accepted or rejected.  If only legacy (MD5) fingerprints for
 the server are available, the ssh-keygen(1) -E option may be used to downgrade the fingerprint algorithm to match.

 Because of the difficulty of comparing host keys just by looking at fingerprint strings, there is also support to compare host keys
 visually, using random art.  By setting the VisualHostKey option to “yes”, a small ASCII graphic gets displayed on every login to a
 server, no matter if the session itself is interactive or not.  By learning the pattern a known server produces, a user can easily find
 out that the host key has changed when a completely different pattern is displayed.  Because these patterns are not unambiguous how‐
 ever, a pattern that looks similar to the pattern remembered only gives a good probability that the host key is the same, not guaran‐
 teed proof.

 To get a listing of the fingerprints along with their random art for all known hosts, the following command line can be used:

       $ ssh-keygen -lv -f ~/.ssh/known_hosts

 If the fingerprint is unknown, an alternative method of verification is available: SSH fingerprints verified by DNS.  An additional re‐
 source record (RR), SSHFP, is added to a zonefile and the connecting client is able to match the fingerprint with that of the key pre‐
 sented.

 In this example, we are connecting a client to a server, “host.example.com”.  The SSHFP resource records should first be added to the
 zonefile for host.example.com:

       $ ssh-keygen -r host.example.com.

 The output lines will have to be added to the zonefile.  To check that the zone is answering fingerprint queries:

       $ dig -t SSHFP host.example.com

 Finally the client connects:

       $ ssh -o "VerifyHostKeyDNS ask" host.example.com
       [...]
       Matching host key fingerprint found in DNS.
       Are you sure you want to continue connecting (yes/no)?

 See the VerifyHostKeyDNS option in ssh_config(5) for more information.

SSH-BASED VIRTUAL PRIVATE NETWORKS     ssh contains support for Virtual Private Network (VPN) tunnelling using the tun(4) network pseudo-device, allowing two networks to be     joined securely.  The sshd_config(5) configuration option PermitTunnel controls whether the server supports this, and at what level     (layer 2 or 3 traffic).
 The following example would connect client network 10.0.50.0/24 with remote network 10.0.99.0/24 using a point-to-point connection from
 10.1.1.1 to 10.1.1.2, provided that the SSH server running on the gateway to the remote network, at 192.168.1.15, allows it.

 On the client:

       # ssh -f -w 0:1 192.168.1.15 true
       # ifconfig tun0 10.1.1.1 10.1.1.2 netmask 255.255.255.252
       # route add 10.0.99.0/24 10.1.1.2

 On the server:

       # ifconfig tun1 10.1.1.2 10.1.1.1 netmask 255.255.255.252
       # route add 10.0.50.0/24 10.1.1.1

 Client access may be more finely tuned via the /root/.ssh/authorized_keys file (see below) and the PermitRootLogin server option.  The
 following entry would permit connections on tun(4) device 1 from user “jane” and on tun device 2 from user “john”, if PermitRootLogin
 is set to “forced-commands-only”:

   tunnel="1",command="sh /etc/netstart tun1" ssh-rsa ... jane
   tunnel="2",command="sh /etc/netstart tun2" ssh-rsa ... john

 Since an SSH-based setup entails a fair amount of overhead, it may be more suited to temporary setups, such as for wireless VPNs.  More
 permanent VPNs are better provided by tools such as ipsecctl(8) and isakmpd(8).

ENVIRONMENT     ssh will normally set the following environment variables:
 DISPLAY               The DISPLAY variable indicates the location of the X11 server.  It is automatically set by ssh to point to a
                       value of the form “hostname:n”, where “hostname” indicates the host where the shell runs, and ‘n’ is an integer ≥
                       1.  ssh uses this special value to forward X11 connections over the secure channel.  The user should normally not
                       set DISPLAY explicitly, as that will render the X11 connection insecure (and will require the user to manually
                       copy any required authorization cookies).

 HOME                  Set to the path of the user's home directory.

 LOGNAME               Synonym for USER; set for compatibility with systems that use this variable.

 MAIL                  Set to the path of the user's mailbox.

 PATH                  Set to the default PATH, as specified when compiling ssh.

 SSH_ASKPASS           If ssh needs a passphrase, it will read the passphrase from the current terminal if it was run from a terminal.
                       If ssh does not have a terminal associated with it but DISPLAY and SSH_ASKPASS are set, it will execute the pro‐
                       gram specified by SSH_ASKPASS and open an X11 window to read the passphrase.  This is particularly useful when
                       calling ssh from a .xsession or related script.  (Note that on some machines it may be necessary to redirect the
                       input from /dev/null to make this work.)

 SSH_AUTH_SOCK         Identifies the path of a UNIX-domain socket used to communicate with the agent.

 SSH_CONNECTION        Identifies the client and server ends of the connection.  The variable contains four space-separated values:
                       client IP address, client port number, server IP address, and server port number.

 SSH_ORIGINAL_COMMAND  This variable contains the original command line if a forced command is executed.  It can be used to extract the
                       original arguments.

 SSH_TTY               This is set to the name of the tty (path to the device) associated with the current shell or command.  If the
                       current session has no tty, this variable is not set.

 SSH_TUNNEL            Optionally set by sshd(8) to contain the interface names assigned if tunnel forwarding was requested by the
                       client.

 SSH_USER_AUTH         Optionally set by sshd(8), this variable may contain a pathname to a file that lists the authentication methods
                       successfully used when the session was established, including any public keys that were used.

 TZ                    This variable is set to indicate the present time zone if it was set when the daemon was started (i.e. the daemon
                       passes the value on to new connections).

 USER                  Set to the name of the user logging in.

 Additionally, ssh reads ~/.ssh/environment, and adds lines of the format “VARNAME=value” to the environment if the file exists and
 users are allowed to change their environment.  For more information, see the PermitUserEnvironment option in sshd_config(5).

FILES     ~/.rhosts             This file is used for host-based authentication (see above).  On some machines this file may need to be world-readable if the             user’s home directory is on an NFS partition, because sshd(8) reads it as root.  Additionally, this file must be owned by the             user, and must not have write permissions for anyone else.  The recommended permission for most machines is read/write for the             user, and not accessible by others.
 ~/.shosts
         This file is used in exactly the same way as .rhosts, but allows host-based authentication without permitting login with  rlogin/rsh.

 ~/.ssh/
         This directory is the default location for all user-specific configuration and authentication information.  There is no general requirement to keep the entire contents of this directory secret, but the recommended permissions are read/write/execute for  the user, and not accessible by others.

 ~/.ssh/authorized_keys
         Lists the public keys (DSA, ECDSA, Ed25519, RSA) that can be used for logging in as this user.  The format of this file is described in the sshd(8) manual page.  This file is not highly sensitive, but the recommended permissions are read/write for the user, and not accessible by others.

 ~/.ssh/config
         This is the per-user configuration file.  The file format and configuration options are described in ssh_config(5).  Because of
         the potential for abuse, this file must have strict permissions: read/write for the user, and not writable by others.  It may
         be group-writable provided that the group in question contains only the user.

 ~/.ssh/environment
         Contains additional definitions for environment variables; see ENVIRONMENT, above.

 ~/.ssh/id_dsa
 ~/.ssh/id_ecdsa
 ~/.ssh/id_ecdsa_sk
 ~/.ssh/id_ed25519
 ~/.ssh/id_ed25519_sk
 ~/.ssh/id_rsa
         Contains the private key for authentication.  These files contain sensitive data and should be readable by the user but not accessible by others (read/write/execute).  ssh will simply ignore a private key file if it is accessible by others.  It is possible to specify a passphrase when generating the key which will be used to encrypt the sensitive part of this file using
         AES-128.

 ~/.ssh/id_dsa.pub
 ~/.ssh/id_ecdsa.pub
 ~/.ssh/id_ecdsa_sk.pub
 ~/.ssh/id_ed25519.pub
 ~/.ssh/id_ed25519_sk.pub
 ~/.ssh/id_rsa.pub
         Contains the public key for authentication.  These files are not sensitive and can (but need not) be readable by anyone.

 ~/.ssh/known_hosts
         Contains a list of host keys for all hosts the user has logged into that are not already in the systemwide list of known host
         keys.  See sshd(8) for further details of the format of this file.

 ~/.ssh/rc
         Commands in this file are executed by ssh when the user logs in, just before the user's shell (or command) is started. 

 /etc/hosts.equiv
         This file is for host-based authentication (see above).  It should only be writable by root.

 /etc/ssh/shosts.equiv
         This file is used in exactly the same way as hosts.equiv, but allows host-based authentication without permitting login with
         rlogin/rsh.

 /etc/ssh/ssh_config
         Systemwide configuration file.  The file format and configuration options are described in ssh_config(5).

 /etc/ssh/ssh_host_key
 /etc/ssh/ssh_host_dsa_key
 /etc/ssh/ssh_host_ecdsa_key
 /etc/ssh/ssh_host_ed25519_key
 /etc/ssh/ssh_host_rsa_key
         These files contain the private parts of the host keys and are used for host-based authentication.

 /etc/ssh/ssh_known_hosts
         Systemwide list of known host keys.  This file should be prepared by the system administrator to contain the public host keys  of all machines in the organization.  It should be world-readable.  See sshd(8) for further details of the format of this file.

 /etc/ssh/sshrc
         Commands in this file are executed by ssh when the user logs in, just before the user's shell (or command) is started.  See the         sshd(8) manual page for more information.


退出状态，如果成果返回远程命令的执行状态，出错的话返回255。

TODO -C      Requests compression of all data (including stdin, stdout, stderr, and data for forwarded X11, TCP and UNIX-domain connections).  The compression algorithm is the same used by gzip(1).  Compression is desirable on modem lines and other slow connections, but will only slow down things on fast networks.  The default value can be set on a host-by-host basis in the configuration files; see the Compression option.请求压缩所有数据(包括stdin, stdout, stderr，以及转发的X11, TCP和unix域连接的数据)。压缩算法与gzip(1)相同。压缩在调制解调器线路和其他慢速连接上是可取的，但只会在高速网络上减慢速度。可以在配置文件中对每个主机设置默认值;请参阅压缩选项。- c cipher_spec 选择加密会话的密码规范。Cipher_spec是一个以逗号分隔的密码列表，按优先级排列，包括aes256，aes128等加密算法。 -D [bind_address:]port 指定本地的应用级动态端口转发。它的工作原理是分配一个套接字来侦听本地端端口，可选地绑定到指定的bind_address。每当建立到此端口的连接时，该连接将通过安全通道转发，然后使用应用程序协议来确定从远程计算机连接到哪里。目前支持SOCKS4和SOCKS5协议，ssh将充当SOCKS服务器。只有root才能前进特权端口。动态端口转发也可以在配置文件中指定。IPv6地址可以通过将地址括在方括号中指定。只有超级用户才能转发特权端口。缺省情况下，本地端口按照“GatewayPorts”设置进行绑定。但是，可以使用显式的bind_address将连接绑定到特定地址。localhost的bind_address表示要绑定的监听端口仅本地使用，而空地址或“*”表示端口应该从所有接口可用。

]]></content>
      <categories>
        <category>Linux大杂烩</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>ssh</tag>
        <tag>scp</tag>
        <tag>known_hosts</tag>
        <tag>StrictHostKeyChecking</tag>
        <tag>fg</tag>
        <tag>hostkeys</tag>
        <tag>ssh-keygen</tag>
        <tag>sftp</tag>
      </tags>
  </entry>
  <entry>
    <title>可追本溯源的 stat</title>
    <url>/2012/09/17/linux-stat-beginner/</url>
    <content><![CDATA[可追本溯源的 statLinux stat 命令用于显示 inode 内容。
话说这个inode是个什么东西呢？
对于存储在硬盘上的文件，特别是Linux的概念就是，一切皆文件 Everything is file。
其最小的存储单元为512字节即一个扇区sector；在读取文件的时候，为了提高效率，是按照4KB的块block来读取的，所以这样看来每次读取了8个sector。
而对于每个文件为了索引的便捷，其元数据的各种信息就是stat获取的，用于描述创建者、文件的各种日期、大小等等等等信息，这个元数据的id就可以认为是inode了，以上。
官方的定义为：

stat - display file or file system status

用法为：
$ stat [options] filename/directory



其中的参数为：

-L, --dereference : 不显示链接的原始文件

-f, --file-system ：显示文件系统状态

--printf=FORMAT ： 与C语言的类似，不过看着转义符更多一些

-t, --terse：超级简介的模式


最简单的使用最简单的其实也是最有用的，直接跟上文件或者目录，如下：
$ stat text.txt   File: ‘text.txt’  Size: 51        	Blocks: 8          IO Block: 4096   regular fileDevice: fd00h/64768d	Inode: 1610934260  Links: 1Access: (0664/-rw-rw-r--)  Uid: ( 1000/     user)   Gid: ( 1000/     user)Context: unconfined_u:object_r:user_tmp_t:s0Access: 2012-09-11 21:24:49.660510438 +0800Modify: 2012-09-09 17:31:54.518005296 +0800Change: 2012-09-09 17:33:09.670327180 +0800 Birth: -  $ stat dir  File: ‘dir’  Size: 51        	Blocks: 0          IO Block: 4096   directoryDevice: fd00h/64768d	Inode: 1610934255  Links: 2Access: (0775/drwxrwxr-x)  Uid: ( 1000/     user)   Gid: ( 1000/     user)Context: unconfined_u:object_r:user_tmp_t:s0Access: 2012-09-13 16:44:56.802331727 +0800Modify: 2012-09-13 16:44:55.624342864 +0800Change: 2012-09-13 16:44:55.624342864 +0800 Birth: -



各个段的解释为：

File：文件或文件夹名
Size：文件大小
Blocks：文件使用的数据块总数
IO Block：IO块大小
regular file：文件类型（常规文件）或者directory文件夹
Device：设备的编号
Inode：Inode号
Links：链接数
Access：文件的权限
Gid, Uid：文件所有者的Gid和Uid
Access：文件的访问时间
Modify：文件的修改时间
Change：文件的状态时间

显示文件系统参数-f将显示文件系统信息，可以看到Type：xfs这个信息。
$ stat -f text.txt   File: "text.txt"    ID: fd0000000000 Namelen: 255     Type: xfsBlock size: 4096       Fundamental block size: 4096Blocks: Total: 244020823  Free: 182831648  Available: 182831648Inodes: Total: 488280064  Free: 487587798



关于printf的那些格式化字符串--printf=FORMAT选项可以跟的FORMAT有很多，较常用为：



格式化字符串
含义



%A
易读的访问状态


%B
每个块的大小（单位为字节）


%d
十进制的设备号


%F
文件类型


%G
所有者的组名


%i
inode数字


%m
挂载点


%n
文件名


%s
总大小（单位：字节）


%U
所有者的用户名


%w
易读的文件生成时间（大写的为Epoch）


%x
易读的文件访问时间（大写的为Epoch）


%y
易读的文件修改时间（大写的为Epoch）


%z
易读的文件上一次修改状态时间（大写的为Epoch）


炫技 ： 一个类似ls -l的用法下面的这个命令可以实现类似ls -l的用法，可以扩展更多，也可以自定义使用，比如alias等等。
$ stat --print="%A. %U %G %s %x %n \n" text.txt -rw-rw-r--. user user 51 2012-09-11 21:24:49.660510438 +0800 text.txt

]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>stat</tag>
        <tag>Linux炫技</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux学习之道</title>
    <url>/2012/07/01/linux-study-method/</url>
    <content><![CDATA[Linux学习之道从http://www.linuxdiyf.com 看的。
做为中国人的特殊情况，学习linux对中国人来说要做的事情相对多了一些：

以linux为荣耀，以帮助他人了解和学习linux为己任。
坚持访问英文网站，尤其是一些大师的个人主页。坚持阅读英文文档，并尽量翻译你读过的文档发表到国内的社区上供他人阅读和整理
了解unix的历史，linux的历史和hacker的历史及文化。
尽可能联系所以可以联系到Linux的爱好者，尽可能多的了解你能接触到的最了解linux的人对linux的看法。并于自己的观点相比较。
空闲时思索为什么自己喜欢linux，别人为什么喜欢linux。为什么你们喜欢的理由不同？
阅读各类的开源许可协议和商业的用户许可协议。对比他们各有哪些问题和优势。

以上使你了解开源文化，是作为一个合格的linux社区成员的前提。

安装一个linux的发行版本。
尽你最大的能力把你的学习、娱乐或者工作的环境转移到linux上来。尽量避免寻找linux功能类似的软件，而是寻找linux下解决同样问题的通用的方法。并且对比同windows下的解决方法哪种更加优越。
学会SHELL编程。SHELL几乎可以作为一个入门语言来学习。最低的要求是能够看懂你自己的版本的linux的配置脚本。理解为什么一些帖子中里提到的配置方法回起作用，并了解你的发行版本怎样从每个配置文件中把设置用环境变量的形式读取并让他生效的。
学会安装以各种方式发行的程序，并且让他们的安装同你系统的惯例一致。熟悉X windows的运作方式。熟悉你的发行版本的安全机制，并且学会定制他们按你的需求工作。

如果仅仅是作为用户并且部分体会unix的哲学，上面的几点就足够了。个人认为这几点足够成长为一个合格的Linux用户了。甚至只要再稍稍的扩充就可以制作自己的发行版本了！而对于不同的用户群体，比如办公用户或者科研人员等。第8条意味着不同的标准。

选择一门或几门语言社区常用的编程语言。
搜集社区或者hackers推荐的图书或资料、网站、新闻组等。
选择一个较小的用你当前学习的语言开发的开源项目。阅读他的代码，并且对比他的代码和你形象的编写方式是否相同？哪种更加优越？
尝试按照TODO中的要求为这个软件编写代码，并且同他的作者联系。学习autoconf和automake等工具的用法。
你也可以不参与项目的开发，但仍然能从代码阅读中获益。如果项目是一种你没有接触到的技术或者标准的实现，那么搜集资料读懂它！
学会使用linux下的调试工具，如果软件还不太稳定，可以帮助找出BUG并且改正。并且学会制作patch发给作者。
如果曾是windows的程序员，尝试把开发环境转移到linux上来。或者开始在windows的开发工作中使用开源的开发工具和SDK。
如果是系统管理员，还要学会在linux部署更强的各类的安全方案。但这已经不属于学习linux的范畴了。

上面介绍了几条学习的要求，主要强调的是学习的态度。至于具体什么样的技术和自己应该在技术层次上的要求，按照上面介绍的方法应该会慢慢的体会到。
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>shell</tag>
        <tag>automake</tag>
        <tag>autoconf</tag>
        <tag>bug</tag>
        <tag>hacker</tag>
        <tag>unix</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux的stat命令</title>
    <url>/2012/09/17/linux-stat/</url>
    <content><![CDATA[Linux 的 stat 命令Linux stat 命令用于显示 inode 内容。
话说这个inode是个什么东西呢？对于存储在硬盘上的文件，特别是Linux的概念就是，一切皆文件。其最小的存储单元为512字节即一个扇区sector；在读取文件的时候，为了提高效率，是按照4KB的块block来读取的，所以这样看来每次读取了8个sector。而对于每个文件为了索引，其元数据的各种信息就是stat获取的，用于描述创建者、文件的各种日期、大小等等等等信息，这个元数据的id就可以认为是inode了，以上。
官方的定义为：

stat - display file or file system status

用法为：
$ stat [options] filename/directory



其中的参数为：

-L, --dereference : 不显示链接的原始文件

-f, --file-system ：显示文件系统状态

--printf=FORMAT ： 与C语言的类似，不过看着转义符更多一些

-t, --terse：超级简介的模式


最简单的使用最简单的其实也是最有用的，直接跟上文件或者目录，如下：
$ stat text.txt   File: ‘text.txt’  Size: 51        	Blocks: 8          IO Block: 4096   regular fileDevice: fd00h/64768d	Inode: 1610934260  Links: 1Access: (0664/-rw-rw-r--)  Uid: ( 1000/     user)   Gid: ( 1000/     user)Context: unconfined_u:object_r:user_tmp_t:s0Access: 2012-09-11 21:24:49.660510438 +0800Modify: 2012-09-09 17:31:54.518005296 +0800Change: 2012-09-09 17:33:09.670327180 +0800 Birth: -  $ stat dir  File: ‘dir’  Size: 51        	Blocks: 0          IO Block: 4096   directoryDevice: fd00h/64768d	Inode: 1610934255  Links: 2Access: (0775/drwxrwxr-x)  Uid: ( 1000/     user)   Gid: ( 1000/     user)Context: unconfined_u:object_r:user_tmp_t:s0Access: 2012-09-13 16:44:56.802331727 +0800Modify: 2012-09-13 16:44:55.624342864 +0800Change: 2012-09-13 16:44:55.624342864 +0800 Birth: -



各个段的解释为：

File：文件或文件夹名
Size：文件大小
Blocks：文件使用的数据块总数
IO Block：IO块大小
regular file：文件类型（常规文件）或者directory文件夹
Device：设备的编号
Inode：Inode号
Links：链接数
Access：文件的权限
Gid, Uid：文件所有者的Gid和Uid
Access：文件的访问时间
Modify：文件的修改时间
Change：文件的状态时间

显示文件系统参数-f将显示文件系统信息，可以看到Type：xfs这个信息。
$ stat -f text.txt   File: "text.txt"    ID: fd0000000000 Namelen: 255     Type: xfsBlock size: 4096       Fundamental block size: 4096Blocks: Total: 244020823  Free: 182831648  Available: 182831648Inodes: Total: 488280064  Free: 487587798



关于printf的那些格式化字符串--printf=FORMAT选项可以跟的FORMAT有很多，较常用为：



格式化字符串
含义



%A
易读的访问状态


%B
每个块的大小（单位为字节）


%d
十进制的设备号


%F
文件类型


%G
所有者的组名


%i
inode数字


%m
挂载点


%n
文件名


%s
总大小（单位：字节）


%U
所有者的用户名


%w
易读的文件生成时间（大写的为Epoch）


%x
易读的文件访问时间（大写的为Epoch）


%y
易读的文件修改时间（大写的为Epoch）


%z
易读的文件上一次修改状态时间（大写的为Epoch）


炫技 ： 一个类似ls -l的用法下面的这个命令可以实现类似ls -l的用法，可以扩展更多，也可以自定义使用，比如alias等等。
$ stat --print="%A. %U %G %s %x %n \n" text.txt -rw-rw-r--. user user 51 2012-09-11 21:24:49.660510438 +0800 text.txt

]]></content>
      <categories>
        <category>Linux</category>
        <category>Linux入门</category>
        <category>Linux炫技</category>
      </categories>
      <tags>
        <tag>touch</tag>
      </tags>
  </entry>
  <entry>
    <title>焕然一新的 su</title>
    <url>/2018/05/07/linux-su-beginner/</url>
    <content><![CDATA[焕然一新的 su.. note::  几处早莺争暖树，谁家新燕啄春泥。  白居易《钱塘湖春行》
su的官方定义为：

su - run a command with substitute user and group ID

一言以蔽之，su - user 能切换到一个用户中去执行一个指令或脚本，而 su 应该是switch user的概念，这个命令可以让我们开启一个进程，赋予新的身份、用户ID、组ID等关联的各种读写访问权限。
所以，理所当然是需要密码的介入的。
而如果没有user的参数，默认就是进入到root账户了。
命令格式该命令格式如下所示：
$ su [options...] [-] [user [args...]]



其中一些比较重要的选项如下所示:

-f ， –fast：快速启动，不读取启动文件，这个取决于具体的shell。
-l ， –login：这个参数让你有焕然一新的感觉，基本类似于重新登录。如果不指定，默认情况下是root环境。
-g，--group：指定主要组，这个只能由root用户指定。
-m， -p ，–preserve-environment：保留环境变量，除非指定了-l。
-s SHELL，--shell=SHELL：切换使用的SHELL。

切换到用于user执行命令command执行如下命令，会切换到user用户，然后执行ls命令
$ su - user -c ls



切换使用的SHELL不同的人，可能对不同的SHELL情有独钟，A喜欢bash，B可能喜欢csh，这个就可以通过-s来切换，如下可以切换到csh
$ su - user -s /bin/csh

关于SHELL，根据安装的环境不同，基本有如下几个：

/bin/bash     
/bin/tcsh    
/usr/bin/sh  
/bin/csh      
/sbin/nologin  
/bin/sh

加与不加-的区别还是有的 su [user] 和 su - [user]su [user]切换到其他用户，但是不切换环境变量，su - [user]则是完整的切换到新的用户环境。
如：
$ pwd/root$ su oper $ pwd  /root$ su - oper Password:$ pwd/home/oper

所以大家在切换用户时，尽量用su - [user]，否则可能会出现环境变量不对的问题。
]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>su</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux的su命令</title>
    <url>/2018/05/07/linux-su/</url>
    <content><![CDATA[简介su - user 能切换到一个用户中去执行一个指令或脚本
命令格式该命令格式如下所示：
$ su [options...] [-] [user [args...]]



其中一些比较重要的选项如下所示:

-f ， –fast：快速启动，不读取启动文件，这个取决于具体的shell。
-l ， –login：这个参数让你有焕然一新的感觉，基本类似于重新登录。如果不指定，默认情况下是root环境。
-g，--group：指定主要组，这个只能由root用户指定。
-m， -p ，–preserve-environment：保留环境变量，除非指定了-l。
-s SHELL，--shell=SHELL：切换使用的SHELL。

切换到用于user执行命令command执行如下命令，会切换到user用户，然后执行ls命令
$ su - user -c ls



切换使用的SHELL不同的人，可能对不同的SHELL情有独钟，A喜欢bash，B可能喜欢csh，这个就可以通过-s来切换，如下可以切换到csh
$ su - user -s /bin/csh

关于SHELL，根据安装的环境不同，基本有如下几个：

/bin/bash     
/bin/tcsh    
/usr/bin/sh  
/bin/csh      
/sbin/nologin  
/bin/sh

su [user] 和 su - [user]的区别：su [user]切换到其他用户，但是不切换环境变量，su - [user]则是完整的切换到新的用户环境。
如：
$ pwd/root$ su oper $ pwd  /root$ su - oper Password:$ pwd/home/oper

所以大家在切换用户时，尽量用su - [user]，否则可能会出现环境变量不对的问题。
]]></content>
      <categories>
        <category>Linux</category>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>su</tag>
      </tags>
  </entry>
  <entry>
    <title>超凡脱俗的 sudo</title>
    <url>/2017/05/07/linux-sudo-beginner/</url>
    <content><![CDATA[超凡脱俗的 sudoLinux sudo命令以系统管理者的身份执行指令，也就是说，经由 sudo 所执行的指令就好像是 root 亲自执行。
如果希望可以执行这个命令，需要管理员在文件 /etc/sudoers 中增加权限即可。
官方的定义为：

execute a command as another user

语法$ sudo [ option ] command

参数说明：

-l 或--list：显示出自己（执行 sudo 的使用者）的权限
-k 将会强迫使用者在下一次执行 sudo 时问密码（不论有没有超过 N 分钟）
-b 将要执行的指令放在后台执行
-p prompt 可以更改问密码的提示语，其中 %u 会代换为使用者的帐号名称， %h 会显示主机名称
-u username/uid 不加此参数，代表要以 root 的身份执行指令，而加了此参数，可以以 username 的身份执行指令（uid 为该 username 的使用者号码）
-s 执行环境变数中的 SHELL 所指定的 shell ，或是 /etc/passwd 里所指定的 shell
-H 将环境变数中的 HOME （家目录）指定为要变更身份的使用者家目录（如不加 -u 参数就是系统管理者 root ）
command 要以系统管理者身份（或以 -u 更改为其他人）执行的指令

没有sudo权限的用户如果没有sudo权限，在执行命令的时候还有下面👇的输出：
$ sudo ls[sudo] password for username: username is not in the sudoers file. This incident will be reported.





指定用户执行命令这个的应用场景为，其他用户在登录，而你具有sudo权限，测试可以通过指定用户名来操作。
$ sudo -u username ls -l





列出目前sudo的权限如果不清楚，可以执行那些命令，可以通过参数-l来查看，主要看在sudoer里面的修改。
$ sudo -lPassword:Matching Defaults entries for user on localhost:    !visiblepw, always_set_home, match_group_by_gid, env_reset, env_keep="COLORS DISPLAY    HOSTNAME HISTSIZE KDEDIR LS_COLORS", env_keep+="MAIL PS1 PS2 QTDIR USERNAME LANG LC_ADDRESS    LC_CTYPE", env_keep+="LC_COLLATE LC_IDENTIFICATION LC_MEASUREMENT LC_MESSAGES",    env_keep+="LC_MONETARY LC_NAME LC_NUMERIC LC_PAPER LC_TELEPHONE", env_keep+="LC_TIME LC_ALL    LANGUAGE LINGUAS _XKB_CHARSET XAUTHORITY", secure_path=/sbin\:/bin\:/usr/sbin\:/usr/binUser user may run the following commands on localhost:    (ALL) ALL

以root权限执行上一条命令
使用sudo快速统计家目录的使用情况$ sudo sh -c "cd /home ; du -s * | sort -rn "15013524344	user11170974156	user2139238772	user31382673532	user441071068	user53523056	user6

]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>Linux炫技</tag>
        <tag>sudo</tag>
        <tag>sort</tag>
        <tag>du</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux的sudo命令</title>
    <url>/2017/05/07/linux-sudo/</url>
    <content><![CDATA[Linux sudo命令Linux sudo命令以系统管理者的身份执行指令，也就是说，经由 sudo 所执行的指令就好像是 root 亲自执行。
如果希望可以执行这个命令，需要管理员在文件 /etc/sudoers 中增加权限即可。
官方的定义为：

execute a command as another user

语法$ sudo [ option ] command

参数说明：

-l 或--list：显示出自己（执行 sudo 的使用者）的权限
-k 将会强迫使用者在下一次执行 sudo 时问密码（不论有没有超过 N 分钟）
-b 将要执行的指令放在后台执行
-p prompt 可以更改问密码的提示语，其中 %u 会代换为使用者的帐号名称， %h 会显示主机名称
-u username/uid 不加此参数，代表要以 root 的身份执行指令，而加了此参数，可以以 username 的身份执行指令（uid 为该 username 的使用者号码）
-s 执行环境变数中的 SHELL 所指定的 shell ，或是 /etc/passwd 里所指定的 shell
-H 将环境变数中的 HOME （家目录）指定为要变更身份的使用者家目录（如不加 -u 参数就是系统管理者 root ）
command 要以系统管理者身份（或以 -u 更改为其他人）执行的指令

没有sudo权限的用户如果没有sudo权限，在执行命令的时候还有下面👇的输出：
$ sudo ls[sudo] password for username: username is not in the sudoers file. This incident will be reported.





指定用户执行命令这个的应用场景为，其他用户在登录，而你具有sudo权限，测试可以通过制定用户名来操作。
$ sudo -u username ls -l





列出目前sudo的权限如果不清楚，可以执行那些命令，可以通过参数-l来查看，主要看在sudoer里面的修改。
$ sudo -lPassword:Matching Defaults entries for user on localhost:    !visiblepw, always_set_home, match_group_by_gid, env_reset, env_keep="COLORS DISPLAY    HOSTNAME HISTSIZE KDEDIR LS_COLORS", env_keep+="MAIL PS1 PS2 QTDIR USERNAME LANG LC_ADDRESS    LC_CTYPE", env_keep+="LC_COLLATE LC_IDENTIFICATION LC_MEASUREMENT LC_MESSAGES",    env_keep+="LC_MONETARY LC_NAME LC_NUMERIC LC_PAPER LC_TELEPHONE", env_keep+="LC_TIME LC_ALL    LANGUAGE LINGUAS _XKB_CHARSET XAUTHORITY", secure_path=/sbin\:/bin\:/usr/sbin\:/usr/binUser user may run the following commands on localhost:    (ALL) ALL

以root权限执行上一条命令
使用sudo快速统计家目录的使用情况$ sudo sh -c "cd /home ; du -s * | sort -rn "15013524344	user11170974156	user2139238772	user31382673532	user441071068	user53523056	user6



炫技 - 快速执行上一条命令第一种方法：在终端输入两个感叹号，然后回车就可以快速地执行上一条命令了。
$ !!]]></content>
      <categories>
        <category>Linux</category>
        <category>Linux入门</category>
        <category>Linux炫技</category>
      </categories>
      <tags>
        <tag>sudo</tag>
        <tag>sort</tag>
        <tag>du</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux的sysctl命令</title>
    <url>/2016/05/07/linux-sysctl/</url>
    <content><![CDATA[简介sysctl命令用于运行时配置内核参数，这些参数位于/proc/sys目录下。sysctl配置与显示在/proc/sys目录中的内核参数．可以用sysctl来设置或重新设置联网功能，如IP转发、IP碎片去除以及源路由检查等。用户只需要编辑/etc/sysctl.conf文件，即可手工或自动执行由sysctl控制的功能。
命令格式sysctl [-n] [-e] -w variable=valuesysctl [-n] [-e] -p &lt;filename&gt; (default /etc/sysctl.conf)sysctl [-n] [-e] -a

命令参数
-w   临时改变某个指定参数的值，如 sysctl -w net.ipv4.ip_forward=1
-a   显示所有的系统参数
-p   从指定的文件加载系统参数，如不指定即从/etc/sysctl.conf中加载

使用范例：如果仅仅是想临时改变某个系统参数的值，可以用两种方法来实现,例如想启用IP路由转发功能：
#echo 1 &gt; /proc/sys/net/ipv4/ip_forward#sysctl -w net.ipv4.ip_forward=1

以上两种方法都可能立即开启路由功能，但如果系统重启，或执行了
# service network restart

命令，所设置的值即会丢失，如果想永久保留配置，可以修改/etc/sysctl.conf文件将 net.ipv4.ip_forward=0改为net.ipv4.ip_forward=1
还有一种方法设置主机名sysctl kernel.hostname
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>sysctl</tag>
      </tags>
  </entry>
  <entry>
    <title>反向显示之 tac</title>
    <url>/2011/02/12/linux-tac-beginner/</url>
    <content><![CDATA[反向显示之 tac.. note::  未老莫还乡，还乡须断肠。  宋 韦庄《菩萨蛮 人人尽说江南好》
tac命令将文件反向输出，刚好与前面的cat输出相反，cat命令可用于输出文件的内容到标准输出。
这个命令其实就是cat的反向输出，😁。
tac的官方定义为：

tac - concatenate and print files in reverse

其用法一般为：
$ tac [OPTION]... [FILE]...



tac命令的可选参数[OPTION]如下所示：

-b, --before ：在行前而不是行尾添加分割标志
-r, --regex：将分割标志作为正则表达式来解析
-s, --separator=STRING：使用STRING作为分割标志

同样使用前面的hello.c文件，内容为：
#include &lt;stdio.h&gt;int main(int argc, char * argv[]){    printf("Hello World\n");        return 0;}


接下来的实例全部根据这个文件展开，Hello World. Hello Linux

显示内容与cat比对输出如下所示：
$ cat hello.c #include &lt;stdio.h&gt;int main(int argc, char * argv[]){    printf("Hello World\n");    return 0;}$ tac hello.c}    return 0;    printf("Hello World\n");{int main(int argc, char * argv[])#include &lt;stdio.h&gt;



其他几个参数用的到时不多，不过搭配起来还是有一些帮助的，比如做一个反序输出，搭配使用-s和-r参数，如下：
$ cat 'Hello World.' | tac -r -s ".".dlroW olleH

这个方法就用到了管道、正则表达式。
]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>文档查看</tag>
        <tag>文件操作</tag>
        <tag>文件管理</tag>
        <tag>tac</tag>
      </tags>
  </entry>
  <entry>
    <title>不可狗尾续貂的tail</title>
    <url>/2011/02/12/linux-tail-beginner/</url>
    <content><![CDATA[不可狗尾续貂的tailtail命令用来查看文件尾部的n行，如果没有指定的n，默认显示10行。
命令格式：
$ tail [option] [filename]  

参数option比较常用的如下所示：

-f 循环读取
-c &lt;数目&gt; 显示的字节数
-n &lt;行数&gt; 显示文件的尾部 n 行内容

常规使用假定文件text.txt有20行，从1-20，默认情况下的使用如下：
$ tail text.txt11121314151617181920



显示N行可以通过-n参数来只显示N行，而不是默认的10行，比如15行，如下:
$ tail -n 15 text.txt67891011121314151617181920



从第N行显示此时如果希望从第N行显示，而不是显示N行，可以通过下面的参数，比如从第15行显示
$ tail -n +15 text.txt151617181920



按照字符显示如果希望显示文件的最后几个字符，比如6个，如下：
$ tail -c 6 text.txt1920# NICE# 查看文件的后60KB$ tail -c 60k filename# 查看文件的后60MB$ tail -c 60m filename





特别赞的一个实时更新的功能参数 -f 常常用于查阅正在改变的日志文件。如下面👇所示：
$ tail -f filename

如果filename的内容在增加，那么显示在屏幕上的内容就会一直更新。
]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>文档查看</tag>
        <tag>文件操作</tag>
        <tag>tail</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux tail 命令</title>
    <url>/2011/02/12/linux-tail/</url>
    <content><![CDATA[查看文件尾部命令tailtail命令用来查看文件尾部的n行，如果没有指定的n，默认显示10行。
命令格式：
$ tail [option] [filename]  

参数option比较常用的如下所示：

-f 循环读取
-c &lt;数目&gt; 显示的字节数
-n &lt;行数&gt; 显示文件的尾部 n 行内容

常规使用假定文件text.txt有20行，从1-20，默认情况下的使用如下：
$ tail text.txt11121314151617181920



显示N行可以通过-n参数来只显示N行，而不是默认的10行，比如15行，如下:
$ tail -n 15 text.txt67891011121314151617181920



从第N行显示此时如果希望从第N行显示，而不是显示N行，可以通过下面的参数，比如从第15行显示
$ tail -n +15 text.txt151617181920



按照字符显示如果希望显示文件的最后几个字符，比如6个，如下：
$ tail -c 6 text.txt1920# NICE# 查看文件的后60KB$ tail -c 60k filename# 查看文件的后60MB$ tail -c 60m filename





特别赞的一个实时更新的功能参数 -f 常常用于查阅正在改变的日志文件。如下面👇所示：
$ tail -f filename

如果filename的内容在增加，那么显示在屏幕上的内容就会一直更新。
]]></content>
      <categories>
        <category>Linux</category>
        <category>Linux入门</category>
        <category>文档查看</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>tail</tag>
      </tags>
  </entry>
  <entry>
    <title>解压方法之一 tar</title>
    <url>/2011/02/12/linux-tar-beginner/</url>
    <content><![CDATA[解压方法之一 tar.. note::  十年磨一剑，霜刃未曾试。  贾岛《剑客 / 述剑》
Linux的tar命令可以用来压缩或者解压缩文件。
官方定义为：

tar - an archiving utility

语法如下$ tar optionA [optionsB] filename



使用该命令时，optionA选项是必须要有的，它告诉tar要做什么事情，optionsB选项是辅助使用的，可以选用。
其中optionsA主要为：

-c 创建新的档案文件。如果用户想备份一个目录或是一些文件，就要选择这个选项。相当于打包的意思。
-x 从档案文件中释放文件。相当于拆包。
-t 列出档案文件的内容，查看已经备份了哪些文件。

不过需要注意的是，这三个参数是互斥的，仅仅能存在一个。
辅助选项常用的为：

-z ：是否同时具有 gzip 的属性，有的话压缩文件格式为：filename.tar.gz
-j ：是否同时具有 bzip2 的属性，有的话压缩文件格式为：filename.tar.bz2  
-v ：压缩的过程中显示文件，这个基本都需要带上，给无聊的终端也来点输出
-p ：使用原文件的原来属性（属性不会依据使用者而变）
--exclude FILE：在压缩的过程中，不要将 FILE 打包，这个对于需要保留一些文件特别重要，比如压缩包中，有一些大文件，可以用这种方法来处理

压缩文件接下来的命令为把a,b,c,d压缩到文件test.tar.gz中。
$ tar czvf test.tar.gz a b c dabcd



查看压缩文件的内容接下来的命令将列出压缩文件的内容，但是不解压，所以可以先确定，再解压不迟
$ tar tzvf test.tar.gz a b c d-rw-rw-r-- oper/oper           12 2010-05-24 22:51 a-rw-rw-r-- oper/oper           18 2010-05-24 22:51 b-rw-rw-r-- oper/oper           15 2010-05-24 22:51 c-rw-rw-r-- oper/oper           28 2010-05-24 22:51 d



解压文件接下来就可以解压操作了。
$ tar zxvf test.tar.gzabcd

]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>tar</tag>
        <tag>归档压缩命令</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux 的 tar 命令</title>
    <url>/2011/02/12/linux-tar/</url>
    <content><![CDATA[Linux 的归档命令 tarLinux的tar命令可以用来压缩或者解压缩文件。
官方定义为：

tar - an archiving utility

语法$ tar optionA [optionsB] filename



使用该命令时，optionA选项是必须要有的，它告诉tar要做什么事情，optionsB选项是辅助使用的，可以选用。
其中optionsA主要为：

-c 创建新的档案文件。如果用户想备份一个目录或是一些文件，就要选择这个选项。相当于打包。
-x 从档案文件中释放文件。相当于拆包。
-t 列出档案文件的内容，查看已经备份了哪些文件。

不过需要注意的是，这三个参数仅仅能存在一个。
辅助选项常用的为：

-z ：是否同时具有 gzip 的属性，有的话压缩文件格式为：filename.tar.gz
-j ：是否同时具有 bzip2 的属性，有的话压缩文件格式为：filename.tar.bz2  
-v ：压缩的过程中显示文件，这个基本都需要带上
-p ：使用原文件的原来属性（属性不会依据使用者而变）
--exclude FILE：在压缩的过程中，不要将 FILE 打包！

压缩文件接下来的命令为把a,b,c,d压缩到文件test.tar.gz中。
$ tar czvf test.tar.gz a b c dabcd



查看压缩文件的内容接下来的命令将列出压缩文件的内容，但是不解压，所以可以先确定，再解压不迟
$ tar tzvf test.tar.gz a b c d-rw-rw-r-- oper/oper           12 2010-05-24 22:51 a-rw-rw-r-- oper/oper           18 2010-05-24 22:51 b-rw-rw-r-- oper/oper           15 2010-05-24 22:51 c-rw-rw-r-- oper/oper           28 2010-05-24 22:51 d



解压文件接下来就可以解压操作了。
$ tar zxvf test.tar.gzabcd














-A或–catenate 新增文件到已存在的备份文件。

-b&lt;区块数目&gt;或–blocking-factor=&lt;区块数目&gt; 设置每笔记录的区块数目，每个区块大小为12Bytes。

-B或–read-full-records 读取数据时重设区块大小。

-c或–create 建立新的备份文件。

-C&lt;目的目录&gt;或–directory=&lt;目的目录&gt; 切换到指定的目录。

-d或–diff或–compare 对比备份文件内和文件系统上的文件的差异。

-f&lt;备份文件&gt;或–file=&lt;备份文件&gt; 指定备份文件。

-F&lt;Script文件&gt;或–info-script=&lt;Script文件&gt; 每次更换磁带时，就执行指定的Script文件。

-g或–listed-incremental 处理GNU格式的大量备份。

-G或–incremental 处理旧的GNU格式的大量备份。

-h或–dereference 不建立符号连接，直接复制该连接所指向的原始文件。

-i或–ignore-zeros 忽略备份文件中的0 Byte区块，也就是EOF。

-k或–keep-old-files 解开备份文件时，不覆盖已有的文件。

-K&lt;文件&gt;或–starting-file=&lt;文件&gt; 从指定的文件开始还原。

-l或–one-file-system 复制的文件或目录存放的文件系统，必须与tar指令执行时所处的文件系统相同，否则不予复制。

-L&lt;媒体容量&gt;或-tape-length=&lt;媒体容量&gt; 设置存放每体的容量，单位以1024 Bytes计算。

-m或–modification-time 还原文件时，不变更文件的更改时间。

-M或–multi-volume 在建立，还原备份文件或列出其中的内容时，采用多卷册模式。

-N&lt;日期格式&gt;或–newer=&lt;日期时间&gt; 只将较指定日期更新的文件保存到备份文件里。

-o或–old-archive或–portability 将资料写入备份文件时使用V7格式。

-O或–stdout 把从备份文件里还原的文件输出到标准输出设备。

-p或–same-permissions 用原来的文件权限还原文件。

-P或–absolute-names 文件名使用绝对名称，不移除文件名称前的”/“号。

-r或–append 新增文件到已存在的备份文件的结尾部分。

-R或–block-number 列出每个信息在备份文件中的区块编号。

-s或–same-order 还原文件的顺序和备份文件内的存放顺序相同。

-S或–sparse 倘若一个文件内含大量的连续0字节，则将此文件存成稀疏文件。

-t或–list 列出备份文件的内容。

-T&lt;范本文件&gt;或–files-from=&lt;范本文件&gt; 指定范本文件，其内含有一个或多个范本样式，让tar解开或建立符合设置条件的文件。

-u或–update 仅置换较备份文件内的文件更新的文件。

-U或–unlink-first 解开压缩文件还原文件之前，先解除文件的连接。

-v或–verbose 显示指令执行过程。

-V&lt;卷册名称&gt;或–label=&lt;卷册名称&gt; 建立使用指定的卷册名称的备份文件。

-w或–interactive 遭遇问题时先询问用户。

-W或–verify 写入备份文件后，确认文件正确无误。

-x或–extract或–get 从备份文件中还原文件。

-X&lt;范本文件&gt;或–exclude-from=&lt;范本文件&gt; 指定范本文件，其内含有一个或多个范本样式，让ar排除符合设置条件的文件。

-z或–gzip或–ungzip 通过gzip指令处理备份文件。

-Z或–compress或–uncompress 通过compress指令处理备份文件。

-&lt;设备编号&gt;&lt;存储密度&gt; 设置备份用的外围设备编号及存放数据的密度。

–after-date=&lt;日期时间&gt; 此参数的效果和指定”-N”参数相同。

–atime-preserve 不变更文件的存取时间。

–backup=&lt;备份方式&gt;或–backup 移除文件前先进行备份。

–checkpoint 读取备份文件时列出目录名称。

–concatenate 此参数的效果和指定”-A”参数相同。

–confirmation 此参数的效果和指定”-w”参数相同。

–delete 从备份文件中删除指定的文件。

–exclude=&lt;范本样式&gt; 排除符合范本样式的文件。

–group=&lt;群组名称&gt; 把加入设备文件中的文件的所属群组设成指定的群组。

–help 在线帮助。

–ignore-failed-read 忽略数据读取错误，不中断程序的执行。

–new-volume-script=&lt;Script文件&gt; 此参数的效果和指定”-F”参数相同。

–newer-mtime 只保存更改过的文件。

–no-recursion 不做递归处理，也就是指定目录下的所有文件及子目录不予处理。

–null 从null设备读取文件名称。

–numeric-owner 以用户识别码及群组识别码取代用户名称和群组名称。

–owner=&lt;用户名称&gt; 把加入备份文件中的文件的拥有者设成指定的用户。

–posix 将数据写入备份文件时使用POSIX格式。

–preserve 此参数的效果和指定”-ps”参数相同。

–preserve-order 此参数的效果和指定”-A”参数相同。

–preserve-permissions 此参数的效果和指定”-p”参数相同。

–record-size=&lt;区块数目&gt; 此参数的效果和指定”-b”参数相同。

–recursive-unlink 解开压缩文件还原目录之前，先解除整个目录下所有文件的连接。

–remove-files 文件加入备份文件后，就将其删除。

–rsh-command=&lt;执行指令&gt; 设置要在远端主机上执行的指令，以取代rsh指令。

–same-owner 尝试以相同的文件拥有者还原文件。

–suffix=&lt;备份字尾字符串&gt; 移除文件前先行备份。

–totals 备份文件建立后，列出文件大小。

–use-compress-program=&lt;执行指令&gt; 通过指定的指令处理备份文件。

–volno-file=&lt;编号文件&gt; 使用指定文件内的编号取代预设的卷册编号。
 For example, the c option requires creating the archive, the v option requests the verbose operation, and  the
 f  option takes an argument that sets the name of the archive to operate upon.  The following command, written
 in the traditional style, instructs tar to store all files from the  directory  /etc  into  the  archive  file
 etc.tar verbosely listing the files being archived:

 tar cfv a.tar /etc

 In  UNIX  or  short-option  style, each option letter is prefixed with a single dash, as in other command line
 utilities.  If an option takes argument, the argument follows it, either as a separate command line  word,  or
 immediately following the option.  However, if the option takes an optional argument, the argument must follow
 the option letter without any intervening whitespace, as in -g/tmp/snar.db.

 Any number of options not taking arguments can be clustered together after a single dash, e.g. -vkp.   Options
 that  take  arguments  (whether  mandatory  or  optional), can appear at the end of such a cluster, e.g. -vkpf
 a.tar.

 The example command above written in the short-option style could look like:

 tar -cvf a.tar /etc
 or
 tar -c -v -f a.tar /etc

 In GNU or long-option style, each option begins with two dashes and  has  a  meaningful  name,  consisting  of
 lower-case letters and dashes.  When used, the long option can be abbreviated to its initial letters, provided
 that this does not create ambiguity.  Arguments to long options are supplied either as a separate command line
 word,  immediately  following  the  option, or separated from the option by an equals sign with no intervening
 whitespace.  Optional arguments must always use the latter method.

 Here are several ways of writing the example command in this style:

 tar --create --file a.tar --verbose /etc
 or (abbreviating some options):
 tar --cre --file=a.tar --verb /etc

 The options in all three styles can be intermixed, although doing so with old options is not encouraged.

 Operation mode The options listed in the table below tell GNU tar what operation it is to perform.  Exactly one of them  must be given.  Meaning of non-optional arguments depends on the operation mode requested. -A, –catenate, –concatenate        Append  archive  to  the end of another archive.  The arguments are treated as the names of archives to        append.  All archives must be of the same format as the archive they are appended to, otherwise the re‐        sulting archive might be unusable with non-GNU implementations of tar.  Notice also that when more than        one archive is given, the members from archives other than the first one will be accessible in the  re‐        sulting archive only if using the -i (–ignore-zeros) option.        Compressed archives cannot be concatenated. -c, –create        Create  a  new  archive.   Arguments  supply  the  names  of the files to be archived.  Directories are        archived recursively, unless the –no-recursion option is given. -d, –diff, –compare        Find differences between archive and file system.  The arguments are optional and specify archive  mem‐        bers to compare.  If not given, the current working directory is assumed. –delete        Delete  from  the  archive.  The arguments supply names of the archive members to be removed.  At least        one argument must be given.        This option does not operate on compressed archives.  There is no short option equivalent. -r, –append        Append files to the end of an archive.  Arguments have the same meaning as for -c (–create). -t, –list        List the contents of an archive.  Arguments are optional.  When given, they specify the  names  of  the        members to list. –test-label        Test  the  archive  volume label and exit.  When used without arguments, it prints the volume label (if        any) and exits with status 0.  When one or more command line arguments are  given.   tar  compares  the        volume  label with each argument.  It exits with code 0 if a match is found, and with code 1 otherwise.        No output is displayed, unless used together with the -v (–verbose) option.        There is no short option equivalent for this option. -u, –update        Append files which are newer than the corresponding copy in the archive.  Arguments have the same mean‐        ing  as  with  -c and -r options.  Notice, that newer files don’t replace their old archive copies, but        instead are appended to the end of archive.  The resulting archive can thus contain several members  of        the same name, corresponding to various versions of the same file. -x, –extract, –get        Extract  files from an archive.  Arguments are optional.  When given, they specify names of the archive        members to be extracted. –show-defaults        Show built-in defaults for various tar options and exit.  No arguments are allowed. -?, –help        Display a short option summary and exit.  No arguments allowed. –usage        Display a list of available options and exit.  No arguments allowed. –version        Print program version and copyright information and exit.


OPTIONS   Operation modifiers       –check-device              Check device numbers when creating incremental archives (default).
   -g, --listed-incremental=FILE
          Handle new GNU-format incremental backups.  FILE is the name of a snapshot file, where tar stores addi‐
          tional information which is used to decide which files changed since the previous incremental dump and,
          consequently, must be dumped again.  If FILE does not exist when creating an archive, it will  be  cre‐
          ated  and  all  files will be added to the resulting archive (the level 0 dump).  To create incremental
          archives of non-zero level N, create a copy of the snapshot file created during the level N-1, and  use
          it as FILE.

          When listing or extracting, the actual contents of FILE is not inspected, it is needed only due to syn‐
          tactical requirements.  It is therefore common practice to use /dev/null in its place.

   --hole-detection=METHOD
          Use METHOD to detect holes in sparse files.  This option implies --sparse.  Valid values for METHOD are
          seek and raw.  Default is seek with fallback to raw when not applicable.

   -G, --incremental
          Handle old GNU-format incremental backups.

   --ignore-failed-read
          Do not exit with nonzero on unreadable files.

   --level=NUMBER
          Set  dump level for created listed-incremental archive.  Currently only --level=0 is meaningful: it in‐
          structs tar to truncate the snapshot file before dumping, thereby forcing a level 0 dump.

   -n, --seek
          Assume the archive is seekable.  Normally tar determines  automatically  whether  the  archive  can  be
          seeked  or not.  This option is intended for use in cases when such recognition fails.  It takes effect
          only if the archive is open for reading (e.g. with --list or --extract options).

   --no-check-device
          Do not check device numbers when creating incremental archives.

   --no-seek
          Assume the archive is not seekable.

   --occurrence[=N]
          Process only the Nth occurrence of each file in the archive.  This option is valid only when used  with
          one  of  the  following  subcommands: --delete, --diff, --extract or --list and when a list of files is
          given either on the command line or via the -T option.  The default N is 1.

   --restrict
          Disable the use of some potentially harmful options.

   --sparse-version=MAJOR[.MINOR]
          Set version of the sparse format to use (implies --sparse).  This option implies --sparse.  Valid argu‐
          ment  values  are 0.0, 0.1, and 1.0.  For a detailed discussion of sparse formats, refer to the GNU Tar
          Manual, appendix D, "Sparse Formats".  Using info reader, it can be accessed running the following com‐
          mand: info tar 'Sparse Formats'.

   -S, --sparse
          Handle  sparse  files efficiently.  Some files in the file system may have segments which were actually
          never written (quite often these are database files created by such systems as DBM).  When  given  this
          option, tar attempts to determine if the file is sparse prior to archiving it, and if so, to reduce the
          resulting archive size by not dumping empty parts of the file.

   Overwrite control       These options control tar actions when extracting a file over an existing copy on disk.
   -k, --keep-old-files
          Don't replace existing files when extracting.

   --keep-newer-files
          Don't replace existing files that are newer than their archive copies.

   --keep-directory-symlink
          Don't replace existing symlinks to directories when extracting.

   --no-overwrite-dir
          Preserve metadata of existing directories.

   --one-top-level[=DIR]
          Extract all files into DIR, or, if used without argument, into a subdirectory named by the base name of
          the archive (minus standard compression suffixes recognizable by --auto-compress).

   --overwrite
          Overwrite existing files when extracting.

   --overwrite-dir
          Overwrite metadata of existing directories when extracting (default).

   --recursive-unlink
          Recursively remove all files in the directory prior to extracting it.

   --remove-files
          Remove files from disk after adding them to the archive.

   --skip-old-files
          Don't replace existing files when extracting, silently skip over them.

   -U, --unlink-first
          Remove each file prior to extracting over it.

   -W, --verify
          Verify the archive after writing it.

   Output stream selection       –ignore-command-error
   Ignore subprocess exit codes.

   --no-ignore-command-error
          Treat non-zero exit codes of children as error (default).

   -O, --to-stdout
          Extract files to standard output.

   --to-command=COMMAND
          Pipe  extracted files to COMMAND.  The argument is the pathname of an external program, optionally with
          command line arguments.  The program will be invoked and the contents of the file being extracted  sup‐
          plied  to  it  on  its standard output.  Additional data will be supplied via the following environment
          variables:

          TAR_FILETYPE
                 Type of the file. It is a single letter with the following meaning:

                         f           Regular file
                         d           Directory
                         l           Symbolic link
                         h           Hard link
                         b           Block device
                         c           Character device

                 Currently only regular files are supported.

          TAR_MODE
                 File mode, an octal number.

          TAR_FILENAME
                 The name of the file.

          TAR_REALNAME
                 Name of the file as stored in the archive.

          TAR_UNAME
                 Name of the file owner.

          TAR_GNAME
                 Name of the file owner group.

          TAR_ATIME
                 Time of last access. It is a decimal number, representing seconds since the Epoch.  If  the  ar‐
                 chive  provides  times  with nanosecond precision, the nanoseconds are appended to the timestamp
                 after a decimal point.

          TAR_MTIME
                 Time of last modification.

          TAR_CTIME
                 Time of last status change.

          TAR_SIZE
                 Size of the file.

          TAR_UID
                 UID of the file owner.

          TAR_GID
                 GID of the file owner.

          Additionally, the following variables contain information about tar operation mode and the archive  be‐
          ing processed:

          TAR_VERSION
                 GNU tar version number.

          TAR_ARCHIVE
                 The name of the archive tar is processing.

          TAR_BLOCKING_FACTOR
                 Current blocking factor, i.e. number of 512-byte blocks in a record.

          TAR_VOLUME
                 Ordinal number of the volume tar is processing (set if reading a multi-volume archive).

          TAR_FORMAT
                 Format of the archive being processed.  One of: gnu, oldgnu, posix, ustar, v7.  TAR_SUBCOMMAND A
                 short option (with a leading dash) describing the operation tar is executing.

   Handling of file attributes       –atime-preserve[=METHOD]              Preserve access times on dumped files, either by restoring the  times  after  reading  (METHOD=replace,              this is the default) or by not setting the times in the first place (METHOD=system)
   --delay-directory-restore
          Delay  setting modification times and permissions of extracted directories until the end of extraction.
          Use this option when extracting from an archive which has unusual member ordering.

   --group=NAME[:GID]
          Force NAME as group for added files.  If GID is not supplied, NAME can be either a user name or numeric
          GID.   In this case the missing part (GID or name) will be inferred from the current host's group data‐
          base.

          When used with --group-map=FILE, affects only those files whose owner group is not listed in FILE.

   --group-map=FILE
          Read group translation map from FILE.  Empty lines are ignored.  Comments are introduced  with  #  sign
          and extend to the end of line.  Each non-empty line in FILE defines translation for a single group.  It
          must consist of two fields, delimited by any amount of whitespace:

          OLDGRP NEWGRP[:NEWGID]

          OLDGRP is either a valid group name or a GID prefixed with +.  Unless NEWGID is supplied,  NEWGRP  must
          also  be  either a valid group name or a +GID.  Otherwise, both NEWGRP and NEWGID need not be listed in
          the system group database.

          As a result, each input file with owner group OLDGRP will be stored in archive with owner group  NEWGRP
          and GID NEWGID.

   --mode=CHANGES
          Force symbolic mode CHANGES for added files.

   --mtime=DATE-OR-FILE
          Set  mtime for added files.  DATE-OR-FILE is either a date/time in almost arbitrary format, or the name
          of an existing file.  In the latter case the mtime of that file will be used.

   -m, --touch
          Don't extract file modified time.

   --no-delay-directory-restore
          Cancel the effect of the prior --delay-directory-restore option.

   --no-same-owner
          Extract files as yourself (default for ordinary users).

   --no-same-permissions
          Apply the user's umask when extracting permissions from the archive (default for ordinary users).

   --numeric-owner
          Always use numbers for user/group names.

   --owner=NAME[:UID]
          Force NAME as owner for added files.  If UID is not supplied, NAME can be either a user name or numeric
          UID.   In  this case the missing part (UID or name) will be inferred from the current host's user data‐
          base.

          When used with --owner-map=FILE, affects only those files whose owner is not listed in FILE.

   --owner-map=FILE
          Read owner translation map from FILE.  Empty lines are ignored.  Comments are introduced  with  #  sign
          and  extend  to the end of line.  Each non-empty line in FILE defines translation for a single UID.  It
          must consist of two fields, delimited by any amount of whitespace:

          OLDUSR NEWUSR[:NEWUID]

          OLDUSR is either a valid user name or a UID prefixed with +.  Unless NEWUID is  supplied,  NEWUSR  must
          also  be  either  a valid user name or a +UID.  Otherwise, both NEWUSR and NEWUID need not be listed in
          the system user database.

          As a result, each input file owned by OLDUSR will be stored in archive with owner name NEWUSR  and  UID
          NEWUID.

   -p, --preserve-permissions, --same-permissions
          extract information about file permissions (default for superuser)

   --preserve
          Same as both -p and -s.

   --same-owner
          Try extracting files with the same ownership as exists in the archive (default for superuser).

   -s, --preserve-order, --same-order
          Sort names to extract to match archive

   --sort=ORDER
          When creating an archive, sort directory entries according to ORDER, which is one of none, name, or in‐
          ode.

          The default is --sort=none, which stores archive members in the same order as returned by the operating
          system.

          Using --sort=name ensures the member ordering in the created archive is uniform and reproducible.

          Using --sort=inode reduces the number of disk seeks made when creating the archive and thus can consid‐
          erably speed up archivation.  This sorting order is supported only if the  underlying  system  provides
          the necessary information.

   Extended file attributes       –acls Enable POSIX ACLs support.
   --no-acls
          Disable POSIX ACLs support.

   --selinux
          Enable SELinux context support.

   --no-selinux
          Disable SELinux context support.

   --xattrs
          Enable extended attributes support.

   --no-xattrs
          Disable extended attributes support.

   --xattrs-exclude=PATTERN
          Specify  the  exclude pattern for xattr keys.  PATTERN is a POSIX regular expression, e.g. --xattrs-ex‐
          clude='^user.', to exclude attributes from the user namespace.

   --xattrs-include=PATTERN
          Specify the include pattern for xattr keys.  PATTERN is a POSIX regular expression.

   Device selection and switching       -f, –file=ARCHIVE              Use archive file or device ARCHIVE.  If this option is not given, tar will first examine  the  environ‐              ment  variable  `TAPE’.  If it is set, its value will be used as the archive name.  Otherwise, tar will              assume the compiled-in default.  The default value can be inspected either  using  the  –show-defaults              option, or at the end of the tar –help output.
          An archive name that has a colon in it specifies a file or device on a remote machine.  The part before
          the colon is taken as the machine name or IP address, and the part after it as the file or device path‐
          name, e.g.:

          --file=remotehost:/dev/sr0

          An optional username can be prefixed to the hostname, placing a @ sign between them.

          By  default,  the  remote host is accessed via the rsh(1) command.  Nowadays it is common to use ssh(1)
          instead.  You can do so by giving the following command line option:

          --rsh-command=/usr/bin/ssh

          The remote machine should have the rmt(8) command installed.  If its pathname does not match tar's  de‐
          fault, you can inform tar about the correct pathname using the --rmt-command option.

   --force-local
          Archive file is local even if it has a colon.

   -F, --info-script=COMMAND, --new-volume-script=COMMAND
          Run COMMAND at the end of each tape (implies -M).  The command can include arguments.  When started, it
          will inherit tar's environment plus the following variables:

          TAR_VERSION
                 GNU tar version number.

          TAR_ARCHIVE
                 The name of the archive tar is processing.

          TAR_BLOCKING_FACTOR
                 Current blocking factor, i.e. number of 512-byte blocks in a record.

          TAR_VOLUME
                 Ordinal number of the volume tar is processing (set if reading a multi-volume archive).

          TAR_FORMAT
                 Format of the archive being processed.  One of: gnu, oldgnu, posix, ustar, v7.

          TAR_SUBCOMMAND
                 A short option (with a leading dash) describing the operation tar is executing.

          TAR_FD File descriptor which can be used to communicate the new volume name to tar.

          If the info script fails, tar exits; otherwise, it begins writing the next volume.

   -L, --tape-length=N
          Change tape after writing Nx1024 bytes.  If N is followed by a size suffix  (see  the  subsection  Size
          suffixes below), the suffix specifies the multiplicative factor to be used instead of 1024.

          This option implies -M.

   -M, --multi-volume
          Create/list/extract multi-volume archive.

   --rmt-command=COMMAND
          Use  COMMAND  instead  of  rmt  when  accessing remote archives.  See the description of the -f option,
          above.

   --rsh-command=COMMAND
          Use COMMAND instead of rsh when accessing remote archives.  See  the  description  of  the  -f  option,
          above.

   --volno-file=FILE
          When  this  option is used in conjunction with --multi-volume, tar will keep track of which volume of a
          multi-volume archive it is working in FILE.

   Device blocking       -b, –blocking-factor=BLOCKS              Set record size to BLOCKSx512 bytes.
   -B, --read-full-records
          When listing or extracting, accept incomplete input records after end-of-file marker.

   -i, --ignore-zeros
          Ignore zeroed blocks in archive.  Normally two consecutive 512-blocks filled with zeroes mean  EOF  and
          tar stops reading after encountering them.  This option instructs it to read further and is useful when
          reading archives created with the -A option.

   --record-size=NUMBER
          Set record size.  NUMBER is the number of bytes per record.  It must be multiple of 512.  It can can be
          suffixed  with  a  size suffix, e.g. --record-size=10K, for 10 Kilobytes.  See the subsection Size suf‐
          fixes, for a list of valid suffixes.

   Archive format selection       -H, –format=FORMAT              Create archive of the given format.  Valid formats are:
          gnu    GNU tar 1.13.x format

          oldgnu GNU format as per tar &lt;= 1.12.

          pax, posix
                 POSIX 1003.1-2001 (pax) format.

          ustar  POSIX 1003.1-1988 (ustar) format.

          v7     Old V7 tar format.

   --old-archive, --portability
          Same as --format=v7.

   --pax-option=keyword[[:]=value][,keyword[[:]=value]]...
          Control pax keywords when creating PAX archives (-H pax).  This option is equivalent to the  -o  option
          of the pax(1)utility.

   --posix
          Same as --format=posix.

   -V, --label=TEXT
          Create  archive  with  volume  name TEXT.  If listing or extracting, use TEXT as a globbing pattern for
          volume name.

   Compression options       -a, –auto-compress              Use archive suffix to determine the compression program.
   -I, --use-compress-program=COMMAND
          Filter data through COMMAND.  It must accept the -d option, for decompression.  The argument  can  con‐
          tain command line options.

   -j, --bzip2
          Filter the archive through bzip2(1).

   -J, --xz
          Filter the archive through xz(1).

   --lzip Filter the archive through lzip(1).

   --lzma Filter the archive through lzma(1).

   --lzop Filter the archive through lzop(1).

   --no-auto-compress
          Do not use archive suffix to determine the compression program.

   -z, --gzip, --gunzip, --ungzip
          Filter the archive through gzip(1).

   -Z, --compress, --uncompress
          Filter the archive through compress(1).

   --zstd Filter the archive through zstd(1).

   Local file selection       –add-file=FILE              Add FILE to the archive (useful if its name starts with a dash).
   --backup[=CONTROL]
          Backup  before removal.  The CONTROL argument, if supplied, controls the backup policy.  Its valid val‐
          ues are:

          none, off
                 Never make backups.

          t, numbered
                 Make numbered backups.

          nil, existing
                 Make numbered backups if numbered backups exist, simple backups otherwise.

          never, simple
                 Always make simple backups

          If CONTROL is not given, the value is taken from the VERSION_CONTROL environment variable.   If  it  is
          not set, existing is assumed.

   -C, --directory=DIR
          Change  to  DIR  before performing any operations.  This option is order-sensitive, i.e. it affects all
          options that follow.

   --exclude=PATTERN
          Exclude files matching PATTERN, a glob(3)-style wildcard pattern.

   --exclude-backups
          Exclude backup and lock files.

   --exclude-caches
          Exclude contents of directories containing file CACHEDIR.TAG, except for the tag file itself.

   --exclude-caches-all
          Exclude directories containing file CACHEDIR.TAG and the file itself.

   --exclude-caches-under
          Exclude everything under directories containing CACHEDIR.TAG

   --exclude-ignore=FILE
          Before dumping a directory, see if it contains FILE.  If so, read exclusion patterns  from  this  file.
          The patterns affect only the directory itself.

   --exclude-ignore-recursive=FILE
          Same  as  --exclude-ignore, except that patterns from FILE affect both the directory and all its subdi‐
          rectories.

   --exclude-tag=FILE
          Exclude contents of directories containing FILE, except for FILE itself.

   --exclude-tag-all=FILE
          Exclude directories containing FILE.

   --exclude-tag-under=FILE
          Exclude everything under directories containing FILE.

   --exclude-vcs
          Exclude version control system directories.

   --exclude-vcs-ignores
          Exclude files that match patterns read from VCS-specific ignore files.  Supported  files  are:  .cvsig‐
          nore, .gitignore, .bzrignore, and .hgignore.

   -h, --dereference
          Follow symlinks; archive and dump the files they point to.

   --hard-dereference
          Follow hard links; archive and dump the files they refer to.

   -K, --starting-file=MEMBER
          Begin at the given member in the archive.

   --newer-mtime=DATE
          Work  on  files whose data changed after the DATE.  If DATE starts with / or . it is taken to be a file
          name; the mtime of that file is used as the date.

   --no-null
          Disable the effect of the previous --null option.

   --no-recursion
          Avoid descending automatically in directories.

   --no-unquote
          Do not unquote input file or member names.

   --no-verbatim-files-from
          Treat each line read from a file list as if it were supplied in the command line.   I.e.,  leading  and
          trailing  whitespace  is  removed and, if the resulting string begins with a dash, it is treated as tar
          command line option.

          This is the default behavior.  The --no-verbatim-files-from option is provided as a way to  restore  it
          after --verbatim-files-from option.

          This  option  is positional: it affects all --files-from options that occur after it in, until --verba‐
          tim-files-from option or end of line, whichever occurs first.

          It is implied by the --no-null option.

   --null Instruct subsequent -T options to read null-terminated names verbatim  (disables  special  handling  of
          names that start with a dash).

          See also --verbatim-files-from.

   -N, --newer=DATE, --after-date=DATE
          Only  store files newer than DATE.  If DATE starts with / or . it is taken to be a file name; the ctime
          of that file is used as the date.

   --one-file-system
          Stay in local file system when creating archive.

   -P, --absolute-names
          Don't strip leading slashes from file names when creating archives.

   --recursion
          Recurse into directories (default).

   --suffix=STRING
          Backup before removal, override usual suffix.  Default suffix is ~, unless  overridden  by  environment
          variable SIMPLE_BACKUP_SUFFIX.

   -T, --files-from=FILE
          Get names to extract or create from FILE.

          Unless  specified otherwise, the FILE must contain a list of names separated by ASCII LF (i.e. one name
          per line).  The names read are handled the same way as command line arguments.  They undergo quote  re‐
          moval and word splitting, and any string that starts with a - is handled as tar command line option.

          If this behavior is undesirable, it can be turned off using the --verbatim-files-from option.

          The --null option instructs tar that the names in FILE are separated by ASCII NUL character, instead of
          LF.  It is useful if the list is generated by find(1) -print0 predicate.

   --unquote
          Unquote file or member names (default).

   --verbatim-files-from
          Treat each line obtained from a file list as a file name, even if it starts with a  dash.   File  lists
          are  supplied  with  the --files-from (-T) option.  The default behavior is to handle names supplied in
          file lists as if they were typed in the command line, i.e. any names starting with a dash  are  treated
          as tar options.  The --verbatim-files-from option disables this behavior.

          This  option  affects  all --files-from options that occur after it in the command line.  Its effect is
          reverted by the --no-verbatim-files-from} option.

          This option is implied by the --null option.

          See also --add-file.

   -X, --exclude-from=FILE
          Exclude files matching patterns listed in FILE.

   File name transformations       –strip-components=NUMBER              Strip NUMBER leading components from file names on extraction.
   --transform=EXPRESSION, --xform=EXPRESSION
          Use sed replace EXPRESSION to transform file names.

   File name matching options       These options affect both exclude and include patterns.
   --anchored
          Patterns match file name start.

   --ignore-case
          Ignore case.

   --no-anchored
          Patterns match after any / (default for exclusion).

   --no-ignore-case
          Case sensitive matching (default).

   --no-wildcards
          Verbatim string matching.

   --no-wildcards-match-slash
          Wildcards do not match /.

   --wildcards
          Use wildcards (default for exclusion).

   --wildcards-match-slash
          Wildcards match / (default for exclusion).

   Informative output       –checkpoint[=N]              Display progress messages every Nth record (default 10).
   --checkpoint-action=ACTION
          Run ACTION on each checkpoint.

   --clamp-mtime
          Only set time when the file is more recent than what was given with --mtime.

   --full-time
          Print file time to its full resolution.

   --index-file=FILE
          Send verbose output to FILE.

   -l, --check-links
          Print a message if not all links are dumped.

   --no-quote-chars=STRING
          Disable quoting for characters from STRING.

   --quote-chars=STRING
          Additionally quote characters from STRING.

   --quoting-style=STYLE
          Set quoting style for file and member names.  Valid values for STYLE are literal, shell,  shell-always,
          c, c-maybe, escape, locale, clocale.

   -R, --block-number
          Show block number within archive with each message.

   --show-omitted-dirs
          When listing or extracting, list each directory that does not match search criteria.

   --show-transformed-names, --show-stored-names
          Show file or archive names after transformation by --strip and --transform options.

   --totals[=SIGNAL]
          Print total bytes after processing the archive.  If SIGNAL is given, print total bytes when this signal
          is delivered.  Allowed signals are: SIGHUP, SIGQUIT, SIGINT, SIGUSR1, and SIGUSR2.  The SIG prefix  can
          be omitted.

   --utc  Print file modification times in UTC.

   -v, --verbose
          Verbosely list files processed.

   --warning=KEYWORD
          Enable  or  disable  warning messages identified by KEYWORD.  The messages are suppressed if KEYWORD is
          prefixed with no- and enabled otherwise.

          Multiple --warning messages accumulate.

          Keywords controlling general tar operation:

          all    Enable all warning messages.  This is the default.

          none   Disable all warning messages.

          filename-with-nuls
                 "%s: file name read contains nul character"

          alone-zero-block
                 "A lone zero block at %s"

          Keywords applicable for tar --create:

          cachedir
                 "%s: contains a cache directory tag %s; %s"

          file-shrank
                 "%s: File shrank by %s bytes; padding with zeros"

          xdev   "%s: file is on a different filesystem; not dumped"

          file-ignored
                 "%s: Unknown file type; file ignored"
                 "%s: socket ignored"
                 "%s: door ignored"

          file-unchanged
                 "%s: file is unchanged; not dumped"

          ignore-archive
                 "%s: file is the archive; not dumped"

          file-removed
                 "%s: File removed before we read it"

          file-changed
                 "%s: file changed as we read it"

          failed-read
                 Suppresses warnings about unreadable files or directories. This keyword applies only if used to‐
                 gether with the --ignore-failed-read option.

          Keywords applicable for tar --extract:

          existing-file
                 "%s: skipping existing file"

          timestamp
                 "%s: implausibly old time stamp %s"
                 "%s: time stamp %s is %s s in the future"

          contiguous-cast
                 "Extracting contiguous files as regular files"

          symlink-cast
                 "Attempting extraction of symbolic links as hard links"

          unknown-cast
                 "%s: Unknown file type '%c', extracted as normal file"

          ignore-newer
                 "Current %s is newer or same age"

          unknown-keyword
                 "Ignoring unknown extended header keyword '%s'"

          decompress-program
                 Controls  verbose  description of failures occurring when trying to run alternative decompressor
                 programs.  This warning is disabled by default (unless --verbose is used).  A common example  of
                 what you can get when using this warning is:

                 $ tar --warning=decompress-program -x -f archive.Z
                 tar (child): cannot run compress: No such file or directory
                 tar (child): trying gzip

                 This  means  that tar first tried to decompress archive.Z using compress, and, when that failed,
                 switched to gzip.

          record-size
                 "Record size = %lu blocks"

          Keywords controlling incremental extraction:

          rename-directory
                 "%s: Directory has been renamed from %s"
                 "%s: Directory has been renamed"

          new-directory
                 "%s: Directory is new"

          xdev   "%s: directory is on a different device: not purging"

          bad-dumpdir
                 "Malformed dumpdir: 'X' never used"

   -w, --interactive, --confirmation
          Ask for confirmation for every action.

   Compatibility options       -o     When creating, same as –old-archive.  When extracting, same as –no-same-owner.
   Size suffixes               Suffix    Units                   Byte Equivalent               b         Blocks                  SIZE x 512               B         Kilobytes               SIZE x 1024               c         Bytes                   SIZE               G         Gigabytes               SIZE x 1024^3               K         Kilobytes               SIZE x 1024               k         Kilobytes               SIZE x 1024               M         Megabytes               SIZE x 1024^2               P         Petabytes               SIZE x 1024^5               T         Terabytes               SIZE x 1024^4               w         Words                   SIZE x 2
RETURN VALUE       Tar exit code indicates whether it was able to successfully perform the requested operation, and if not,  what       kind of error occurred.
   0      Successful termination.

   1      Some  files differ.  If tar was invoked with the --compare (--diff, -d) command line option, this means
          that some files in the archive differ from their disk counterparts.  If tar was given one of the --cre‐
          ate,  --append  or  --update  options,  this  exit  code means that some files were changed while being
          archived and so the resulting archive does not contain the exact copy of the file set.

   2      Fatal error.  This means that some fatal, unrecoverable error occurred.

   If a subprocess that had been invoked by tar exited with a nonzero exit code, tar itself exits with that  code
   as well.  This can happen, for example, if a compression option (e.g. -z) was used and the external compressor
   program failed.  Another example is rmt failure during backup to a remote device.

]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>tar</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux的tcpdump命令</title>
    <url>/2012/05/06/linux-tcpdump-beginner/</url>
    <content><![CDATA[创建、修改、更新文件的touchlinux的tcpdump命令不常用，一般用来修改文件时间戳(可更改文件或目录的日期时间，包括存取时间和更改时间)或者新建一个不存在的文件。
命令格式$ touch [选项]... 文件...



其中选项如下所示：

-a   只更改存取时间。
-c   或–no-create 　不建立任何文档。
-d 　使用指定的日期时间，而非现在的时间。
-m  只更改变动时间。
-r 　把指定文件或目录的日期时间，统统设成和参考文件或目录的日期时间相同。
-t 　使用指定的日期时间，而非现在的时间。

创建不存在的文件$ ls$ touch a.txt b.txt$ lsa.txt b.txt

更新b.txt 的时间和 a.txt 时间戳相同# 将文件b.txt的时间戳与a.txt保持一致$ touch -r a.txt b.txt

设定文件的时间戳# 设定filename的时间戳为2012年05月06日13时14分15秒$ touch -t 201205061314.15 filename$ ls -l-rw-rw-r--. 1 user user 0 May  6  2012 filename

其中-t  time 使用指定的时间值 time 作为指定文件相应时间戳记的新值．此处的 time的形式如下为： [[CC]YY]MMDDhhmm[.SS]     
其中秒及年可以省略。
]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>touch</tag>
      </tags>
  </entry>
  <entry>
    <title>双向输出的 tee</title>
    <url>/2011/02/12/linux-tee-beginner/</url>
    <content><![CDATA[双向输出的 teeLinux的tee命令可以将输出输出到终端的同时写入文件。
这个命令对于既想试试看到输出保存到文件稍后查看的操作十分有用。
官方定义为：

tee - read from standard input and write to standard output and files

语法具体的使用方法为：
$ tee [OPTION]... [FILE]...



参数：

-a, --append 　追加到现有文件的后面，而非覆盖它．
-i, --ignore-interrupts 　忽略中断信号。

一般使用比如最简单的想查看一下当前有哪些文件并保存到一个日志，如下：
$ lsa.txt b.txt c.txt d.txt e.txt$ ls | tee list.loga.txt b.txt c.txt d.txt e.txt$ cat list.loga.txt b.txt c.txt d.txt e.txt

可以看到tee在保证同时显示在终端上还输出到了文件 list.log中。
同时保存到多个文件tee当然也是可以同时输出到多个文件的，比如：
$ lsa.txt b.txt c.txt d.txt e.txt$ ls | tee list.log listB.loga.txt b.txt c.txt d.txt e.txt$ cat list.loga.txt b.txt c.txt d.txt e.txt$ cat listB.loga.txt b.txt c.txt d.txt e.txt





与自己对话与自己对话如何呢，或者叫做复读机？ 
tee命令直接跟文件的话，会等待输入，并同步进行输出到终端和文件的操作。
$ tee test.log hellohelloworldworld$ cat test.loghelloworld



​    
]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>cat</tag>
        <tag>tee</tag>
      </tags>
  </entry>
  <entry>
    <title>终端技巧</title>
    <url>/2016/02/12/linux-terminal-misc/</url>
    <content><![CDATA[终端技巧打开终端的方式
鼠标点右键–terminal,即可打开。
点任务栏的”application”里面的”terminal”打开
命令方式：Alt＋F2后在出现”运行应用程序”中输入x-terminal-emulator(一般在你输入到x-term后系统会自己显示全部)或者输入”gnome-terminal”

使用终端的快捷方式
Shift+Ctrl+T:新建标签页
Shift+Ctrl+W:关闭标签页
Ctrl+PageUp:前一标签页
Ctrl+PageDown:后一标签页
Shift+Ctrl+PageUp:标签页左移
Shift+Ctrl+PageDown:标签页右移
Alt+1:切换到标签页1
Alt+2:切换到标签页2
Alt+3:切换到标签页3
Shift+Ctrl+N:新建窗口
Shift+Ctrl+Q:关闭终端

终端中的复制／粘贴:

Shift+Ctrl+C:复制
Shift+Ctrl+V:粘贴

终端改变大小：

F11：全屏
Ctrl+plus:放大
Ctrl+minus:减小
Ctrl+0:原始大小

打开多个终端时，要从一个终端转到另外一个终端，可以通过同时按下alt后，再按tab键，按到自己想要的终端后松开，即可跳到想要得终端
]]></content>
      <categories>
        <category>Linux炫技</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>terminal</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux的 tee 命令</title>
    <url>/2011/02/12/linux-tee/</url>
    <content><![CDATA[Linux的 tee 命令tee可以看见输出并将其写入到一个文件中可以看见输出并将其写入到一个文件中
如下使用tee命令在屏幕上看见输出并同样写入到日志文件my.log中
ls | tee my.log

tee可以保证你同时在屏幕上看到ls的输出并写入文件 my.log。
tee 的解释为：read from standard input and write to standard output and files
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>tee</tag>
      </tags>
  </entry>
  <entry>
    <title>时光总是催人老 time</title>
    <url>/2013/02/12/linux-time-beginner/</url>
    <content><![CDATA[时光总是催人老 time.. note::
  林花谢了春红，太匆匆。无奈朝来寒雨晚来风。

李煜《相见欢·林花谢了春红》

Linux time命令的用途，在于测量指定命令消耗的时间。
最常用的在于大概评估一个程序的运行时间。
这个命令很容易给人的印象是与date混淆起来
官方定义为：

time - time a simple command or give resource usage

可以给出包括系统的粗略时间。
语法$ time [options] command [arguments...]

参数：
​	- 可以认为没有参数
示例会显示程序或命令执行的消耗时间
$ time ls /varaccount  crash  games     lib    log  ......real    0m0.014suser    0m0.003ssys     0m0.010s$ time ps -auxroot     295490  0.0  0.0      0     0 ?        S    Feb20   0:10 [ldlm_cb00_019root     297717  0.0  0.0      0     0 ?        S&lt;   Jan29   0:04 [kworker/58:1Hroot     304801  0.0  0.0      0     0 ?        S    Mar19   0:00 [kworker/1:1]root     311110  0.0  0.0      0     0 ?        S    Mar20   0:00 [kworker/66:0]root     313146  0.0  0.0      0     0 ?        S    Mar20   0:01 [kworker/73:2]root     313461  0.0  0.0      0     0 ?        S&lt;   Jan29   0:00 [kworker/44:2Hroot     313914  0.0  0.0      0     0 ?        S    Feb21   0:10 [kworker/9:2]root     314118  0.0  0.0      0     0 ?        S    Feb21   3:34 [kworker/18:1]root     315801  0.0  0.0      0     0 ?        S    Mar20   0:00 [kworker/79:2]real    0m0.180suser    0m0.019ssys     0m0.114



唯一需要留意的是上面的三个含义：

real : 程序从开始调用到最后终止之间经过的实时时间
user : 程序本身，以及它所调用的库中的子例程使用的CPU 时间
sys : 程序直接或间接调用的系统调用执行的CPU 时间

]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>time</tag>
        <tag>时间日期</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux的 time 命令</title>
    <url>/2013/02/12/linux-time/</url>
    <content><![CDATA[Linux的 time 命令Linux time命令的用途，在于测量指定命令消耗的时间。
最常用的在于大概评估一个程序的运行时间。🔑
这个命令很容易给人的印象是与date混淆起来
官方定义为：

time - time a simple command or give resource usage

可以给出包括系统的粗略时间。
语法$ time [options] command [arguments...]

参数：
​	- 可以认为没有参数
1⃣ 示例会显示程序或命令执行的消耗时间
$ time ls /varaccount  crash  games     lib    log  ......real    0m0.014suser    0m0.003ssys     0m0.010s#=====================================$ time ps -auxroot     295490  0.0  0.0      0     0 ?        S    Feb20   0:10 [ldlm_cb00_019root     297717  0.0  0.0      0     0 ?        S&lt;   Jan29   0:04 [kworker/58:1Hroot     304801  0.0  0.0      0     0 ?        S    Mar19   0:00 [kworker/1:1]root     311110  0.0  0.0      0     0 ?        S    Mar20   0:00 [kworker/66:0]root     313146  0.0  0.0      0     0 ?        S    Mar20   0:01 [kworker/73:2]root     313461  0.0  0.0      0     0 ?        S&lt;   Jan29   0:00 [kworker/44:2Hroot     313914  0.0  0.0      0     0 ?        S    Feb21   0:10 [kworker/9:2]root     314118  0.0  0.0      0     0 ?        S    Feb21   3:34 [kworker/18:1]root     315801  0.0  0.0      0     0 ?        S    Mar20   0:00 [kworker/79:2]real    0m0.180suser    0m0.019ssys     0m0.114



唯一需要留意的是上面的三个含义：

real : 程序从开始调用到最后终止之间经过的实时时间
user : 程序本身，以及它所调用的库中的子例程使用的CPU 时间
sys : 程序直接或间接调用的系统调用执行的CPU 时间

]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>time</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux tmux终端复用神器</title>
    <url>/2016/05/06/linux-tmux/</url>
    <content><![CDATA[简介Tmux是一个优秀的终端复用软件，类似GNU Screen，但来自于OpenBSD，采用BSD授权。使用它最直观的好处就是，通过一个终端登录远程主机并运行tmux后，在其中可以开启多个控制台而无需再“浪费”多余的终端来连接这台远程主机；是BSD实现的Screen替代品，相对于Screen，它更加先进：支持屏幕切分，而且具备丰富的命令行参数，使其可以灵活、动态的进行各种布局和操作。
功能
提供了强劲的、易于使用的命令行界面。
可横向和纵向分割窗口。
窗格可以自由移动和调整大小，或直接利用四个预设布局之一。
支持 UTF-8 编码及 256 色终端。
可在多个缓冲区进行复制和粘贴。
可通过交互式菜单来选择窗口、会话及客户端。
支持跨窗口搜索。
支持自动及手动锁定窗口。

使用进入tmux面板后，一定要先按ctrl+b，然后松开，再按其他的组合键才生效。
新建会话第一个启动的 Tmux 窗口，编号是0，第二个窗口的编号是1。使用编号区分会话，不太直观，更好的方法是为会话起名。使用下面的指令即可：
$ tmux new -s &lt;session-name&gt;

查看会话查看当前所有的 Tmux 会话
$ tmux ls# or$ tmux list-session


分离会话这个是最常用的方法了，按下Ctrl+b d或者输入tmux detach命令，就会将当前会话与窗口分离。而此时会话里面的进程依然在后台执行。
参考查看会话来查看所有的会话。
接入会话attach命令用于重新接入某个已存在的会话，可以通过编号或者会话名来接入
# 使用会话编号$ tmux attach -t 0# 使用会话名称$ tmux attach -t &lt;session-name&gt;

杀死会话可以通过tmux kill-session命令用于杀死某个会话，与attach类似，可以通过会话编号与session名来kill
# 使用会话编号$ tmux kill-session -t 0# 使用会话名称$ tmux kill-session -t &lt;session-name&gt;


切换会话tmux switch命令用于切换会话。
# 使用会话编号$ tmux switch -t 0# 使用会话名称$ tmux switch -t &lt;session-name&gt;

重命名会话tmux rename-session命令用于重命名会话。
$ tmux rename-session -t 0 &lt;new-name&gt;

上面命令将0号会话重命名。
最简操作流程综上所述，以下是 Tmux 的最简操作流程。

新建会话tmux new -s session_name
在 Tmux 窗口运行所需的程序
按下快捷键Ctrl+b d将会话分离
下次使用时，重新连接到会话tmux attach-session -t session_name

窗格操作Tmux 可以将窗口分成多个窗格（pane），每个窗格运行不同的命令。以下命令都是在 Tmux 窗口中执行。
划分窗格tmux split-window命令用来划分窗格。
# 划分上下两个窗格$ tmux split-window# 划分左右两个窗格$ tmux split-window -h

移动光标tmux select-pane命令用来移动光标位置。
# 光标切换到上方窗格$ tmux select-pane -U# 光标切换到下方窗格$ tmux select-pane -D# 光标切换到左边窗格$ tmux select-pane -L# 光标切换到右边窗格$ tmux select-pane -R

交换窗格位置tmux swap-pane命令用来交换窗格位置。
# 当前窗格上移$ tmux swap-pane -U# 当前窗格下移$ tmux swap-pane -D


窗口管理除了将一个窗口划分成多个窗格，Tmux 也允许新建多个窗口。
新建窗口tmux new-window命令用来创建新窗口。
$ tmux new-window# 新建一个指定名称的窗口$ tmux new-window -n &lt;window-name&gt;

切换窗口tmux select-window命令用来切换窗口。
# 切换到指定编号的窗口$ tmux select-window -t &lt;window-number&gt;# 切换到指定名称的窗口$ tmux select-window -t &lt;window-name&gt;

重命名窗口tmux rename-window命令用于为当前窗口起名（或重命名）。
$ tmux rename-window &lt;new-name&gt;

七、其他命令下面是一些其他命令。
列出所有快捷键，及其对应的 Tmux 命令$ tmux list-keys
列出所有 Tmux 命令及其参数$ tmux list-commands
列出当前所有 Tmux 会话的信息$ tmux info
重新加载当前的 Tmux 配置$ tmux source-file ~/.tmux.conf
常用到的几个组合键：


快捷键
说明



ctrl+b ?
显示快捷键帮助


ctrl+b 空格键
采用下一个内置布局，这个很有意思，在多屏时，用这个就会将多有屏幕竖着展示


Ctrl+b ,
窗口重命名


ctrl+b !
把当前窗口变为新窗口


ctrl+b  “
模向分隔窗口


ctrl+b %
纵向分隔窗口


Ctrl+b ;
光标切换到上一个窗格


Ctrl+b {
当前窗格与上一个窗格交换位置


Ctrl+b }
当前窗格与下一个窗格交换位置


ctrl+b 空格键
采用下一个内置布局，这个很有意思，在多屏时，用这个就会将多有屏幕竖着展示


ctrl+b !
把当前窗口变为新窗口


ctrl+b  “
模向分隔窗口


ctrl+b %
纵向分隔窗口


ctrl+b q
显示分隔窗口的编号


ctrl+b o
跳到下一个分隔窗口。多屏之间的切换


ctrl+b 上下键
上一个及下一个分隔窗口


ctrl+b C-方向键
调整分隔窗口大小


ctrl+b &amp;
确认后退出当前tmux


ctrl+b [
复制模式，即将当前屏幕移到上一个的位置上，其他所有窗口都向前移动一个。


ctrl+b c
创建新窗口


ctrl+b d
脱离当前会话；这样可以暂时返回Shell界面，输入tmux attach能够重新进入之前的会话


ctrl+b n
选择下一个窗口


ctrl+b l
最后使用的窗口


Ctrl+b o
光标切换到下一个窗格


ctrl+b n
选择下一个窗口


ctrl+b l
最后使用的窗口


ctrl+b p
选择前一个窗口


ctrl+b w
以菜单方式显示及选择窗口


ctrl+b s
以菜单方式显示和选择会话。这个常用到，可以选择进入哪个tmux


ctrl+b t
显示时钟。然后按enter键后就会恢复到shell终端状态


Ctrl+b q
显示窗格编号


Ctrl+b x
关闭当前窗格


Ctrl+b z
当前窗格全屏显示，再使用一次会变回原来大小


Ctrl+b 
光标切换到其他窗格。是指向要切换到的窗格的方向键，比如切换到下方窗格，就按方向键↓


Ctrl+b Ctrl+o
所有窗格向前移动一个位置，第一个窗格变成最后一个窗格


Ctrl+b Alt+o
所有窗格向后移动一个位置，最后一个窗格变成第一个窗格


Ctrl+b Ctrl+
按箭头方向调整窗格大小


Ctrl+b 
切换到指定编号的窗口，其中的是状态栏上的窗口编号


基本概念tmux有三个基本概念：

会话(Session)
窗口(Window)
面板(Pane)

窗格(Pane)操作
% 左右平分出两个窗格
“ 上下平分出两个窗格
x 关闭当前窗格
{ 当前窗格前移
} 当前窗格后移
; 选择上次使用的窗格
o 选择下一个窗格，也可以使用上下左右方向键来选择
space 切换窗格布局，tmux 内置了五种窗格布局，也可以通过 ⌥1 至 ⌥5来切换
z 最大化当前窗格，再次执行可恢复原来大小
q 显示所有窗格的序号，在序号出现期间按下对应的数字，即可跳转至对应的窗格

窗口(window)操作tmux 除了窗格以外，还有窗口（window） 的概念。依次使用以下快捷键来熟悉 tmux 的窗口操作：

c 新建窗口，此时当前窗口会切换至新窗口，不影响原有窗口的状态
p 切换至上一窗口
n 切换至下一窗口
w 窗口列表选择，注意 macOS 下使用 ⌃p 和 ⌃n 进行上下选择
&amp; 关闭当前窗口
, 重命名窗口，可以使用中文，重命名后能在 tmux 状态栏更快速的识别窗口 id
0 切换至 0 号窗口，使用其他数字 id 切换至对应窗口
f 根据窗口名搜索选择窗口，可模糊匹配

Session操作刚说完flag就倒了，本地使用还好，SSH的时候session真的必不可少。
下面列出一些session的操作
启动新会话：tmux [new -s 会话名 -n 窗口名]

恢复会话：tmux at [-t 会话名]

列出所有会话：tmux ls

关闭会话：tmux kill-session -t 会话名

关闭所有会话：tmux kill-server
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>tmux</tag>
      </tags>
  </entry>
  <entry>
    <title>任务管理器的 top</title>
    <url>/2012/02/12/linux-top-beginner/</url>
    <content><![CDATA[任务管理器的 toptop命令比较像Windows里面的任务管理器，提供一个动态实时的系统状态检测，可以检测实时显示内存、CPU、进程的运行状态，主要在分析系统负载的时候比较常用。
官方定义为：

top - display Linux processes

状态默认实时显示，间隔为1秒。
使用的方法如下（选项超级多，其实不复杂）：
$ top -bcHiOSs -d secs -n max -u|U user -p pid -o fld -w [cols]

参数说明：

-d : 改变显示的更新速度，或是在交互式( interactive command)按 s或d
-c : 切换显示模式，共有两种模式，一是只显示执行程序的名称，另一种是显示完整的路径与名称；这个在定位执行命令的时候较常用
-n : 更新的次数，完成后将会退出
-b : 批模式操作，主要用来将 top 的结果输出到其他程序或者文件；
-i : 不显示任何闲置不使用CPU的进程
-s : 安全模式，取消交谈式指令
-pN1 -pN2 ...  or  -pN1,N2,N3 ...：指定PID模式，仅仅监控N1，N2等信息
-u/U user：仅仅关注user的进程情况

常规使用在输入top命令以后，如果希望退出，可以数据q或者直接Ctrl+c即可。
还有一个情况，可以输入h进行帮助查询，用于进一步的交互操作。
通常情况下，最常用的就是输入top命令，不加任何参数，这种情况下最希望看到的就是最占用系统资源的进程。
如下所示：
$ toptop - 22:23:20 up 461 days,  7:52, 18 users,  load average: 1.82, 1.57, 1.45Tasks: 773 total,   1 running, 768 sleeping,   0 stopped,   4 zombie%Cpu(s): 10.1 us,  6.5 sy,  0.0 ni, 83.3 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 stKiB Mem : 32664832 total,   668020 free, 15683576 used, 16313236 buff/cacheKiB Swap: 16449532 total, 13409776 free,  3039756 used. 15787188 avail Mem   PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND                                                                                7965 dbus      20   0   76092   8456   1704 S   7.5  0.0  40307:04 dbus-daemon                                                                                                                  23460 root      20   0  397640   5560   3248 S   4.2  0.0   4738:26 accounts-daemon                                                                        4321 user       20   0  821828 104812   4584 S   3.2  0.3   7380:28 gsd-color                                    

此时可以看到系统的基本信息，可以看到分为三个部分：

汇总信息：可以看到系统的运行状态，总的负载信息，运行总的任务，登陆的用户，CPU及内存的状态等等。
Fields/Columns 头信息：用来标记接下来所有进程对应的信息
Task 区域：每个运行程序的各种信息，在Fields/Columns有对应的，比如PID、用户、占用CPU、MEM及对应的命令等等。

显示完整命令$ top -c7965 dbus      20   0   76092   8456   1704 S   7.5  0.0  40307:04 /usr/bin/dbus-daemon  

此时省去其他信息，可以看到dbus-daemon增加了路径信息为**/usr/bin/dbus-daemon**
设置信息更新次数这个命令用于定量显示，比如刷新10次后退出，如下：
$ top -n 10



设置信息更新时间如果觉得太长或者太短，可以通过-d来设置，或者在交互模式下输入d或者s来设置。
$ top -d 0.8 # 设置为0.8秒$ top -d 6 # 设置为6秒



显示指定的进程信息如果仅仅对某个进程感兴趣，如下指定PID即可。
$ top -p 1234 # 对进程1234感兴趣



指定用户的进程信息作为管理员or朋友，或许对某个用户感兴趣，比如user，此时可以仅仅显示该用户的进程信息
$ top -u user
]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>系统管理</tag>
        <tag>top</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux的 top 命令</title>
    <url>/2012/02/12/linux-top/</url>
    <content><![CDATA[Linux 的 top 命令top命令比较像Windows里面的任务管理器，提供一个动态实时的系统状态检测，可以检测实时显示内存、CPU、进程的运行状态，主要在分析系统负载的时候比较常用。
官方定义为：

top - display Linux processes

状态默认实时显示，间隔为1秒。
使用的方法如下（选项超级多，其实不复杂）：
$ top -bcHiOSs -d secs -n max -u|U user -p pid -o fld -w [cols]

参数说明：

-d : 改变显示的更新速度，或是在交互式( interactive command)按 s或d
-c : 切换显示模式，共有两种模式，一是只显示执行程序的名称，另一种是显示完整的路径与名称；这个在定位执行命令的时候较常用
-n : 更新的次数，完成后将会退出
-b : 批模式操作，主要用来将 top 的结果输出到其他程序或者文件；
-i : 不显示任何闲置不使用CPU的进程
-s : 安全模式，取消交谈式指令
-pN1 -pN2 ...  or  -pN1,N2,N3 ...：指定PID模式，仅仅监控N1，N2等信息
-u/U user：仅仅关注user的进程情况

常规使用在输入top命令以后，如果希望退出，可以数据q或者直接Ctrl+c即可。
还有一个情况，可以输入h进行帮助查询，用于进一步的交互操作。
通常情况下，最常用的就是输入top命令，不加任何参数，这种情况下最希望看到的就是最占用系统资源的进程。
如下所示：
$ toptop - 22:23:20 up 461 days,  7:52, 18 users,  load average: 1.82, 1.57, 1.45Tasks: 773 total,   1 running, 768 sleeping,   0 stopped,   4 zombie%Cpu(s): 10.1 us,  6.5 sy,  0.0 ni, 83.3 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 stKiB Mem : 32664832 total,   668020 free, 15683576 used, 16313236 buff/cacheKiB Swap: 16449532 total, 13409776 free,  3039756 used. 15787188 avail Mem   PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND                                                                                7965 dbus      20   0   76092   8456   1704 S   7.5  0.0  40307:04 dbus-daemon                                                                                                                  23460 root      20   0  397640   5560   3248 S   4.2  0.0   4738:26 accounts-daemon                                                                        4321 user       20   0  821828 104812   4584 S   3.2  0.3   7380:28 gsd-color                                    

此时可以看到系统的基本信息，可以看到分为三个部分：

汇总信息：可以看到系统的运行状态，总的负载信息，运行总的任务，登陆的用户，CPU及内存的状态等等。
Fields/Columns 头信息：用来标记接下来所有进程对应的信息
Task 区域：每个运行程序的各种信息，在Fields/Columns有对应的，比如PID、用户、占用CPU、MEM及对应的命令等等。

显示完整命令$ top -c7965 dbus      20   0   76092   8456   1704 S   7.5  0.0  40307:04 /usr/bin/dbus-daemon  

此时省去其他信息，可以看到dbus-daemon增加了路径信息为**/usr/bin/dbus-daemon**
设置信息更新次数这个命令用于定量显示，比如刷新10次后退出，如下：
$ top -n 10



设置信息更新时间如果觉得太长或者太短，可以通过-d来设置，或者在交互模式下输入d或者s来设置。
$ top -d 0.8 # 设置为0.8秒$ top -d 6 # 设置为6秒



显示指定的进程信息如果仅仅对某个进程感兴趣，如下指定PID即可。
$ top -p 1234 # 对进程1234感兴趣



指定用户的进程信息作为管理员or朋友，或许对某个用户感兴趣，比如user，此时可以仅仅显示该用户的进程信息
$ top -u user





全局设置A - Alt display      Off (full-screen)

H - Threads mode     Off (summarize as tasks)I - Irix mode        On  (no, `solaris’ smp)

p - PID monitoring   Off (show all processes)

B - 使能加粗 ：可以切换全局的显示设置Summary-Area-defaultsl - Load Avg/Uptime  On  (thus program name)t - Task/Cpu states  On  (1+1 lines, see 1') m - Mem/Swap usage   On  (2 lines worth) 1 - Single Cpu       Off (thus multiple cpus) Task-Area-defaults b - Bold hilite      Off (use reverse’)

J - Num align right  On  (not left justify)j - Str align right  Off (not right justify)R - Reverse sort     On  (pids high-to-low)

u - User filter      Off (show euid only)

U - User filter      Off (show any uid)V - Forest view      On  (show as branches)x - Column hilite    Off (no, sort field)y - Row hilite       On  (yes, running tasks)z - color/mono       On  (show colors)


​       
参考实例
显示进程信息：
[root@linuxcool ~]# top

显示完整的进程信息：
[root@linuxcool ~]# top -c

以批处理模式显示程序信息：
[root@linuxcool ~]# top -b

以累积模式显示程序信息：
[root@linuxcool ~]# top -s

设置信息更新次数：
[root@linuxcool ~]# top -n 2



]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>系统管理</tag>
        <tag>top</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux的touch命令</title>
    <url>/2012/05/06/linux-touch-beginner/</url>
    <content><![CDATA[创建、修改、更新文件的touchlinux的touch命令不常用，一般用来修改文件时间戳(可更改文件或目录的日期时间，包括存取时间和更改时间)或者新建一个不存在的文件。
命令格式$ touch [选项]... 文件...



其中选项如下所示：

-a   只更改存取时间。
-c   或–no-create 　不建立任何文档。
-d 　使用指定的日期时间，而非现在的时间。
-m  只更改变动时间。
-r 　把指定文件或目录的日期时间，统统设成和参考文件或目录的日期时间相同。
-t 　使用指定的日期时间，而非现在的时间。

创建不存在的文件$ ls$ touch a.txt b.txt$ lsa.txt b.txt

更新b.txt 的时间和 a.txt 时间戳相同# 将文件b.txt的时间戳与a.txt保持一致$ touch -r a.txt b.txt

设定文件的时间戳# 设定filename的时间戳为2012年05月06日13时14分15秒$ touch -t 201205061314.15 filename$ ls -l-rw-rw-r--. 1 user user 0 May  6  2012 filename

其中-t  time 使用指定的时间值 time 作为指定文件相应时间戳记的新值．此处的 time的形式如下为： [[CC]YY]MMDDhhmm[.SS]     
其中秒及年可以省略。
]]></content>
      <categories>
        <category>Linux</category>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>touch</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux的touch命令</title>
    <url>/2012/05/06/linux-touch/</url>
    <content><![CDATA[创建、修改、更新文件的touchlinux的touch命令不常用，一般用来修改文件时间戳(可更改文件或目录的日期时间，包括存取时间和更改时间)或者新建一个不存在的文件。
命令格式$ touch [选项]... 文件...



其中选项如下所示：

-a   只更改存取时间。
-c   或–no-create 　不建立任何文档。
-d 　使用指定的日期时间，而非现在的时间。
-m  只更改变动时间。
-r 　把指定文件或目录的日期时间，统统设成和参考文件或目录的日期时间相同。
-t 　使用指定的日期时间，而非现在的时间。

创建不存在的文件$ ls$ touch a.txt b.txt$ lsa.txt b.txt

更新b.txt 的时间和 a.txt 时间戳相同# 将文件b.txt的时间戳与a.txt保持一致$ touch -r a.txt b.txt

设定文件的时间戳# 设定filename的时间戳为2012年05月06日13时14分15秒$ touch -t 201205061314.15 filename$ ls -l-rw-rw-r--. 1 user user 0 May  6  2012 filename

其中-t  time 使用指定的时间值 time 作为指定文件相应时间戳记的新值．此处的 time的形式如下为： [[CC]YY]MMDDhhmm[.SS]     
其中秒及年可以省略。
]]></content>
      <categories>
        <category>Linux</category>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>touch</tag>
      </tags>
  </entry>
  <entry>
    <title>真假转换之间 tr</title>
    <url>/2018/07/07/linux-tr-beginner/</url>
    <content><![CDATA[真假转换之间 tr.. note::  假作真时真亦假，无为有处有还无。  曹雪芹《红楼梦》
Linux tr 命令用于转换或删除字符。
tr 命令可以从标准输入读取数据，经过字符串转译后，将结果输出到标准输出。
官方定义为：

tr - translate or delete characters

使用方法为：
$ tr [OPTION]... SET1 [SET2]



其中常用的三个选项为：

-d, --delete：删除指令字符
[:lower:] ：所有小写字母
[:upper:] ：所有大写字母
[:blank:] ：所有空格

a-z小写全部转换为大写默认无参数的显示
$ echo "Hello World, Welcome to Linux!" | tr a-z A-ZHELLO WORLD, WELCOME TO LINUX!# 还有一种方法$ echo "Hello World, Welcome to Linux!" | tr [:lower:] [:upper:]HELLO WORLD!





A-Z大写全部转换为小写默认无参数的显示
$ echo "Hello World, Welcome to Linux!" | tr  A-Z a-zhello world, welcome to linux!# 还有一种方法$ echo "Hello World, Welcome to Linux!" | tr [:upper:] [:lower:]hello world, welcome to linux!



貌似起名可以用这个很多变量或者函数起名字都会移除元音字符，可以考虑使用-d参数，如下：
$ echo "Hello World, Welcome to Linux!" | tr -d a,o,e,iHll Wrld Wlcm t Lnux!




不过感觉删除的多了，也不一定是好事。。。
比如里外看Wlcm不晓得啥意思

移除文件中的所有空格同理，使用-d，结合[:blank:]可以快速删除所有空格。
$ echo "Hello World, Welcome to Linux!" | tr -d [:blank:]HelloWorld,WelcometoLinux!

]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>cat</tag>
        <tag>tr</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux的tracepath命令</title>
    <url>/2013/05/06/linux-tracepath-beginner/</url>
    <content><![CDATA[Linux的tracepath命令tracepath用于显示报文到达某一个地址的路由信息，能够发现其中的MTU信息。
在探测过程中，会使用UDP端口或随机端口。所以可以看到后面的？符号。与traceroute类似。
这对于长距离的数据传输分析有很明显的帮助作用。
官方的定义为：

 tracepath, tracepath6 - traces path to a network host discovering MTU along this path

使用方法为：
$ tracepath [-n] [-b] [-l pktlen] [-m max_hops] [-p port] destination

其中选项如下所示：

-n：只显示IP地址信息（默认是显示域名的，这个选项将不显示域名了）
-b：同时显示主机名和IP地址（默认没有域名的只显示IP地址，这个选项即使没有主机名也会把IP地址作为主机名）
-l：设置初始化的数据包长度，默认tracepath为65535，而tracepaht6为128000
-m：设置最大的hops（或最大的TTL）为max_hops（默认为30）
-p：设置初始使用的目标端口

官网的一个例子及含义root@mops:~ $ tracepath6 3ffe:2400:0:109::21?: [LOCALHOST]                      pmtu 15001:  dust.inr.ac.ru                   0.411ms2:  dust.inr.ac.ru        asymm  1   0.390ms pmtu 14802:  3ffe:2400:0:109::2               463.514ms reached    Resume: pmtu 1480 hops 2 back 2



以其中一行为例：



TTL
探测信息



1?:
[LOCALHOST]                      pmtu 1500


1:
dust.inr.ac.ru                   0.411ms


这一列显示探测的TTL，用分号来分割。不过有些情况下信息不足以确认，就出现了猜测的?
显示网络探测信息：如果未发送到网络，则为路由器地址或者localhost地址；这里还会显示MTU、延迟等等等。


最后一行会总结整个链路的状态信息，显示了检测到的路径MTU、到达目的地的hops以及从目的地返回的hops数。
可以与ping配合使用，可以先用ping获取到具体的IP地址，然后使用tracepath进行进一步的分析。
$  ping www.bing.comPING china.bing123.com (202.89.233.101) 56(84) bytes of data.64 bytes from 202.89.233.101 (202.89.233.101): icmp_seq=1 ttl=116 time=28.1 ms64 bytes from 202.89.233.101 (202.89.233.101): icmp_seq=2 ttl=116 time=27.9 ms^C--- china.bing123.com ping statistics ---2 packets transmitted, 2 received, 0% packet loss, time 1001msrtt min/avg/max/mdev = 27.964/28.072/28.181/0.199 ms$ tracepath 202.89.233.101 1?: [LOCALHOST]                                         pmtu 1500 1:  no reply 2:  202.127.24.1                                          2.859ms ...]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>tracepath</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux的traceroute命令</title>
    <url>/2013/05/06/linux-traceroute-beginner/</url>
    <content><![CDATA[Linux的traceroute命令..note:: 少小离家老大回，乡音无改鬓毛衰。 贺知章《回乡偶书二首·其一》
Linux traceroute命令用于打印显示数据包到网络主机的路径。
traceroute会跟踪从IP网络发送到指定主机的路由包，并利用IP协议的生存时间(TTL)字段，试图在通往主机路径上的每个网关得到一个ICMP TIME_EXCEEDED响应，由此可得具体的路由信息。
官方的定义为：

 traceroute - print the route packets trace to network host

语法使用方法还挺复杂的，不过常用的不多：
$ traceroute [-46dFITUnreAV] [-f first_ttl] [-g gate,...]               [-i device] [-m max_ttl] [-p port] [-s src_addr]               [-q nqueries] [-N squeries] [-t tos]               [-l flow_label] [-w waittimes] [-z sendwait] [-UL] [-D]               [-P proto] [--sport=port] [-M method] [-O mod_options]               [--mtu] [--back]               host [packet_len]


最简单的一个实例显示到达目的地的数据包路由
$ traceroute www.bing.comtraceroute to www.bing.com (202.89.233.101), 30 hops max, 60 byte packets 1  * * * 2  10.12.24.1 (202.127.24.1)  3.487 ms  3.490 ms  4.484 ms 3  * * * 4  192.168.1.53 (192.168.1.53)  4.437 ms  4.435 ms  4.426 ms 5  * * 211.102.30.10 (211.102.30.10)  4.358 ms 6  202.97.63.141 (202.97.63.141)  4.344 ms 202.97.53.117 (202.97.53.117)  3.892 ms 202.97.37.61 (202.97.37.61)  5.872 ms 7  202.97.87.121 (202.97.87.121)  3.902 ms 202.97.87.153 (202.97.87.153)  3.878 ms * 8  202.97.97.233 (202.97.97.233)  35.858 ms  40.803 ms  40.796 ms 9  * 36.110.248.146 (36.110.248.146)  26.951 ms *10  * 220.181.81.82 (220.181.81.82)  26.931 ms 180.149.128.201 (180.149.128.201)  26.941 ms11  220.181.17.86 (220.181.17.86)  33.956 ms 220.181.81.10 (220.181.81.10)  26.943 ms *




]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>ping</tag>
        <tag>traceroute</tag>
        <tag>ping6</tag>
        <tag>tcpdump</tag>
        <tag>netstat</tag>
      </tags>
  </entry>
  <entry>
    <title>树状结构的tree</title>
    <url>/2015/04/07/linux-tree-beginner/</url>
    <content><![CDATA[树状结构的treeLinux tree命令以树状图列出目录的内容。
执行tree指令，它会列出指定目录下的所有文件，包括子目录里的文件。
官方定义为：

tree - list contents of directories in a tree-like format.

使用方法为：
$ tree  [-acdfghilnpqrstuvxACDFQNSUX] [-L level [-R]] [-H baseHREF] [-T title] [-o filename] [--nolinks] [-P pattern] [-I pat‐       tern] [--inodes] [--device]  [--noreport]  [--dirsfirst]  [--version]  [--help]  [--filelimit  #]  [--si]  [--prune]  [--du]       [--timefmt format] [--matchdirs] [--fromfile] [--] [directory ...]



参数比较多，也比较复杂。其中常用的选项为：

-d 显示目录名称而非内容。
-D 列出文件或目录的更改时间。

​    
实例 默认显示默认显示当前目录的信息，比如tree和tree .的含义一样。命令有如下输出结果：
$ tree   .├── a├── aa│   ├── aab│   ├── aac│   ├── aad│   └── aae├── b├── bb│   └── bbb├── c├── d├── e└── f2 directories, 11 files





只显示目录$ tree -d         .├── aa└── bb





显示具体的修改时间$ tree -D.├── [Apr 7 22:34]  a├── [Apr 7 22:37]  aa│   ├── [Apr 7 22:35]  aab│   ├── [Apr 7 22:35]  aac│   ├── [Apr 7 22:35]  aad│   └── [Apr 7 22:35]  aae├── [Apr 7 22:34]  b├── [Apr 7 22:39]  bb│   └── [Apr 7 22:39]  bbb├── [Apr 7 22:34]  c├── [Apr 7 22:34]  d├── [Apr 7 22:33]  e└── [Apr 7 22:33]  f2 directories, 11 files




默认情况下tree可能没有安装，可以通过apt/yum install tree来安装。

]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>目录导航</tag>
        <tag>tree</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux下碰到的一些问题</title>
    <url>/2011/05/26/linux-troubleshootings/</url>
    <content><![CDATA[Linux下碰到的一些问题如何解决warning: no newline at end of file?今天写了一段代码, 是在Windows下编辑的, 保存后放在linux系统下编译.
gcc和cc都产生以下的警告: 
a.h:1:2: warning: no newline at end of file

后来发现解决这个问题产生的原因是源文件的最后一行没有回车符造成的; 解决的办法很简单, 在最后一行敲一个回车, 然后保存, 重新编译.
Linux运行文件时报错 bash $’\r’ command not found这个主要是跨平台的问题，在Windows下编写好的sh文件，丢到Linux下运行会报错：bash: $’\r’: command not found。这是因为Windows系统的文件换行使用的是\r\n，而Unix系统是\n，可以通过下面的方式解决：
通过dos2unix来进行文件转换
$ dos2unix filename.sh

或者使用vim打开文件，然后使用命令:set ff=unix，保存文件即可。
send-mail: fatal: parameter inet_interfaces: no local interface found for ::1在Linux里面使用mail发送邮件的时候报错：
$ echo 'Title' | mail -s "TEST" mail@mail.com$ send-mail: fatal: parameter inet_interfaces: no local interface found for ::1



解决方法如下：打开文件 /etc/postfix/main.cf，将原始内容
inet_interfaces = localhostinet_protocols = all

修改为：
inet_interfaces = allinet_protocols = all




然后重新启动就ok了，service postfix restart
bashrc每次都不自动导入新建的用户发现每次都不能把各种环境变量导入进来，导致类似的命令都无法使用，后面发现是少了bash_profile文件，只需要新建该文件：
$ touch ~/.bash_profile

然后加上如下内容：
# .bash_profile# Get the aliases and functionsif [ -f ~/.bashrc ]; then        . ~/.bashrcfi# User specific environment and startup programsPATH=$PATH:$HOME/.local/bin:$HOME/binexport PATH



保存退出重新登陆，顺利解决。
/lib64/libstdc++.so.6: version `CXXABI_1.3.8’ not found这个问题出现在CentOS7上，编译一个软件的时候出现的，首先可以查看CXXABI可用的版本，如下：
$ strings /usr/lib64/libstdc++.so.6 | grep 'CXXABI'CXXABI_1.3CXXABI_1.3.1CXXABI_1.3.2CXXABI_1.3.3CXXABI_1.3.4CXXABI_1.3.5CXXABI_1.3.6CXXABI_1.3.7CXXABI_1.3.8CXXABI_1.3.9CXXABI_1.3.10CXXABI_1.3.11CXXABI_1.3.12CXXABI_TM_1CXXABI_FLOAT128CXXABI_1.3CXXABI_1.3.11CXXABI_1.3.2CXXABI_1.3.6CXXABI_FLOAT128CXXABI_1.3.12CXXABI_1.3.9CXXABI_1.3.1CXXABI_1.3.5CXXABI_1.3.8CXXABI_1.3.4CXXABI_TM_1CXXABI_1.3.7CXXABI_1.3.10CXXABI_1.3.3



查看本机的其他关于libstdc的版本
$ find / -name libstdc++.so.6/var/lib/docker/overlay2/7929ef6fe4ed49351d40d41db72096133c8767d3f2aea01eab66040e38efba37/diff/usr/lib/x86_64-linux-gnu/libstdc++.so.6/var/lib/docker/overlay2/39955c16316d10641ff5a9ed525094e7b29f0657e26332511c972b437c309598/diff/usr/lib/x86_64-linux-gnu/libstdc++.so.6/var/lib/docker/overlay2/42fa5b2822ec5fd3837777e5b06583b6aeab9b48b2a3b168e99f9e3251084d27/diff/usr/lib/x86_64-linux-gnu/libstdc++.so.6/var/lib/docker/overlay2/3732c1cb1021032bffa34a3858c00a3c33e4e67102eb7216412a5079ba6f4369/diff/usr/lib64/libstdc++.so.6.../var/lib/docker/overlay2/565aeb287ef033e4384a87fcc2f451c68db294e659124f6d772dcb1658470d8e/diff/usr/lib/x86_64-linux-gnu/libstdc++.so.6/var/lib/docker/overlay2/hi35aa9ta0ij3t4x3k6br7gm6/diff/usr/lib/x86_64-linux-gnu/libstdc++.so.6/var/lib/docker/overlay2/whqa9v6f82q5x1i2mxsh8fo08/diff/usr/lib/x86_64-linux-gnu/libstdc++.so.6/var/lib/snapd/snap/core/15419/usr/lib/x86_64-linux-gnu/libstdc++.so.6/var/lib/snapd/snap/core/15511/usr/lib/x86_64-linux-gnu/libstdc++.so.6/usr/lib/libstdc++.so.6/usr/lib64/libstdc++.so.6/home/oper/anaconda3/lib/libstdc++.so.6



解决的方法，很简单，且已经奏效，把anaconda里面比较新的做一个软连接到/usr/lib64即可解决，不过记得做好备份。
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>difx</tag>
        <tag>touch</tag>
      </tags>
  </entry>
  <entry>
    <title>终端链接 tty</title>
    <url>/2017/04/12/linux-tty-beginner/</url>
    <content><![CDATA[终端链接 ttyLinux tty命令用于显示终端机连接标准输入设备的文件名称。
在Linux操作系统中，所有外围设备都有其名称与代号，这些名称代号以特殊文件的类型存放于/dev目录下。
比如ttyN就是今天说的设备，而sddN等就是硬盘设备。
你可以执行tty(teletypewriter)指令查询目前使用的终端机的文件名称。
官方定义为：

tty - print the file name of the terminal connected to standard input

使用方法比较简单：
$ tty [-s][--help][--version]

对于-s选项就是–silent，–quiet，即屏蔽掉输出，仅仅显示一个退出状态。
默认使用默认情况下显示当前终端
$ tty/dev/pts/4



查询谁在以及在那个tty在Linux里面输入who可以看到目前登陆的用户，而输出信息包括用户名，tty终端，及登陆的时间信息等等。
$ whouser1      pts/4        2017-04-21 19:58 (xxx.xxx.xxx.xxx)user1      pts/5        2017-04-07 13:41 (:99)user1      pts/0        2017-04-08 16:31 (:99)user1      pts/1        2017-04-08 17:12 (:99)user1      :0           2017-04-15 15:05 (:0)user1      pts/2        2017-04-15 15:38 (:0)user2  	   pts/3        2017-04-16 08:53 (:3)user2      pts/6        2017-04-16 11:01 (:3)user2      pts/7        2017-04-16 16:49 (:3)user3      pts/8        2017-04-21 20:05 (xxx.xxx.xxx.xxx)user3      pts/9        2017-04-21 20:07 (xxx.xxx.xxx.xxx)



而如前面所说，对于write命令其中有一个参数就是指定ttyN的信息。
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>write</tag>
        <tag>Linux炫技</tag>
        <tag>who</tag>
        <tag>tty</tag>
      </tags>
  </entry>
  <entry>
    <title>Ubuntu busybox 无法启动问题</title>
    <url>/2019/02/01/linux-ubuntu-busybox/</url>
    <content><![CDATA[Ubuntu busybox 无法启动问题屏幕错误提示
错误显示类似于：
mount: mounting /dev/disk/by-uuid/***************************** on /rootfailed: Invalid argumentmount: mounting /sys on /root/sys failed: No such file or directorymount: mounting /dev on /root/dev failed: No such file or directorymount: mounting /sys on /root/sys failed: No such file or directorymount: mounting /proc on /root/proc failed: No such file or directoryTarget file system doesn't have /sbin/initNo init found. Try passing init= bootargBusybox v1.13.3 (Ubuntu 1:1.13.3-1ubuntu7) built-in shell (ash)Enter 'help' for a list of built-in commands(initramfs) _

解决方案
从Ubuntu10.04 live CD引导系统；
打开命令行；
运行sudo fdisk -l回车，目的是查看设备名称。输出类似于：Disk /dev/sda: 250.1 GB, 250059350016 bytes255 heads, 63 sectors/track, 30401 cylindersUnits = cylinders of 16065 * 512 = 8225280 bytesDisk identifier: **********Device Boot Start End Blocks Id System/dev/sda1 * 1 30238 242886703+ 83 Linux/dev/sda2 30239 30401 1309297+ 5 Extended/dev/sda5 30239 30401 1309266 82 Linux swap / Solaris
选择Linux所在分区: /dev/sda1。如果/boot单独分区了则选择/boot所在分区。（我个人认为）
运行sudo fsck /dev/sda1回车;
重启电脑，正常引导系统。

]]></content>
      <categories>
        <category>Linux</category>
        <category>Ubuntu</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title>Ubuntu 删除多余内核</title>
    <url>/2012/03/27/linux-ubuntu-delete-kernels/</url>
    <content><![CDATA[ubuntu删除多余内核如果升级到了一个新的内核，并且还比较稳定，那么老的内核就可以清理了，放在电脑里也占位置。方法（命令行比较通用）如下：
1.查看系统内存在的内核版本列表：
sudo dpkg –get-selections |grep linux

结果:
libselinux1                              installlinux-firmware                              installlinux-generic                                 installlinux-headers-3.2.0-33                       installlinux-headers-3.2.0-33-generic                installlinux-headers-3.2.0-33-generic-pae        installlinux-headers-3.2.0-34                       installlinux-headers-3.2.0-34-generic                installlinux-headers-3.2.0-34-generic-pae        installlinux-headers-3.2.0-35                       installlinux-headers-3.2.0-35-generic                installlinux-headers-3.2.0-35-generic-pae        installlinux-headers-3.2.0-37                       installlinux-headers-3.2.0-37-generic                installlinux-headers-3.2.0-37-generic-pae        installlinux-headers-3.2.0-38                       installlinux-headers-3.2.0-38-generic                installlinux-headers-3.2.0-38-generic-pae        installlinux-headers-3.2.0-40                       installlinux-headers-3.2.0-40-generic                installlinux-headers-3.2.0-40-generic-pae        installlinux-headers-generic                         installlinux-headers-generic-pae                 installlinux-image-2.6.32-21-generic                 deinstalllinux-image-2.6.32-40-generic                 deinstalllinux-image-2.6.32-41-generic                 deinstalllinux-image-2.6.32-42-generic                 installlinux-image-3.2.0-33-generic                   installlinux-image-3.2.0-34-generic                   installlinux-image-3.2.0-35-generic                   installlinux-image-3.2.0-37-generic                   installlinux-image-3.2.0-38-generic                   installlinux-image-3.2.0-40-generic                   installlinux-image-generic                            installlinux-libc-dev                                 installlinux-sound-base                          installpptp-linux                               installsyslinux                                   installsyslinux-common                                installsyslinux-legacy                              installutil-linux                                  install

2.查看当前Ubuntu系统使用的内核版本
uname -a

结果：
Linux linux 3.2.0-40-generic #64-Ubuntu SMP Mon Mar 25 21:22:26 UTC 2013 i686 i686 i386 GNU/Linux

3.删除多余内核：
sudo apt-get purgelinux-image-2.6.32-21-generic linux-image-2.6.32-40-generic linux-image-2.6.32-41-generic linux-image-2.6.32-42-generic linux-image-3.2.0-33-generic linux-image-3.2.0-34-generic linux-image-3.2.0-35-generic linux-image-3.2.0-37-generic linux-image-3.2.0-38-genericlinux-headers-3.2.0-33 linux-headers-3.2.0-34 linux-headers-3.2.0-35 linux-headers-3.2.0-37 linux-headers-3.2.0-38

更新grub：
sudo update-grub

再次查看一下内核列表，就发现旧版本已经不存在了！
]]></content>
      <categories>
        <category>Linux</category>
        <category>Ubuntu</category>
      </categories>
      <tags>
        <tag>apt-get</tag>
        <tag>kernel</tag>
        <tag>gtk</tag>
        <tag>dpkg</tag>
        <tag>get-selections</tag>
        <tag>purge</tag>
        <tag>update-grub</tag>
      </tags>
  </entry>
  <entry>
    <title>Ubuntu 安装GTK</title>
    <url>/2012/02/01/linux-ubuntu-install-gtk/</url>
    <content><![CDATA[Ubuntu 安装GTK我利用此方法成功在UBUNTU 10.04下安装GTK 2.20.1。
安装1、安装gcc/g++/gdb/make 等基本编程工具
$sudo apt-get install build-essential

2、安装 libgtk2.0-dev libglib2.0-dev 等开发相关的库文件
$sudo apt-get install gnome-core-devel

3、用于在编译GTK程序时自动找出头文件及库文件位置　　
$sudo apt-get install pkg-config

4、安装 devhelp GTK文档查看程序
$sudo apt-get install devhelp

5、安装 gtk/glib 的API参考手册及其它帮助文档
$sudo apt-get install libglib2.0-doc libgtk2.0-doc

6、安装基于GTK的界面GTK是开发Gnome窗口的c/c++语言图形库
$sudo apt-get install glade libglade2-dev

或者
$sudo apt-get install glade-gnome glade-common glade-doc

7、安装gtk2.0 或者 将gtk+2.0所需的所有文件统通下载安装完毕
$sudo apt-get install libgtk2.0-dev

或者
$sudo apt-get install libgtk2.0*

　　
查看GTK库版本1、查看1.2.x版本
$pkg-config –modversion gtk+

2、查看 2.x 版本
$pkg-config –modversion gtk+-2.0

3、查看pkg-config的版本
$pkg-config –version

4、查看是否安装了gtk
$pkg-config –list-all grep gtk

　　
测试程序//Helloworld.c#include &lt;gtk/gtk.h&gt;int main(int argc,char *argv[]){    GtkWidget    *window;    GtkWidget    *label;    gtk_init(&amp;argc,&amp;argv);    /* create the main, top level, window */    window = gtk_window_new(GTK_WINDOW_TOPLEVEL);    /* give it the title */    gtk_window_set_title(GTK_WINDOW(window),“Hello World”);    /* connect the destroy signal of the window to gtk_main_quit     * when the window is about to be destroyed we get a notification and     * stop the main GTK+ loop     */    g_signal_connect(window,“destroy”,G_CALLBACK(gtk_main_quit),NULL);    /* create the “Hello, World” label */    label = gtk_label_new(“Hello, World”);    /* and insert it into the main window */    gtk_container_add(GTK_CONTAINER(window),label);    /* make sure that everything, window and label, are visible */    gtk_widget_show_all(window);    /* start the main loop, and let it rest until the application is closed */    gtk_main();    return 0;}


　　
编译运行1、编译
$gcc -o Helloworld Helloworld.c `pkg-config –cflags –libs gtk+-2.0`

2、运行
$./Helloworld
]]></content>
      <categories>
        <category>Linux</category>
        <category>Ubuntu</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>gtk</tag>
        <tag>ubuntu</tag>
        <tag>gnome</tag>
        <tag>pkg-config</tag>
        <tag>build-essential</tag>
        <tag>libgtk</tag>
      </tags>
  </entry>
  <entry>
    <title>Ubuntu 安装Intel IPP</title>
    <url>/2018/02/01/linux-ubuntu-install-ipp/</url>
    <content><![CDATA[How to install Intel IPP on UbuntuI wanted to try Intel Integrated Performance Primitives (IPP) with OpenCV. I installed IPP with these steps:
Intel IPP can be downloaded from here. If you are using it for non-commercial purposes, you can get it for free through Intel’s Non-Commercial Software Development webpage. You need to register with an email address. You will be sent an email with the download link and a registration key.
Download the Intel IPP version you want, beware that its a huge download. I downloaded Intel IPP 7.1, which ships as a 777MB .tgz file.
Unzip the downloaded .tgz file. Run the install.sh file. You will be asked to enter your registration key.
The installer walks you through the steps of installing IPP. I was asked to install the gcc-multilib package, before I could proceed. So, I did:
$ sudo apt-get install gcc-multilib

By default, the IPP files are installed to /opt/intel/
Going by the steps given on the Intel website, you are supposed to run the ippvars.sh script, which is in the /opt/intel/ipp/bin directory. It sets the following environment variables: IPPROOT, LIBRARY_PATH and LD_LIBRARY_PATH. This script failed to work for me. So, I set those manually in my .bashrc:
# My .bashrcexport IPPROOT=/opt/intel/composer_xe_2013.1.117/ippexport LIBRARY_PATH=$LIBRARY_PATH:/opt/intel/composer_xe_2013.1.117/ipp/lib/intel64:/opt/intel/composer_xe_2013.1.117/compiler/lib/intel64export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/opt/intel/composer_xe_2013.1.117/ipp/lib/intel64:/opt/intel/composer_xe_2013.1.117/compiler/lib/intel64]]></content>
      <categories>
        <category>Linux</category>
        <category>Ubuntu</category>
      </categories>
      <tags>
        <tag>ipp</tag>
        <tag>linux</tag>
        <tag>ubuntu</tag>
        <tag>intel</tag>
      </tags>
  </entry>
  <entry>
    <title>Ubuntu11.10初始配置</title>
    <url>/2011/12/01/linux-ubuntu11.10-initial-configuration/</url>
    <content><![CDATA[Ubuntu11.10初始配置升级软件源选择服务器。打开ubuntu软件中心，在顶部菜单栏里进入 “编辑—&gt;软件源”，在 “ubuntu软件” 菜单卡中的 “下载自:” 选择合适的服务器。中国大陆用户选择 “中国的服务器” ，然后可能会需要输入密码，你输入就是。修改好后 “关闭” 。升级软件源。sudo apt-get update &amp;&amp; sudo apt-get upgrade
安装常用插件、拓展包、语言支持。1.sudo apt-get install ubuntu-restricted-extras   —安装解码器、flashplayer、java虚拟机、微软字体及一些以前由于版权受限的软件包2.系统设置–语言支持  —安装需要的语言包3. “系统设置” 中进入 “附加驱动”
安装CCSM$ sudo apt-get install compizconfig-settings-manager

安装gnome 33 目前已在Ubuntu 11.10 源中，如果喜欢GNOME 3桌面环境，可通过软件中心或下面命令安装gnome 3：apt-get install gnome-shellShell”登录即可；如果你喜欢KDE界面，可选择Kubuntu版本下载；喜欢lxde桌面环境，则下载Lubuntu版本即可。当然，我们可以在Unity环境下进行安装。
$　　sudo apt-get install kubuntu-desktop

安装系统工具$　　sudo apt-get install utweak  ailurus git-core git planner freeMind dia nautilus-open-terminal indent

互联网工具$ sudo apt-get install pidgin

音频播放$ sudo apt-get install vlc audacious mplayer mplayer-fonts mozilla-mplayer
安装编码：$　　sudo apt-get install non-free-codecs libxine1-ffmpeg gxine mencoder libmpcdec3 libquicktime1 flac faac faad sox ffmpeg2theora libmpeg2-4 uudeview flac libmpeg3-1 mpeg3-utils mpegdemux liba52-dev mpeg2dec vorbis-tools id3v2 mpg321 mpg123 libflac++6 ffmpeg libmp4v2-0 totem-mozilla icedax tagtool easytag id3tool lame nautilus-script-audio-convert libmad0 libjpeg-progs
　　若要支持DVD，则安装
$ sudo apt-get install libdvdcss2$ sudo /usr/share/doc/libdvdread4/./install-css.sh

字典$　　sudo apt-get install stardict
安装解压工具$　　sudo apt-get install unace unrar zip unzip p7zip-full p7zip-rar sharutils rar uudeview mpack lha arj cabextract

图形$　　sudo apt-get install shutter gthumb
输入法$ sudo apt-get install fcitx

软件开发配置$ sudo apt-get install build-essential samba vim vim-full  ssh bison flex sharutils automake emacs  libc6 libc6-dev manpages-dev gnome-core-devel libglib2.0-doc libgtk2.0-doc  devhelp glade-gnome glade-common glade-doc python ruby erlang
]]></content>
      <categories>
        <category>Linux</category>
        <category>Ubuntu</category>
      </categories>
      <tags>
        <tag>install</tag>
        <tag>ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title>放开了去的 ulimit 命令</title>
    <url>/2014/02/12/linux-ulimit-beginner/</url>
    <content><![CDATA[放开了去的  ulimit.. note::  离离原上草，一岁一枯荣。  白居易《草 / 赋得古原草送别》
ulimit简介对于高并发或者频繁读写文件的应用程序而言，有时可能需要修改系统能够打开的最多文件句柄数，否则就可能会出现too many open files的错误。
而句柄数分为系统总限制和单进程限制。可以使用ulimit -n来查看系统对单个进程的限制及可以打开的文件数目。
或者执行ulimit -a来查看所有的详细信息。
临时修改打开文件数目对于临时的修改而言，可以终端中输入下面的命令，将该值调整为65536.
$ ulimit -HSn 65535


 上面的命令将open files修改为65535，不过退出当前shell后即失效。        H和S分别表示硬限制和软限制

永久修改如果希望永久修改，需要修改配置文件 /etc/security/limits.conf，修改后需要重新启动系统。
* soft nofile 65535* hard nofile 65535

其中的*表示所有的用户，soft和hard分别表示软硬限制，nofile表示能够打开的最大文件数，第四列为具体的值。其中具体的值有一个上次，在文件/proc/sys/fs/nr_open，默认为1048576，完全够用了。
系统总打开句柄限制上面讨论的均为单个线程的限制，属于线程级别的，系统级别的限制在文件/proc/sys/fs/file-max文件中。
修改这个文件也是临时生效的，重启失效，如果希望永久生效，需要修改下面文件：/etc/sysctl.conf
可以添加下面这行
fs.file-max = 6815744

然后运行sysctl -p或者重启生效。可以通过lsof -p PID 来查看单个进程打开的文件句柄
]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>bash内建命令</tag>
        <tag>ulimit</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux的 ulimit 命令</title>
    <url>/2014/02/12/linux-ulimit/</url>
    <content><![CDATA[Linux对打开文件数量的限制 ulimit对于高并发或者频繁读写文件的应用而言，需求修改系统能够打开的文件句柄数，否则会出现too many open files的错误。
而句柄数分为系统总限制和单进程限制。可以使用ulimit -n来查看系统对单个进程的限制，及open files。
或者执行ulimit -a来查看所有的详细信息。
临时修改打开文件数目$ ulimit -HSn 65535

上面的命令将open files修改为65535，退出当前shell后即失效。H和S分别表示硬限制和软限制
永久修改如果希望永久修改，需要修改配置文件 /etc/security/limits.conf，修改后需要重新启动系统。
* soft nofile 65535* hard nofile 65535

其中的*表示所有的用户，soft和hard分别表示软硬限制，nofile表示能够打开的最大文件数，第四列为具体的值。其中具体的值有一个上次，在文件/proc/sys/fs/nr_open，默认为1048576，完全够用了。
系统总打开句柄限制上面讨论的均为单个线程的限制，属于线程级别的，系统级别的限制在文件/proc/sys/fs/file-max文件中。
修改这个文件也是临时生效的，重启失效，如果希望永久生效，需要修改下面文件：/etc/sysctl.conf
可以添加下面这行
fs.file-max = 6815744

然后运行sysctl -p或者重启生效。
可以通过lsof -p PID 来查看单个进程打开的文件句柄
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>ulimit</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux uname</title>
    <url>/2018/03/07/linux-uname-beginner/</url>
    <content><![CDATA[linux 之uname命令Linux uname命令用于打印系统信息。
uname 可显示电脑、操作系统、发行版本等等信息。
官方的定义为：

uname - print system information

使用的方法为：
$ uname [OPTION]...

常用的一些选项为：

-a, --all：打印全部的信息
-s, --kernel-name：打印内核名
-n, --nodename：打印网络节点hostnme，即主机名
-r, --kernel-release：打印内核发行版
-v, --kernel-version：打印内核版本
-m, --machine：打印机器的硬件名字
-p, --processor：打印processor或者unknown
-i, --hardware-platform：打印硬件平台或者“unknown”
-o, --operating-system：打印操作系统

一些实例显示系统信息，这个基本足矣
$ uname -aLinux localdomain 3.10.0-1160.36.2.el7.x86_64 #1 SMP Wed Jul 21 11:57:15 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux

显示计算机类型：
$ uname -mx86_64

显示计算机名：
$ uname -nlocaodomain

显示操作系统发行编号：
$ uname -r3.10.0-1160.36.2.el7.x86_64

显示操作系统名称：
$ uname -sLinux

显示系统版本与时间：
$ uname -v#1 SMP Wed Jul 21 11:57:15 UTC 2020



SEE ALSO       arch(1), uname(2)
]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>uname</tag>
        <tag>GNU coreutils</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux uname</title>
    <url>/2018/03/07/linux-uname/</url>
    <content><![CDATA[linux 之uname命令Linux uname命令用于打印系统信息。
uname 可显示电脑、操作系统、发行版本等等信息。
官方的定义为：

uname - print system information

使用的方法为：
$ uname [OPTION]...

常用的一些选项为：

-a, --all：打印全部的信息
-s, --kernel-name：打印内核名
-n, --nodename：打印网络节点hostnme，即主机名
-r, --kernel-release：打印内核发行版
-v, --kernel-version：打印内核版本
-m, --machine：打印机器的硬件名字
-p, --processor：打印processor或者unknown
-i, --hardware-platform：打印硬件平台或者“unknown”
-o, --operating-system：打印操作系统

一些实例显示系统信息，这个基本足矣
$ uname -aLinux localdomain 3.10.0-1160.36.2.el7.x86_64 #1 SMP Wed Jul 21 11:57:15 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux

显示计算机类型：
$ uname -mx86_64

显示计算机名：
$ uname -nlocaodomain

显示操作系统发行编号：
$ uname -r3.10.0-1160.36.2.el7.x86_64

显示操作系统名称：
$ uname -sLinux

显示系统版本与时间：
$ uname -v#1 SMP Wed Jul 21 11:57:15 UTC 2020



SEE ALSO       arch(1), uname(2)
]]></content>
      <categories>
        <category>Linux</category>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>uname</tag>
        <tag>GNU coreutils</tag>
      </tags>
  </entry>
  <entry>
    <title>你是唯一的 uniq</title>
    <url>/2012/12/27/linux-uniq-beginner/</url>
    <content><![CDATA[你是唯一的 uniq.. note::  安得有车马，尚无渔与樵。  宋·王安石《游章义寺》 
Linux uniq 命令用于检查及删除文本文件中重复出现的行列，一般与 sort 命令结合使用。
官方定义为：

uniq - report or omit repeated lines

uniq 可检查文本文件中重复出现的行列。
语法语法比较简单，直接用就可以。
$ uniq [OPTION]... [INPUT [OUTPUT]]

常用的参数为：

-c或--count 在每列旁边显示该行重复出现的次数。

-d或--repeated 仅显示重复出现的行列。

-u或--unique 仅显示出一次的行列。


假定有1个文件为testfile，内容如下：
testfile	Hello 1	Hello 2	Hello 2	Hello 3	Hello 3	Hello 3	Hello 4	Hello 4	Hello 4    Hello 4



默认无参数使用uniq 命令可以删除重复的行，不管有多少重复的行，仅仅显示一行。
$  uniq testfileHello 1Hello 2Hello 3Hello 4



统计出现频次如果希望统计每一行出现的频次，可以使用-c参数，其中第一行输出为出现的次数
$  uniq -c testfile      1 Hello 1      2 Hello 2      3 Hello 3      4 Hello 4



仅仅显示重复的行在某些情况下，或许只想看到有重复的列，使用-d参数 ：
$  uniq -d testfileHello 2Hello 3Hello 4





仅仅显示不重复的行而某些情况下，或许只想看到不重复的列，使用-u参数：
$  uniq -u testfileHello 1
]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>文件操作</tag>
        <tag>uniq</tag>
        <tag>数据处理</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux的 uniq 命令</title>
    <url>/2012/12/27/linux-uniq/</url>
    <content><![CDATA[Linux的 uniq 命令Linux uniq 命令用于检查及删除文本文件中重复出现的行列，一般与 sort 命令结合使用。
官方定义为：

uniq - report or omit repeated lines

uniq 可检查文本文件中重复出现的行列。
语法语法比较简单，直接用就可以。
$ uniq [OPTION]... [INPUT [OUTPUT]]

常用的参数为：

-c或--count 在每列旁边显示该行重复出现的次数。

-d或--repeated 仅显示重复出现的行列。

-u或--unique 仅显示出一次的行列。


假定有1个文件为testfile，内容如下：
testfile	Hello 1	Hello 2	Hello 2	Hello 3	Hello 3	Hello 3	Hello 4	Hello 4	Hello 4    Hello 4



1⃣ 默认无参数使用uniq 命令可以删除重复的行，不管有多少重复的行，仅仅显示一行。
$  uniq testfileHello 1Hello 2Hello 3Hello 4



2⃣ 统计出现频次如果希望统计每一行出现的频次，可以使用-c参数，其中第一行输出为出现的次数
$  uniq -c testfile      1 Hello 1      2 Hello 2      3 Hello 3      4 Hello 4



3⃣ 仅仅显示重复的行在某些情况下，或许只想看到有重复的列，使用-d参数 ：
$  uniq -d testfileHello 2Hello 3Hello 4





4⃣ 仅仅显示不重复的行而某些情况下，或许只想看到不重复的列，使用-u参数：
$  uniq -u testfileHello 1
]]></content>
      <categories>
        <category>Linux</category>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>uniq</tag>
      </tags>
  </entry>
  <entry>
    <title>解压命令之一 unzip</title>
    <url>/2018/03/07/linux-unzip-beginner/</url>
    <content><![CDATA[解压命令之一 unzip.. _linux-beginner-unzip:
Linux unzip命令用于解压缩zip文件。
官方的定义为：

unzip - list, test and extract compressed files in a ZIP archive

基本命令$ unzip file.zip

unzip 只需在命令后跟上要解压的文件名，如 file.zip，将该压缩文件解压缩到当前目录。
指定目录解压如果需要指定解压缩的目标目录，可以使用 -d 参数：
$ unzip archive.zip -d /path/where/to/extract

这样就会把压缩文件解压到指定的目录中。
不解压某些文件如果压缩的文件巨大，而不想解压其中的某些，可以用下面的命令
$ unzip file.zip -x data

这个命令的意思为，解压file.zip，但是不把里面的data解压。
]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>unzip</tag>
        <tag>归档压缩</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux useradd</title>
    <url>/2013/03/07/linux-useradd-beginner/</url>
    <content><![CDATA[linux中创建新用户useradduseradd用于创建或者更新用户账号信息，是管理员必备的命令之一。
官方的定义为：

useradd - create a new user or update default new user information

使用的方法为：
$ useradd [options] LOGIN$ useradd -D    $ useradd -D [options]


在使用 -D 选项的时候，useradd 命令将使用系统默认、用户命令行指定的参数创建一个新的用户账户。依赖于命令行选项，useradd命令会更新系统文件或者创建用户的home目录并拷贝初始文件，这个除非相当专业，慎用。
默认情况下，useradd会创建一个同名的group。
常用的一些选项为：

-c, --comment COMMENT ：备注，通常会报错在passwd的备注栏中，一般为用户的全名。
-d, --home-dir HOME_DIR：指定用户登陆时候的HOME目录
-e, --expiredate EXPIRE_DATE：用户账户被禁用的日期，格式为： YYYY-MM-DD。如果不指定，将使用 /etc/default/useradd的值，或者默认取空不过期
-s, --shell SHELL：指定登陆后使用的shell，对于不同于默认设定的shell比较有用

默认添加用户$ sudo useradd username$ id username uid=1001(username) gid=1001(username) groups=1001(username)

正常情况下，创建用户user，会自动在/home目录创建，通过id命令可以看到有同名的group也创建了。
加上备注$ sudo useradd username -c "USER NAME"

通过这个参数可以设置用户的备注名或者昵称，可以在/etc/passwd中看到，这个对于用户管理而言很方便，而GUI登陆来说比较方便，会显示备注名。
设定登陆的目录默认情况下创建的目录位于/home ，但是如果希望更改到，比如/home1，那么此时使用-d参数即可，如下：
$ sudo useradd  -d /home1/ username



更改默认的SHELL有些用户可能对csh情有独钟，那么此时可以使用-s来更改，如下：
$ sudo useradd -s /usr/bin/csh username

目前默认均为bash。
设定失效日期这个选项通常对于临时账户很有效，比如来了一个实习生，实习一个月就离开，此时2013-03-07，那么一个月以后失效的命令为：
$ sudo useradd username -e 2013-04-07

那么一个月以后，该账户将被禁用登陆。
]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>管理员</tag>
        <tag>System Management Commands</tag>
        <tag>useradd</tag>
        <tag>adduser</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux useradd</title>
    <url>/2013/03/07/linux-useradd/</url>
    <content><![CDATA[linux中创建新用户useradduseradd用于创建或者更新用户账号信息，是管理员必备的命令之一。
官方的定义为：

useradd - create a new user or update default new user information

使用的方法为：
$ useradd [options] LOGIN$ useradd -D    $ useradd -D [options]


在使用 -D 选项的时候，useradd 命令将使用系统默认、用户命令行指定的参数创建一个新的用户账户。依赖于命令行选项，useradd命令会更新系统文件或者创建用户的home目录并拷贝初始文件，这个除非相当专业，慎用。
默认情况下，useradd会创建一个同名的group。
常用的一些选项为：

-c, --comment COMMENT ：备注，通常会报错在passwd的备注栏中，一般为用户的全名。
-d, --home-dir HOME_DIR：指定用户登陆时候的HOME目录
-e, --expiredate EXPIRE_DATE：用户账户被禁用的日期，格式为： YYYY-MM-DD。如果不指定，将使用 /etc/default/useradd的值，或者默认取空不过期
-s, --shell SHELL：指定登陆后使用的shell，对于不同于默认设定的shell比较有用

默认添加用户$ sudo useradd username$ id username uid=1001(username) gid=1001(username) groups=1001(username)

正常情况下，创建用户user，会自动在/home目录创建，通过id命令可以看到有同名的group也创建了。
加上备注$ sudo useradd username -c "USER NAME"

通过这个参数可以设置用户的备注名或者昵称，可以在/etc/passwd中看到，这个对于用户管理而言很方便，而GUI登陆来说比较方便，会显示备注名。
设定登陆的目录默认情况下创建的目录位于/home ，但是如果希望更改到，比如/home1，那么此时使用-d参数即可，如下：
$ sudo useradd  -d /home1/ username



更改默认的SHELL有些用户可能对csh情有独钟，那么此时可以使用-s来更改，如下：
$ sudo useradd -s /usr/bin/csh username

目前默认均为bash。
设定失效日期这个选项通常对于临时账户很有效，比如来了一个实习生，实习一个月就离开，此时2013-03-07，那么一个月以后失效的命令为：
$ sudo useradd username -e 2013-04-07

那么一个月以后，该账户将被禁用登陆。
useradd 用户名
-u　 指定用户uid
-g 　指定用户所属主组
-G 　指定用户所属附属组


使用useradd时，如果后面不添加任何参数选项，例如： #sudo useradd test创建出来的用户将是默认“三无”用户：一无Home Directory，二无密码，三无系统Shell。
使用adduser时，创建用户的过程更像是一种人机对话，系统会提示你输入各种信息，然后会根据这些信息帮你创建新用户。
所以，adduser更适合初级使用者，因为不用去记那些繁琐的参数选项，只要跟着系统的提示一步一步进行下去就行，缺点就是整个创建过程比较复杂而漫长；而useradd比较适合有些高阶经验的使用者，往往一行命令加参数就能解决很多问题，所以创建起来十分方便。

例1：
# useradd -d /usr/leo -m leo

此命令创建了一个用户leo -d和-m选项用来为登录名leo产生一个主目录/usr/leo（/usr为默认的用户主目录所在的父目录）。
例2：
# useradd -d /home/leo -s /usr/bin/bash -g leo -G admin,root leo

此命令新建了一个用户leo/bin/sh，他属于group用户组，同时又属于admin和root用户组，其中group用户组是其主组。这里可能新建组：groupadd group 及 groupadd admin增加用户账号就是在/etc/passwd文件中为新用户增加一条记录，同时更新其他系统文件，如/etc/shadow，/etc/group等。Linux提供了集成的系统管理工具userconf，他能用来对用户账号进行统一管理。

注： 用户帐户本身在 /etc/passwd 中定义。Linux 系统包含一个 /etc/passwd 的同伴文件，叫做 /etc/shadow。该文件不像 /etc/passwd，只有对于 root 用户来说是可读的，并且包含加密的密码信息

​       
OPTIONS       The options which apply to the useradd command are:
   -b, --base-dir BASE_DIR
       The default base directory for the system if -d HOME_DIR is not specified.  BASE_DIR is concatenated with the account name to define
       the home directory. If the -m option is not used, BASE_DIR must exist.

       If this option is not specified, useradd will use the base directory specified by the HOME variable in /etc/default/useradd, or
       /home by default.
       
# useradd defaults file
GROUP=100
HOME=/home
INACTIVE=-1
EXPIRE=
SHELL=/bin/bash
SKEL=/etc/skel
CREATE_MAIL_SPOOL=yes

​​​​​       -D, –defaults           See below, the subsection “Changing the default values”.
​​       -f, –inactive INACTIVE           The number of days after a password expires until the account is permanently disabled. A value of 0 disables the account as soon as           the password has expired, and a value of -1 disables the feature.
       If not specified, useradd will use the default inactivity period specified by the INACTIVE variable in /etc/default/useradd, or -1
       by default.

   -g, --gid GROUP
       The group name or number of the user's initial login group. The group name must exist. A group number must refer to an already       existing group.

       If not specified, the behavior of useradd will depend on the USERGROUPS_ENAB variable in /etc/login.defs. If this variable is set to
       yes (or -U/--user-group is specified on the command line), a group will be created for the user, with the same name as her
       loginname. If the variable is set to no (or -N/--no-user-group is specified on the command line), useradd will set the primary group
       of the new user to the value specified by the GROUP variable in /etc/default/useradd, or 100 by default.

   -G, --groups GROUP1[,GROUP2,...[,GROUPN]]]
       A list of supplementary groups which the user is also a member of. Each group is separated from the next by a comma, with no
       intervening whitespace. The groups are subject to the same restrictions as the group given with the -g option. The default is for
       the user to belong only to the initial group.

   -k, --skel SKEL_DIR
       The skeleton directory, which contains files and directories to be copied in the user's home directory, when the home directory is        created by useradd.

       This option is only valid if the -m (or --create-home) option is specified.

       If this option is not set, the skeleton directory is defined by the SKEL variable in /etc/default/useradd or, by default, /etc/skel.

       If possible, the ACLs and extended attributes are copied.

   -K, --key KEY=VALUE
       Overrides /etc/login.defs defaults (UID_MIN, UID_MAX, UMASK, PASS_MAX_DAYS and others).

       Example: -K PASS_MAX_DAYS=-1 can be used when creating system account to turn off password aging, even though system account has no
       password at all. Multiple -K options can be specified, e.g.: -K UID_MIN=100  -K UID_MAX=499

   -l, --no-log-init
       Do not add the user to the lastlog and faillog databases.

       By default, the user's entries in the lastlog and faillog databases are reset to avoid reusing the entry from a previously deleted       user.

   -m, --create-home
       Create the user's home directory if it does not exist. The files and directories contained in the skeleton directory (which can be        defined with the -k option) will be copied to the home directory.

       By default, if this option is not specified and CREATE_HOME is not enabled, no home directories are created.

       The directory where the user's home directory is created must exist and have proper SELinux context and permissions. Otherwise the
       user's home directory cannot be created or accessed.

   -M, --no-create-home
       Do no create the user's home directory, even if the system wide setting from /etc/login.defs (CREATE_HOME) is set to yes.

   -N, --no-user-group
       Do not create a group with the same name as the user, but add the user to the group specified by the -g option or by the GROUP       variable in /etc/default/useradd.

       The default behavior (if the -g, -N, and -U options are not specified) is defined by the USERGROUPS_ENAB variable in       /etc/login.defs.

   -o, --non-unique
       Allow the creation of a user account with a duplicate (non-unique) UID.

       This option is only valid in combination with the -u option.

   -p, --password PASSWORD
       The encrypted password, as returned by crypt(3). The default is to disable the password.

       Note: This option is not recommended because the password (or encrypted password) will be visible by users listing the processes.

       You should make sure the password respects the system's password policy.

   -r, --system
       Create a system account.

       System users will be created with no aging information in /etc/shadow, and their numeric identifiers are chosen in the       SYS_UID_MIN-SYS_UID_MAX range, defined in /etc/login.defs, instead of UID_MIN-UID_MAX (and their GID counterparts for the creation       of groups).

       Note that useradd will not create a home directory for such a user, regardless of the default setting in /etc/login.defs       (CREATE_HOME). You have to specify the -m options if you want a home directory for a system account to be created.

   -R, --root CHROOT_DIR
       Apply changes in the CHROOT_DIR directory and use the configuration files from the CHROOT_DIR directory.

   -P, --prefix PREFIX_DIR
       Apply changes in the PREFIX_DIR directory and use the configuration files from the PREFIX_DIR directory. This option does not chroot       and is intended for preparing a cross-compilation target. Some limitations: NIS and LDAP users/groups are not verified. PAM       authentication is using the host files. No SELINUX support.

​​       -u, –uid UID           The numerical value of the user’s ID. This value must be unique, unless the -o option is used. The value must be non-negative. The           default is to use the smallest ID value greater than or equal to UID_MIN and greater than every other user.
       See also the -r option and the UID_MAX description.

   -U, --user-group
       Create a group with the same name as the user, and add the user to this group.

       The default behavior (if the -g, -N, and -U options are not specified) is defined by the USERGROUPS_ENAB variable in
       /etc/login.defs.

   -Z, --selinux-user SEUSER
       The SELinux user for the user's login. The default is to leave this field blank, which causes the system to select the default
       SELinux user.

   Changing the default values       When invoked with only the -D option, useradd will display the current default values. When invoked with -D plus other options, useradd       will update the default values for the specified options. Valid default-changing options are:
   -b, --base-dir BASE_DIR
       The path prefix for a new user's home directory. The user's name will be affixed to the end of BASE_DIR to form the new user's home
       directory name, if the -d option is not used when creating a new account.

       This option sets the HOME variable in /etc/default/useradd.

   -e, --expiredate EXPIRE_DATE
       The date on which the user account is disabled.

       This option sets the EXPIRE variable in /etc/default/useradd.

   -f, --inactive INACTIVE
       The number of days after a password has expired before the account will be disabled.

       This option sets the INACTIVE variable in /etc/default/useradd.

   -g, --gid GROUP
       The group name or ID for a new user's initial group (when the -N/--no-user-group is used or when the USERGROUPS_ENAB variable is set
       to no in /etc/login.defs). The named group must exist, and a numerical group ID must have an existing entry.

       This option sets the GROUP variable in /etc/default/useradd.

   -s, --shell SHELL
       The name of a new user's login shell.

       This option sets the SHELL variable in /etc/default/useradd.

NOTES       The system administrator is responsible for placing the default user files in the /etc/skel/ directory (or any other skeleton directory        specified in /etc/default/useradd or on the command line).
CAVEATS       You may not add a user to a NIS or LDAP group. This must be performed on the corresponding server.
   Similarly, if the username already exists in an external user database such as NIS or LDAP, useradd will deny the user account creation   request.

   Usernames may contain only lower and upper case letters, digits, underscores, or dashes. They can end with a dollar sign. Dashes are not   allowed at the beginning of the username. Fully numeric usernames and usernames . or .. are also disallowed. It is not recommended to   use usernames beginning with . character as their home directories will be hidden in the ls output. In regular expression terms:
   [a-zA-Z0-9_.][a-zA-Z0-9_.-]*[$]?

   Usernames may only be up to 32 characters long.

CONFIGURATION       The following configuration variables in /etc/login.defs change the behavior of this tool:
   CREATE_HOME (boolean)
       Indicate if a home directory should be created by default for new users.

       This setting does not apply to system users, and can be overridden on the command line.

   GID_MAX (number), GID_MIN (number)
       Range of group IDs used for the creation of regular groups by useradd, groupadd, or newusers.

       The default value for GID_MIN (resp.  GID_MAX) is 1000 (resp. 60000).

   MAIL_DIR (string)
       The mail spool directory. This is needed to manipulate the mailbox when its corresponding user account is modified or deleted. If
       not specified, a compile-time default is used.

   MAIL_FILE (string)
       Defines the location of the users mail spool files relatively to their home directory.

   The MAIL_DIR and MAIL_FILE variables are used by useradd, usermod, and userdel to create, move, or delete the user's mail spool.

   If MAIL_CHECK_ENAB is set to yes, they are also used to define the MAIL environment variable.

   MAX_MEMBERS_PER_GROUP (number)
       Maximum members per group entry. When the maximum is reached, a new group entry (line) is started in /etc/group (with the same name,
       same password, and same GID).

       The default value is 0, meaning that there are no limits in the number of members in a group.

       This feature (split group) permits to limit the length of lines in the group file. This is useful to make sure that lines for NIS
       groups are not larger than 1024 characters.

       If you need to enforce such limit, you can use 25.

       Note: split groups may not be supported by all tools (even in the Shadow toolsuite). You should not use this variable unless you
       really need it.

   PASS_MAX_DAYS (number)
       The maximum number of days a password may be used. If the password is older than this, a password change will be forced. If not
       specified, -1 will be assumed (which disables the restriction).

   PASS_MIN_DAYS (number)
       The minimum number of days allowed between password changes. Any password changes attempted sooner than this will be rejected. If
       not specified, -1 will be assumed (which disables the restriction).

   PASS_WARN_AGE (number)
       The number of days warning given before a password expires. A zero means warning is given only upon the day of expiration, a
       negative value means no warning is given. If not specified, no warning will be provided.

   SUB_GID_MIN (number), SUB_GID_MAX (number), SUB_GID_COUNT (number)
       If /etc/subuid exists, the commands useradd and newusers (unless the user already have subordinate group IDs) allocate SUB_GID_COUNT
       unused group IDs from the range SUB_GID_MIN to SUB_GID_MAX for each new user.

       The default values for SUB_GID_MIN, SUB_GID_MAX, SUB_GID_COUNT are respectively 100000, 600100000 and 65536.

   SUB_UID_MIN (number), SUB_UID_MAX (number), SUB_UID_COUNT (number)
       If /etc/subuid exists, the commands useradd and newusers (unless the user already have subordinate user IDs) allocate SUB_UID_COUNT
       unused user IDs from the range SUB_UID_MIN to SUB_UID_MAX for each new user.

       The default values for SUB_UID_MIN, SUB_UID_MAX, SUB_UID_COUNT are respectively 100000, 600100000 and 65536.

   SYS_GID_MAX (number), SYS_GID_MIN (number)
       Range of group IDs used for the creation of system groups by useradd, groupadd, or newusers.

       The default value for SYS_GID_MIN (resp.  SYS_GID_MAX) is 101 (resp.  GID_MIN-1).

   SYS_UID_MAX (number), SYS_UID_MIN (number)
       Range of user IDs used for the creation of system users by useradd or newusers.

       The default value for SYS_UID_MIN (resp.  SYS_UID_MAX) is 101 (resp.  UID_MIN-1).

   UID_MAX (number), UID_MIN (number)
       Range of user IDs used for the creation of regular users by useradd or newusers.

       The default value for UID_MIN (resp.  UID_MAX) is 1000 (resp. 60000).

   UMASK (number)
       The file mode creation mask is initialized to this value. If not specified, the mask will be initialized to 022.

       useradd and newusers use this mask to set the mode of the home directory they create

       It is also used by login to define users' initial umask. Note that this mask can be overridden by the user's GECOS line (if
       QUOTAS_ENAB is set) or by the specification of a limit with the K identifier in limits(5).

   USERGROUPS_ENAB (boolean)
       Enable setting of the umask group bits to be the same as owner bits (examples: 022 -&gt; 002, 077 -&gt; 007) for non-root users, if the
       uid is the same as gid, and username is the same as the primary group name.

       If set to yes, userdel will remove the user's group if it contains no more members, and useradd will create by default a group with
       the name of the user.

FILES       /etc/passwd           User account information.
   /etc/shadow
       Secure user account information.

   /etc/group
       Group account information.

   /etc/gshadow
       Secure group account information.

   /etc/default/useradd
       Default values for account creation.

   /etc/skel/
       Directory containing default files.

   /etc/subgid
       Per user subordinate group IDs.

   /etc/subuid
       Per user subordinate user IDs.

   /etc/login.defs
       Shadow password suite configuration.

EXIT VALUES       The useradd command exits with the following values:
   0
       success

   1
       can't update password file

   2
       invalid command syntax

   3
       invalid argument to option

   4
       UID already in use (and no -o)

   6
       specified group doesn't exist

   9
       username already in use

   10
       can't update group file

   12
       can't create home directory

   14
       can't update SELinux user mapping

SEE ALSO       chfn(1), chsh(1), passwd(1), crypt(3), groupadd(8), groupdel(8), groupmod(8), login.defs(5), newusers(8), subgid(5),       subuid(5),userdel(8), usermod(8).
]]></content>
      <categories>
        <category>Linux</category>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>管理员</tag>
        <tag>System Management Commands</tag>
        <tag>useradd</tag>
        <tag>adduser</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux userdel</title>
    <url>/2013/03/07/linux-userdel-beginner/</url>
    <content><![CDATA[linux中删除用户userdeluserdel用于删除用户账号信息，是管理员必备的命令之一。
userdel将删除用户帐号与相关的文件。若不加参数，则仅仅删除用户帐号，账号的目录可能还会存在。
官方的定义为：

userdel - delete a user account and related files

使用的方法为：
$ userdel [options] LOGIN

其中LOGIN为将删除的用户名，需要确保其存在，不然会报错。
其中很常用的options为：

-r, --remove：删除用户登陆的目录以及目录中所有的文件，还有用户的邮件信息，在其他文件系统的文件可能需要手动删除。
-f, --force：这个选项强制删除用户账号，即便该用户仍在登陆。同时还会删除用户的home目录和mail信息。总之很彪悍的一个参数，可能会引起其他问题，慎用慎用，不用不用。

默认使用删除用户账号user，这个选项将把
$ sudo userdel username



彻底删除账号信息$ sudo userdel -r username

-r参数将把用户的账号以及默认位于/home/username/的所有文件进行删除，谨慎操作，无法找回，除非确认该账号确实不再使用，并且文件确实不在具备价值。
如何确认是否成功？userdel命令是有返回信息的，如果需要确认命令的执行情况，如下返回值：   

0 成功
1 无法更新password文件
2 无效的命令语法
6 指定的用户不存在
8 用户正在登陆
10 无法更新group文件
12 无法移除home目录


警告：如果一个用户还有程序在运行，userdel是不允许删除该账户的。此时可以通过kill掉改程序，或者使用-f来强制删除。
通常情况下，不要这么做。

]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>危险命令</tag>
        <tag>管理员</tag>
        <tag>System Management Commands</tag>
        <tag>userdel</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux userdel</title>
    <url>/2013/03/07/linux-userdel/</url>
    <content><![CDATA[linux中删除用户userdeluserdel用于删除用户账号信息，是管理员必备的命令之一。
userdel将删除用户帐号与相关的文件。若不加参数，则仅仅删除用户帐号，账号的目录可能还会存在。
官方的定义为：

userdel - delete a user account and related files

使用的方法为：
$ userdel [options] LOGIN

其中LOGIN为将删除的用户名，需要确保其存在，不然会报错。
其中很常用的options为：

-r, --remove：删除用户登陆的目录以及目录中所有的文件，还有用户的邮件信息，在其他文件系统的文件可能需要手动删除。
-f, --force：这个选项强制删除用户账号，即便该用户仍在登陆。同时还会删除用户的home目录和mail信息。总之很彪悍的一个参数，可能会引起其他问题，慎用慎用，不用不用。

默认使用删除用户账号user，这个选项将把
$ sudo userdel username



彻底删除账号信息$ sudo userdel -r username

-r参数将把用户的账号以及默认位于/home/username/的所有文件进行删除，谨慎操作，无法找回，除非确认该账号确实不再使用，并且文件确实不在具备价值。
如何确认是否成功？userdel命令是有返回信息的，如果需要确认命令的执行情况，如下返回值：   

0 成功
1 无法更新password文件
2 无效的命令语法
6 指定的用户不存在
8 用户正在登陆
10 无法更新group文件
12 无法移除home目录


警告：如果一个用户还有程序在运行，userdel是不允许删除该账户的。此时可以通过kill掉改程序，或者使用-f来强制删除。
通常情况下，不要这么做。

SEE ALSO       chfn(1), chsh(1), passwd(1), login.defs(5), gpasswd(8), groupadd(8), groupdel(8), groupmod(8), subgid(5), subuid(5),       usermod(8).
]]></content>
      <categories>
        <category>Linux</category>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>管理员</tag>
        <tag>System Management Commands</tag>
        <tag>userdel</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux usermod</title>
    <url>/2015/03/07/linux-usermod-beginner/</url>
    <content><![CDATA[Linux usermod 命令Linux usermod命令用于修改用户账号的各种设置，在多群组权限的情况下，十分常用。
官方定义为：

usermod - modify a user account

语法用法为：
$ usermod [options] LOGIN

常用的几个参数为：

-a 追加用户组，通常与-G一起使用

-c COMMENT 　修改用户帐号的备注文字

-e YYYY-MM-DD  　修改帐号的有效期限。

-g newgroup 修改用户所属的群组。

-G groups 　修改用户所属的附加群组。


修改备注名字正常情况下在创建用户的时候，不太会指定全名，此时可以使用-c来补全备注。
$ usermod -c "Full Name" user

上面的命令将用户user的备注更改为Full Name。
指定账号有效期可以通过-e参数来指定账号的有效期，特别是在知道用户用过一段时间后就不在使用，这种情况十分有效。
$ usermod -e 2015-12-12 user

上面的命令将用户user的有效期定义到2015年12月12日。
重新指定用户组参数-g将把用户的默认属组更新。
$ usermod -g newgroup user

上面的命令为把user默认组更改为newgroup。正常情况下，用户将在创建的时候默认创建一个同名的群组。
新增用户组这个指令用的是最多的，也就是把用户同时追加到其他组，如下所示：
$ usermod -a -G group1 group2 group3 user

含义为把用户user同时追加到用户组group1、group2和group3。
]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>usermod</tag>
        <tag>系统管理</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux usermod</title>
    <url>/2015/03/07/linux-usermod/</url>
    <content><![CDATA[Linux usermod 命令Linux usermod命令用于修改用户账号的各种设置，在多群组权限的情况下，十分常用。
官方定义为：

usermod - modify a user account

语法用法为：
$ usermod [options] LOGIN

常用的几个参数为：

-a 追加用户组，通常与-G一起使用

-c COMMENT 　修改用户帐号的备注文字

-e YYYY-MM-DD  　修改帐号的有效期限。

-g newgroup 修改用户所属的群组。

-G groups 　修改用户所属的附加群组。


修改备注名字正常情况下在创建用户的时候，不太会指定全名，此时可以使用-c来补全备注。
$ usermod -c "Full Name" user

上面的命令将用户user的备注更改为Full Name。
指定账号有效期可以通过-e参数来指定账号的有效期，特别是在知道用户用过一段时间后就不在使用，这种情况十分有效。
$ usermod -e 2015-12-12 user

上面的命令将用户user的有效期定义到2015年12月12日。
重新指定用户组参数-g将把用户的默认属组更新。
$ usermod -g newgroup user

上面的命令为把user默认组更改为newgroup。正常情况下，用户将在创建的时候默认创建一个同名的群组。
新增用户组这个指令用的是最多的，也就是把用户同时追加到其他组，如下所示：
$ usermod -a -G group1 group2 group3 user

含义为把用户user同时追加到用户组group1、group2和group3。
# 添加用户user1到组group1里。$ usermod -a -G group1 user1



实例更改登录目录
# usermod -d /home/hnlinux root

改变用户的uid
# usermod -u 777 root



-f&lt;缓冲天数&gt; 　修改在密码过期后多少天即关闭该帐号。

-l&lt;帐号名称&gt; 　修改用户帐号名称。
-L 　锁定用户密码，使密码无效。
-s 　修改用户登入后所使用的shell。
-u 　修改用户ID。
-U 　解除密码锁定。

OPTIONS       The options which apply to the usermod command are:
   -a, --append
       Add the user to the supplementary group(s). Use only with the -G option.

   -b, --badnames
       Allow names that do not conform to standards.


   -d, --home HOME_DIR
       The user's new login directory.

       If the -m option is given, the contents of the current home directory will be moved to the new home directory, which is created if it does not already
       exist.



   -f, --inactive INACTIVE
       The number of days after a password expires until the account is permanently disabled.

       A value of 0 disables the account as soon as the password has expired, and a value of -1 disables the feature.

       This option requires a /etc/shadow file. A /etc/shadow entry will be created if there were none.

   -g, --gid GROUP
       The group name or number of the user's new initial login group. The group must exist.


   -G, --groups GROUP1[,GROUP2,...[,GROUPN]]]
       A list of supplementary groups which the user is also a member of. Each group is separated from the next by a comma, with no intervening whitespace.
       The groups are subject to the same restrictions as the group given with the -g option.

       If the user is currently a member of a group which is not listed, the user will be removed from the group. This behaviour can be changed via the -a        option, which appends the user to the current supplementary group list.

   -l, --login NEW_LOGIN
       The name of the user will be changed from LOGIN to NEW_LOGIN. Nothing else is changed. In particular, the user's home directory or mail spool should
       probably be renamed manually to reflect the new login name.

   -L, --lock
       Lock a user's password. This puts a '!' in front of the encrypted password, effectively disabling the password. You can't use this option with -p or
       -U.

       Note: if you wish to lock the account (not only access with a password), you should also set the EXPIRE_DATE to 1.

   -m, --move-home
       Move the content of the user's home directory to the new location.

       This option is only valid in combination with the -d (or --home) option.

       usermod will try to adapt the ownership of the files and to copy the modes, ACL and extended attributes, but manual changes might be needed afterwards.

   -o, --non-unique
       When used with the -u option, this option allows to change the user ID to a non-unique value.

   -p, --password PASSWORD
       The encrypted password, as returned by crypt(3).

       Note: This option is not recommended because the password (or encrypted password) will be visible by users listing the processes.

       The password will be written in the local /etc/passwd or /etc/shadow file. This might differ from the password database configured in your PAM        configuration.

       You should make sure the password respects the system's password policy.

   -R, --root CHROOT_DIR
       Apply changes in the CHROOT_DIR directory and use the configuration files from the CHROOT_DIR directory.

   -P, --prefix PREFIX_DIR
       Apply changes in the PREFIX_DIR directory and use the configuration files from the PREFIX_DIR directory. This option does not chroot and is intended        for preparing a cross-compilation target. Some limitations: NIS and LDAP users/groups are not verified. PAM authentication is using the host files. No        SELINUX support.

   -s, --shell SHELL
       The name of the user's new login shell. Setting this field to blank causes the system to select the default login shell.

   -u, --uid UID
       The new numerical value of the user's ID.

       This value must be unique, unless the -o option is used. The value must be non-negative.

       The user's mailbox, and any files which the user owns and which are located in the user's home directory will have the file user ID changed
       automatically.

       The ownership of files outside of the user's home directory must be fixed manually.

       No checks will be performed with regard to the UID_MIN, UID_MAX, SYS_UID_MIN, or SYS_UID_MAX from /etc/login.defs.

   -U, --unlock
       Unlock a user's password. This removes the '!' in front of the encrypted password. You can't use this option with -p or -L.

       Note: if you wish to unlock the account (not only access with a password), you should also set the EXPIRE_DATE (for example to 99999, or to the EXPIRE       value from /etc/default/useradd).

   -v, --add-subuids FIRST-LAST
       Add a range of subordinate uids to the user's account.

       This option may be specified multiple times to add multiple ranges to a users account.

       No checks will be performed with regard to SUB_UID_MIN, SUB_UID_MAX, or SUB_UID_COUNT from /etc/login.defs.

   -V, --del-subuids FIRST-LAST
       Remove a range of subordinate uids from the user's account.

       This option may be specified multiple times to remove multiple ranges to a users account. When both --del-subuids and --add-subuids are specified, the
       removal of all subordinate uid ranges happens before any subordinate uid range is added.

       No checks will be performed with regard to SUB_UID_MIN, SUB_UID_MAX, or SUB_UID_COUNT from /etc/login.defs.

   -w, --add-subgids FIRST-LAST
       Add a range of subordinate gids to the user's account.

       This option may be specified multiple times to add multiple ranges to a users account.

       No checks will be performed with regard to SUB_GID_MIN, SUB_GID_MAX, or SUB_GID_COUNT from /etc/login.defs.

   -W, --del-subgids FIRST-LAST
       Remove a range of subordinate gids from the user's account.

       This option may be specified multiple times to remove multiple ranges to a users account. When both --del-subgids and --add-subgids are specified, the
       removal of all subordinate gid ranges happens before any subordinate gid range is added.

       No checks will be performed with regard to SUB_GID_MIN, SUB_GID_MAX, or SUB_GID_COUNT from /etc/login.defs.

   -Z, --selinux-user SEUSER
       The new SELinux user for the user's login.

       A blank SEUSER will remove the SELinux user mapping for user LOGIN (if any).

CAVEATS       You must make certain that the named user is not executing any processes when this command is being executed if the user’s numerical user ID, the user’s       name, or the user’s home directory is being changed.  usermod checks this on Linux. On other platforms it only uses utmp to check if the user is logged in.
   You must change the owner of any crontab files or at jobs manually.

   You must make any changes involving NIS on the NIS server.

CONFIGURATION       The following configuration variables in /etc/login.defs change the behavior of this tool:
   LASTLOG_UID_MAX (number)
       Highest user ID number for which the lastlog entries should be updated. As higher user IDs are usually tracked by remote user identity and
       authentication services there is no need to create a huge sparse lastlog file for them.

       No LASTLOG_UID_MAX option present in the configuration means that there is no user ID limit for writing lastlog entries.

   MAIL_DIR (string)
       The mail spool directory. This is needed to manipulate the mailbox when its corresponding user account is modified or deleted. If not specified, a
       compile-time default is used.

   MAIL_FILE (string)
       Defines the location of the users mail spool files relatively to their home directory.

   The MAIL_DIR and MAIL_FILE variables are used by useradd, usermod, and userdel to create, move, or delete the user's mail spool.

   MAX_MEMBERS_PER_GROUP (number)
       Maximum members per group entry. When the maximum is reached, a new group entry (line) is started in /etc/group (with the same name, same password, and
       same GID).

       The default value is 0, meaning that there are no limits in the number of members in a group.

       This feature (split group) permits to limit the length of lines in the group file. This is useful to make sure that lines for NIS groups are not larger
       than 1024 characters.

       If you need to enforce such limit, you can use 25.

       Note: split groups may not be supported by all tools (even in the Shadow toolsuite). You should not use this variable unless you really need it.

   SUB_GID_MIN (number), SUB_GID_MAX (number), SUB_GID_COUNT (number)
       If /etc/subuid exists, the commands useradd and newusers (unless the user already have subordinate group IDs) allocate SUB_GID_COUNT unused group IDs
       from the range SUB_GID_MIN to SUB_GID_MAX for each new user.

       The default values for SUB_GID_MIN, SUB_GID_MAX, SUB_GID_COUNT are respectively 100000, 600100000 and 65536.

   SUB_UID_MIN (number), SUB_UID_MAX (number), SUB_UID_COUNT (number)
       If /etc/subuid exists, the commands useradd and newusers (unless the user already have subordinate user IDs) allocate SUB_UID_COUNT unused user IDs
       from the range SUB_UID_MIN to SUB_UID_MAX for each new user.

       The default values for SUB_UID_MIN, SUB_UID_MAX, SUB_UID_COUNT are respectively 100000, 600100000 and 65536.

​       chfn(1), chsh(1), passwd(1), crypt(3), gpasswd(8), groupadd(8), groupdel(8), groupmod(8), login.defs(5), subgid(5), subuid(5), useradd(8), userdel(8).
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>usermod</tag>
        <tag>Linux入门</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux VirutalBox</title>
    <url>/2010/01/03/linux-virtualbox/</url>
    <content><![CDATA[挂载$ mount -t vboxsf local_dir virtualbox_dir

Troubleshooting安装增强功能的时候，未能加载虚拟光盘通常第一次安装没有问题，但是如果系统升级以后，再重新安装会出现问题，此时可以进入系统看一下以前安装的时候，光盘是不是没有退出，点击退出，重新尝试一下，即可解决。
VBoxClient: the VirtualBox kernel service is not running.  Exitingplease install libelf-dev, libelf-devel or elfutils-libelf-devel

This system is currently not set up to build kernel modules.在安装增强功能时，也可能会出现依赖包没有安装的情况，具体报错如下：解决方法为安装他所提示的包
# CentOS$ yum install kernel-devel-CURRENT_KERNEL #（具体替换代码所显示的包版本）# Ubuntu$ apt install linux-source
]]></content>
      <categories>
        <category>Linux</category>
        <category>Ubuntu</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>VNCViewer</tag>
        <tag>VNC</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux VNCViewer远程桌面按d后最小化桌面</title>
    <url>/2010/01/03/linux-vncviewer/</url>
    <content><![CDATA[VNCViewer远程桌面按d后最小化桌面使用VNCViewer登录了ubuntu以后，发现每次按下d键时都会隐藏所有的窗口，后来看了一下，是因为Ubuntu内置的默认有个快捷键shortcut是d。如图示：
即Hide all normal windows的快捷键为D，只需要改成你比较不常用的，或者诸如ALT+D等等即可解决问题。
]]></content>
      <categories>
        <category>Linux</category>
        <category>Ubuntu</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>VNCViewer</tag>
        <tag>VNC</tag>
      </tags>
  </entry>
  <entry>
    <title>什么？谁？w (who &amp; what)</title>
    <url>/2014/02/12/linux-w-beginner/</url>
    <content><![CDATA[什么？谁？w (who &amp; what).. code::  去年花里逢君别，今日花开已一年。  韦应物《寄李儋元锡》
w可以认为是加强版的who，果然越简洁越强大，就比如less比more是功能更多的。
w不仅可以显示谁在登录，还可以打印他们在做什么。w显示的信息如下：

登录的用户；
运行的程序；
第一行显示的信息：当前时间、系统运行的时间、多少用户登录、系统的负载（分贝为1，5，15分钟）

官方定义为：

 w - Show who is logged on and what they are doing.

用法为：
$ w [options] user [...]



常用的两个选项为：

-h 　不显示各栏位的标题信息列。

-s 　简洁格式列表，不显示用户登入时间，JCPU或者PCPU的时间


默认的显示显示当前用户的登录信息及执行的命令
$ w16:29:03 up 26 days,  2:49, 6 users,  load average: 1.00, 0.97, 0.96USER     TTY      FROM LOGIN@   IDLE   JCPU   PCPU WHATuser     pts/4    :1   07Sep21 20days  9:59   1:53m bashuser     pts/0    :2   08Sep21  6days  0.70s  1:53m zshuser     pts/1    :3   08Sep21 20days  1:13m  1:53m bashuser      :0      :0   15Sep21 6days  27days 21.36s zshuser     pts/2    :0   15Sep21 14days  0.25s  0.25s zshuser     pts/3    :3   16Sep21 24:45m  0.22s  0.22s bash



不显示标题行$ w -h16:29:16 up 26 days,  2:49, 6 users,  load average: 1.20, 0.67, 0.76USER     TTY      FROM  LOGIN@   IDLE   JCPU   PCPU WHATuser     pts/4    :1    07Sep21 20days  9:59   1:53m bashuser     pts/0    :2    08Sep21  6days  0.70s  1:53m zshuser     pts/1    :3    08Sep21 20days  1:13m  1:53m bashuser      :0      :0    15Sep21 6days  27days 21.36s zshuser     pts/2    :0    15Sep21 14days  0.25s  0.25s zshuser     pts/3    :3    16Sep21 24:45m  0.22s  0.22s bash



简洁模式显示$ w -s16:29:26 up 26 days,  2:49, 6 users,  load average: 1.50, 0.67, 0.36USER     TTY      FROM    IDLE   WHATuser     pts/4    :1     20days  bashuser     pts/0    :2      6days  zshuser     pts/1    :3     20days  bashuser      :0      :0     6days   zshuser     pts/2    :0     14days  zshuser     pts/3    :3     24:45m  bash
]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>w</tag>
        <tag>用户信息</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux wait函数进程进程</title>
    <url>/2011/10/19/linux-wait/</url>
    <content><![CDATA[wait3和wait4函数–进程控制wait3和wait4提供的功能比wait、waitpid和waitid所提供的功能要多一个，这与附加参数rusage有关。该参数要求内核返回由终止进程及其所有子进程使用的资源汇总。
#include &lt;sys/types.h&gt;#include &lt;sys/wait.h&gt;#include &lt;sys/time.h&gt;#include &lt;sys/resource.h&gt;pid_t wait3(int *statloc, int options, struct rusage *rusage);pid_t wait4(pid_t pid, int *statloc, int options, struct rusage *rusage);//两个函数返回值:若成功返回进程ID，若出错则返回-1

资源统计信息包括用户CPU时间总量、系统CPU时间总量、页面出错次数、接收到信号的次数等。有关细节参阅getrusage(2)手册页。
下表中列出了各个wait函数所支持的不同的参数。
| 函数| pid| options| rusage| POSIX.1| Free BSD 5.2.1| Linux 2.4.22| Mac OSX 10.3| Solaris 9|| wait| | | | √|√ |√ |√ |√||waited   |  √ | √  |   |   |   |   |   | √  ||waitpid   | √  | √  |   | √  | √  | √  | √  | √  ||wait3   |   | √  | √  |   | √  | √  | √  | √  ||wait4   | √  | √  | √  |   | √  | √  | √  | √  |
]]></content>
      <categories>
        <category>Linux</category>
        <category>CentOS</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>wait</tag>
        <tag>wait3</tag>
        <tag>wait4</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux的 wall 命令</title>
    <url>/2011/04/12/linux-wall-beginner/</url>
    <content><![CDATA[可以上墙的广播命令wall   Linux wall命令会将信息传给每一个 mesg 设定为 yes 的上线使用者（可以输入mesg，如果返回is yes就可以收到）。当使用终端登陆的时候，可以使用EOF (通常用 Ctrl+D)。所有人均可以使用该命令。
官方的定义为：

wall – send a message to everybody’s terminal.

所以wall应该是write all user’s teminal的缩写。
使用的方法为：
  $ wall [-n] [ message ]

其中参数-n的含义为，修改显示的广播信息放松抬头，看示例即可明白。
这个命令的使用场景为如果需要升级维护系统，可以通过wall命令通知所有在线的用户。
如下：
$ wallDear all,We want to make you aware that this weekend 12PM CST,there will be scheduled down time for approximately 6 hours.During this time we will add more capacity and software updateto our infrastructure and service.Please save all your works and logout for safe.See you next week.Regards,AdminCtrl+D #退出



所有登陆的终端都会收到这个消息：
Broadcast message from user@localhost (pts/4) (Mon Apr 18 22:02:22 2011):Dear all,We want to make you aware that this weekend 12PM CST,there will be scheduled down time for approximately 6 hours.During this time we will add more capacity and software updateto our infrastructure and service.Please save all your works and logout for safe.See you next week.Regards,Admin

需要注意的是，这个命令最大支持20行的信息，超过了就不会广播了。
如果使用-n参数的效果如下
$ wall -n 'hello'# 其他终端用户收到的消息Remote broadcast message (Mon Apr 18 22:05:22 2011):hello



可以看到此时的通知抬头变成了 Remote broadcast message，去掉了是哪个用户发送的消息。
]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>网络</tag>
        <tag>wall</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux的 wc 命令</title>
    <url>/2011/02/12/linux-wc-beginner/</url>
    <content><![CDATA[Linux 之 wc 查看文件信息wc命令可以查看一下文件的行数、字数、字符数的信息。
官方定义为：

 wc - print newline, word, and byte counts for each file

语法$ wc [-clw][--help][--version][文件...]

参数：

-c或--bytes或--chars 只显示Bytes数。
-l或--lines 显示行数。
-w或--words 只显示字数。
-L 或--max-line-length 打印最长一行的长度

简单的使用 wc统计在默认的情况下，wc将计算指定文件的行数、字数，以及字节数。使用的命令为：
$ wc file1 

先查看file1文件的内容，可以看到：
$ cat file1  Hello World! 

$  wc file1 	# file1文件的统计信息 1  2 13 file1 	# file1文件的行数为1、单词数2、字节数13 

其中，3 个数字分别表示file1文件的行数、单词数，以及该文件的字节数。
Ⓜ同时统计多个文件如果想同时统计多个文件的信息，例如同时统计file1、file2、file3，可使用如下命令：
$ wc file*  1   2  13 file1  2   5  33 file2  4  16  76 file3  7  23 122 total # 总计输出信息



⭐ 统计最长一行的长度这个对于终端输出比较有用，要知道以前的终端最长支持80个字符。
其实当前倒是没有这个限制，不过稍短一些的代码看着还是赏心悦目的。
比如查看系统的版本：
$ wc -L /etc/redhat-release 40 /etc/redhat-release

可知这一行的最长为40个字符。
而此时我们就可以使用这个技巧来获取一个工程所有文件最长的是多少。
]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>wc</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux的 wc 命令</title>
    <url>/2011/02/12/linux-wc/</url>
    <content><![CDATA[Linux 之 wc 查看文件信息wc命令可以查看一下文件的行数、字数、字符数的信息。
官方定义为：

 wc - print newline, word, and byte counts for each file

语法$ wc [-clw][--help][--version][文件...]

参数：

-c或--bytes或--chars 只显示Bytes数。
-l或--lines 显示行数。
-w或--words 只显示字数。
-L 或--max-line-length 打印最长一行的长度

简单的使用 wc统计在默认的情况下，wc将计算指定文件的行数、字数，以及字节数。使用的命令为：
$ wc file1 

先查看file1文件的内容，可以看到：
$ cat file1  Hello World! 

$  wc file1 	# file1文件的统计信息 1  2 13 file1 	# file1文件的行数为1、单词数2、字节数13 

其中，3 个数字分别表示file1文件的行数、单词数，以及该文件的字节数。
Ⓜ同时统计多个文件如果想同时统计多个文件的信息，例如同时统计file1、file2、file3，可使用如下命令：
$ wc file*  1   2  13 file1  2   5  33 file2  4  16  76 file3  7  23 122 total # 总计输出信息



⭐ 统计最长一行的长度这个对于终端输出比较有用，要知道以前的终端最长支持80个字符。
其实当前倒是没有这个限制，不过稍短一些的代码看着还是赏心悦目的。
比如查看系统的版本：
$ wc -L /etc/redhat-release 40 /etc/redhat-release

可知这一行的最长为40个字符。
而此时我们就可以使用这个技巧来获取一个工程所有文件最长的是多少。
]]></content>
      <categories>
        <category>Linux</category>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>wc</tag>
      </tags>
  </entry>
  <entry>
    <title>非交互的下载工具 wget</title>
    <url>/2013/07/07/linux-wget-beginner/</url>
    <content><![CDATA[非交互的下载工具 wgetLinux系统中的wget是一个下载文件📀的命令行工具，特别普遍 。
对于Linux用户是必不可少的工具，对于经常要下载一些软件或从远程服务器恢复备份到本地服务器，这个命令尤为重要。
wget支持很多协议，比如HTTP，HTTPS和FTP协议，还可以使用HTTP代理。
wget的有诸多特点，比如

自动下载 wget支持自动下载，即wget可以在用户退出系统的之后在后台执行。这意味着你可以登录系统，启动一个wget下载任务，然后退出系统，wget将在后台执行直到任务完成，这是个牛气冲天的功能。
完全重建 wget 可以跟踪HTML页面上的链接依次下载来创建远程服务器的本地版本，完全重建原始站点的目录结构。这又常被称作”递归下载”。在递归下载的时候，wget 遵循Robot Exclusion标准(/robots.txt). wget可以在下载的同时，将链接转换成指向本地文件，以方便离线浏览。
高稳定 wget 非常稳定，它在带宽很窄的情况下和不稳定网络中有很强的适应性.如果是由于网络的原因下载失败，wget会不断地尝试，直到整个文件下载完毕。如果是服务器打断下载过程，它会再次联到服务器上从停止的地方继续下载。这对从那些限定了链接时间的服务器上下载大文件非常有用。

命令格式$ wget [参数] [URL地址]

用于从网络上下载资源，没有指定目录，下载资源会默认为当前目录。wget虽然功能强大，但是使用起来还是比较简单：
使用范例wget的命令参数很多，不过常用的为下面几个，详细的可以看进阶。
使用wget下载单个文件比如，我们下载个Ubuntu的最新版本，试下效果如何
$ wget http://releases.ubuntu.com/16.04/ubuntu-16.04-desktop-amd64.iso

在下载的过程中会显示进度条，包含（下载完成百分比，已经下载的字节，当前下载速度，剩余下载时间）。
使用wget -O下载并以不同的文件名保存这个对于动态链接的下载比较有用，特别是有些文件的名字实在是太……………….长了
$ wget -O wordpress.zip http://www.ubuntu.com/download.aspx?id=1234

使用wget -c断点续传$ wget -c http://releases.ubuntu.com/16.04/ubuntu-16.04-desktop-amd64.iso# or$ wget --continue http://releases.ubuntu.com/16.04/ubuntu-16.04-desktop-amd64.iso

使用wget -c重新启动下载中断的文件，对于我们下载大文件时突然由于网络等原因中断非常有帮助，我们可以继续接着下载而不是重新下载一个文件。需要继续中断的下载时可以使用-c参数。
使用wget -o把下载信息存入日志文件$ wget -o download.log URL

不希望下载信息直接显示在终端而是在一个日志文件，可以使用，特别注意需要与-O来区分开~
]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>wget</tag>
        <tag>网络命令</tag>
        <tag>数据下载</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux wget 命令</title>
    <url>/2013/07/07/linux-wget/</url>
    <content><![CDATA[Linux 之 wget 下载命令Linux系统中的wget是一个下载文件📀的命令行工具，特别普遍  。
对于Linux用户是必不可少的工具，对于经常要下载一些软件或从远程服务器恢复备份到本地服务器，这个命令尤为重要。
wget支持很多协议，比如HTTP，HTTPS和FTP协议，还可以使用HTTP代理。
wget的特点自动下载wget支持自动下载，即wget可以在用户退出系统的之后在后台执行。这意味着你可以登录系统，启动一个wget下载任务，然后退出系统，wget将在后台执行直到任务完成，这是个牛气冲天的功能。
完全重建wget 可以跟踪HTML页面上的链接依次下载来创建远程服务器的本地版本，完全重建原始站点的目录结构。这又常被称作”递归下载”。在递归下载的时候，wget 遵循Robot Exclusion标准(/robots.txt). wget可以在下载的同时，将链接转换成指向本地文件，以方便离线浏览。
高稳定wget 非常稳定，它在带宽很窄的情况下和不稳定网络中有很强的适应性.如果是由于网络的原因下载失败，wget会不断地尝试，直到整个文件下载完毕。如果是服务器打断下载过程，它会再次联到服务器上从停止的地方继续下载。这对从那些限定了链接时间的服务器上下载大文件非常有用。
命令格式$ wget [参数] [URL地址]

用于从网络上下载资源，没有指定目录，下载资源会默认为当前目录。wget虽然功能强大，但是使用起来还是比较简单：
使用范例wget的命令参数很多，不过常用的为下面几个，详细的可以看进阶。
使用wget下载单个文件比如，我们下载个Ubuntu的最新版本，试下效果如何
$ wget http://releases.ubuntu.com/16.04/ubuntu-16.04-desktop-amd64.iso

在下载的过程中会显示进度条，包含（下载完成百分比，已经下载的字节，当前下载速度，剩余下载时间）。
使用wget -O下载并以不同的文件名保存这个对于动态链接的下载比较有用，特别是有些文件的名字实在是太……………….长了
$ wget -O wordpress.zip http://www.ubuntu.com/download.aspx?id=1234

使用wget -c断点续传$ wget -c http://releases.ubuntu.com/16.04/ubuntu-16.04-desktop-amd64.iso

使用wget -c重新启动下载中断的文件，对于我们下载大文件时突然由于网络等原因中断非常有帮助，我们可以继续接着下载而不是重新下载一个文件。需要继续中断的下载时可以使用-c参数。
使用wget -o把下载信息存入日志文件$ wget -o download.log URL

不希望下载信息直接显示在终端而是在一个日志文件，可以使用，特别注意需要与-O来区分开~
使用wget 下载网站上的所有文件$ wget -r -np -nd http://example.com/packages/	



这条命令可以下载 http://example.com 网站上 packages 目录中的所有文件。其中，-np 的作用是不遍历父目录，-nd 表示不在本机重新创建目录结构。
支持扩展名$ wget -r -np -nd --accept=iso http://example.com/centos-5/i386/



与上一条命令相似，但多加了一个 –accept=iso 选项，这指示wget仅下载 i386 目录中所有扩展名为 iso 的文件。你也可以指定多个扩展名，只需用逗号分隔即可。
镜像一个网站$ wget -m -k (-H) http://www.example.com/

该命令可用来镜像一个网站，wget将对链接进行转换。如果网站中的图像是放在另外的站点，那么可以使用 -H 选项。
使用wget –limit -rate限速下载$ wget --limit-rate=300k http://releases.ubuntu.com/16.04/ubuntu-16.04-desktop-amd64.iso

当你执行wget的时候，它默认会占用全部可能的宽带下载。但是当你准备下载一个大文件，而你还需要下载其它文件时就有必要限速了。
使用wget -b后台下载$ wget -b http://releases.ubuntu.com/16.04/ubuntu-16.04-desktop-amd64.iso

对于下载非常大的文件的时候，我们可以使用参数-b进行后台下载。
$ wget -b http://releases.ubuntu.com/16.04/ubuntu-16.04-desktop-amd64.isoContinuing in background, pid 1840.Output will be written to `wget-log'.

你可以使用以下命令来察看下载进度：
tail -f wget-log

使用wget –tries增加重试次数wget --tries=40 URL

如果网络有问题或下载一个大文件也有可能失败。wget默认重试20次连接下载文件。如果需要，你可以使用–tries增加重试次数。
使用wget -i下载多个文件wget -i filelist.txt


首先，保存一份下载链接文件
cat &gt; filelist.txturl1url2url3url4

接着使用这个文件和参数-i下载
使用wget –reject过滤指定格式下载wget --reject=gif ur

下载一个网站，但你不希望下载图片，可以使用以下命令。
使用wget -Q限制总下载文件大小wget -Q5m -i filelist.txt

当你想要下载的文件超过5M而退出下载，你可以使用。注意：这个参数对单个文件下载不起作用，只能递归下载时才有效。
使用wget -r -A下载指定格式文件wget -r -A .pdf url

可以在以下情况使用该功能：

下载一个网站的所有图片
下载一个网站的所有视频
下载一个网站的所有PDF文件

使用wget -P下载文件到指定目录默认情况下，wget会将文件下载到当前目录，并且都是非交互静默发生的，我们这里使用-P或者--directory-prefix参数来指出特定目录，避免了下载后需要再次移动的操作。
如下所示，我们这里使用wget下载一个wget的最新源码包到/tmp/wget目录。
$ mkdir /tmp/wget$ wget -P /tmp/wget https://ftp.gnu.org/gnu/wget/wget-1.19.tar.gz



使用wget FTP下载可以使用wget来完成ftp链接的下载。
使用wget匿名ftp下载：
wget ftp-url

使用wget用户名和密码认证的ftp下载
wget --ftp-user=USERNAME --ftp-password=PASSWORD url



使用wget递归下载某目录下的所有文件$ wget -c -r -k -p urlor$ wget -c -r -nd -np -k -L -p -A c,h url


-c 断点续传 
-r 递归下载，下载指定网页某一目录下（包括子目录）的所有文件 
-nd 递归下载时不创建一层一层的目录，把所有的文件下载到当前目录 
-np 递归下载时不搜索上层目录。如wget -c -r www.xxx.org/pub/path/ 没有加参数-np，就会同时下载path的上一级目录pub下的其它文件 
-k 将绝对链接转为相对链接，下载整个站点后脱机浏览网页，最好加上这个参数 
-L 递归时不进入其它主机，如wget -c -r www.xxx.org/ 如果网站内有一个这样的链接： www.yyy.org，不加参数-L，就会像大火烧山一样，会递归下载www.yyy.org网站 
-p 下载网页所需的所有文件，如图片等 
-A 指定要下载的文件样式列表，多个样式用逗号分隔 
-i 后面跟一个文件，文件内指明要下载的URL。

命令参数全启动参数
-V, –version 显示wget的版本后退出
-h, –help 打印语法帮助
-b, –background 启动后转入后台执行
-e, –execute=COMMAND 执行.wgetrc格式的命令，wgetrc格式参见/etc/wgetrc或~/.wgetrc

记录和输入文件参数：
-o, –output-file=FILE 把记录写到FILE文件中
-a, –append-output=FILE 把记录追加到FILE文件中
-d, –debug 打印调试输出
-q, –quiet 安静模式(没有输出)
-v, –verbose 冗长模式(这是缺省设置)
-nv, –non-verbose 关掉冗长模式，但不是安静模式
-i, –input-file=FILE 下载在FILE文件中出现的URLs
-F, –force-html 把输入文件当作HTML格式文件对待
-B, –base=URL 将URL作为在-F -i参数指定的文件中出现的相对链接的前缀
–sslcertfile=FILE 可选客户端证书
–sslcertkey=KEYFILE 可选客户端证书的KEYFILE
–egd-file=FILE 指定EGD socket的文件名

下载参数
–bind-address=ADDRESS 指定本地使用地址(主机名或IP，当本地有多个IP或名字时使用)
-t, –tries=NUMBER 设定最大尝试链接次数(0 表示无限制).
-O –output-document=FILE 把文档写到FILE文件中
-nc, –no-clobber 不要覆盖存在的文件或使用.#前缀
-c, –continue 接着下载没下载完的文件
–progress=TYPE 设定进程条标记
-N, –timestamping 不要重新下载文件除非比本地文件新
-S, –server-response 打印服务器的回应
–spider 不下载任何东西
-T, –timeout=SECONDS 设定响应超时的秒数
-w, –wait=SECONDS 两次尝试之间间隔SECONDS秒
–waitretry=SECONDS 在重新链接之间等待1…SECONDS秒
–random-wait 在下载之间等待0…2*WAIT秒
-Y, –proxy=on/off 打开或关闭代理
-Q, –quota=NUMBER 设置下载的容量限制
–limit-rate=RATE 限定下载输率

目录参数
-nd –no-directories 不创建目录
-x, –force-directories 强制创建目录
-nH, –no-host-directories 不创建主机目录
-P, –directory-prefix=PREFIX 将文件保存到目录 PREFIX/…
–cut-dirs=NUMBER 忽略 NUMBER层远程目录

HTTP 选项参数：

–http-user=USER 设定HTTP用户名为 USER.
–http-passwd=PASS 设定http密码为 PASS
-C, –cache=on/off 允许/不允许服务器端的数据缓存 (一般情况下允许)
-E, –html-extension 将所有text/html文档以.html扩展名保存
–ignore-length 忽略 Content-Length头域
–header=STRING 在headers中插入字符串 STRING
–proxy-user=USER 设定代理的用户名为 USER
–proxy-passwd=PASS 设定代理的密码为 PASS
–referer=URL 在HTTP请求中包含 Referer: URL头
-s, –save-headers 保存HTTP头到文件
-U, –user-agent=AGENT 设定代理的名称为 AGENT而不是 Wget/VERSION
–no-http-keep-alive 关闭 HTTP活动链接 (永远链接)
–cookies=off 不使用 cookies
–load-cookies=FILE 在开始会话前从文件 FILE中加载cookie
–save-cookies=FILE 在会话结束后将 cookies保存到 FILE文件中

FTP 选项参数
-nr, –dont-remove-listing 不移走 .listing文件
-g, –glob=on/off 打开或关闭文件名的 globbing机制
–passive-ftp 使用被动传输模式 (缺省值).
–active-ftp 使用主动传输模式
–retr-symlinks 在递归的时候，将链接指向文件(而不是目录)

递归下载参数
-r, –recursive 递归下载－－慎用!
-l, –level=NUMBER 最大递归深度 (inf 或 0 代表无穷)
–delete-after 在现在完毕后局部删除文件
-k, –convert-links 转换非相对链接为相对链接
-K, –backup-converted 在转换文件X之前，将之备份为 X.orig
-m, –mirror 等价于 -r -N -l inf -nr
-p, –page-requisites 下载显示HTML文件的所有图片

递归下载中的包含和不包含(accept/reject)
-A, –accept=LIST 分号分隔的被接受扩展名的列表
-R, –reject=LIST 分号分隔的不被接受的扩展名的列表
-D, –domains=LIST 分号分隔的被接受域的列表
–exclude-domains=LIST 分号分隔的不被接受的域的列表
–follow-ftp 跟踪HTML文档中的FTP链接
–follow-tags=LIST 分号分隔的被跟踪的HTML标签的列表
-G, –ignore-tags=LIST 分号分隔的被忽略的HTML标签的列表
-H, –span-hosts 当递归时转到外部主机
-L, –relative 仅仅跟踪相对链接
-I, –include-directories=LIST 允许目录的列表
-X, –exclude-directories=LIST 不被包含目录的列表
-np, –no-parent 不要追溯到父目录
wget -S –spider url 不下载只显示过程

指定用户名密码下载部分网站可能需要用户名密码才能下载，如果是自己的机器，可以使用下面的命令
$ wget --username user --passwd password http://example.com/filenam

其中的username和passwd分别为用户名和密码。
但是如果是公用服务器就有一个风险，别人可以看到这些信息，所以此时，可以通过下面的命令，手动输入密码：
$ wget --user=username --ask-password http://example.com/filenamePassword for user `username`:[SECRET (not visible)]

此时输入密码就万无一失了。
命令格式
wget [参数] [URL地址]

用于从网络上下载资源，没有指定目录，下载资源回默认为当前目录。wget虽然功能强大，但是使用起来还是比较简单：
wget下面的特点是使用它主要考虑的方面：

支持断点下传功能，可以让网络不是太好的用户可以放心了
同时支持FTP和HTTP下载方式；尽管现在大部分软件可以使用HTTP方式下载，但是，有些时候，仍然需要使用FTP方式下载软件
支持代理服务器
设置方便简单；可能，习惯图形界面的用户已经不是太习惯命令行了，但是，命令行在设置上其实有更多的优点，最少，鼠标可以少点很多次，也不要担心是否错点鼠标
程序小，完全免费

使用范例
wget的命令参数很多，不过常用的为下面几个，详细的可以看最后。
使用wget下载单个文件比如，我们下载个Ubuntu的最新版本，试下效果如何
wget http://releases.ubuntu.com/16.04/ubuntu-16.04-desktop-amd64.iso

在下载的过程中会显示进度条，包含（下载完成百分比，已经下载的字节，当前下载速度，剩余下载时间）。
使用wget -O下载并以不同的文件名保存这个对于动态链接的下载比较有用
wget -O wordpress.zip http://www.ubuntu.com/download.aspx?id=1234

使用wget –limit -rate限速下载wget --limit-rate=300k http://releases.ubuntu.com/16.04/ubuntu-16.04-desktop-amd64.iso

当你执行wget的时候，它默认会占用全部可能的宽带下载。但是当你准备下载一个大文件，而你还需要下载其它文件时就有必要限速了。
使用wget -c断点续传wget -c http://releases.ubuntu.com/16.04/ubuntu-16.04-desktop-amd64.iso

使用wget -c重新启动下载中断的文件，对于我们下载大文件时突然由于网络等原因中断非常有帮助，我们可以继续接着下载而不是重新下载一个文件。需要继续中断的下载时可以使用-c参数。
使用wget -b后台下载wget -b http://releases.ubuntu.com/16.04/ubuntu-16.04-desktop-amd64.iso

对于下载非常大的文件的时候，我们可以使用参数-b进行后台下载。
wget -b http://releases.ubuntu.com/16.04/ubuntu-16.04-desktop-amd64.iso Continuing in background, pid 1840. Output will be written to `wget-log'.

你可以使用以下命令来察看下载进度：
tail -f wget-log



使用wget –tries增加重试次数wget --tries=40 URL

如果网络有问题或下载一个大文件也有可能失败。wget默认重试20次连接下载文件。如果需要，你可以使用–tries增加重试次数。
使用wget -i下载多个文件wget -i filelist.txt

首先，保存一份下载链接文件
cat &gt; filelist.txt url1 url2 url3 url4

接着使用这个文件和参数-i下载
使用wget –reject过滤指定格式下载wget --reject=gif ur

下载一个网站，但你不希望下载图片，可以使用以下命令。
使用wget -o把下载信息存入日志文件wget -o download.log URL

不希望下载信息直接显示在终端而是在一个日志文件，可以使用
使用wget -Q限制总下载文件大小wget -Q5m -i filelist.txt

当你想要下载的文件超过5M而退出下载，你可以使用。注意：这个参数对单个文件下载不起作用，只能递归下载时才有效。
使用wget -r -A下载指定格式文件wget -r -A.pdf url

可以在以下情况使用该功能：

下载一个网站的所有图片
下载一个网站的所有视频
下载一个网站的所有PDF文件

使用wget FTP下载可以使用wget来完成ftp链接的下载。
使用wget匿名ftp下载：
wget ftp-url

使用wget用户名和密码认证的ftp下载
wget --ftp-user=USERNAME --ftp-password=PASSWORD url

- 
更详细的命令阅读原文吧…
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>wget</tag>
        <tag>Linux入门</tag>
        <tag>数据下载</tag>
      </tags>
  </entry>
  <entry>
    <title>你是干什么的 whatis</title>
    <url>/2011/02/12/linux-whatis-beginner/</url>
    <content><![CDATA[你是干什么的 whatis其实整个命令已出现，你的脑海里面应该浮现的是：

What is your name?

如题所述，这个命令用于查询一个命令到底执行了什么功能，并将查询的结果输出出来，相当于man的一个选项-f。
whatis的官方定义为：

whatis - display manual page descriptions

仅仅提供一个比较简单的命令描述.
使用方法也比较简单，如下：
$ whatis [options] name


其中的name可以是Linux命令、系统调用、库函数、系统等等内容

以前面的命令为例，执行如下所示：
$ whatis ls cd file cat more lessls (1)               - list directory contentsls (1p)              - list directory contentscd (1)               - bash built-in commands, see bash(1)cd (1p)              - change the working directorycd (n)               - Change working directoryfile (1)             - determine file typefile (1p)            - determine file typefile (n)             - Manipulate file names and attributescat (1)              - concatenate files and print on the standard outputcat (1p)             - concatenate and print filesmore (1)             - file perusal filter for crt viewingmore (1p)            - display files on a page-by-page basisless (1)             - opposite of moreless (3pm)           - perl pragma to request less of something




可以看到whatis是支持同时查询多个命令的

拓展whatis可以通过-w、-r以及-C等选项来设定通配符、正则表达式以及配置文件等等，不过最简单的还是简单查看一个命令的简单描述，其他的可以交给man来处理。
]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>man</tag>
        <tag>帮助命令</tag>
        <tag>whatis</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux 的 whatis 命令</title>
    <url>/2011/02/12/linux-whatis/</url>
    <content><![CDATA[whatis  你是干什么的其实整个命令已出现，你的脑海里面应该浮现的是：

What is your name?

如题所述，这个命令用于查询一个命令到底执行了什么功能，并将查询的结果输出出来，相当于man的一个选项-f。
whatis的官方定义为：

whatis - display manual page descriptions

仅仅提供一个比较简单的命令描述.
使用方法也比较简单，如下：
$ whatis [options] name


其中的name可以是Linux命令、系统调用、库函数、系统等等内容

以前面的命令为例，执行如下所示：
$ whatis ls cd file cat more lessls (1)               - list directory contentsls (1p)              - list directory contentscd (1)               - bash built-in commands, see bash(1)cd (1p)              - change the working directorycd (n)               - Change working directoryfile (1)             - determine file typefile (1p)            - determine file typefile (n)             - Manipulate file names and attributescat (1)              - concatenate files and print on the standard outputcat (1p)             - concatenate and print filesmore (1)             - file perusal filter for crt viewingmore (1p)            - display files on a page-by-page basisless (1)             - opposite of moreless (3pm)           - perl pragma to request less of something




可以看到whatis是支持同时查询多个命令的

拓展whatis可以通过-w、-r以及-C等选项来设定通配符、正则表达式以及配置文件等等，不过最简单的还是简单查看一个命令的简单描述，其他的可以交给man来处理。
]]></content>
      <categories>
        <category>Linux</category>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>man</tag>
        <tag>whatis</tag>
      </tags>
  </entry>
  <entry>
    <title>指定目录的定位 whereis</title>
    <url>/2014/03/20/linux-whereis-beginner/</url>
    <content><![CDATA[指定目录的定位 whereis.. note::
你在哪里，哪里就是风景。

​	
Linux whereis 命令用于定位查找一个命令的二进制、源文件或帮助文件。
不过这些文件一般是位于特定目录的。
其他的程序定位可以考虑使用locate命令。
官方的定义为：

whereis - locate the binary, source, and manual page files for a command

使用语法使用语法如下：
$ whereis [options] [-BMS directory... -f] name...



其他的选项可以为： 

-b : 查找二进制文件

-m：查找手册

-s：查找源文件

-B &lt;directory&gt; 　在设置的目录下查找二进制文件。

-M &lt;directory&gt; 　在设置的目录下查找说明文件。

-S &lt;directory&gt; 　在设置的目录下查找原始代码文件。


实例比如查找bash的位置，输入如下命令：
$ whereis bashbash: /usr/bin/bash /etc/bash.bashrc /usr/share/man/man1/bash.1.gz

可以看到，以上的输出信息从左至右分别为程序名、bash路径、bash的man帮助手册路径。
单独查找文件可以通过不同的参数来查找不同的文件，如下：
# 查找二进制文件$ whereis -b bashbash: /usr/bin/bash /etc/bash.bashrc # 查找帮助文件$ whereis -m bashbash: /usr/share/man/man1/bash.1.gz# 查找源文件$ whereis -s bashbash:
]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>帮助命令</tag>
        <tag>whereis</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux 的 which 命令</title>
    <url>/2012/12/27/linux-which-beginner/</url>
    <content><![CDATA[Linux which命令Linux which命令用于查找一个命令，不像find，find是用来查找文件的。
官方定义为：

which - locate a command

改名了会在当前环境变量中查找符合条件的命令。
语法$ which [-a] filename ...



这个命令基本没有参数，只有一个：

-a     print all matching pathnames of each argument

如果找到相关的指令并可执行，将返回0.
默认无参数查找命令并显示具体路径：
$ which bash/usr/bin/bash 

可能会输出不同，取决于环境变量。
显示所有命令一个命令，可能会有多个版本，或者同一个版本的多个位置，可以使用-a参数来检索。
$ which -a bash/usr/bin/bash/bin/bash



一个小小无聊的尝试 在Ubuntu操作系统中，看看下面的命令：
$ which whichwhich: shell built-in command

显示为内建指令
扩展如果确认程序或者命令已经安装，但是就是找不到这个命令，如下：
$ which commandcommand not found



这个时候就需要确定环境变量的配置PATH，可以通过下面的命令来查看：
$ echo $PATH/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin

此时可以从输出中看到，所确认命令的路径是否在当前环境变量中，如果没有的话，就需要考虑添加进来了。
]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>which</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux 的 which 命令</title>
    <url>/2012/12/27/linux-which/</url>
    <content><![CDATA[Linux which命令Linux which命令用于查找一个命令，不像find，find是用来查找文件的。
官方定义为：

which - locate a command

改名了会在当前环境变量中查找符合条件的命令。
语法$ which [-a] filename ...



这个命令基本没有参数，只有一个：

-a     print all matching pathnames of each argument

如果找到相关的指令并可执行，将返回0.
1⃣ 默认无参数查找命令并显示具体路径：
$ which bash/usr/bin/bash 

可能会输出不同，取决于环境变量。
2⃣ 显示所有命令一个命令，可能会有多个版本，或者同一个版本的多个位置，可以使用-a参数来检索。
$ which -a bash/usr/bin/bash/bin/bash



3⃣ 一个小小无聊的尝试 在Ubuntu操作系统中，看看下面的命令：
$ which whichwhich: shell built-in command

显示为内建指令
扩展如果确认程序或者命令已经安装，但是就是找不到这个命令，如下：
$ which commandcommand not found



这个时候就需要确定环境变量的配置PATH，可以通过下面的命令来查看：
$ echo $PATH/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin

此时可以从输出中看到，所确认命令的路径是否在当前环境变量中，如果没有的话，就需要考虑添加进来了。
]]></content>
      <categories>
        <category>Linux</category>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>which</tag>
      </tags>
  </entry>
  <entry>
    <title>谁？ who</title>
    <url>/2012/03/12/linux-who-beginner/</url>
    <content><![CDATA[谁？who.. note::  物是人非事事休，欲语泪先流。  李清照《武陵春·春晚》
知道了我是谁，接下来就要知道谁是谁了。
who将显示谁在登录，显示的内容可能包括用户名、终端登录口，登录的时间等等信息。
官方定义为：

who - show who is logged on

用法为：
$ who [OPTION]... [ FILE | ARG1 ARG2 ]

常用的参数为：

-q , --count：只显示登入系统的帐号名称和总人数；
-s：此参数将忽略不予处理，仅负责解决who指令其他版本的兼容性问题；
-a, --all：效果为加上 -b -d --login -p -r -t -T -u
-b, --boot：上一次系统的重启时间
-d, --dead：打印dead进程 
-H, --heading：打印每一列的表头
-q, --count：所有登录的用户名以及用户登录的数量
-s, --short：打印USER/LINE/WHEN（默认为这个参数）

默认使用显示当前登录系统的用户
$ who       user      pts/0  2012-03-02 10:12 user2     pts/1  2012-03-10 09:12



系统的运行时间这个信息显示系统自上一次重启后的运行时间。
$ who -b			system boot 2012-02-16 14:05



显示表头信息使用-H或者--heading可以看到表头信息
$ who -HUSER     LINE     WHEN         user      pts/0  2012-03-02 10:12 user2     pts/1  2012-03-10 09:12



显示登录的人员及总数$ who -quser1 user1 user2 user2 user3 user4# users=6

]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>who</tag>
        <tag>用户信息</tag>
      </tags>
  </entry>
  <entry>
    <title>我是谁 whoami</title>
    <url>/2012/02/12/linux-whoami-beginner/</url>
    <content><![CDATA[我是谁 whoami.. note::  想当年，金戈铁马，气吞万里如虎。  辛弃疾《永遇乐·京口北固亭怀古》
我知道你是谁，但我不知道我是谁，此时whoami可以帮助你，哈哈。
whoami将打印当前用户的名字。与id -un类似。
官方定义为：

whoami - print effective userid

用法为：
$ whoami [option] ..

这命令，基本没有参数。
我暂时。。也没有想到为什么会有这个命令。
唯一的可能使你找管理员来配置个啥，然后他需要知道你是谁，不，我是谁。
我看了一下源码，果然简洁：
#include &lt;config.h&gt;#include &lt;stdio.h&gt;#include &lt;sys/types.h&gt;#include &lt;pwd.h&gt;#include "system.h"#include "die.h"#include "error.h"#include "long-options.h"#include "quote.h"/* The official name of this program (e.g., no 'g' prefix).  */#define PROGRAM_NAME "whoami"#define AUTHORS proper_name ("Richard Mlynarik")voidusage (int status){  if (status != EXIT_SUCCESS)    emit_try_help ();  else    {      printf (_("Usage: %s [OPTION]...\n"), program_name);      fputs (_("\Print the user name associated with the current effective user ID.\n\Same as id -un.\n\\n\"), stdout);      fputs (HELP_OPTION_DESCRIPTION, stdout);      fputs (VERSION_OPTION_DESCRIPTION, stdout);      emit_ancillary_info (PROGRAM_NAME);    }  exit (status);}intmain (int argc, char **argv){  struct passwd *pw;  uid_t uid;  uid_t NO_UID = -1;  initialize_main (&amp;argc, &amp;argv);  set_program_name (argv[0]);  setlocale (LC_ALL, "");  bindtextdomain (PACKAGE, LOCALEDIR);  textdomain (PACKAGE);  atexit (close_stdout);  parse_gnu_standard_options_only (argc, argv, PROGRAM_NAME, PACKAGE_NAME,                                   Version, true, usage, AUTHORS,                                   (char const *) NULL);  if (optind != argc)    {      error (0, 0, _("extra operand %s"), quote (argv[optind]));      usage (EXIT_FAILURE);    }  errno = 0;  uid = geteuid ();  pw = (uid == NO_UID &amp;&amp; errno ? NULL : getpwuid (uid));  if (!pw)    die (EXIT_FAILURE, errno, _("cannot find name for user ID %lu"),         (unsigned long int) uid);  puts (pw-&gt;pw_name);  return EXIT_SUCCESS;}



其中使用的即为uid = geteuid ();。
]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>whoami</tag>
        <tag>用户信息</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux的 whoami命令</title>
    <url>/2012/02/12/linux-whoami/</url>
    <content><![CDATA[whoami 我是谁我知道你是谁，但我不知道我是谁，此时whoami可以帮助你，哈哈。
whoami将打印当前用户的名字。与id -un类似。
官方定义为：

whoami - print effective userid

用法为：
$ whoami [option] ..

这命令，基本没有参数。
我暂时。。也没有想到为什么会有这个命令。
唯一的可能使你找管理员来配置个啥，然后他需要知道你是谁，不，我是谁。
我看了一下源码，果然简洁：
#include &lt;config.h&gt;#include &lt;stdio.h&gt;#include &lt;sys/types.h&gt;#include &lt;pwd.h&gt;#include "system.h"#include "die.h"#include "error.h"#include "long-options.h"#include "quote.h"/* The official name of this program (e.g., no 'g' prefix).  */#define PROGRAM_NAME "whoami"#define AUTHORS proper_name ("Richard Mlynarik")voidusage (int status){  if (status != EXIT_SUCCESS)    emit_try_help ();  else    {      printf (_("Usage: %s [OPTION]...\n"), program_name);      fputs (_("\Print the user name associated with the current effective user ID.\n\Same as id -un.\n\\n\"), stdout);      fputs (HELP_OPTION_DESCRIPTION, stdout);      fputs (VERSION_OPTION_DESCRIPTION, stdout);      emit_ancillary_info (PROGRAM_NAME);    }  exit (status);}intmain (int argc, char **argv){  struct passwd *pw;  uid_t uid;  uid_t NO_UID = -1;  initialize_main (&amp;argc, &amp;argv);  set_program_name (argv[0]);  setlocale (LC_ALL, "");  bindtextdomain (PACKAGE, LOCALEDIR);  textdomain (PACKAGE);  atexit (close_stdout);  parse_gnu_standard_options_only (argc, argv, PROGRAM_NAME, PACKAGE_NAME,                                   Version, true, usage, AUTHORS,                                   (char const *) NULL);  if (optind != argc)    {      error (0, 0, _("extra operand %s"), quote (argv[optind]));      usage (EXIT_FAILURE);    }  errno = 0;  uid = geteuid ();  pw = (uid == NO_UID &amp;&amp; errno ? NULL : getpwuid (uid));  if (!pw)    die (EXIT_FAILURE, errno, _("cannot find name for user ID %lu"),         (unsigned long int) uid);  puts (pw-&gt;pw_name);  return EXIT_SUCCESS;}



其中使用的即为uid = geteuid ();。
]]></content>
      <categories>
        <category>Linux</category>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>whoami</tag>
      </tags>
  </entry>
  <entry>
    <title>探索网络信息的利器 whois</title>
    <url>/2018/08/26/linux-whois-beginner/</url>
    <content><![CDATA[探索网络信息的利器 whois在网络的世界中，虚虚实实，真真假假，了解域名、IP地址的所有者信息是至关重要的。Linux系统也提供了一个强大的工具whois，它能够查询并展示域名、IP地址的注册信息、所有者以及其他相关细节。
什么是whois命令？whois是一个用于查询互联网资源的命令行工具。通过whois命令，用户可以获取关于域名、IP地址和AS号码（Autonomous System Number，自治系统号码）等网络资源的注册信息。这些信息包括域名的所有者、注册商、注册日期、过期日期等重要数据。
如何使用whois命令？在Linux终端中，使用whois命令非常简单。

查询域名信息
whois example.com

这将显示example.com域名的注册信息，包括注册商、注册日期、过期日期等。

查询IP地址信息
whois 8.8.8.8

这将显示IP地址8.8.8.8的注册信息，提供该IP地址的所有者和注册信息。

通过管道和grep过滤需要的信息
whois example.com | grep "Registrar"

通过管道和grep命令，可以筛选出包含特定关键词（如”Registrar”）的信息，使查询结果更易读。


注意事项
whois提供的信息可能因注册商、注册政策等因素而有所不同，不一定是100%准确的。
有些注册商对whois查询设置了限制，可能会要求输入验证码或限制查询次数。

]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>Linux炫技</tag>
        <tag>ip</tag>
        <tag>网络命令</tag>
      </tags>
  </entry>
  <entry>
    <title>通配符 - 命令行的倚天剑、屠龙刀</title>
    <url>/2016/02/12/linux-wildcard-misc/</url>
    <content><![CDATA[通配符 - 命令行的倚天剑、屠龙刀命令行能干很多GUI图形界面不能做的事情，不知道你的Linux倚天剑、屠龙刀有没有出鞘呢。
很多熟悉Linux命令行的人，对命令行的威力应该叹为观止了。
这其中，我认为通配符，或者广一点来说，正则表达式，真的可以成为天下武林至尊，宝刀屠龙了。
说个最简单的例子

我想拷贝某个文件夹里面的在三个小时内曾经修改过的包含hero的文件。

请大家踊跃发言，如何解决。
下面就说下几个比较常用的通配符。



通配符
匹配项



*
匹配任意多个字符


?
匹配任一单个字符


[characters]
匹配任意一个属于字符集合中的字符


![characters]
匹配任意一个不属于字符集合中的额字符


现在我们执行ls命令，可以看到有下面几个文件：
➜   lsab  abb  ac  ad  ae  af

实例一 *匹配任意多个字符
➜   ls a*ab  abb  ac  ad  ae  af➜   ls ab*ab  abb➜

实例二 ?匹配任一单个字符
➜   ls a?ab  ac  ad  ae  af➜   ls a??abb➜


实例三 [characters]匹配任意一个属于字符集合中的字符
➜   ls a[bcd]ab  ac  ad


实例四 ![characters]匹配任意一个不属于字符集合中的额字符
➜   ls a[!(bcd)]ae  af

通配符 - 命令行的倚天剑、屠龙刀继续昨天的倚天剑的通配符操作。
为什么分两次：

俺觉得昨天的知道的肯定知道，无外乎复习下
不知道的其实也够一天几分钟的量了

为什么说通配符：

后面的很多操作都会用到通配符
通配符不掌握不要说你会用Linux
考虑花几十个tips来说下正则表达式

昨天的都比较简单，今天来点有难度的。

其实我觉得屠龙刀比倚天剑厉害，因为我喜欢灭绝师太，^_^。

首先看下目前文件夹里面都有什么，下面所有的操作都基于这个文件列表：
➜  ls1a  1b  a12  a123  a13  a14  ab  AB  abb  ABC  ac  ad  ae  af  b12  b123  b13  b14

实例 [:alnum:] - 匹配任意一个字母或数字➜  ls [[:alnum:]]*1a  1b  a12  a123  a13  a14  ab  AB  abb  ABC  ac  ad  ae  af  b12  b123  b13  b14

实例 [:alpha:] - 匹配任意一个字母➜  ls [[:alpha:]]*a12  a123  a13  a14  ab  AB  abb  ABC  ac  ad  ae  af  b12  b123  b13  b14

实例 [:digit:] - 匹配任意一个数字➜  ls [[:digit:]]*1a  1b

实例 [:lower:] - 匹配任意一个小写字母➜  ls [[:lower:]]*a12  a123  a13  a14  ab  abb  ac  ad  ae  af  b12  b123  b13  b14

实例 [:upper:] - 匹配任意一个大写字母➜  ls [[:upper:]]*AB  ABC
]]></content>
      <categories>
        <category>Linux炫技</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>ls</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux的 write命令</title>
    <url>/2011/04/15/linux-write-beginner/</url>
    <content><![CDATA[私信某个用户的write命令   Linux write命令会将信息传给某一个 mesg 设定为 yes 的上线使用者（可以输入mesg，如果返回is yes就可以收到）。当使用终端登陆的时候，可以使用EOF (通常用 Ctrl+D)。所有人均可以使用该命令。
官方的定义为：

write – send a message to another user.

使用的方法为：
  $ write user [ttyname]

相比于wall命令，多了一个[ttyname]这个参数。
在使用write的时候，用户会收到如下的信息格式：
Message from yourname@yourhost on yourtty at hh:mm …       
而多了的[ttyname]这个参数用于在一个用户登陆了很多的终端后，可以指定向哪个终端发送命令。
这个命令的使用场景为单独向某个用户发送命令，比如账户快到期了、用户要续费了等等。
如下：
$ write userDear user,We want to make you aware that your account will disable in two weeks.Please save all your works or contact me for longer use.Regards,AdminCtrl+D #退出



所有登陆的终端都会收到这个消息：
Message from admin@localhost on pts/4 at 22:39 ...Dear user,We want to make you aware that your account will disable in two weeks.Please save all your works or contact me for longer use.Regards,AdminEOF



如果用户没有登陆，会有下面的输出：
$ write userwrite: user is not logged in



而如果一个用户登陆了好几个终端，在不指定的情况下会有如下提示：
$ write userwrite: useris logged in more than once; writing to pts/N
]]></content>
      <categories>
        <category>Linux</category>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>write</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux xargs 命令</title>
    <url>/2015/05/13/linux-xargs-beginner/</url>
    <content><![CDATA[Linux xargs命令xargs是一个非常非常强大的命令，是eXtended ARGuments的缩写。
可以取一个命令的输出作为另一个命令的参数。
默认的用法为初始化输入字符，加上一些参数就能达到超级赞的效果（这里说的参数一般是和管道一起使用）。
官方定义为：

xargs - build and execute command lines from standard input

含义为从标准输入构建和执行命令。
用法为：
$ xargs [options] [command [initial-arguments]]



常用参数为：

-n max-args, --max-args=max-args ：后面加次数，表示命令在执行的时候一次用的argument的个数，默认是用所有的
--delimiter=delim, -d delim ：默认的分隔符是回车，这里重定义了分隔符修改的是xargs的分隔符。

基本用法读取输入数据重新格式化后输出。比如一个测试文件，内容如下：
$ cat test.txth e l l o w o r l dH O W A R E Y O U

现在我们单行输出：
$ cat test.txt | xargsh e l l o w o r l d H O W A R E Y O U



指定输出几个字符也可以使用参数-n指定一行输出几个字符，比如
$ cat test.txt | xargs -n3h e ll o wo r ld H O W A R E Y OU


这对于对仗的唐诗是个绝佳的选择，比如五言绝句。

指定分界符使用-d参数可以指定定界符：
$ echo "name1,name2,name3,name4" | xargs -d,name1 name2 name3 name4

可以认为简单快捷地初步解析了CSV格式的数据了。
同上，配合上-n选项，可以指定每行输出几项
$ echo "name1,name2,name3,name4" | xargs -d, -n2name1 name2name3 name4



结合管道的简单使用前面说了很强大，到底如何强大呢，加入你有一个文件夹photo，里面有几百个文件夹，可能还有各种文件，其中有一些jpg后缀的特别想保存，怎么办，一个命令搞定。
接下来这个命令就是找出所有的.jpg格式的图片，并将其打包归档。
$ find /the/path/of/photo -name *.jpg -type f -print | xargs tar -cvzf images.tar.gz

8. 复制文件到多个目录通常使用 cp 命令进行文件复制。复制文件通常看起来类似：
# cp /path-to-file/my_file.txt /path-to-new-directory/

现在假设你需要复制该文件到多个目录：
# cp /home/user/my_file.txt /home/user/1# cp /home/user/my_file.txt /home/user/2# cp /home/user/my_file.txt /home/user/3

这有点荒唐。相反，你可以用简单的一行命令解决问题：
# echo /home/user/1/ /home/user/2/ /home/user/3/ | xargs -n 1  cp /home/user/my_file.txt


其他的强大组合，以后再续。
]]></content>
      <categories>
        <category>Linux</category>
        <category>Shell</category>
      </categories>
      <tags>
        <tag>shell</tag>
        <tag>Linux炫技</tag>
        <tag>xargs</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux xargs 命令</title>
    <url>/2015/05/13/linux-xargs/</url>
    <content><![CDATA[Linux xargs命令xargs是一个非常非常强大的命令，是eXtended ARGuments的缩写，可以取一个命令的输出作为另一个命令的参数。
默认的用法为初始化输入字符，加上一些参数就能达到超级赞的效果（这里说的参数一般是和管道一起使用）。
官方定义为：

xargs - build and execute command lines from standard input

含义为从标准输入构建和执行命令。
用法为：
$ xargs [options] [command [initial-arguments]]



常用参数为：

-n max-args, --max-args=max-args ：后面加次数，表示命令在执行的时候一次用的argument的个数，默认是用所有的
--delimiter=delim, -d delim ：默认的分隔符是回车，这里重定义了分隔符修改的是xargs的分隔符。

基本用法读取输入数据重新格式化后输出。比如一个测试文件，内容如下：
$ cat test.txth e l l o w o r l dH O W A R E Y O U

现在我们单行输出：
$ cat test.txt | xargsh e l l o w o r l d H O W A R E Y O U



指定输出几个字符也可以使用参数-n指定一行输出几个字符，比如
$ cat test.txt | xargs -n3h e ll o wo r ld H O W A R E Y OU


这对于对仗的唐诗是个绝佳的选择，比如五言绝句。

指定分界符使用-d参数可以指定定界符：
$ echo "name1,name2,name3,name4" | xargs -d,name1 name2 name3 name4

可以认为简单快捷地初步解析了CSV格式的数据了。
同上，配合上-n选项，可以指定每行输出几项
$ echo "name1,name2,name3,name4" | xargs -d, -n2name1 name2name3 name4



结合管道的简单使用前面说了很强大，到底如何强大呢，加入你有一个文件夹photo，里面有几百个文件夹，可能还有各种文件，其中有一些jpg后缀的特别想保存，怎么办，一个命令搞定。
接下来这个命令就是找出所有的.jpg格式的图片，并将其打包归档。
$ find /the/path/of/photo -name *.jpg -type f -print | xargs tar -cvzf images.tar.gz



其他的强大组合，以后再续。
获得/etc下所有以.conf结尾的文件。可以有多种方法获得如下结果。以下命令仅仅为了帮助大家理解如何使用xargs.find命令的输入结果一个接一个的传递给xargs，作为ls -l的参数。
$ find /etc -name "*.conf" | xargs ls –l

当你想下载一些URL，这些URL都保存在一个文件里，你可以以如下的方式使用xargs命令
$ cat url-list.txt | xargs wget –c





Linux xargs 命令xargs（英文全拼： eXtended ARGuments）是给命令传递参数的一个过滤器，也是组合多个命令的一个工具。
xargs 可以将管道或标准输入（stdin）数据转换成命令行参数，也能够从文件的输出中读取数据。
xargs 也可以将单行或多行文本输入转换为其他格式，例如多行变单行，单行变多行。
xargs 默认的命令是 echo，这意味着通过管道传递给 xargs 的输入将会包含换行和空白，不过通过 xargs 的处理，换行和空白将被空格取代。
xargs 是一个强有力的命令，它能够捕获一个命令的输出，然后传递给另外一个命令。
之所以能用到这个命令，关键是由于很多命令不支持|管道来传递参数，而日常工作中有有这个必要，所以就有了 xargs 命令，例如：
find /sbin -perm +700 |ls -l       #这个命令是错误的find /sbin -perm +700 |xargs ls -l   #这样才是正确的



命令格式：
somecommand |xargs -item  command

参数：

-a file 从文件中读入作为 stdin
-e flag ，注意有的时候可能会是-E，flag必须是一个以空格分隔的标志，当xargs分析到含有flag这个标志的时候就停止。
-p 当每次执行一个argument的时候询问一次用户。
-t 表示先打印命令，然后再执行。
-i 或者是-I，这得看linux支持了，将xargs的每项名称，一般是一行一行赋值给 {}，可以用 {} 代替。
-r no-run-if-empty 当xargs的输入为空的时候则停止xargs，不用再去执行了。
-s num 命令行的最大字符数，指的是 xargs 后面那个命令的最大命令行字符数。
-L num 从标准输入一次读取 num 行送给 command 命令。
-l 同 -L。
-x exit的意思，主要是配合-s使用。。
-P 修改最大的进程数，默认是1，为0时候为as many as it can ，这个例子我没有想到，应该平时都用不到的吧。

假设一个命令为 sk.sh 和一个保存参数的文件 arg.txt：
#!/bin/bash#sk.sh命令内容，打印出所有参数。echo $*

arg.txt文件内容：
# cat arg.txtaaabbbccc

xargs 的一个选项 -I，使用 -I 指定一个替换字符串 {}，这个字符串在 xargs 扩展时会被替换掉，当 -I 与 xargs 结合使用，每一个参数命令都会被执行一次：
# cat arg.txt | xargs -I {} ./sk.sh -p {} -l-p aaa -l-p bbb -l-p ccc -l

复制所有图片文件到 /data/images 目录下：
ls *.jpg | xargs -n1 -I {} cp {} /data/images

xargs 结合 find 使用
用 rm 删除太多的文件时候，可能得到一个错误信息：**/bin/rm Argument list too long.** 用 xargs 去避免这个问题：
find . -type f -name "*.log" -print0 | xargs -0 rm -f

xargs -0 将 \0 作为定界符。
统计一个源代码目录中所有 php 文件的行数：
find . -type f -name "*.php" -print0 | xargs -0 wc -l

查找所有的 jpg 文件，并且压缩它们：
find . -type f -name "*.jpg" -print | xargs tar -czvf images.tar.gz

xargs 其他应用
假如你有一个文件包含了很多你希望下载的 URL，你能够使用 xargs下载所有链接：
# cat url-list.txt | xargs wget -c




DESCRIPTION       This manual page documents the GNU version of xargs.  xargs reads items from the standard input, delimited by blanks (which can be pro‐       tected with double or single quotes or a backslash) or newlines, and executes the command (default is /bin/echo) one or more times with       any initial-arguments followed by items read from standard input.  Blank lines on the standard input are ignored.
   The  command  line for command is built up until it reaches a system-defined limit (unless the -n and -L options are used).  The speci‐
   fied command will be invoked as many times as necessary to use up the list of input items.  In general, there will be many fewer  invo‐
   cations  of  command  than there were items in the input.  This will normally have significant performance benefits.  Some commands can
   usefully be executed in parallel too; see the -P option.

   Because Unix filenames can contain blanks and newlines, this default behaviour is often problematic; filenames containing blanks and/or
   newlines  are  incorrectly  processed  by  xargs.  In these situations it is better to use the -0 option, which prevents such problems.
   When using this option you will need to ensure that the program which produces the input for xargs also uses a null character as a sep‐
   arator.  If that program is GNU find for example, the -print0 option does this for you.

   If  any  invocation of the command exits with a status of 255, xargs will stop immediately without reading any further input.  An error
   message is issued on stderr when this happens.

OPTIONS       -0, –null              Input items are terminated by a null character instead of by whitespace, and the quotes and backslash  are  not  special  (every              character  is  taken  literally).  Disables the end of file string, which is treated like any other argument.  Useful when input              items might contain white space, quote marks, or backslashes.  The GNU find -print0 option  produces  input  suitable  for  this              mode.
   -a file, --arg-file=file
          Read  items from file instead of standard input.  If you use this option, stdin remains unchanged when commands are run.  Other‐
          wise, stdin is redirected from /dev/null.



   -E eof-str
          Set  the  end of file string to eof-str.  If the end of file string occurs as a line of input, the rest of the input is ignored.
          If neither -E nor -e is used, no end of file string is used.

   -e[eof-str], --eof[=eof-str]
          This option is a synonym for the -E option.  Use -E instead, because it is POSIX compliant while this option is not.  If eof-str
          is omitted, there is no end of file string.  If neither -E nor -e is used, no end of file string is used.

   -I replace-str
          Replace  occurrences  of replace-str in the initial-arguments with names read from standard input.  Also, unquoted blanks do not
          terminate input items; instead the separator is the newline character.  Implies -x and -L 1.

   -i[replace-str], --replace[=replace-str]
          This option is a synonym for -Ireplace-str if replace-str is specified.  If the replace-str argument is missing, the  effect  is
          the same as -I{}.  This option is deprecated; use -I instead.

   -L max-lines
          Use  at  most max-lines nonblank input lines per command line.  Trailing blanks cause an input line to be logically continued on
          the next input line.  Implies -x.

   -l[max-lines], --max-lines[=max-lines]
          Synonym for the -L option.  Unlike -L, the max-lines argument is optional.  If max-lines is not specified, it defaults  to  one.
          The -l option is deprecated since the POSIX standard specifies -L instead.


   -P max-procs, --max-procs=max-procs
          Run up to max-procs processes at a time; the default is 1.  If max-procs is 0, xargs will run as many processes as possible at a
          time.   Use  the -n option or the -L option with -P; otherwise chances are that only one exec will be done.  While xargs is run‐
          ning, you can send its process a SIGUSR1 signal to increase the number of commands to run simultaneously, or a  SIGUSR2  to  de‐
          crease  the number.  You cannot increase it above an implementation-defined limit (which is shown with --show-limits).  You can‐
          not decrease it below 1.  xargs never terminates its commands; when asked to decrease, it merely waits for more than one  exist‐
          ing command to terminate before starting another.

          Please  note that it is up to the called processes to properly manage parallel access to shared resources.  For example, if more
          than one of them tries to print to stdout, the output will be produced in an indeterminate order (and very likely mixed up)  un‐
          less  the processes collaborate in some way to prevent this.  Using some kind of locking scheme is one way to prevent such prob‐
          lems.  In general, using a locking scheme will help ensure correct output but reduce performance.  If you don't want to tolerate
          the  performance  difference,  simply  arrange for each process to produce a separate output file (or otherwise use separate re‐
          sources).

   -o, --open-tty
          Reopen stdin as /dev/tty in the child process before executing the command.  This is useful if you want xargs to run an interac‐
          tive application.

   -p, --interactive
          Prompt  the user about whether to run each command line and read a line from the terminal.  Only run the command line if the re‐
          sponse starts with `y' or `Y'.  Implies -t.

   --process-slot-var=name
          Set the environment variable name to a unique value in each running child process.  Values are reused once child processes exit.
          This can be used in a rudimentary load distribution scheme, for example.

   -r, --no-run-if-empty
          If  the  standard input does not contain any nonblanks, do not run the command.  Normally, the command is run once even if there
          is no input.  This option is a GNU extension.

   -s max-chars, --max-chars=max-chars
          Use at most max-chars characters per command line, including the command and initial-arguments and the terminating nulls at  the
          ends of the argument strings.  The largest allowed value is system-dependent, and is calculated as the argument length limit for
          exec, less the size of your environment, less 2048 bytes of headroom.  If this value is more than 128KiB, 128Kib is used as  the
          default  value;  otherwise,  the  default value is the maximum.  1KiB is 1024 bytes.  xargs automatically adapts to tighter con‐
          straints.

   --show-limits
          Display the limits on the command-line length which are imposed by the operating system, xargs' choice of buffer size and the -s
          option.  Pipe the input from /dev/null (and perhaps specify --no-run-if-empty) if you don't want xargs to do anything.

   -t, --verbose
          Print the command line on the standard error output before executing it.

   -x, --exit
          Exit if the size (see the -s option) is exceeded.

   --help Print a summary of the options to xargs and exit.

   --version
          Print the version number of xargs and exit.

EXAMPLES       find /tmp -name core -type f -print | xargs /bin/rm -f
   Find  files named core in or below the directory /tmp and delete them.  Note that this will work incorrectly if there are any filenames
   containing newlines or spaces.

   find /tmp -name core -type f -print0 | xargs -0 /bin/rm -f

   Find files named core in or below the directory /tmp and delete them, processing filenames in such a way that file or  directory  names
   containing spaces or newlines are correctly handled.

   find /tmp -depth -name core -type f -delete

   Find  files  named  core  in or below the directory /tmp and delete them, but more efficiently than in the previous example (because we
   avoid the need to use fork(2) and exec(2) to launch rm and we don't need the extra xargs process).

   cut -d: -f1 &lt; /etc/passwd | sort | xargs echo

   Generates a compact listing of all the users on the system.

EXIT STATUS       xargs exits with the following status:       0 if it succeeds       123 if any invocation of the command exited with status 1-125       124 if the command exited with status 255       125 if the command is killed by a signal       126 if the command cannot be run       127 if the command is not found       1 if some other error occurred.
   Exit codes greater than 128 are used by the shell to indicate that a program died due to a fatal signal.

STANDARDS CONFORMANCE       As of GNU xargs version 4.2.9, the default behaviour of xargs is not to have a logical end-of-file marker.   POSIX  (IEEE  Std  1003.1,       2004 Edition) allows this.
   The  -l and -i options appear in the 1997 version of the POSIX standard, but do not appear in the 2004 version of the standard.  There‐
   fore you should use -L and -I instead, respectively.

   The -o option is an extension to the POSIX standard for better compatibility with BSD.

   The POSIX standard allows implementations to have a limit on the size of arguments to the exec functions.  This limit could be  as  low
   as  4096  bytes  including  the size of the environment.  For scripts to be portable, they must not rely on a larger value.  However, I
   know of no implementation whose actual limit is that small.  The --show-limits option can be used to  discover  the  actual  limits  in
   force on the current system.

SEE ALSO       find(1), locate(1), locatedb(5), updatedb(1), fork(2), execvp(3), kill(1), signal(7),
   The   full  documentation  for  xargs is maintained as a Texinfo manual.  If the info and xargs programs are properly installed at your
   site, the command info xargs should give you access to the complete manual.

COPYRIGHT       Copyright © 1990-2019 Free Software Foundation, Inc.  License GPLv3+: GNU GPL version 3 or later https://gnu.org/licenses/gpl.html.       This is free software: you are free to change and redistribute it.  There is NO WARRANTY, to the extent permitted by law.
BUGS       The -L option is incompatible with the -I option, but perhaps should not be.
   It is not possible for xargs to be used securely, since there will always be a time gap between the production of  the  list  of  input
   files  and  their  use in the commands that xargs issues.  If other users have access to the system, they can manipulate the filesystem
   during this time window to force the action of the commands xargs runs to apply to files that you didn't intend.  For a  more  detailed
   discussion  of  this  and related problems, please refer to the ``Security Considerations'' chapter in the findutils Texinfo documenta‐
   tion.  The -execdir option of find can often be used as a more secure alternative.

   When you use the -I option, each line read from the input is buffered internally.   This means that there is  an  upper  limit  on  the
   length of input line that xargs will accept when used with the -I option.  To work around this limitation, you can use the -s option to
   increase the amount of buffer space that xargs uses, and you can also use an extra invocation of xargs to ensure that very  long  lines
   do not occur.  For example:

   somecommand | xargs -s 50000 echo | xargs -I '{}' -s 100000 rm '{}'

   Here,  the  first  invocation  of  xargs has no input line length limit because it doesn't use the -i option.  The second invocation of
   xargs does have such a limit, but we have ensured that the it never encounters a line which is longer than it can handle.   This is not
   an ideal solution.  Instead, the -i option should not impose a line length limit, which is why this discussion appears in the BUGS sec‐
   tion.  The problem doesn't occur with the output of find(1) because it emits just one filename per line.

   The best way to report a bug is to use the form at https://savannah.gnu.org/bugs/?group=findutils.  The reason for  this  is  that  you
   will  then  be able to track progress in fixing the problem.   Other comments about xargs(1) and about the findutils package in general
   can be sent to the bug-findutils mailing list.  To join the list, send email to bug-findutils-request@gnu.org.

                                                                                                                                  XARGS(1)

]]></content>
      <categories>
        <category>Linux</category>
        <category>Shell</category>
      </categories>
      <tags>
        <tag>shell</tag>
        <tag>xargs</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux xfs文件系统</title>
    <url>/2012/08/02/linux-xfs-filesystem/</url>
    <content><![CDATA[
文章写在2012年，目前最新的很多操作系统发行版，比如CentOS，已经内置支持了xfs文件系统，大部分的操作均可省略了。

XFS 文件系统XFS文件系统是SGI开发的高级日志文件系统，XFS极具伸缩性，非常健壮。
在Linux环境下。目前版本可用的最新XFS文件系统的为1.2版本，可以很好地工作在2.4核心下。
XFS文件系统简介主要特性包括以下几点：

数据完全性
采用XFS文件系统，当意想不到的宕机发生后，首先，由于文件系统开启了日志功能，所以你磁盘上的文件不再会意外宕机而遭到破坏了。不论目前文件系统上存储的文件与数据有多少，文件系统都可以根据所记录的日志在很短的时间内迅速恢复磁盘文件内容。

传输特性
XFS文件系统采用优化算法，日志记录对整体文件操作影响非常小。XFS查询与分配存储空间非常快。XFS文件系统能连续提供快速的反应时间。笔者曾经对XFS、JFS、Ext3、ReiserFS文件系统进行过测试，XFS文件文件系统的性能表现相当出众。

可扩展性
XFS 是一个全64-bit的文件系统，它可以支持上百万T字节的存储空间。对特大文件及小尺寸文件的支持都表现出众，支持特大数量的目录。最大可支持的文件大小为263 = 9 x 1018 = 9 exabytes，最大文件系统尺寸为18 exabytes。
XFS使用高的表结构(B+树)，保证了文件系统可以快速搜索与快速空间分配。XFS能够持续提供高速操作，文件系统的性能不受目录中目录及文件数量的限制。

传输带宽
XFS 能以接近裸设备I/O的性能存储数据。在单个文件系统的测试中，其吞吐量最高可达7GB每秒，对单个文件的读写操作，其吞吐量可达4GB每秒。


XFS文件系统的使用1.下载与编译内核下载相应版本的内核补丁，解压补丁软件包，对系统核心打补丁。
下载地址：ftp://oss.sgi.com/projects/xfs/d … .4.18-all.patch.bz2
对核心打补丁，下载解压后，得到一个文件：xfs-1.1-2.4.18-all.patch文件。
对核心进行修补如下：
# cd /usr/src/linux# patch -p1 &lt; /path/to/xfs-1.1-2.4.18-all.patch

修补工作完成后，下一步要进行的工作是编译核心，将XFS编译进Linux核心可中。
首先运行以下命令，选择核心支持XFS文件系统：
#make menuconfig



在“文件系统“菜单中选择：
&lt;*&gt; SGI XFS filesystem support ##说明：将xfs文件系统的支持编译进核心或 SGI XFS。 filesystem support ##说明：以动态加载模块的方式支持XFS文件系统。
另外还有两个选择：

Enable XFS DMAPI　##说明：对磁盘管理的API，存储管理应用程序使用。

Enable XFS Quota　##说明：支持配合Quota对用户使用磁盘空间大小管理。


完成上工作后，退出并保存核心选择配置。之后，然后编译内核，安装核心:
# make bzImage# make module# make module_install# make install

如果你对以上复杂繁琐的工作没有耐心或没有把握，那么可以直接从SGI的站点上下载已经打好补丁的核心，其版本为2.4.18。它是一个rpm软件包，你只要简单地安装即可。SGI提交的核心有两种，分别供smp及单处理器的机器使用。
2.创建XFS文件系统完成对核心的编译后，还应下载与之配套的xfsprogs工具软件包，也即mkfs.xfs工具。不然我们无法完成对分区的格式化:即无法将一个分区格式化成XFS文件系统的格式。要下载的软件包名称：xfsprogs-2.0.3。
将所下载的xfsProgs工具解压，安装，mkfs.xfs自动安装在/sbin目录下。
# tar –xvf xfsprogs-2.0.3.src.tar.gz# cd xfsprogs-2.0.3src# ./configure# make# make install

使用mkfs.xfs格式化磁盘为XFS文件系统，方法如下：
# /sbin/mkfs.xfs /dev/sda6 ＃说明：将分区格式化为`XFS`文件系统

格式化磁盘时，如果mkfs.xfs提示你分区原本已被格式化为其它文件系统，可以使用参数 –f 强行格式化：
#/sbin/mkfs.xfs –f /dev/sda6

3.加载XFS文件系统#mount –t xfs /dev/sda6 /xfs ##其中/xfs是主分区/下的一个目录。

最后，为了让系统启动后就自动加载，应该更改/etc/fstab，这样系统启动后就会自动加载XFS分区而不必每次都手工加载。
要说明的一点是目前的XFS由于受Linux内存页限制，在x86版本中，只能实现文件系统的块尺寸为4K。另外，XFS文件系统可以不同的方式 mount，即允许文件系统以读方式加载，也允许以读写方式加载。这是因为XFS文件系统用作根文件系统时，为了安全要以只读方式加载。
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>xfs</tag>
        <tag>xfsprogs</tag>
      </tags>
  </entry>
  <entry>
    <title>CentOS xfs 疑难解决</title>
    <url>/2020/05/17/linux-xfs-troubleshooting/</url>
    <content><![CDATA[xfs文件系统无法mount首先阐述一下碰到的问题，N年前做了一个高速记录系统，使用的为CentOS6.8的稳定系统，在备份机上做了同样的系统，最近可能强迫症所致，更新了一下，导致软件版本不一致，引起了文件系统无法挂载。
详细的信息如下：
# mount /dev/sdb /data/mount: wrong fs type, bad option, bad superblock on /dev/sdb,       missing codepage or helper program, or other error       In some cases useful info is found in syslog - try       dmesg | tail  or so

查看一下日志，可以看到如下信息：
# dmesg | tailXFS (sdb): bad versionXFS (sdb): SB validate failed

妥妥滴xfs的版本问题引起的无法挂载。
再深一步进行挖掘，自行创建一个xfs的文件系统进行分析：
# dd if=/dev/zero of=/var/tmp/dddddd.img bs=1024k seek=10240 count=1记录了1+0 的读入记录了1+0 的写出1048576字节(1.0 MB)已复制，0.00263831 秒，397 MB/秒# losetup /dev/loop0 /var/tmp/dddddd.img# mkfs.xfs /dev/loop0meta-data=/dev/loop0             isize=256    agcount=4, agsize=655424 blks         =                       sectsz=512   attr=2, projid32bit=0data     =                       bsize=4096   blocks=2621696, imaxpct=25         =                       sunit=0      swidth=0 blksnaming   =version 2              bsize=4096   ascii-ci=0log      =internal log           bsize=4096   blocks=2560, version=2         =                       sectsz=512   sunit=0 blks, lazy-count=1realtime =none                   extsz=4096   blocks=0, rtextents=0# echo "version" |  xfs_db /dev/loop0xfs_db&gt; versionversionnum [0xb4a4+0xa] = V4,NLINK,ALIGN,DIRV2,LOGV2,EXTFLG,MOREBITS,ATTR2,LAZYSBCOUNTxfs_db&gt; # xfs_db /dev/loop0xfs_db&gt; versionversionnum [0xb4a4+0xa] = V4,NLINK,ALIGN,DIRV2,LOGV2,EXTFLG,MOREBITS,ATTR2,LAZYSBCOUNTxfs_db&gt; quit

可以从versionnum [0xb4a4+0xa] 知道此时的版本为V4 或者-V参数知道此时安装xfs版本为3.1.1。
查看xfs版本# mkfs.xfs -V
]]></content>
      <categories>
        <category>Linux</category>
        <category>CentOS</category>
      </categories>
      <tags>
        <tag>xfsprogs</tag>
        <tag>mkfs.xfs</tag>
      </tags>
  </entry>
  <entry>
    <title>CentOS 上源码升级安装xfs软件包</title>
    <url>/2017/06/08/linux-xfs/</url>
    <content><![CDATA[安装依赖软件包sudo yum install libtool automake gettext libblkid-devel libuuid-devel
获取xfs最新软件包wget https://www.kernel.org/pub/linux/utils/fs/xfs/xfsprogs/xfsprogs-4.5.0.tar.gz
安装tar zxvf xfsprogs-4.5.0.tar.gz./configuremakemake installsudo make install

查看xfs版本mkfs.xfs -V
]]></content>
      <categories>
        <category>Linux</category>
        <category>CentOS</category>
      </categories>
      <tags>
        <tag>yum</tag>
        <tag>automake</tag>
        <tag>xfs</tag>
        <tag>libtool</tag>
        <tag>gettext</tag>
        <tag>libblkid</tag>
        <tag>libuuid</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux XTerm的使用</title>
    <url>/2013/09/01/linux-xterm/</url>
    <content><![CDATA[XTermxterm包的简介最古老最基础的X Window终端模拟包是xterm。xterm包是在X Window出现之初便已经存在了的，默认包含在大多数X Window包中。
XTerm是一个X Window System上的终端模拟器，用来提供多个独立的SHELL输入输出。
XTerm最先是Jim Gettys的学生Mark Vandevoorde在1984年夏天为VS100写的独立虚拟终端，当时X的开发刚刚开始。很快人们就发现它作为X的一部分比作为独立的程序更为有用，于是它开始针对X而开发。
Gettys曾讲述过有关的故事, “xterm内部如此恐怖的部分原因是它最初被计划开发成一个能驱动多个VS100显示器的单独进程。”（”part of why xterm’s internals are so horrifying is that it was originally intended that a single process be able to drive multiple VS100 displays.”）
xterm包提供基本的VT102/220终端模拟CLI和图形Tektronix 4014环境，尽管xterm是一个完整的终端模拟包，但是运行它不需要太多的资源和内存。由于这种特性，xterm包在针对老硬件设计的Linux发行版中仍然很常见。有些图形桌面环境（比如fluxbox）用它作为默认的终端模拟包。
尽管没有太多炫目的特性，但是xterm包提供了一个非常好的功能，即模拟VT220终端，最新的xterm版本甚至能模拟VT系列的颜色控制码，因而能够在脚本中使用颜色。       按住鼠标几个键同时按下CTRL可以访问xterm的几个菜单。包括xterm主菜单、VT选项菜单和VT字体选项菜单
XTerm Troubleshooting打开xterm的时候出现下面的警告：
xterm: cannot load font -misc-fixed-medium-r-semicondensed--

主要因为丢失了xterm需要的字体包，解决方法如下所示：
$ yum install xorg-x11-fonts*



XTerm的颜色系列XTerm是一个X Window System上的终端模拟器，用来提供多个独立的SHELL输入输出。而使用xterm可以设置字体和背景的颜色。
$ xterm -fg LightGoldenrod1 -bg CornflowerBlue

具体的效果如下所示：

]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>xterm</tag>
      </tags>
  </entry>
  <entry>
    <title>CentOS 安装配置zabbix库</title>
    <url>/2017/06/08/linux-zabbix/</url>
    <content><![CDATA[CentOS 安装配置zabbix库安装zabbix库$ sudo rpm -ivh https://repo.zabbix.com/zabbix/5.4/rhel/7/x86_64/zabbix-release-5.4-1.el7.noarch.rpm# 安装zabbix前端的一些包$ yum-config-manager --enable rhel-7-server-optional-rpms# Installation$ sudo yum install zabbix-server-mysql

新建数据库新建 zabbix Mysql 数据库及专用账号
$ mysql 



mysql &gt; CREATE DATABASE zabbix character set utf8 collate utf8_bin;mysql &gt; GRANT all ON zabbix.* TO 'zabbix'@'%' IDENTIFIED BY 'zabbix';mysql &gt; flush privileges;mysql &gt; quit






导入数据默认情况下，执行下述命令就可以；
# zcat /usr/share/doc/zabbix-server-mysql*/create.sql.gz | mysql -uzabbix -p zabbix

但是我好想没有找到这个压缩文件，所以执行下面的命令：
$ cd /usr/share/zabbix-mysql/# 依次导入下列sql表$ cat schema.sql | mysql -uzabbix -p zabbix$ cat images.sql | mysql -uzabbix -p zabbix$ cat data.sql | mysql -uzabbix -p zabbix



配置数据库$ vim /etc/zabbix/zabbix_server.confDBHost=localhostDBName=zabbixDBUser=zabbixDBPassword=zabbix



启动 Zabbix server 进程$ service zabbix-server start$ systemctl enable zabbix-server

web UI 安装zabbix重启一下Httpd 服务后，进入 http://zabbix-server-ip/zabbix 即可web配置，
初始登录信息为Admin/zabbix
安装zabbix agent安装Zabbix Agent
yum install zabbix-agent

编辑Zabbix Agent 配置文件
vim /etc/zabbix/zabbix_agentd.confServer=[zabbix server ip]ServerActive=[zabbix server ip]Hostname=[ Hostname of client system ]

重启Zabbix Agent
service zabbix-agent restart添加开机启动​```bashchkconfig zabbix-agent on



Zabbix agent on Zabbix server is unreachable for 5 minutes checked and found that the ServerActive address is not changed to zabbix-server IP address in configuration file. So we changed it to Zabbix-server IP.
We made the changes in:
/etc/zabbix/zabbix_agentd.conf

and restarted the service using:
$ sudo service zabbix-agent2 start 

This fixed the issue.
Not able to find zabbix data source in grafana After enabling pluginIt appears as signed on grafana’s plugin panel, but /etc/grafana/grafana.ini needs editing.
…[plugins]allow_loading_unsigned_plugins = alexanderzobnin-zabbix-datasource
zabbix 无法启动server服务器可以检查日志tailf /var/log/zabbix/zabbix_server.log 
ZABBIX 报错连接拒绝(cannot connect to [10050]: [111] Connection refused)首先还是看一下防火墙等是不是阻断.然后确认数据库的最大连接数.默认的是256.
1.vim /etc/my.cnf[mysqld]max_connections=需要添加的最大连接数
2.vim /etc/systemd/system.confDefaultLimitNOFILE=65535DefaultLimitNPROC=65535
3.重启
systemctl daemon-reload
systemctl restart mysqld.service
查看最大连接数mysql&gt;show variables like ‘max_connections’;查看当前连接数show status like ‘%thread%’;
]]></content>
      <categories>
        <category>Linux</category>
        <category>CentOS</category>
      </categories>
      <tags>
        <tag>yum</tag>
        <tag>automake</tag>
        <tag>xfs</tag>
        <tag>libtool</tag>
        <tag>gettext</tag>
        <tag>libblkid</tag>
        <tag>libuuid</tag>
      </tags>
  </entry>
  <entry>
    <title>红帽系的软件管理利器 - yum</title>
    <url>/2012/03/12/linux-yum-beginner/</url>
    <content><![CDATA[红帽系的软件管理利器 - yum.. note::  当年不肯嫁春风，无端却被秋风误。  贺铸《芳心苦·杨柳回塘》
我从ubuntu开始，后面短暂切换到Fedora，然后切换到CentOS，在CentOS断更之前，再无改变，所以最了解的还是yum命令了。
官方定义为：

yum -  Yellowdog Updater Modified

说实话，yum跟yellowdog感觉半毛线关系都没有，那为什么有这个名字呢？
其实曾经有一个基于PowerPC架构的Linux发行版，名为Yellow Dog Linux。
而yum的名字即来源于此，且为其改进版本。
yum是一个强大的包管理工具，常用于 Red Hat 系的 Linux 发行版，如 CentOS、Fedora 和 RHEL。
它简化了安装、更新、删除和管理软件包的过程。
基本其他基于RPM的Linux发行版也使用这个命令。
其他列出了一些常用和不太常用的命令，基本足矣。
安装软件包使用 yum 安装软件包的基本语法是：
$ sudo yum install package_name

例如，要安装 wget 软件包，可以使用以下命令：
$ sudo yum install wget

yum 会自动解决依赖关系，确保所有必需的软件包都被安装。
更新软件包保持系统更新对于安全性和性能非常重要。要更新特定的软件包，使用：
$ sudo yum update package_name

例如，更新 wget：
$ sudo yum update wget

要更新所有已安装的软件包，只需运行：
$ sudo yum update

删除软件包如果需要删除一个软件包，语法如下：
$ sudo yum remove package_name

例如，删除 wget：
$ sudo yum remove wget

yum 将处理指定软件包的删除，并删除不再需要的依赖项。
检查可用更新要检查是否有可用更新而不实际应用它们，使用：
$ yum check-update

此命令会列出所有有可用更新的软件包，帮助您决定哪些需要更新。
列出已安装的软件包要列出系统上所有已安装的软件包，运行：
$ yum list installed

此命令提供了当前已安装的所有软件包的详细列表。
搜索软件包如果不确定软件包的确切名称，可以使用：
$ yum search keyword

例如，搜索与 wget 相关的软件包：
$ yum search wget

此命令会返回与关键字匹配的软件包列表。
显示软件包信息要查看特定软件包的详细信息，使用：
$ yum info package_name

例如，获取 wget 的信息：
$ yum info wget

此命令提供软件包的详细信息，如版本、发布、大小和简短描述。
清理 yum 缓存随着时间推移，yum 的缓存会增长并占用磁盘空间。要清理缓存，使用：
$ sudo yum clean all

此命令会删除缓存数据，释放空间，并确保 yum 获取最新的软件包信息。
管理仓库yum 使用仓库作为软件包的来源。要列出所有配置的仓库，运行：
$ yum repolist

启用特定仓库：
$ sudo yum-config-manager --enable repository_name

禁用特定仓库：
$ sudo yum-config-manager --disable repository_name

高级用法安装特定版本的软件包如果需要安装特定版本的软件包，使用：
$ sudo yum install package_name-version

例如，安装 wget 的 1.20 版本：
$ sudo yum install wget-1.20

降级软件包要将软件包降级到以前的版本，使用：
$ sudo yum downgrade package_name

组安装yum 允许您安装为特定目的而设计的一组软件包。例如，安装开发工具组，使用：
$ sudo yum groupinstall "Development Tools"
]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>yum</tag>
        <tag>linux</tag>
        <tag>software</tag>
        <tag>dangerous</tag>
      </tags>
  </entry>
  <entry>
    <title>解压方法之一 zip</title>
    <url>/2018/03/07/linux-zip-beginner/</url>
    <content><![CDATA[解压方法之一 zip.. _linux-beginner-zip:
:ref:unzip&lt;linux-beginner-unzip&gt; 
.. note::  林花谢了春红，太匆匆。无奈朝来寒雨，晚来风。  李煜《相见欢·林花谢了春红》
Linux zip命令的功能是用于压缩文件，解压命令为unzip。
通过zip命令可以将很多文件打包成.zip格式的压缩包，里面会包含文件的名称、路径、创建时间、上次修改时间、权限等信息，与tar命令相似。
对于类似文本文件而言，压缩比基本可以达到2:1到3:1.
官方的定义为：

zip - package and compress (archive) files

语法zip的参数超级的多，各种设置也是很巧妙，不过常用的就几个，其他的放在后面再说。
$ zip  [-aABcdDeEfFghjklLmoqrRSTuvVwXyz!@$] [--longoption ...]  [-b path] [-n suffixes] [-t date] [-tt date] [zipfile [file ...]]  [-xi list]

参数
-r 或 --recurse-paths ：遍历整个目录 for example:
-j 或 --junk-paths： 仅保存文件名，而不保存路径。默认情况下zip将保存整个路径

参考实例将指定目录及其内全部文件都打包成zip格式压缩包文件：
$ zip -r backuptest.zip /etc  adding: etc/resolv.conf (stored 0%)  adding: etc/fonts/ (stored 0%)  adding: etc/fonts/conf.d/ (stored 0%)  adding: etc/fonts/conf.d/65-0-wqy-zenhei-sharp.conf (deflated 88%)  adding: etc/fonts/conf.d/59-liberation-mono.conf (deflated 57%)  adding: etc/fonts/conf.d/57-paratype-pt-sans.conf (deflated 66%)  adding: etc/fonts/conf.d/59-liberation-sans.conf (deflated 74%)  adding: etc/fonts/conf.d/65-0-ttf-arphic-uming.conf (deflated 87%)  adding: etc/fonts/conf.d/65-1-vlgothic-gothic.conf (deflated 74%)  adding: etc/fonts/conf.d/65-0-lohit-nepali.conf (deflated 57%)  adding: etc/fonts/conf.d/20-unhint-small-dejavu-sans.conf (deflated 43%)  adding: etc/fonts/conf.d/61-urw-d050000l.conf (deflated 71%)  adding: etc/fonts/conf.d/57-dejavu-sans.conf (deflated 77%)  ...

zip还支持通配符的表达，比如将当前工作目录内所有以.jpg为后缀的文件打包：
$ zip -r backuptest.zip *.jpg  adding: test0.jpg (deflated 56%)  adding: test10.jpg (deflated 56%)  adding: test12.jpg (deflated 56%)  adding: test14.jpg (deflated 56%)  adding: test16.jpg (deflated 56%)  adding: test18.jpg (deflated 56%)  adding: test20.jpg (deflated 56%)  adding: test2.jpg (deflated 56%)  adding: test22.jpg (deflated 56%)  adding: test24.jpg (deflated 56%)  adding: test26.jpg (deflated 56%)  adding: test28.jpg (deflated 56%)


仅保存文件名zip默认情况下会保存路径信息，如果加上-j将不保存路径信息，而仅仅保存文件。这个情况可以在希望把同一类文件放在一起时比较有用。
$ zip -j foo foo/*]]></content>
      <categories>
        <category>Linux入门</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>zip</tag>
        <tag>unzip</tag>
        <tag>zipcloak</tag>
        <tag>zipnote</tag>
        <tag>zipsplit</tag>
        <tag>归档压缩命令</tag>
      </tags>
  </entry>
  <entry>
    <title>Mac 平台上 13 款实用的代码编辑器推荐</title>
    <url>/2012/08/06/mac-code-editor/</url>
    <content><![CDATA[Mac 平台上 13 款实用的代码编辑器推荐如今网络上有很多针对 Mac 平台的代码编辑器，因此要找到正确的、最适合你的代码编辑器可能需要一段时间。这里主要整理了 13 款实用的代码编辑器，一些是免费、开源的，也有一些收费的，但你可以免费试用.
EspressoEspresso是一款功能强大的代码编辑工具，拥有专业检查与分类、语法高亮、优雅的导航、即时预览、同步功能等，具有惊人的可扩展能力和速度，支持代码折叠，还能以dom方式呈现。Espresso还整合了CSSEdit 3的功能特性。
TextMateTextMate把苹果OS X操作系统体验带进了编辑器的世界，整合了UNIX内核和苹果GUI两者的优点。TextMate的设计使有经验的开发者和新用户都很受益。
Aptana Studio 3Aptana Studio 3是一个用于Web开发的开源工具。它能够让开发人员使用单一环境来测试Web应用程序。Aptana支持HTML5、CSS3、JavaScript、Ruby、Rails、PHP和Python。它提供了非常多的功能，包括代码辅助编辑器、调试器、部署向导和IDE自定义。
Taco HTMLTaco HTML是Mac里首屈一指的HTML和PHP编辑器。作为一个HTML编辑器，Taco HTML使得用户能够快速创建自己的网站。它是专为Mac OS X设计的，并拥有许多先进功能，包括拼写检查、浏览器即时预览、PHP预览、语法检查等。
Tumult HyperEditTumult HyperEdit是一个轻盈的HTML编辑器，当你在输入时，便可即时查看网页的预览效果。HyperEdit 打破了HTML代码编写的繁琐周期——储存文件、然后在浏览器中载入、观看页面、在浏览器及编辑窗口中切换调试。它实现了撰写、修改与预览的同步进行，加快了整个页面设计的进程。W3C验证会将错误的语法用红色的下划线标记出来。它内嵌了与Safari相同的渲染引擎，因此不仅符合标准而且速度还非常快。
Dreamweaver CS6Adobe Dreamweaver CS6提供了一套直观的可视界面，供你创建和编辑网站。新的流体网格布局专为自适应网格版面创建网页，这个网格版面是跨平台兼容性设计的。在发布前，可以使用“多屏幕预览“来审阅您的设计。
Coda 2Coda 2是Mac版网页编辑器，它整合了终端、文字编辑器、CSS编辑器、内容发布等整个Web开发流程所需工具。新版本的Coda 2增加了诸多新的特性和功能，进行了新的用户界面设计。新增了可实现快速导航的滚动标签栏，整合了CSS、用户函数/变量补全、智能缩进、代码折叠等特性，支持Git版本管理，内置了MySQL编辑器。
SkEditSKEdit编辑器使你更容易创建和维护网站，它拥有所有必要的功能，如代码提示、代码折叠、FTP / SFTP的集成、Subversion的集成，它支持HTML、CSS、PHP、Cold Fusion、Ruby、SQL等编程语言。它包括一个代码库，你可以用最喜爱的脚本语言来编写脚本，并随时跟踪最常用的代码片段。
Firebug
Firebug是最流行和强大的Web开发工具：
实时查看HTML并修改其风格和布局。
最先进的JavaScript调试功能，适合任何浏览器。
准确地监视网络的使用和性能。
扩展Firebug并增加新的功能，使Firebug更强大。
获得你所需要的信息。

BareBones使用磁盘或FTP浏览器来查看和打开本地或远程卷的文件。
在磁盘浏览器、多文件搜索结果窗口、项目窗口上编辑文件。可以在多窗口中编辑单一文件！
创建BBEdit项目组，并在一个单一的窗口编辑相关文件，不用管它们在磁盘上的位置。
可以使用内置的Open from FTP/SFTP Server和Save to FTP/SFTP Server命令在FTP/SFTP服务器上直接创建文件；也可以使用Interarchy、Fetch、Transmit或任何其他支持“BBEdit编辑”的文件传输客户端。
Open File by Name操作可以让你快速访问BBEdit项目（或Xcode项目）中的内容。
Text WranglerTextWrangler是一款全能的文本编辑器。与BBEdit的区别是它有丰富的专业功能集，包括Web创作功能和软件开发工具。
EditRocketEditRocket提供了必要的工具和功能，允许开发者编辑、创建、调试，并且快速、方便地浏览源代码。
Komodo EditKomodo Edit可以在 Windows、Mac 和 Linux 上运行，并支持PHP、Python、Ruby、JavaScript、Perl、TCL、XML、HTML5以及CSS3。另有后台语法检测、颜色匹配、错误捕捉、自动补齐、Fast Open、远程文件编辑、Vi快捷键、shell命令集、宏指令和代码片段等特性。值得一提的是，该IDE为用户提供了丰富的可扩展功能，支持类似firefox的.xpi扩展。
]]></content>
      <categories>
        <category>MacOSX</category>
        <category>Editor</category>
      </categories>
      <tags>
        <tag>Aptana</tag>
        <tag>BareBones</tag>
        <tag>Coda</tag>
        <tag>Dreamweaver</tag>
        <tag>EditRocket</tag>
        <tag>Espresso</tag>
        <tag>fFirebug</tag>
        <tag>Komodo</tag>
        <tag>SkEdit</tag>
        <tag>Taco</tag>
        <tag>TextWrangler</tag>
        <tag>TextMate</tag>
        <tag>Tumult</tag>
        <tag>HyperEdit</tag>
      </tags>
  </entry>
  <entry>
    <title>Mac不能复制拷贝写入文件到移动硬盘,U盘怎么办</title>
    <url>/2015/07/16/mac-copy-to-usb/</url>
    <content><![CDATA[Mac不能复制拷贝写入文件到移动硬盘,U盘怎么办我们先可以查看移动硬盘的分区格式，下图中显示是一块 NTFS 格式的移动硬盘，并且为只读状态。
此时我们在这块 NTFS 格式的移动硬盘上点击右键，发现没有“新建文件夹”选项，
当分区格式为 NTFS 的拷贝文件时，这时可以看到不能操作
虽然 Mac 系统不提供对 NTFS 分区的存储设备的支持，但是我们可以借助一些其它第三方软件来把文件拷贝到硬盘或 U 盘中。这里推荐一款免费的软件名为Mounty11，可以让帮助我们往 NTFS格式的存储设备中拷贝文件。
把上面的软件下载并打开以后，若当前已经插入 NTFS 的存储设备的话，会得到下图的提示。点击 YES 按钮，可以重新挂载存储设备，然后就可以往里面拷贝资料了。
如果挂载成功的话，会自动打开存储设备窗口，这时我们再打开设备简介，可以看到已经支持读和写了。
此时我们尝试在这块 NTFS 格式的移动硬盘上创建一个新文件夹，已经可以成功建立，证明可以往里面拷贝文件数据了。
另外，当我们运行了 Mounty11 软件以后，还可以通过点击屏幕顶部菜单栏中的软件图标，然后点击 re-mount 想要进行写入的磁盘名称即可。
]]></content>
      <categories>
        <category>MacOSX</category>
      </categories>
      <tags>
        <tag>MacOSX</tag>
        <tag>ntfs</tag>
        <tag>mount</tag>
        <tag>mounty</tag>
      </tags>
  </entry>
  <entry>
    <title>Mac 锁屏利器Nearlock</title>
    <url>/2018/02/04/mac-nearlock/</url>
    <content><![CDATA[锁屏利器Nearlock给大家推荐一款Mac的锁屏利器Nearlock。
这个软件的slogan是Lock and unlock your Mac with your iPhone。
不过这个有个硬性条件，就是需要同时拥有Mac和iPhone，Mac可以是MBP、MB、iMac、iWatch等系列产品。
Nearlock使用比较方便，软件通过蓝牙来判断Mac和iPhone的距离，从而通过设置来开启或者锁定Mac，这个对于临时有急事而又来不及锁屏的哥们来说还是很不错的，特别是进入办公室以后，做到座位上，不用任何操作，自动解锁，进入系统，OK，开始干活。
Nearlock有免费版，不过Pro版支持后台运行，喜欢就入手吧。
]]></content>
      <categories>
        <category>MacOSX</category>
      </categories>
      <tags>
        <tag>MacOSX</tag>
        <tag>Nearlock</tag>
        <tag>lock</tag>
      </tags>
  </entry>
  <entry>
    <title>Mac Mounting NFS shares on Mac OS X</title>
    <url>/2013/08/26/mac-nfs/</url>
    <content><![CDATA[Mounting NFS shares on Mac OS X解决MacOS无法挂载NFS，Operation not permitted错误
新装的Openfiler开启nfs之后，用Macbook的图形界面通过
无法连接。
先在服务器上自己挂自己试了一下，没有问题，说明问题可能在Macbook客户端上。在Macbook上打开终端：
# mount -t nfs IP:/ path localpath

#使用保留端口再试一下
# mount -o resvport IP:/path localpath
]]></content>
      <categories>
        <category>MacOSX</category>
      </categories>
      <tags>
        <tag>nfs</tag>
        <tag>mount</tag>
      </tags>
  </entry>
  <entry>
    <title>MacOSX 如何安装hexo</title>
    <url>/2016/09/02/macosx-install-hexo/</url>
    <content><![CDATA[MacOSX 如何安装hexo安装Node.js环境因为Hexo是基于Node.js环境的，所以我们需要安装Node.js.
下载和安装Node.js命令行安装brew install npmwget -qO- https://raw.githubusercontent.com/creationix/nvm/v0.33.2/install.sh | bashnvm install stable

部署且安装Hexo博客安装Hexo
npm install -g hexo-clinpm install hexo-generator-index --savenpm install hexo-generator-archive --savenpm install hexo-generator-category --savenpm install hexo-generator-tag --savenpm install hexo-server --save # server独立出来了，需要单独安装npm install hexo-deployer-git --savenpm install hexo-generator-search --savenpm install hexo-renderer-marked@0.2 --savenpm install hexo-renderer-stylus@0.2 --savenpm install hexo-generator-feed@1 --savenpm install hexo-generator-sitemap@1 --save
这里采用npm方式来部署hexo静态博客。
部署文件夹这里我们可以先建立一个文件夹，用来安装hexo
mkdir hexocd hexo
初始化Hexo
hexo init

生成静态页面
hexo generate

本地预览
hexo server

此时就可以打开浏览器输入http://localhost:4000来预览了。
]]></content>
      <categories>
        <category>MacOSX</category>
        <category>Git</category>
      </categories>
      <tags>
        <tag>MacOSX</tag>
        <tag>git</tag>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>MacOSX 上 安装及使用homebrew</title>
    <url>/2013/02/06/macosx-install-homebrew/</url>
    <content><![CDATA[MacOSX 上 安装及使用homebrewHomebrew的安装与使用Mac OS X是基于Unix的操作系统，可以安装大部分为Unix/Linux开发的软件。然而，如果只是以使用为目的，对每个软件都进行手工编译不是很方便，也不利于管理已安装的软件，于是出现了类似于Linux中APT、Yum等类似的软件包管理系统，其中最著名的有MacPorts、Fink、Homebrew等。
我曾经是MacPorts的使用者，但了解Homebrew之后，立即“弃暗投明”了。其实MacPorts也是一个很不错的解决方案，除了一个实在让我头疼的特性。MacPorts有个原则，对于软件包之间的依赖，都在MacPorts内部解决（/opt/local），无论系统本身是否包含了需要的库，都不会加以利用。这使得MacPorts过分的庞大臃肿，导致系统出现大量软件包的冗余，占用不小的磁盘空间，同时稍大型一点的软件编译时间都会难以忍受。
而Homebrew的原则恰恰相反，它尽可能地利用系统自带的各种库，使得软件包的编译时间大为缩短；同时由于几乎不会造成冗余，软件包的管理也清晰、灵活了许多。Homebrew的另一个特点是使用Ruby定义软件包安装配置（叫做formula），定制非常简单。
至于Fink，由于并未安装使用过，不加讨论。（从互联网上的消息看，Fink由于维护人手的问题，软件包的更新不是很及时。）于我而言，Homebrew已经足够完善，除非发现重大的问题或者出现新的具有突破性的竞争对手，否则我没兴趣折腾别的软件包管理系统了。
下面说说Homebrew的安装与使用。
Homebrew的安装首先确保你的系统满足如下要求：

 基于Intel CPU


 操作系统为Mac OS X 10.5 Leopard或更高版本


 已安装版本管理工具Git（Mac OS X 10.7 Lion已经预安装）


 已安装Xcode开发工具1


 已安装Java Developer Update2



注1：Xcode 4.3中，命令行编译工具是可选安装，需要在Preferences &gt; Downloads中激活。注2：可选，Homebrew本身不依赖于Java，只有部分软件包的安装需要Java支持。
 Homebrew的安装非常简单，在终端程序中输入以下命令即可。
$ ruby -e “$(curl -fsSL https://raw.github.com/mxcl/homebrew/go)”

由于Homebrew的安装地址可能变化，请到官方网站查看最新的安装方法。安装过程需要输入root口令。
Homebrew的使用Homebrew的可执行命令是brew，其基本使用方法如下（以wget为例）。
# 查找软件包$ brew search wget# 安装软件包$ brew install wget# 列出已安装的软件包$ brew list# 删除软件包$ brew remove wget# 查看软件包信息$ brew info wget# 列出软件包的依赖关系$ brew deps wget# 更新brew$ brew update# 列出过时的软件包（已安装但不是最新版本）$ brew outdated# 更新过时的软件包（全部或指定）$ brew upgrade 或 brew upgrade wget# 定制自己的软件包

如果自己需要的软件包并不能在Homebrew中找到，怎么办呢，毕竟Homebrew是一个新生项目，不可能满足所有人的需求。当然，我们可以自行编译安装，但手工安装的软件包游离于Homebrew之外，管理起来不是很方便。
前文说过，Homebrew使用Ruby实现的软件包配置非常方便，下面简单谈一谈软件包的定制（假定软件包名称是bar，来自foo站点）。

 首先找到待安装软件的源码下载地址



http://foo.com/bar-1.0.tgz2.      建立自己的formulabrew create http://foo.com/bar-1.0.tgz3.      编辑formula，上一步建立成功后，Homebrew会自动打开新建的formula进行编辑，也可用如下命令打开formula进行编辑。brew edit barHomebrew自动建立的formula已经包含了基本的configure和make install命令，对于大部分软件，不需要进行修改，退出编辑即可。4.      输入以下命令安装自定义的软件包brew install bar关于Homebrew的其它功能，比如将自定义软件包提交到官方发布等，请参考Homebrew项目的主页及其Man Page。你将发现Homebrew不仅是“家酿”，更是“佳酿”。
refer from : http://linfan.info/blog/2012/02/25/homebrew-installation-and-usage/
]]></content>
      <categories>
        <category>MacOSX</category>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>ruby</tag>
        <tag>macosx</tag>
        <tag>homebrew</tag>
        <tag>fink</tag>
        <tag>macports</tag>
      </tags>
  </entry>
  <entry>
    <title>MacOS系统MacPort的按照与使用</title>
    <url>/2012/09/19/macosx-install-macports/</url>
    <content><![CDATA[MacOS系统中MacPorts安装和使用Mac系统中除了使用dmg、pkg的格式来安装软件，比较方便的还有MacPorts和brew软件，这两个软件类似Linux下面的yum和apt，可以帮助快速地解决依赖，按照软件。
这里说一下MacPorts的按照与使用，详细信息可以参考官网MacPorts
安装MacPorts
下载：

官方网站: http://www.macports.org/install.php
Mac Port的说明文档: http://guide.macports.org
使用pkg二进制包直接安装，找到与本系统版本一直的pkg文件下载，双击安装即可。


加入环境


安装结束后还暂时不能使用，需要将/opt/local/bin和/opt/local/sbin添加到$PATH搜索路径中，编辑/etc/profile文件中，加上
export PATH=/opt/local/bin:$PATHexport PATH=/opt/local/sbin:$PATH


Mac Port中第三方软件下载包存放的默认路径是：/opt/local/var/macports/distfiles/

使用Mac Port前应该首先更新Port的index


MacPorts使用# 更新ports tree和MacPorts版本，强烈推荐第一次运行的时候使用-v参数，显示详细的更新过程。$ sudo port - v selfupdate# 查看Mac Port中当前可用的软件包及其版本$ port list# 搜索索引中的软件$ port search name# 查看包详细信息$ port info name# 查看包详细信赖信息$ port deps name# 查看安装时允许客户定制的参数$ port variants name# 安装新软件$ sudo port install name# 安装完毕之后，清除安装时产生的临时文件$ sudo port clean --all name# 卸载软件$ sudo port uninstall name# 查看有更新的软件以及版本$ port outdated# 升级可以更新的软件$ sudo port upgrade outdated

]]></content>
      <categories>
        <category>MacOSX</category>
      </categories>
      <tags>
        <tag>macosx</tag>
        <tag>macport</tag>
      </tags>
  </entry>
  <entry>
    <title>MacOSX dyld - Library not loaded /usr/local/gfortran/lib/libgfortran.3.dylib Reason image not found</title>
    <url>/2019/09/02/macosx-linked-libgfortran/</url>
    <content><![CDATA[MacOSX dyld -  Library not loaded - /usr/local/gfortran/lib/libgfortran.3.dylib Reason: image not found这个问题发生在我尝试在MacOSX上安装aips软件的时候。
已经确认有libgfortran进行了安装，唯一的解释就是没有把该lib路径添加到系统路径。
下面的解决方法比较简单粗暴，直接将该lib拷贝到系统路径即可。
首先定位lib所在位置：
$ locate libgfortran.3.dylib

此时可能会有很多选项，为了与aips匹配，我们选择这个路径，这个版本我们确认是可以被使用的。
/Users/leo/aips31DEC18/31DEC18/MACINT/LIBR/INTELCMP/libgfortran.3.dylib

拷贝该文件到系统路径，再次尝试，完美解决。
$ ln /usr/local/Cellar/gcc@5/5.5.0_3/lib/gcc/5/libgfortran.3.dylib /usr/local/lib/libgfortran.3.dylib
]]></content>
      <categories>
        <category>MacOSX</category>
      </categories>
      <tags>
        <tag>MacOSX</tag>
        <tag>dyld</tag>
        <tag>libgfortran</tag>
      </tags>
  </entry>
  <entry>
    <title>MacOSX svnadmin无法使用的问题</title>
    <url>/2019/09/02/macosx-svnadmin/</url>
    <content><![CDATA[MacOSX svnadmin无法使用的问题MacOSX是默认自带安装svn的，不过路径不在系统路径，
将   /Library/Developer/CommandLineTools/usr/bin/ 加入系统路径即可解决
export PATH=$PATH:/Library/Developer/CommandLineTools/usr/bin/
]]></content>
      <categories>
        <category>MacOSX</category>
        <category>SVN</category>
      </categories>
      <tags>
        <tag>MacOSX</tag>
        <tag>svn</tag>
      </tags>
  </entry>
  <entry>
    <title>MacOSX 集锦</title>
    <url>/2013/09/19/macosx-tips/</url>
    <content><![CDATA[MacOSX 集锦快捷键
⌘ + Q = Quit
⌘ + W = Close window
⌘ + O = Open a file in your application
⌘ + P = Print
⌘ + C = Copy
⌘ + V = Paste
⌘ + X = Cut
⌘ + S = Save
⌘ + Z = Undo
⌘ + A = Select All
⌘ + Y or Space = Quicklook
⌘ + Tab = Cycle through windows
⌘ + ⇧+ 3 = Take fullscreen picture
⌘ + ⇧ + 4 = Take selected area screenshot
⌘ + ⇧ + 4 + Space = Take screenshot of window or menu
⌥ + ⌘ + Escape = Bring up Force Quit window
⌘ + Space = Spotlight search
⌘ +``` (back tick) = Cycle through applications windows
⌘ + . = Cancel operation
⌘ + ⇧ + ? = Open help
⌘ + I = Get Info
⌘ + [ = Go backwards in history in Finder
⌘ + ] = Go forwards in history in Finder
⌘ + Up Arrow = Go to previous folder in hierarchy
⌘ + Down Arrow = Open folder of file in Finder
⌘ + ⌥ + T = Show hide Finder’s toolbar
⌘ + Delete = Move item to Trash
⌘ + ⇧ + Delete = Empty Trash
⌘ + E = Eject disk
⌘ + F = Find
⌘ + G = Next result in Find option
⌘ + H = Hide application
⌘ + M = Minimize
⌘ + N = New window
⌘ + ⌥ + W = Close all windows
⌘ + ⇧ + Z = Redo
⌘ + ⇧ + H = Go to Home folder
⌘ + ⇧ + D = Go to Desktop
⌘ + ⇧ + C = Go to Computer
⌘ + ⇧ + K = Go to Network
⌘ + ⇧ + I = Go to iDisk
⌘ + ⇧ + A = Go to Application
⌘ + ⇧ + U = Go to Utilities
⌘ + ⇧ + G = Go to folder
⇧ + ⌘ + Q = Log out
⇧ + ⌘ + ⌥ + Q = Log out immediately.
⌘ + D = Duplicate in Finder
⌘ + ⌥ + 8 = Turn on Voice Over
⌘ + ⌥ + + = Zoom in (if turned on)
⌘ + ⌥ + – =Zoom Out
⌘ + ⌥ + D = Show/Hide Dock
^ + Eject = Show shutdown dialog
^ + ⌘ + Eject = Close all and restart
⌥ + ⌘ + Eject = Sleep
⌘ + Shift + F = Find file by name
⌘ + R = Refresh widget

]]></content>
      <categories>
        <category>MacOSX</category>
      </categories>
      <tags>
        <tag>macosx</tag>
        <tag>shortcut</tag>
      </tags>
  </entry>
  <entry>
    <title>MacOSX的好工具</title>
    <url>/2017/11/17/macosx-tools/</url>
    <content><![CDATA[MacOSX 好工具软件相关HomebrewHomebrew号称macOS缺失的软件包管理器。
安装方法为：
/usr/bin/ruby -e "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)"

详情见 Brew。
MacPortsMacPorts是开源社区发起的一项方便开发者在Shell下进行软件的编译、安装和升级等操作的开源项目，旨在方便Mac环境下的开发者。更多的关于MacPorts的信息，你可以登陆官网查看MacPorts。
软件卸载通过drag，drop来卸载软件，与安装一样简单，参考软件 Zapper。

AppZapper. Simply drag one or more apps onto AppZapper.  Then, watch as it finds the extra files and lets you delete them with on click.

终端工具终端除了系统自带的terminal比较好用，还有一个iTerm基本属于神器，推荐。
go2shell用过Linux基本知道邮件就可以打开终端，这个在MacOSX中可以通过go2shell来弥补。
下载网址  https://zipzapmac.com/Go2Shell，下载后安装即可，可以通过下面的命令来打开配置窗口。
$ open -a Go2Shell --args config

文档工具Mac下最好的Latex编辑器首选MacTex，当然TexShop也特别好，关于详细的讨论参考 https://discussions.apple.com/message/18653515#18653515
搜索相关Alfred 3 for Mac极其强悍的效率工具，建议使用。
支持文件搜索、网页收拾、收藏夹搜索、计算器、联系人搜索、剪贴板搜索等。
Alfred is an award-winning app for Mac OS X which boosts your efficiency with hotkeys, keywords, text expansion and more. Search your Mac and the web, and be more productive with custom actions to control your Mac.
]]></content>
      <categories>
        <category>MacOSX</category>
        <category>brew</category>
        <category>Latex</category>
      </categories>
      <tags>
        <tag>latex</tag>
        <tag>macosx</tag>
        <tag>macports</tag>
        <tag>brew</tag>
        <tag>port</tag>
        <tag>appzapper</tag>
      </tags>
  </entry>
  <entry>
    <title>MacOSX import的定义</title>
    <url>/2013/01/06/macosx-xcode-import/</url>
    <content><![CDATA[import is a feature provided by the GCC compiler, which is what Xcode uses when you’re compiling Objective- C, C, and C++ programs. #import guarantees that a header file will be included only once, no matter how many times the #import directive is actually seen for that file.
NOTE

In C, programmers typically use a scheme based on the #ifdef directive to avoid the situation where one file includes a second file, which then, recursively, includes the first.

In Objective- C, programmers use #import to accomplish the same thing.
So import equals to ifndef plus include.
]]></content>
      <categories>
        <category>MacOSX</category>
      </categories>
      <tags>
        <tag>xcode</tag>
        <tag>macosx</tag>
        <tag>import</tag>
        <tag>include</tag>
      </tags>
  </entry>
  <entry>
    <title>Matlab帮助信息</title>
    <url>/2010/01/13/matlab-help/</url>
    <content><![CDATA[帮助信息：
可以输入help来查看分类信息，或者help topic来查看每个topic的，或者使用lookfor来搜索，这个比较宽松，而help命令只能搜索出那些关键词完全匹配的结果。
演示系统：
我们可以输入demo来查看相应的演示模块。
]]></content>
      <categories>
        <category>Matlab</category>
      </categories>
      <tags>
        <tag>matlab</tag>
        <tag>demo</tag>
        <tag>help</tag>
        <tag>lookfor</tag>
      </tags>
  </entry>
  <entry>
    <title>Microsoft Visual Studio Code技巧</title>
    <url>/2017/03/23/microsoft-visual-studio-code/</url>
    <content><![CDATA[Visual Studio CodeExtensions
C/C++
Chinese ( Simplified) Language Pack for Visual Studio Code
Doxygen Documentation Generator
Markdown All in One
Python
TODO Highlight
Vim
Wakatime
YAML Support by Red Hat
vscode-icons
autoconf
LaTex Workshop

添加 Visual Studio Code 命令行到 Mac OS X 环境变量在环境变量中加入下面一行，或者bashrc亦或者zsh，然后就可以在终端输入code来启动了。
code () { VSCODE_CWD="$PWD" open -n -b "com.microsoft.VSCode" --args $* ;}

增加xelatex用于编译中文文章只需要在tex文件的最前面，加上% !TEX program = xelatex，在编译的时候就会直接调用xelatex。
% !TEX program = xelatex\documentclass{article}\author{Hello}\title{Test of xelatex in VSCode}\begin{document}\maketitle你好，世界！\end{document}

]]></content>
      <categories>
        <category>Microsoft</category>
      </categories>
      <tags>
        <tag>editor</tag>
        <tag>Visual Studio Code</tag>
      </tags>
  </entry>
  <entry>
    <title>美丽散文</title>
    <url>/2011/02/11/one-essay/</url>
    <content><![CDATA[
一旦当我懂得了珍惜的时候 本该珍惜的东西早已悄悄地从这个世界溜走了 - 季羡林 《赋得永久的悔》

能够百分之六十为他人着想 百分之四十为自己着想 他就是一个及格的好人 - 季羡林 《季羡林读书与做人》
]]></content>
      <categories>
        <category>读书</category>
        <category>感悟</category>
      </categories>
      <tags>
        <tag>坚持</tag>
        <tag>成功</tag>
        <tag>一句话</tag>
        <tag>一首诗</tag>
        <tag>一段情</tag>
        <tag>一首歌</tag>
      </tags>
  </entry>
  <entry>
    <title>美丽诗句</title>
    <url>/2011/02/11/one-poetry/</url>
    <content><![CDATA[
逢人不说人间事  便是人间无事人 - 杜荀鹤《赠质上人》

黑夜给了我黑色的眼睛 我却用它来寻找光明 - 顾城《一代人》

]]></content>
      <categories>
        <category>读书</category>
        <category>感悟</category>
      </categories>
      <tags>
        <tag>坚持</tag>
        <tag>成功</tag>
        <tag>一句话</tag>
        <tag>一首诗</tag>
        <tag>一段情</tag>
        <tag>一首歌</tag>
      </tags>
  </entry>
  <entry>
    <title>优美歌曲</title>
    <url>/2011/02/11/one-song/</url>
    <content><![CDATA[
我曾经跨过山和大海  也穿过人山人海 我曾经拥有着的一切  转眼都飘散如烟 - 朴树《平凡之路》

]]></content>
      <categories>
        <category>读书</category>
        <category>感悟</category>
      </categories>
      <tags>
        <tag>坚持</tag>
        <tag>成功</tag>
        <tag>一句话</tag>
        <tag>一首诗</tag>
        <tag>一段情</tag>
        <tag>一首歌</tag>
      </tags>
  </entry>
  <entry>
    <title>persist</title>
    <url>/2011/02/11/one-word-insist/</url>
    <content><![CDATA[
不是成功的路太远而是能坚持的人不多

这个世界上总会有人陪你走一段只要你坚持下去

当你对这个世界敞开怀抱的时候
这个世界才会对你敞开怀抱
当你拒绝这个世界
你也必然会被这个世界所拒绝。

最可怕的敌人
就是没有坚强的信念

罗曼·罗兰


意志坚强的人
能把世界放在手中 
像泥块一样任意揉捏

歌德

]]></content>
      <categories>
        <category>读书</category>
        <category>感悟</category>
      </categories>
      <tags>
        <tag>坚持</tag>
        <tag>成功</tag>
        <tag>一句话</tag>
        <tag>一首诗</tag>
        <tag>一段情</tag>
        <tag>一首歌</tag>
      </tags>
  </entry>
  <entry>
    <title>Distribution models of antennas in radio astronomy Efficiency comparison of the golden spiral interferometry</title>
    <url>/2024/12/24/paper-Distribution%20models%20of%20antennas%20in%20radio%20astronomy%20Efficiency%20comparison%20of%20the%20golden%20spiral%20interferometry/</url>
    <content><![CDATA[Distribution models of antennas in radio astronomy: Efficiency comparison of the golden spiral interferometry
Elio Quiroga Rodríguez.

射电天文学干涉测量中有不同的天线振兴。文章阐述了包括黄金螺旋、网格、随机排列以及类似于甚大阵列的“Y”形配置。
每种配置均模拟了一百个天线，并对所得的UV覆盖范围和图像质量进行了分析。
结果表明，黄金螺旋提供了更均匀的UV覆盖，没有明显的间隙，通过减少旁瓣和伪影提高了图像质量。
相比之下，网格在UV覆盖中呈现周期性结构，由于间隙和伪影可能会降低图像质量。
随机排列提供了更自然的覆盖，但在分辨率和旁瓣控制方面效率较低。
“Y”形配置在其臂上实现了高分辨率，但在某些方向上缺乏完整覆盖，这可能会对这些角度的图像质量产生负面影响。
黄金螺旋的自相似性允许有效捕获观测源中的大结构和小结构，最大限度地获取空间信息。
结论为，对于分辨率和灵敏度至关重要的应用，黄金螺旋是最佳配置，其次是“Y”形配置，网格是最不合适的。
 黄金螺旋在几个关键方面已被证明是优越的，包括UV覆盖、图像质量和捕获空间信息的效率。其分布最大限度地减少了基线长度的冗余，并在观测空间尺度之间提供了平滑过渡，使其对大结构和小结构都有利。相比之下，“Y”形配置因其在臂上提供高分辨率的能力而脱颖而出，但其在垂直于臂的方向上缺乏覆盖限制了其在某些情况下的应用。另一方面，随机排列比网格提供更均匀的覆盖，但在旁瓣控制方面没有达到相同水平，并且在分辨率方面可能效率较低。最后，网格是最不理想的配置，因为其周期性结构存在固有问题，导致所得图像中存在明显的间隙和伪影。
具体的描述如下：
黄金螺旋构型UV覆盖特性：黄金螺旋构型提供了更为均匀的UV覆盖，不存在显著间隙。这一特性归因于其对数性质，使得在UV平面上的采样点分布更加合理，能够有效减少因覆盖不均匀而产生的成像问题。例如，在模拟图像中可以观察到其成像特性更为平滑，相较于其他构型，对观测源的空间信息采集更为全面且均衡。
对成像质量的影响：通过减少旁瓣和伪影，黄金螺旋构型显著提升了成像质量。均匀的UV覆盖确保了在傅里叶变换过程中，不同空间频率成分能够得到更准确的采样和恢复，从而在最终图像中呈现出更清晰、更真实的天体结构。在与其他构型对比的模拟图像中，该构型所生成的图像在细节呈现和整体清晰度上表现出色，伪影和旁瓣干扰明显减少。 
 空间尺度敏感性：其自相似性使得望远镜能够在多个尺度上保持良好的覆盖，对观测对象中的大尺度和小尺度结构均具有较高的敏感性。这意味着无论是大规模的星系结构还是小范围的恒星形成区域，黄金螺旋构型都能够有效地捕捉到相关信息，从而提供更为丰富的天体物理细节。在对不同类型天体的观测模拟中，该构型能够更全面地展现天体的多尺度特征，从宏观结构到微观细节都能清晰分辨。 
网格构型 UV覆盖周期性结构：正方形网格构型在UV覆盖中呈现出明显的周期性结构。这种周期性导致在图像中容易出现旁瓣，周期性的间隙还会引入显著的伪影，从而严重影响成像质量。例如，在UV覆盖图中可以清晰看到规则的网格图案，这使得在图像重建过程中，某些空间频率成分被过度强调或缺失，进而产生伪影和旁瓣效应。 
 对成像的负面影响：由于上述周期性结构带来的问题，网格构型生成的图像整体质量下降。旁瓣会掩盖天体的真实信号，使图像中的微弱结构难以被检测到；伪影则会误导对天体形态和结构的判断。在对天体细节要求较高的观测中，网格构型的这种局限性表现得尤为明显，导致其在四种构型中成像效果最差。 
随机构型 覆盖特性：随机排列构型提供了相对自然的覆盖，但这种随机性也带来了一些问题。虽然它在一定程度上避免了像网格构型那样的周期性结构，但由于缺乏系统性，其覆盖的均匀性仍不如黄金螺旋构型。在UV覆盖图中，随机构型的采样点分布较为分散，没有明显的规律，这可能导致在某些区域的覆盖不足或过度，从而影响成像效果。 
 分辨率和旁瓣控制效率：随机构型在分辨率和旁瓣控制方面的效率较低。由于天线位置的随机性，其形成的基线组合不够优化，使得在傅里叶变换过程中对空间频率的采样不够精确，进而影响了图像的分辨率。同时，随机的基线分布也难以有效抑制旁瓣的产生，导致图像中旁瓣较多，降低了图像的对比度和清晰度，与布恩的观点存在一定矛盾。 
“Y”形构型 臂上的高分辨率：“Y”形构型在其臂上能够实现高分辨率成像，这得益于其长基线的设计。长基线使得在臂方向上对空间频率的采样更为精细，能够捕捉到更细微的结构信息。在对具有明显线性结构的天体（如星系旋臂、射电喷流等）进行观测时，“Y”形构型在臂上的高分辨率优势得以充分体现，能够清晰地呈现出这些结构的细节。
 覆盖稀疏问题：然而，“Y”形构型在垂直于臂的方向上覆盖较为稀疏。这种稀疏性可能导致在这些方向上的空间信息采集不足，从而在图像中产生覆盖不完整的区域，容易出现潜在的成像伪影。在对整体结构较为复杂、不具有明显线性特征的天体进行观测时，“Y”形构型在某些角度的成像质量可能会受到影响，限制了其在更广泛观测场景中的应用。 通过对不同构型在UV覆盖、成像质量、分辨率以及空间尺度敏感性等方面的详细描述和对比，可以清晰地呈现出各种构型的优缺点，为后续关于阵列配置优化及其对干涉成像影响的讨论提供有力依据。
]]></content>
      <categories>
        <category>READING</category>
      </categories>
      <tags>
        <tag>imaging</tag>
        <tag>UV coverage</tag>
        <tag>UV覆盖</tag>
        <tag>Synthetic</tag>
        <tag>spiral</tag>
      </tags>
  </entry>
  <entry>
    <title>天文相关会议[已结束]</title>
    <url>/2018/10/30/past-astronomy-meetings/</url>
    <content><![CDATA[天文相关会议【已结束】搜集系列相关会议，供大家参考。更好阅读体验参考原文天文会议汇总。
欢迎大家补充、修改PR、fork、star或clone，一般一月更新一次，谢谢。
原始文件请参考 天文会议汇总。
Forthcoming即将召开的会议参考 天文会议汇总
Past Events


Begin
End
Title
Location
Website



2018-07-24
2018-07-27
中国科学数据大会 （2018）– 科学数据与人工智能
黑龙江省黑河
http://dc2018.codata.cn/


2018-08-14
2018-08-17
中国天文学会第七届青年天文论坛
新疆乌鲁木齐
http://yaf2018.csp.escience.cn/dct/page/1


2018-09-03
2018-09-07
12th DiFX Users and Developers Meeting
Bad Kötzting/Wettzell, Germany
http://www.fs.wettzell.de/veranstaltungen/vlbi/difx2018/difx2018.html


2018-09-14
2018-09-17
空间超长波天文学术研讨会
贵州省平塘县天文小镇
http://tianlai.bao.ac.cn/long_wave.htm


2018-09-17
2018-09-21
21cm宇宙学与天籁合作组会议
贵州省平塘县天文小镇
http://tianlai2018.csp.escience.cn/dct/page/1


2018-09-25
2018-09-29
CASPER Workshop 2018
贵阳
http://casper2018.csp.escience.cn/dct/page/1


02 October 2018
04 October 2018
GGOS Days 2018
Tsukuba, Japan
http://176.28.21.212/en/meetings/2018/ggos-days/general


08 October 2018
11 October 2018
14th EVN Symposium and Users’ Meeting
Granada, Spain
http://evnsymp2018.iaa.es/


09 October 2018
12 October 2018
GRACE/GRACE-FO Science Team Meeting 2018
Potsdam, Germany
https://www.gstm-2018.eu/


09 October 2018
12 October 2018
SIRGAS 2018 Symposium: Geocentric Reference System for the Americas
Aguascalientes, Mexico
http://geoweb2.inegi.org.mx/sirgas2018/html/en/index.html


2018-10-21
2018-11-1
中法2018年“实测天体物理”暑期学校
云南大学
http://www.swifar.ynu.edu.cn/info/1062/1393.htm


2018-10-22
2018-10-26
Global Radio Scintillometry Astrophysics 2018
上海交通大学
https://scintillometry-2018.github.io/


2018-10-22
2018-10-28
The BRICS Association of Gravity Astrophysics and Cosmology
Durban, South Africa
https://acru.ukzn.ac.za/~brics-acg/


22 October 2018
23 October 2018
Joint meeting of the ESA Topical Teams: ACES &amp; General Relativity and ACES &amp; Geodesy, clocks and time transfer
Munich, Germany
https://www.bgu.tum.de/fesg/aces/


23 October 2018
25 October 2018
The 10th Multi-Global Navigation Satellite Systems Asia Conference
Melbourne, Australia
https://2018.mgaconference.com.au/


2018-10-24
2018-10-27
中科院计算机网络信息中心2018年用户大会暨技术交流会
中国西安
http://cnic2018.cnic.cn/dct/page/1


2018-10-27
2018-10-31
中国天文学会2018年学术年会
云南昆明
http://2018casmeeting.csp.escience.cn/dct/page/1


29 October 2018
02 November 2018
IGS 2018 Workshop: Multi-GNSS Through Global Collaboration
Wuhan, China
http://igsworkshop2018.gnsswhu.cn/


2018-10-31
2018-11-01
中国天文学会第十四次全国会员代表大会
云南昆明
http://astronomy.pmo.cas.cn/qt/tzgg/201808/t20180824_423917.html


2018-11-02
2018-11-05
Sino-French ‘LIA-ORIGINS’ Workshop - From First Epochs of Matter and Galaxy Formation to Extraterrestrial Life
云南昆明
http://2018lia.csp.escience.cn/dct/page/1


03 November 2018
03 November 2018
ILRS Analysis Standing Committee Meeting
Canberra, Australia



04 November 2018
06 November 2018
International Workshop on GNSS Ionosphere (IWGI2018)
Shanghai, China
http://202.127.29.4/geodesy/iwgi2018/


04 November 2018
09 November 2018
13th Meeting of the International Committee on Global Navigation Satellite Systems (ICG)
Xi’an, China
http://icg13.beidou.gov.cn/


05 November 2018
08 November 2018
International Data Week 2018: The Digital Frontiers of Global Science
Gaborone, Botswana
http://internationaldataweek.org/


05 November 2018
09 November 2018
21st International Workshop on Laser Ranging
Canberra, Australia
http://www.iwlr2018.serc.org.au/


09 November 2018
10 November 2018
31st CODATA General Assembly
Gaborone, Botswana
http://www.codata.org/events/general-assembly/general-assembly-2018


09 November 2018
10 November 2018
3rd Meeting of the Asia-Oceania VLBI Group for Geodesy and Astrometry (AOV)
Canberra, Australia
http://auscope.phys.utas.edu.au/aov/meetings/aov2018/3rdaovgm.html


12 November 2018
15 November 2018
7th International VLBI Technology Workshop
Krabi, Thailand
http://www.narit.or.th/en/index.php/ivtw2018


2018-11-12
2018-11-16
The life and times of the Milky Way - The symbiosis between Gaia and ground-based spectroscopic surveys
上海
http://gaia2018.csp.escience.cn/dct/page/1


19 November 2018
21 November 2018
First United Nations World Geospatial Information Congress
Deqing, Zhejiang Province, China
http://ggim.un.org/meetings/2018-1st_Congress_Deqing


2018-11-14
2018-11-17
第一届空间地球科学学术研讨会
海南三亚
http://sess2018.csp.escience.cn/dct/page/1


2018-11-21
2018-11-25
中国虚拟天文台与天文信息学2018年学术年会
江西景德镇
http://www.china-vo.org/events/cvo2018/index.html


2018-11-22
2018-11-23
2018中国SKA科学大会
上海市
http://skachina2018.csp.escience.cn/dct/page/1


2018-12-03
2018-12-04
2018年度北京大学科维理天体物理论坛 - 中国未来地面天文设备展望
北京大学
http://kiaa.pku.edu.cn/astroforum18/


2018-12-10
2018-12-13
IEEE BigData 2018
Seattle, WA, USA
http://cci.drexel.edu/bigdata/bigdata2018/index.html


08 October 2018
10 October 2018
9th OPTICON Gaia Science Alerts workshop
Vipava, Slovenia
https://www.ast.cam.ac.uk/ioa/wikis/gsawgwiki/index.php/Workshop2018:main


10 December 2018
14 December 2018
AGU 2018 Fall Meeting
Washington, D.C., USA
https://fallmeeting.agu.org/2018/


28 January 2019
31 January 2019
ION Precise Time and Time Interval Meeting (PTTI)
Reston, VA, USA🇺🇸
https://www.ion.org/ptti/index.cfm


29 January 2019
30 January 2019
Second Asia SKA Initiative On Neutron Star (ASIONS) meeting
Kantary Hills, Chiang Mai, Thailand
https://indico.narit.or.th/event/96/


12 February 2019
15 February 2019
NZ SKA Forum 2019
Auckland University of Technology (AUT), New Zealand
https://irasr.aut.ac.nz/news-And-events2/news-And-events/nz-ska-forum-2019


14 March 2019
16 March 2019
VLBI Training School
Las Palmas de Gran, Spain🇪🇸
http://www.oan.es/evga2019/index.shtml


17 March 2019
19 March 2019
24th Meeting of the European VLBI group for Geodesy and Astrometry(EVGA)
Las Palmas de Gran, Spain🇪🇸
http://www.oan.es/evga2019/index.shtml


20 March 2019

18th IVS Analysis Workshop
Las Palmas de Gran, Spain🇪🇸
http://www.oan.es/evga2019/index.shtml


25 March 2019
29 March 2019
2019 Santa Barbara Gaia Sprint
Santa Barbara, CA, USA🇺🇸
http://gaia.lol/2019SB.html


2019-04-01
2019-04-03
首届东陆天体物理论坛-大规模巡天时代：近场宇宙学和时域天文
云南昆明🇨🇳
http://www.mephisto.ynu.edu.cn/intro_Donglu.html


April 2019

IGS 2019 Analysis Workshop
Potsdam, Germany🇩🇪
TBA


3 April 2019
5 April 2019
SKA History Meeting
Jodrell Bank, UK🇬🇧
https://indico.skatelescope.org/event/518/


07 April 2019
12 April 2019
EGU General Assembly 2019
Vienna, Austria🇦🇹
http://www.egu2019.eu/


08 April 2019
12 April 2019
ESLAB #53: The Gaia Universe
Noordwijk, The Netherlands🇳🇱
https://www.cosmos.esa.int/web/the-gaia-universe/


08 April 2019
12 April 2019
SKA General Science Meeting and Key Science Workshop 2019 “New Science enabled by New Technologies in the SKA Era”
Alderley Park in Alderley Edge (Mon, Tue, Wed), and the new SKA Headquarters (Thu, Fri) at Jodrell Bank🇬🇧
https://indico.skatelescope.org/event/467/


09 April 2019
12 April 2019
European Navigation Conference 2019 (ENC 2019)
Warsaw, Poland🇵🇱
http://enc2019.eu/


15 April 2019
17 April 2019
Eating VLBI workshop 2019 “East Asia to Italy: Nearly Global VLBI”
Bologna,CNR Research area,Italy🇮🇹
https://sites.google.com/a/inaf.it/eating-vlbi-workshop-2019/home


2019-04-18
2019-04-22
2019年射电天文前沿与技术研讨会
贵州平塘🇨🇳
http://crat2019.csp.escience.cn/dct/page/1


22 April 2019
26 April 2019
FIG Working Week 2019
Hanoi, Vietnam🇻🇳
http://www.fig.net/fig2019/


01 May 2019
31 May 2019
24th EVGA Working Meeting &amp; 20th IVS Analysis Workshop [exact dates TBD]
Las Palmas de Gran Canaria, Spain🇪🇸
TBA


13 May 2019
17 May 2019
ESA Living Planet Symposium
Milan, Italy🇮🇹
https://lps19.esa.int/QuickEventWebsitePortal/living-planet-symposium-2019/website


05 May 2019
09 May 2019
Tenth IVS Technical Operations Workshop
Westford, MA, USA🇺🇸
https://www.haystack.mit.edu/workshop/TOW2019/Index.html


22 May 2019
24 May 2019
EUREF 2019 Symposium
Tallinn, Estonia🇪🇪
TBA


29 May 2019
31 May 2019
East Asia SKA Science Workshop2019
Shanghai, China🇨🇳
http://eassw2019.csp.escience.cn/dct/page/1


2019-06-02
2019-06-05
2019年VLBI科学技术及应用研讨会
西安市临潼区🇨🇳
http://vlbi2019.csp.escience.cn/dct/page/1


10 June 2019
14 June 2019
Zooming in on Star Formation
Nafplio, Greece🇬🇷
https://indico.nbi.ku.dk/event/1055/


2019-06-10
2019-06-21
The Xth International Pulsar Timing Array (IPTA) workshop
Pune, India🇮🇳
https://conf.ncra.tifr.res.in/event/2/


2019-06-11
2019-06-13
110米口径全向可动射电望远镜前沿科学与技术研讨会
新疆乌鲁木齐🇨🇳
http://973-2019.csp.escience.cn/dct/page/1


12 June 2019
14 June 2019
PASC19
ETH Zurich, Switzerland🇨🇭
https://pasc19.pasc-conference.org/


2019-06-17
2019-06-20
The 41st PIERS
Rome,Italy意大利
http://piers.org/piers2019Rome/


June 25 2019
June 27 2019
Radio/Millimeter Astrophysical Frontiers in the Next Decade
University of Virginia, Inn at Darden, Charlottesville, VA
https://web.cvent.com/event/113b66a4-48cd-4881-a098-ed5820c65813/summary


2019-06-26
2019-06-28
FAST/Future Pulsar Symposium 8
陕西西安🇨🇳
http://www.phy.pku.edu.cn/~FPS/FPS8/FPS8.html


08 July 2019
18 July 2019
27th IUGG General Assembly
Montreal, Canada🇨🇦
http://iugg2019montreal.com/


2019-07-05
2019-07-07
第二届全国大数据与人工智能科学大会
云南昆明🇨🇳
http://csiam-bd-ai.csp.escience.cn/dct/page/1


2019-07-10
2019-07-15
2019年度分子云与恒星形成研讨会
新疆阿勒泰🇨🇳
http://2019mcandsf.csp.escience.cn/dct/page/1


2019-07-14
2019-07-18
中国天文学会第12届张衡学术研讨会
新疆乌鲁木齐🇨🇳
http://zhangheng2019.csp.escience.cn/dct/page/65540


2019-07-22
2019-07-24
The 4th International Conference on Lunar and Deep Space Exploration (LDSE)
珠海市🇨🇳



2019-08-21
2019-08-23
第六届中国科学数据大会-科学数据与重大科研基础设施
贵州省贵阳市🇨🇳
http://dc2019.csp.escience.cn/dct/page/1


28 July 2019
02 August 2019
AOGS 16th Annual Meeting
Singapore🇸🇬
http://www.asiaoceania.org/aogs2019/


9 August 2019
11 August 2019
BigCom 2019 - The 5th International Conference on Big Data Computing and Communications
Qing Dao, China🇨🇳
http://staff.ustc.edu.cn/~bigcom2019/index.html


2019-09-06
2019-09-10
中国天文学会2019年学术年会
青海省海西州德令哈市🇨🇳
http://2019casmeeting.csp.escience.cn/dct/page/1


16 Sep 2019
20 Sep 2019
ION GNSS+ 2019
Miami, Florida, USA🇺🇸
TBA


2019-09-19
2019-09-20
CODATA 2019: Towards next-generation data-driven science: policies, practices and platforms
Beijing，China🇨🇳
http://www.codata.org/events/conferences/codata-2019-beijing


2019-09-23
2019-09-27
12th East Asian VLBI Workshop
Ibaraki,Japan🇯🇵
http://vlbi.sci.ibaraki.ac.jp/eavw19/


7 October 2019
11 October 2019
ERIS 2019 - European Radio Interferometry School
Gothenburg, Sweden
https://www.chalmers.se/en/researchinfrastructure/oso/events/ERIS2019/Pages/default.aspx


01 October 2019
30 November 2019
The Earth’s Time Varying Rotation: A Centennial Celebration
TBA
TBA


2019-10-14
2019-10-17
SKA-VLBI Key Science Projects and Operations Workshop
Jodrell Bank Observatory，United Kingdom
https://indico.skatelescope.org/event/539/


2019-11-01
2019-11-04
中国天文学会行星科学与深空探测前沿研讨会暨中科院行星科学重点实验室和月球与行星科学国家重点实验室 2019 年联合学术年会
四川成都🇨🇳



01 November 2019
30 November 2019
14th Meeting of the International Committee on Global Navigation Satellite Systems (ICG) [exact dates TBD]
India🇮🇳
TBA


2019-11-11
2019-11-15
The 13th DiFX Users and Developers Workshop
Melbourne🇦🇺
http://astronomy.swin.edu.au/research/conferences/difx2019/


2019-11-18
2019-11-20
8th International VLBI Technology Workshop
Sydney 🇦🇺
https://www.atnf.csiro.au/ivtw19/


2019-11-25
2019-11-28
The SKA System Design, Operations &amp; Plans
上海🇨🇳
https://indico.skatelescope.org/event/551/


2019-11-27
2019-12-01
中国虚拟天文台与天文信息学2019年学术年会
黑龙江大庆市🇨🇳
http://www.china-vo.org/events/cvo2019/index.html


09 December 2019
13 December 2019
AGU 2019 Fall Meeting
San Francisco, CA, USA🇺🇸
TBA


]]></content>
      <categories>
        <category>Astronomy</category>
      </categories>
      <tags>
        <tag>astronomy</tag>
        <tag>vlbi</tag>
        <tag>astromeeting</tag>
      </tags>
  </entry>
  <entry>
    <title>PGPLOT手册</title>
    <url>/2011/07/11/pgplot-0-all/</url>
    <content><![CDATA[关于PGPLOT的翻译第一章 介绍1.1 PGPLOT简介1.2 PGPLOT安装1.3 PGPLOT手册简介安装1.4 PGPLOT图像设备1.5 PGPLOT环境变量第二章 PGPLOT的简单使用2.0 PGPLOT的简单使用2.1 PGPLOT的简单使用简介2.2 PGPLOT的一个示例程序2.3 PGPLOT的数据初始化2.4 PGPLOT 开始使用2.5 PGPLOT 绘图比例和坐标轴2.6 PGPLOT 标记坐标轴2.7 PGPLOT 绘制图形标记2.8 PGPLOT 绘制线2.9 PGPLOT 结束绘图2.10 PGPLOT 编译和运行第三章 窗口和视图3.1 PGPLOT的窗口和视图3.2 PGPLOT的视图选择3.3 PGPLOT的视图选择3.4 PGPLOT的窗口特性3.5 PGPLOT的窗口特性3.6 PGPLOT 集大成函数PGENV第四章 元素4.1 PGPLOT的基元简介4.2 PGPLOT的基元剪裁4.3 PGPLOT的基元线条4.4 PGPLOT的基元图标记4.5 PGPLOT的基元文字4.6 PGPLOT的基元区域填充第五章 属性5.1 PGPLOT的属性简介5.2 PGPLOT的属性简介 颜色索引5.3 PGPLOT的属性简介 颜色显示5.4 PGPLOT的属性简介 线条类型5.5 PGPLOT的属性简介 线条宽度5.6 PGPLOT的属性简介  字符高度5.7 PGPLOT的属性简介 字符字体5.8 PGPLOT的属性简介 文字背景5.9 PGPLOT的属性简介  填充类型5.10 PGPLOT的属性简介 获取属性5.11 PGPLOT的属性保存与复原第六章 高级函数6.1 PGPLOT的高级应用6.2 PGPLOT的高级应用 XY绘图6.3 PGPLOT的高级应用 直方图6.4 PGPLOT的高级应用 两个变量的函数第七章 图形交互7.1 PGPLOT图形交互 简介7.2 PGPLOT图形交互 光标7.3 PGPLOT图形交互 使用光标7.4 PGPLOT图形交互 缓冲]]></content>
      <categories>
        <category>PGPLOT</category>
      </categories>
      <tags>
        <tag>pgplot</tag>
        <tag>doc</tag>
      </tags>
  </entry>
  <entry>
    <title>关于PGPLOT的翻译</title>
    <url>/2011/07/11/pgplot-0-intro/</url>
    <content><![CDATA[
虽然只是自己的随笔，随便写写，还是献给我亲爱的父母和可爱的女朋友WXM同学。

序言
本心得手册为PGPLOT的C语言编程中文手册，为广大的中国PGPLOT fans而作。
由于最近有个项目要用到PGPLOT，就花了几天的时间来熟悉这个天文界极为常见的图库，后面因为在网上没有找到关于C-bind的文章，就索性大概写了一下心得（由于正常工作时间不可能全部花在这个上面，所以时间就比较紧促，排版方面也是很草草了了~）。
最后我会附上PGPLOT的manual原版，我没有纯粹的来翻译这本手册，只是大概按照自己的学习步骤，随便写了写，因为对中英文的计算机术语没有较深涉入，所以会有些术语不是很标准，希望读到的XDJM多多的提意见。
在c语言中一般都要加上c前缀，比如PGBOX在c语言中调用为cpgbox。有些函数比如PGWINDOW有相同含义的PGSWIN，在C语言中调用cpgswin即可。
对了，本文PGPLOT的操作平台为Linux/MacOSX系统。
好友cosmancosman.leo@gmail.com（全能牛人）前一段时间用python调用PGPLOT做出了一个天文数据处理的软件，如果有PGPLOT和python的接口问题，可以咨询他。
大部分文档写于2011-06-18~2011-07-18
]]></content>
      <categories>
        <category>PGPLOT</category>
      </categories>
      <tags>
        <tag>pgplot</tag>
        <tag>doc</tag>
      </tags>
  </entry>
  <entry>
    <title>PGPLOT简介</title>
    <url>/2011/06/11/pgplot-1-1-intro/</url>
    <content><![CDATA[PGPLOT是个Fortran子程序库。
目前，由于不同语言之间的协议不同，在C或者C++中直接调用PGPLOT是比较困难的。
另外，c语言是传值调用的，而FORTRAN是按引用传递的。CPGPLOT 库包装了C和PGPLOT库，其中的函数屏蔽了不同系统的差别，提供了与系统无关的接口。
编写PGPLOT程序的时候，只需要在头文件中添加文件头cpgplot.h即可，其中包含了我们所需要调用的一些函数原型。
CPGPLOT库只能用在与ANSI C兼容的c编译器（可以解析C函数原型）。
PGPLOT是一个设备无关的画图软件包，常用于简单的科学计算做图。PGPLOT用Fortran语言，但可以在C、Perl、Phython、Ruby等语言中调用，支持PS、GIF、PNG等很多图形格式，可以运行在Linux, SunOS, Solaris, HPUX, AIX, Irix, and MacOS X/Darwin等操作系统。
PGPLOT由加州理工（California Institute of Technology）的Tim Pearson编写。Tim是加州理工天文系（Department of Astronomy)的助理教授，主要做射电、宇宙学方面的研究。
目前PGPLOT最新的版本是2001-02-26发布的5.2.2版。版权属于加州理工学院。PGPLOT不是开放软件，但可以免费用于非商业用途。
]]></content>
      <categories>
        <category>PGPLOT</category>
      </categories>
      <tags>
        <tag>pgplot</tag>
        <tag>introduction</tag>
      </tags>
  </entry>
  <entry>
    <title>PGPLOT安装</title>
    <url>/2011/06/11/pgplot-1-2-install/</url>
    <content><![CDATA[详细的安装参考 文章Ubuntu/Debain/Fedora/Mac/CentOS 安装PGPLOT  。
]]></content>
      <categories>
        <category>PGPLOT</category>
      </categories>
      <tags>
        <tag>pgplot</tag>
        <tag>installation</tag>
      </tags>
  </entry>
  <entry>
    <title>PGPLOT手册简介安装</title>
    <url>/2011/06/11/pgplot-1-3-manual-intro/</url>
    <content><![CDATA[本教程既是PGPLOT的入门教程也是参考手册。
入门教程：介绍了如何使用PGPLOT
➢	参考手册：关于PGPLOT的所有函数的定义和使用实例。➢	第二章：入门指导，列举了一个最简单的绘图程序➢	第三章：基本特性➢	第四章：介绍四种组成图像的基元：线条、图标记、文字、区域填充➢	第五章：如何改变基元的属性，比如颜色、线条类型、字体等➢	第六章：描述了一些经过包装的高级程序及函数➢	第七章：PGPLOT图像交互式的能力➢	第八章：图元文件的使用
	附录A：PGPLOT所有的函数原型	附录B：PGPLOT注释可以用的字符和符号	附录C：PGPLOT不同平台的安装	附录D：PGPLOT支持的设备细节介绍	附录E：扩展PGPLOT以支持其他设备的说明	附录F：C语言中如何调用PGPLOT
]]></content>
      <categories>
        <category>PGPLOT</category>
      </categories>
      <tags>
        <tag>pgplot</tag>
        <tag>introduction</tag>
      </tags>
  </entry>
  <entry>
    <title>PGPLOT图像设备</title>
    <url>/2011/06/11/pgplot-1-4-device/</url>
    <content><![CDATA[一般说的包括两种：

   产生硬拷贝输出的，比如ps文件等；
   交互设备，只是显示在我们的显示器上。

输出设备描述格式：device name（file name）/ device type
]]></content>
      <categories>
        <category>PGPLOT</category>
      </categories>
      <tags>
        <tag>pgplot</tag>
        <tag>ps</tag>
        <tag>device</tag>
      </tags>
  </entry>
  <entry>
    <title>PGPLOT环境变量</title>
    <url>/2011/06/11/pgplot-1-5-enviroment/</url>
    <content><![CDATA[关于环境变量的设置，在 Ubuntu/Debain/Fedora/Mac/CentOS 安装PGPLOT 章节中已经有详细描述。
Mark：在安装是不要漏过任何一个细节。
主要为 PGPLOT_DIR 和 PGPLOT_DEV
]]></content>
      <categories>
        <category>PGPLOT</category>
      </categories>
      <tags>
        <tag>pgplot</tag>
        <tag>environment</tag>
      </tags>
  </entry>
  <entry>
    <title>PGPLOT的简单使用</title>
    <url>/2011/06/11/pgplot-2-0-simple-use-of-pgplot/</url>
    <content><![CDATA[本章节介绍了用PGPLOT创建一个图像的基本过程，主要分为下面几个章节：

PGPLOT的简单使用简介
PGPLOT的一个示例程序
PGPLOT的数据初始化
PGPLOT 开始使用
PGPLOT 绘图比例和坐标轴
PGPLOT 标记坐标轴
PGPLOT 绘制图形标记
PGPLOT 绘制线
PGPLOT 结束绘图
PGPLOT编译和运行

]]></content>
      <categories>
        <category>PGPLOT</category>
      </categories>
      <tags>
        <tag>pgplot</tag>
        <tag>usage</tag>
      </tags>
  </entry>
  <entry>
    <title>PGPLOT的简单使用简介</title>
    <url>/2011/06/11/pgplot-2-1-intro/</url>
    <content><![CDATA[本章节介绍了用PGPLOT创建一个图像的基础子程序，并有一些示例程序。
一个图像主要有下面几个部分组成：

   坐标轴
   标记
   点或线

在使用PGPLOT画图的时候，至少要用到4个PGPLOT的子程序。

PGBEGIN：开启PGPLOT并制定输出设备
PGENV：设定图像的坐标轴范围、标签等
PGPOINT/PGLINE：画点或线
PGEND：关闭画图程序

当然，如果在一个设备上想画很多的图形，只需要重复23即可。而对于14，除非想在不同的设备上输出，否则只调用一次就够了。
]]></content>
      <categories>
        <category>PGPLOT</category>
      </categories>
      <tags>
        <tag>pgplot</tag>
        <tag>usage</tag>
      </tags>
  </entry>
  <entry>
    <title>PGPLOT 编译和运行</title>
    <url>/2011/06/11/pgplot-2-10-compile-and-run/</url>
    <content><![CDATA[编译并运行程序在编译并链接好程序后，执行程序是会提示：
Graphics device/type (? to see list, default /Xserve):
这里我们输入“？”，查看一下可用的设备，我的如下所示，这个设备列表与安装时修改的drives.list相关联。
Graphics device/type (? to see list, default /Xserve): ? PGPLOT v5.2.2 Copyright 1997 California Institute of Technology Interactive devices:    /XWINDOW   (X window window@node:display.screen/xw)    /XSERVE    (A /XWINDOW window that persists for re-use) Non-interactive file formats:    /GIF       (Graphics Interchange Format file, landscape orientation)    /VGIF      (Graphics Interchange Format file, portrait orientation)    /LATEX     (LaTeX picture environment)    /NULL      (Null device, no output)    /PNG       (Portable Network Graphics file)    /TPNG      (Portable Network Graphics file - transparent background)    /PS        (PostScript file, landscape orientation)    /VPS       (PostScript file, portrait orientation)    /CPS       (Colour PostScript file, landscape orientation)    /VCPS      (Colour PostScript file, portrait orientation) Graphics device/type (? to see list, default /Xserve):

默认输出之屏幕，如上述图像所有，然后我选择/PS，就会发现在可执行程序相同目录中多了一个文件PGPLOT.ps文件（这个对于科研人员使用Latex调用图比较方便）。
]]></content>
      <categories>
        <category>PGPLOT</category>
      </categories>
      <tags>
        <tag>pgplot</tag>
        <tag>compile</tag>
      </tags>
  </entry>
  <entry>
    <title>PGPLOT的一个示例程序</title>
    <url>/2011/06/11/pgplot-2-2-example/</url>
    <content><![CDATA[PGPLOT 的一个示例程序简介PGPLOT典型的应用主要是一些已知测定点的描绘和理论曲线的比对。
这里给出一个简单的例子程序，画出5个数据点，理论曲线为y=x^2。
代码代码如下所示：
/** * Copyright (c) 2010-2017, Guo Shaoguang * * All rights reserved. * * @file shao_pgplot_y=x2.c * @author 	Guo Shaoguang * @email 	sgguo@shao.ac.cn * @date	2011.06.11 * @version	v1.0 * * @brief This file will y=x^2 using PGPLOT */#include "../include/cpgplot.h"#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;int main() {    int i;    static float xs[] = {1.0, 2.0, 3.0, 4.0, 5.0};    static float ys[] = {1.0, 4.0, 9.0, 16.0, 25.0};    float xr[100], yr[100];    int n = sizeof(xr) / sizeof(xr[0]);    printf("Now begin to plot ...\n");    /// 1. Enable the PGPLOT and setting the device    if (cpgbeg(0, "?", 1, 1) != 1)        return EXIT_FAILURE;    /// 2. Setting the axis of x and y including label    cpgenv(0.0, 10.0, 0.0, 20.0, 0, 1);    cpglab("(x)", "(y)", "y = x\\u2\\d");    cpgiden();    /// 3. Begin plot points / lines    cpgpt(5, xs, ys, 9);    for (i = 0; i &lt; n; i++) {        xr[i] = 0.1 * i;        yr[i] = xr[i] * xr[i];    }    cpgline(n,xr,yr);    /// 4. Close the PGPLOT    cpgend();    return EXIT_SUCCESS;}

结果
]]></content>
      <categories>
        <category>PGPLOT</category>
      </categories>
      <tags>
        <tag>pgplot</tag>
        <tag>demo</tag>
        <tag>cpgbeg</tag>
        <tag>cpgenv</tag>
        <tag>cpglab</tag>
        <tag>cpgiden</tag>
        <tag>cpgpt</tag>
        <tag>cpgline</tag>
        <tag>cpgend</tag>
      </tags>
  </entry>
  <entry>
    <title>PGPLOT的数据初始化</title>
    <url>/2011/06/11/pgplot-2-3-data-init/</url>
    <content><![CDATA[关于数据初始化就不多做解释了。
但凡对C语言有了解的人，应该和容易明白上述代码（除了PGPLOT调用子函数）。
]]></content>
      <categories>
        <category>PGPLOT</category>
      </categories>
      <tags>
        <tag>pgplot</tag>
      </tags>
  </entry>
  <entry>
    <title>PGPLOT 开始使用</title>
    <url>/2011/06/11/pgplot-2-4-start-pgplot/</url>
    <content><![CDATA[开始使用PGPLOT编程的第一步就是要选定输出的设备，函数为cpgbeg。
]]></content>
      <categories>
        <category>PGPLOT</category>
      </categories>
      <tags>
        <tag>pgplot</tag>
        <tag>cpgbeg</tag>
      </tags>
  </entry>
  <entry>
    <title>PGPLOT 绘图比例和坐标轴</title>
    <url>/2011/06/11/pgplot-2-5-defining-plot-scales-and-drawing-axes/</url>
    <content><![CDATA[函数cpgenv 开始一幅新的图片并且定义了变量的范围和图像的比例，cpgenv 也可以按照参数绘制指定的坐标轴，详细参考函数原型。
]]></content>
      <categories>
        <category>PGPLOT</category>
      </categories>
      <tags>
        <tag>pgplot</tag>
        <tag>cpgbeg</tag>
      </tags>
  </entry>
  <entry>
    <title>PGPLOT 标记坐标轴</title>
    <url>/2011/06/11/pgplot-2-6-labeling-the-axes/</url>
    <content><![CDATA[一般函数cpgenv 之后就开始调用cpglab来标记坐标轴以及整个图像的标题。
]]></content>
      <categories>
        <category>PGPLOT</category>
      </categories>
      <tags>
        <tag>pgplot</tag>
        <tag>cpglab</tag>
      </tags>
  </entry>
  <entry>
    <title>PGPLOT 绘制图形标记</title>
    <url>/2011/06/11/pgplot-2-7-drawing-graph-markers/</url>
    <content><![CDATA[函数cpgpt用于绘制一个或多个点，详细参考函数原型。
]]></content>
      <categories>
        <category>PGPLOT</category>
      </categories>
      <tags>
        <tag>pgplot</tag>
        <tag>cpgpt</tag>
      </tags>
  </entry>
  <entry>
    <title>PGPLOT 绘制线</title>
    <url>/2011/06/11/pgplot-2-8-drawing-lines/</url>
    <content><![CDATA[函数cpgline用于绘制一条线，详细参考函数原型。
]]></content>
      <categories>
        <category>PGPLOT</category>
      </categories>
      <tags>
        <tag>pgplot</tag>
        <tag>cpgline</tag>
      </tags>
  </entry>
  <entry>
    <title>PGPLOT 结束绘图</title>
    <url>/2011/06/11/pgplot-2-9-ending-the-plot/</url>
    <content><![CDATA[在结束绘图后调用函数cpgend，如果不结束可能会影响到后续的程序。
]]></content>
      <categories>
        <category>PGPLOT</category>
      </categories>
      <tags>
        <tag>pgplot</tag>
        <tag>cpgend</tag>
      </tags>
  </entry>
  <entry>
    <title>PGPLOT的窗口和视图</title>
    <url>/2011/06/11/pgplot-3-1-window-intro/</url>
    <content><![CDATA[简介本章主要介绍一些图像显示的位置和比例的控制问题。
在上一章的简单示例中，我们通过PGENV来自动的控制图像的位置和标记信息。但是，为了获得对位置和标记等的完全控制，我们还需要了解下述知识:

View Surface：视图面
Window：窗口
Viewport：视口

另外还有两个坐标系统：

World Coordinates：世界坐标系
Device Coordinates：设备坐标系

一个简单的PGPLOT图像或许只是描述了二维的两个变量之间的依赖关系。一个典型的图像包括数据点（误差条、点标记或者块标记）、连接在一起的线条，或者理论模型的平滑曲线。另外还要加上坐标来指出刻度等信息。
程序员应该在矩形的笛卡尔坐标轴上描述出一些必要的信息。
当然，对于这样的坐标系有一定的弊端，只能描述浮点型数据。
对于x和y坐标系不同计量单位的图像，我们后面会有所介绍。比如横坐标为时间，纵坐标为流量密度的射电源图像。
在PGPLOT编程过程中选择世界坐标系作为默认设置。
PGPLOT maps a selected rectangular region of the world-coordinate space (termed the window) onto a specified rectangle (termed the viewport) on the view surface (the screen of an interactive display or a sheet of paper on a hardcopy plotter).

这一段比较重要，指出了上面我们提到的三个术语，这三个术语要搞搞清楚，后面对于一些子程序，会对不同的术语做出不同配置。我不做翻译。只可意会不可言传~ ^_^

通俗的理解，先指定view surface，可以是显示的图像或者保存的ps文件；然后设置viewport，这个就是方框内的图形，不包括注释；而window就是实际对应的数值信息，比如随着时间的流量信息。

]]></content>
      <categories>
        <category>PGPLOT</category>
      </categories>
      <tags>
        <tag>pgplot</tag>
        <tag>view surface</tag>
        <tag>window</tag>
        <tag>viewport</tag>
      </tags>
  </entry>
  <entry>
    <title>PGPLOT的视图选择</title>
    <url>/2011/06/11/pgplot-3-2-select-view-surface/</url>
    <content><![CDATA[一个图像程序第一件要做的事情就是告诉PGPLOT选择使用什么设备作为输出，前面我们也提到过，一共有两种不同的设备类型。
这个设备类型我们可以在pgbeg函数中提前确定，例如PGBEG (0, ‘plotfile.ps/PS’, 1, 1)，就是输出文件名为plotfile.ps的ps类型文件。也可以使用“？“来输出时自行选择。
当然，在完成我们的绘图工作以后，调用cpgend来刷新输出结果是有必要的，就像C语言中malloc以后要调用free，以免引起内存泄露。
对于不同的输出设备，PGPLOT默认是有一些输出default设置的。比如ps输出，就会采用标准的18X5inches的景观模式。
如果你有自己的审美观，准备设置一些高级的输出，那么这是你可以调用pgpage（后面有详细介绍）来设定宽度、比例。
PGBEG的最后两个参数nx和ny，可以将窗口分割为nx*ny个小窗口，例如nx和ny均取3，那么将绘制出9副图片。

]]></content>
      <categories>
        <category>PGPLOT</category>
      </categories>
      <tags>
        <tag>pgplot</tag>
        <tag>malloc</tag>
        <tag>free</tag>
        <tag>ps</tag>
        <tag>pgend</tag>
        <tag>pgbeg</tag>
        <tag>pgpaper</tag>
      </tags>
  </entry>
  <entry>
    <title>PGPLOT的窗口特性</title>
    <url>/2011/06/12/pgplot-3-4-define-window/</url>
    <content><![CDATA[通过调用PGSWIN来设置window属性。
PGSWIN (1975.0, 1984.0, 5.0, 20.0)

X轴从1975到1984
Y轴从5到20
]]></content>
      <categories>
        <category>PGPLOT</category>
      </categories>
      <tags>
        <tag>pgplot</tag>
        <tag>pgswin</tag>
      </tags>
  </entry>
  <entry>
    <title>PGPLOT的视图选择</title>
    <url>/2011/06/12/pgplot-3-3-define-viewport/</url>
    <content><![CDATA[默认的视口输出居中并留有一定的余量用于注解标记。
但是如果想改变这些默认设置，可以使用pgvport（比例象限）、pgvsize（实际尺寸）等函数。这些函数都会在后面有详细介绍。
]]></content>
      <categories>
        <category>PGPLOT</category>
      </categories>
      <tags>
        <tag>pgplot</tag>
        <tag>pgvport</tag>
        <tag>pgvsize</tag>
      </tags>
  </entry>
  <entry>
    <title>PGPLOT的窗口特性</title>
    <url>/2011/06/12/pgplot-3-5-annotating-viewport/</url>
    <content><![CDATA[通过下面的函数：
PGBOX ('BCTN', 0.0, 0, 'BCNST', 0.0, 0)CALL PGLAB ('Epoch', 'Flux Density (Jy)', 'Variation of 3C345 at 10.7 GHz')
来给图像做注解。
PGMTXT可以给视口中的任何一个点做注解。
]]></content>
      <categories>
        <category>PGPLOT</category>
      </categories>
      <tags>
        <tag>pgplot</tag>
        <tag>pgbox</tag>
        <tag>pglab</tag>
      </tags>
  </entry>
  <entry>
    <title>PGPLOT 集大成函数PGENV</title>
    <url>/2011/06/12/pgplot-3-6-routine-pgenv/</url>
    <content><![CDATA[这里将上面几个小部分提到的函数全部展示一下。
其实调用PGPAGE、PGSVP、 PGSWIN和 PGBOX 是比较不方便的方法，虽然可以随心所欲的展示一些成果。
这四个函数也可用通过一个集成的函数来搞定，即PGENV (for PGPLOT ENVironment) 。
比如

PGENV (1975.0, 1984.0, 5.0, 20.0, 0, 0)

与下面四个函数的效果是相同的

CALL PGPAGE
CALL PGVSTD
CALL PGSWIN (1975.0, 1984.0, 5.0, 20.0)
CALL PGBOX  (‘BCNST’, 0.0, 0, ‘BCNST’, 0.0, 0)

]]></content>
      <categories>
        <category>PGPLOT</category>
      </categories>
      <tags>
        <tag>pgplot</tag>
        <tag>pgswin</tag>
        <tag>pgbox</tag>
        <tag>pgenv</tag>
        <tag>pgpage</tag>
        <tag>pgsvp</tag>
      </tags>
  </entry>
  <entry>
    <title>PGPLOT的基元简介</title>
    <url>/2011/06/12/pgplot-4-1-element-intro/</url>
    <content><![CDATA[在上一章选定好我们的窗口和视口后，我们就可以开始作图了。
本章我们描述最基础的程序，叫做基元。基元就是可以画出图像的元素。
这里有四种不同的基元：

lines：线条
graph-markers：图标记
text：文字
area fill：区域填充

]]></content>
      <categories>
        <category>PGPLOT</category>
      </categories>
      <tags>
        <tag>pgplot</tag>
        <tag>lines</tag>
        <tag>graph-markers</tag>
        <tag>text</tag>
        <tag>area</tag>
      </tags>
  </entry>
  <entry>
    <title>PGPLOT的基元剪裁</title>
    <url>/2011/06/12/pgplot-4-2-element-clipping/</url>
    <content><![CDATA[在视口边缘的基元可能要被剪裁掉。
由于默认显示的规则不同，所以四种基元被裁减掉的可能性如下：

线条在与viewport的交叉处外被裁剪；
如果图标记的中心在viewport边缘或者里面就会画出来，否则就裁剪掉；
文字除非越过了view surface，一般都不会裁减掉；
区域填充也是在 viewport的边缘裁减掉；

]]></content>
      <categories>
        <category>PGPLOT</category>
      </categories>
      <tags>
        <tag>pgplot</tag>
        <tag>viewport</tag>
        <tag>graph-markers</tag>
        <tag>text</tag>
        <tag>area</tag>
        <tag>line</tag>
      </tags>
  </entry>
  <entry>
    <title>PGPLOT的基元线条</title>
    <url>/2011/06/12/pgplot-4-3-element-line/</url>
    <content><![CDATA[绘制线条的函数为pgline。这个函数可以绘制一条或多条直线线段。这个函数的详细介绍参考索引。
还有两个更基础的pgmove和pgdraw。这些主要应用于数控绘图机上，所以一般我们用模块化比较好的pgline。
Pgline线条可以有pgmove和pgdraw组合而成 。两者的转化如下所示：
（主要显示出两者转化的代码，全部的代码如最基础代码所示。）
实例如下：
cpgline(n, xr[1], yr[1]);for (i = 2; i &lt; n; i++)  cpgdraw(xr[i],yr[i]);

等效于
cpgline(n, xr, yr);

]]></content>
      <categories>
        <category>PGPLOT</category>
      </categories>
      <tags>
        <tag>pgplot</tag>
        <tag>pgline</tag>
        <tag>pgmove</tag>
        <tag>pgdraw</tag>
      </tags>
  </entry>
  <entry>
    <title>PGPLOT的基元图标记</title>
    <url>/2011/06/12/pgplot-4-4-element-graph-marker/</url>
    <content><![CDATA[图标记就是一些符号，例如·、○、■、×等符号。这些符号为了标记一些特殊的点。
我们可以调用pgpt1来绘制这些标记。
标记符号太多了，这里画了10个不同的标记。
/// @file shao_pgplot_graph_markers.cfor (j = 0; j &lt; 10; j++) {       for (i = 0; i &lt; 10; i++) {           cpgpt1(i * 1.0 +1.0, j * 1.0 + 1.0, i * 10 + j);       }   }

随便写了一个从1到10的标记如图所示。
不同的标记如下所示：

]]></content>
      <categories>
        <category>PGPLOT</category>
      </categories>
      <tags>
        <tag>pgplot</tag>
        <tag>pgline</tag>
        <tag>pgmove</tag>
        <tag>pgdraw</tag>
      </tags>
  </entry>
  <entry>
    <title>PGPLOT的基元文字</title>
    <url>/2011/06/12/pgplot-4-5-element-fonts/</url>
    <content><![CDATA[文字主要用来做一些标记注释或者标题。
比如使用pgtext、pgptext、pgmtxt等等。
##转义字符的含义



转义字符
解释



\u
开始一个上标或结束一个下标


\d
开始一个下标或结束一个上标 (记住\u和\d 必须成对出现)


\b
退格


\fn
正常字体


\fr
罗马字体


\fi
意大利字体


\fs
手写体


\
反斜杠字符


\x
乘号×


.
居中点


\A
物理中埃 (Å)


\gx
希腊字母


\mn \mnn
图标记，参考附录


(nnnn)
如果其中一个n的后面不是数字或者),那么）可能会被忽略。这个用于表示一些特殊字符（数学符号、音乐符号、天文符号和地制图的符号），参考附录


代码测试如下：
/// &gt; upper and lower fontcpgtext(1.0,1.0,"SHAO\\u2011\\d");/// &gt; backspacecpgtext(1.0,2.0,"SHAO\\b");/// &gt; normal fontcpgtext(1.0,3.0,"\\fnSHAO");/// &gt; roma fontcpgtext(1.0,4.0,"\\frSHAO");/// &gt; italy fontcpgtext(1.0,5.0,"\\fiSHAO");/// &gt; hand writing fontcpgtext(1.0,6.0,"\\fsSHAO");/// &gt;cpgtext(1.0,7.0,"\\\\x\\.\\A");/// &gt; Greek alphabet/// &gt; alpha/beta/gamma/delta/epsilon/zeta/eta/theta/// &gt; iota/kappa/lambda/mu/nu/xi/omicron/pi/// &gt; rho/sigma/tau/upsilon/phi/chi/psi/omegacpgtext(1.0,8.0,"\\ga\\gA|\\gb\\gB|\\gg\\gG|\\gd\\gD|\\ge\\gE|\\gz\\gZ|\\gy\\gY|\\gh\\gH|");cpgtext(1.0,9.0,"\\gi\\gI|\\gk\\gK|\\gl\\gL|\\gm\\gM|\\gn\\gN|\\gc\\gC|\\go\\gO|\\gp\\gP|");cpgtext(1.0,10.0,"\\gr\\gR|\\gs\\gS|\\gt\\gT|\\gu\\gU|\\gf\\gF|\\gx\\gX|\\gq\\gQ|\\gw\\gW|");cpgtext(5.0,1.0,"\\m1 \\m2 \\m3 \\m4 \\m5 \\m6 \\m7 \\m8 \\m9 \\m10");cpgtext(5.0,2.0,"\\m11 \\m12 \\m13 \\m14 \\m15 \\m16 \\m17 \\m18 \\m19 \\m20");cpgtext(5.0,3.0,"\\m21 \\m22 \\m23 \\m24 \\m25 \\m26 \\m27 \\m28 \\m29 \\m30 \\m31");...

]]></content>
      <categories>
        <category>PGPLOT</category>
      </categories>
      <tags>
        <tag>pgplot</tag>
        <tag>pgtext</tag>
        <tag>pgptext</tag>
      </tags>
  </entry>
  <entry>
    <title>PGPLOT的基元区域填充</title>
    <url>/2011/06/12/pgplot-4-6-element-area-fill/</url>
    <content><![CDATA[区域填充可以让程序员把任意多边形的内部进行着色或渲染。
主要函数为pgploy（画任意多边形）、pgrect（画简易矩形）、pgcirc（画圆）。
例如，用PGPLOT (10，nx，ny)作图如下：
//file shao_pgplot_area_fill.float xs[11] = {0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0};float ys[11] = {0.0, 1.0, 4.0, 6.0, 8.0, 8.0, 7.0, 8.0, 6.0, 4.0, 0.0};cpgpoly(11, xs, ys);cpgrect(1.0, 9.0, 1.0, 8.0);cpgcirc(5., 5., 5.);

]]></content>
      <categories>
        <category>PGPLOT</category>
      </categories>
      <tags>
        <tag>pgplot</tag>
        <tag>pgploy</tag>
        <tag>pgrect</tag>
        <tag>pgcirc</tag>
      </tags>
  </entry>
  <entry>
    <title>PGPLOT的属性简介</title>
    <url>/2011/06/12/pgplot-5-1-property-intro/</url>
    <content><![CDATA[上一章中绘制的图像可以通过更改基元的属性来让绘制的图像发生变化。这些改变属性的函数如下示：



属性
函数



颜色索引
PGSCI


颜色显示
PGSCR, PGSCRN,和 PGSHLS.


线条类型
PGSLS


线条宽度
PGSLW


字符高度
PGSCH


字符字体
PGSCF


文本背景
PGSTBG


填充区域风格
PGSFS, PGSHS.


上述这些设置程序可以混杂使用。
一旦一个属性在适当的地方被调用后，这个属性会影响到后续的绘图，直到这个属性再次改变为止。
上述说明可以通过PGSxx用于设置新的属性，同样PGQxx用于查询基元的当前值，这样就可以在改变属性之前保存老的属性。
]]></content>
      <categories>
        <category>PGPLOT</category>
      </categories>
      <tags>
        <tag>pgplot</tag>
        <tag>PGSCI</tag>
        <tag>PGSCR</tag>
        <tag>PGSCRN</tag>
        <tag>PGSHLS</tag>
        <tag>PGSLS</tag>
        <tag>PGSLW</tag>
        <tag>PGSCH</tag>
        <tag>PGSCF</tag>
        <tag>PGSTBG</tag>
        <tag>PGSFS</tag>
        <tag>PGSHS</tag>
      </tags>
  </entry>
  <entry>
    <title>PGPLOT的属性简介 获取属性</title>
    <url>/2011/06/12/pgplot-5-10-property-get-property-func/</url>
    <content><![CDATA[PGPLOT中有一系列的获取属性函数用于在准备更改基元属性的时候保存旧的属性的函数。比如：

PGQLW(LW) 用于获取线条宽度
PGQCI(CI) 用于获取颜色索引


详细参考附录

]]></content>
      <categories>
        <category>PGPLOT</category>
      </categories>
      <tags>
        <tag>pgplot</tag>
        <tag>PGQLW</tag>
        <tag>PGQCI</tag>
      </tags>
  </entry>
  <entry>
    <title>PGPLOT的属性 保存与复原</title>
    <url>/2011/06/12/pgplot-5-11-property-save-and-back-property/</url>
    <content><![CDATA[在绘图过程中如果仅仅希望修改图像的部分属性，可以使用PGSAVE和PAUNSA来方便的实现。
PGSAVE保存当前的PGPLOT属性到一个私有存储区域。
这些属性可以由PAUNSA来恢复。
保存的属性包括：

字符字体
字符高度
颜色索引值
填充区域类型
线条类型
线条宽度
绘图位置
箭头类型
阴影类型

颜色显示是不保存的。
PS：在调用PGSAVE和PGUNSA的时候，两者一定是成对出现的。
有将近20个属性可以通过PGSAVE来保存。
例如：（下述为fortran代码）
* save current attributes      CALL PGSAVE* change the attributes and draw something      CALL PGSLW(2)      CALL PGSCI(11)      CALL PGLINE(7, X, Y)* 还原 the attributes      CALL PGUNSA      RETURN

]]></content>
      <categories>
        <category>PGPLOT</category>
      </categories>
      <tags>
        <tag>pgplot</tag>
        <tag>PGSLS</tag>
      </tags>
  </entry>
  <entry>
    <title>PGPLOT的属性简介 颜色索引</title>
    <url>/2011/06/12/pgplot-5-2-property-color-index/</url>
    <content><![CDATA[颜色索引值影响前面提到的所有基元，可以通过函数PGSCI和PGSCR修改。
设备的不同有主要一点就是在它们显示颜色的能力上。
一般而言，在大多数的硬拷贝设备上，默认的颜色搭配是白底黑字，但在大多数显像管设备上，默认的是黑底白（绿）字。
颜色可以通过一个整型的参数（索引值）来改变。
颜色索引1是默认的颜色，0是背景颜色。
可用的颜色数量主要取决于设备本身。就像在大多数的单色设备上，0、1是可用的，而对于一些显像管设备，可用的颜色标记可以从0到255。当然，有些单色设备还可以选择不同的亮度值（强度值）。
/// @file shao_pgplot_color_index.c  static float xs[] = {1.0, 2.0, 3.0, 4.0, 5.0};  static float ys[] = {1.0, 4.0, 9.0, 16.0, 25.0};  float xr[100], yr[100];  int n = sizeof(xr) / sizeof(xr[0]);  cpgsci(2);  cpgpt(5, xs, ys, 9);  for (i = 0; i &lt; n; i++) {      xr[i] = 0.1 * i;      yr[i] = (sin(xr[i])+1)*10;  }  cpgsci(3);  cpgline(n,xr,yr);


]]></content>
      <categories>
        <category>PGPLOT</category>
      </categories>
      <tags>
        <tag>pgplot</tag>
        <tag>PGSCI</tag>
        <tag>PGSCR</tag>
      </tags>
  </entry>
  <entry>
    <title>PGPLOT的属性简介 颜色显示</title>
    <url>/2011/06/12/pgplot-5-3-property-color-disp/</url>
    <content><![CDATA[每一个颜色索引值都有相关联的颜色显示（定义了相关的颜色和强度）。颜色显示可以用HLS或者RGB来表示：

HLS：Hue, Lightness, and Saturation—色度、亮度和饱和度(0&lt;H&lt;360,0.0&lt;=LS&lt;=1.0)
RGB：Red, Green, and Blue –红、绿、蓝(0.0&lt;=RGB&lt;=1.0)

默认 颜色显示


Color Index
Color
(H, L, S)
(R, G, B)



0
Black (background)
0, 0.00, 0.00
0.00, 0.00, 0.00


1
White (default)
0, 1.00, 0.00
1.00, 1.00, 1.00


2
Red
120, 0.50, 1.00
1.00, 0.00, 0.00


3
Green
240, 0.50, 1.00
0.00, 1.00, 0.00


4
Blue
0, 0.50, 1.00
0.00, 0.00, 1.00


5
Cyan (Green + Blue)
300, 0.50, 1.00
0.00, 1.00, 1.00


6
Magenta (Red + Blue)
60, 0.50, 1.00
1.00, 0.00, 1.00


7
Yellow  (Red + Green)
180, 0.50, 1.00
1.00, 1.00, 0.00


8
Red + Yellow (Orange)
150, 0.50, 1.00
1.00, 0.50, 0.00


9
Green + Yellow
210, 0.50, 1.00
0.50, 1.00, 0.00


10
Green + Cyan
270, 0.50, 1.00
0.00, 1.00, 0.50


11
Blue + Cyan
330, 0.50, 1.00
0.00, 0.50, 1.00


12
Blue + Magenta
30, 0.50, 1.00
0.50, 0.00, 1.00


13
Red + Magenta
90, 0.50, 1.00
1.00, 0.00, 0.50


14
Dark Gray
0, 0.33, 0.00
0.33, 0.33, 0.33


15
Light Gray
0, 0.66, 0.00
0.66, 0.66, 0.66


16–255
Undefined




设备一般分成三类颜色显示：

   static color，颜色固定，不更改
pseudo-color，更新索引表，并更新颜色
direct color，更新后续绘制的颜色

在可以显示一系列强度的单色设备上，显示强度I与RGB的的关系如下所示：
I = 0.30 R + 0.59 G + 0.11 B

与美国国家电视系统委员会规定的美国彩色电视系统标准一样。
用三基色RGB设置颜色显示
PGSCR(2, 0.0, 1.0, 0.3)

用色彩饱和度HLS设置颜色显示色彩饱和度HLS（Hue-Saturation-Lightness）

Hue为一个角度,红色为120°,绿色为240°,蓝色为0°(或360°).
Lightness 的范围从0.0（黑色）到1.0（白色）。
Saturation的范围从0.0（灰色）到1.0（纯色）。

当Hue为0.0的时候是与我们的颜色不相关的。



Examples
H
L
S
R
G
B



black
any
0.0
0.0
0.0
0.0
0.0


white
any
1.0
0.0
1.0
1.0
1.0


medium gray
any
0.5
0.0
0.5
0.5
0.5


red
120
0.5
1.0
1.0
0.0
0.0


yellow
180
0.5
1.0
1.0
1.0
0.0


pink
120
0.7
0.8
0.94
0.46
0.46


通过名字设置颜色显示第三种除了PGSCR、PGSHLS用于设置颜色显示的就是函数PGSCRN，PGSCRN通过名字来设置颜色。例如：
PGSCRN(2, 'MediumOrchid', IER)

预设值前景色和背景色与设备相关的默认颜色显示可以通过修改环境变量来更改。
比如在UNIX操作系统中，可以通过：
export PGPLOT_FOREGROUND=blackexport PGPLOT_BACKGROUND=white

或者更有创意的：
export PGPLOT_FOREGROUND=goldexport PGPLOT_FOREGROUND=slategrey
]]></content>
      <categories>
        <category>PGPLOT</category>
      </categories>
      <tags>
        <tag>pgplot</tag>
        <tag>PGSCI</tag>
        <tag>PGSCR</tag>
      </tags>
  </entry>
  <entry>
    <title>PGPLOT的属性简介 线条类型</title>
    <url>/2011/06/12/pgplot-5-4-property-line-type/</url>
    <content><![CDATA[线条类型可以是实线、点画先、点线等。
可以通过函数PGSLS来改变。默认的线条类型是实心不间断的线。
下面描述了线条类型的种类：

实线
破折号组成的线long dashes,
划点划点线dash-dot-dash-dot,
点线dotted,
划点点点dash-dot-dot-dot.

例如调用PGSLS(1)、PGSLS(2)、PGSLS(3)、PGSLS(4)、PGSLS(5)的效果为(从上到下)：

]]></content>
      <categories>
        <category>PGPLOT</category>
      </categories>
      <tags>
        <tag>pgplot</tag>
        <tag>PGSLS</tag>
      </tags>
  </entry>
  <entry>
    <title>PGPLOT的属性简介 线条宽度</title>
    <url>/2011/06/12/pgplot-5-5-property-line-width/</url>
    <content><![CDATA[线条宽度影响线条、图标记和文本。
可以通过PGSLW来设定线条宽度。
线条的宽度也是因设备而异的，不同的设备可能有不同的分辨率。但大部分的设备上都是的线条的单位宽度为0.005英寸(也就是0.13毫米). 默认宽度为1，最大的可能只为201。
分别对同一组数据进行绘图，
/// @file shao_pgplot_line_width.ccpgslw(1);cpgslw(5);cpgslw(10);cpgslw(15);cpgslw(50);


]]></content>
      <categories>
        <category>PGPLOT</category>
      </categories>
      <tags>
        <tag>pgplot</tag>
        <tag>PGSLS</tag>
      </tags>
  </entry>
  <entry>
    <title>PGPLOT的属性简介 字符高度</title>
    <url>/2011/06/12/pgplot-5-6-property-character-height/</url>
    <content><![CDATA[字符高度影响图标记和文本。
默认的字符高度为视图表面的1/40。
可以通过PGSCH来改变字符大小。
/// @file shao_pgplot_character_height.ccpgsch(1);cpgtext(1,2,"1. Hello SHAO");cpgsch(2);cpgtext(1,3,"2. Hello SHAO");cpgsch(3);cpgtext(1,4,"3. Hello SHAO");cpgsch(10);cpgtext(1,5,"10. Hello SHAO");


]]></content>
      <categories>
        <category>PGPLOT</category>
      </categories>
      <tags>
        <tag>pgplot</tag>
        <tag>PGSLS</tag>
      </tags>
  </entry>
  <entry>
    <title>PGPLOT的属性简介 文本背景</title>
    <url>/2011/06/12/pgplot-5-8-property-text-background/</url>
    <content><![CDATA[这个属性影响文本的显示。可以使用PGSTBG来设置。
文本可以使透明的或者不透明的。这个取决于他的属性值。

   -1: 透明   0 - 255: 不透明的。

例如如下类似代码
/// @file shao_pgplot_text_background.ccpgstbg(-1);cpgtext(1,2,"Hello SHAO");cpgstbg(1);cpgtext(1,3,"Hello SHAO");cpgstbg(10);cpgtext(1,4,"Hello SHAO");cpgstbg(50);cpgtext(1,5,"Hello SHAO");cpgstbg(100);cpgtext(1,6,"Hello SHAO");cpgstbg(150);cpgtext(1,7,"Hello SHAO");cpgstbg(200);cpgtext(1,8,"Hello SHAO");cpgstbg(250);cpgtext(1,9,"Hello SHAO");


]]></content>
      <categories>
        <category>PGPLOT</category>
      </categories>
      <tags>
        <tag>pgplot</tag>
        <tag>PGSLS</tag>
      </tags>
  </entry>
  <entry>
    <title>PGPLOT的属性简介 字符字体</title>
    <url>/2011/06/12/pgplot-5-7-property-character-font/</url>
    <content><![CDATA[字符字体只影响文本。
有四种字体可用，在前面也有过介绍了。
默认的第一种是最简单也是可以最快画出来的。如下：

normal (simple) font (default),
roman font,
italic font,
script font.

可以通过 PGSCF来改变字体。例如：通过类似下面的代码，显示出四种字体
   //@file : shao_pgplot_character_font.ccpgsch(3);   cpgscf(1);   cpgtext(0, 1, "Hello SHAO using normal font");   cpgscf(2);   cpgtext(0, 4, "Hello SHAO using roman font");   cpgscf(3);   cpgtext(0, 7, "Hello SHAO using italic font");   cpgscf(4);   cpgtext(0, 10, " Hello SHAO using script font");







]]></content>
      <categories>
        <category>PGPLOT</category>
      </categories>
      <tags>
        <tag>pgplot</tag>
        <tag>PGSLS</tag>
      </tags>
  </entry>
  <entry>
    <title>PGPLOT的属性简介 填充区域类型</title>
    <url>/2011/06/12/pgplot-5-9-property-fillarea-style/</url>
    <content><![CDATA[使用函数PGSFS修改。
填充区域类型有四种格式： solid (实心的，颜色填充整个区域), outline (轮廓的，只有轮廓被描绘), hatched (阴影线，有平行线条构成) or cross-hatched (交叉平行线，有两组交叉的平行线绘制线条s).
各种格式对应的数字代码为：

   1: solid (default),   2: outline   3: hatched,   4: cross-hatched.

四种格式如图所示：
/// @file shao_pgplot_fillarea_style.c   cpgsfs(1);   cpgcirc(1., 1., 1.);   cpgsfs(2);   cpgcirc(1., 3., 1.);   cpgsfs(3);   cpgcirc(1., 5., 1.);   cpgsfs(4);   cpgcirc(1., 7., 1.);


]]></content>
      <categories>
        <category>PGPLOT</category>
      </categories>
      <tags>
        <tag>pgplot</tag>
        <tag>PGSFS</tag>
      </tags>
  </entry>
  <entry>
    <title>PGPLOT的高级应用</title>
    <url>/2011/06/12/pgplot-6-1-advanced-program-intro/</url>
    <content><![CDATA[简介这章主要介绍一些高级程序，所谓的高级就是把其他一些比较低级的组合一下，就比如我们前面提到的pgenv等效4个函数的组合。
]]></content>
      <categories>
        <category>PGPLOT</category>
      </categories>
      <tags>
        <tag>pgplot</tag>
      </tags>
  </entry>
  <entry>
    <title>PGPLOT的高级应用 XY绘图</title>
    <url>/2011/06/12/pgplot-6-2-advanced-program-xy-plots/</url>
    <content><![CDATA[XY绘图在第二章介绍过xy-绘图的基础技术。可以通过PGPT画一些散点图，通过PGLINE来绘制一些线段。
属性通过一些不同的属性可以区分不同的数据集合。
图标记可以通过选择不同的记号、不同的颜色、不同的大小来区分。
直线和曲线可以通过线条类型、颜色和宽度来区分。
盒体参数如果用前面讲的比较基础的一下函数来替代PGENV，比如PGBOX，我们就可以完成更多的关于图形外观的设置。
cpgbox("G", 30., 0, "G", 0.2, 0 );cpgbox("ABCTSN", 90., 3, "ABCTSNV", 0.0, 0 );

阶梯式的线条图前面介绍过，使用PGLINE，可以绘制直线，有时，为了显示数字化地光谱，我们可能需要使用PGBIN 绘制有一定阶梯式的线条图，即直方图。
误差线实际数据的图形常需要包含误差线。函数PGERRX和PGERRY就可以单独绘制出水平的和垂直的误差线。误差函数通常与PGPT结合使用，来绘制2-sigma误差线里的点。
对数轴​有些情况下， x-轴或者 y-轴需要用对数的方式来代替普通的坐标表达方式，即用对数值代替大量的实际值。PGPLOT没有提供这样的对数机制。所以如果单纯的希望使用PGPLOT来表达，那么可以采用计算\log10 x 和log10 y 的方式来绘制。除此之外，还有一个更便捷的方法，函数PGENV（最后一个参数）和PGBOX都提供了对数值的选项。
]]></content>
      <categories>
        <category>PGPLOT</category>
      </categories>
      <tags>
        <tag>pgplot</tag>
        <tag>PGSLS</tag>
      </tags>
  </entry>
  <entry>
    <title>PGPLOT的高级应用 直方图</title>
    <url>/2011/06/12/pgplot-6-3-advanced-program-histograms/</url>
    <content><![CDATA[#直方图
函数PGHIST绘制直方图，用于显示数据的频率分布。
]]></content>
      <categories>
        <category>PGPLOT</category>
      </categories>
      <tags>
        <tag>pgplot</tag>
      </tags>
  </entry>
  <entry>
    <title>PGPLOT的高级应用 两个变量的函数</title>
    <url>/2011/06/12/pgplot-6-4-advanced-program-functions-of-two-variables/</url>
    <content><![CDATA[两个变量的函数-三维显示具有两个变量的函数 f(x,y)需要一个三维的显示。但是PGPLOT并没有提供任何的三维显示能力，但是它提供的三种方法用于显示三维数据。
等值线图函数(PGCONT 和PGCONS)可以绘制。
灰度图像函数PGGRAY与PGCONT使用类似。不像PGCONT那样绘制等值线，而是对应于每个点描述出它的灰度值，来呈现三维效果。由于大量的点需要处理，所以有些设备上这个函数的运行比较慢。
横截面函数PGHI2D绘制二维数组数列的一些列横截面。每一个横截面都隐藏在下面绘制的图像后面，以此来呈现三维效果。
]]></content>
      <categories>
        <category>PGPLOT</category>
      </categories>
      <tags>
        <tag>pgplot</tag>
        <tag>PGSLS</tag>
      </tags>
  </entry>
  <entry>
    <title>PGPLOT图形交互 简介</title>
    <url>/2011/06/12/pgplot-7-1-interactive-graph-intro/</url>
    <content><![CDATA[简介前面章节已经描述过如何绘制静态图片。
一个交互式的程序允许用户通过图像输入设备来控制图像的显示方式。对于PGPLOT的交互式性能仅支持有限的设备。
]]></content>
      <categories>
        <category>PGPLOT</category>
      </categories>
      <tags>
        <tag>pgplot</tag>
        <tag>PGSLS</tag>
      </tags>
  </entry>
  <entry>
    <title>PGPLOT图形交互 光标</title>
    <url>/2011/06/12/pgplot-7-2-interactive-graph-the-cursor/</url>
    <content><![CDATA[光标一些PGPLOT支持的图形设备中有图形光标。图形光标在视图面上表现为一个加号、十字交叉线、菱形，并且可以被与图形设备相连的鼠标、操纵杆移动。如果已经不支持这种机制，PGPLOT允许用户通过方向键来操作他的终端。
]]></content>
      <categories>
        <category>PGPLOT</category>
      </categories>
      <tags>
        <tag>pgplot</tag>
        <tag>PGSLS</tag>
      </tags>
  </entry>
  <entry>
    <title>PGPLOT图形交互 使用光标</title>
    <url>/2011/06/12/pgplot-7-3-interactive-graph-using-the-cursor/</url>
    <content><![CDATA[使用光标关于光标输入的基本程序有PGCURS和PGBAND.
两外，PGPLOT还提供了三个比较高级的关于光标输入的程序: PGOLIN, PGNCUR和PGLCUR。
这3个程序都要求设备有消除功能。
]]></content>
      <categories>
        <category>PGPLOT</category>
      </categories>
      <tags>
        <tag>pgplot</tag>
        <tag>PGSLS</tag>
      </tags>
  </entry>
  <entry>
    <title>PGPLOT图形交互 缓冲</title>
    <url>/2011/06/12/pgplot-7-4-interactive-graph-buffering/</url>
    <content><![CDATA[缓冲默认情况下， PGPLOT都会确保在视图中我们看到的图像一直是最新的，即每一个PGPLOT的子程序在将控制权返回给调用函数之前就已经更新了图像。为了改善效率，PGPLOT可以把一些指令保存到一个buffer，等到这个buffer满了再一起发送给设备。这就意味着我们看到的图像并不一定时最新的了。这种情况对于一个交互式的程序就存在一定的问题了，用户必须告诉程序什么时候更新。
为了控制buffering的输出，有3个PGPLOT 程序 (PGBBUF, PGEBUF和PGUPDT) 可用。这几个函数都没有参数。
]]></content>
      <categories>
        <category>PGPLOT</category>
      </categories>
      <tags>
        <tag>pgplot</tag>
        <tag>PGSLS</tag>
      </tags>
  </entry>
  <entry>
    <title>PGPLOT 附录a - 子函数描述</title>
    <url>/2011/06/12/pgplot-appendixs-a/</url>
    <content><![CDATA[PGPLOT 附录附录 A Subroutine Descriptions]]></content>
      <categories>
        <category>PGPLOT</category>
      </categories>
      <tags>
        <tag>pgplot</tag>
      </tags>
  </entry>
  <entry>
    <title>PGPLOT 附录 符号</title>
    <url>/2011/06/12/pgplot-appendixs-b/</url>
    <content><![CDATA[附录 B PGPLOT Symbols
B.1 Character Encoding
B.2 Additional Symbols
Figure B.0: Character Encoding
Figure B.1: Symbols 1-527
Figure B.2: Symbols 528-713
Figure B.3: Symbols 714-2017
Figure B.4: Symbols 2018-2192
Figure B.5: Symbols 2193-2400
Figure B.6: Symbols 2401-2747
Figure B.7: Symbols 2748-2932

]]></content>
      <categories>
        <category>PGPLOT</category>
      </categories>
      <tags>
        <tag>pgplot</tag>
      </tags>
  </entry>
  <entry>
    <title>PGPLOT 附录 C语言调用PGPLOT</title>
    <url>/2011/06/12/pgplot-appendixs-c/</url>
    <content><![CDATA[附录 C Calling PGPLOT from a C Program
C.1 Introduction
C.2 Using the CPGPLOT library
C.3 Limitations
C.4 Other Machine Dependencies
C.5 Examples

]]></content>
      <categories>
        <category>PGPLOT</category>
      </categories>
      <tags>
        <tag>pgplot</tag>
      </tags>
  </entry>
  <entry>
    <title>PGPLOT 附录 支持的设备</title>
    <url>/2011/06/12/pgplot-appendixs-d/</url>
    <content><![CDATA[附录 D Supported Devices
Introduction
Available Devices

]]></content>
      <categories>
        <category>PGPLOT</category>
      </categories>
      <tags>
        <tag>pgplot</tag>
      </tags>
  </entry>
  <entry>
    <title>PGPLOT 附录 写入设备</title>
    <url>/2011/06/12/pgplot-appendixs-e/</url>
    <content><![CDATA[附录 E Writing a Device Handler
E.1 Introduction
E.2 The device dispatch routine GREXEC
E.3 Device handler interface
E.4 Handler state
E.5 Summary of operations

]]></content>
      <categories>
        <category>PGPLOT</category>
      </categories>
      <tags>
        <tag>pgplot</tag>
      </tags>
  </entry>
  <entry>
    <title>PGPLOT 附录 安装说明</title>
    <url>/2011/06/12/pgplot-appendixs-f/</url>
    <content><![CDATA[按照参考Ubuntu/Debain/Fedora/Mac/CentOS 安装PGPLOT 
]]></content>
      <categories>
        <category>PGPLOT</category>
      </categories>
      <tags>
        <tag>pgplot</tag>
      </tags>
  </entry>
  <entry>
    <title>PGPLOT 附录 G 移植</title>
    <url>/2011/06/12/pgplot-appendixs-g/</url>
    <content><![CDATA[附录  G Porting PGPLOT
G.1 General Notes
G.2 Porting to UNIX systems

]]></content>
      <categories>
        <category>PGPLOT</category>
      </categories>
      <tags>
        <tag>pgplot</tag>
      </tags>
  </entry>
  <entry>
    <title>PGPLOT 附录</title>
    <url>/2011/06/12/pgplot-appendixs/</url>
    <content><![CDATA[PGPLOT 附录
附录 A 子函数描述
附录 B 符号 
附录 C C语言调用PGPLOT
附录 D 支持的设备
附录 E 写入设备
附录 F 安装说明
附录  G PGPLOT移植

]]></content>
      <categories>
        <category>PGPLOT</category>
      </categories>
      <tags>
        <tag>pgplot</tag>
      </tags>
  </entry>
  <entry>
    <title>PGPLOT 在C 中的使用</title>
    <url>/2011/06/12/pgplot-c/</url>
    <content><![CDATA[C的使用每个函数都有其对应的C语言的标准，基本上都是在函数名前加上一个c，就像python接口类型，是每个函数名前加上一个p。
在写C语言调用PGPLOT的时候，需要包含以下头文件：
#include "cpgplot.h"
]]></content>
      <categories>
        <category>PGPLOT</category>
      </categories>
      <tags>
        <tag>pgplot</tag>
        <tag>PGSLS</tag>
      </tags>
  </entry>
  <entry>
    <title>PGPLOT cpgarro绘制箭头</title>
    <url>/2013/04/26/pgplot-cpgarro/</url>
    <content><![CDATA[PGARRO – 绘制一个箭头对应的C函数为
void cpgarro(float x1, float y1, float x2, float y2);

从(X1,Y1)到(X2,Y2)绘制一个箭头。
箭头的大小取决于PGSCH的设定。默认大小为视图表面的1/40。 箭头的形状取决于PGSAH。
参数:
X1, Y1 (输入)  : 箭头尾部世界坐标X2, Y2 (输入)  : 箭头头部世界坐标
]]></content>
      <categories>
        <category>PGPLOT</category>
      </categories>
      <tags>
        <tag>cpgarro</tag>
        <tag>PGARRO</tag>
      </tags>
  </entry>
  <entry>
    <title>PGPLOT cpgask控制新页的提示</title>
    <url>/2013/04/27/pgplot-cpgask/</url>
    <content><![CDATA[PGASK – 控制新页的提示对应的C函数为
void cpgask(Logical flag);

改变PGPLOT的提示状态。如果提示状态是开的，那么PGPAGE 将提示``Type RETURN for next page:’’并等待用户输入回车以显示新的页面。初始的提示状态为了交互设备一般都是打开的，而对于非交互设备，提示状态都是关闭的。
参数:
FLAG   (输入)  : 	如果为1，并且设备为交互式设备提示状态打开。		            	如果为0，提示状态关闭。
]]></content>
      <categories>
        <category>PGPLOT</category>
      </categories>
      <tags>
        <tag>cpgask</tag>
        <tag>PGASK</tag>
      </tags>
  </entry>
  <entry>
    <title>PGPLOT cpgaxis绘制一个坐标轴</title>
    <url>/2013/04/28/pgplot-cpgaxis/</url>
    <content><![CDATA[PGAXIS – 绘制一个轴对应的C函数为
void cpgaxis(const char *opt, float x1, float y1, float x2, float y2, float v1, float v2, float step, int nsub, float dmajl, float dmajr, float fmin, float disp, float orient);

绘制一个从点(X1,Y1)到点(X2,Y2)的轴。
正常情况下，这个函数绘制一条平均细分的标准线。
如果选项’L’存在，那么将绘制对数轴。
参数:
OPT    (输入)  : 单字符选项:                   L : 绘制对数轴                   N : 标记数字坐标                   1 : 强制十进制坐标                   2 : 强制指数坐标 X1, Y1 (输入)  : 绘制坐标轴的一点 X2, Y2 (输入)  : 绘制坐标轴的另一点 V1     (输入)  : 绘制坐标轴的起始值 V2     (输入)  : 绘制坐标轴的终止值 STEP   (输入)  : 绘制坐标轴的主要刻度标记如果STEP=0.0,则有pgplot自动选择 NSUB   (输入)  : 绘制坐标轴的细分刻度标记，如果NSUB &lt;= 1,则不显示。如果是对数轴，NSUB将被忽略。 DMAJL  (输入)  : 坐标轴上方刻度标记的长度 DMAJR  (输入)  : 坐标轴下方刻度标记的长度 FMIN   (输入)  : 主刻度之间小的刻度标记 DISP   (输入)  : 底部坐标距离轴的距离 ORIENT (输入)  : 标签文本的角度方位 (0-360°).
]]></content>
      <categories>
        <category>PGPLOT</category>
      </categories>
      <tags>
        <tag>cpgask</tag>
        <tag>PGAXIS</tag>
      </tags>
  </entry>
  <entry>
    <title>PGPLOT cpgband读取有锚定点的光标位置</title>
    <url>/2011/06/12/pgplot-cpgband/</url>
    <content><![CDATA[PGBAND – 读取有锚定点的光标位置对应的C函数为
int cpgband(int mode, int posn, float xref, float yref, float *x,  float *y, char *ch_scalar);

用户读取光标位置和字符类型。位置返回值为世界坐标。如果POSN=1，PGBAND 指出光标的位置，并且允许用户使用鼠标或者方向键移动光标。在确定光标位置后，用户可以输入键盘上的一个字符；PGBAND将返回这个字符和新的光标位置。
一些交互设备提供了一些光标类型的可选项，一般而言都是较细的线条，但在绘制这个的时候，不会擦除以前的绘图。
下面的关于MODE的选项也和锚定点XREF,YREF有关。对于设备不支持光标类型的，默认MODE=0.
– 如果 MODE=0, 锚定点将被忽略，类似PGCURS.– 如果 MODE=1, 从锚定点到光标位置绘制一个直线线条– 如果 MODE=2, 从锚定点（左下角）到光标位置（右上角）绘制一个中空的矩形。当然矩形的边缘为平行或者垂直的。– 如果 MODE=3, 绘制两条扩展并横跨显示宽度的水平线，其中一条通过锚定点，另一条通过光标位置。这通常用于选择一个已知的Y轴范围。– 如果 MODE=4, 绘制两条扩展并横跨显示宽度的垂直线，其中一条通过锚定点，另一条通过光标位置。这通常用于选择一个已知的X轴范围。– 如果 MODE=5, 只绘制一条水平线条– 如果 MODE=6, 只绘制一条水平线条– 如果 MODE=7, 以光标为中心绘制一个十字交叉线
返回值:
PGBAND          : 成功返回1；无光标或失败返回0

参数:
MODE   (输入)  : 显示方式 (从0到7:上面有描述).POSN   (输入)  : 如果POSN=1, PGBAND 将把光标放在点(X,Y);如果POSN=0,光标将被放置在当前的位置XREF   (输入)  : 锚定点的x坐标YREF   (输入)  : 锚定点的y坐标X      (输入/输出) : 光标的x坐标Y      (输入/输出) : 光标的y坐标CH     (输出) : 用户输入的字符值，如果没有光标或者出现错误，返回’\0’
]]></content>
      <categories>
        <category>PGPLOT</category>
      </categories>
      <tags>
        <tag>cpgband</tag>
        <tag>PGBAND</tag>
      </tags>
  </entry>
  <entry>
    <title>PGPLOT cpgbbuf开始批处理输出</title>
    <url>/2013/04/30/pgplot-cpgbbuf/</url>
    <content><![CDATA[cpgbbuf – 开始批处理输出 (buffer)对应的C函数为 void cpgbbuf(void);
开始保存图形的输出命令到一个内部的buffer；这个函数与PGEBUF成对使用（或者这个buffer被PGUPDT清空）。这个函数极大地改进了PGPLOT的效率。PGBBUF会增加一个内部计数器，而PGEBUF减少这个内部计数器，当这个计数器降到0的时候将把buffer中的内容输出到设备。
PGBBUF和PGEBUF 应成对出现。
参数: 无
]]></content>
      <categories>
        <category>PGPLOT</category>
      </categories>
      <tags>
        <tag>cpgbbuf</tag>
        <tag>PGBBUF</tag>
        <tag>PGEBUF</tag>
        <tag>PGUPDT</tag>
      </tags>
  </entry>
  <entry>
    <title>PGPLOT cpgbeg 打开一个图形设备</title>
    <url>/2011/06/12/pgplot-cpgbeg/</url>
    <content><![CDATA[cpgbeg – 打开一个图形设备对应的C函数为
int cpgbeg(int unit, const char *file, int nxsub, int nysub);

新的程序最好用PGOPEN而不是PGBEG。PGOPEN会保留现存程序的兼容性。PGBEG不像PGOPEN，它将关闭打开的任何图形设备，所以对于它不能被用于并行的打开设备。
PGBEG 为随后的绘图打开一个图形设备或者一个文件。在调用其他子程序之前，都必须使用PGBEG或PGOPEN打开一个设备。
返回值:
 PGBEG         : 返回1成功，其他失败并在标准错误单元中显示错误信息。
参数:

UNIT  (输入)   : 0(惯例)
FILE  (输入)   : 输出设备或文件名，参考PGOPEN
NXSUB  (输入)  : 视图面细分的X轴（横向）个数
NYSUB  (输入)  : 视图面细分的Y轴（纵向）个数

PGPLOT将在屏幕上显示NXSUB * NYSUB个图像。如果有N个细分视图的话，PGPAGE 将移动到下一个子视图，而不是下一个物理页。如果NXSUB &gt; 0, PGPLOT将横向排列，如果 NXSUB &lt;0, PGPLOT将纵向排列。
如果const char *file为？，那么输出为：
Graphics device/type (? to see list, default /Xserve): ?PGPLOT v5.2.2 Copyright 1997 California Institute of TechnologyInteractive devices:   /XWINDOW   (X window window@node:display.screen/xw)   /XSERVE    (A /XWINDOW window that persists for re-use)Non-interactive file formats:   /GIF       (Graphics Interchange Format file, landscape orientation)   /VGIF      (Graphics Interchange Format file, portrait orientation)   /LATEX     (LaTeX picture environment)   /NULL      (Null device, no output)   /PNG       (Portable Network Graphics file)   /TPNG      (Portable Network Graphics file - transparent background)   /PS        (PostScript file, landscape orientation)   /VPS       (PostScript file, portrait orientation)   /CPS       (Colour PostScript file, landscape orientation)   /VCPS      (Colour PostScript file, portrait orientation)Graphics device/type (? to see list, default /Xserve):

]]></content>
      <categories>
        <category>PGPLOT</category>
      </categories>
      <tags>
        <tag>cpgbeg</tag>
        <tag>PGBEG</tag>
        <tag>PGOPEN</tag>
        <tag>PGPAGE</tag>
      </tags>
  </entry>
  <entry>
    <title>PGPLOT cpgbin – 数据的直方图</title>
    <url>/2013/05/02/pgplot-cpgbin/</url>
    <content><![CDATA[cpgbin – 数据的直方图对应的C函数为
void cpgbin(int nbin, const float *x, const float *data, Logical center);

绘制有NBIN个值的直方图。
参数:

NBIN   (输入) :  显示直方图的个数
X      (输入)  : 直方图的横坐标
DATA   (输入)  : 直方图的数据值
CENTER (输入)  : 如果为1，则X坐标位于直方图中间，为0，则坐标值位于直方图起始的位置。

]]></content>
      <categories>
        <category>PGPLOT</category>
      </categories>
      <tags>
        <tag>cpgbin</tag>
        <tag>PGBIN</tag>
      </tags>
  </entry>
  <entry>
    <title>PGPLOT cpgbox - 在视口周围的框架上标记标签</title>
    <url>/2013/05/02/pgplot-cpgbox/</url>
    <content><![CDATA[cpgbox - 在视口周围的框架上标记标签对应的C函数为
void cpgbox(const char *xopt, float xtick, int nxsub, const char *yopt, float ytick, int nysub);

给视口注释框架、轴线和数字标记等。
PGBOX 被PGENV调用，也可以独自使用。
参数:

XOPT&nbsp;&nbsp; (输入)&nbsp; : X坐标轴的选项字符串，选项可以使单个字符串或者多个字符串（没有顺序安排）
XTICK&nbsp; (输入)&nbsp; : X坐标轴的主要标记坐标间隔，如果XTICK=0.0，那么坐标间隔主要标记将有PGBOX自行选择，所以坐标轴上至少有三个主要的标记符号。-NXSUB&nbsp; (输入)&nbsp; : X坐标轴的坐标间隔之间有几个刻度值。同样如果XTICK=0.0或者NXSUB=0，这个数据将有PGBOX自行选择。
YOPT&nbsp;&nbsp; (输入)&nbsp; : Y坐标轴的选项字符串，选项可以使单个字符串或者多个字符串（没有顺序安排）
YTICK&nbsp; (输入)&nbsp; : Y坐标轴的主要标记坐标间隔，如果XTICK=0.0，那么坐标间隔主要标记将有PGBOX自行选择，所以坐标轴上至少有三个主要的标记符号。
NYSUB&nbsp; (输入)&nbsp; : Y坐标轴的坐标间隔之间有几个刻度值。同样如果YTICK=0.0或者NYSUB=0，这个数据将有PGBOX自行选择。

选项 (参数XOPT和YOPT):

A : 绘制坐标轴(X坐标轴为水平线条Y=0,Y坐标轴为水平线条X=0)
B : 绘制框架的左（Y）下（X）边缘
C : 绘制框架的右（Y）上（X）边缘
G : 绘制网格线条
I : 将刻度标记放置于视口的外部而不是内部
L : 对数形式标记坐标轴
N : 在主要的间隔上（X轴下方，Y轴左方）标记数值
P : 扩展主要间隔的刻度标记超出视口，如果选项中有I，这个就可以忽略
M : 在非常规的地方做出数值标记（X轴上方，Y轴右方）
T : 在主要坐标间隔上做出刻度标记


S : 画出主要间隔的分割的小的刻度标记
V : 垂直放置数值标记，只是用于Y轴，默认为平行于Y坐标轴
1 : 强制十进制形式标记
2 : 强制指数形式标记



为了得到一个完整的框架，XOPT和YOPT必须都指定选项BC。
在调用PGENV 是，通过调用PGBOX, 可以通过参数AXIS来设置XOPT和YOPT，两者关系如下：
-1: ‘BC’, 0: ‘BCNST’, 1: ‘ABCNST’, 2: ‘ABCGNST’.
对指数坐标轴而言，主要间隔一直为1.0。如果希望坐标轴以时间或角度为单位，可以调用PGTBOX。
]]></content>
      <categories>
        <category>PGPLOT</category>
      </categories>
      <tags>
        <tag>cpgbox</tag>
        <tag>PGBOX</tag>
      </tags>
  </entry>
  <entry>
    <title>PGPLOT cpgclos – 关闭选定的图形设备</title>
    <url>/2013/05/05/pgplot-cpgclos/</url>
    <content><![CDATA[PGCLOS – 关闭选定的图形设备对应的C函数为
void cpgclos(void);

关闭当前选定的图形设备。在设备关闭后，如果需要再次绘图，需要用PGSLCT选择另一个设备或者使用PGOPEN重新打开一个设备。如果调用PGCLOS的请求被忽略，一些图像可能会丢失。[这个函数实在PGPLOT 5.1.0.版本中添加了，老版本用PGEND 代替。]
参数: 无
]]></content>
      <categories>
        <category>PGPLOT</category>
      </categories>
      <tags>
        <tag>PGOPEN</tag>
        <tag>cpgclos</tag>
        <tag>PGCLOS</tag>
        <tag>PGEND</tag>
      </tags>
  </entry>
  <entry>
    <title>PGPLOT cpgconb 绘制等高线图</title>
    <url>/2013/05/06/pgplot-cpgconb/</url>
    <content><![CDATA[cpgconb 绘制等高线图对应的C函数为
void cpgconb(const float *a, int idim, int jdim, int i1, int i2,  int j1, int j2, const float *c, int nc, const float *tr, float blank);

绘制出一个数组的等高线图。这个函数与PGCONS基本相同，除了多了一个有参数blank定义的“魔数”，可能会导致等高线图有缺口。这个函数对大部分的数据测量都是比较有用的，but not all of the points of a grid.
参数:

A      (输入)  : 数组.
IDIM   (输入)  :数组A的一维大小
JDIM   (输入)  : 数组A的二维大小
I1,I2  (输入)  : 准备绘制成等高线的第一维索引的范围
J1,J2  (输入)  : 准备绘制成等高线的第二维索引的范围.
C      (输入)  : 等高线水平数组(与数组A有相同的单位); 尺寸至少为NC.
NC     (输入)  : 等高线水平的数字(小于等于C的尺寸). 这个值的绝对值用于对函数PGCONT的兼容，所以这个值的符号是很重要的。
TR     (输入)  : 定义从I，J网格向世界坐标转换的数组。点A(I,J)的世界坐标由下列公式给出：

X = TR(1) + TR(2)*I + TR(3)*JY = TR(4) + TR(5)*I + TR(6)*J通常TR(3) 和TR(5) 均为0，除非这个坐标变换包含旋转或者修剪。


BLANK   (输入) : 数组A中精确等于这个值的元素将被忽略。


]]></content>
      <categories>
        <category>PGPLOT</category>
      </categories>
      <tags>
        <tag>cpgconb</tag>
        <tag>PGCONB</tag>
        <tag>PGCONS</tag>
      </tags>
  </entry>
  <entry>
    <title>PGPLOT cpgconb 绘制等高线图</title>
    <url>/2013/05/06/pgplot-cpgcurs/</url>
    <content><![CDATA[cpgcurs – 读取光标位置对应的C函数为
int cpgcurs(float *x, float *y, char *ch_scalar);

读取光标位置和用户的输入。在用户移动光标时输入一个字符。PGCURS就可以返回当前的光标值和字符。
返回值:

PGCURS         : 如果调用成功返回1；如果没有光标或其他错误返回0。

参数:

X      (输入/输出) : 光标的x坐标
Y      (输入/输出) : 光标的y坐标
CH     (输出) : 用户输入的字符，如果没有光标或其他错误返回’\0’

交互式程序比较常用
]]></content>
      <categories>
        <category>PGPLOT</category>
      </categories>
      <tags>
        <tag>cpgcurs</tag>
        <tag>PGCURS</tag>
      </tags>
  </entry>
  <entry>
    <title>PGPLOT cpgenv 设置窗口、视口及标签框架</title>
    <url>/2013/05/21/pgplot-cpgenv/</url>
    <content><![CDATA[cpgenv 设置窗口、视口及标签框架对应的C函数为
void cpgenv(float xmin, float xmax, float ymin, float ymax, int just, int axis);

设置PGPLOT “作图环境Environment”。PGENV为随后的PGPT，PGLINE 构建比例坐标。绘图将前进到一个新页或面板（如果有需要可以清空屏幕）。如果”提示状态”是打开的(参考PGASK)，在清空屏幕前，需要用户的确认。通过参数AXIS可以绘制需要的方框，坐标轴,标签等。
参数:

XMIN   (输入)  : 视口左下角的x坐标
XMAX   (输入)  : 视口右上角的x坐标（XMAX可以比XMIN小).
YMIN   (输入)  : 视口左下角的y坐标
YMAX   (输入)  : 视口右上角的y坐标（YMAX可以比YMIN小)
JUST   (输入)  : 如果 JUST=1,x和y轴的坐标尺度是相同的，如果为其他值，缩放比例无关。
AXIS   (输入)  : 控制坐标, 刻度标记等
AXIS = -2 : 不绘制方框、坐标和刻度;
AXIS = -1 : 只绘制方框;
AXIS =  0 : 绘制方框和刻度标记
AXIS =  1 : 与AXIS=0类似，不过添加了显示坐标轴(X=0, Y=0);
AXIS =  2 : 与AXIS=1类似，不过添加了主刻度的网格线
AXIS = 10 : X轴的方框和刻度用对数表示;
AXIS = 20 : Y轴的方框和刻度用对数表示;
AXIS = 30 : X、Y轴的方框和刻度均用对数表示.



对于其他的axis选项，使用函数PGBOX。PGENV 可以通过设置环境变量参数PGPLOT_ENVOPT 来使用一些PGBOX的属性。
例如:

PGPLOT_ENVOPT=P      ! 越出的刻度标记
PGPLOT_ENVOPT=I      ! 反转刻度标记
PGPLOT_ENVOPT=IV     ! 反转刻度标记、y垂直标记

]]></content>
      <categories>
        <category>PGPLOT</category>
      </categories>
      <tags>
        <tag>cpgenv</tag>
        <tag>PGASK</tag>
        <tag>PGBOX</tag>
        <tag>PGENV</tag>
        <tag>PGPT</tag>
        <tag>PGLINE</tag>
        <tag>PGPLOT_ENVOPT</tag>
      </tags>
  </entry>
  <entry>
    <title>PGPLOT cpgconb 绘制等高线图</title>
    <url>/2013/05/20/pgplot-cpgerrb/</url>
    <content><![CDATA[PGERRB – horizontal or vertical error bar对应的C函数为
void cpgerrb(int dir, int n, const float *x, const float *y, const float *e, float t);

SUBROUTINE PGERRB (DIR, N, X, Y, E, T)INTEGER DIR, NREAL X(*), Y(*), E(*)REAL T

绘制误差图，方向由DIR指定，这个函数只是绘制误差图，如果需要标注误差值的点，可以使用PGPT函数。
测试数据为：
static float xs[] = {0.0, 1.0, 2.0, 3.0, 4.0, 5.0 ,6.0,7.0,8.0,9.0,10.0};static float ys[] = {0.5, 1.0, 1.5,2.0, 2.5, 3.0, 3.5 ,4.0,4.5,5.0,5.5,6.0};static float err[] = {1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0};

参数说明

DIR    (输入)  : 绘制数据点误差图的方向。
单方向:
DIR为1时，绘制+X (X to X+E);
DIR为2时，绘制+Y (Y to Y+E);
DIR为3时，绘制-X (X to X-E);
DIR为4时，绘制-Y (Y to Y-E);
双方向：
DIR为5时，绘制+/-X (X-E to X+E);
DIR为6时，绘制+/-Y (Y-E to Y+E);
N      (输入)  :绘制误差图的数目
X      (输入)  : 数据的x坐标
Y      (输入)  : 数据的y坐标
E      (输入)  : 绘制数据误差图的值
T      (输入)  : 误差图终端的长度，如果T = 0.0，将不绘制终端

注: X, Y和E的维数必须大于或等于N. 如果 N 为1,那么 X, Y和E就应该是同等数量的变量或表达式。
]]></content>
      <categories>
        <category>PGPLOT</category>
      </categories>
      <tags>
        <tag>cpgpt</tag>
        <tag>cpgerrb</tag>
        <tag>PGERRB</tag>
      </tags>
  </entry>
  <entry>
    <title>PGPLOT cpgiden – 在图形的底端标记上用户名、日期和时间</title>
    <url>/2013/05/30/pgplot-cpgiden/</url>
    <content><![CDATA[PGIDEN –在图形的底端标记上用户名、日期和时间对应的C函数为
void cpgiden(void);

在图形的底端标记上用户名、日期和时间
参数: 无
]]></content>
      <categories>
        <category>PGPLOT</category>
      </categories>
      <tags>
        <tag>cpgiden</tag>
        <tag>PGIDEN</tag>
      </tags>
  </entry>
  <entry>
    <title>PGPLOT cpglab</title>
    <url>/2013/04/30/pgplot-cpglab/</url>
    <content><![CDATA[PGLAB – x轴、y轴以及标题对应的C函数为
void cpglab(const char *xlbl, const char *ylbl, const char *toplbl);

在视口的外面做标签。这个函数是PGMTXT的简易接口。如果PGLAB描述的信息不够充分，还需要使用PGMTXT。
参数:
XLBL   (输入) : x轴的标签(视口底端居中)YLBL   (输入) : y轴的标签(视口左端居中，垂直描述)TOPLBL (输入) : 整个图像的标签 (视口上方居中)


]]></content>
      <categories>
        <category>PGPLOT</category>
      </categories>
      <tags>
        <tag>cpglab</tag>
        <tag>PGLAB</tag>
        <tag>PGMTXT</tag>
      </tags>
  </entry>
  <entry>
    <title>PGPLOT cpglcur – 使用光标绘制线条</title>
    <url>/2013/06/03/pgplot-cpglcur/</url>
    <content><![CDATA[cpglcur – 使用光标绘制线条对应的C函数为
void cpglcur(int maxpt, int *npt, float *x, float *y);

用户可以通过光标来绘制多线条的交互函数。这个函数允许用户添加或者删除顶点，顶点通过直线连接。
参数:

MAXPT  (输入)  : 能被接受的点的最大值
NPT    (输入/输出) : 输入点的数目，第一次调用时为0
X      (输入/输出) :数组的x坐标 (尺寸至少为MAXPT).
Y      (输入/输出) :数组的y坐标(尺寸至少为MAXPT).

注:

光标选择的点将返回到一个数组中，顺序与输入的类似。
使用命令：


A (Add)  -在当前光标添加一个点
D (Delete) –删除上一次输入的点 delete last-entered point.
X (eXit)   - 离开子程序

  
]]></content>
      <categories>
        <category>PGPLOT</category>
      </categories>
      <tags>
        <tag>cpglcur</tag>
      </tags>
  </entry>
  <entry>
    <title>PGPLOT cpgldev –在标准输出上列出可用的设备类型</title>
    <url>/2013/06/03/pgplot-cpgldev/</url>
    <content><![CDATA[cpgldev –在标准输出上列出可用的设备类型对应的C函数为
void cpgldev(void);

列出当前PGPLOT安装可用的设备列表。
参数: 无.
]]></content>
      <categories>
        <category>PGPLOT</category>
      </categories>
      <tags>
        <tag>ps</tag>
        <tag>xterm</tag>
        <tag>cpgldev</tag>
        <tag>PGLDEV</tag>
        <tag>cps</tag>
        <tag>vcps</tag>
        <tag>vcs</tag>
        <tag>xserve</tag>
        <tag>xwindow</tag>
      </tags>
  </entry>
  <entry>
    <title>PGPLOT cpglen – 计算字符串的长度（不同单位）</title>
    <url>/2013/06/04/pgplot-cpglen/</url>
    <content><![CDATA[cpglen – 计算字符串的长度（不同单位）对应的C函数为
void cpglen(int units, const char *string, float *xl, float *yl);

计算出字符在x和y方向上的长度
输入UNITS    :  0 =&gt; 标准化的设备坐标            1 =&gt; 返回英寸            2 =&gt; 返回毫米            3 =&gt; 返回绝对的设备坐标            4 =&gt; 返回世界坐标            5 =&gt; 返回当前视口大小的比例STRING   :  感兴趣的字符串

输出XL       :  字符在x方向上的长度YL       :  字符在y方向上的长度
]]></content>
      <categories>
        <category>PGPLOT</category>
      </categories>
      <tags>
        <tag>cpglen</tag>
        <tag>PGLEN</tag>
      </tags>
  </entry>
  <entry>
    <title>PGPLOT cpgline – 绘制一个多线段的线条</title>
    <url>/2013/06/05/pgplot-cpgline/</url>
    <content><![CDATA[cpgline – 绘制一个多线段的线条对应的C函数为
void cpgline(int n, const float *xpts, const float *ypts);

绘制多线段的比较原生态的一个函数。多线段是指一条或多条连接的线段。多线段使用当前的颜色索引、线条类型和线条宽度属性。超出视口外的将被裁减掉。
参数:

N      (输入)  : 定义线条的点数，包含N-1条线段。N应该大于1（如果是1或者小于1），将没有线段显示
XPTS   (输入)  : 标记点的x坐标
YPTS   (输入)  : 标记点的y坐标

X和Y的维数要大于等于N.
]]></content>
      <categories>
        <category>PGPLOT</category>
      </categories>
      <tags>
        <tag>cpgline</tag>
        <tag>PGLINE</tag>
      </tags>
  </entry>
  <entry>
    <title>PGPLOT cpgmove – 移动点(改变当前的点位置)</title>
    <url>/2013/06/06/pgplot-cpgmove/</url>
    <content><![CDATA[cpgmove – 移动点(改变当前的点位置)对应的C函数为
void cpgmove(float x, float y);

将当前点移动到另一个点(X,Y)的比较原生的函数。
参数:

X      (输入)  : 新点的x坐标
Y      (输入)  : 新点的y坐标

]]></content>
      <categories>
        <category>PGPLOT</category>
      </categories>
      <tags>
        <tag>cpgmove</tag>
        <tag>PGMOVE</tag>
      </tags>
  </entry>
  <entry>
    <title>PGPLOT cpgmtxt – 在视口相关位置做文本标记</title>
    <url>/2013/06/06/pgplot-cpgmtxt/</url>
    <content><![CDATA[cpgmtxt – 在视口相关位置做文本标记对应的C函数为
void cpgmtxt(const char *side, float disp, float coord, float fjust, const char *text);

在指定的地方标记文本。这个函数对于图形注解是很有用的。有个简略的使用PGLAB。文本使用当前的颜色索引值、线条宽度、字符高度和字符字体。
参数:

SIDE   (输入)  :为其中的一个字符’B’, ‘L’, ‘T’,或’R’分别代表Bottom（底端）、Left（左部）、Top（上方）和Right（右部）。 如果还包含“V”。例如’LV’或’RV’，那么字符串将垂直写。
DISP   (输入)  : 字符距离坐标轴的位置。负值在视口里面，正值在视口外面。
COORD  (输入)  : 字符在视图中的位置(整体范围在0-1之间)。
FJUST  (输入)  : 校正字符的对齐方式。如果FJUST = 0.0，字符的左端将对齐COORD; 如果 JUST = 0.5，字符的中间将对齐COORD; 如果 JUST = 1.0，字符的右端对齐COORD。其他介于0和1的值有对应的对齐位置，不过不是很有用。-TEXT   (输入) :  输入的字符。结尾的空格将被忽略，起始的空格保留。

]]></content>
      <categories>
        <category>PGPLOT</category>
      </categories>
      <tags>
        <tag>PGMTXT</tag>
        <tag>cpgmtxt</tag>
      </tags>
  </entry>
  <entry>
    <title>PGPLOT cpgopen – 打开一个图形设备</title>
    <url>/2013/06/11/pgplot-cpgopen/</url>
    <content><![CDATA[cpgopen – 打开一个图形设备对应的C函数为
int cpgopen(const char *device);

为PGPLOT的输出打开一个图形设备。如果设备打开成功，图形将输出到该设备直到使用PGSLCT选择了其他的设备或者使用PGCLOS关闭了该设备。
PGOPEN的返回值应该加以辨别是否打开成功。例如：
ISTAT = PGOPEN('plot.ps/PS')

如果 (ISTAT .LE. 0 ) STOP
DEVICE 参数的值为一个字符串，取值如下所示：

完整的设备描述形式“device/type”或者“file/type”；其中的’type’为PGPLOT支持设备类型的一种。
单纯的设备描述形式’/type’
设备描述形式’/type’被省略时，使用环境变量定义好的PGPLOT_TYPE
空字符串 (“ ”)；这种情况下，PGOPEN将使用设定好的环境变量PGPLOT_DEV。如果环境变量未定义使用’/NULL’
双引号加一个问号 (“?”)；这种情况下将提示用户键入要输出的设备类型，也可以输入？来查看设备列表。
非空字符串但是第一个字符为问号的 (比如’?Device: ‘)；这种情况下PGPLOT将给用户提示信息，不过前缀是？后面的字符串。


对于情况 (5)和 (6)，设备的类型将由输入确定。设备的类型是不区分大小写的（例如’/ps’和’/PS’是相同的）。

有效地DEVICE参数示例：

‘plot.ps/ps’, ‘dir/plot.ps/ps’, ‘“dir/plot.ps”/ps’, ‘user:[tjp.plots]plot.ps/PS’
‘/ps’      (PGPLOT默认为’PGPLOT.ps/ps’)
‘plot.ps’  (如果PGPLOT_TYPE定义为’ps’, PGPLOT将解释为’plot.ps/ps’)
‘   ‘      (取决于定义的PGPLOT_DEV)
‘?  ‘
‘?Device specification for PGPLOT: ‘[这个函数是在5.1.0版本加入的，老程序用PGBEG替代。

返回值:

PGOPEN   : 返回值（正值）将被PGSLCT使用。 如果返回0或者负值，将有错误信息输入到标准错误单元。

参数:

DEVICE  (输入) : 设备描述符（参考上面的描述）

]]></content>
      <categories>
        <category>PGPLOT</category>
      </categories>
      <tags>
        <tag>PGOPEN</tag>
        <tag>PGCLOS</tag>
        <tag>cpgopen</tag>
        <tag>PGSLCT</tag>
      </tags>
  </entry>
  <entry>
    <title>PGPLOT cpgpage – 前进到新的页面</title>
    <url>/2013/06/12/pgplot-cpgpage/</url>
    <content><![CDATA[cpgpage – 前进到新的页面对应的C函数为
void cpgpage(void);

在一个新页或者面板显示图形，如果需要也可以清空屏幕。如果“提示状态”是打开的（参考PGASK），那么清空屏幕前需要用户的确认。如果视图被PGBEG 或 PGSUBP 分成了几个子面板，PGPAGE将前进到下一个面板，如果当前的面板已经是最后一个了，那么PGPAGE将清空屏幕或者打开一个新的页。PGPAGE不会改变PGPLOT的窗口或视图，但是如果由于设备的不同，而导致的视图面的大小改变，PGPAGE将同比例改变。参数: 无
]]></content>
      <categories>
        <category>PGPLOT</category>
      </categories>
      <tags>
        <tag>PGASK</tag>
        <tag>PGBEG</tag>
        <tag>PGPAGE</tag>
        <tag>cpgpage</tag>
        <tag>PGSUBP</tag>
      </tags>
  </entry>
  <entry>
    <title>PGPLOT cpgpanl – 切换到当前视图的不同面板</title>
    <url>/2013/06/13/pgplot-cpgpanl/</url>
    <content><![CDATA[cpgpanl – 切换到当前视图的不同面板对应的C函数为
void cpgpanl(int nxc, int nyc);

开始在一个不同的面板作图。如果视口被PGBEG 或者PGSUBP划分为几个子窗口，这个函数可以移动到一个不同的面板。

注：PGPLOT不记录使用哪个视口和窗口。需要通过PGPANL来设定。PGPLOT不清空这个面板，在调用PGPANL再调用PGERAS来清空面板。

参数:

IX     (输入)  : 水平索引值
IY     (输入)  : 垂直索引值

]]></content>
      <categories>
        <category>PGPLOT</category>
      </categories>
      <tags>
        <tag>PGBEG</tag>
        <tag>PGSUBP</tag>
        <tag>cpgpanl</tag>
        <tag>PGPANL</tag>
        <tag>PGERAS</tag>
      </tags>
  </entry>
  <entry>
    <title>PGPLOT cpgpap – 改变视图表面的大小</title>
    <url>/2013/06/12/pgplot-cpgpap/</url>
    <content><![CDATA[cpgpap – 改变视图表面的大小对应的C函数为
void cpgpap(float width, float aspect);

这个函数用于改变视图的大小到一个指定的宽度和纵横比的视图。获取一个比标准大小还小的视图总是可行的，如果比标准大小大，则只适用于一些设备。这个函数应该在PGBEG之后或者PGPAGE之前调用。随后的图形将采用设置的属性，直到下一次调用PGPAP。
参数:

WIDTH  (输入)  : 视图图形的宽度（英寸计），如果 WIDTH=0.0，PGPAP 将获得最大与ASPECT参数一致的视图表面。
ASPECT (输入)  : 视图表面的综合比 (height/width)，ASPECT=1.0正方形， ASPECT&lt;1.0水平型的矩形，ASPECT&gt;1.0垂直型的矩形。

]]></content>
      <categories>
        <category>PGPLOT</category>
      </categories>
      <tags>
        <tag>PGBEG</tag>
        <tag>PGPAGE</tag>
        <tag>cpgpap</tag>
        <tag>PGPAP</tag>
      </tags>
  </entry>
  <entry>
    <title>PGPLOT cpgtext</title>
    <url>/2013/06/06/pgplot-cpgtext/</url>
    <content><![CDATA[cpgtextcpgtext(5.0, 5.0, "a Text String \\u5\\d");cpgtext(5.0, 6.0, "\\faa text string");cpgtext(5.0, 7.0, "\\faa text string");cpgtext(5.0, 8.0, "\\faa text string");

]]></content>
      <categories>
        <category>PGPLOT</category>
      </categories>
      <tags>
        <tag>cpgtext</tag>
        <tag>PGTEXT</tag>
      </tags>
  </entry>
  <entry>
    <title>PGPLOT 非标准函数</title>
    <url>/2013/06/06/pgplot-non-standard/</url>
    <content><![CDATA[
PGADVANCE –非标准的PGPAGE
PGBEGIN –非标准的PGBEG
PGCURSE –非标准的PGCURS
PGLABEL –非标准的PGLAB
PGMTEXT –非标准的PGMTXT
PGNCURSE –非标准的PGNCUR
PGPAPER –非标准的PGPAP
PGPOINT –非标准的PGPT
PGPTEXT –非标准的PGPTXT
PGVPORT –非标准的PGSVP
PGVSIZE –非标准的PGVSIZ
PGVSTAND –非标准的PGVSTD
PGWINDOW –非标准的PGSWIN

]]></content>
      <categories>
        <category>PGPLOT</category>
      </categories>
      <tags>
        <tag>PGBEG</tag>
        <tag>PGPAGE</tag>
        <tag>PGCURS</tag>
        <tag>PGPT</tag>
        <tag>PGLAB</tag>
        <tag>PGMTXT</tag>
        <tag>PGPAP</tag>
        <tag>PGADVANCE</tag>
        <tag>PGBEGIN</tag>
        <tag>PGCURSE</tag>
        <tag>PGLABEL</tag>
        <tag>PGMTEXT</tag>
        <tag>PGNCUR</tag>
        <tag>PGNCURSE</tag>
        <tag>PGPAPER</tag>
        <tag>PGPOINT</tag>
        <tag>PGPTXT</tag>
        <tag>PGPTEXT</tag>
        <tag>PGSVP</tag>
        <tag>PGVPORT</tag>
        <tag>PGVSIZ</tag>
        <tag>PGVSIZE</tag>
        <tag>PGVSTD</tag>
        <tag>PGVSTAND</tag>
        <tag>PGSWIN</tag>
        <tag>PGWINDOW</tag>
      </tags>
  </entry>
  <entry>
    <title>Python学习</title>
    <url>/2010/08/06/python-README/</url>
    <content><![CDATA[Python大纲
Python-history Python历史
Python-IDE Python开发环境IDE
Python-helloworld Python第一个程序
Python-comment Python注释
Python-filetype Python文件类型
Python-name Python文件名
Python-variable Python变量与常量

Python 参考书
零基础学Python
https://www.runoob.com/python3/python3-tutorial.html

]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>Python argparse</title>
    <url>/2018/02/06/python-argparse/</url>
    <content><![CDATA[argsparse是python的命令行解析的标准模块，内置于python，不需要安装。这个库可以让我们直接在命令行中就可以向程序中传入参数并让程序运行。
argparse定义四个步骤

导入argparse包 ——import argparse
创建一个命令行解析器对象 ——创建 ArgumentParser() 对象
给解析器添加命令行参数 ——调用add_argument() 方法添加参数
解析命令行的参数 ——使用 parse_args() 解析添加的参数

举个例子如下：
.. literalinclude:: ../../src/python-argparse.py
默认输出如下所示：
.. code::bash
  $ python src/python-argparse.py  Namespace(name=’Zhang San’, age=18)  Name : Zhang San Age :  18
  sgguo@LENOVO-P71-LEO MINGW64 ~/OneDrive/mycode/3-Minutes-Programming/python (master)  $ python src/python-argparse.py –help  usage: python-argparse.py [-h] [–name NAME] [–age AGE]
  Demo of argparse
  optional arguments:    -h, –help   show this help message and exit    –name NAME    –age AGE
]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>argparse</tag>
        <tag>效率包</tag>
      </tags>
  </entry>
  <entry>
    <title>Python 参考书</title>
    <url>/2012/02/06/python-books/</url>
    <content><![CDATA[Python参考书基础进阶专题]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>book</tag>
      </tags>
  </entry>
  <entry>
    <title>Python class类</title>
    <url>/2012/02/06/python-class/</url>
    <content><![CDATA[类和实例类和对象是面向对象编程的两个主要方面。
其中类创建一个新类型，而对象是这个类的实例，类使用class关键字创建。
__init__方法属于Python语言的构造函数，一个类只能有一个init方法，用于初始化类及其变量。
类的属性和方法
类的方法：在类的内部使用def关键字定义一个方法，与一般函数不同，需要包含self参数，且为第一个参数
类的私有方法：在类的内部使用，命名格式为__private_method，以两个下划线开始，不能在类的外部调用，只能在内部调用
类的私有属性：在类的内部使用，也是以两个下划线开头

类的动态属性如果不希望类的某些属性被悄悄滴访问、赋值和修改，希望在被访问、赋值和修改的时候能得到一些通知，这时可以使用函数property，函数原型为：
property([fget[,fset[,fdel[,doc]]]])

有两种方法可以完成这个工作，分别如下所示，其中第二种相对而言更加灵活、方便和简单，推荐使用。
使用类的属性class MyClass(object):    def __init__(self):        self._param = None    def getParam(self):        print('get param : %s' % self._param)        return self._param    def setParam(self, value):        print('set param : %s' % self._param)        self._param = value    def delParam(self):        print('del param : %s' % self._param)        del self._param    parameter = property(getParam, setParam, delParam)if __name__ == '__main__':    cls = MyClass()    cls.parameter = 1024    print('current param : %s ' % cls.parameter)    del cls.parameter



使用@property访问类的属性class MyClass(object):    def __init__(self):        self._param = None    @property    def param(self):        print('get param : %s' % self._param)        return self._param    @param.setter    def param(self, value):        print('set param : %s' % self._param)        self._param = value    @param.deleter    def param(self):        print('del param : %s' % self._param)        del self._paramif __name__ == '__main__':    cls = MyClass()    cls.param = 1024    print('current param : %s ' % cls.param)    del cls.param

]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>class</tag>
        <tag>instance</tag>
      </tags>
  </entry>
  <entry>
    <title>Python 注释</title>
    <url>/2012/02/06/python-comment/</url>
    <content><![CDATA[Python 注释Python的注释方法如下：

使用#开头
使用三个单引号’’’ 主要用在块注释上
使用三个双引号””” 主要用在块注释上

]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>comment</tag>
      </tags>
  </entry>
  <entry>
    <title>python 虚拟环境conda</title>
    <url>/2018/01/23/python-conda/</url>
    <content><![CDATA[Python 虚拟环境 conda更新镜像更新地址$ conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/$ conda config --set show_channel_urls yes



使用Conda 是一个开源的软件包管理系统和环境管理系统，用于安装多个版本的软件包及其依赖关系，并在它们之间轻松切换。
安装可以下载一个科学计算包anaconda，怕麻烦的人可以直接安装，自带很多必须包
创建
$ conda create --name AI python=3.7#or$ conda create --prefix /the/path/AI python=3.7
使用
$ conda env list #查看当前存在的虚拟环境$ conda activate py3 #激活虚拟环境 activate py3 windows下# or$ conda activate /home/share/AI$ conda install numpy #安装包$ source deactivate #退出虚拟环境$ conda remove -n py3 --all #删除虚拟环境

共享环境导出和使用requirement.txt文件$ conda list -e &gt; requirements.txt$ conda install --yes --file requirements.txt





共享环境导出和使用yml文件$ conda env export &gt; /path/to/environment.yaml#其中-f表示你要导出文件在本地的路径，所以/path/to/environment.yml要换成你本地的实际路径$ conda env update -f=/path/to/environment.yml# 安装yml文件$ conda env create -f environment.yaml



Troubleshooting当电脑上安装了Python2 和 python3时，有如下错误：
raise ImportError('This package should not be accessible on Python 3. 'ImportError: This package should not be accessible on Python 3. Either you are trying to run from the python-future src folder or your installation of python-future is corrupted

这大概率是因为环境变量PYTHONPATH的原因，重置该环境变量即可。
unset PYTHONPATH

即可解决
]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>conda</tag>
      </tags>
  </entry>
  <entry>
    <title>Python 的数据类型</title>
    <url>/2010/08/06/python-datatype/</url>
    <content><![CDATA[Python的数据类型数字字符串]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>数字</tag>
        <tag>字符串</tag>
      </tags>
  </entry>
  <entry>
    <title>Python Django 教程1</title>
    <url>/2017/01/23/python-django-tutorial01/</url>
    <content><![CDATA[创建第一个Django应用检查django是否安装及版本
$ python -m django --version

创建项目$ django-admin startproject mysite

创建目录如下所示：
➜  django git:(master) ✗ tree mysitemysite├── manage.py└── mysite    ├── __init__.py    ├── settings.py    ├── urls.py    └── wsgi.py

运行服务器$ python manage.py runserver

如果出现下面的问题，可以通过migrate来解决。
You have 13 unapplied migration(s). Your project may not work properly until you apply the migrations for app(s): admin, auth, contenttypes, sessions.Run 'python manage.py migrate' to apply them.


mysite git:(master) ✗ python manage.py migrate

修改端口默认情况下为8000端口，可以通过加上port口来更改，比如更改为8080，命令如下
$ python manage.py runserver 8080

在修改代码后，不需要重启runserver，因为会重载代码，除非新增了文件。
创建APP应用➜  mysite git:(master) ✗ python manage.py startapp polls

创建了一个polls目录，列表如下：
polls/    __init__.py    admin.py    apps.py    migrations/        __init__.py    models.py    tests.py    views.py

编写第一个视图编辑文件polls/views.py，内容如下：
from django.http import HttpResponsedef index(request):    return HttpResponse("Hello, world. You're at the polls index.")

为了使用这个视图，我们需要在polls文件夹新建一个urls.py文件，用来映射该视图。
其中polls/urls.py的内容如下所示：
from django.urls import pathfrom . import viewsurlpatterns = [    path('', views.index, name='index'),]

接下来需要在mysite/urls.py中指定polls.urls文件，内容如下：
from django.urls import include, pathfrom django.contrib import adminurlpatterns = [    path('polls/', include('polls.urls')),    path('admin/', admin.site.urls),]
]]></content>
      <categories>
        <category>Python</category>
        <category>Django</category>
      </categories>
      <tags>
        <tag>django</tag>
        <tag>django-admin</tag>
        <tag>startproject</tag>
        <tag>startapp</tag>
        <tag>runserver</tag>
        <tag>migrate</tag>
        <tag>migration</tag>
      </tags>
  </entry>
  <entry>
    <title>Python Django 教程2</title>
    <url>/2017/01/23/python-django-tutorial02/</url>
    <content><![CDATA[Python Django 教程2本教程将将创建数据库，模型并介绍自动生成的管理员站点。
创建数据库数据库默认设置在mysite/settings.py文件中的DATABASES中，其中为ENGINE和NAME字段，可以自行更改。
使用
$ python manage.py migrate

来生成settings.py文件中需要的数据库表。
创建模型修改文件polls/models.py文件内容如下：
from django.db import modelsclass Question(models.Model):    question_text = models.CharField(max_length=200)    pub_date = models.DateTimeField('date published')class Choice(models.Model):    question = models.ForeignKey(Question, on_delete=models.CASCADE)    choice_text = models.CharField(max_length=200)    votes = models.IntegerField(default=0)

激活模型为了可以访问到该模型，需要在INSTLLED_APP参数设置中，添加polls，文件mysite/settings.py内容如下所示：
INSTALLED_APPS = [    'polls.apps.PollsConfig',    'django.contrib.admin',    'django.contrib.auth',    'django.contrib.contenttypes',    'django.contrib.sessions',    'django.contrib.messages',    'django.contrib.staticfiles',]


其中polls.aps.PollsConfig位于polls/apps.py文件中

然后使用下述命令来让Django包含polls应用。
$ python manage.py makemigrations polls

使用
$ python manage.py migrate

来生成settings.py文件中需要的数据库表。
创建模型的三个步骤

Change your models (in models.py).
Run python manage.py makemigrations to create migrations for those changes
Run python manage.py migrate to apply those changes to the database.

玩转API接口$ python manage.py shell

增加易读接口返回
from django.db import modelsclass Question(models.Model):    # ...    def __str__(self):        return self.question_textclass Choice(models.Model):    # ...    def __str__(self):        return self.choice_text

Django 管理 Admin创建管理员账号$ python manage.py createsuperuser

启动服务器$ python manage.py runserver

Now, open a Web browser and go to “/admin/” on your local domain – e.g., http://127.0.0.1:8000/admin/
让poll在admin中可编辑，编辑polls/admin.py文件内容如下：
from django.contrib import adminfrom .models import Questionadmin.site.register(Question)
]]></content>
      <categories>
        <category>Python</category>
        <category>Django</category>
      </categories>
      <tags>
        <tag>models</tag>
        <tag>django</tag>
        <tag>django-admin</tag>
        <tag>runserver</tag>
        <tag>migrate</tag>
        <tag>migration</tag>
        <tag>DATABASES</tag>
      </tags>
  </entry>
  <entry>
    <title>Python Django 教程3</title>
    <url>/2017/01/23/python-django-tutorial03/</url>
    <content><![CDATA[Python Django 教程3本教程将聚焦于创建公共接口-视图。
Writing more views更新views页面polls/views.py
def detail(request, question_id):    return HttpResponse("You're looking at question %s." % question_id)def results(request, question_id):    response = "You're looking at the results of question %s."    return HttpResponse(response % question_id)def vote(request, question_id):    return HttpResponse("You're voting on question %s." % question_id)

Write views that actually do somethingA shortcut: render()Raising a 404 errorA shortcut: get_object_or_404()Use the template systemRemoving hardcoded URLs in templatesNamespacing URL names]]></content>
      <categories>
        <category>Python</category>
        <category>Django</category>
      </categories>
      <tags>
        <tag>models</tag>
        <tag>django</tag>
        <tag>django-admin</tag>
        <tag>runserver</tag>
        <tag>migrate</tag>
        <tag>migration</tag>
        <tag>DATABASES</tag>
      </tags>
  </entry>
  <entry>
    <title>Python Django 教程4</title>
    <url>/2017/01/23/python-django-tutorial04/</url>
    <content><![CDATA[Python Django 教程4本教程将主要关注简单的表单处理以及如何对代码进行优化。
编写一个简单的表单使用通用视图：代码还是少点好改良 URLconf改良视图]]></content>
      <categories>
        <category>Python</category>
        <category>Django</category>
      </categories>
      <tags>
        <tag>models</tag>
        <tag>django</tag>
        <tag>django-admin</tag>
        <tag>runserver</tag>
        <tag>migrate</tag>
        <tag>migration</tag>
        <tag>DATABASES</tag>
      </tags>
  </entry>
  <entry>
    <title>Python Django 教程5</title>
    <url>/2017/01/23/python-django-tutorial05/</url>
    <content><![CDATA[Python Django 教程5本教程将主要为Django应用创建自动化测试。
]]></content>
      <categories>
        <category>Python</category>
        <category>Django</category>
      </categories>
      <tags>
        <tag>models</tag>
        <tag>django</tag>
        <tag>django-admin</tag>
        <tag>runserver</tag>
        <tag>migrate</tag>
        <tag>migration</tag>
        <tag>DATABASES</tag>
      </tags>
  </entry>
  <entry>
    <title>Python Django 教程6</title>
    <url>/2017/01/23/python-django-tutorial06/</url>
    <content><![CDATA[Python Django 教程6本教程将主要为Django应用添加一张样式表和一张图片。
样式表创建下列代码：
polls/static/polls/style.css
li a {    color: green;}

下一步，在polls/templates/polls/index.html的顶端添加如下内容 ：
polls/templates/polls/index.html{% load staticfiles %}&lt;link rel="stylesheet" type="text/css" href="{% static 'polls/style.css' %}" /&gt;


添加背景图片我们将创建一个子目录来存放图片。 在polls/static/polls/目录中创建一个 images 子目录。在这个目录中，放入一张图片background.gif。换句话，将你的图片放在 polls/static/polls/images/background.gif。
然后，向你的样式表添加（polls/static/polls/style.css）：
body {    background: white url("images/background.gif") no-repeat right bottom;}

重新加载http://localhost:8000/polls/，你应该在屏幕的右下方看到载入的背景图片。
]]></content>
      <categories>
        <category>Python</category>
        <category>Django</category>
      </categories>
      <tags>
        <tag>models</tag>
        <tag>django</tag>
        <tag>django-admin</tag>
        <tag>runserver</tag>
        <tag>migrate</tag>
        <tag>migration</tag>
        <tag>DATABASES</tag>
      </tags>
  </entry>
  <entry>
    <title>Python 如何提取python中的一列</title>
    <url>/2012/11/24/python-extract-one-column/</url>
    <content><![CDATA[如何提取python中的一列&gt;&gt;&gt; arr[[10, 11, 12, 13, 14, 15, 16, 17, 18, 19], [11, 12, 13, 14, 15, 16, 17, 18, 19, 20], [12, 13, 14, 15, 16, 17, 18, 19, 20, 21], [13, 14, 15, 16, 17, 18, 19, 20, 21, 22], [14, 15, 16, 17, 18, 19, 20, 21, 22, 23], [15, 16, 17, 18, 19, 20, 21, 22, 23, 24], [16, 17, 18, 19, 20, 21, 22, 23, 24, 25], [17, 18, 19, 20, 21, 22, 23, 24, 25, 26], [18, 19, 20, 21, 22, 23, 24, 25, 26, 27], [19, 20, 21, 22, 23, 24, 25, 26, 27, 28], [20, 21, 22, 23, 24, 25, 26, 27, 28, 29], [21, 22, 23, 24, 25, 26, 27, 28, 29, 30]]&gt;&gt;&gt; l = [x[0] for x in arr]&gt;&gt;&gt; l[10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]&gt;&gt;&gt;
]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>column</tag>
      </tags>
  </entry>
  <entry>
    <title>Python 的文件类型</title>
    <url>/2010/08/06/python-filetype/</url>
    <content><![CDATA[Python的文件类型源代码后缀以py结束的文件，比如下面的文件python_helloworld.py。
if __name__ == "__main__":    print ("Hello World")

字节代码可以通过两种方法来编译为字节代码，直接用下面的命令或者脚本，执行后会生成一个后缀为pyc的文件
转换命令$ python -m py_compile python_helloworld.py

转换脚本import py_compilepy_compile.compile('python_helloworld.py')

优化代码扩展名为pyo，o的意思就是优化过的代码，使用的方法如下：
$ python -O -m py_compile python_helloworld.py
]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>Python格式化字符串</title>
    <url>/2018/02/03/python-format-string/</url>
    <content><![CDATA[Python 格式化字符串Python的格式化输出方法很多，相比较于C还是有很多便捷的方面。下面开始说说。
格式化操作符 %%是Python风格的字符串格式化字符串，与C语言中的printf函数的字符串类似。
下面是一些格式化的集合



格式化符号
说明



%c
转换成字符串


%r
优先使用repr函数进行字符串转换


%s
优先用str函数进行字符串转换


%d %i
转成有符号十进制


%u
转成无符号十进制


%o
转成无符号八进制


%x %X
转成无符号十六进制，x/X表示小大写


%e %E
转成科学计数法，e/E控制输出e/E


%f %F
转成浮点数


%g %G
%e与%f的简写


%%
输出%


示例如下：
a = 'x'string = 'hello world\n'n = 12f = 3.1415print ('%c' % a)print ('%r' % string)print ('%s' % string)print ('%d' % n)print ('%i' % n)print ('%u' % n)print ('%o' % n)print ('%x' % n)print ('%X' % n)print ('%f' % f)print ('%F' % f)print ('%e' % f)print ('%E' % f)print ('%g' % f)print ('%G' % f)

输出如下：
x'hello world\n'hello world12121214cC3.1415003.1415003.141500e+003.141500E+003.14153.1415


这里比较需要留意的是str与repr两个内建函数之间的差异。

格式化操作符辅助符号如果希望输出的时候美化输出，通常下面的一些辅助符号会起到比较好的作用。



辅助符
作用



*
定义宽度或者小数点精度


-
左对齐


+
在正数前面加上加号+


#
在八进制前面显示0，十六进制前面加上0x或者0X，取决于用的是x还是X


0
显示的数字前面填充0而不是默认的空格


(var)
映射变量，通常用来吹了字段类型的参数


m.n
m是显示的最小总宽度，n表示的是小数点后面的位数


示例如下：
n = 1234f = 3.1415926students = [{'name': 'Han Meimei', 'age': 17}, {'name': 'Li Lei', 'age': 18}, {'name': 'Wei Hua', 'age': 17}]print('%d =&gt; hex =&gt; %x' % (n, n))print('%d =&gt; hex =&gt; %X' % (n, n))print('%d =&gt; hex =&gt; %#x' % (n, n))print('%d =&gt; hex =&gt; %#X' % (n, n))print('value f is %f' % f)print('value f is %.4f' % f)print('name: %10s, age: %10d' % (students[0]['name'], students[0]['age']))print('name: %-10s, age: %-10d' % (students[1]['name'], students[1]['age']))print('name: %*s, age: %0*d' % (10, students[1]['name'], 10, students[1]['age']))for student in students:    print('%(name)s is %(age)d years old' % student)

输出结果如下所示：
1234 =&gt; hex =&gt; 4d21234 =&gt; hex =&gt; 4D21234 =&gt; hex =&gt; 0x4d21234 =&gt; hex =&gt; 0X4D2value f is 3.141593value f is 3.1416name: Han Meimei, age:         17name: Li Lei    , age: 18        name:     Li Lei, age: 0000000018Han Meimei is 17 years oldLi Lei is 18 years oldWei Hua is 17 years old

字符串模板示例如下：
from string import Templates = Template('Hi, $name! $name is $age years old.')print(s.substitute(name='Han Meimei', age='17'))hmm = {'name' : 'Han Meimei', 'age': 17}print(s.substitute(hmm))

输出结果如下：
Hi, Han Meimei! Han Meimei is 17 years old.Hi, Han Meimei! Han Meimei is 17 years old.

字符串内建函数format从Python2.6开始，新增了一种格式化字符串的字符串str.format，通过这个函数可以对字符串进行格式化处理。在format函数中，使用{}符号来当做格式化操作符。
示例如下：
# 位置参数print('{0} is {1} years old.'.format('lily', 18))print('{} is {} years old.'.format('lily', 18))print('Hi {0}. {0} is {1} years old.'.format('lily', 18))# 关键字参数print('{name} is {age} years old'.format(name='lily', age=18))# 下标参数lily = ['lily', 18]print('{0[0]} is {0[1]} years old'.format(lily))# 填充与对齐# ^&lt;&gt;分别表示居中、左对齐、右对齐，后面带宽度# ：后面带填充的字符，只能是一个字符，不知道的的话用空格填充print('{:&gt;8}'.format('3.14'))print('{:&lt;8}'.format('3.14'))print('{:^8}'.format('3.14'))print('{:0&gt;8}'.format('3.14'))print('{:a&gt;8}'.format('3.14'))# 浮点数精度print('{:.4f}'.format(3.1415926))print('{:0&gt;10.4f}'.format(3.1415926))# 进制# b/d/o/x分别表示二进制、十进制、八进制、十六进制print('{:b}'.format(12))print('{:d}'.format(12))print('{:o}'.format(12))print('{:x}'.format(12))print('{:#x}'.format(12))print('{:#X}'.format(12))# 千位分隔符print('{:,}'.format(1230000000))

输出结果如下：
lily is 18 years old.lily is 18 years old.Hi lily. lily is 18 years old.lily is 18 years oldlily is 18 years old    3.143.14      3.14  00003.14aaaa3.143.141600003.141611001214c0xc0XC1,230,000,000
]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>string</tag>
        <tag>format</tag>
      </tags>
  </entry>
  <entry>
    <title>第一个Python程序</title>
    <url>/2010/08/06/python-helloworld/</url>
    <content><![CDATA[第一个Python程序Python的源代码文件以py作为后缀，命名为python_helloworld.py，先写一个最简单的程序。
if __name__ == "__main__":    print ("Hello World")

可以在终端中直接用python来执行这个程序
$ python python_helloworld.py
]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>Python 历史及由来</title>
    <url>/2010/08/06/python-history/</url>
    <content><![CDATA[Python历史及由来有Guido van Rossum在1989年开发，并与1991年初发表。
属于解释型语言，比Java可读性更强。
]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>history</tag>
      </tags>
  </entry>
  <entry>
    <title>Python IDE 之开发利器PyCharm</title>
    <url>/2016/06/01/python-ide-PyCharm/</url>
    <content><![CDATA[开发利器之PyCharm在没有遇到Jetbrains的开发套件之前，其实我是犹豫的，比如我会用着成为利器之神的VIM，然后成为神之利器的Emacs，偶尔在用下号称编码人员最爱的Sublime，直到遇到Jetbrains开发套件，套不犹豫地购买License，开始徜徉在Jetbrains的海洋中，云淡风轻，与世无争。

悄悄告诉你一件事情，其实有些套件是有Community版本的，没有License的限制，但是相应地功能也会少一些，可以先试用，感觉性价比可以了在购买。

为什么呢，因为Jetbrains各个系列都拥有高度一致的开发GUI，集成了VIM，让我效率很高，集成了Git，让我在一个开发环境中可以完成需要切换N个终端才能完成的事情，还有自动代码格式化，代码完成、重构，等等。

待我细细讲来。

先来个预览吧，

PycharmPycharm特点如所有其它 JetBrains 集成开发环境一样，PyCharm 具有智能代码编辑器，能理解 Python 的特性并提供卓越的生产力推进工具：自动代码格式化、代码完成、重构、自动导入和一键代码导航等。这些功能在先进代码分析程序的支持下，使 PyCharm 成为 Python 专业开发人员和刚起步人员使用的有力工具。
这些够了吗，这些还不够，还有：

针对 Django 开发的高级支持，包括智能代码完成、检查、重构和特定代码导航
综合 Python 调试器和图形单元测试工具
支持先进 Python 开发工具链，包括 virtualenv 和 buildout
版本控制系统整合——针对 Mercurial、Git、SVN、Perforce 和 CVS 等大多数版本控制系统的统一用户界面 (UI)
Google App Engine 支持，能到 App Engine 服务器上运行和部署用户的应用，同时确保代码满足沙盒环境需求
REPL 和 Django 控制台，具备胜过标准控制台的众多优势：运行中语法检查;括号和引号匹配和自动配对;以及代码完成。
还有跨平台，通杀三大主流平台Windows，MacOSX和Linux，当然我觉得MacOSX上吗的体验最好。

Pycharm快捷键调出快捷键的方法很简单，入下图所示：

列出的快捷键如下面所示：

其实我们用到的快捷键远远没有那么多啦，不过作为一个辣么牛的编辑器，一句话，别人可以不用，但是你不能没有，意思就是：

有没有是你的态度，用不用是我的权利。

这一点标明Jetbrains的态度那是杠杠滴OK。
用到的快捷键就那下面几个，一一说来。
代码基本完成快捷键这个功能但凡能存活到现在的编辑器，都会具有这个功能，就是看代码完成的效率问题了。
这里有一个比较悲催的事情，就是Jetbrains默认的快捷键总是会跟输入法切换键有冲突，所以这个是我们需要比较注意的，我们需要改变这个快捷键，如何修改参考下面的修改默认快捷键，因为默认的快捷键比较多，可以在搜索区域输入basic即可。不要用你使用最多的键，比如可以改为**Ctrl + ,**，这个目前看来还没有跟其他什么主流软件有冲突，所以培养用户的习惯还是很重要的。
其实这个功能我用的不是特别多，这是为什么呢，因为在你输入的过程中，Jetbrains已经会比较快捷方便地给你提示了。如下所示：

霸气的TAB如果在Linux里面你还是照旧所有的字符都输入进入，我只能说佩服，还有不屑，因为在节省时间的问题上，为什么不用下Tab键呢？
Jetbrains也有这个很好的传统，有两种情况：

当你什么也没有输入的时候，Tab默认是4个空格的缩进
但是当你输入前几个字母的时候，Jetbrains会智能地列出所有的候选项，这时候你只要按下Tab，就会默认选择第一个候选项，这对于双手不离开键盘而言，是很好的提高输入速度，以及保证流畅思考编程的一个小技巧。

Shift+Enter 智能换行如果鼠标位于class function():的任何一个位置，此时(ˇˍˇ) 想～写下一行代码了，小case，直接Shift+Enter切换到下一行正确的位置写代码即可。
修改默认快捷键打开Preference，或者快捷栏中看起来像扳手的图标，会打开如下所示的界面，在左侧中选择keymap即可。

PyCharm插件如何安装插件同样跟修改快捷键一样，这次要找的是Plugins，顺便力推几个插件。

VIM插件效果就是PyCharm的编辑器就是一个VIM开启的终端，各种赞。
顺便提供一个vim的快捷键，供参考。

支持Markdown写作如果现在你还在用富文本编辑器，估计会被鄙视的，高大上一点，最重要的是有效率一点，那就妥妥滴Markdown吧，会自动解析Markdown的各种标记。

支持Docker我下载了一个docker，打开工程的时候，会提示：

]]></content>
      <categories>
        <category>Python</category>
        <category>IDE</category>
      </categories>
      <tags>
        <tag>PyCharm</tag>
      </tags>
  </entry>
  <entry>
    <title>Python IDE 之 终端开发环境IPython</title>
    <url>/2016/06/01/python-ide-ipython/</url>
    <content><![CDATA[开发利器之IPython下载使用]]></content>
      <categories>
        <category>Python</category>
        <category>IDE</category>
      </categories>
      <tags>
        <tag>IPython</tag>
      </tags>
  </entry>
  <entry>
    <title>Python 条件判断语句</title>
    <url>/2010/08/07/python-if/</url>
    <content><![CDATA[Python 条件判断语句判断是否及格60分判断a与b的大小]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>数字</tag>
        <tag>字符串</tag>
      </tags>
  </entry>
  <entry>
    <title>Python __init__.py的作用</title>
    <url>/2015/08/07/python-init/</url>
    <content><![CDATA[init.py 标识该目录是一个python的模块包（module package）。
当用 import 导入该目录时，会执行 init.py 里面的代码。
]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>init</tag>
      </tags>
  </entry>
  <entry>
    <title>Mac OSX 安装Python3和pip3</title>
    <url>/2018/02/03/python-install-on-macosx/</url>
    <content><![CDATA[Mac OSX 安装Python3和pip3Python2即将在2020年迎来它最后的时光，或许现在你应该或者必须切换到Python3版本了。
下面简单说一下在Mac OSX上安装Python3和pip3的步骤
安装 python3打开Python的 (官网)[https://www.python.org/] 下载python3的 OS X 版本，应该是一个pkg文件。双击安装，默认情况下会把pip3也安装上。
Python的版本可以通过下面的命令来查看。
$python3 --version
Install pip3:pip3也可以通过下面的方式来安装：
$ curl https://pip.pypa.io/en/stable/installing/get-pip.py$ python3 get-pip.py

可以通过下面的命令来确定pip3是否安装完成
$ which pip3
]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>macosx</tag>
        <tag>python3</tag>
        <tag>pip3</tag>
      </tags>
  </entry>
  <entry>
    <title>Python 编程概述</title>
    <url>/2013/02/03/python-introduction/</url>
    <content><![CDATA[Python 编程概述在程序的开始输入from future import division后，python一旦看到这个语句，运算符/就会严格执行True除法，运算符//则严格执行Floor除法。
字符串格式化Python将字符串作为内建数据类型提供，这使得python程序可以执行非常强大的、基于文本的处理。
多行字符串输出，推荐使用三个引号’’’ string ‘’’或者””” string “””抽象的对象
如果可以，用对象的概念，我们可以看到沙滩而不是沙子，看到森林而不是树木，看到房子而不是砖块。
过程式和OOP在过程式语言中，基本编程单元是“函数”，而在面向对象语言中，基本编程单元是“类”，最终通过它实例化（即“创建”的一种更好听的说法）出对象。Python类包含了函数（用于实现类的行为）和数据（用于实现类的属性）。
]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>string</tag>
        <tag>import</tag>
        <tag>from</tag>
        <tag>OOP</tag>
      </tags>
  </entry>
  <entry>
    <title>Python lambda表达式</title>
    <url>/2012/02/06/python-lambda/</url>
    <content><![CDATA[lambda表达式lambda是一个表达式，而不是一个语句，它能够出现在Python语法不允许def出现的地方。
lambda可以用来编写简单的函数，而def用来处理更强大的任务。
比如下面的例子：
add1 = lambda x,y : x + ymulti2 = lambda x,y : x * yx = 2y = 3print('x = 2 , y =3')print('x+y = ',add1(x,y))print('x*y = ',multi2(x,y))

从上面的代码可以看出，labmda表达式是为了减少单行函数的定义而存在的。
lambda的使用大量简化了代码，使得代码简洁、清晰。
]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>lambda</tag>
      </tags>
  </entry>
  <entry>
    <title>Python List列表</title>
    <url>/2012/02/06/python-list/</url>
    <content><![CDATA[边界检查尽管列表没有固定的大小，但是Python仍然不允许引用不存在的元素，超出列表末尾之外的索引总是会导致错误，对列表末尾范围之外的赋值也是如此。
为了让一个列表增大，我们可以调用append这样的列表方法。
]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>list</tag>
        <tag>append</tag>
      </tags>
  </entry>
  <entry>
    <title>python中文档SPHINX的使用</title>
    <url>/2017/03/31/python-matplotlib-basic-plot-functions/</url>
    <content><![CDATA[pyplot基础图表函数概述matplotlib可以绘制各种类型的图，基本的几个如下表所示，示例图见下。



函数
说明



plt.plot(x,y,fmt, …)
绘制一个坐标图


plt.boxplot(data,notch,position)
绘制一个箱体图


plt.bar(left,height,width,bottom)
绘制一个条形图


plt.barh(width,bottom,left,height)
绘制一个横向条形图


plt.polar(theta,r)
绘制极坐标图


plt.pie(data,explode)
绘制饼图


plt.pas(x,NFFT=256,pad_to,Fs)
绘制功率谱密度图


plt.specgram(x,NFFT=256,pad_to,F)
绘制谱图


plt.cohere(x,y,NFFT=256,Fs)
绘制X-Y的相关性函数


plt.scatter(x,y)
绘制散点图，其中，x和y长度相同


plt.step(x,y,where)
绘制步阶图


plt.hist(x,bins,normed)
绘制直方图


plt.contour(X,Y,Z,N)
绘制等值图


plt.vlines()
绘制垂直图


plt.stem(x,y,linefmt,markerfmt)
绘制柴火图


plt.plot_date()
绘制数据日期


plot 示例图
boxplot 示例图
bar 示例图
barh 示例图
polar 示例图
pie 示例图
pas 示例图
specgram 示例图
cohere 示例图
scatter 示例图
step 示例图
hist 示例图
contour 示例图
vlines 示例图
stem 示例图
plot_date 示例图
]]></content>
      <categories>
        <category>Python</category>
        <category>Matplotlib</category>
      </categories>
      <tags>
        <tag>plot</tag>
        <tag>boxplot</tag>
        <tag>bar</tag>
        <tag>barh</tag>
        <tag>polar</tag>
        <tag>pie</tag>
        <tag>pas</tag>
        <tag>specgram</tag>
        <tag>cohere</tag>
        <tag>scatter</tag>
        <tag>step</tag>
        <tag>hist</tag>
        <tag>contour</tag>
        <tag>vlines</tag>
        <tag>stem</tag>
        <tag>plot_date</tag>
      </tags>
  </entry>
  <entry>
    <title>Python开发者Matplotlib指南</title>
    <url>/2017/03/31/python-matplotlib-plot/</url>
    <content><![CDATA[Matplotlib 简介至理名言：A picture is worth a thousand words。
MatplotLib 支持交互和非交互的绘图，并且可以保持图像到PNG、PS和其他类型的文件。
支持的输出格式


Format
Type Description



EPS
Vector Encapsulated PostScript.


JPG
Raster Graphic format with lossy compression method for photographic output.


PDF
Vector Portable Document Format (PDF).


PNG
Raster Portable Network Graphics (PNG), a raster graphics format with a lossless compression method (more adaptable to line art than JPG).


PS
Vector Language widely used in publishing and as printers jobs format.


SVG
Vector Scalable Vector Graphics (SVG), XML based.


支持的后端


Backend
Description



GTKAgg
GTK+ (The GIMP ToolKit GUI library) canvas with AGG rendering.


GTK
GTK+ canvas with GDK rendering. GDK rendering is rather primitive, and doesn’t include anti-aliasing for the smoothing of lines.


GTKCairo
GTK+ canvas with Cairo rendering.


WxAgg
wxWidgets (cross-platform GUI and tools library for GTK+, Windows, and Mac OS X. It uses native widgets for each operating system, so applications will have the look and feel that users expect on that operating system) canvas with AGG rendering.


WX
wxWidgets canvas with native wxWidgets rendering.


TkAgg
Tk (graphical user interface for Tcl and many other dynamic languages) canvas with AGG rendering.


QtAgg
Qt (cross-platform application framework for desktop and embedded development) canvas with AGG rendering (for Qt version 3 and earlier).


Qt4Agg
Qt4 canvas with AGG rendering.


FLTKAgg
FLTK (cross-platform C++ GUI toolkit for UNIX/Linux (X11), Microsoft Windows, and Mac OS X) canvas with Agg rendering.


渲染器的输出格式为：


渲染器
文件类型



AGG
.png


PS
.eps or .ps


PDF
.pdf


SVG
.svg


Cairo
.png, .ps, .pdf, .svg


GDK
.png, .jpg



python-dateutil - 增强datetime

可以使用的集成环境IDE
Enthought Python Distribution
Python(x,y)
Sage
Anaconda

开始使用 Matplotlib三种使用Matplotlib的方式
pyplot: 提供与Matlab类似的函数式环境，state-machine interface。通常用于interactive ploting的模式，例如ipython，可立即看到绘图结果。使用方式如下：from matplotlib import pyplot as plt,pyplot中提供的函数接口见：http://matplotlib.org/api/pyplot_api.html#pyplot
pylab：结合了pyplot（用于作图）和numpy（用于数学计算）。在本书中被嫌弃。使用方式如下：ipython -pylab
面向对象式的

对于面向对象式的，比如下面的代码：
import matplotlib.pyplot as pltimport numpy as npx = np.arange(0, 10, 0.1)y = np.random.randn(len(x))fig = plt.figure()ax = fig.add_subplot(111)l, = plt.plot(x, y)t = ax.set_title('random numbers')plt.show()


用Matplotlib绘制第一幅图片源码import matplotlib.pyplot as pltimport numpy as nplen = 10x = []y = []z = []xx = range(len)for i in range(len):    x.append(np.random.rand())    y.append(np.random.rand())    z.append(np.random.rand())plt.plot(xx,x)plt.plot(xx,y)plt.plot(xx,z)plt.show()


效果图
用Matplotlib绘制添加各种信息的图片在前面的基础上添加上网格，坐标，坐标轴信息和标题等信息
源码import matplotlib.pyplot as pltimport numpy as nplen = 10x = []y = []z = []xx = range(len)for i in range(len):    x.append(np.random.rand())    y.append(np.random.rand())    z.append(np.random.rand())plt.plot(xx,x)plt.plot(xx,y)plt.plot(xx,z)plt.legend(['legend x','legend y','legend z'],loc='best')plt.grid(True)plt.xlabel('Points')plt.ylabel('Random Value')plt.title('Test data')plt.show()

效果图
保存图像到文件plt.savefig('plot.png')

绘图键盘快捷键与功能


键盘快捷键
命令



h or r or home
Home or Reset


c or left arrow or backspace
后退


v or right arrow
前进


p
Pan or Zoom


o
Zoom-to-rectangle


s
保存


f
全屏


hold x
Constrain pan or zoom to x-axis


hold y
Constrain pan or zoom to y-axis


hold ctrl
Preserve aspect ratio


g
网格显示


l
Toggle y-axis scale (log or linear)


进入matplotlib环境$ ipython -pylab

 在该命令下，

ion ： 打开交互模式
ioff：关闭交互模式
draw：强制重绘

配置Matplotlib全局配置文件 /etc/matplotlibrc

在该文件中我们可以看到backend : TkAgg，因为TkAgg不基于任何依赖，所以在大部分平台上都会正常工作，这也是因为python默认使用的就是Tk/Tcl。

几个小技巧plt.hold() # 是否保留原来图像plt.interactive(True) # 使能交互模式plt.legend # 有几个位置，可以使用`loc`参数




String
Code



best
0


upper right
1


upper left
2


lower  left
3


lower right
4


right
5


center left
6


center right
7


lower center
8


upper center
9


center
10


绘图的美化这一章用来美化绘图咯。
颜色选项通过加上简单的一个参数就可以控制图片的线条颜色了。
源码import matplotlib.pyplot as pltimport numpy as nplen = 10x = []y = []z = []xx = range(len)for i in range(len):    x.append(np.random.rand())    y.append(np.random.rand())    z.append(np.random.rand())# Adding color parametersplt.plot(xx,x,'y',label='legend x')plt.plot(xx,y,'m',label='legend y')plt.plot(xx,z,'c',label='legend z')plt.legend()plt.grid(True)plt.xlabel('Points')plt.ylabel('Random Value')plt.title('Colors')plt.show()

效果图支持的颜色列表：



Color abbreviation
Color Name



b
blue 蓝色


c
cyan 蓝绿色


g
green 绿色


k
black 黑色


m
magenta 品红色


r
red 红色


w
white 白色


y
yellow 黄色


颜色的表示方法除了用缩写，还可以使用颜色名字或者16进制的RGB代码，比如下面的三行代码效果是一样的。
plot(xx,x,'r')plot(xx,x,'red')plot(xx,x,'#FF0000')

线条类型源码#!/usr/bin/env python# coding=utf-8# Author    :   Guo Shaoguang# Email     :   sgguo@shao.ac.cn# Institute :   Shanghai Astronomical Observatoryimport matplotlib.pyplot as pltimport numpy as nplen = 10x = []y = []z = []xx = range(len)for i in range(len):    x.append(np.random.rand())    y.append(np.random.rand())    z.append(np.random.rand())# Using different line stylesplt.plot(xx,x,'--',label='x')plt.plot(xx,y,'-.',label='y')plt.plot(xx,z,':',label='z')plt.legend()plt.grid(True)plt.xlabel('Points')plt.ylabel('Random Value')plt.title('Colors')plt.show()

效果图线条类型表


类型缩写
类型



-
实线


–
虚线


-.
点划线


:
点线


点标记类型源码#!/usr/bin/env python# coding=utf-8# Author    :   Guo Shaoguang# Email     :   sgguo@shao.ac.cn# Institute :   Shanghai Astronomical Observatoryimport matplotlib.pyplot as pltimport numpy as nplen = 10x = []y = []z = []m = []n = []xx = range(len)for i in range(len):    x.append(np.random.rand())    y.append(np.random.rand())    z.append(np.random.rand())    m.append(np.random.rand())    n.append(np.random.rand())# Using different line stylesplt.plot(xx,x,'o',label='x')plt.plot(xx,y,'^',label='y')plt.plot(xx,z,'x',label='z')plt.plot(xx,m,'s',label='z')plt.plot(xx,n,'D',label='z')plt.legend()plt.grid(True)plt.xlabel('Points')plt.ylabel('Random Value')plt.title('Markers')plt.show()

效果图标记点类型


标记缩写
标记类型



.
点


,
像素


o
圆


v
倒三角


^
正三角


&lt;
左三角


&gt;
右三角


1
Tripod down marker


2
Tripod up marker


3
Tripod left marker


4
Tripod right marker


s
Square marker


p
Pentagon marker


*
Star marker


h
Hexagon marker


H
Rotated hexagon marker


+
Plus marker


x
Cross (x) marker


D
Diamond marker


d
Thin diamond marker






_
Horizontal line (hline symbol) marker


组合标记和线类型其实颜色、线条类型以及点标记是可以组合使用的。
源码#!/usr/bin/env python# coding=utf-8# Author    :   Guo Shaoguang# Email     :   sgguo@shao.ac.cn# Institute :   Shanghai Astronomical Observatoryimport matplotlib.pyplot as pltimport numpy as nplen = 10x = []y = []z = []m = []xx = range(len)for i in range(len):    x.append(np.random.rand())    y.append(np.random.rand())    z.append(np.random.rand())    m.append(np.random.rand())# Using different line stylesplt.plot(xx,x,'--o',label='x')plt.plot(xx,y,'-.^',label='y')plt.plot(xx,z,'-x',label='z')plt.plot(xx,m,':s',label='z')plt.legend()plt.grid(True)plt.xlabel('Points')plt.ylabel('Random Value')plt.title('Line with Markers')plt.show()

效果图使用关键词参数来更好地控制绘图前面的格式化参数虽然很有用，但是还是有些缺点的，比如，不允许我们分别设置点和线的颜色。所以这里就需要使用关键词参数了。
源码#!/usr/bin/env python# coding=utf-8# Author    :   Guo Shaoguang# Email     :   sgguo@shao.ac.cn# Institute :   Shanghai Astronomical Observatoryimport matplotlib.pyplot as pltimport numpy as nplen = 5x = []y = []z = []m = []xx = range(len)for i in range(len):    x.append(np.random.rand())    y.append(np.random.rand())    z.append(np.random.rand())plt.plot(xx,x,color='blue',linestyle='dashdot',linewidth=2,marker='o',         markerfacecolor='red',markeredgecolor='black',label='x')plt.plot(xx,y,color='green',linestyle='solid',linewidth=3,marker='s',         markerfacecolor='blue',markeredgecolor='red',label='y')plt.plot(xx,z,color='cyan',linestyle=':',linewidth=2,marker='^',         markerfacecolor='green',markeredgecolor='blue',label='z')plt.legend()plt.grid(True)plt.xlabel('Points')plt.ylabel('Random Value')plt.title('Keyword')plt.show()
效果图其实plot能做出许多美轮美奂的图片，这就取决于你的想象力了。
关键词参数列表


关键词参数
描述



color or c
设置线条颜色; accepts any Matplotlib color format.


linestyle
设置线条类型; accepts the line styles seen previously.


linewidth
设置线条宽度; accepts a float value in points.


marker Sets
the line marker style.


markeredgecolor
设置标记边缘颜色; accepts any Matplotlib color format.


markeredgewidth
设置标记边缘宽度; accepts float value in points.


markerfacecolor
设置标记内部颜色; accepts any Matplotlib color format.


markersize
设置标记点大小; accepts float values.


设置x轴与y轴的tick标记源码#!/usr/bin/env python# coding=utf-8# Author    :   Guo Shaoguang# Email     :   sgguo@shao.ac.cn# Institute :   Shanghai Astronomical Observatoryimport matplotlib.pyplot as pltimport numpy as nplen = 5x = []y = []z = []m = []xx = range(len)for i in range(len):    x.append(np.random.rand())    y.append(np.random.rand())    z.append(np.random.rand())plt.plot(xx,x,color='blue',linestyle='dashdot',linewidth=2,marker='o',         markerfacecolor='red',markeredgecolor='black',label='x')plt.plot(xx,y,color='green',linestyle='solid',linewidth=3,marker='s',         markerfacecolor='blue',markeredgecolor='red',label='y')plt.plot(xx,z,color='cyan',linestyle=':',linewidth=2,marker='^',         markerfacecolor='green',markeredgecolor='blue',label='z')plt.legend()plt.grid(True)plt.xlabel('Points')plt.ylabel('Random Value')plt.title('Keyword')plt.xticks(range(len),['a','b','c','d','e'])plt.yticks(np.arange(0,1,0.05))plt.show()

效果图绘图类型前面说的都是线类型，其实matplotlib可以绘制很多类型，如下图所示。
直方图直方图 主要用于显示出现的频率值，将某一部分数据集放在一个category里面，这个category称谓bins 。默认的bins值为10，可以通过参数bins来修改该值，比如下面的源码将其更改为25。
源码#!/usr/bin/env python# coding=utf-8# Author    :   Guo Shaoguang# Email     :   sgguo@shao.ac.cn# Institute :   Shanghai Astronomical Observatoryimport matplotlib.pyplot as pltimport numpy as nplen = 1000y = np.random.randn(len)plt.hist(y,bins=25,color='red',label='Data')plt.legend()plt.grid(True)plt.xlabel('Points')plt.ylabel('Random Value')plt.title('Histogram Charts')plt.show()

效果图误差条形图对于实验值，精确的值通常情况下是不存在的，因为有各种各样的误差值，那么此时误差条形图就来了。
且看如何使用该图。
源码#!/usr/bin/env python# coding=utf-8# Author    :   Guo Shaoguang# Email     :   sgguo@shao.ac.cn# Institute :   Shanghai Astronomical Observatoryimport matplotlib.pyplot as pltimport numpy as npx = np.arange(0,10,0.2)y = np.exp(-x)e1 = 0.1 * np.abs(np.random.randn(len(y)))e2 = 0.15 * np.abs(np.random.randn(len(y)))plt.errorbar(x,y,xerr=e1,yerr=e2,ecolor='red',fmt='-',label='error')plt.axis([0,10,-0.5,1.2])plt.legend()plt.grid(True)plt.xlabel('Points')plt.ylabel('Random Value')plt.title('Error Bar Charts')plt.show()

效果图可以看到上面的误差图是对称的，如果是非对称的，只需要将plot的语句更改为如下所示
plt.errorbar(x,y,yerr=[e1,e2],ecolor='red',fmt='-',label='error')

非对称效果图直方图直方图主要用于可视化两组或者多组值。
源码#!/usr/bin/env python# coding=utf-8# Author    :   Guo Shaoguang# Email     :   sgguo@shao.ac.cn# Institute :   Shanghai Astronomical Observatoryimport matplotlib.pyplot as pltplt.bar([1,2,3,4],[4,6,3,8])plt.grid(True)plt.xlabel('Points')plt.ylabel('Value')plt.title('Bar Charts')plt.show()

参数
width：bar的宽度
color：bar的颜色
xerr，yerr：bar的误差
bottom：bar的底部坐标

效果图更清晰的直方图源码#!/usr/bin/env python# coding=utf-8# Author    :   Guo Shaoguang# Email     :   sgguo@shao.ac.cn# Institute :   Shanghai Astronomical Observatoryimport matplotlib.pyplot as pltimport numpy as npdict = {'A':40,'B':70,'C':35,'D':86}for i,key in enumerate(dict):    print i,key    plt.bar(i,dict[key])# 因为宽度默认为0.8，此处的0.4即为每个bar的中间位置plt.xticks(np.arange(len(dict))+0.4,dict.keys())# 只显示有用的值plt.yticks(dict.values())plt.xlabel('Points')plt.ylabel('Value')plt.title('Clear Bar Charts')plt.show()

效果图复杂直方图源码#!/usr/bin/env python# coding=utf-8# Author    :   Guo Shaoguang# Email     :   sgguo@shao.ac.cn# Institute :   Shanghai Astronomical Observatoryimport matplotlib.pyplot as pltimport numpy as npdata1 = 10*np.random.rand(5)data2 = 10*np.random.rand(5)data3 = 10*np.random.rand(5)e2 = 0.5 * np.abs(np.random.randn(len(data2)))locs = np.arange(1,len(data1)+1)width = 0.27plt.bar(locs,data1,width=width)plt.bar(locs+width,data2,yerr=e2,width=width,color='red')plt.bar(locs+2*width,data3,width=width,color='green')plt.xticks(locs + width *1.5,locs)plt.xlabel('Points')plt.ylabel('Value')plt.title('Complex Bar Charts')plt.show()

效果图饼状图饼状图主要用于表述某一部分在整体中占得比例。
源码#!/usr/bin/env python# coding=utf-8# Author    :   Guo Shaoguang# Email     :   sgguo@shao.ac.cn# Institute :   Shanghai Astronomical Observatoryimport matplotlib.pyplot as pltx = [25,35,45]labels = ['Good','Failed','Passed']plt.pie(x,labels=labels)plt.title('Pie Charts')plt.show()

效果图参数
explode : 所属的部分是否相对于半径有偏移，也就是突出显示的意思
colors : 颜色控制
labels ： 标记
shadow ： 是否有阴影渲染

源码#!/usr/bin/env python# coding=utf-8# Author    :   Guo Shaoguang# Email     :   sgguo@shao.ac.cn# Institute :   Shanghai Astronomical Observatoryimport matplotlib.pyplot as pltx = [5,25,35,45,10]labels = ['Excellent','Good','Failed','Passed','Bad']explode = [0.1,0.2,0.0,0.1,0.0]shadow = [0.0,0.1,0.2,0.1,0.0]plt.pie(x,labels=labels,explode=explode,shadow=shadow)plt.title('Pie Charts')plt.show()
效果图散点图散点图主要用于鉴定两组变量的潜在关系，也就是相关关系。
源码#!/usr/bin/env python# coding=utf-8# Author    :   Guo Shaoguang# Email     :   sgguo@shao.ac.cn# Institute :   Shanghai Astronomical Observatoryimport matplotlib.pyplot as pltimport numpy as npx = np.random.randn(1000)y = np.random.randn(1000)plt.scatter(x,y)plt.title('Scatter Plot')plt.show()

效果图修饰散点图可以使用下面的几个参数来修饰散点图：

s：表示点的大小size
c：表示点的颜色color
marker：表示点的样式，可以参考前面关于Marker的描述

#!/usr/bin/env python# coding=utf-8# Author    :   Guo Shaoguang# Email     :   sgguo@shao.ac.cn# Institute :   Shanghai Astronomical Observatoryimport matplotlib.pyplot as pltimport numpy as npx = np.random.randn(1000)y = np.random.randn(1000)size = 50*np.random.randn(1000)colors = np.random.rand(1000)plt.scatter(x,y,s=size,c=colors)plt.title('Scatter Plot')plt.show()

效果图极坐标图极坐标使用了一个完全不同的坐标系，前面的绘图，我们使用的都是笛卡尔坐标系，分别为x与y轴。而极坐标使用的是半径与角度（或弧度，Matplotlib默认使用角度）。
源码#!/usr/bin/env python# coding=utf-8# Author    :   Guo Shaoguang# Email     :   sgguo@shao.ac.cn# Institute :   Shanghai Astronomical Observatoryimport matplotlib.pyplot as pltimport numpy as nptheta = np.arange(0.,2.,1./180.)*np.pi# Draw a spiralplt.polar(3*theta,theta/5)# Draw a polar rose, a pretty function that resembles a flowerplt.polar(theta,np.cos(8*theta))# Draw a circularplt.polar(theta,[1.4]*len(theta))plt.title('Polar Plot')plt.show()

效果图可以通过参数rgrids和thetagrid来控制相关的参数显示，比如下面的代码将绘制一个蝴蝶。
rgrids的参数有下面几个：

radii：The radial distances at which the grid lines should be drawn.
labels: The labels to display at radii grid. By default, the values from radii would be used, but if not None, then it has to be of the same length as that of radii.
angle: The angle at which the labels are displayed (by default it’s 22.5°).

thetagrids的参数有下面几个：

angles: label的位置
labels: Specifies the labels to be printed at given angles. If None, then the angles values are used, or else the array must be of the same length of angles.
frac: The polar axes radius fraction at which we want the label to be drawn (1 is the edge, 1.1 is outside, and 0.9 is inside).

#!/usr/bin/env python# coding=utf-8# Author    :   Guo Shaoguang# Email     :   sgguo@shao.ac.cn# Institute :   Shanghai Astronomical Observatoryimport matplotlib.pyplot as pltimport numpy as nptheta = np.arange(0.,2.,1./180.)*np.pir = np.abs(np.sin(5*theta)-2.*np.cos(theta))plt.polar(theta,r)plt.thetagrids(range(45,360,90))plt.rgrids(np.arange(0.2,3.,.7),angle=90)plt.title('Polar Plot')plt.show()

效果图说明转载请注明作者及其出处
githubHomepageHomepageCSDN
图片中的文字、注释与箭头前面的图片我们很简单地添加了x、y轴和标题的问题。这里我们学着添加图片内部的文字。
其中text中的x、y为坐标值；figtext为相对坐标，(0,0)为左下角，(1,1)为左上角；
除了text，用的比较多的应该是annotate，既可以写上文字，也可以标记出来具体的点。
annotate的参数：

width: The width of the arrow in points
frac: The fraction of the arrow length occupied by the head
headwidth: The width of the base of the arrow head in points
shrink: Moves the tip and the base of the arrow some percent away fromthe annotated point and text, in percentage (so 0.05 is equal to 5%)

annotate已经很好用了，不过我们还可以通过arrow来任意指定箭头的位置、大小和方向。
源码#!/usr/bin/env python# coding=utf-8# Author    :   Guo Shaoguang# Email     :   sgguo@shao.ac.cn# Institute :   Shanghai Astronomical Observatoryimport matplotlib.pyplot as pltimport numpy as npx = np.arange(0,4*np.pi,.01)y = np.sin(x)plt.plot(x,y)plt.text(0.1,-0.05,'Sin(x)')plt.figtext(0.5,.5,'sin(x) center')plt.annotate('This point must be really \nmean something',xy=(np.pi/2.,1),xytext=(2.9,0.7),             arrowprops=dict(facecolor='cyan',shrink=0.05))plt.title('Text &amp;&amp; Annotation')plt.show()

Another
#!/usr/bin/env python# coding=utf-8# Author    :   Guo Shaoguang# Email     :   sgguo@shao.ac.cn# Institute :   Shanghai Astronomical Observatoryimport matplotlib.pyplot as pltplt.axis([0,10,0,20])arrstyles = ['-','-&gt;','-[','&lt;-','&lt;-&gt;','fancy','simple','wedge']for i,style in enumerate(arrstyles):    plt.annotate(style,xytext=(1,2+2*i),xy=(4,1+2*i),arrowprops=dict(arrowstyle=style))for i,style in enumerate(arrstyles):    plt.annotate('',xytext=(6,2+2*i),xy=(8,1+2*i),arrowprops=dict(arrowstyle=style))plt.title('Different Arrows')plt.show()


效果图Matplotlib 进阶使用Matplotlib的几种方式有三种使用Matplotlib的方法：

pyplot
pylab：将Matplotlib和NumPy集合在一起，很像Matlab
面向对象的方式：这也是最好的一种方式，因为可以对返回的结果进行全方位的控制

 同一个程序用上面的三种方法，效果图如下所示：
 源码如下所示：
pyplotimport matplotlib.pyplot as pltimport numpy as npx = np.arange(0, 10, 0.1)y = np.random.randn(len(x))plt.plot(x, y)plt.title('random numbers')plt.show()
pylab使用ipython -pylab，输入代码如下：
In [1]: x = arange(0, 10, 0.1)In [2]: y = randn(len(x))In [3]: plot(x, y)Out[3]: [&lt;matplotlib.lines.Line2D object at 0x4284dd0&gt;]In [4]: title('random numbers')In [5]: show()


这里需要特别注意的是 ipython -pylab 与from pylab import * 是不一样的。

OO最后来一个面向对象的，代码如下所示：
import matplotlib.pyplot as pltimport numpy as npx = np.arange(0, 10, 0.1)y = np.random.randn(len(x))fig = plt.figure()ax = fig.add_subplot(111)l, = plt.plot(x, y)t = ax.set_title('random numbers')plt.show()

对比从上面的代码来看，pylab模式下的代码最少，pyplot次之，面向对象的代码最多。
正如python之禅所说：”Explicit is better than implicit” ，”Simple is better than complex” 。在简单的交互模式下，pylab或者pyplot是最好的选择，因为他们隐藏了很多复杂性，但是如果我们需要更深一步的控制，面向对象的API此时就会派上用场了，因为OO模式会清晰地告诉我们从哪里来，到哪里去。特别是再将Matplotlib嵌入到GUI的时候更是如此。
Matplotlib的几个对象


对象
描述



FigureCanvas
Figure实例的容器类


Figure
Axes实例的容器


Axes
基本绘画单元诸如线、文字等的矩形区域


Subplots前面的OO模式的代码，来看看几个概念的解释：

fig = plt.figure()：figure函数返回一个Figure对象，我们可以在其上增加Axes实例
ax = fig.add_subplot(121)：add_subplot返回一个Axes实例，我们可以在其上绘制图形

add_subplot的使用有三个参数：
fig.add_subplot(numrow,numcols,fignum)

比如下面的代码：
#!/usr/bin/env python# coding=utf-8# Author    :   Guo Shaoguang# Email     :   sgguo@shao.ac.cn# Institute :   Shanghai Astronomical Observatoryimport matplotlib.pyplot as pltimport numpy as npfig = plt.figure()x = np.arange(0,10,0.1)y = np.random.randn(len(x))ax1 = fig.add_subplot(121)#l, = plt.plot(x,y)#l.set_color('red')ax1.plot(x,y,'rs-')ax1.set_title('Random Numbers 1')ax1.set_xlabel('x')ax1.set_ylabel('y')x = np.arange(0,10,0.1)y = np.random.randn(len(x))ax2 = fig.add_subplot(122)ax2.plot(x,y)ax2.set_title('Random Numbers 2')plt.show()


多个FigureMatplotlib 不仅提供了在一个Figure里面绘制多个Axes的功能，还能绘制多幅Figure。
#!/usr/bin/env python# coding=utf-8# Author    :   Guo Shaoguang# Email     :   sgguo@shao.ac.cn# Institute :   Shanghai Astronomical Observatoryimport matplotlib.pyplot as pltfig1 = plt.figure()ax1 = fig1.add_subplot(111)ax1.plot([1, 2, 3], [1, 2, 3]);fig2 = plt.figure()ax2 = fig2.add_subplot(111)ax2.plot([1, 2, 3], [3, 2, 1]);plt.show()




两个坐标轴有的时候希望在同一副图像上绘制两个数据集。特别是对同一个X变量，具有不同的Y值。
这里的技巧在于twinx函数，它会创建第二套坐标，并且与第一套坐标重合，来绘制图形。不过要注意的是，因为使用了twinx，所有的设置都会重置，包括线条的颜色也会是蓝色，所以为了区分，需要设置颜色。
源码#!/usr/bin/env python# coding=utf-8# Author    :   Guo Shaoguang# Email     :   sgguo@shao.ac.cn# Institute :   Shanghai Astronomical Observatoryimport matplotlib.pyplot as pltimport numpy as npx = np.arange(0.1,np.e,0.01)y1 = np.exp(-x)y2 = np.log(x)fig = plt.figure()ax1 = fig.add_subplot(111)ax1.plot(x,y1)ax1.set_ylabel('Y values for exp(-x)')ax2 = ax1.twinx()ax2.plot(x,y2,'r')ax2.set_xlim([0,np.e])ax2.set_ylabel('Y values for ln(x)')ax2.set_xlabel('Same X for both exp(-x) and ln(x)')plt.show()

效果图对数坐标轴对数坐标轴主要针对有对数关系或者数据增长或缩减比较迅速的数据。
其中semilogx/semilogy一样是将plot与set_xscale/set_yscale合并为一个命令。
而loglog是将x/y全部设置为对数坐标。
源码#!/usr/bin/env python# coding=utf-8# Author    :   Guo Shaoguang# Email     :   sgguo@shao.ac.cn# Institute :   Shanghai Astronomical Observatoryimport matplotlib.pyplot as pltimport numpy as npx = np.arange(0.,20,0.01)fig = plt.figure()ax1 = fig.add_subplot(311)y1 = np.exp(-x)ax1.plot(x,y1)ax1.grid(True)ax1.set_yscale('log')ax1.set_ylabel('log y')ax2 = fig.add_subplot(312)y2 = np.cos(np.pi*x)ax2.semilogx(x,y2)ax2.set_xlim([0,20])ax2.grid(True)ax2.set_ylabel('Log X')ax3 = fig.add_subplot(313)y3 = np.exp(x/4.)ax3.loglog(x,y3,basex=3)ax3.grid(True)ax3.set_ylabel('Log x and y')plt.show()

效果图共享坐标轴有些情况下，我们希望不同的Figure共享同一个坐标轴，这样在一个坐标改变时会联动其他坐标同时改变。
这对于金融数据、硬件测试、健康状态监测都是很有帮助的。
源码#!/usr/bin/env python# coding=utf-8# Author    :   Guo Shaoguang# Email     :   sgguo@shao.ac.cn# Institute :   Shanghai Astronomical Observatoryimport matplotlib.pyplot as pltimport numpy as npx = np.arange(20)fig = plt.figure()ax1 = fig.add_subplot(311)ax1.plot(x,x)ax2 = fig.add_subplot(312,sharex=ax1)ax2.plot(x*2,x*2)ax3 = fig.add_subplot(313,sharex=ax1)ax3.plot(x*3,x*3)plt.show()

效果图绘制日期使用plot_date绘制坐标轴为日期的图形。下面的linestyle会将各个随机点连接起来，下图有个缺点就是x的日期坐标轴会覆盖。
源码#!/usr/bin/env python# coding=utf-8# Author    :   Guo Shaoguang# Email     :   sgguo@shao.ac.cn# Institute :   Shanghai Astronomical Observatoryimport matplotlib as mplimport matplotlib.pyplot as pltimport numpy as npimport datetime as dtdates = [dt.datetime.today() + dt.timedelta(days=i) for i in range(10)]values = np.random.rand(len(dates))plt.plot_date(mpl.dates.date2num(dates),values,linestyle='-')plt.show()

效果图日期格式化date的格式如下所示：
datetime.datetime(2008, 7, 18, 14, 36, 53, 494013)

为了能让Matplotlib使用日期，我们需要将其更改为浮点类型。
可以参考下面的函数：

date2num
num2date
drange

drange比较有用的情况：
import matplotlib as mplfrom matplotlib import datesimport datetime as dtdate1 = dt.datetime(2008, 9, 23)date2 = dt.datetime(2009, 4, 12)delta = dt.timedelta(days=10)dates = mpl.dates.drange(date1, date2, delta)

前面绘制的图片比较丑，是真丑，x轴坐标完全看不到。
此时我们就需要使用locator和formatter来格式化坐标轴。其中：

locator : control the tick’s position
formatter : control the formatting of labels

因为matplotlib有默认的设置，所以最好将这些设置放在plot_date函数的后面，以防被其重置为原来的值。
解释：

fig.autofmt_xdate() 用于美化调整日期显示格式，会旋转以防文字重叠
subplots_adjust() 用于调整plot的空间，可以使用bottom，top，left和right关键词以及wspace和hspace关键词

源码#!/usr/bin/env python# coding=utf-8# Author    :   Guo Shaoguang# Email     :   sgguo@shao.ac.cn# Institute :   Shanghai Astronomical Observatoryimport matplotlib as mplimport matplotlib.pyplot as pltimport numpy as npimport datetime as dtfig = plt.figure()ax2 = fig.add_subplot(212)date2_1 = dt.datetime(2008,9,23)date2_2 = dt.datetime(2008,10,3)delta2 = dt.timedelta(days=1)dates2 = mpl.dates.drange(date2_1,date2_2,delta2)y2 = np.random.rand(len(dates2))ax2.plot_date(dates2,y2,linestyle='-')dateFmt = mpl.dates.DateFormatter('%Y-%m-%d')ax2.xaxis.set_major_formatter(dateFmt)daysLoc = mpl.dates.DayLocator()hoursLoc = mpl.dates.HourLocator(interval = 6)ax2.xaxis.set_major_locator(daysLoc)ax2.xaxis.set_minor_locator(hoursLoc)fig.autofmt_xdate()fig.subplots_adjust(left=0.18)ax1 = fig.add_subplot(211)date1_1 = dt.datetime(2008,9,23)date1_2 = dt.datetime(2009,2,16)delta1 = dt.timedelta(days=10)dates1 = mpl.dates.drange(date1_1,date1_2,delta1)y1 = np.random.rand(len(dates1))ax1.plot_date(dates1,y1,linestyle='-')monthsLoc = mpl.dates.MonthLocator()weeksLoc = mpl.dates.WeekdayLocator()ax1.xaxis.set_major_locator(monthsLoc)ax1.xaxis.set_minor_locator(weeksLoc)monthsFmt = mpl.dates.DateFormatter('%b')ax1.xaxis.set_major_formatter(monthsFmt)plt.show()

效果图Qt4中潜入MatplotlibQt应该是跨平台做的算是很好的了，一次编辑，多次编译跨平台。
这一章会介绍：

把Matplotlib的Figure对象嵌入到Qt的组件中
把Matplotlib的Figure和导航工具栏嵌入到Qt的组件中
使用时间来实时更新Matplotlib
使用Qt Designer来绘制GUI，然后调用程序使用Matplotlib

Qt4和PyQt4的简介Qt是一个跨平台的开发框架，被广泛用于GUI的开发，最有名的应当是KDE桌面环境了。
其实Qt不仅仅是一个GUI开发工具包，它还包含一系列的网络、线程、Unicode、正则表达式、数据库、OpenGL和XML等库。
Qt是跨平台的，可以用与Unix/Linux，Windows，MacOSX。
尽管Qt是用C++来编写的，也可以通过绑定来使用其他语言，诸如Ruby，Java，Perl和Python。
PyQt绑定Qt2和Qt3，PyQt4绑定的是Qt4。
几个比较重要的Qt模块：

QtCore：非GUI类
QtGui：GLI类
QtOpenGL，QtSql，QtSvg，QtText，QtXml，QtNetwork等

嵌入一个Matplotlib Figure到一个Qt窗口几个需要注意的事情：

from matplotlib.figure import Figure ：这里的Figure是我们绘图的后端独立单元from matplotlib.backends.backend_qt4agg import FigureCanvasQTAgg as FigureCanvas ：这里的FigureCanvas使我们绘图的画布，并且除了是一个Matplotlib类外，还是一个QWidget类，所以可以直接继承使用。

源码#!/usr/bin/env python# coding=utf-8# Author    :   Guo Shaoguang# Email     :   sgguo@shao.ac.cn# Institute :   Shanghai Astronomical Observatoryimport sysfrom PyQt4 import QtGuiimport numpy as npfrom matplotlib.figure import Figurefrom matplotlib.backends.backend_qt4agg import FigureCanvasQTAgg as FigureCanvasclass Qt4MplCanvas(FigureCanvas):    '''    Class to represent the FigureCanvas widget    '''    def __init__(self):        self.fig = Figure()        self.axes = self.fig.add_subplot(111)        self.x = np.arange(0.,3.,0.01)        self.y = np.cos(2*np.pi*self.x)        self.axes.plot(self.x,self.y)        # initialize the canvas where the Figure renders into        FigureCanvas.__init__(self,self.fig)qApp = QtGui.QApplication(sys.argv)mpl = Qt4MplCanvas()mpl.show()sys.exit(qApp.exec_())

效果图PyQt4中嵌入Figure和导航条源码#!/usr/bin/env python# coding=utf-8# Author    :   Guo Shaoguang# Email     :   sgguo@shao.ac.cn# Institute :   Shanghai Astronomical Observatoryimport sysfrom PyQt4 import QtGuiimport numpy as npfrom matplotlib.figure import Figurefrom matplotlib.backends.backend_qt4agg import FigureCanvasQTAgg as FigureCanvasfrom matplotlib.backends.backend_qt4agg import NavigationToolbar2QT as NavigationToolbarclass Qt4MplCanvas(FigureCanvas):    '''    Class to represent the FigureCanvas widget    '''    def __init__(self,parent):        self.fig = Figure()        self.axes = self.fig.add_subplot(111)        self.x = np.arange(0.,3.,0.01)        self.y = np.cos(2*np.pi*self.x)        self.axes.plot(self.x,self.y)        # initialize the canvas where the Figure renders into        FigureCanvas.__init__(self,self.fig)        self.setParent(parent)        FigureCanvas.setSizePolicy(self,QtGui.QSizePolicy.Expanding,QtGui.QSizePolicy.Expanding)        FigureCanvas.updateGeometry(self)class ApplicationWindow(QtGui.QMainWindow):    def __init__(self):        QtGui.QMainWindow.__init__(self)        self.setWindowTitle("Matplotlib Figure in a Qt4 Window With NavigationToolbar")        self.main_widget = QtGui.QWidget(self)        vbl = QtGui.QVBoxLayout(self.main_widget)        qmc = Qt4MplCanvas(self.main_widget)        ntb = NavigationToolbar(qmc,self.main_widget)        vbl.addWidget(qmc)        vbl.addWidget(ntb)        self.main_widget.setFocus()        self.setCentralWidget(self.main_widget)qApp = QtGui.QApplication(sys.argv)aw = ApplicationWindow()aw.show()sys.exit(qApp.exec_())

效果图
直方图源码效果图]]></content>
      <categories>
        <category>Python</category>
        <category>matplotlib</category>
        <category>book</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>plot</tag>
        <tag>matplotlib</tag>
        <tag>numpy</tag>
      </tags>
  </entry>
  <entry>
    <title>Python matplotlib scatter 的使用</title>
    <url>/2017/03/31/python-matplotlib-scatter/</url>
    <content><![CDATA[scatter简介基本用法scatter(x, y, s=None, c=None, marker=None, cmap=None, norm=None, vmin=None, vmax=None, alpha=None, linewidths=None, verts=None, edgecolors=None, hold=None, data=None, **kwargs)

其中各个参数的含义如下:
x，y： 输入数据s：指定散点的大小c：指定散点的颜色。marker：指定散点的图形样式。应参数支持'.'（点标记）、','（像素标记）、'o'（圆形标记）、'v'（向下三角形标记）、'^'（向上三角形标记）、'&lt;'（向左三角形标记）、'&gt;'（向右三角形标记）、'1'（向下三叉标记）、'2'（向上三叉标记）、'3'（向左三叉标记）、'4'（向右三叉标记）、's'（正方形标记）、'p'（五地形标记）、'*'（星形标记）、'h'（八边形标记）、'H'（另一种八边形标记）、'+'（加号标记）、'x'（x标记）、'D'（菱形标记）、'd'（尖菱形标记）、'|'（竖线标记）、'_'（横线标记）等值。cmap：指定散点的颜色映射，会使用不同的颜色来区分散点的值norm：`〜matplotlib.colors.Normalize`，可选，默认：无       `〜matplotlib.colors.Normalize`实例用于缩放       亮度数据为0,1。`norm`只有在`c`是一个数组时才被使用       彩车。如果`None'，则使用默认值：func：`normalize`。vmin，vmax：标量，可选，默认值：无       `vmin`和`vmax`与`norm`结合使用来标准化       亮度数据。如果其中任何一个都是`无'，那么最小和最大的       使用颜色数组。请注意，如果你通过一个“规范”实例，你的       `vmin`和`vmax`的设置将被忽略。alpha：指定散点的透明度，介于0（透明）和1（不透明）之间，linewidths：指定散点边框线的宽度verts：（x，y）的序列，可选       如果`marker`为None，这些顶点将用于       构建标记。标记的中心位于       在（0,0）为标准化单位。整体标记重新调整       由``s``完成。edgecolors ：指定散点边框的颜色


示例图1从原点开始逐渐增加点的大小
x = [i for i in np.arange(0,10,1)]y = [0]*len(x)s = [3**n for n in range(len(x))]plt.scatter(x,y,s=s)plt.show()


示意图2展示一个随机散点图
np.random.seed(5565)N = 50x = np.random.rand(N)y = np.random.rand(N)colors = np.random.rand(N)area = (30 * np.random.rand(N))**2  # 0 to 15 point radiiplt.scatter(x, y, s=area, c=colors, alpha=0.5)plt.show()


示意图3画个同心圆
plt.figure(figsize=(8,6))plt.scatter(2, 1, s=4000, c='r')plt.scatter(2, 1, s=1000 ,c='b')plt.scatter(2, 1, s=10, c='g')plt.show()


示意图4带标记
plt.figure(figsize=(8,6))x_coords = [0.13, 0.22, 0.39, 0.59, 0.68, 0.74,0.93]y_coords = [0.75, 0.34, 0.44, 0.52, 0.80, 0.25,0.55]plt.scatter(x_coords, y_coords, marker = 's', s = 50)for x, y in zip(x_coords, y_coords):    plt.annotate('(%s,%s)'%(x,y), xy=(x,y),xytext = (0, -10), textcoords = 'offset points',ha = 'center', va = 'top')plt.xlim([0,1])plt.ylim([0,1])plt.show()


其他示意图标记的示意图

两个分类的示意图

]]></content>
      <categories>
        <category>Python</category>
        <category>Matplotlib</category>
      </categories>
      <tags>
        <tag>plot</tag>
        <tag>scatter</tag>
      </tags>
  </entry>
  <entry>
    <title>Python 导入模块</title>
    <url>/2015/02/06/python-module/</url>
    <content><![CDATA[Python导入模块使用importimport mathprint(math.pi)print(math.sin(math.pi))

使用fromfrom math import pi,sin,cosprint(pi)print(sin(123))print(cos(123))

定义别名from math import sin as mysinfrom math import cos as mycosprint(mysin(123))print(mycos(123))
]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>import</tag>
        <tag>from</tag>
      </tags>
  </entry>
  <entry>
    <title>构建Python开源包</title>
    <url>/2018/02/03/python-opensource/</url>
    <content><![CDATA[构建Python开源包项目创建按照需求，一般需要创建如下目录及文件：
$ tree ..├── LICENSE├── README.md├── docs├── example└── tests

搭建虚拟运行环境在搭建自己的库的时候，如果希望有一个干净的项目环境的，可以使用virtualenv。方便为后面生成私有项目的 requirement.txt 依赖包文件。
可以使用source ~/virtual/bin/activate进入环境，使用pip freeze &gt; requirement.txt来生成依赖包文件。
编写项目代码这一步主要为构建代码的原型架构以及代码，每个包都需要包含一个’init.py’文件。
编写安装脚本在包的根目录创建文件setup.py，内容一般如下所示：
.. literalinclude::  ../../src/python-package-demo/setup.py
编写文档进入docs文件夹，运行sphinx-quickstart，然后编写相应的rst文件即可。
默认的index.rst的内容如下：
.. literalinclude:: ../../../src/python-package-demo/docs/index.rst
]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>pip</tag>
      </tags>
  </entry>
  <entry>
    <title>Python 命名规则</title>
    <url>/2012/02/06/python-name/</url>
    <content><![CDATA[Python 命名规则Python有自己的编码规则和命名规则，一般如下：

变量名、包名、模块名用小谢
类名首字母大写，或者全部大写，对象名小写
函数名小写

]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>name</tag>
        <tag>module</tag>
        <tag>class</tag>
        <tag>variable</tag>
        <tag>package</tag>
      </tags>
  </entry>
  <entry>
    <title>Python os mkdir</title>
    <url>/2018/02/03/python-os-mkdir/</url>
    <content><![CDATA[Python 创建文件夹os.mkdir() 方法os.mkdir() 方法用于以数字权限模式创建目录。默认的模式为 0777 (八进制)。
如果目录有多级，则创建最后一级，如果最后一级目录的上级目录有不存在的，则会抛出一个 OSError。语法
mkdir()方法语法格式如下：
os.mkdir(path[, mode])


参数

path – 要创建的目录，可以是相对或者绝对路径。
mode – 要为目录设置的权限数字模式。

返回值
该方法没有返回值。
实例以下实例演示了 mkdir() 方法的使用：
.. literalinclude:: ../../src/python-mkdir.py
执行以上程序输出结果为：
Created
]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>mkdir</tag>
        <tag>os</tag>
        <tag>mkdirs</tag>
      </tags>
  </entry>
  <entry>
    <title>Python 编写一个自己的包</title>
    <url>/2018/02/06/python-package/</url>
    <content><![CDATA[Python 编写一个自己的包这个教程将会指导你开发一个属于自己的python包，还包含如何添加必要的文件以及包的结构，最后说说如何编译并上传该文件。
简单示例假定工程的名称为：example_pkg，需要创建下列目录结构：
packaging_tutorial/  example_pkg/    __init__.py

下面所有的操作均在目录中packaging_tutorial进行。
example_pkg/init.py is required to import the directory as a package, and can simply be an empty file.
创建package文件标准package起始最好包含以下文件，
packaging_tutorial/  example_pkg/    __init__.py  tests/  setup.py  LICENSE  README.md

创建test文件夹tests/主要用来存放unit测试文件，此时先留空。
创建 setup.pysetup.py文件用于编译，内容主要包含package的名字、版本、描述等等信息。
示例如下：
import setuptoolswith open("README.md", "r") as fh:    long_description = fh.read()setuptools.setup(    name="example-pkg-YOUR-USERNAME-HERE", # Replace with your own username    version="0.0.1",    author="Example Author",    author_email="author@example.com",    description="A small example package",    long_description=long_description,    long_description_content_type="text/markdown",    url="https://github.com/pypa/sampleproject",    packages=setuptools.find_packages(),    classifiers=[        "Programming Language :: Python :: 3",        "License :: OSI Approved :: MIT License",        "Operating System :: OS Independent",    ],    python_requires='&gt;=3.6',)

setup() 的几个最必须的参数如下所示：
name is the distribution name of your package. This can be any name as long as only contains letters, numbers, _ , and -. It also must not already be taken on pypi.org. Be sure to update this with your username, as this ensures you won’t try to upload a package with the same name as one which already exists when you upload the package.version is the package version see PEP 440 for more details on versions.author and author_email are used to identify the author of the package.description is a short, one-sentence summary of the package.long_description is a detailed description of the package. This is shown on the package detail package on the Python Package Index. In this case, the long description is loaded from README.md which is a common pattern.long_description_content_type tells the index what type of markup is used for the long description. In this case, it’s Markdown.url is the URL for the homepage of the project. For many projects, this will just be a link to GitHub, GitLab, Bitbucket, or similar code hosting service.packages is a list of all Python import packages that should be included in the distribution package. Instead of listing each package manually, we can use find_packages() to automatically discover all packages and subpackages. In this case, the list of packages will be example_pkg as that’s the only package present.classifiers gives the index and pip some additional metadata about your package. In this case, the package is only compatible with Python 3, is licensed under the MIT license, and is OS-independent. You should always include at least which version(s) of Python your package works on, which license your package is available under, and which operating systems your package will work on. For a complete list of classifiers, see https://pypi.org/classifiers/.


创建README.md创建 README.md ，写上你准备写入的内容：
# Example PackageThis is a simple example package. You can use[Github-flavored Markdown](https://guides.github.com/features/mastering-markdown/)to write your content.


创建LICENSE比如使用MIT
Copyright (c) 2018 The Python Packaging AuthorityPermission is hereby granted, free of charge, to any person obtaining a copyof this software and associated documentation files (the "Software"), to dealin the Software without restriction, including without limitation the rightsto use, copy, modify, merge, publish, distribute, sublicense, and/or sellcopies of the Software, and to permit persons to whom the Software isfurnished to do so, subject to the following conditions:The above copyright notice and this permission notice shall be included in allcopies or substantial portions of the Software.THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS ORIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THEAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHERLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THESOFTWARE.

生成发布包接下来我们生成发布的软件包
$ python3 setup.py sdist bdist_wheel

这个命令会生成两个文件：
dist/  example_pkg_YOUR_USERNAME_HERE-0.0.1-py3-none-any.whl  example_pkg_YOUR_USERNAME_HERE-0.0.1.tar.gz

其中 tar.gz 文件为源码，.whl为编译的包。
比较新的pip可以直接按照whl格式的编译包。
一般而言，我们都需要上次源码以及编译包。
参考代码参考 https://www.github.com/shaoguangleo/atas/python
]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>package</tag>
      </tags>
  </entry>
  <entry>
    <title>Python 包收集</title>
    <url>/2021/01/06/python-package-collection/</url>
    <content><![CDATA[Python 特备好用的包显示
colorama 跨平台颜色显示

天文历算
PyEphem ： 用于计算各种天体、卫星等的位置信息

参考代码参考 https://www.github.com/shaoguangleo/atas/python
]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>package</tag>
      </tags>
  </entry>
  <entry>
    <title>Python 模块的搜索路径</title>
    <url>/2015/02/06/python-path/</url>
    <content><![CDATA[Python 模块的搜索路径设置PYTHONPATH环境变量$ export PYTHONPATH=$PYTHONPATH:/new/path/

通过sys.path来设置import sysprint (sys.path)print (sys.path.append('/new/path'))print (sys.path)

通过IDE来设置根据不用的IDE，有不同的方法，一般在setting那里，比如Pycharm或者VS code。
获取文件路径print("获取当前文件路径——" + os.path.realpath(__file__))  # 获取当前文件路径parent = os.path.dirname(os.path.realpath(__file__))print("获取其父目录——" + parent)  # 从当前文件路径中获取目录garder = os.path.dirname(parent)print("获取父目录的父目录——" + garder)print("获取文件名" + os.path.basename(os.path.realpath(__file__)))  # 获取文件名# 当前文件的路径pwd = os.getcwd()               print("当前运行文件路径" + pwd)# 当前文件的父路径father_path = os.path.abspath(os.path.dirname(pwd) + os.path.sep + ".")print("运行文件父路径" + father_path)# 当前文件的前两级目录grader_father = os.path.abspath(os.path.dirname(pwd) + os.path.sep + "..")print("运行文件父路径的父路径" + grader_father)



import oscurpath = os.path.realpath(__file__)        # 获取当前文件绝对路径print(curpath)dirpath = os.path.dirname(curpath)          # 获取当前文件的文件夹路径print(dirpath)casespath = os.path.join(dirpath, "cases")      # 拼接文件路径print(casespath)report = os.path.join(dirpath, "report", "result.html")         # 拼接文件夹路径print(report)

]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>path</tag>
      </tags>
  </entry>
  <entry>
    <title>pip换源（更换软件镜像源）</title>
    <url>/2017/01/23/python-pip-change-source/</url>
    <content><![CDATA[pip使用国内镜像源pip是Python中非常方便易用的安装包管理器，但是在实际下载安装包的时候总是连接不上或者下载速度特别慢, pypi.python.org就是其中一个。
所以，使用pip给Python安装软件时，经常出现Timeout连接超时错误。修改pip连接的软件库到国内的源可以解决这个问题。

阿里云 http://mirrors.aliyun.com/pypi/simple/
中国科技大学 https://pypi.mirrors.ustc.edu.cn/simple/ 
豆瓣(douban) http://pypi.douban.com/simple/ 
清华大学 https://pypi.tuna.tsinghua.edu.cn/simple/
中国科学技术大学 http://pypi.mirrors.ustc.edu.cn/simple/

方法如下：
直接修改配置文件1）检查pip.conf文件是否存在
$ cd ~$ mkdir .pip$ ls ~/.pip$
2）直接编辑pip.conf    vi ~/.pip/pip.conf
[global]index-url = http://mirrors.aliyun.com/pypi/simple/[install]trusted-host = mirrors.aliyun.com

或者
[global]  timeout = 6000  index-url = http://pypi.douban.com/simple/  [install]  use-mirrors = true  mirrors = http://pypi.douban.com/simple/  trusted-host = pypi.douban.com

临时换源如果只是想临时更改一下，可以使用-i参数，
命令格式：sudo pip3 install 包名 -i 镜像源url
比如：
$ pip3 install numpy -i https://pypi.douban.com/simple

]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>pip</tag>
      </tags>
  </entry>
  <entry>
    <title>pip 使用</title>
    <url>/2017/01/23/python-pip/</url>
    <content><![CDATA[简介pip是Python中非常方便易用的安装包管理器，但是在实际下载安装包的时候总是连接不上或者下载速度特别慢, pypi.python.org就是其中一个。
所以，使用pip给Python安装软件时，经常出现Timeout连接超时错误。修改pip连接的软件库可以解决这个问题。

阿里云 https://mirrors.aliyun.com/pypi/simple/
中国科技大学 https://pypi.mirrors.ustc.edu.cn/simple/ 
豆瓣(douban) https://pypi.douban.com/simple/
清华大学 https://pypi.tuna.tsinghua.edu.cn/simple/
中国科学技术大学 https://pypi.mirrors.ustc.edu.cn/simple/

更新软件有两种方法，一种可以通过逐个更新模块：
# 查看所有可更新的模块：　　pip list --outdated# 更新某一个模块：　　　　　pip install --upgrade module_name

#安装对应的模块：　　　　　$ pip install pip-review#更新所有的模块： 　　　　  $ pip-review --local --interactive

更新源方法如下：
直接修改配置文件1）检查pip.conf文件是否存在
$ cd ~$ mkdir .pip$ ls ~/.pip$
2）直接编辑pip.conf    sudo vi ~/.pip/pip.conf
[global]index-url = https://mirrors.aliyun.com/pypi/simple/[install]trusted-host = mirrors.aliyun.com

或者
[global]  timeout = 6000  index-url = https://pypi.douban.com/simple/  [install]  use-mirrors = true  mirrors = https://pypi.douban.com/simple/  trusted-host = pypi.douban.com

临时换源命令格式：sudo pip3 install 包名 -i 镜像源url
比如：sudo pip3 install django -i https://pypi.douban.com/simple
Troubleshootingpip install mpi4pyTraceback (most recent call last):  File "~/virtual_evn/bin/pip", line 6, in &lt;module&gt;    from pip._internal.cli.main import main

解决方法：
$ export PYTHONPATH=~/virtual_env/lib/python3.7/site-packages/
]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>pip</tag>
      </tags>
  </entry>
  <entry>
    <title>Python property函数</title>
    <url>/2019/05/10/python-property/</url>
    <content><![CDATA[Python property动态属性如果不希望类的某些属性被悄悄地访问、赋值或修改，希望在访问、赋值或修改时能得到一些通知，可以使用函数property。
函数原型为：
property([fget[,fset[,fdel[,doc]]]])

它返回新式类的一个属性，其中fget是属性被访问时执行的方法，fset是属性被赋值时执行的方法，fdel是属性被删除时执行的方法。
比如下面的例子：
class MyClass(object):    def __init__(self) :        self._param = None    def getParam(self):        print('get param : %s ' % self._param)        return self._param    def setParam(self, value):        print('set param : %s' % self._param)        self._param = value    def delParam(self):        print('del param : %s' % self._param)        del self._param    param = property(getParam, setParam, delParam)if __name__ == '__main__':    myclass = MyClass()    myclass.param = 123    print('current param is : %s' % myclass.param)    del myclass.param

接下来用property来访问类的属性
class MyClass(object):    def __init__(self) :        self._param = None    @property    def param(self):        print('get param : %s ' % self._param)        return self._param    @param.setter    def param(self, value):        print('set param : %s' % self._param)        self._param = value    @param.deleter    def param(self):        print('del param : %s' % self._param)        del self._paramif __name__ == '__main__':    myclass = MyClass()    myclass.param = 123    print('current param is : %s' % myclass.param)    del myclass.param

两种方法效果一致，不过第二种方法更加的灵活、简单，在开发中建议使用。
]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>lambda</tag>
      </tags>
  </entry>
  <entry>
    <title>Python PyGtk 学习笔记</title>
    <url>/2011/08/07/python-pygtk/</url>
    <content><![CDATA[PyGtk 学习笔记PyGtk简介PyGtk是一套用Python封装的GTK 的图形库，通过Python编程语言使用PyGtk图形库可以轻松的写出GUI程序。它是GNOME项目的一部分。PyGTK是基于LGPL许可之下的免费软件。其原始作者是James Henstridge。PyGTK非常容易使用,对于速成原型法,它是相当理想的。普遍地认为,PyGTK是最流行的GTK 库封装中的一种。其中PyGtk包含几个模块：GObject、ATK、GTK、Pango、Cairo、CladeGObject是基类,它为PyGTK所以类提供通用的属性和函数。

    ATK 是一个提供辅助功能的工具包。该工具包提供了帮助残障人士使用计算机的各种工具。


    GTK 是用户界面模块。


    Pango是一个用于处理文本和国际化的库。


    Cairo是一个用于创建2D矢量模型的库。


    Glade是用来从XML描述中构建GUI界面。



如果你是Linux用户的话，不必担心安装配置问题，目前大部分Linux发行版中都包含了Python、PyGtk，所以直接用就行了。
从一个简单示例开始很简单的一个窗口，下面是实现它的完整代码：
#!/usr/bin/python#-*- encoding:utf-8 -*-#建立一个窗口import gtkclass PyApp(gtk.Window):    def __init__(self):        super(PyApp, self).__init__()        self.set_title("PyGtk")        self.set_size_request(250, 150)        self.set_position(gtk.WIN_POS_CENTER)        self.connect(“destroy”, gtk.main_quit)        self.show()    def main(self):        gtk.main()print __name__if __name__ == "__main__":    pyapp = PyApp()    pyapp.main()

使用PyGtk当然要有一定的Python基础，把上述代码保存为pygtkwin.py，在控制台执行如下命令就能看到一个窗口了。python pygtkwin.py简单分析一下代码：
import gtk#这里是导入PyGtk的gtk模块。self.set_title(“PyGtk”)self.set_size_request(250, 150)self.set_position(gtk.WIN_POS_CENTER)#这里的PyApp继承至GTK的窗口类，即gtk.Window。上面的set分别是设置窗口标题、窗口尺寸、窗口位置。self.connect(“destroy”, gtk.main_quit)#这里的connect是把该类的destroy事件绑定到gtk.main_quit方法上。效果就是点击窗口的关闭按钮，就会销毁整个装口。self.show()#用来现实这个窗口。gtk.main()#使用于启动GTK的循环，来保持窗口的运行。
]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>PyGTK</tag>
        <tag>GTK</tag>
        <tag>ATK</tag>
        <tag>Cairo</tag>
        <tag>Glade</tag>
        <tag>Pango</tag>
      </tags>
  </entry>
  <entry>
    <title>python pyinstaller打包</title>
    <url>/2013/01/23/python-pyinstaller/</url>
    <content><![CDATA[Python程序打包UI =&gt; Python在Qt的界面开发开发中，设计界面可以使用Qt Creator或者Designer，本质是一样的。
设计完成会生成一个ui后缀的文件，格式其实是xml语言的文本文件。
按照设计比如生成一个window.ui的文件，那么可以使用pyuic来生成python文件，命令如下所示：
pyuic5 window.ui -o window.py

此时的window.py文件就是界面的python接口了，接下来我们需要做的就是编写一个程序调用这个界面，简单的如下所示：
import sysfrom PyQt5.QtWidgets import QApplication, QMainWindow, QFileDialogfrom window import *class MyMainWindow(QMainWindow, Ui_MainWindow):    def __init__(self, parent=None):        super(MyMainWindow, self).__init__(parent)        self.setupUi(self)        self.actionClose.triggered.connect(self.close)        self.actionOpen.triggered.connect(self.openMsg)if __name__ == '__main__':    app = QApplication(sys.argv)    myWin = MyMainWindow()    myWin.show()    sys.exit(app.exec_())

RC = &gt; PythonPyQt5提供了pyrcc5来将资源文件转化为python文件，默认加上rc后缀与Qt Designer保持一致。命令如下所示：
pyrcc5 app.qrc -o app_rc.py

check一下生成的python文件，可以直接调用。
]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>pyinstaller</tag>
      </tags>
  </entry>
  <entry>
    <title>python PyQt 界面设计</title>
    <url>/2017/01/23/python-pyqt5-ui/</url>
    <content><![CDATA[PyQt界面设计UI =&gt; Python在Qt的界面开发开发中，设计界面可以使用Qt Creator或者Designer，本质是一样的。
设计完成会生成一个ui后缀的文件，格式其实是xml语言的文本文件。
按照设计比如生成一个window.ui的文件，那么可以使用pyuic来生成python文件，命令如下所示：
pyuic5 window.ui -o window.py

此时的window.py文件就是界面的python接口了，接下来我们需要做的就是编写一个程序调用这个界面，简单的如下所示：
import sysfrom PyQt5.QtWidgets import QApplication, QMainWindow, QFileDialogfrom window import *class MyMainWindow(QMainWindow, Ui_MainWindow):    def __init__(self, parent=None):        super(MyMainWindow, self).__init__(parent)        self.setupUi(self)        self.actionClose.triggered.connect(self.close)        self.actionOpen.triggered.connect(self.openMsg)if __name__ == '__main__':    app = QApplication(sys.argv)    myWin = MyMainWindow()    myWin.show()    sys.exit(app.exec_())

RC = &gt; PythonPyQt5提供了pyrcc5来将资源文件转化为python文件，默认加上rc后缀与Qt Designer保持一致。命令如下所示：
pyrcc5 app.qrc -o app_rc.py

check一下生成的python文件，可以直接调用。
]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>pyuic5</tag>
        <tag>pyrcc5</tag>
      </tags>
  </entry>
  <entry>
    <title>python 环境变量设置PYTHONPATH</title>
    <url>/2017/01/23/python-pythonpath/</url>
    <content><![CDATA[python 环境变量设置PYTHONPATHPYTHONPATH是Python搜索路径，默认我们import的模块都会从PYTHONPATH里面寻找。
打印PYTHONPATH：
import osprint sys.path&gt;['', '/usr/local/lib/python2.7/dist-packages/dlib-19.4.0-py2.7-linux-x86_64.egg', '/home/leo',...]

注意：sys.path 也可以用 os.sys.path 替换，两个应该是同一个命令，推荐使用sys.path, 因为 os.sys.path 在python document 中好像没有提及．
设置PYTHONPATH方法一：命令窗口添加路径
export PYTHONPATH=$PYTHONPATH:/home/leo

注意：此方法只在当前命令窗口生效，即如果打开一个新的Terminal 窗口，定位到当前目录，　打印PYTHONPATH 是没有刚才加入的路径的．
方法二：在python 中添加：
import syssys.path.append('/home/leo/')]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>PYTHONPATH</tag>
      </tags>
  </entry>
  <entry>
    <title>PyQt 教程</title>
    <url>/2018/01/10/python-qt-0/</url>
    <content><![CDATA[PyQt教程PyQt是一个GUI组件包，是Qt的一个Python接口，十分强大，并且可跨平台。
PyQt是一个Python编程和Qt库的瑞士军刀。
本教程将指导如何使用PyQt.
]]></content>
      <categories>
        <category>Python</category>
        <category>PyQt5</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>PyQt5</tag>
      </tags>
  </entry>
  <entry>
    <title>PyQt 教程</title>
    <url>/2018/01/10/python-qt-1-introduction/</url>
    <content><![CDATA[PyQt教程PyQt是一个GUI组件包，跨平台，支持Windows，Linux和MacOSX。
PyQt的API包括非界面的QtCore，界面的QtGui和其他一些诸如QtXml、QtSvg、QtSql等。
PyQt有两个版本，目前为5.5版本。
]]></content>
      <categories>
        <category>Python</category>
        <category>PyQt5</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>PyQt5</tag>
      </tags>
  </entry>
  <entry>
    <title>PyQt5 教程</title>
    <url>/2018/01/10/python-qt-2-helloworld/</url>
    <content><![CDATA[PyQt5 最简单的hello world简介创建一个简单的GUi程序，需要包括下面几个步骤：

导入QtWidgets模组
创建一个Application
QWidget用于创建顶层窗口，然后增加一个QLabel
设置标签的内容为Hello World
设置窗口的尺寸和位置
进入主循环

源码import sysfrom PyQt5 import QtGui, QtWidgetsdef window():    app = QtWidgets.QApplication(sys.argv)    w = QtWidgets.QWidget()    b = QtWidgets.QLabel(w)    b.setText("Hello World")    w.setGeometry(100,100,200,50)    b.move(50,20)    w.setWindowTitle("PyQt HelloWorld")    w.show()    sys.exit(app.exec_())if __name__ == '__main__':    window()

效果图
]]></content>
      <categories>
        <category>Python</category>
        <category>PyQt5</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>PyQt5</tag>
      </tags>
  </entry>
  <entry>
    <title>python中文档SPHINX的使用</title>
    <url>/2017/01/23/python-reStructuredText/</url>
    <content><![CDATA[reStructuredText 简介 reStructuredText (reST) 为文档生成者提供足够的信息. reST 被认为是简单，实用的标记语言，因此学习它不会花太多时间.
See also
读物 reStructuredText User Documentation. 文档内 “ref” 链接指向reST的分类参考文献.
段落段落 (:duref:ref ) 是reST 文件的基本模块. 段落是由空行分隔的一段文本. 和Python一样, 对齐也是reST的操作符, 因此同一段落的行都是左对齐的.
内联标记标准的reST 内联标记相当简单:

星号: *text* 是强调 (斜体),
双星号: **text** 重点强调 (加粗),
反引号: text 代码样式.

星号及反引号在文本中容易与内联标记符号混淆，可使用反斜杠符号转义.
标记需注意的一些限制:

不能相互嵌套,
内容前后不能由空白: 这样写* text* 是错误的,
如果内容需要特殊字符分隔. 使用反斜杠转义，如: thisis\ *one*\ word.

这些限制在未来版本可能会被改善.
reST 也允许自定义 “文本解释角色”’, 这意味着可以以特定的方式解释文本. Sphinx以此方式提供语义标记及参考索引，操作符为 :rolename:content``.
标准reST 提供以下规则:

:durole:emphasis – 写成 *emphasis*
:durole:strong – 写成 **strong**
:durole:literal – 写成 literal
:durole:subscript – 下标
:durole:superscript – 上标
:durole:title-reference – 书、期刊等材料的标题

详情请查看 内联标记 .
列表与引用列表标记 (:duref:ref ) 的使用最自然: 仅在段落的开头放置一个星号和一个缩进. 编号的列表也可以;也可以使用符号 # 自动加序号:
* 这是一个项目符号列表.* 它有两项，  第二项使用两行.1. 这是个有序列表.2. 也有两项.#. 是个有序列表.#. 也有两项.

列表可以嵌套，但是需跟父列表使用空行分隔
* 这是* 一个列表  * 嵌套列表  * 子项* 父列表继续

定义列表 (:duref:ref )
术语 (term 文本开头行)   定义术语，必须缩进   可以有多段组成下一术语（term）   描述.

一行仅能写一个术语.
引用段落 (:duref:ref ) 仅使用缩进（相对于周围段落）创建.
行模块 (:duref:ref ) 可以这样分隔
| 这些行| 在源文件里| 被分隔的一模一样.

还有其他有用的模块:

字段列表 (:duref:ref )
选项列表(:duref:ref )
字面引用模块 (:duref:ref )
文档测试模块 (:duref:ref )

源代码字面代码块 (:duref:ref ) 在段落的后面使用标记 :: 引出. 代码块必须缩进(同段落，需要与周围文本以空行分隔):
这是一段正常文本. 下一段是代码文字::   它不需要特别处理，仅是   缩进就可以了.   它可以有多行.再是正常的文本段... code-block:: c                                                   :linenos:                                                       :emphasize-lines: 3,6   # 高亮显示3、6行                                                                                                        void foo()                                                      {                                                                                                    int i;                                                                                                                          for(i=0; i&lt;10; i++)                                                 printf("i: %d\n", a);                                   }       

这个 :: 标记很优雅:

如果作为独立段落存在,则整段都不会出现在文档里.
如果前面有空白，则标记被移除.
如果前面是非空白，则标记被一个冒号取代.

因此上面的例子第一段文字将变为”下一段是代码文字:”.
表格支持两种表格. 一种是 网格表格 (:duref:ref ), 可以自定义表格的边框. 如下:
+------------------------+------------+----------+----------+| Header row, column 1   | Header 2   | Header 3 | Header 4 || (header rows optional) |            |          |          |+========================+============+==========+==========+| body row 1, column 1   | column 2   | column 3 | column 4 |+------------------------+------------+----------+----------+| body row 2             | ...        | ...      |          |+------------------------+------------+----------+----------+

简单表格 (:duref:ref ) 书写简单, 但有一些限制: 需要有多行，且第一列元素不能分行显示，如下:
=====  =====  =======A      B      A and B=====  =====  =======False  False  FalseTrue   False  FalseFalse  True   FalseTrue   True   True=====  =====  =======

超链接外部链接使用 ``链接文本 http://example.com/_ 可以插入网页链接. 链接文本是网址，则不需要特别标记，分析器会自动发现文本里的链接或邮件地址.
可以把链接和标签分开 (:duref:ref ), 如下:
段落里包含 `a link`_... _a link: http://example.com/

内部链接内部链接是Sphinx特定的reST角色, 查看章节 交叉索引的位置.
章节章节的标题 (:duref:ref ) 在双上划线符号之间（或为下划线）, 并且符号的长度不能小于文本的长度:
=================This is a heading=================

通常没有专门的符号表示标题的等级，但是对于Python 文档，可以这样认为:

# 及上划线表示部分
* 及上划线表示章节
=, 小章节
-, 子章节
^, 子章节的子章节
", 段落

当然也可以标记（查看 reST 文档), 定义章节的层次，但是需要注意输出格式(HTML, LaTeX)所支持的层次深度 .
显式标记显式标记”Explicit markup” (:duref:ref ) 用在那些需做特殊处理的reST结构中, 如尾注，突出段落，评论，通用指令.
显式标记以 .. 开始，后跟空白符，与下面段落的缩进一样. (在显示标记与正常的段落间需有空行，这听起来有些复杂，但是写起来会非常直观.)
指令指令 (:duref:ref ) 是显式标记最常用的模块. 也是reST 的扩展规则, 在 Sphinx 经常被用到.
文档工具支持以下指令:

警告: 

, :dudir:caution, 注意
:dudir:danger, 危险
:dudir:error, 错误
:dudir:hint,提示
:dudir:important,重要
:dudir:note,注解
:dudir:tip, 小技巧
:dudir:warning 警告
及通用标记 :dudir:admonition. (大多数模式仅支持 “note” 及 “warning” )


图像:

:dudir:image (详情可看下面的 图像 )
:dudir:figure (有标题及可选说明的图像)


额外的主体元素:

:dudir:contents  (本地，仅是当前文件的内容表格)
:dudir:container (自定义容器，用来生成HTML的 &lt;div&gt; )
:dudir:rubric (和文档章节无关的标题)
:dudir:topic, :dudir:sidebar (高亮显示的主体元素)
:dudir:parsed-literal (支持内联标记的斜体模块)
:dudir:epigraph (可选属性行的摘要模块)
:dudir:highlights, :dudir:pull-quote (有自己的类属性的摘要模块)
:dudir:compound ( 复合段落)


专用表格:

:dudir:table (有标题的表格)
:dudir:csv-table (CSV自动生成表格)
:dudir:list-table (列表生成的表格)


专用指令:

:dudir:raw (包含原始格式的标记)
:dudir:include (包含reStructuredText标记的文件) – 在Sphinx中,如果包含绝对文件路径，指令会以源目录地址做为参照
:dudir:class (将类属性指派给下一个元素) [1]


HTML 特性:

:dudir:meta (生成HTML &lt;meta&gt; 标签)
:dudir:title (覆盖文档标题)


影响标记:

:dudir:default-role (设置新的默认角色)
:dudir:role (创建新的角色)

如果仅有一个文件，最好使用 :confval:default_role.


设置不使用指令 :dudir:sectnum, :dudir:header 及 :dudir:footer.
Sphinx 新增指令可查阅 Sphinx标记的组成.
指令有名字，参数，选项及内容组成. (记住这些，在下面一小节中自定义指令里会用到).来看一个例子:
.. function:: foo(x)              foo(y, z)   :module: some.module.name   返回用户输入的一行文本.

function 是指令名字. 在第一行和第二行给出了两个参数, 及一个选项 module (如你所见，选项在参数后给出，由冒号引出). 选项必须与指令有一样的缩进.
指令的内容在隔开一个空行后，与指令有一样缩进.
图像reST 支持图像指令 (:dudir:ref ), 如下:
.. image:: gnu.png   (选项)

这里给出的文件名( gnu.png) 必须是源文件的相对路径，如果是绝对路径则以源目录为根目录. 例如，在文件 sketch/spam.rst 引用图像 images/spam.png ，则使用 ../images/spam.png 或者 /images/spam.png.
Sphinx 会自动将图像文件拷贝到输出目录的子目录里，( 输出HTML时目录为 _static )
图像的大小选项 (width 及 height) : 如果没有单位或单位为像素, 给定的尺寸信息仅在输出通道支持像素时才有用 ( 如输出LaTeX 没用). 其他单位在输出(如 pt )HTML、LaTeX 时被用到.
Sphinx 延伸了标准的文档化行为，只需在后面加星号:
.. image:: gnu.*

上面这样写，Sphinx 会搜索所有名字匹配的图像，而不管图像类型. 每个生成器则会选择最合适的图像. 一般，在源文件目录里文件名 gnu.* 会含有两个文件 gnu.pdf 和 gnu.png , LaTeX 生成器会选择前者，而HTML 生成器则匹配后者.
Changed in version 0.4: 添加对文件名以星号结束的支持.
Changed in version 0.6: 图像路径可以是绝对路径.
尾注尾注 (:duref:ref ), 使用 [#name]_ 标记尾注的位置, 尾注的内容则在文档底部红色标题”Footnotes”的后面 , 如下:
Lorem ipsum [#f1]_ dolor sit amet ... [#f2]_.. rubric:: Footnotes.. [#f1] 第一条尾注的文本... [#f2] 第二条尾注的文本.

你也可以使用数字尾注 ([1]_) 或使用自动排序的([#]_).
引用支持标准的reST 引用 (:duref:ref ) , 且新增了”global”特性, 所有参考文献不受所在文件的限制. 如:
Lorem ipsum [Ref]_ dolor sit amet... [Ref] 参考文献, 书,URL 等.

引用的使用同尾注很相近，但是它们没有数字标签或以 # 开始.
替换reST 支持替换 “substitutions” (:duref:ref ), 有一小段文本或标记被关联到 |name|. 定义与尾注一样需有明确的标记块，如下:
.. |name| replace:: replacement *text*

或者:
.. |caution| image:: warning.png             :alt: Warning!

详情查看 :duref:reST reference for substitutions  .
如果想在所有文档中使用这些替换, 需把它们放在 :confval:rst_prolog 或一个单独文件里， 然后在使用它们的文档文件里包含这个文件，包含指令 include . (请给出包含文件的扩展名，已区别于其他的源文件，避免Sphinx将其作为独立的文档文件.)
Sphinx 定义了一些默认的替换, 请查看 替换.
评论有明确标记块但又不是有效的结构标记的标记 (像上面的尾注）都被视为评论 (:duref:ref ). 例如:
.. 这是一个评论.

可以通过缩进产生多行评论:
..   这整个缩进块都是   一个评论.   仍是一个评论.

源编码在reST使用Unicode字符可以容易的包含特殊字符如破折号，版权标志. Sphinx 默认源文件使用UTF-8 编码; 你可以通过 :confval:source_encoding 的配置值改变编码.
常见问题具体使用中可能会遇到一些问题:

内联标记的分离 如上面所讲，内联标记需与周围的文本使用空格分隔, 内联标记内部则使用反斜线转义空格. 查看详情: the reference .
内联标记不能嵌套 像这样写 *see :func:foo* 是不允许的.

Footnotes



[1]
当默认主域里包含指令 class , 这个指令将被隐藏 因此, Sphinx使用 rst-class.







Be sure to say yes to autodoc
More information can refer https://zh-sphinx-doc.readthedocs.io/en/latest/rest.html#id2
]]></content>
      <categories>
        <category>Python</category>
        <category>Sphinx</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>sphinx</tag>
      </tags>
  </entry>
  <entry>
    <title>Python read() readline()以及readlines()用法</title>
    <url>/2012/01/23/python-read/</url>
    <content><![CDATA[python中read() readline()以及readlines()用法文件对象提供了三个“读”方法： .read()、.readline() 和 .readlines()。每种方法可以接受一个变量以限制每次读取的数据量，但它们通常不使用变量。

read() 每次读取整个文件，它通常用于将文件内容放到一个字符串变量中。然而 .read() 生成文件内容最直接的字符串表示，但对于连续的面向行的处理，它却是不必要的，并且如果文件大于可用内存，则不可能实现这种处理。
readline() 和 readlines() 非常相似。它们都在类似于以下的结构中使用：

Python .readlines() 示例
fh = open(‘c:\\autoexec.bat’)for  line in  fh.readlines():print  line

.readline() 和 .readlines() 之间的差异是后者一次读取整个文件，象 .read() 一样。.readlines() 自动将文件内容分析成一个行的列表，该列表可以由 Python 的 for … in … 结构进行处理。另一方面，.readline() 每次只读取一行，通常比 .readlines() 慢得多。仅当没有足够内存可以一次读取整个文件时，才应该使用 .readline()。
]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>read</tag>
        <tag>readline</tag>
        <tag>readlines</tag>
      </tags>
  </entry>
  <entry>
    <title>python中文档SPHINX的输出格式</title>
    <url>/2023/01/23/python-sphinx-output-format/</url>
    <content><![CDATA[SPHINX的输出文档格式用rst编写，然后用sphinx-build进行编译，还是效果相当不错地，只要掌握了格式，可以一次编译，多种格式输出，主要是用的可能是html和pdf，不过其他格式也是具备的。
这些命令提供了广泛的灵活性，以满足各种输出格式的需求，如下所示：

HTML：make html 生成HTML格式的文档。
目录HTML：make dirhtml 生成HTML格式的文档，每个目录下都有一个名为index.html的文件。
单个HTML文件：make singlehtml 生成一个单独的大型HTML文件，这个比较方便分享。
Pickle：make pickle 生成Pickle文件。
JSON：make json 生成JSON文件。
HTML帮助项目：make htmlhelp 生成HTML格式的帮助项目。
qthelp项目：make qthelp 生成qthelp项目。
Devhelp项目：make devhelp 生成Devhelp项目。
ePub：make epub 生成ePub格式的电子书。
LaTeX：make latex 生成LaTeX格式的文档，可以设置 PAPER=a4 或者 PAPER=letter。
LaTeXPDF：make latexpdf 生成LaTeX和PDF格式的文档。
LaTeXPDFJA：make latexpdfja 生成LaTeX和PDF格式的文档，使用platex/dvipdfmx编译运行。
文本：make text 生成文本文件。
手册页：make man 生成手册页。
Texinfo：make texinfo 生成Texinfo格式的文档。
info：make info 生成Texinfo格式的文档，并通过makeinfo运行它们。
获取gettext：make gettext 生成PO消息目录，用于多语种支持。
变更概览：make changes 生成所有已更改/添加/弃用项的概览。
XML：make xml 生成Docutils原生XML文件。
伪XML：make pseudoxml 为显示目的生成伪XML-XML文件。
链接检查：make linkcheck 检查所有外部链接的完整性。
doctest：make doctest 运行文档中嵌入的所有doctest（如果启用）。
覆盖率：make coverage 运行文档的覆盖率检查（如果启用）。
清理：make clean 删除构建目录中的所有内容。

]]></content>
      <categories>
        <category>Sphinx</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>Python</tag>
        <tag>sphinx</tag>
      </tags>
  </entry>
  <entry>
    <title>python 字符串操作</title>
    <url>/2018/01/23/python-string/</url>
    <content><![CDATA[Python的字符串操作字符串连接用+print ('hello' + 'world')

直接连接print ('hello'  ' world')
标准输出的重定向from io import StringIOimport sysold_stdout = sys.stdoutresult = StringIO()sys.stdout = resultprint('hello','world')sys.stdout = old_stdoutresult_str = result.getvalue()print(result_str)

格式化输出s = '&lt;%s&gt; &lt;%s&gt;' % ('hello','world')


使用join函数s = " ".join(['hello','world'])print(s)
]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>string</tag>
      </tags>
  </entry>
  <entry>
    <title>Python 什么是Tkinter</title>
    <url>/2018/01/01/python-tkinter-1-1-what-is-tkinter/</url>
    <content><![CDATA[什么是 Tkinter?Tkinter模块是Tk GUI工具的标准Python接口。 最开始由Sun Labs开发。
Tk和Tkinter在大多数的Unix平台上都适用，同时也支持Windows和Macintosh。
从8.0版本开始，Tk支持原生的界面，体验很不错。
Tkinter包含许多模块。Tk接口由模块 _tkinter 提供。这个模块包含的都是低层次的接口，对于应用程序不需要调用。
公共的接口也是蛮多的，不过最常用的就是Tkinter模块。
导入方式为：
import tkinter

更常用的为：
from tkinter import *

或者
import tkinter as Tk

]]></content>
      <categories>
        <category>Python</category>
        <category>GUI</category>
        <category>Tkinter</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>python3</tag>
        <tag>tkinter</tag>
      </tags>
  </entry>
  <entry>
    <title>python中文档SPHINX的使用</title>
    <url>/2017/01/23/python-sphinx/</url>
    <content><![CDATA[Python中文档Sphinx的使用安装软件包$ pip install Sphinx

生成模板# 大部分默认即可$ sphinx-quickstart

此时可以看到生成的文件为：
➜  docs git:(master) ✗ ls _build    _static   Makefile                                         _templates   conf.py  index.rst

此时查看index.rst文件
.. toctree::   :maxdepth: 2   :caption: Contents:Indices and tables==================* :ref:`genindex`* :ref:`modindex`* :ref:`search`





输出文件# 生成html文件$ make html# 生成pdf文件$ make latexpdf

新增文件此时新增一个文档和图片
touch hello.rstcp test.png _static/test.png

更新index.rst文件，注意缩进
.. toctree::   :maxdepth: 2   :caption: Contents:   hello.rst   .. image:: _static/test.pngIndices and tables==================* :ref:`genindex`* :ref:`modindex`* :ref:`search`

更新模板可以通过修改_static/default.css和_templates/layout.html来修改和定制网站的外观。
多语种支持安装软件
$pip3 install sphinx-intl

增加下列信息到conf.py，
locale_dirs = ['locale/']gettext_compact = False

生成pot文件
make gettext

生成po文件
$ sphinx-intl update -p _build/gettext -l en


此时就能看到在文件locale/en/LC_MESSAGES中的信息

构建翻译的文档
$ make -e SPHINXOPTS="-D language='en'" html



Be sure to say yes to autodoc
More information can refer [http://www.matplotlib.org/sampledoc]
]]></content>
      <categories>
        <category>Python</category>
        <category>Sphinx</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>sphinx</tag>
      </tags>
  </entry>
  <entry>
    <title>Python Tkinter对话窗口</title>
    <url>/2018/01/01/python-tkinter-1-10-dialog-windows/</url>
    <content><![CDATA[Dialog WindowsWhile the standard dialogs described in the previous section may be sufficient for many simpler applications, most larger applications require more complicated dialogs. For example, to set configuration parameters for an application, you will probably want to let the user enter more than one value or string in each dialog.
Basically, creating a dialog window is no different from creating an application window. Just use the Toplevel widget, stuff the necessary entry fields, buttons, and other widgets into it, and let the user take care of the rest. (By the way, don’t use the ApplicationWindow class for this purpose; it will only confuse your users).
But if you implement dialogs in this way, you may end up getting both your users and yourself into trouble. The standard dialogs all returned only when the user had finished her task and closed the dialog; but if you just display another toplevel window, everything will run in parallel. If you’re not careful, the user may be able to display several copies of the same dialog, and both she and your application will be hopelessly confused.
In many situations, it is more practical to handle dialogs in a synchronous fashion; create the dialog, display it, wait for the user to close the dialog, and then resume execution of your application. The wait_window method is exactly what we need; it enters a local event loop, and doesn’t return until the given window is destroyed (either via the destroy method, or explicitly via the window manager):
widget.wait_window(window)
(Note that the method waits until the window given as an argument is destroyed; the only reason this is a method is to avoid namespace pollution).
In the following example, the MyDialog class creates a Toplevel widget, and adds some widgets to it. The caller then uses wait_window to wait until the dialog is closed. If the user clicks OK, the entry field’s value is printed, and the dialog is then explicitly destroyed.
Creating a simple dialogfrom Tkinter import *class MyDialog:    def __init__(self, parent):        top = self.top = Toplevel(parent)        Label(top, text="Value").pack()        self.e = Entry(top)        self.e.pack(padx=5)        b = Button(top, text="OK", command=self.ok)        b.pack(pady=5)    def ok(self):        print "value is", self.e.get()        self.top.destroy()root = Tk()Button(root, text="Hello!").pack()root.update()d = MyDialog(root)root.wait_window(d.top)

If you run this program, you can type something into the entry field, and then click OK, after which the program terminates (note that we didn’t call the mainloop method here; the local event loop handled by wait_window was sufficient). But there are a few problems with this example:
The root window is still active. You can click on the button in the root window also when the dialog is displayed. If the dialog depends on the current application state, letting the users mess around with the application itself may be disastrous. And just being able to display multiple dialogs (or even multiple copies of one dialog) is a sure way to confuse your users.

You have to explicitly click in the entry field to move the cursor into it, and also click on the OK button. Pressning Enter in the entry field is not sufficient.

There should be some controlled way to cancel the dialog (and as we learned earlier, we really should handle the WM_DELETE_WINDOW protocol too).

To address the first problem, Tkinter provides a method called grab_set, which makes sure that no mouse or keyboard events are sent to the wrong window.
The second problem consists of several parts; first, we need to explicitly move the keyboard focus to the dialog. This can be done with the focus_set method. Second, we need to bind the Enter key so it calls the ok method. This is easy, just use the bind method on the Toplevel widget (and make sure to modify the ok method to take an optional argument so it doesn’t choke on the event object).
The third problem, finally, can be handled by adding an additional Cancel button which calls the destroy method, and also use bind and protocol to do the same when the user presses Escape or explicitly closes the window.
The following Dialog class provides all this, and a few additional tricks. To implement your own dialogs, simply inherit from this class and override the body and apply methods. The former should create the dialog body, the latter is called when the user clicks OK.
A dialog support class (File: tkSimpleDialog.py)from Tkinter import *import osclass Dialog(Toplevel):    def __init__(self, parent, title = None):        Toplevel.__init__(self, parent)        self.transient(parent)        if title:            self.title(title)        self.parent = parent        self.result = None        body = Frame(self)        self.initial_focus = self.body(body)        body.pack(padx=5, pady=5)        self.buttonbox()        self.grab_set()        if not self.initial_focus:            self.initial_focus = self        self.protocol("WM_DELETE_WINDOW", self.cancel)        self.geometry("+%d+%d" % (parent.winfo_rootx()+50,                                  parent.winfo_rooty()+50))        self.initial_focus.focus_set()        self.wait_window(self)    #    # construction hooks    def body(self, master):        # create dialog body.  return widget that should have        # initial focus.  this method should be overridden        pass    def buttonbox(self):        # add standard button box. override if you don't want the        # standard buttons        box = Frame(self)        w = Button(box, text="OK", width=10, command=self.ok, default=ACTIVE)        w.pack(side=LEFT, padx=5, pady=5)        w = Button(box, text="Cancel", width=10, command=self.cancel)        w.pack(side=LEFT, padx=5, pady=5)        self.bind("&lt;Return&gt;", self.ok)        self.bind("&lt;Escape&gt;", self.cancel)        box.pack()    #    # standard button semantics    def ok(self, event=None):        if not self.validate():            self.initial_focus.focus_set() # put focus back            return        self.withdraw()        self.update_idletasks()        self.apply()        self.cancel()    def cancel(self, event=None):        # put focus back to the parent window        self.parent.focus_set()        self.destroy()    #    # command hooks    def validate(self):        return 1 # override    def apply(self):        pass # override

The main trickery is done in the constructor; first, transient is used to associate this window with a parent window (usually the application window from which the dialog was launched). The dialog won’t show up as an icon in the window manager (it won’t appear in the task bar under Windows, for example), and if you iconify the parent window, the dialog will be hidden as well. Next, the constructor creates the dialog body, and then calls grab_set to make the dialog modal, geometry to position the dialog relative to the parent window, focus_set to move the keyboard focus to the appropriate widget (usually the widget returned by the body method), and finally wait_window.
Note that we use the protocol method to make sure an explicit close is treated as a cancel, and in the buttonbox method, we bind the Enter key to OK, and Escape to Cancel. The default=ACTIVE call marks the OK button as a default button in a platform specific way.
Using this class is much easier than figuring out how it’s implemented; just create the necessary widgets in the body method, and extract the result and carry out whatever you wish to do in the apply method. Here’s a simple example (we’ll take a closer look at the grid method in a moment).
Creating a simple dialog, revisitedimport tkSimpleDialogclass MyDialog(tkSimpleDialog.Dialog):    def body(self, master):        Label(master, text="First:").grid(row=0)        Label(master, text="Second:").grid(row=1)        self.e1 = Entry(master)        self.e2 = Entry(master)        self.e1.grid(row=0, column=1)        self.e2.grid(row=1, column=1)        return self.e1 # initial focus    def apply(self):        first = int(self.e1.get())        second = int(self.e2.get())        print first, second # or something

And here’s the resulting dialog:
Running the dialog2.py scriptNote that the body method may optionally return a widget that should receive focus when the dialog is displayed. If this is not relevant for your dialog, simply return None (or omit the return statement).
The above example did the actual processing in the apply method (okay, a more realistic example should probably to something with the result, rather than just printing it). But instead of doing the processing in the apply method, you can store the entered data in an instance attribute:
    ...    def apply(self):        first = int(self.e1.get())        second = int(self.e2.get())        self.result = first, secondd = MyDialog(root)print d.result

Note that if the dialog is cancelled, the apply method is never called, and the result attribute is never set. The Dialog constructor sets this attribute to None, so you can simply test the result before doing any processing of it. If you wish to return data in other attributes, make sure to initialize them in the body method (or simply set result to 1 in the apply method, and test it before accessing the other attributes).
Grid LayoutsWhile the pack manager was convenient to use when we designed application windows, it may not be that easy to use for dialogs. A typical dialog may include a number of entry fields and check boxes, with corresponding labels that should be properly aligned. Consider the following simple example:Simple Dialog Layout
To implement this using the pack manager, we could create a frame to hold the label “first:”, and the corresponding entry field, and use side=LEFT when packing them. Add a corresponding frame for the next line, and pack the frames and the checkbutton into an outer frame using side=TOP. Unfortunately, packing the labels in this fashion makes it impossible to get the entry fields lined up, and if we use side=RIGHT to pack the entry field instead, things break down if the entry fields have different width. By carefully using width options, padding, side and anchor packer options, etc., we can get reasonable results with some effort. But there’s a much easier way: use the grid manager instead.
This manager splits the master widget (typically a frame) into a 2-dimensional grid, or table. For each widget, you only have to specify where in this grid it should appear, and the grid managers takes care of the rest. The following body method shows how to get the above layout:Using the grid geometry maanager
def body(self, master):    Label(master, text="First:").grid(row=0, sticky=W)    Label(master, text="Second:").grid(row=1, sticky=W)    self.e1 = Entry(master)    self.e2 = Entry(master)    self.e1.grid(row=0, column=1)    self.e2.grid(row=1, column=1)    self.cb = Checkbutton(master, text="Hardcopy")    self.cb.grid(row=2, columnspan=2, sticky=W)

For each widget that should be handled by the grid manager, you call the grid method with the row and column options, telling the manager where to put the widget. The topmost row, and the leftmost column, is numbered 0 (this is also the default). Here, the checkbutton is placed beneath the label and entry widgets, and the columnspan option is used to make it occupy more than one cell. Here’s the result:
Using the grid managerIf you look carefully, you’ll notice a small difference between this dialog, and the dialog shown by the dialog2.py script. Here, the labels are aligned to the left margin. If you compare the code, you’ll find that the only difference is an option called sticky.
When its time to display the frame widget, the grid geometry manager loops over all widgets, calculating a suitable width for each row, and a suitable height for each column. For any widget where the resulting cell turns out to be larger than the widget, the widget is centered by default. The sticky option is used to modify this behavior. By setting it to one of E, W, S, N, NW, NE, SE, or SW, you can align the widget to any side or corner of the cell. But you can also use this option to stretch the widget if necessary; if you set the option to E+W, the widget will be stretched to occupy the full width of the cell. And if you set it to E+W+N+S (or NW+SE, etc), the widget will be stretched in both directions. In practice, the sticky option replaces the fill, expand, and anchor options used by the pack manager.
The grid manager provides many other options allowing you to tune the look and behavior of the resulting layout. These include padx and pady which are used to add extra padding to widget cells, and many others. See the Grid Geometry Manager chapter for details.
Validating DataWhat if the user types bogus data into the dialog? In our current example, the apply method will raise an exception if the contents of an entry field is not an integer. We could of course handle this with a try/except and a standard message box:
    ...    def apply(self):        try:            first = int(self.e1.get())            second = int(self.e2.get())            dosomething((first, second))        except ValueError:            tkMessageBox.showwarning(                "Bad input",                "Illegal values, please try again"            )There’s a problem with this solution: the ok method has already removed the dialog from the screen when the apply method is called, and it will destroy it as soon as we return. This design is intentional; if we carry out some potentially lengthy processing in the apply method, it would be very confusing if the dialog wasn’t removed before we finished. The Dialog class already contain hooks for another solution: a separate validate method which is called before the dialog is removed.In the following example, we simply moved the code from apply to validate, and changed it to store the result in an instance attribute. This is then used in the apply method to carry out the work.    ...    def validate(self):        try:            first= int(self.e1.get())            second = int(self.e2.get())            self.result = first, second            return 1        except ValueError:            tkMessageBox.showwarning(                "Bad input",                "Illegal values, please try again"            )            return 0    def apply(self):        dosomething(self.result)

Note that if we left the processing to the calling program (as shown above), we don’t even have to implement the apply method.
]]></content>
      <categories>
        <category>Python</category>
        <category>GUI</category>
        <category>Tkinter</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>tkinter</tag>
      </tags>
  </entry>
  <entry>
    <title>Python Tkinter 你好</title>
    <url>/2018/01/01/python-tkinter-1-2-hello-tkinter/</url>
    <content><![CDATA[你好, Tkinter废话不多说，直接上代码。
写过代码都知道，第一个肯定就是Hello-world了。先来一个简单的。
我们的第一个代码helloworld.py
#!/usr/bin/python#tk/helloworld.py# -*- coding: UTF-8 -*-import tkinterroot = tkinter.Tk()w = tkinter.Label(root, text='你好，Tkinter!')w.pack()root.mainloop()

运行示例如何运行呢，与python程序一样，如下所述：
$ python helloworld.py

如果一些顺利，你会看到下面的一幅图片：

如果希望停止该程序，直接点击关闭按钮即可。
细节首先第一行，我们看到需要导入tkinter模块。
该模块包含所有的类，函数和其他Tk工具运行所需要的一切。大多数情况下，你可以简单地导入Tkinter的所有到你的模块空间。
import tkinter

初始化tkinter，我们需要创建一个Tk根组件。根组件包含一个title bar和由窗口管理器提供的装饰组件。对于每一个程序创建一个根组件即可，并且需要在所有的组件之前创建。
root = tkinter.Tk()

接下来，我们创建一个根组件的Label子组件。
w = tkinter.Label(root, text="Hello, world!")w.pack()

Label组件可以使用文本、图标和其他图像显示。在这个示例中，我们使用文本显示。
然后，我们使用pack方法来将文本显示到组件上。不过直到我们使用Tkinter的事件主循环，我们才能看到这个窗口。
root.mainloop()

在我们关闭窗口前，程序将一直处在事件循环中。这个事件循环不仅仅接收来自用户（比如鼠标🖱点击和键盘⌨️输入）和系统（比如重绘事件和窗口配置信息）的事件，也会处理Tkinter本身的事件。
比如串口重绘或者配置等。这也就意味着如果不进入这个事件循环，之前的程序窗口是无法显示出来的。
]]></content>
      <categories>
        <category>Python</category>
        <category>GUI</category>
        <category>Tkinter</category>
      </categories>
      <tags>
        <tag>tkinter</tag>
        <tag>Label</tag>
        <tag>pack</tag>
        <tag>mainloop</tag>
      </tags>
  </entry>
  <entry>
    <title>Python Tkinter 你好2</title>
    <url>/2018/01/01/python-tkinter-1-3-hello-tkinter-again/</url>
    <content><![CDATA[你好，Tkinter2如果程序写的大了，一般需要把代码包装到一个或许多类里面。
第二个Hello程序#!/usr/bin/python#tk/helloworld_class.py# -*- coding: UTF-8 -*-from tkinter import *class App:    def __init__(self, master):        frame = Frame(master)        frame.pack()        self.button = Button(frame, text='Quit', foreground='red', background='blue', command=frame.quit)        self.button.pack(side=LEFT)        self.hi_there = Button(frame, text='Hello', command=self.say_hi)        self.hi_there.pack(side=LEFT)    def say_hi(self):        print('Hi there, welcome to tkinter!')root = Tk()app = App(root)root.mainloop()root.destroy() # optional; see description below

运行程序运行这个程序，将会出现下面的这个窗口。

点击Hello按钮，终端输出信息 “Hi there, welcome to tkinter!”，如果点击Quit按钮，程序将退出。

注意：有些程序可能不会按照上面介绍的运行，这个时候就要检查下Tkinter的说明文档了，看看操作环境相关的配置，然后debug。

细节这个示例，我们使用了class方法。初始化init方法创建一个继承自master的容器frame。
class App:    def init(self, master):        frame = Frame(master)        frame.pack()

frame实例存储为局部变量，创建这个组建后，调用pack方法使之可见。
然后创建2个按钮组件，为frame的子组件。
self.button = Button(frame, text='Quit', foreground='red', background='blue', command=frame.quit)    self.button.pack(side=LEFT)    self.hi_there = Button(frame, text='Hello', command=self.say_hi)    self.hi_there.pack(side=LEFT)





这次，我们传递了一定数量的选项给结构器，第一个按钮被标记为 “QUIT”，前景色为红色 (其中fg 是foreground的简称)。第二个标记为 “Hello”。两个按钮都有一个command选项，这个选项指定了一个函数或者方法，在按钮被点击的时候调用。
按钮实例存储在实例属性组中。side=LEFT 参数表示这两个按钮在帧中将被分开放置；第一个按钮被放置在帧的左边缘，第二个被放在第一个的右边(帧的左边缘仍保留着空格)。默认情况下，部件的放置都是相对于它们的父亲(frame 部件相对于 master，button 相对于 frame)。如果 side 选项没指定，side 默认值为 TOP。
 “hello” 按钮的回调函数如下所示，每次点击的时候都会在终端打印一条消息：
def say_hi(self):        print('Hi there, welcome to tkinter!')

最后，我们使用一些脚本来创建 Tk root 部件和一个App的实例（使用root作为它的父类）：
root = Tk()app = App(root)root.mainloop()root.destroy()




关于部件引用Button(frame, text="Hello", command=self.hello).pack(side=LEFT)

如果不需要对一个窗口部件进行引用，可以用单独的一行创建并且进行包装，如上所述。
但是如果需要对其进行调用，就需要分开了，如下所示：
w = Button(frame, text="Hello", command=self.hello)w.pack(side=LEFT)

关于部件名字在上述实例中，我们使用的button或者hi_there都是部件的引用，而不是部件实际的名字，实际的名字大部分是由一系列数字组成的，这个有Tkinter自动为这些新部件赋值。
比如，我们可以打印出来名字如下所示：
&gt;&gt;&gt; print str(ok).1428748.1432920
]]></content>
      <categories>
        <category>Python</category>
        <category>GUI</category>
        <category>Tkinter</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>tkinter</tag>
      </tags>
  </entry>
  <entry>
    <title>Python Tkinter Button窗口组件类</title>
    <url>/2018/01/01/python-tkinter-1-4-1-tkinter-button/</url>
    <content><![CDATA[Button 窗口部件Button(按钮)窗口部件是一个标准的 Tkinter 窗口部件，用来实现各种按钮。
按钮能够包含文本或图象，并与一个 Python 函数或方法相关联。当这个按钮被按下时，Tkinter 自动调用相关联的函数或方法。 
按钮仅能显示一种字体，但是这个文本可以跨行。另外，这个文本中的一个字母可以有__下划线__，例如标明一个快捷键。默认情况，Tab 键用于将焦点移动到一个按钮部件。 
一、那么什么时候用按钮部件呢?简而言之，按钮部件用来让用户说“马上给我执行这个任务”，通常我们用显示在按钮上的文本或图象来提示。 按钮通常用在工具条中或应用程序窗口中，并且用来接收或忽略输入在对话框中的数据。 
关于按钮和输入的数据的配合，可以参看 Checkbutton 和 Radiobutton 部件。 
二、样式普通的按钮很容易被创建，仅仅指定按钮的内容(文本、位图、图象)和一个当按钮被按下时的回调函数即可: 
b = Button(master, text="OK", command=self.ok) 



没有回调函数的按钮是没有用的，当你按下这个按钮时它什么也不做。你可能在开发一个应用程序的时候想实现这种按钮，比如为了不干扰你的 beta 版的测试者:
b = Button(master, text="Help", state=DISABLED) 



 如果你没有指定尺寸，按钮的大小将正好能够容纳它的内容。你可以用 padx 和 pady 选项来增加内容与按钮 边框的间距。你也可以用 height 和 width 选项来显式地设置按钮的尺寸。如果你在按钮中显示文本，那么这些选项将以文本的单位为定义按钮的尺寸。如果你替而代之显示图象，那么按钮的尺寸将是象素 (或其它的屏幕单位)。你实际上甚至能够用象素单位来定义文本按钮的尺寸，但这可能带来意外的结果。下面是指定尺寸 的一段例子代码: 
f = Frame(master, height=32, width=32) f.pack_propagate(0) # don't shrink b = Button(f, text="Sure!") b.pack(fill=BOTH, expand=1) 

按钮能够显示多行文本(但只能用一种字体)。 你可以使用多行或 wraplength 选项来使按钮自己调整文本。 当调整文本时，使用 anchor,justify,也可加上 padx 选项来得到你所希望的格式。一个例子如下:
b = Button(master, text=longtext, anchor=W, justify=LEFT, padx=2) 

为了使一个普通的按钮看起来像凹入的，例如你想去实现某种类型的工具框，你可简单地将 relief 的值从 “RAISED“改变为”SUNKEN: 
三、方法Button 窗口部件支持标准的 Tkinter 窗口部件接口，加上下面的方法: 

flash():频繁重画按钮，使其在活动和普通样式下切换
invoke() :调用与按钮相关联的命令
下面的方法与你实现自己的按钮绑定有关:

tkButtonDown(), tkButtonEnter(), tkButtonInvoke(), tkButtonLeave(), tkButtonUp() 这些方法可以用在定制事件绑定中，所有这些方法接收 0 个或多个形参。 
四、选项Button 窗口部件支持下面的选项: 
activebackground, activeforeground类型:颜色;说明:当按钮被激活时所使用的颜色。
anchor类型:常量; 说明:控制按钮上内容的位置。使用N, NE, E, SE, S, SW, W, NW, or CENTER这些值之一。默认值 是 CENTER。 
background (bg), foreground (fg)类型:颜色;说明:按钮的颜色。默认值与特定平台相关。
bitmap类型:位图; 说 明:显示在窗口部件中的位图。如果 image 选项被指定了，则这个选项被忽略。下面的位图在所有平台上 都有 效:error, gray75, gray50, gray25, gray12, hourglass, info, questhead, question, 和 warning. 
这后面附加的位图仅在 Macintosh 上有效:document, stationery, edition, application, accessory, folder, pfolder, trash, floppy, ramdisk, cdrom, preferences, querydoc, stop, note, 和 caution.
 
borderwidth (bd)

类型:整数; 说明:按钮边框的宽度。默认值与特定平台相关。但通常是 1 或 2 象素。 
command类型:回调; 说明:当按钮被按下时所调用的一个函数或方法。所回调的可以是一个函数、方法或别的可调用的 Python 对 象。 
cursor类型:光标;说明:当鼠标移动到按钮上时所显示的光标。
default类型:常量; 说明:如果设置了，则按钮为默认按钮。注意这个语法在Tk 8.0b2中已改变。 
disabledforeground类型:颜色;说明:当按钮无效时的颜色。
font类型:字体;说明:按钮所使用的字体。按钮只能包含一种字体的文本。
highlightbackground, highlightcolor类型:颜色; 说明:控制焦点所在的高亮边框的颜色。当窗口部件获得焦点的时候，边框为 highlightcolor 所指定的颜 色。否则边框为 highlightbackground 所指定的颜色。默认值由系统所定。 
highlightthickness类型:距离; 说明:控制焦点所在的高亮边框的宽度。默认值通常是 1 或 2 象素。 
image类型:图象; 说明:在部件中显示的图象。如果指定，则 text 和 bitmap 选项将被忽略。 
justify类型:常量; 
说明:定义多行文本如何对齐。可取值有:LEFT, RIGHT, 或 CENTER。 
padx, pady类型:距离;说明:指定文本或图象与按钮边框的间距。
relief类型:常量; 说明:边框的装饰。通常按钮按下时是凹陷的，否则凸起。另外的可能取值有 GROOVE, RIDGE, 和 FLAT。 
state类型:常量; 说明:按钮的状态:NORMAL, ACTIVE 或 DISABLED。默认值为 NORMAL。 
takefocus类型:标志; 说明:表明用户可以 Tab 键来将焦点移到这个按钮上。默认值是一个空字符串，意思是如果按钮有按键绑定的 话，它可以通过所绑定的按键来获得焦点。 
text类型:字符串; 说明:显示在按钮中的文本。文本可以是多行。如果 bitmaps 或 image 选项被使用，则 text 选项被忽略。 
textvariable类型:变量; 说明:与按钮相关的 Tk 变量(通常是一个字符串变量)。如果这个变量的值改变，那么按钮上的文本相应更新。 
underline类型:整数; 说明:在文本标签中哪个字符加下划线。默认值为-1，意思是没有字符加下划线。 
width, height类型:距离; 说明:按钮的尺寸。如果按钮显示文本，尺寸使用文本的单位。如果按钮显示图象，尺寸以象素为单位(或屏 幕的单位)。如果尺寸没指定，它将根据按钮的内容来计算。 
wraplength类型:距离; 说明:确定一个按钮的文本何时调整为多行。它以屏幕的单位为单位。默认不调整。 
]]></content>
      <categories>
        <category>Python</category>
        <category>GUI</category>
        <category>Tkinter</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>tkinter</tag>
      </tags>
  </entry>
  <entry>
    <title>Python Tkinter 组件配置</title>
    <url>/2018/01/01/python-tkinter-1-5-widget-configuration/</url>
    <content><![CDATA[组件配置我们通常使用选项而不是方法来控制组件的显示。标准的选项包括文本、颜色、大小、命令回调等。为了处理这些选项，所有的核心组件都提供了相同的配置接口：
配置接口widgetclass(master, option=value, …) =&gt; widget


其中widgetclass为上一节提到的组件类

创建这个窗口部件的一个实例，这个实例作为给定的 master 的孩子，并且使用给定的选项。所有的选项都有默认值，因此在简单的情况下，你仅需要指定这个 master。如果你想的话，你也可以不指定 master;Tkinter这时会使用最近创建的 root 窗口作为 master。注意这个 name 选项仅能 在窗口部件被创建时设置。
cget(“option”) =&gt; string
返回一个选项的当前值。选项的名字和返回值都是字符串。要得到 name 选项，使用 str(widget)代替。
config(option=value, …)
configure(option=value, …)
设置一个或多个选项(作为关键字参数给定)。注意一些选项的名字与 Python 中的保留字相同(class,from 等)。要使用这些作为关键字参数，仅需要在这些选项名后添加一下划线(class_,from_)。注意你不能用此方法来设置 name 选项;name 选项只能在窗口部件被创建时设置。
为了方便起见，窗口部件也实现一个局部的字典接口。 setitem 方法映射 configure，而__getitem__方法映射 cget。你可以使用下面的语法来设置和查询选项:
value = widget[“option”]widget[“option”] = value
注意每个赋值都导致一个对 Tk 的调用。如果你希望去改变多个选项，单独地调用(config 或 configure)去改变它们是一个好的主意。
这下面的字典方法也适用于窗口部件
keys() =&gt; list
返回窗口部件中所有可以被设置的选项的一个列表。name 选项不包括在这个列表中(它不能通过字典接口被查询或修改)
向后兼容性关键字参数在 Python1.3时被引入。之前，使用原始的 Python 字典将选项传递给窗口构造器和 configure方法。原代码类似如下:
self.button = Button(frame, {"text": "QUIT", "fg": "red", "command": frame.quit})self.button.pack({"side": LEFT})

关键字参数语法更优雅和少容易发生错误。但是为了与存在的代码兼容，Tkinter 仍支持老的语法。在新的程序中你不应再用老的语法，即使是在某些情况下是很有吸引力的。例如，如果你创建了一个定制的窗口部件，它需要沿它的父类传递配置选项，你的代码可能如下:
def __init__(self, master, **kw):    Canvas.__init__(self, master, kw) # kw is a dictionary

上面的代码在当前版本的 Tkinter 下工作的很好，但是它在将来的版本下可能不工作。一个通常的办法是使用 apply 函数:
def __init__(self, master, **kw):    apply(Canvas.__init__, (self, master), kw)

这个 apply 函数使用了一个函数(一个未约束的方法)，一个带参数的元组(它必须包括 self，因为我们调用一个未约束的方法)，一个可选的，提供了关键字参数的字典。
]]></content>
      <categories>
        <category>Python</category>
        <category>GUI</category>
        <category>Tkinter</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>tkinter</tag>
      </tags>
  </entry>
  <entry>
    <title>Python Tkinter 的窗口组件类</title>
    <url>/2018/01/01/python-tkinter-1-4-tkinter-classes/</url>
    <content><![CDATA[Tkinter 窗口组件类Tkinter支持下列15种核心组件：
Button按钮按钮，用于执行命令或其他操作。
Canvas画布结构化的graphics。这个组件用于绘制graphs 和 plots，创建图像编辑器，部署其他组件。
Checkbutton复选按钮有两个值，通过激活按钮来切换。
Entry 输入框用于输入文本。
Frame一个容器窗口部件。帧可以有边框和背景，当创建一个应用程序或 dialog(对话)版面时，帧被用来组织其它 的窗口部件。
Label 标签用于显示文本或者图像。
Listbox显示供选方案的一个列表。listbox 能够被配置来得到 radiobutton 或 checklist 的状态
Menu菜单条，用来实现下拉或者弹出式菜单
Menubutton菜单按钮，用来实现下拉式菜单，目前基本可以使用Menu来实现
Message显示文本。与 label 窗口部件类似，但是能够自动地调整文本到给定的宽度或比率。
Radiobutton代表一个变量，为多个值中的一个。点击它将为这个变量设置值，并且清除与这同一变量相关的其它radiobutton。
Scale允许你通过滑块来设置一数字值
Scrollbar配合canvas, entry, listbox, and text窗口部件使用的标准滚动条。
Text格式化文本显示。允许你用不同的样式和属性来显示和编辑文本。同时支持内嵌图象和窗口。
Toplevel一个容器窗口部件，作为一个单独的、最上面的窗口显示。

在Python 2.3 (Tk 8.4)，增加了下述组件：

LabelFrameA variant of the Frame widget that can draw both a border and a title.
PanedWindowA container widget that organizes child widgets in resizable panes.
SpinboxA variant of the Entry widget for selecting values from a range or an ordered set.
Also note that there’s no widget class hierarchy in Tkinter; all widget classes are siblings in the inheritance tree.
所有这些窗口部件提供了 Misc 和几何管理方法、配置管理方法和部件自己定义的另外的方法。此外，Toplevel类也提供窗口管理接口。这意味一个典型的窗口部件类提供了大约 150 种方法。
MixinsThe Tkinter module provides classes corresponding to the various widget types in Tk, and a number of mixin and other helper classes (a mixin is a class designed to be combined with other classes using multiple inheritance). When you use Tkinter, you should never access the mixin classes directly.
Implementation mixinsThe Misc class is used as a mixin by the root window and widget classes. It provides a large number of Tk and window related services, which are thus available for all Tkinter core widgets. This is done by delegation; the widget simply forwards the request to the appropriate internal object.
The Wm class is used as a mixin by the root window and Toplevel widget classes. It provides window manager services, also by delegation.
Using delegation like this simplifies your application code: once you have a widget, you can access all parts of Tkinter using methods on the widget instance.
Geometry mixinsThe Grid, Pack, and Place classes are used as mixins by the widget classes. They provide access to the various geometry managers, also via delegation.
Grid    The grid geometry manager allows you to create table-like layouts, by organizing the widgets in a 2-dimensional grid. To use this geometry manager, use the grid method.Pack    The pack geometry manager lets you create a layout by “packing” the widgets into a parent widget, by treating them as rectangular blocks placed in a frame. To use this geometry manager for a widget, use the pack method on that widget to set things up.Place    The place geometry manager lets you explicitly place a widget in a given position. To use this geometry manager, use the place method.
Widget configuration managementThe Widget class mixes the Misc class with the geometry mixins, and adds configuration management through the cget and configure methods, as well as through a partial dictionary interface. The latter can be used to set and query individual options, and is explained in further detail in the next chapter.
]]></content>
      <categories>
        <category>Python</category>
        <category>GUI</category>
        <category>Tkinter</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>tkinter</tag>
      </tags>
  </entry>
  <entry>
    <title>Python Tkinter 组件外观</title>
    <url>/2018/01/01/python-tkinter-1-6-widget-styling/</url>
    <content><![CDATA[组件样式所有的Tkinter标准组件都提供了最基础的样式选项，这些选项可以用来修改诸如颜色、字体和其他显示信息。
颜色大多数组件允许你指定组件和文本的颜色，可以使用 background 和 foreground 选项。为了指定颜色，可以使用颜色的名字，比如red，或者RGB参数，比如FF0000。
颜色名Tkinter 包括一个颜色数据库，它将颜色名映射到相应的 RGB 值。这个数据库包括了通常的名称如 Red,Green, Blue, Yellow, 和 LightBlue，也可使用外来的如 Moccasin，PeachPuff 等等。
在 X window系统上，颜色名由 X server 定义。你能够找到 一个名为 xrgb.txt 的文件，它包含了一个由颜色名和相应RGB 值组成的列表。在 Windows 和 Macintosh 系统上，颜色名表内建于 Tk 中。
在 Windows 下，你可以使用 Windows 系统颜色(用户可以通过控制面板来改变这些颜色):
SystemActiveBorder, SystemActiveCaption, SystemAppWorkspace, SystemBackground, SystemButtonFace, SystemButtonHighlight, SystemButtonShadow, SystemButtonText, SystemCaptionText, SystemDisabledText, SystemHighlight, SystemHighlightText, SystemInactiveBorder, SystemInactiveCaption, SystemInactiveCaptionText, SystemMenu, SystemMenuText, SystemScrollbar, SystemWindow, SystemWindowFrame, SystemWindowText.

在 Macintosh 上，下面的系统颜色是有效的:
SystemButtonFace, SystemButtonFrame, SystemButtonText, SystemHighlight, SystemHighlightText, SystemMenu, SystemMenuActive, SystemMenuActiveText, SystemMenuDisabled, SystemMenuText, SystemWindowBody.

颜色名是大小写不敏感的。许多颜色（并不是所有的颜色）名词与词之间有无格都有效。例如”lightblue”, “light blue”, 和”Light Blue”都是同一颜色。
RGB 格式如果你需要显式地指定颜色名，你可以使用如下格式的字符串
#RRGGBB

RR, GG, BB 分别是 red,green 和 blue 值的十六进制表示。下面的例子演示了如何将一个颜色三元组转换 为 一个 Tk 颜色格式:
tk_rgb = "#%02x%02x%02x" % (128, 192, 200)

Tk 也支持用形如”#RGB”和”rrrrggggbbbb”去分别指定16和65536程度之间的值。
你可以使用窗口部件的 winfo_rgb 方法来将一个代表颜色的字符串(名字或 RGB 格式)转换为一个三元组:
rgb = widget.winfo_rgb("red")red, green, blue = rgb[0]/256, rgb[1]/256, rgb[2]/256

注意 winfo_rgb 返回16位的 RGB 值，范围在065535之间。要将它们映射到更通用的0255范围内，你必须将每个值都除以256(或将它们向右移8位)。
字体窗口部件允许你显示文本和指定所使用的字体。所有的窗口部件都提供了合理的默认值，你很少需要去为简单 元素如标签和按钮指定字体。 
字体通常使用 font 窗口部件选项指定。Tkinter 支持一定数量的不同字体描述类型: 

Font descriptors
User-defined font names
System fonts
X font descriptors

Tk8.0以前的版本仅X font描述被支持。Font descriptors #
Starting with Tk 8.0, Tkinter supports platform independent font descriptors. You can specify a font as tuple containing a family name, a height in points, and optionally a string with one or more styles. Examples:
(“Times”, 10, “bold”)(“Helvetica”, 10, “bold italic”)(“Symbol”, 8)
To get the default size and style, you can give the font name as a single string. If the family name doesn’t include spaces, you can also add size and styles to the string itself:
“Times 10 bold”“Helvetica 10 bold italic”“Symbol 8”
Here are some families available on most Windows platforms:
Arial (corresponds to Helvetica), Courier New (Courier), Comic Sans MS, Fixedsys, MS Sans Serif, MS Serif, Symbol, System, Times New Roman (Times), and Verdana:
Note that if the family name contains spaces, you must use the tuple syntax described above.
The available styles are normal, bold, roman, italic, underline, and overstrike.
Tk 8.0 automatically maps Courier, Helvetica, and Times to their corresponding native family names on all platforms. In addition, a font specification can never fail under Tk 8.0; if Tk cannot come up with an exact match, it tries to find a similar font. If that fails, Tk falls back to a platform-specific default font. Tk’s idea of what is “similar enough” probably doesn’t correspond to your own view, so you shouldn’t rely too much on this feature.
Tk 4.2 under Windows supports this kind of font descriptors as well. There are several restrictions, including that the family name must exist on the platform, and not all the above style names exist (or rather, some of them have different names).
Font namesIn addition, Tk 8.0 allows you to create named fonts and use their names when specifying fonts to the widgets.
The tkFont module provides a Font class which allows you to create font instances. You can use such an instance everywhere Tkinter accepts a font specifier. You can also use a font instance to get font metrics, including the size occupied by a given string written in that font.
tkFont.Font(family=”Times”, size=10, weight=tkFont.BOLD)tkFont.Font(family=”Helvetica”, size=10, weight=tkFont.BOLD,            slant=tkFont.ITALIC)tkFont.Font(family=”Symbol”, size=8)
If you modify a named font (using the config method), the changes are automatically propagated to all widgets using the font.
The Font constructor supports the following style options (note that the constants are defined in the tkFont module):
family
Font family.

size
Font size in points. To give the size in pixels, use a negative value.

weight
Font thickness. Use one of NORMAL or BOLD. Default is NORMAL.

slant
Font slant. Use one of NORMAL or ITALIC. Default is NORMAL.

underline
Font underlining. If 1 (true), the font is underlined. Default is 0 (false).

overstrike
Font strikeout. If 1 (true), a line is drawn over text written with this font. Default is 0 (false).

System fontsTk also supports system specific font names. Under X, these are usually font aliases like fixed, 6x10, etc.
Under Windows, these include ansi, ansifixed, device, oemfixed, system, and systemfixed:
On the Macintosh, the system font names are application and system.
Note that the system fonts are full font names, not family names, and they cannot be combined with size or style attributes. For portability reasons, avoid using these names wherever possible.
X Font DescriptorsX Font Descriptors are strings having the following format (the asterisks represent fields that are usually not relevant. For details, see the Tk documentation, or an X manual):
--family-weight-slant-–-size----*-charset
The font family is typically something like Times, Helvetica, Courier or Symbol.
The weight is either Bold or Normal. Slant is either R for “roman” (normal), I for italic, or O for oblique (in practice, this is just another word for italic).
Size is the height of the font in decipoints (that is, points multiplied by 10). There are usually 72 points per inch, but some low-resolution displays may use larger “logical” points to make sure that small fonts are still legible. The character set, finally, is usually ISO8859-1 (ISO Latin 1), but may have other values for some fonts.
The following descriptor requests a 12-point boldface Times font, using the ISO Latin 1 character set:
--Times-Bold-R-–-120----*-ISO8859-1
If you don’t care about the character set, or use a font like Symbol which has a special character set, you can use a single asterisk as the last component:
--Symbol---–-80-
A typical X server supports at least Times, Helvetica, Courier, and a few more fonts, in sizes like 8, 10, 12, 14, 18, and 24 points, and in normal, bold, and italic (Times) or oblique (Helvetica, Courier) variants. Most servers also support freely scaleable fonts. You can use programs like xlsfonts and xfontsel to check which fonts you have access to on a given server.
This kind of font descriptors can also be used on Windows and Macintosh. Note that if you use Tk 4.2, you should keep in mind that the font family must be one supported by Windows (see above).
Text FormattingWhile text labels and buttons usually contain a single line of text, Tkinter also supports multiple lines. To split the text across lines, simply insert newline characters (\n) where necessary.
By default, the lines are centered. You can change this by setting the justify option to LEFT or RIGHT. The default value is CENTER.
You can also use the wraplength option to set a maximum width, and let the widget wrap the text over multiple lines all by itself. Tkinter attempts to wrap on whitespace, but if the widget is too narrow, it may break individual words across lines.
BordersAll Tkinter widgets have a border (though it’s not visible by default for some widgets). The border consists of an optional 3D relief, and a focus highlight region.Relief #
The relief settings control how to draw the widget border:
borderwidth (or bd)
This is the width of the border, in pixels. Most widgets have a default borderwidth of one or two pixels. There’s hardly any reason to make the border wider than that.

relief
This option controls how to draw the 3D border. It can be set to one of SUNKEN, RAISED, GROOVE, RIDGE, and FLAT.

Focus HighlightsThe highlight settings control how to indicate that the widget (or one of its children) has keyboard focus. In most cases, the highlight region is a border outside the relief. The following options control how this extra border is drawn:
highlightcolor
This option is used to draw the highlight region when the widget has keyboard focus. It’s usually black, or some other distinct contrast color.

highlightbackground
This option is used to draw the highlight region when the widget doesn’t have focus. It’s usually same as the widget background.

highlightthickness
This option is the width of the highlight region, in pixels. It is usually one or two pixels for widgets that can take keyboard focus.

Cursorscursor
This option controls which mouse cursor to use when the mouse is moved over the widget.

If this option isn’t set, the widget uses the same mouse pointer as its parent.

Note that some widgets, including the Text and Entry widgets, set this option by default.

]]></content>
      <categories>
        <category>Python</category>
        <category>GUI</category>
        <category>Tkinter</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>tkinter</tag>
      </tags>
  </entry>
  <entry>
    <title>Python Tkinter 事件和绑定</title>
    <url>/2018/01/01/python-tkinter-1-7-events-and-binding/</url>
    <content><![CDATA[事件和绑定As was mentioned earlier, a Tkinter application spends most of its time inside an event loop (entered via the mainloop method). Events can come from various sources, including key presses and mouse operations by the user, and redraw events from the window manager (indirectly caused by the user, in many cases).
Tkinter provides a powerful mechanism to let you deal with events yourself. For each widget, you can bind Python functions and methods to events.
widget.bind(event, handler)

If an event matching the event description occurs in the widget, the given handler is called with an object describing the event.
Here’s a simple example:
Capturing clicks in a windowfrom Tkinter import *root = Tk()def callback(event):    print "clicked at", event.x, event.yframe = Frame(root, width=100, height=100)frame.bind("&lt;Button-1&gt;", callback)frame.pack()root.mainloop()

In this example, we use the bind method of the frame widget to bind a callback function to an event called . Run this program and click in the window that appears. Each time you click, a message like “clicked at 44 63” is printed to the console window.
Keyboard events are sent to the widget that currently owns the keyboard focus. You can use the focus_set method to move focus to a widget:
Capturing keyboard eventsfrom Tkinter import *root = Tk()def key(event):    print "pressed", repr(event.char)def callback(event):    frame.focus_set()    print "clicked at", event.x, event.yframe = Frame(root, width=100, height=100)frame.bind("&lt;Key&gt;", key)frame.bind("&lt;Button-1&gt;", callback)frame.pack()root.mainloop()

If you run this script, you’ll find that you have to click in the frame before it starts receiving any keyboard events.
EventsEvents are given as strings, using a special event syntax:


The type field is the most important part of an event specifier. It specifies the kind of event that we wish to bind, and can be user actions like Button, and Key, or window manager events like Enter, Configure, and others. The modifier and detail fields are used to give additional information, and can in many cases be left out. There are also various ways to simplify the event string; for example, to match a keyboard key, you can leave out the angle brackets and just use the key as is. Unless it is a space or an angle bracket, of course.
Instead of spending a few pages on discussing all the syntactic shortcuts, let’s take a look on the most common event formats:
Event Formats

A mouse button is pressed over the widget. Button 1 is the leftmost button, button 2 is the middle button (where available), and button 3 the rightmost button. When you press down a mouse button over a widget, Tkinter will automatically “grab” the mouse pointer, and subsequent mouse events (e.g. Motion and Release events) will then be sent to the current widget as long as the mouse button is held down, even if the mouse is moved outside the current widget. The current position of the mouse pointer (relative to the widget) is provided in the x and y members of the event object passed to the callback.

You can use ButtonPress instead of Button, or even leave it out completely: &lt;Button-1&gt;, &lt;ButtonPress-1&gt;, and &lt;1&gt; are all synonyms. For clarity, I prefer the &lt;Button-1&gt; syntax.



The mouse is moved, with mouse button 1 being held down (use B2 for the middle button, B3 for the right button). The current position of the mouse pointer is provided in the x and y members of the event object passed to the callback.



Button 1 was released. The current position of the mouse pointer is provided in the x and y members of the event object passed to the callback.



Button 1 was double clicked. You can use Double or Triple as prefixes. Note that if you bind to both a single click (&lt;Button-1&gt;) and a double click, both bindings will be called.



The mouse pointer entered the widget (this event doesn’t mean that the user pressed the Enter key!).



The mouse pointer left the widget.



Keyboard focus was moved to this widget, or to a child of this widget.



Keyboard focus was moved from this widget to another widget.



The user pressed the Enter key. You can bind to virtually all keys on the keyboard. For an ordinary 102-key PC-style keyboard, the special keys are Cancel (the Break key), BackSpace, Tab, Return(the Enter key), Shift_L (any Shift key), Control_L (any Control key), Alt_L (any Alt key), Pause, Caps_Lock, Escape, Prior (Page Up), Next (Page Down), End, Home, Left, Up, Right, Down, Print, Insert, Delete, F1, F2, F3, F4, F5, F6, F7, F8, F9, F10, F11, F12, Num_Lock, and Scroll_Lock.



The user pressed any key. The key is provided in the char member of the event object passed to the callback (this is an empty string for special keys).

a
The user typed an “a”. Most printable characters can be used as is. The exceptions are space (&lt;space&gt;) and less than (&lt;less&gt;). Note that 1 is a keyboard binding, while &lt;1&gt; is a button binding.



The user pressed the Up arrow, while holding the Shift key pressed. You can use prefixes like Alt, Shift, and Control.



The widget changed size (or location, on some platforms). The new size is provided in the width and height attributes of the event object passed to the callback.

The Event ObjectThe event object is a standard Python object instance, with a number of attributes describing the event.
Event Attributeswidget
The widget which generated this event. This is a valid Tkinter widget instance, not a name. This attribute is set for all events.

x, y
The current mouse position, in pixels.

x_root, y_root
The current mouse position relative to the upper left corner of the screen, in pixels.

char
The character code (keyboard events only), as a string.

keysym
The key symbol (keyboard events only).

keycode
The key code (keyboard events only).

num
The button number (mouse button events only).

width, height
The new size of the widget, in pixels (Configure events only).

type
The event type.

For portability reasons, you should stick to char, height, width, x, y, x_root, y_root, and widget. Unless you know exactly what you’re doing, of course…
Instance and Class BindingsThe bind method we used in the above example creates an instance binding. This means that the binding applies to a single widget only; if you create new frames, they will not inherit the bindings.
But Tkinter also allows you to create bindings on the class and application level; in fact, you can create bindings on four different levels:
the widget instance, using bind.

the widget’s toplevel window (Toplevel or root), also using bind.

the widget class, using bind_class (this is used by Tkinter to provide standard bindings).

the whole application, using bind_all.

For example, you can use bind_all to create a binding for the F1 key, so you can provide help everywhere in the application. But what happens if you create multiple bindings for the same key, or provide overlapping bindings?
First, on each of these four levels, Tkinter chooses the “closest match” of the available bindings. For example, if you create instance bindings for the  and  events, only the second binding will be called if you press the Enter key.
However, if you add a  binding to the toplevel widget, both bindings will be called. Tkinter first calls the best binding on the instance level, then the best binding on the toplevel window level, then the best binding on the class level (which is often a standard binding), and finally the best available binding on the application level. So in an extreme case, a single event may call four event handlers.
A common cause of confusion is when you try to use bindings to override the default behavior of a standard widget. For example, assume you wish to disable the Enter key in the text widget, so that the users cannot insert newlines into the text. Maybe the following will do the trick?
def ignore(event):    passtext.bind(““, ignore)
or, if you prefer one-liners:
text.bind(““, lambda e: None)
(the lambda function used here takes one argument, and returns None)
Unfortunately, the newline is still inserted, since the above binding applies to the instance level only, and the standard behavior is provided by a class level bindings.
You could use the bind_class method to modify the bindings on the class level, but that would change the behavior of all text widgets in the application. An easier solution is to prevent Tkinter from propagating the event to other handlers; just return the string “break” from your event handler:
def ignore(event):    return “break”text.bind(““, ignore)
or
text.bind(““, lambda e: “break”)
By the way, if you really want to change the behavior of all text widgets in your application, here’s how to use the bind_class method:
top.bind_class(“Text”, ““, lambda e: None)
But there are a lot of reasons why you shouldn’t do this. For example, it messes things up completely the day you wish to extend your application with some cool little UI component you downloaded from the net. Better use your own Text widget specialization, and keep Tkinter’s default bindings intact:
class MyText(Text):    def init(self, master, **kw):        apply(Text.init, (self, master), kw)        self.bind(““, lambda e: “break”)
ProtocolsIn addition to event bindings, Tkinter also supports a mechanism called protocol handlers. Here, the term protocol refers to the interaction between the application and the window manager. The most commonly used protocol is called WM_DELETE_WINDOW, and is used to define what happens when the user explicitly closes a window using the window manager.
You can use the protocol method to install a handler for this protocol (the widget must be a root or Toplevel widget):
widget.protocol(“WM_DELETE_WINDOW”, handler)
Once you have installed your own handler, Tkinter will no longer automatically close the window. Instead, you could for example display a message box asking the user if the current data should be saved, or in some cases, simply ignore the request. To close the window from this handler, simply call the destroy method of the window:
Capturing destroy eventsfrom Tkinter import *import tkMessageBox
def callback():    if tkMessageBox.askokcancel(“Quit”, “Do you really wish to quit?”):        root.destroy()
root = Tk()root.protocol(“WM_DELETE_WINDOW”, callback)
root.mainloop()
Note that even you don’t register an handler for WM_DELETE_WINDOW on a toplevel window, the window itself will be destroyed as usual (in a controlled fashion, unlike X). However, as of Python 1.5.2, Tkinter will not destroy the corresponding widget instance hierarchy, so it is a good idea to always register a handler yourself:
top = Toplevel(…)
make sure widget instances are deletedtop.protocol(“WM_DELETE_WINDOW”, top.destroy)
Future versions of Tkinter will most likely do this by default.
Other ProtocolsWindow manager protocols were originally part of the X window system (they are defined in a document titled Inter-Client Communication Conventions Manual, or ICCCM). On that platform, you can install handlers for other protocols as well, like WM_TAKE_FOCUS and WM_SAVE_YOURSELF. See the ICCCM documentation for details.
]]></content>
      <categories>
        <category>Python</category>
        <category>GUI</category>
        <category>Tkinter</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>tkinter</tag>
      </tags>
  </entry>
  <entry>
    <title>Python Tkinter 应用程序窗口</title>
    <url>/2018/01/01/python-tkinter-1-8-application-windows/</url>
    <content><![CDATA[Application WindowsBase WindowsIn the simple examples we’ve used this far, there’s only one window on the screen; the root window. This is automatically created when you call the Tk constructor, and is of course very convenient for simple applications:
from Tkinter import *
root = Tk()
create window contents as children to root…root.mainloop()
If you need to create additional windows, you can use the Toplevel widget. It simply creates a new window on the screen, a window that looks and behaves pretty much like the original root window:
from Tkinter import *
root = Tk()
create root window contents…top = Toplevel()
create top window contents…root.mainloop()
There’s no need to use pack to display the Toplevel, since it is automatically displayed by the window manager (in fact, you’ll get an error message if you try to use pack or any other geometry manager with a Toplevel widget).
MenusTkinter provides a special widget type for menus. To create a menu, you create an instance of the Menu class, and use add methods to add entries to it:
add_command(label=string, command=callback) adds an ordinary menu entry.

add_separator() adds an separator line. This is used to group menu entries.

add_cascade(label=string, menu=menu instance) adds a submenu (another Menu instance). This is either a pull-down menu or a fold-out menu, depending on the parent.

Here’s an example:
Creating a small menufrom Tkinter import *
def callback():    print “called the callback!”
root = Tk()
create a menumenu = Menu(root)root.config(menu=menu)
filemenu = Menu(menu)menu.add_cascade(label=”File”, menu=filemenu)filemenu.add_command(label=”New”, command=callback)filemenu.add_command(label=”Open…”, command=callback)filemenu.add_separator()filemenu.add_command(label=”Exit”, command=callback)
helpmenu = Menu(menu)menu.add_cascade(label=”Help”, menu=helpmenu)helpmenu.add_command(label=”About…”, command=callback)
mainloop()
In this example, we start out by creating a Menu instance, and we then use the config method to attach it to the root window. The contents of that menu will be used to create a menubar at the top of the root window. You don’t have to pack the menu, since it is automatically displayed by Tkinter.
Next, we create a new Menu instance, using the menubar as the widget parent, and the add_cascade method to make it a pulldown menu. We then call add_command to add commands to the menu (note that all commands in this example use the same callback), and add_separator to add a line between the file commands and the exit command.
Finally, we create a small help menu in the same fashion.
ToolbarsMany applications place a toolbar just under the menubar, which typically contains a number of buttons for common functions like open file, print, undo, etc.
In the following example, we use a Frame widget as the toolbar, and pack a number of ordinary buttons into it.Creating a simple toolbar
from Tkinter import *
root = Tk()
def callback():    print “called the callback!”
create a toolbartoolbar = Frame(root)
b = Button(toolbar, text=”new”, width=6, command=callback)b.pack(side=LEFT, padx=2, pady=2)
b = Button(toolbar, text=”open”, width=6, command=callback)b.pack(side=LEFT, padx=2, pady=2)
toolbar.pack(side=TOP, fill=X)
mainloop()
The buttons are packed against the left side, and the toolbar itself is packed against the topmost side, with the fill option set to X. As a result, the widget is resized if necssary, to cover the full with of the parent widget.
Also note that I’ve used text labels rather than icons, to keep things simple. To display an icon, you can use the PhotoImage constructor to load a small image from disk, and use the image option to display it.
Status BarsFinally, most applications sport a status bar at the bottom of each application window. Implementing a status bar with Tkinter is trivial: you can simply use a suitably configured Label widget, and reconfigure the text option now and then. Here’s one way to do it:
status = Label(master, text=””, bd=1, relief=SUNKEN, anchor=W)status.pack(side=BOTTOM, fill=X)
If you wish to be fancy, you can use the following class instead. It wraps a label widget in a convenience class, and provides set and clear methods to modify the contents.
A Status Bar Class (File: tkSimpleStatusBar.py)
class StatusBar(Frame):
def __init__(self, master):
    Frame.__init__(self, master)
    self.label = Label(self, bd=1, relief=SUNKEN, anchor=W)
    self.label.pack(fill=X)

def set(self, format, *args):
    self.label.config(text=format % args)
    self.label.update_idletasks()

def clear(self):
    self.label.config(text="")
    self.label.update_idletasks()

The set method works like C’s printf function; it takes a format string, possibly followed by a set of arguments (a drawback is that if you wish to print an arbitrary string, you must do that as set(“%s”, string)). Also note that this method calls the update_idletasks method, to make sure pending draw operations (like the status bar update) are carried out immediately.
But the real trick here is that we’ve inherited from the Frame widget. At the cost of a somewhat awkward call to the frame widget’s constructor, we’ve created a new kind of custom widget that can be treated as any other widget. You can create and display the status bar using the usual widget syntax:
status = StatusBar(root)status.pack(side=BOTTOM, fill=X)
We could have inherited from the Label widget itself, and just extended it with set and clear methods. This approach have a few drawbacks, though:
It makes it harder to maintain the status bar’s integrity. Some team members may cheat, and use config instead of set. That’s not a big deal, until the day you decide to do some extra processing in the set method. Or the day you decide to use a Canvas widget to implement a fancier status bar.

It increases the risk that your additional methods conflict with attributes or methods used by Tkinter. While the Frame and Toplevel widgets have relatively few methods, other widgets can have several dozens of widget specific attributes and methods.

Future versions of Tkinter may use factory functions rather than class constructors for most widgets. However, it’s more or less guaranteed that such versions will still provide Frame and Toplevel classes. Better safe than sorry, in other words.

]]></content>
      <categories>
        <category>Python</category>
        <category>GUI</category>
        <category>Tkinter</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>tkinter</tag>
      </tags>
  </entry>
  <entry>
    <title>Python Tkinter 标准对话框</title>
    <url>/2018/01/01/python-tkinter-1-9-standard-dialogs/</url>
    <content><![CDATA[Standard DialogsBefore we look at what to put in that application work area, let’s take a look at another important part of GUI programming: displaying dialogs and message boxes.
Starting with Tk 4.2, the Tk library provides a set of standard dialogs that can be used to display message boxes, and to select files and colors. In addition, Tkinter provides some simple dialogs allowing you to ask the user for integers, floating point values, and strings. Where possible, these standard dialogs use platform-specific mechanisms, to get the right look and feel.
Message BoxesThe tkMessageBox module provides an interface to the message dialogs.
The easiest way to use this module is to use one of the convenience functions: showinfo, showwarning, showerror, askquestion, askokcancel, askyesno, or askretrycancel. They all have the same syntax:
tkMessageBox.function(title, message [, options]).
The title argument is shown in the window title, and the message in the dialog body. You can use newline characters (\n) in the message to make it occupy multiple lines. The options can be used to modify the look; they are explained later in this section.
The first group of standard dialogs is used to present information. You provide the title and the message, the function displays these using an appropriate icon, and returns when the user has pressed OK. The return value should be ignored.
Here’s an example:
try:
    fp = open(filename)
except:
    tkMessageBox.showwarning(
        "Open file",
        "Cannot open this file\n(%s)" % filename
    )
    return

The showinfo dialogThe showwarning dialogThe showerror dialog
The second group is used to ask questions. The askquestion function returns the strings “yes” or “no” (you can use options to modify the number and type of buttons shown), while the others return a true value of the user gave a positive answer (ok, yes, and retry, respectively).
if tkMessageBox.askyesno("Print", "Print this report?"):
    report.print()

The askquestion dialogThe askokcancel dialogThe askyesno dialogThe askretrycancel dialog
[Screenshots made on a Swedish version of Windows 95. Hope you don’t mind…]
Message Box OptionsIf the standard message boxes are not appropriate, you can pick the closest alternative (askquestion, in most cases), and use options to change it to exactly suit your needs. You can use the following options (note that message and title are usually given as arguments, not as options).
default constant
Which button to make default: ABORT, RETRY, IGNORE, OK, CANCEL, YES, or NO (the constants are defined in the tkMessageBox module).
icon (constant)
Which icon to display: ERROR, INFO, QUESTION, or WARNING
message (string)
The message to display (the second argument to the convenience functions). May contain newlines.
parent (widget)
Which window to place the message box on top of. When the message box is closed, the focus is returned to the parent window.
title (string)
Message box title (the first argument to the convenience functions).
type (constant)
Message box type; that is, which buttons to display: ABORTRETRYIGNORE, OK, OKCANCEL, RETRYCANCEL, YESNO, or YESNOCANCEL.
]]></content>
      <categories>
        <category>Python</category>
        <category>GUI</category>
        <category>Tkinter</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>tkinter</tag>
      </tags>
  </entry>
  <entry>
    <title>Python GUI编程(Tkinter)</title>
    <url>/2018/01/01/python-tkinter/</url>
    <content><![CDATA[Python GUI编程(Tkinter)Python 提供了很多个图形开发界面的库，其中Tkinter模块是(Tk 接口)是 Python 的标准 Tk GUI 工具包的接口。 Tk 和 Tkinter 可以在大多数的 Unix 平台下使用,同样可以应用在 Windows 和 Macintosh 系统里。Tk8.0 的后续版本可以实现本地窗口风格,并良好地运行在绝大多数平台中。
Tkinter 编程Tkinter 是 Python 的标准 GUI 库。Python 使用 Tkinter 可以快速的创建 GUI 应用程序。
由于 Tkinter 是内置到 python 的安装包中、只要安装好 Python 之后就能 import Tkinter 库、而且 IDLE 也是用 Tkinter 编写而成、对于简单的图形界面 Tkinter 还是能应付自如。

注意：Python3.x 版本使用的库名为 tkinter,即首写字母 T 为小写。

import tkinter

创建一个GUI程序
导入 Tkinter 模块
创建控件
指定这个控件的 master， 即这个控件属于哪一个
告诉 GM(geometry manager) 有一个控件产生了。

实例:
#!/usr/bin/python# -*- coding: UTF-8 -*-import Tkintertop = Tkinter.Tk()# 进入消息循环top.mainloop()


实例2：
#!/usr/bin/python# -*- coding: UTF-8 -*-from Tkinter import *           # 导入 Tkinter 库root = Tk()                     # 创建窗口对象的背景色                                # 创建两个列表li     = ['C','python','php','html','SQL','java']movie  = ['CSS','jQuery','Bootstrap']listb  = Listbox(root)          #  创建两个列表组件listb2 = Listbox(root)for item in li:                 # 第一个小部件插入数据    listb.insert(0,item)for item in movie:              # 第二个小部件插入数据    listb2.insert(0,item)listb.pack()                    # 将小部件放置到主窗口中listb2.pack()root.mainloop()                 # 进入消息循环

Tkinter 组件Tkinter的提供各种控件，如按钮，标签和文本框，一个GUI应用程序中使用。这些控件通常被称为控件或者部件。
目前有15种Tkinter的部件。我们提出这些部件以及一个简短的介绍，在下面的表:



控件
描述



Button
按钮控件；在程序中显示按钮。


Canvas
画布控件；显示图形元素如线条或文本


Checkbutton
多选框控件；用于在程序中提供多项选择框


Entry
输入控件；用于显示简单的文本内容


Frame
框架控件；在屏幕上显示一个矩形区域，多用来作为容器


Label
标签控件；可以显示文本和位图


Listbox
列表框控件；在Listbox窗口小部件是用来显示一个字符串列表给用户


Menubutton
菜单按钮控件，由于显示菜单项。


Menu
菜单控件；显示菜单栏,下拉菜单和弹出菜单


Message
消息控件；用来显示多行文本，与label比较类似


Radiobutton
单选按钮控件；显示一个单选的按钮状态


Scale
范围控件；显示一个数值刻度，为输出限定范围的数字区间


Scrollbar
滚动条控件，当内容超过可视化区域时使用，如列表框。


Text
文本控件；用于显示多行文本


Toplevel
容器控件；用来提供一个单独的对话框，和Frame比较类似


Spinbox
输入控件；与Entry类似，但是可以指定输入范围值


PanedWindow
PanedWindow是一个窗口布局管理的插件，可以包含一个或者多个子控件。


LabelFrame
labelframe 是一个简单的容器控件。常用与复杂的窗口布局。


tkMessageBox
用于显示你应用程序的消息框。


标准属性标准属性也就是所有控件的共同属性，如大小，字体和颜色等等。



属性
描述



Dimension
控件大小；


Color
控件颜色；


Font
控件字体；


Anchor
锚点；


Relief
控件样式；


Bitmap
位图；


Cursor
光标；


几何管理Tkinter控件有特定的几何状态管理方法，管理整个控件区域组织，一下是Tkinter公开的几何管理类：包、网格、位置



几何方法
描述



pack()
包装；


grid()
网格；


place()
位置；


]]></content>
      <categories>
        <category>Python</category>
        <category>GUI</category>
        <category>Tkinter</category>
        <category>Matplotlib</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>tkinter</tag>
      </tags>
  </entry>
  <entry>
    <title>Python 工具集大全</title>
    <url>/2018/01/01/python-tools/</url>
    <content><![CDATA[Python 工具集IDE


开发环境
描述
网址



IDLE
The standard Python environment
http://www.python.org/idle


Pythonwin
Windows-oriented environment
http://www.python.org/download/windows


ActivePython
Feature-packed; contains Pythonwin IDE
http://www.activestate.com


Komodo
Commercial IDE
http://www.activestate.com3


Wingware
Commercial IDE
http://www.wingware.com


BlackAdder
Commercial IDE and (Qt) GUI builder
http://www.thekompany.com


Boa Constructor
Free IDE and GUI builder
http://boa-constructor.sf.net


Anjuta
Versatile IDE for Linux/UNIX
http://anjuta.sf.net


Arachno Python
Commercial IDE
http://www.python-ide.com


Code Crusader
Commercial IDE
http://www.newplanetsoftware.com


Code Forge
Commercial IDE
http://www.codeforge.com


Eclipse
Popular, flexible, open source IDE
http://www.eclipse.org


eric
Free IDE using Qt
http://eric-ide.sf.net


KDevelop
Cross-language IDE for KDE
http://www.kdevelop.org


VisualWx
Free GUI builder
http://visualwx.altervista.org


wxDesigner
Commercial GUI builder
http://www.roebling.de


wxGlade
Free GUI builder
http://wxglade.sf.net


软件安装pipPip 是目前安装python包很好的工具，但有时可能网络比较慢或者无法访问，此时可以临时更改pypi镜像。
国内pypi镜像

阿里：https://mirrors.aliyun.com/pypi/simple
豆瓣：http://pypi.douban.com/simple
中国科学技术大学：http://pypi.mirrors.ustc.edu.cn/simple/

指定单次安装源方法如下:
pip install &lt;包名&gt; -i http://pypi.v2ex.com/simple

图形库列举了一些Python的图形库，其中matplotlib功能最强大，Cairoplot最漂亮，django-chartit与Django集成了。
matplotlibMatplotlib 是一个由 John Hunter 等开发的，用以绘制 二维图形的 Python 模块。它利用了 Python 下的数值计算模块 Numeric 及 Numarray，克隆了许多 Matlab 中的函数， 用以帮助用户轻松地获得高质量的二维图形。Matplotlib 可以绘制多种形式的图形包括普通的线图，直方图，饼图，散点图以及误差线图等；可以比较方便的定制图形的各种属性比如图线的类型，颜色，粗细，字体的大小 等；它能够很好地支持一部分 TeX 排版命令，可以比较美观地显示图形中的数学公式。个人比较推荐这个类库。可以用于生成通常是由 matlab 或者 Mathematica 生成的高质量图表。
CairoplotCairoplot在网页上的表现力堪比flex中的图表图形效果。非常漂亮，非常赞！但是这个似乎只能跑在linux平台上。所以很多windows用户估计要失望了。
ChacoChaco是一个2D的绘图库。其中文简单教程参考：http://hyry.dip.jp/pydoc/chaco_intro.html
更多资料：
http://cairoplot.sourceforge.net/index.htmlhttps://github.com/rodrigoaraujo01/cairoplothttps://groups.google.com/forum/?fromgroups#!forum/cairoplot
Python Google Chart,官网：http://pygooglechart.slowchop.com/ 。从命名方式来看，这个肯定与google chart扯上了关系。所以该类库是对Google chart API的一个完整封装。
PyCha官网：https://bitbucket.org/lgs/pycha/wiki/Home 。PyCha可是说是Cairo 类库的一个简单封装，为了是实现轻量级，以及容易使用，当然还做了一些优化等。
pyOFC2官网：http://btbytes.github.com/pyofc2/ 。它是Open Falsh Library的Python类库。所以图形具有Flash效果，可以随鼠标移动动态显示图标中信息，这是优越于其他静态图示的。
Pychart官网：http://home.gna.org/pychart/ 。pyChart是用于创建高品质封装的PostScript，PDF格式，PNG，或SVG图表Python库。
PLPlot官网：http://plplot.sourceforge.net/ 。PLPlot是用于创建科学图表的跨平台软件包。以C类库为核心，支持各种语言绑定(C, C++, Fortran, Java, Python, Perl etc.)。开源免费。
reportlab官网：http://www.reportlab.com/software/opensource/ 。这个我们之前介绍过，参考http://www.codecho.com/installation-and-example-of-reportlab-in-python/ 。这个类库支持在pdf中画图表。
Vpython官网：http://www.vpython.org/index.html ，VPython是Visual Python的简写，Visual是由Carnegie Mellon University（卡耐基–梅隆大学）在校学生David Scherer于2000年撰写的一个Python 3D绘图模块。
Pycairohttp://cairographics.org/pycairo/ Pycairo is a set of Python bindings for the cairo graphics library.
panda3dhttp://www.panda3d.org/ Panda3D不像是一个画基本图表的东东，它是一个 3D 引擎，用于三维图形的演示及游戏开发。程序库采用C++以及Python语言来绑定。用panda3d进行游戏开发通常写一段Python或C + +程序控制panda3d程序库。
django-chartit非常漂亮的，并且与Django集成哦，它与MYSQL数据库集成了~
http://chartit.shutupandship.comhttps://github.com/pgollakota/django-chartit
时间库
time
datetime : 扩展的time，表示绝对时间和相对时间
calendar : 有几个比较有用的工具，比如isleap

文件读写
pickle ：简单滴只用dump和load即可
shelve：数据存在硬盘而不是内存中，适合在内存有限的情况下读取非常大的数据

数据分析
pandas
numpy

]]></content>
      <categories>
        <category>Python</category>
        <category>GUI</category>
        <category>IDE</category>
        <category>Matplotlib</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>Anjuta</tag>
        <tag>pip</tag>
        <tag>Komodo</tag>
        <tag>matplotlib</tag>
        <tag>ActivePython</tag>
        <tag>IDLE</tag>
        <tag>kdevelop</tag>
        <tag>Pythonwin</tag>
        <tag>visualwx</tag>
        <tag>wingware</tag>
        <tag>wxDesigner</tag>
        <tag>wxglade</tag>
        <tag>cairoplot</tag>
        <tag>chaco</tag>
        <tag>django-chartit</tag>
        <tag>panda3d</tag>
        <tag>pycairo</tag>
        <tag>pycha</tag>
        <tag>Pychart</tag>
        <tag>pyofc2</tag>
        <tag>reportlab</tag>
        <tag>Vpython</tag>
      </tags>
  </entry>
  <entry>
    <title>python3 内置虚拟环境venv</title>
    <url>/2019/01/23/python-venv-python3/</url>
    <content><![CDATA[Python3 内置虚拟环境venv.. _python-venv-python3:
在虚拟环境中安装（可选）您还可以选择在虚拟环境（或应用程序虚拟环境）中安装各种软件，以保持环境清洁。
$ python3 -m venv packenv

创建后，通过从命令行运行来激活虚拟环境
# Windows$ call packenv\scripts\activate.bat# Linux$ source packenv/bin/activate

最后，安装所需的软件包，比如numpy
$ pip3 install numpy



同时也可以增加一个提示符，比如NAME
$ python3 -m venv --prompt NAME virtual_name ]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>virtual</tag>
        <tag>venv</tag>
      </tags>
  </entry>
  <entry>
    <title>Python 常量和变量</title>
    <url>/2012/02/06/python-variable/</url>
    <content><![CDATA[Python 常量和变量常量常量是一旦初始化后就不能改变的变量，在C++中使用const指定常量。
变量计算机内存中的一块区域，变量可以存储任何事，而且可以改变。
局部变量a = 1b = 2def add():    a = 10    b = 5    return a + bprint (add())print (a)print (b)

全局变量_a = 1_b = 2def add():    global _a    global _b    _a = 10    _b = 5    return _a + _bdef sub():    global _a    global _b    _a = 10    _b = 5    return _a - _bprint (add())print (sub())print(_a)print(_b)

这里有一个global的关键字，如果没有这个关键字是不对的，结果可能对，但是实际的运行不是你认为的那样
_a = 1_b = 2def add():    _a = 10    _b = 5    return _a + _bdef sub():    _a = 10    _b = 5    return _a - _bprint (add())print (sub())print(_a)print(_b)
]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>name</tag>
        <tag>variable</tag>
      </tags>
  </entry>
  <entry>
    <title>python 虚拟环境virtualenv</title>
    <url>/2017/01/23/python-virtualenv/</url>
    <content><![CDATA[python 虚拟环境virtualenv在开发Python应用程序的时候，经常会因为各个应用程序使用的环境或包不同，而导致应用程序无法运行，亦或者因为没有管理员权限无法安装相应的包。
此时就需要使用Python的强大虚拟机工具virtualenv了，为每个应用创建一套自己的Python运行环境。
安装首先，我们用pip安装virtualenv：
$ pip3 install virtualenv
使用第一步，创建目录：$ mkdir myproject$ cd myproject/


第二步，创建一个独立的Python运行环境，命名为venv：$ virtualenv --no-site-packages venvUsing base prefix '/usr/local/.../Python.framework/Versions/3.4'New python executable in venv/bin/python3.4Also creating executable in venv/bin/pythonInstalling setuptools, pip, wheel...done.

命令virtualenv就可以创建一个独立的Python运行环境，我们还加上了参数–no-site-packages，这样，已经安装到系统Python环境中的所有第三方包都不会复制过来，这样，我们就得到了一个不带任何第三方包的“干净”的Python运行环境。
新建的Python环境被放到当前目录下的venv目录。有了venv这个Python环境，可以用source进入该环境：
第三部，调用虚拟环境$ source venv/bin/activate(venv)$

注意到命令提示符变了，有个(venv)前缀，表示当前环境是一个名为venv的Python环境。
第四步，安装各种包下面正常安装各种第三方包，并运行python命令：
(venv)$ pip install jinja2...Successfully installed jinja2-2.7.3 markupsafe-0.23(venv)$ python myapp.py...

在venv环境下，用pip安装的包都被安装到venv这个环境下，系统Python环境不受任何影响。也就是说，venv环境是专门针对myproject这个应用创建的。
第五步，退出虚拟环境退出当前的venv环境，使用deactivate命令：
(venv)$ deactivate$
此时就回到了正常的环境，现在pip或python均是在系统Python环境下执行。
指定python版本如果存在多个python解释器，可以选择指定一个Python解释器（比如python2.7），没有指定则由系统默认的解释器来搭建，比如下面的命令为使用python2.7来搭建。
$ virtualenv -p /usr/bin/python2.7 my_project_env

参考
https://www.liaoxuefeng.com/wiki/0014316089557264a6b348958f449949df42a6d3a2e542c000/001432712108300322c61f256c74803b43bfd65c6f8d0d0000

]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>sphinx</tag>
      </tags>
  </entry>
  <entry>
    <title>python 虚拟环境virtualenv</title>
    <url>/2017/01/23/python-vitualenv/</url>
    <content><![CDATA[简介在开发Python应用程序的时候，经常会因为各个应用程序使用的环境或包不同，而导致应用程序无法运行，亦或者因为没有管理员权限无法安装相应的包。
此时就需要使用Python的强大虚拟机工具virtualenv了，为每个应用创建一套自己的Python运行环境。
安装首先，我们用pip安装virtualenv：
$ pip3 install virtualenv



使用第一步，创建目录：$ mkdir myproject$ cd myproject/





第二步，创建一个独立的Python运行环境，命名为venv：$ virtualenv --no-site-packages venvUsing base prefix '/usr/local/.../Python.framework/Versions/3.4'New python executable in venv/bin/python3.4Also creating executable in venv/bin/pythonInstalling setuptools, pip, wheel...done.




命令virtualenv就可以创建一个独立的Python运行环境，我们还加上了参数–no-site-packages，这样，已经安装到系统Python环境中的所有第三方包都不会复制过来，这样，我们就得到了一个不带任何第三方包的“干净”的Python运行环境。
新建的Python环境被放到当前目录下的venv目录。有了venv这个Python环境，可以用source进入该环境：
第三部，调用虚拟环境$ source venv/bin/activate(venv)$


注意到命令提示符变了，有个(venv)前缀，表示当前环境是一个名为venv的Python环境。
第四步，安装各种包下面正常安装各种第三方包，并运行python命令：
(venv)$ pip install jinja2...Successfully installed jinja2-2.7.3 markupsafe-0.23(venv)$ python myapp.py...



在venv环境下，用pip安装的包都被安装到venv这个环境下，系统Python环境不受任何影响。也就是说，venv环境是专门针对myproject这个应用创建的。
第五步，退出虚拟环境退出当前的venv环境，使用deactivate命令：
(venv)$ deactivate$


此时就回到了正常的环境，现在pip或python均是在系统Python环境下执行。
指定python版本如果存在多个python解释器，可以选择指定一个Python解释器（比如python2.7），没有指定则由系统默认的解释器来搭建，比如下面的命令为使用python2.7来搭建。
$ virtualenv -p /usr/bin/python2.7 my_project_env



参考
https://www.liaoxuefeng.com/wiki/0014316089557264a6b348958f449949df42a6d3a2e542c000/001432712108300322c61f256c74803b43bfd65c6f8d0d0000

]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>sphinx</tag>
      </tags>
  </entry>
  <entry>
    <title>python 虚拟环境管理工具virtualenvwrapper</title>
    <url>/2017/01/23/python-virtualenvwrapper/</url>
    <content><![CDATA[python 虚拟环境管理工具virtualenvwrapper你可以在系统的任意地方创建虚拟环境，当下次需要这个某个环境的时候很难找，virtualenv不便于对环境的集中管理，virtualenvwrapper很好的解决了这个问题
首先需要安装：
$ pip install virtualenv$ pip install virtualenvwrapper

接下来创建一个目录，用来存放我们的虚拟环境，比如
$ mkdir ~/virtualenv/

然后配置环境变量：
$ export WORKON_HOME=~/Pyenv$ VIRTUALENVWRAPPER_PYTHON=/usr/bin/python3$ source /usr/local/bin/virtualenvwrapper.sh

这些内容可以写进bashrc文件中。
创建虚拟环境利用 virtualenvwrapper，我们可以使用下面的命令轻松创建一个虚拟环境。
$ mkvirtualenv spide$ mkvirtualenv --python=/usr/local/python3.7/bin/python py3 #指定解释器为3.7$ mkvirtualenv -p python3.7 pynew #指定版本比较喜欢用这个

然后就可以使用包管理命令了：
$ lsvirtualenv -b #查看虚拟环境$ workon #切换或者进入虚拟环境$ workon virtualenv-name # 进入虚拟环境virtualenv-name$ lssitepackages #查看当前环境中安装的那些包（启动虚拟环境后）$ deactivate #退出虚拟环境$ rmvirtualenv virtualname #虚拟环境名 删除虚拟环境
]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>virtualenv</tag>
        <tag>virtualenvwrapper</tag>
      </tags>
  </entry>
  <entry>
    <title>python 虚拟环境管理工具virtualenvwrapper</title>
    <url>/2017/01/23/python-vitualenvwrapper/</url>
    <content><![CDATA[python 虚拟环境管理工具virtualenvwrapper首先需要安装：
$ pip install virtualenv$ pip install virtualenvwrapper

接下来创建一个目录，用来存放我们的虚拟环境，比如
$ mkdir ~/virtualenv/

然后配置环境变量：
$ export WORKON_HOME=~/Pyenv$ VIRTUALENVWRAPPER_PYTHON=/usr/bin/python3$ source /usr/local/bin/virtualenvwrapper.sh

这些内容可以写进bashrc文件中。
创建虚拟环境利用 virtualenvwrapper，我们可以使用下面的命令轻松创建一个虚拟环境。
$ mkvirtualenv spide

然后就可以使用包管理命令了：
$ lsvirtualenv -b #查看虚拟环境$ workon #切换或者进入虚拟环境$ workon virtualenv-name # 进入虚拟环境virtualenv-name$ lssitepackages #查看当前环境中安装的那些包（启动虚拟环境后）$ deactivate #退出虚拟环境$ rmvirtualenv #虚拟环境名 删除虚拟环境
]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>virtualenv</tag>
        <tag>virtualenvwrapper</tag>
      </tags>
  </entry>
  <entry>
    <title>Python 循环语句</title>
    <url>/2010/08/07/python-while/</url>
    <content><![CDATA[Python 循环语句whilefor]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>for</tag>
        <tag>while</tag>
      </tags>
  </entry>
  <entry>
    <title>Qt中显示消息框</title>
    <url>/2014/09/03/qt-messagebox/</url>
    <content><![CDATA[Qt 的消息框Qt的消息框基本分为下面几种。

critical ： 出现比较严重的问题
information：提示信息
question：问题信息
warning：警告信息
aboutQt：关于Qt的信息
about：主要用于自定义，在个人程序里面属于用的比较多的

critical 严重错误源代码如下```    int rst = QMessageBox::critical(this,tr("Test Title"),tr("This is just a test\nWhat do you want to do?"),QMessageBox::Yes|QMessageBox::No|QMessageBox::Cancel);    if (rst == QMessageBox::Cancel)        qDebug("Cancel");    else if (rst == QMessageBox::Yes){        return save()    }    else {        return false;    }
效果图information 信息源代码如下```    int rst = QMessageBox::information(this,tr("Test Title"),tr("This is just a test\nWhat do you want to do?"),QMessageBox::Yes|QMessageBox::No|QMessageBox::Cancel);    if (rst == QMessageBox::Cancel)        qDebug("Cancel");    else if (rst == QMessageBox::Yes){        return save()    }    else {        return false;    }

效果图question 提问源代码如下```    int rst = QMessageBox::question(this,tr("Test Title"),tr("This is just a test\nWhat do you want to do?"),QMessageBox::Yes|QMessageBox::No|QMessageBox::Cancel);    if (rst == QMessageBox::Cancel)        qDebug("Cancel");    else if (rst == QMessageBox::Yes){        return save()    }    else {        return false;    }

效果图warning 警告源代码如下```    int rst = QMessageBox::warning(this,tr("Test Title"),tr("This is just a test\nWhat do you want to do?"),QMessageBox::Yes|QMessageBox::No|QMessageBox::Cancel);    if (rst == QMessageBox::Cancel)        qDebug("Cancel");    else if (rst == QMessageBox::Yes){        return save()    }    else {        return false;    }

效果图aboutQt源代码如下QMessageBox::aboutQt(this,"Test");
效果图about源代码如下```QMessageBox::about(this,"My App","This is just a demo\nVersion 0.1 Alpha\nWill improve in the following days...");

效果图about改进源代码如下```    QMessageBox::about(this,tr("About My App"),                       tr("&lt;h2&gt; My App 0.1 Alpha&lt;/h2&gt;"                          "&lt;p&gt;Copyright &amp;copy; 2014 Software Inc."                          "&lt;p&gt;My App is a small application that "                          "demonstrates blabla...."));

效果图]]></content>
      <categories>
        <category>Qt</category>
      </categories>
      <tags>
        <tag>Qt</tag>
        <tag>QMessageBox</tag>
        <tag>warning</tag>
        <tag>information</tag>
        <tag>critical</tag>
        <tag>question</tag>
        <tag>about</tag>
        <tag>aboutQt</tag>
      </tags>
  </entry>
  <entry>
    <title>Qt模态对话框</title>
    <url>/2014/09/03/qt-model-dialog/</url>
    <content><![CDATA[假设有个对话框的类Dialog，首先初始化一个对象
Dialog *dialog;dialog = new Dialog(this);

如果使用show调用，那就是非模态对话框
dialog-&gt;show();

如果使用exec调用，那就是模态对话框
dialog-&gt;exec();
]]></content>
      <categories>
        <category>Qt</category>
      </categories>
      <tags>
        <tag>Qt</tag>
        <tag>model</tag>
      </tags>
  </entry>
  <entry>
    <title>qt新建一个动作并与菜单连接</title>
    <url>/2014/09/02/qt-new-action/</url>
    <content><![CDATA[定义#include &lt;QIcon&gt;#include &lt;QAction&gt;#include &lt;QKeySequence&gt;QAction *quitAction;QAction *aboutQtAction;

初始化quitAction = new QAction(tr("&amp;Quit"),this);quitAction-&gt;setIcon(QIcon(":/quit.ico"));quitAction-&gt;setShortcut(QKeySequence::Quit);/// quitAction-&gt;setShortcut(tr("Ctrl+Q")); //Another short cut binding methodquitAction-&gt;setStatusTip(tr("Quit the program"));connect(quitAction,SIGNAL(triggered()),this,SLOT(close()));aboutQtAction = new QAction(tr("About Qt"),this);aboutQtAction-&gt;setStatusTip(tr("Show the Qt library's About Box"));connect(aboutQtAction,SIGNAL(triggered()),qApp,SLOT(aboutQt()));

连接/// Link the action to the menu bar   ui-&gt;menu_File-&gt;addAction(quitAction);   ui-&gt;menu_File-&gt;addAction(aboutQtAction);   ui-&gt;menuAbout-&gt;addAction(aboutQtAction);
]]></content>
      <categories>
        <category>Qt</category>
      </categories>
      <tags>
        <tag>Qt</tag>
        <tag>about</tag>
      </tags>
  </entry>
  <entry>
    <title>Qt右键弹出菜单</title>
    <url>/2014/09/02/qt-open-menu-right-click/</url>
    <content><![CDATA[实现代码ui-&gt;tableView-&gt;addAction(cutAction);ui-&gt;tableView-&gt;addAction(copyAction);ui-&gt;tableView-&gt;addAction(pasteAction);ui-&gt;tableView-&gt;setContextMenuPolicy(Qt::ActionsContextMenu);this-&gt;setCentralWidget(ui-&gt;tableView); //set the central widget
]]></content>
      <categories>
        <category>Qt</category>
      </categories>
      <tags>
        <tag>Qt</tag>
        <tag>menu</tag>
      </tags>
  </entry>
  <entry>
    <title>Qt PyQt5 简介</title>
    <url>/2016/08/19/qt-pyqt-introduction/</url>
    <content><![CDATA[PyQt5简介在软件设计过程中，图形用户界面（GUI）特别重要，漂亮、简介的用户界面可以增加软件的使用量，减少对终端不熟悉的人员的学习曲线。
Python作为目前超级火的语言，虽然本身不具备GUI功能，但是其强大的胶水特性，可以通过PyQt、Tkinter、wxPython等来扩展GUI功能。
PyQt是一个用于创建GUI应用程序的跨平台工具包，将Python编程语言和Qt库融合在一起。发挥出强强联合的特点。
而PyQt5是Qt5的python扩展，以前还有PyQt4，不过已经不在更新，不建议使用。
]]></content>
      <categories>
        <category>Qt</category>
        <category>PyQt</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>pyqt4</tag>
        <tag>pyqt5</tag>
      </tags>
  </entry>
  <entry>
    <title>创建一个Qt Quick 应用</title>
    <url>/2015/09/04/qt-quick-application/</url>
    <content><![CDATA[#include &lt;QApplication&gt;#include &lt;QSplashScreen&gt;#include &lt;QDateTime&gt;int main(int argc, char *argv[]){    QApplication a(argc, argv);    QSplashScreen *splash = new QSplashScreen;    splash-&gt;setPixmap(QPixmap(":/images/china.jpg"));    //splash-&gt;setWindowFlags(Qt::WindowStaysOnTopHint);    splash-&gt;show();    splash-&gt;showMessage("Will start in 1 seconds",Qt::AlignTop,Qt::blue);    QDateTime n=QDateTime::currentDateTime();        QDateTime now;        do{            now=QDateTime::currentDateTime();            a.processEvents();        } while (n.secsTo(now)&lt;=2);    splash-&gt;showMessage("Started...",Qt::AlignTop,Qt::blue);    do{        now=QDateTime::currentDateTime();        a.processEvents();    } while (n.secsTo(now)&lt;=2);    MainWindow w;    w.show();    splash-&gt;finish(&amp;w);    delete splash;    return a.exec();}
]]></content>
      <categories>
        <category>Qt</category>
      </categories>
      <tags>
        <tag>GUI</tag>
        <tag>Qt</tag>
        <tag>quick</tag>
      </tags>
  </entry>
  <entry>
    <title>QT读取写入二进制文件</title>
    <url>/2014/09/04/qt-read-write-file/</url>
    <content><![CDATA[读写二进制文件需要的头文件#include &lt;QMessageBox&gt;#include &lt;QString&gt;#include &lt;QPixmap&gt;#include &lt;QFile&gt;#include &lt;QDataStream&gt;


写二进制文件bool write_file(const QString &amp;filename){    QFile file(filename);    if(!file.open(QIODevice::WriteOnly))        {        QMessageBox::warning(this,tr("My App"),tr("Cannot write file %1:\n%2 .").arg(file.fileName()).arg(file.errorString()));        return false;    }    QDataStream out(&amp;file);    out.setVersion(QDataStream::Qt_5_7);    out &lt;&lt; qint32(0x1234abcd);    QApplication::setOverrideCursor(Qt::WaitCursor);    for (int i;i&lt;100;i++)        out &lt;&lt; quint16(i);    QApplication::setOverrideCursor(Qt::ArrowCursor);    return true;}

读二进制文件bool read_file(const QString &amp;filename){    QFile file(filename);    if(!file.open(QIODevice::ReadOnly))        {        QMessageBox::warning(this,tr("My App"),tr("Cannot read file %1:\n%2.").arg(file.fileName()).arg(file.errorString()));        return false;    }    QDataStream in(&amp;file);    in.setVersion(QDataStream::Qt_5_7);    //in &lt;&lt; qint32(0x1234abcd);    qint32 magic;    in &gt;&gt; magic;    if (magic != 0x1234abcd)    {        QMessageBox::warning(this,tr("My App"),tr("This is not a correct file"));        return false;    }    QApplication::setOverrideCursor(Qt::WaitCursor);    quint16 temp;    while (!in.atEnd()) {        in &gt;&gt; temp;        ui-&gt;textEdit-&gt;setText(QString("%1").arg(temp));    }    QApplication::setOverrideCursor(Qt::ArrowCursor);    return true;}
]]></content>
      <categories>
        <category>Qt</category>
      </categories>
      <tags>
        <tag>read</tag>
        <tag>write</tag>
        <tag>Qt</tag>
      </tags>
  </entry>
  <entry>
    <title>QT读取写入配置文件</title>
    <url>/2014/09/03/qt-read-write-setting/</url>
    <content><![CDATA[读写配置文件Qt提供了一个读取配置文件的类QSetting
写配置文件void write_setting(){    QSettings setting("SHAO","My App");    setting.setValue("name","SHAO");    setting.setValue("code",200030);}

读配置文件void read_setting(){    QSettings setting("SHAO","My App");    QString name = setting.value("name").toString();    qint32 code = setting.value("code").toInt();}

读取配置ini文件配置文件（.ini)格式：
number=2[config]node1=sucesssize=20[source]name=PC

读取上面的ini文件的简单代码如下所示
QSettings settings("test.ini",QSettings::IniFormat);ui-&gt;label-&gt;setText(settings.value("config/node1").toString());ui-&gt;lineEdit-&gt;setText(settings.value("config/size").toString());int a=settings.value("number").toInt();qDebug("the value a is: %d",a);
]]></content>
      <categories>
        <category>Qt</category>
      </categories>
      <tags>
        <tag>read</tag>
        <tag>write</tag>
        <tag>Qt</tag>
      </tags>
  </entry>
  <entry>
    <title>QT中设置窗口图标</title>
    <url>/2014/08/31/qt-set-windows-icon/</url>
    <content><![CDATA[如何设置Qt应用程序窗口图标首先添加资源新建里面选择Qt-&gt;Qt Resource File，添加一个image.qrc文件
在构造函数里面加入函数#include &lt;QIcon&gt;this-&gt;setWindowIcon(QIcon(":/images/file.ico"));

更新pro文件使用resource文件的时候需要更新pro配置文件，添加下面行
RESOURCES += image.qrc

效果图效果图如下所示：
]]></content>
      <categories>
        <category>Qt</category>
      </categories>
      <tags>
        <tag>Qt</tag>
        <tag>Icon</tag>
      </tags>
  </entry>
  <entry>
    <title>Qt信号和槽</title>
    <url>/2011/08/09/qt-signal-slot/</url>
    <content><![CDATA[信号和槽信号和槽用于对象间的通讯。
信号/槽机制是Qt的一个中心特征并且也许是Qt与其它工具包的最不相同的部分。
在图形用户界面编程中，我们经常希望一个窗口部件的一个变化被通知给另一个窗口部件。更一般地，我们希望任何一类的对象可以和其它对象进行通讯。例如，如果我们正在解析一个XML文件，当我们遇到一个新的标签时，我们也许希望通知列表视图我们正在用来表达XML文件的结构。
回调较老的工具包使用一种被称作回调的通讯方式来实现同一目的。回调是指一个函数的指针，所以如果你希望一个处理函数通知你一些事件，你可以把另一个函数（回调）的指针传递给处理函数。处理函数在适当的时候调用回调。
回调有两个主要缺点:

首先他们不是类型安全的。我们从来都不能确定处理函数使用了正确的参数来调用回调;
其次回调和处理函数是非常强有力地联系在一起的，因为处理函数必须知道要调用哪个回调。

关于一些信号和槽连接的摘要图信号和槽在Qt中我们有一种可以替代回调的技术。我们使用信号和槽。
当一个特定事件发生的时候，一个信号被发射。
Qt的窗口部件有很多预定义的信号，但是我们总是可以通过继承来加入我们自己的信号。槽就是一个可以被调用处理特定信号的函数。Qt的窗口部件又很多预定义的槽，但是通常的习惯是你可以加入自己的槽，这样你就可以处理你所感兴趣的信号。
信号和槽的机制是类型安全的：一个信号的签名必须与它的接收槽的签名相匹配。（实际上一个槽的签名可以比它接收的信号的签名少，因为它可以忽略额外的签名。）因为签名是一致的，编译器就可以帮助我们检测类型不匹配。
信号和槽是宽松地联系在一起的：一个发射信号的类不用知道也不用注意哪个槽要接收这个信号。Qt的信号和槽的机制可以保证如果你把一个信号和一个槽连接起来，槽会在正确的时间使用信号的参数而被调用。
信号和槽可以使用任何数量、任何类型的参数。它们是完全类型安全的：不会再有回调核心转储(core dump)。
从QObject类或者它的一个子类（比如QWidget类）继承的所有类可以包含信号和槽。当对象改变它们的状态的时候，信号被发送，从某种意义上讲，它们也许对外面的世界感兴趣。这就是所有的对象通讯时所做的一切。它不知道也不注意无论有没有东西接收它所发射的信号。这就是真正的信息封装，并且确保对象可以用作一个软件组件。
一个信号和槽连接的例子槽可以用来接收信号，但它们是正常的成员函数。一个槽不知道它是否被任意信号连接。此外，对象不知道关于这种通讯机制和能够被用作一个真正的软件组件。
你可以把许多信号和你所希望的单一槽相连，并且一个信号也可以和你所期望的许多槽相连。把一个信号和另一个信号直接相连也是可以的。（这时，只要第一个信号被发射时，第二个信号立刻就被发射。） 总体来看，信号和槽构成了一个强有力的组件编程机制。
一个小例子一个最小的C++类声明如下：
class Foo    {    public:        Foo();        int value() const { return val; }        void setValue( int );    private:        int val;    };

 一个小的Qt类如下：
class Foo : public QObject    {        Q_OBJECT    public:        Foo();        int value() const { return val; }    public slots:        void setValue( int );    signals:        void valueChanged( int );    private:        int val;    };

这个类有同样的内部状态，和公有方法来访问状态，但是另外它也支持使用信号和槽的组件编程：这个类可以通过发射一个信号，valueChanged()，来告诉外面的世界它的状态发生了变化，并且它有一个槽，其它对象可以发送信号给这个槽。
所有包含信号和/或者槽的类必须在它们的声明中提到Q_OBJECT。
槽可以由应用程序的编写者来实现。这里是Foo::setValue()的一个可能的实现：
void Foo::setValue( int v )    {        if ( v != val ) {            val = v;            emit valueChanged(v);        }    }

emit valueChanged(v)这一行从对象中发射valueChanged信号。正如你所能看到的，你通过使用emit signal(arguments)来发射信号。
下面是把两个对象连接在一起的一种方法：
Foo a, b;    connect(&amp;a, SIGNAL(valueChanged(int)), &amp;b, SLOT(setValue(int)));    b.setValue( 11 ); // a == undefined  b == 11    a.setValue( 79 ); // a == 79         b == 79    b.value();


调用a.setValue(79)会使a发射一个valueChanged() 信号，b将会在它的setValue()槽中接收这个信号，也就是b.setValue(79) 被调用。接下来b会发射同样的valueChanged()信号，但是因为没有槽被连接到b的valueChanged()信号，所以没有发生任何事（信号消失了）。

注意只有当v != val的时候setValue()函数才会设置这个值并且发射信号。这样就避免了在循环连接的情况下（比如b.valueChanged() 和a.setValue()连接在一起）出现无休止的循环的情况。
这个例子说明了对象之间可以在互相不知道的情况下一起工作，只要在最初的时在它们中间建立连接。
预处理程序改变或者移除了signals、slots和emit 这些关键字，这样就可以使用标准的C++编译器。
在一个定义有信号和槽的类上运行moc。这样就会生成一个可以和其它对象文件编译和连接成引用程序的C++源文件。
信号当对象的内部状态发生改变，信号就被发射，在某些方面对于对象代理或者所有者也许是很有趣的。只有定义了一个信号的类和它的子类才能发射这个信号。
例如，一个列表框同时发射highlighted()和activated()这两个信号。绝大多数对象也许只对activated()这个信号感兴趣，但是有时想知道列表框中的哪个条目在当前是高亮的。如果两个不同的类对同一个信号感兴趣，你可以把这个信号和这两个对象连接起来。
当一个信号被发射，它所连接的槽会被立即执行，就像一个普通函数调用一样。信号/槽机制完全不依赖于任何一种图形用户界面的事件回路。当所有的槽都返回后 emit也将返回。
如果几个槽被连接到一个信号，当信号被发射时，这些槽就会被按任意顺序一个接一个地执行。
信号会由moc自动生成并且一定不要在.cpp文件中实现。它们也不能有任何返回类型（比如使用void）。
关于参数需要注意。我们的经验显示如果信号和槽不使用特殊的类型，它们都可以多次使用。如果使用了一个特殊的类型，就只能被连接到被设计成可以处理的槽。
槽当一个和槽连接的信号被发射的时候，这个槽被调用。槽也是普通的C++函数并且可以像它们一样被调用；它们唯一的特点就是它们可以被信号连接。槽的参数不能含有默认值，并且和信号一样，为了槽的参数而使用自己特定的类型是很不明智的。
因为槽就是普通成员函数，但却有一点非常有意思的东西，它们也和普通成员函数一样有访问权限。一个槽的访问权限决定了谁可以和它相连：

一个public slots:区包含了任何信号都可以相连的槽。这对于组件编程来说非常有用：你生成了许多对象，它们互相并不知道，把它们的信号和槽连接起来，这样信息就可以正确地传递，并且就像一个铁路模型，把它打开然后让它跑起来。
一个protected slots:区包含了之后这个类和它的子类的信号才能连接的槽。这就是说这些槽只是类的实现的一部分，而不是它和外界的接口。
一个private slots:区包含了之后这个类本身的信号可以连接的槽。这就是说它和这个类是非常紧密的，甚至它的子类都没有获得连接权利这样的信任。


你也可以把槽定义为虚的，这在实践中被发现也是非常有用的。

信号和槽的机制是非常有效的，但是它不像“真正的”回调那样快。信号和槽稍微有些慢，这是因为它们所提供的灵活性，尽管在实际应用中这些不同可以被忽略。通常，发射一个和槽相连的信号，大约只比直接调用那些非虚函数调用的接收器慢十倍。这是定位连接对象所需的开销，可以安全地重复所有地连接（例如在发射期间检查并发接收器是否被破坏）并且可以按一般的方式安排任何参数。当十个非虚函数调用听起来很多时，举个例子来说，时间开销只不过比任何一个“new”或者 “delete”操作要少些。当你执行一个字符串、矢量或者列表操作时，需要“new”或者 “delete”，信号和槽仅仅对一个完整函数调用地时间开销中的一个非常小的部分负责。无论何时你在一个槽中使用一个系统调用和间接地调用超过十个函数的时间是相同的。在一台i585-500机器上，你每秒钟可以发射2，000，000个左右连接到一个接收器上的信号，或者发射1，200，000个左右连接到两个接收器的信号。信号和槽机制的简单性和灵活性对于时间的开销来说是非常值得的，你的用户甚至察觉不出来。
元对象信息元对象编译器（moc）解析一个C++文件中的类声明并且生成初始化元对象的C++代码。元对象包括所有信号和槽函数的名称，还有这些函数的指针。
元对象包括一些额外的信息，比如对象的类名称。你也可以检查一个对象是否继承了一个特定的类，比如：
if (widget-&gt; inherits("QButton") ) {        // 是的，它是一个Push Button、Radio Button或者其它按钮。  }

一个真实的例子这是一个注释过的简单的例子（代码片断选自qlcdnumber.h）。
 #include "qframe.h"    #include "qbitarray.h"    class QLCDNumber : public QFrame {        Q_OBJECTpublic:        QLCDNumber( QWidget *parent=0, const char *name=0 );        QLCDNumber( uint numDigits, QWidget *parent=0, const char *name=0 );signals:        void    overflow();public slots:        void    display( int num );        void    display( double num );        void    display( const char *str );        void    setHexMode();        void    setDecMode();        void    setOctMode();        void    setBinMode();        void    smallDecimalPoint( bool ); };


QLCDNumber通过QFrame和QWidget还有#include这样的相关声明继承了含有绝大多数信号/槽知识的QObject。
Q_OBJECT是由预处理器展开声明几个由moc来实现的成员函数，如果你得到了几行 “virtual function QButton::className not defined”这样的编译器错误信息，你也许忘记运行moc或者忘记在连接命令中包含moc输出。
它并不和moc直接相关，但是如果你继承了QWidget，你当然想在你的构造器中获得_parent_和_name_这两个参数，而且把它们传递到父类的构造器中。
一些解析器和成员函数在这里省略掉了，moc忽略了这些成员函数。
当QLCDNumber被请求显示一个不可能值时，它发射一个信号。
如果你没有留意溢出，或者你认为溢出不会发生，你可以忽略overflow()信号，也就是说你可以不把它连接到任何一个槽上。
另一方面如果当数字溢出时，你想调用两个不同的错误函数，很简单地你可以把这个信号和两个不同的槽连接起来。Qt将会两个都调用（按任意顺序）。
一个槽就是一个接收函数，用来获得其它窗口部件状态变或的信息。QLCDNumber 使用它，就像上面的代码一样，来设置显示的数字。因为display()是这个类和程序的其它的部分的一个接口，所以这个槽是公有的。
几个例程把[QScrollBar的newValue信号连接到display槽，所以LCD数字可以继续显示滚动条的值。请注意display()被重载了，当你把一个信号和这个槽相连的时候，Qt将会选择适当的版本。如果使用回调，你会发现五个不同的名字并且自己来跟踪类型。
]]></content>
      <categories>
        <category>Qt</category>
      </categories>
      <tags>
        <tag>signal</tag>
        <tag>Qt</tag>
        <tag>slot</tag>
        <tag>connect</tag>
      </tags>
  </entry>
  <entry>
    <title>Qt如何编写程序启动界面</title>
    <url>/2014/09/04/qt-splash-window/</url>
    <content><![CDATA[#include &lt;QApplication&gt;#include &lt;QSplashScreen&gt;#include &lt;QDateTime&gt;int main(int argc, char *argv[]){    QApplication a(argc, argv);    QSplashScreen *splash = new QSplashScreen;    splash-&gt;setPixmap(QPixmap(":/images/china.jpg"));    //splash-&gt;setWindowFlags(Qt::WindowStaysOnTopHint);    splash-&gt;show();    splash-&gt;showMessage("Will start in 1 seconds",Qt::AlignTop,Qt::blue);    QDateTime n=QDateTime::currentDateTime();        QDateTime now;        do{            now=QDateTime::currentDateTime();            a.processEvents();        } while (n.secsTo(now)&lt;=2);    splash-&gt;showMessage("Started...",Qt::AlignTop,Qt::blue);    do{        now=QDateTime::currentDateTime();        a.processEvents();    } while (n.secsTo(now)&lt;=2);    MainWindow w;    w.show();    splash-&gt;finish(&amp;w);    delete splash;    return a.exec();}
]]></content>
      <categories>
        <category>Qt</category>
        <category>GUI</category>
      </categories>
      <tags>
        <tag>GUI</tag>
        <tag>Qt</tag>
        <tag>splash</tag>
      </tags>
  </entry>
  <entry>
    <title>Qt问题集锦</title>
    <url>/2011/08/19/qt-troubleshooting/</url>
    <content><![CDATA[Qt问题集锦Qt中出现class QApplication has no member named setMainWidget主要是因为qmake使用的是qt4的版本，而在qt4中已经不支持setMainWidget这个函数了，解决方法：在所有包含头文件的最前面添加**#define QT3_SUPPORT**，可以提供对qt3的支持，这样就可以解决问题了。
]]></content>
      <categories>
        <category>Qt</category>
      </categories>
      <tags>
        <tag>qt</tag>
      </tags>
  </entry>
  <entry>
    <title>QT中定时更新日期时间控件</title>
    <url>/2014/08/30/qt-update-timer/</url>
    <content><![CDATA[如何定时更新日期时间控件首先定义一个定时器timer = new QTimer(this);connect(timer,SIGNAL(timeout()),this,SLOT(update_time()));timer-&gt;start(1000);

编写定时器对应的信号槽QDateTime current = QDateTime::currentDateTime();ui-&gt;dateTimeEdit-&gt;setDateTime(current);
]]></content>
      <categories>
        <category>Qt</category>
      </categories>
      <tags>
        <tag>time</tag>
        <tag>date</tag>
        <tag>Qt</tag>
        <tag>timer</tag>
      </tags>
  </entry>
  <entry>
    <title>Qt窗口时候更改过</title>
    <url>/2014/09/03/qt-window-modified/</url>
    <content><![CDATA[每个Widget都有一个windowModified属性，如果该窗口的文档存在没有保存的变化，则将其设置为true，否则设置为false。
this-&gt;setWindowModified(true);this-&gt;setWindowTitle(tr("%1[*] - %2").arg(filename).arg(path));
]]></content>
      <categories>
        <category>Qt</category>
      </categories>
      <tags>
        <tag>Qt</tag>
        <tag>windowModified</tag>
      </tags>
  </entry>
  <entry>
    <title>Aegean installation</title>
    <url>/2020/04/03/radio-astronomy-install-aegean/</url>
    <content><![CDATA[Aegean安装步骤Aegean为MWA阵列的点源搜索软件，由Paul开发，网址为:  https://github.com/PaulHancock/Aegean 
# 稳定版$ wget https://github.com/PaulHancock/Aegean/archive/v.2.2.0.tar.gz$ tar zxvf v.2.2.0.tar.gz$ cd Aegean-v.2.2.0$ python3 setup.py build$ sudo python3 setup.py install# 最新版$ pip3 install git+https://github.com/PaulHancock/Aegean.git
]]></content>
      <categories>
        <category>射电天文</category>
      </categories>
      <tags>
        <tag>astronomy</tag>
        <tag>AstroSoft</tag>
        <tag>天文</tag>
        <tag>射电</tag>
        <tag>radio</tag>
        <tag>radio astronomy</tag>
        <tag>aegean</tag>
      </tags>
  </entry>
  <entry>
    <title>CASA installation</title>
    <url>/2017/04/03/radio-astronomy-install-casa/</url>
    <content><![CDATA[CASA安装步骤下载: https://casa.nrao.edu/casa_obtaining.shtml
安装步骤 ： https://casa.nrao.edu/casadocs/latest/usingcasa/obtaining-and-installing
$ export CASAPATH=/the/path/of/casa/$ cd $CASAPATH$ tar zxvf casa-release-x.x.x.tar.gz

把下述内容添加到~/.bashrc，这样就可以自启动了
export PATH=$PATH:/usr/local/bin/casa-release-5.4.1-31.el7/bin


对于开启了SELinux的Linux而言，可能需要关闭这个功能setsebool -P allow_execheap=1

]]></content>
      <categories>
        <category>射电天文</category>
      </categories>
      <tags>
        <tag>astronomy</tag>
        <tag>AstroSoft</tag>
        <tag>天文</tag>
        <tag>射电</tag>
        <tag>radio</tag>
        <tag>radio astronomy</tag>
        <tag>casa</tag>
      </tags>
  </entry>
  <entry>
    <title>casacore  installation</title>
    <url>/2019/01/19/radio-astronomy-install-casacore/</url>
    <content><![CDATA[简介casacore 是一系列射电天文数据处理的C++库
安装Debian/Ubuntu$ apt-get update$ sudo apt-get install build-essential cmake gfortran g++ libncurses5-dev libreadline-dev flex bison libblas-dev liblapacke-dev libcfitsio-dev wcslib-dev$ sudo apt-get install libhdf5-serial-dev libfftw3-dev python-numpy libboost-python-dev libpython3.4-dev libpython2.7-dev$ apt-get search casacore$ apt-get install casacore

CentOS$ yum update$ sudo yum install cmake cmake-gui gcc-gfortran gcc-c++ flex bison blas blas-devel  lapack lapack-devel cfitsio cfitsio-devel wcslib wcslib-devel ncurses ncurses-devel readline readline-develpython-devel boost boost-devel fftw fftw-devel hdf5 hdf5-devel numpy boost-python$ apt-get search casacore$ apt-get install casacore

MacOSX$ brew tap ska-sa/tap$ brew install casacore

Docker$ docker pull quay.io/casacore/casacore:master

测试数据集ftp://ftp.astron.nl/outgoing/Measures/
代码参考 https://www.github.com/shaoguangleo/radio_astronomy
]]></content>
      <categories>
        <category>射电天文</category>
      </categories>
      <tags>
        <tag>astronomy</tag>
        <tag>AstroSoft</tag>
        <tag>天文</tag>
        <tag>射电</tag>
        <tag>radio</tag>
        <tag>radio astronomy</tag>
      </tags>
  </entry>
  <entry>
    <title>AstroSoft 安装 CFITSIO</title>
    <url>/2015/02/24/radio-astronomy-install-cfitsio/</url>
    <content><![CDATA[如何安装CFITSIO  – how to install CFITSIO如果只是使用，那么可以使用下面一个命令来获取FFTW的运行环境(需要安装docker)：
$ docker run -it shaoguangleo/ubuntu-cfitsio# or$ docker run -it shaoguangleo/centos-cfitsio

如果希望运行图形界面，运行下述命令：
$ docker run -it -e DISPLAY=unix$DISPLAY -v /tmp/.X11-unix:/tmp/.X11-unix shaoguangleo/ubuntu-cfitsio# or$ docker run -it -e DISPLAY=unix$DISPLAY -v /tmp/.X11-unix:/tmp/.X11-unix shaoguangleo/centos-cfitsio

如果希望体验一下源码安装，安装如下所示，配置参考[ASTROSOFT_CONFIG][astrosoft_config]：
$ source astrosoft_config.sh$ cd ~$ wget $CFITSIO_WEBSITE/cfitsio$CFITSIO_VERSION.tar.gz$ gunzip -c cfitsio${CFITSIO_VERSION}.tar.gz | tar xvf -$ cd cfitsio$ ./configure --prefix=$ASTROSOFT$ make clean$ make$ make shared$ make install

]]></content>
      <categories>
        <category>射电天文</category>
      </categories>
      <tags>
        <tag>AstroSoft</tag>
        <tag>天文</tag>
        <tag>射电</tag>
        <tag>docker</tag>
        <tag>cfitsio</tag>
        <tag>pulsar</tag>
        <tag>Tempo</tag>
        <tag>PSRCHIVE</tag>
      </tags>
  </entry>
  <entry>
    <title>AstroSoft 安装 dspsr</title>
    <url>/2015/01/24/radio-astronomy-install-dspsr/</url>
    <content><![CDATA[如何安装dspsr  – how to install dspsr如果只是使用，那么可以使用下面一个命令来获取Tempo的运行环境(需要安装docker)：
$ docker run -it shaoguangleo/ubuntu-pulsar

如果希望运行图形界面，运行下述命令：
$ docker run -it -e DISPLAY=unix$DISPLAY -v /tmp/.X11-unix:/tmp/.X11-unix shaoguangleo/ubuntu-pulsar

如果希望体验一下Tempo，安装如下所示，配置参考[ASTROSOFT_CONFIG][astrosoft_config]：
$ tar zxvf tempo.tar.gz$ cd tempo$ ./prepare$ ./configure --prefix=/usr/local/tempo$ make$ make install$ cp -rv clock ephem tzpar util /usr/local/tempo$ cp tempo.hlp /usr/local/tempo$ cp obsys.dat /usr/local/tempo$ echo "export PATH=$PATH:/usr/local/tempo/bin" &gt;&gt; ~/.bashrc$ echo "export TEMPO=/usr/local/tempo" &gt;&gt; ~/.bashrc$ echo "export CLKDIR=/usr/local/tempo/clock" &gt;&gt; ~/.bashrc$ echo "export PARDIR=/usr/local/tempo/tzpar" &gt;&gt; ~/.bashrc$ echo "export EPHDIR=/usr/local/tempo/ephem" &gt;&gt; ~/.bashrc$ echo "export OBSYS=/usr/local/tempo/obsys.dat" &gt;&gt; ~/.bashrc

Enjoy~[^ astrosoft_config]: https://github.com/shaoguangleo/AstroSoft
]]></content>
      <categories>
        <category>射电天文</category>
      </categories>
      <tags>
        <tag>AstroSoft</tag>
        <tag>天文</tag>
        <tag>射电</tag>
        <tag>docker</tag>
        <tag>configure</tag>
        <tag>PATH</tag>
        <tag>pulsar</tag>
        <tag>Tempo</tag>
        <tag>tempo</tag>
        <tag>CLKDIR</tag>
        <tag>PARDIR</tag>
        <tag>EPHDIR</tag>
        <tag>OBSYS</tag>
      </tags>
  </entry>
  <entry>
    <title>AstroSoft 安装 Difmap</title>
    <url>/2019/06/03/radio-astronomy-install-difmap/</url>
    <content><![CDATA[安装步骤
首先下载压缩包wget ftp://ftp.astro.caltech.edu/pub/difmap/difmapx.x.tar.gz；
x.x为版本号，目前最新版本2.5e


解压tar xvf difmap2.5e.tar.gz
进入目录cd uvf_difmap
编辑configure文件，将f77修改为gfortran，并酌情修改pgplot参数
对于MacOSX比较麻烦，可能修改的地方比较多，比如PGPLOT以及CCLIB


编译./configure system_name
其中system_name可以为如下参数：
sun4-gcc  -  Sun sparc running SUNOS4.* using gcc.
sol2-gcc  -  Sun sparc running Solaris 2.* using gcc.
sol2-cc   -  Sun Sparc running Solaris 2.* using the SUN ANSI cc
           compiler.


hppa-c89  -  HP9000 700 or 800 series workstations using c89.
IBM-c89   -  IBM 6xxx series workstations using c89.
alpha-osf1-gcc - Alpha AXP running OSF1, using the Gnu C compiler, gcc.
alpha-osf1-cc  - Alpha AXP running OSF1, using the native DEC C compiler.
linux-i486-gcc - I486 PC running Linux, using the Gnu C compiler, gcc.
linux-ia64-ecc - Itanium PC running Linux, using the Intel compiler ecc.
linux-ia64-gcc - Itanium or AMD64 PC running Linux, using gcc.
apple-osx-gcc  - Macintosh computer running OSX, using the Gnu C compiler.
intel-osx-gcc  - Intel Mac computer running OSX, using the Gnu C compiler.


安装./makeall

详情参考压缩包中的README文件
代码参考 https://www.github.com/shaoguangleo/radio_astronomy
]]></content>
      <categories>
        <category>射电天文</category>
      </categories>
      <tags>
        <tag>astronomy</tag>
        <tag>AstroSoft</tag>
        <tag>天文</tag>
        <tag>射电</tag>
        <tag>radio</tag>
        <tag>radio astronomy</tag>
        <tag>difmap</tag>
      </tags>
  </entry>
  <entry>
    <title>Duchamp installation</title>
    <url>/2020/04/03/radio-astronomy-install-duchamp/</url>
    <content><![CDATA[ADuchamp安装步骤下载:  https://www.atnf.csiro.au/computing/software/duchamp/downloads/Duchamp-1.6.1.tar.gz 
需要安装PGPLOT、WCSLIB和CFITSIO
tar zxvf Duchmap-1.6.1.tar.gzcd Duchmap-1.6.1./configuremakemake libmake cleanmake install
]]></content>
      <categories>
        <category>射电天文</category>
      </categories>
      <tags>
        <tag>astronomy</tag>
        <tag>AstroSoft</tag>
        <tag>天文</tag>
        <tag>射电</tag>
        <tag>radio</tag>
        <tag>radio astronomy</tag>
        <tag>duchamp</tag>
      </tags>
  </entry>
  <entry>
    <title>AstroSoft 安装 FFTW</title>
    <url>/2015/02/24/radio-astronomy-install-fftw/</url>
    <content><![CDATA[如何安装FFTW  – how to install FFTW如果只是使用，那么可以使用下面一个命令来获取FFTW的运行环境(需要安装docker)：
$ docker run -it shaoguangleo/ubuntu# or$ docker run -it shaoguangleo/centos

如果希望运行图形界面，运行下述命令：
$ docker run -it -e DISPLAY=unix$DISPLAY -v /tmp/.X11-unix:/tmp/.X11-unix shaoguangleo/ubuntu# or$ docker run -it -e DISPLAY=unix$DISPLAY -v /tmp/.X11-unix:/tmp/.X11-unix shaoguangleo/centos

如果希望体验一下源码安装，安装如下所示，配置参考[ASTROSOFT_CONFIG][astrosoft_config]：
假定version为fftw的版本号：
$ wget http://www.fftw.org/fftw-version.tar.gz$ gunzip -c fftw-version.tar.gz | tar xvf -$ cd fftw-version# for psrchive$ ./configure --prefix=$ASTROSOFT --enable-float --enable-threads --enable-shared CFLAGS=-fPIC FFLAGS=-fPIC$ make$ make check$ make install$ make clean# for tempo2$ ./configure --prefix=$ASTROSOFT CFLAGS=-fPIC FFLAGS=-fPIC$ make$ make check$ make install$ make clean
]]></content>
      <categories>
        <category>射电天文</category>
      </categories>
      <tags>
        <tag>AstroSoft</tag>
        <tag>天文</tag>
        <tag>射电</tag>
        <tag>docker</tag>
        <tag>pulsar</tag>
        <tag>Tempo</tag>
        <tag>PSRCHIVE</tag>
        <tag>tempo2</tag>
        <tag>psrchive</tag>
      </tags>
  </entry>
  <entry>
    <title>AstroSoft 安装 Miriad</title>
    <url>/2019/06/03/radio-astronomy-install-miriad/</url>
    <content><![CDATA[Miriad 安装下载所需的源码、编译版本等首先下载压缩包:
$ mkdir /usr/local/astrosoft$ cd /usr/local/astrosoft/$ wget ftp://ftp.atnf.csiro.au/pub/software/miriad/miriad-common.tar.bz2$ wget ftp://ftp.atnf.csiro.au/pub/software/miriad/miriad-code.tar.bz2$ wget ftp://ftp.atnf.csiro.au/pub/software/miriad/miriad-linux64.tar.bz2


解压$ cd /usr/local/astrosoft/$ tar xvf miriad-common.tar.bz2$ tar xvf miriad-code.tar.bz2$ tar xvf miriad-code.tar.bz2

安装依赖配置环境$ cd /usr/local/astrosoft/miriad$ sudo apt -y install libncurses-dev # Ubuntu$ sudo yum -y install ncurses-devel  # CentOS$ export MIR=/usr/local/astrosoft/miriad$ sed -e "s,@MIRROOT@,$MIR," scripts/MIRRC.in &gt; MIRRC$ sed -e "s,@MIRROOT@,$MIR," scripts/MIRRC.sh.in &gt; MIRRC.sh$ source MIRRC.sh$ source $MIR/MIRRC.sh$ export PATH=$MIRBIN:$PATH 

参考详细的可以参考 https://shaoguangleo.github.io/tags/AstroSoft/ 
]]></content>
      <categories>
        <category>射电天文</category>
      </categories>
      <tags>
        <tag>astronomy</tag>
        <tag>AstroSoft</tag>
        <tag>天文</tag>
        <tag>射电</tag>
        <tag>miriad</tag>
        <tag>radio</tag>
        <tag>radio astronomy</tag>
      </tags>
  </entry>
  <entry>
    <title>Obit installation</title>
    <url>/2020/08/28/radio-astronomy-install-obit/</url>
    <content><![CDATA[安装 Obit下载源码包
Obit : http://www.jive.nl/parseltongue/releases/Obit-22JUN10m.tar.gz

tar zxvf Obit-22JUN10m.tar.gzmv Obit /usr/local/astrosoft/Obit-22JUN10mcd  /usr/local/astrosoft/Obit-22JUN10m./configure --prefix=/usr/local/astrosoft/Obit-22JUN10mmake


代码参考 https://www.github.com/shaoguangleo/radio_astronomy
]]></content>
      <categories>
        <category>射电天文</category>
      </categories>
      <tags>
        <tag>astronomy</tag>
        <tag>AstroSoft</tag>
        <tag>天文</tag>
        <tag>射电</tag>
        <tag>radio</tag>
        <tag>radio astronomy</tag>
        <tag>difmap</tag>
      </tags>
  </entry>
  <entry>
    <title>Parseltongue installation</title>
    <url>/2018/08/28/radio-astronomy-install-parseltongue/</url>
    <content><![CDATA[安装 Parseltongue下载源码包
Parseltongue : http://www.jive.nl/parseltongue/releases/parseltongue-2.3.tar.gz
Obit : http://www.jive.nl/parseltongue/releases/Obit-22JUN10m.tar.gz

MacOSX 安装brew install http://www.jive.nl/parseltongue/releases/obit.rbbrew install http://www.jive.nl/parseltongue/releases/parseltongue.rb

Ubuntu安装$ sudo add-apt-repository ppa:kettenis-w/parseltongue$ sudo apt-get update$ sudo apt-get install parseltongue

源码安装$ tar zxvf parseltongue-x.x.tar.gz$ cd parseltongue-x.x$ ./configure --with-obit=/usr/lib64/obit --prefix=/the/path/you/want/to/install$ make$ make install





使用condaconda create --name python27 python=2.7conda activate python27conda install -c kettenis parseltongue

代码参考 https://www.github.com/shaoguangleo/radio_astronomy
]]></content>
      <categories>
        <category>射电天文</category>
      </categories>
      <tags>
        <tag>astronomy</tag>
        <tag>AstroSoft</tag>
        <tag>天文</tag>
        <tag>射电</tag>
        <tag>radio</tag>
        <tag>radio astronomy</tag>
        <tag>difmap</tag>
      </tags>
  </entry>
  <entry>
    <title>Ubuntu/Debain/Fedora/Mac/CentOS 安装PGPLOT</title>
    <url>/2018/01/21/radio-astronomy-install-pgplot/</url>
    <content><![CDATA[本篇日志主要讲述了如何在MacOSX和Linux上安装PGPLOT，以避免经历一些不必要的坑。
Ubuntu/Debain/Fedora/Mac/CentOS 安装PGPLOT最简单的安装方式为使用我提供的docker镜像，参考AstroSoft。
只需要下面的一个命令，即可使用。目前支持Ubuntu和CentOS两大发行版。
Ubuntu$ docker run -it -e DISPLAY=unix$DISPLAY -v /tmp/.X11-unix:/tmp/.X11-unix shaoguangleo/ubuntu-pgplot

CentOS$ docker run -it -e DISPLAY=unix$DISPLAY -v /tmp/.X11-unix:/tmp/.X11-unix shaoguangleo/centos-pgplot

开始下面开始正文，源码安装。正常情况下，安装分为两个步骤：

安装图形库
配置环境变量
然后可以使用一些demo来测试程序是否正常运行

Mac 用户Mac上最方便的安装PGPLOT的方法就是使用port，首先确认已经安装了port，然后执行：
$ port installed pgplot

不同的PGPLOT库 (libpgplot.* 和 libcpgplot.*) 安装在 /opt/local/lib 文件夹，X11  服务安装在 /opt/local/bin/pgxwin_server，其他一些文件安装在/opt/local/share/pgplot。
安装完成后，要确定下环境变量是否配置好，可以使用下述命令来检查：
$ echo $PGPLOT_DIR$ echo $PGPLOT_DEV

如果环境变量没有设置，可以通过下属命令来设置：
$ export PGPLOT_DIR=/opt/local/lib$ export PGPLOT_DEV=/Xserve

当然最好的方法就是把这些环境变量写在.bashrc文件中。
最后确保所有的示例程序工作正常。
$ /opt/local/share/pgplot/examples/pgdemo1$ /opt/local/share/pgplot/examples/pgdemo2$ /opt/local/share/pgplot/examples/pgdemo3...



Linux 用户在Linux系统中，从pgplot下载源码，在Linux里面手动编译的方式比较好，目前最新的版本为pgplot5.2。不过这里比较注意，一个前提条件就是X11文件是可用的，另外一个就是需要安装gfortran编辑器。
不同的系统支持的包不同，详细看下面的命令。
Fedora:$ sudo yum install libX11-devel$ sudo yum install gcc-gfortran

Ubuntu:$ sudo apt-get install xorg-dev$ sudo apt-get install gfortran

CentOS:$ sudo yum install libX11-devel$ sudo yum install gcc-gfortran

OpenSUSE:$ sudo zypper install xorg-X11-devel$ sudo zypper install gcc-fortran

Debian:$ sudo apt-get install libX11-dev$ sudo apt-get install gfortran


详细的安装步骤
下载源码 pgplot5.2
解压并将源码放在/usr/local/src/中

# cd /usr/local/src# mv ~/Downloads/pgplot5.2.tar.gz .# tar zxvf pgplot5.2.tar.gz

创建pgplot安装的路径:

# mkdir /usr/local/pgplot# cd /usr/local/pgplot


拷贝 drivers.list 文件到安装目录:

# cp /usr/local/src/pgplot/drivers.list .


编辑drives.list文件，将下面的注释取消：


/PS
/VPS
/CPS
/VCPS
/XServe


创建makefile文件

# /usr/local/src/pgplot/makemake /usr/local/src/pgplot linux g77_gcc_aout

编辑makefile文件，并将FCOMPL=g77替换为FCOMPL=gfortran

编译源码：

# make# make cpg# make clean

确定环境变量已经设置：
$ export PGPLOT_DIR=/usr/local/pgplot$ export PGPLOT_DEV=/Xserve

使用测试用例来检测安装已经完成。
$ /usr/local/pgplot/pgdemo1$ /usr/local/pgplot/pgdemo2$ /usr/local/pgplot/pgdemo3...
]]></content>
      <categories>
        <category>射电天文</category>
      </categories>
      <tags>
        <tag>CentOS</tag>
        <tag>pgplot</tag>
        <tag>Linux</tag>
        <tag>PGPLOT</tag>
        <tag>AstroSoft</tag>
        <tag>天文</tag>
        <tag>射电</tag>
        <tag>MacOSX</tag>
        <tag>docker</tag>
        <tag>Debian</tag>
        <tag>ubuntu</tag>
        <tag>centos</tag>
        <tag>Fedora</tag>
        <tag>fedora</tag>
        <tag>mac</tag>
        <tag>debian</tag>
        <tag>Ubuntu</tag>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title>AstroSoft 安装 PSRCAT</title>
    <url>/2015/02/24/radio-astronomy-install-psrcat/</url>
    <content><![CDATA[如何安装PSRCAT  – how to install PSRCAT如果只是使用，那么可以使用下面一个命令来获取FFTW的运行环境(需要安装docker)：
$ docker run -it shaoguangleo/ubuntu-psrcat# or$ docker run -it shaoguangleo/centos-psrcat

如果希望运行图形界面，运行下述命令：
$ docker run -it -e DISPLAY=unix$DISPLAY -v /tmp/.X11-unix:/tmp/.X11-unix shaoguangleo/ubuntu-psrcat# or$ docker run -it -e DISPLAY=unix$DISPLAY -v /tmp/.X11-unix:/tmp/.X11-unix shaoguangleo/centos-psrcat

如果希望体验一下源码安装，安装如下所示，配置参考[ASTROSOFT_CONFIG][astrosoft_config]：
$ source astrosoft_config.sh$ cd ~$ wget $PSRCAT_WEBSITE/$PSRCAT_VERSION.tar.gz$ tar zxvf $PSRCAT_VERSION.tar.gz$ cd psrcat_tar$ csh makeit$ mkdir -p $ASTROSOFT/psrcat/bin$ cp psrcat $ASTROSOFT/psrcat/bin$ cp psrcat.db $ASTROSOFT/psrcat$ export PSRCAT_FILE=$ASTROSOFT/psrcat/psrcat.db$ export PATH=$PATH:$ASTROSOFT/psrcat/bin

]]></content>
      <categories>
        <category>射电天文</category>
      </categories>
      <tags>
        <tag>AstroSoft</tag>
        <tag>天文</tag>
        <tag>射电</tag>
        <tag>docker</tag>
        <tag>pulsar</tag>
        <tag>PSRCHIVE</tag>
        <tag>psrcat</tag>
      </tags>
  </entry>
  <entry>
    <title>AstroSoft 安装 PSRCHIVE</title>
    <url>/2015/02/24/radio-astronomy-install-psrchive/</url>
    <content><![CDATA[如何安装PSRCHIVE  – how to install PSRCHIVE如果只是使用，那么可以使用下面一个命令来获取FFTW的运行环境(需要安装docker)：
$ docker run -it shaoguangleo/ubuntu-psrchive# or$ docker run -it shaoguangleo/centos-psrchive

如果希望运行图形界面，运行下述命令：
$ docker run -it -e DISPLAY=unix$DISPLAY -v /tmp/.X11-unix:/tmp/.X11-unix shaoguangleo/ubuntu-psrchive# or$ docker run -it -e DISPLAY=unix$DISPLAY -v /tmp/.X11-unix:/tmp/.X11-unix shaoguangleo/centos-psrchive

如果希望体验一下源码安装，安装如下所示，配置参考[ASTROSOFT_CONFIG][astrosoft_config]：
$ source astrosoft_config.sh$ git clone $PSRCHIVE_WEBSITE psrchive_src$ source $ASTROSOFT/start_tempo2.rc$ source $ASTROSOFT/start_pgplot.rc$ source $ASTROSOFT/start_psrcat.rc$ export PSRCHIVE=$ASTROSOFT/psrchive$ export PATH=$PATH:$PSRCHIVE/bin$ export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$ASTROSOFT/epsic/lib$ cd psrchive_src $ ./packages/epsic.csh$ ./bootstrap$ ./configure --prefix=$ASTROSOFT/psrchive --with-cfitsio-dir=$ASTROSOFT/cfitsio --enable-shared CFLAGS=-fPIC FFLAGS=-fPIC$ make  $ make install$ make clean

]]></content>
      <categories>
        <category>射电天文</category>
      </categories>
      <tags>
        <tag>AstroSoft</tag>
        <tag>天文</tag>
        <tag>射电</tag>
        <tag>docker</tag>
        <tag>pulsar</tag>
        <tag>PSRCHIVE</tag>
        <tag>tempo2</tag>
        <tag>psrchive</tag>
        <tag>psrcat</tag>
      </tags>
  </entry>
  <entry>
    <title>python-casacore  installation</title>
    <url>/2019/01/19/radio-astronomy-install-python-casacore/</url>
    <content><![CDATA[简介python-casacore是casacore的python绑定。
在安装这个之前，需要先行安装casacore。
安装二进制安装$ pip install python-casacore

Debian/Ubuntu$ sudo apt-get install python-casacore

Kern此处为使用Ubuntu LTS系统的
$ sudo apt-get install software-properties-common$ sudo add-apt-repository ppa:kernsuite/kern-5$ sudo apt-get update$ sudo apt-get install python-casacore

MacOSXOn Macs, you may need to create an /etc/sysctl.conf filePut in it the following lines
重启后可以使用 sysctl kern.sysv来查看状态。
代码参考 https://www.github.com/shaoguangleo/radio_astronomy
]]></content>
      <categories>
        <category>射电天文</category>
      </categories>
      <tags>
        <tag>astronomy</tag>
        <tag>AstroSoft</tag>
        <tag>天文</tag>
        <tag>射电</tag>
        <tag>radio</tag>
        <tag>radio astronomy</tag>
      </tags>
  </entry>
  <entry>
    <title>SExtractor installation</title>
    <url>/2020/04/03/radio-astronomy-install-sextractor/</url>
    <content><![CDATA[SExtractor 安装步骤下载:  http://www.astromatic.net/software/sextractor
http://www.astromatic.net/download/sextractor/sextractor-2.19.5.tar.gz
需要安装PGPLOT、WCSLIB和CFITSIO
tar zxvf sextractor-2.19.5.tar.gzcd sextractor-2.19.5./configure --prefix=/where/you/want/installmakemake libmake cleanmake install
]]></content>
      <categories>
        <category>射电天文</category>
      </categories>
      <tags>
        <tag>astronomy</tag>
        <tag>AstroSoft</tag>
        <tag>天文</tag>
        <tag>射电</tag>
        <tag>radio</tag>
        <tag>radio astronomy</tag>
        <tag>sextractor</tag>
      </tags>
  </entry>
  <entry>
    <title>swspec installation</title>
    <url>/2021/02/02/radio-astronomy-install-swspec/</url>
    <content><![CDATA[swspec安装步骤下载:  https://github.com/gofrito/swspec
# 首先安装依赖Intel IPP# 比如路径为：/opt/intel/ipp/6.0.1.071/em64t# 还需要安装Plplot# 下载$ git clone https://github.com/gofrito/swspec$ cd swspec$ chmod +x mark5access/build.sh$ make# 需要root账户
]]></content>
      <categories>
        <category>射电天文</category>
        <category>天文</category>
        <category>射电</category>
      </categories>
      <tags>
        <tag>astronomy</tag>
        <tag>AstroSoft</tag>
        <tag>radio</tag>
        <tag>radio astronomy</tag>
        <tag>swspec</tag>
      </tags>
  </entry>
  <entry>
    <title>AstroSoft 安装 Tempo</title>
    <url>/2015/01/24/radio-astronomy-install-tempo/</url>
    <content><![CDATA[如何安装Tempo  – how to install Tempo如果只是使用，那么可以使用下面一个命令来获取Tempo的运行环境(需要安装docker)：
$ docker run -it shaoguangleo/ubuntu-tempo# or$ docker run -it shaoguangleo/centos-tempo

如果希望运行图形界面，运行下述命令：
$ docker run -it -e DISPLAY=unix$DISPLAY -v /tmp/.X11-unix:/tmp/.X11-unix shaoguangleo/ubuntu-tempo# or$ docker run -it -e DISPLAY=unix$DISPLAY -v /tmp/.X11-unix:/tmp/.X11-unix shaoguangleo/centos-tempo

如果希望体验一下Tempo，安装如下所示，配置参考[ASTROSOFT_CONFIG][astrosoft_config]：
$ tar zxvf tempo.tar.gz$ cd tempo$ ./prepare$ ./configure --prefix=/usr/local/tempo$ make$ make install$ cp -rv clock ephem tzpar util /usr/local/tempo$ cp tempo.hlp /usr/local/tempo$ cp obsys.dat /usr/local/tempo$ echo "export PATH=$PATH:/usr/local/tempo/bin" &gt;&gt; ~/.bashrc$ echo "export TEMPO=/usr/local/tempo" &gt;&gt; ~/.bashrc$ echo "export CLKDIR=/usr/local/tempo/clock" &gt;&gt; ~/.bashrc$ echo "export PARDIR=/usr/local/tempo/tzpar" &gt;&gt; ~/.bashrc$ echo "export EPHDIR=/usr/local/tempo/ephem" &gt;&gt; ~/.bashrc$ echo "export OBSYS=/usr/local/tempo/obsys.dat" &gt;&gt; ~/.bashrc

]]></content>
      <categories>
        <category>射电天文</category>
      </categories>
      <tags>
        <tag>AstroSoft</tag>
        <tag>docker</tag>
        <tag>configure</tag>
        <tag>PATH</tag>
        <tag>pulsar</tag>
        <tag>Tempo</tag>
        <tag>tempo</tag>
        <tag>CLKDIR</tag>
        <tag>PARDIR</tag>
        <tag>EPHDIR</tag>
        <tag>OBSYS</tag>
      </tags>
  </entry>
  <entry>
    <title>AstroSoft 安装 Tempo2</title>
    <url>/2015/01/24/radio-astronomy-install-tempo2/</url>
    <content><![CDATA[如何安装Tempo2  – how to install Tempo2如果只是使用，那么可以使用下面一个命令来获取Tempo的运行环境(需要安装docker)：
$ docker run -it shaoguangleo/ubuntu-tempo2# or$ docker run -it shaoguangleo/centos-tempo2

如果希望运行图形界面，运行下述命令，配置参考[ASTROSOFT_CONFIG][astrosoft_config]：
$ docker run -it -e DISPLAY=unix$DISPLAY -v /tmp/.X11-unix:/tmp/.X11-unix shaoguangleo/ubuntu-tempo2# or$ docker run -it -e DISPLAY=unix$DISPLAY -v /tmp/.X11-unix:/tmp/.X11-unix shaoguangleo/centos-tempo2

如果希望体验一下Tempo2，安装如下所示：
$ source astrosoft_config.sh$ git clone $TEMPO2_WEBSITE tempo2_src$ cd tempo2_src$ ./bootstrap$ cp -r T2runtime $ASTROSOFT/tempo2/$ export TEMPO2=$ASTROSOFT/tempo2$ echo "export TEMPO2=$ASTROSOFT/tempo2" &gt;&gt; ~/.bashrc$ ./configure --prefix=$ASTROSOFT/tempo2$ make$ make install$ make plugins$ make plugins-install#make temponest-instal

]]></content>
      <categories>
        <category>射电天文</category>
      </categories>
      <tags>
        <tag>AstroSoft</tag>
        <tag>docker</tag>
        <tag>pulsar</tag>
        <tag>tempo2</tag>
      </tags>
  </entry>
  <entry>
    <title>aips 初步安装与尝试</title>
    <url>/2011/01/26/radio_astronomy_aips_install_cont/</url>
    <content><![CDATA[aips初步安装与尝试最近准备开始处理一些VLA观测的数据，于是装了aips。本身aips的安装十分简单，到NRAO网站上下载一个安装脚本&nbsp;ftp://ftp.aoc.nrao.edu/pub/software/aips/31DEC10/install.pl&nbsp;
[XXX@XXX]$&nbsp;perl install.pl -n&nbsp;

(切记，这里一定要加上-n参数，如果你自己下下来一个tar包安装，就等着欲哭无泪吧。哈哈。^_^，经验之谈)安装就自动进行了，过程中选择一些目录（比如，主目录），基本不需要改什么东西。&nbsp;装完了在主目录里会有一个脚本LOGIN.SH，运行一下&nbsp;
[XXX@XXX]$ . LOGIN.SH&nbsp;
然后就可以用aips了。（不过我遇到的问题是index不能生成，不晓得怎么回事？？）&nbsp;
[XXX@XXX]$ aips&nbsp;
但是还是有一些问题，我迷糊了好几天，终于在NRAO的网站上找到一点信息&nbsp;http://www.aips.nrao.edu/aipsmgr/&nbsp;我遇到的问题和tape server有关，我按照上面网页上说的在/etc/services里加了几行内容
sssin           5000/tcp        SSSIN      # AIPS TV serverssslock         5002/tcp        SSSLOCK    # AIPS TV Lockmsgserv         5008/tcp        MSGSERV    # AIPS Message Servertekserv         5009/tcp        TEKSERV    # AIPS TekServeraipsmt0         5010/tcp        AIPSMT0    # AIPS remote FITS disk accessaipsmt1         5011/tcp        AIPSMT1    # AIPS remote tape 1aipsmt2         5012/tcp        AIPSMT2    # AIPS remote tape 2aipsmt3         5013/tcp        AIPSMT3aipsmt4         5014/tcp        AIPSMT4aipsmt5         5015/tcp        AIPSMT5aipsmt6         5016/tcp        AIPSMT6aipsmt7         5017/tcp        AIPSMT7
然后就正常了。后来在另外一台机器上也装了aips，但是老是出错。后来想明白，这个机器上装了不只一个aips（另一个是管理员装的），我用了其中的一个（管理员装的），但是把数据放在了另一个aips对应的文件夹（我自己装的）里，于是就死活找不到文件。这个错误太低级了，但是也算是找到并改正了。&nbsp;关于如何开始使用aips，网上有两个简单的教程不错(这两个都有找到)&nbsp;http://www-astro.physics.ox.ac.uk/~hrk/AIPS_TUTORIAL/HRK_AIPS_1.html
http://veraserver.mtk.nao.ac.jp/VERA/kurayama/WinterSchool/aips2.htm
参考 http://blog.sciencenet.cn/blog-117333-328076.html代码参考 https://www.github.com/shaoguangleo/radio_astronomy
]]></content>
      <categories>
        <category>射电天文</category>
        <category>天文</category>
        <category>射电</category>
      </categories>
      <tags>
        <tag>astronomy</tag>
        <tag>AstroSoft</tag>
        <tag>radio</tag>
        <tag>radio astronomy</tag>
        <tag>difmap</tag>
      </tags>
  </entry>
  <entry>
    <title>Difmap Introduction</title>
    <url>/2016/04/03/radio_astronomy_difmap_introduction/</url>
    <content><![CDATA[引言Difmap是一个强有力的处理多维数组成像的程序。Difmap起初是为了处理VLBI连续谱数据，后来开始处理VLA数据集。DIFMAP通过使用现代计算机日益增加的RAM容量来最小化加载数据和重构模型所花费的时间。这个手册会带你畅游DIFMAP的基本操作，来进行CLEAN及自校准你的数据。
所有的测试数据位于/home/share/data/difmap中，请拷贝到自己的文件夹进行操作。
代码参考 https://www.github.com/shaoguangleo/radio_astronomy
]]></content>
      <categories>
        <category>射电天文</category>
        <category>天文</category>
        <category>射电</category>
      </categories>
      <tags>
        <tag>astronomy</tag>
        <tag>radio</tag>
        <tag>radio astronomy</tag>
        <tag>difmap</tag>
      </tags>
  </entry>
  <entry>
    <title>Difmap 载入数据</title>
    <url>/2016/04/03/radio_astronomy_difmap_load_data/</url>
    <content><![CDATA[载入数据现在我们已经在Difmap环境中了，将有一个如下的提示符：
0&gt;

现在我们开始输入第一个命令，用于载入数据。
0&gt; observe YOUR_DATA

提示：这里可以简单地输入obs然后使用Tab即可补全剩余的命令。这项技术有助于在整个Difmap的使用过程中节省宝贵的时间。随时随地掌握这些技巧，可以提升软件使用体验^_^。此时应该可以看到下述输出了。
Reading UV FITS file: 3C219.L(A.butDefinitelyB).postProc.uvfAN table 1: 2454 integrations on 406 of 406 possible baselines.Apparent sampling: 0.732128 visibilities/baseline/integration-bin.Found source: 3C219There are 2 IFs, and a total of 2 channels: IF  Channel    Frequency  Freq offset  Number of   Overall IF      origin    at origin  per channel   channels    bandwidth ------------------------------------------------------------- (Hz) 01        1    1.385e+09      2.5e+07          1      2.5e+07 02        2    1.665e+09      2.5e+07          1      2.5e+07Polarization(s): RR LL RL LRRead 307 lines of history.Reading 5835496 visibilities.

该命令详细列出了源的相关信息。检查所有的Ifs，通道、频率等都是正确的。如果出现了诸如“”的错误，你可能需要返回AIPS来确定输出了正确的数据。如果需要得到更多的信息，可以输入下述命令：
0&gt; headerUV FITS miscellaneous header keyword values: OBSERVER = "AC149" DATE-OBS = "1986-05-18" ORIGIN   = "AIPSlocalhost    LOCALHOST            31DEC11" TELESCOP = "VLA" INSTRUME = "VLA" EQUINOX  = 2000.00Sub-array 1 contains:406 baselines   29 stations2454 integrations    4 scans Station  name               X (m)            Y (m)             Z(m)   01     VLA:_N28      -1.600864e+06    -5.041770e+06     3.557965e+06   02     VLA:_W28      -1.604866e+06    -5.046527e+06     3.552962e+06   03     VLA:_N16      -1.601062e+06    -5.041898e+06     3.556058e+06   04     VLA:_W24      -1.604009e+06    -5.045468e+06     3.553404e+06   05     VLA:_W12      -1.602045e+06    -5.043040e+06     3.554428e+06   06     VLA:_W04      -1.601316e+06    -5.042139e+06     3.554808e+06   07     VLA:_W20      -1.603250e+06    -5.044530e+06     3.553798e+06   08     VLA:_W36      -1.606842e+06    -5.048973e+06     3.551913e+06   09     VLA:_W08      -1.601614e+06    -5.042508e+06     3.554652e+06   10     VLA:_E32      -1.597053e+06    -5.036606e+06     3.553059e+06   11     VLA:_OUT      -1.601185e+06    -5.041978e+06     3.554876e+06   12     VLA:_N36      -1.600691e+06    -5.041658e+06     3.559632e+06   13     VLA:_E36      -1.596128e+06    -5.035403e+06     3.552652e+06   14     VLA:_W16      -1.602593e+06    -5.043718e+06     3.554141e+0615     VLA:_N32      -1.600781e+06    -5.041716e+06     3.558761e+06   16     VLA:_N20      -1.601005e+06    -5.041861e+06     3.556610e+06   17     VLA:_E12      -1.600416e+06    -5.040979e+06     3.554536e+06   18     VLA:_E20      -1.599341e+06    -5.039580e+06     3.554065e+06   19     VLA:_E28      -1.597900e+06    -5.037707e+06     3.553432e+06   20     VLA:_E24      -1.598663e+06    -5.038699e+06     3.553767e+06   21     VLA:_N08      -1.601148e+06    -5.041953e+06     3.555236e+06   22     VLA:_N04      -1.601174e+06    -5.041970e+06     3.554987e+06   23     VLA:_E08      -1.600802e+06    -5.041479e+06     3.554706e+06   24     VLA:_E16      -1.599926e+06    -5.040341e+06     3.554320e+06   25     VLA:_E04      -1.601069e+06    -5.041826e+06     3.554825e+06   26     VLA:_N12      -1.601110e+06    -5.041929e+06     3.555597e+06   27     VLA:_N24      -1.600930e+06    -5.041813e+06     3.557330e+06   28     VLA:_W32      -1.605809e+06    -5.047694e+06     3.552459e+06   29     VPT:_OUT      -1.601185e+06    -5.041978e+06     3.554876e+06There are 2 IFs, and a total of 2 channels: IF  Channel    Frequency  Freq offset  Number of   Overall IF      origin    at origin  per channel   channels    bandwidth ------------------------------------------------------------- (Hz) 01        1    1.385e+09      2.5e+07          1      2.5e+07 02        2    1.665e+09      2.5e+07          1      2.5e+07Source parameters: Source: 	 3C219 RA     = 	 09 21 08.548 (2000.0)	 09 20 14.260 (apparent) DEC    = 	+45 38 57.920        	+45 42 30.877Antenna pointing center: OBSRA  = 	 09 21 08.548 (2000.0) OBSDEC = 	+45 38 57.920Data characteristics: Recorded units are UNCALIB. Recorded polarizations: RR LL RL LR Phases are rotated 0 mas East and 0 mas North. UVW coordinates are rotated by 0 degrees clockwise. Scale factor applied to FITS data weights: 1 Coordinate projection: SINSummary of overall dimensions: 1 sub-arrays, 2 IFs, 2 channels, 2454 integrations 4 polarizations, and up to 406 baselines per sub-arrayTime related parameters: Reference date: 1986 day 249/00:00:00  (1986 Sep 06) Julian Date: 2446679.50, Epoch J1986.678 GAST at reference date: 22 59 10.041 Coherent integration time   = 0.0 sec Incoherent integration time = 0.0 sec Sum of scan durations = 26460 sec UT range: 249/09:51:21 to 249/23:30:22 Mean epoch:  JD 2446680.195 = J1986.680

此时在启动目录会生成一个log文件difmap.log，这个文件记录了你在DIFMAP交互环境中输入的所有命令。 It will also include selected output lines though they will be preceded by a ! in order to comment them out.这个log文件可以通过一种脚本的形式来使用，可以通过在交互命令中输入 @difmap.log来执行这个脚本。但需要注意的是这个脚本无法与PGPLOT进行交互，所以交互式的flagging都不会发生。所以要特别注意这一点。
The next step is to choose the Stokes parameter you are interested in:
0&gt; select i	Where i refers to the Stokes I parameter. You can select any Stokes parameter (e.g. select q or u) to work with.



















代码参考 https://www.github.com/shaoguangleo/radio_astronomy
]]></content>
      <categories>
        <category>射电天文</category>
        <category>天文</category>
        <category>射电</category>
      </categories>
      <tags>
        <tag>astronomy</tag>
        <tag>radio</tag>
        <tag>radio astronomy</tag>
        <tag>difmap</tag>
      </tags>
  </entry>
  <entry>
    <title>Difmap 启动</title>
    <url>/2016/04/03/radio_astronomy_difmap_startup/</url>
    <content><![CDATA[启动difmap服务器已经安装了Difmap2.4l版本，只需要在环境变量PATH中加入/usr/local/difmap即可，详细安装步骤可以参考DIFMAP安装手册。
安装好DIFMAP后，打开一个终端，然后进入到数据所在的目录。输入difmap即可得到如下提示信息：

TODO : Adding difmap startup terminal

这个示例我们使用源J1036+1326的C Band C Array的数据，This is from Project AT0205, Seg A, source TEX1033+137, taken on 7/20/97 with 370 seconds TOS.
代码参考 https://www.github.com/shaoguangleo/radio_astronomy
]]></content>
      <categories>
        <category>射电天文</category>
        <category>天文</category>
        <category>射电</category>
      </categories>
      <tags>
        <tag>astronomy</tag>
        <tag>radio</tag>
        <tag>radio astronomy</tag>
        <tag>difmap</tag>
      </tags>
  </entry>
  <entry>
    <title>AIPS 简略安装说明</title>
    <url>/2011/01/19/radio_astronomy_install_aips_simple/</url>
    <content><![CDATA[AIPS 简略安装说明下载脚本wget ftp://ftp.aoc.nrao.edu/pub/software/aips/31DEC23/install.plchmod +x install.pl

开始安装perl install.pl -n

其中需要注意的是：

安装脚本选择在~/aips/中
group owenrship 设置为 prjg9600014
Site name 为 SHAO
Data Area 设置为 ： /groups/vlbi_group/home/share/aips/data/
Printer 设为为 A4

安装完成后添加下列信息到/etc/service
sssin           5000/tcp        SSSIN      # AIPS TV serverssslock         5002/tcp        SSSLOCK    # AIPS TV Lockmsgserv         5008/tcp        MSGSERV    # AIPS Message Servertekserv         5009/tcp        TEKSERV    # AIPS TekServeraipsmt0         5010/tcp        AIPSMT0    # AIPS remote FITS disk accessaipsmt1         5011/tcp        AIPSMT1    # AIPS remote tape 1aipsmt2         5012/tcp        AIPSMT2    # AIPS remote tape 2


代码参考 https://www.github.com/shaoguangleo/radio_astronomy
]]></content>
      <categories>
        <category>射电天文</category>
      </categories>
      <tags>
        <tag>astronomy</tag>
        <tag>aips</tag>
        <tag>天文</tag>
        <tag>射电</tag>
        <tag>radio</tag>
        <tag>radio astronomy</tag>
      </tags>
  </entry>
  <entry>
    <title>aips 详细安装攻略</title>
    <url>/2011/01/19/radio_astronomy_install_aips/</url>
    <content><![CDATA[AIPS 详细安装攻略下载脚本# 下载安装脚本wget ftp://ftp.aoc.nrao.edu/pub/software/aips/31DEC23/install.pl# 更改可执行权限chmod +x install.pl

开始安装perl install.pl -n # 二进制安装# 选择cnSRC group，对于实例来讲设置为prjg9600014

具体安装步骤AIPS安装步骤 黑体部分特别注意
预备工作We assume that you have followed the instructions and retrieved the Latest version of AIPS (or the frozen, released version). This means you have:

Downloaded the latest version of the Install Wizard (install.pl);
If you are doing a binary installation from a CD, downloaded the latest version of the CD set-up procedure (CDSETUP) (Both of these are on the CD, so the download is only a precaution.);
   Binary installations are offered for MacIntosh PPC computers (using the IBM xlf compiler), MacIntosh Intel computers (using the Intel compiler), Solaris Ultra computers (using the SUNWspro compiler), and Linux computers (using the Intel compiler). These are also available from CDrom for the frozen version of AIPS. If you are not doing a binary installation, you must have downloaded the “tarball” (.tar.gz) file for the release;
   Placed install.pl and the tar file (if appropriate) or CDSETUP in what will be your AIPS_ROOT area.
   Moved any old $HOME/.AIPSRC to a new name for reference. An old file may confuse the new installation.
   Alternatively, you may edit the old $HOME/.AIPSRC for use by the new installation. Delete the lines showing DOWNLOADED and UNPACKED and correct the CCOMOPT line to refer to the new version rather than the old one.You should also make sure you have perl installed (it is, in /usr/bin on Linux systems) as that is a pre-requisite of running the wizard.If you are installing from CDrom, you should now transfer to the guide to CDSETUP.

进行二进制安装而不是解压文本并编译它，请在调用中添加-n选项。如果对于安装过程超级感兴趣，可以加上-d选项进入详细模式（并在菜单之间禁用清除屏幕功能）。
How the Menus workThe “install wizard” is really just a simple, albeit large, perl script that walks you through a series of menus. This is not a “GUI” or graphical wizard; it only uses text, and can be run in any terminal emulator (or even on an old fashioned VT100 if you have one). At each menu, the screen is cleared, some brief explanatory text will appear at the top of the screen, and a menu or other question will be presented. You then enter whatever text is appropriate and press  or  to continue.At each menu prompt, you will have several universal options:-	Back to go back to the previous menu;-	Quit to exit immediately-	On most menus/queries, pressing  will cause a default sensible action to occur.In addition, you can use the interrupt () sequence to stop the install at any time. If you do, or if you use the Quit option, the details of what you have already entered will be saved. This information is stored in a /.AIPSRC file (the tilde “/“ means the file is in your login area) and is re-read on subsequent invocations of the install wizard. The .AIPSRC file is plain text, with keyword=value pairs so it is easy to understand.The remainder of this document will describe – in more detail than the script itself does – what is occuring at each of the menus, and what options you have. Note that menus 1, 2, 3, and 10 will be skipped when doing a binary installation from the network or from CD.
Screen 0: INTRODUCTIONBefore it does anything, the script looks around for a “tarball”, i.e., the 31DEC03.tar.gz file. It checks the current working directory, the AIPS_ROOT area if this is defined, and finally if these fail, your home directory. Then it shows you the welcome screen:
Screen 0: INTRODUCTIONWelcome to the new AIPS Install Wizard (AipsWiz)!It will do the following:

Look for (and/or download) the ‘tarball’ for 31DEC03
Unpack it wherever you specify
Ask you for various settings through a set of menus
Review your settings, and
Do the installation with no further input needed.

Things can go wrong (!) so this procedure is not perfect,but it saves state in a file .AIPSRC in your home area.So you can easily restart an interrupted install attempt,without re-entering all your settings.  You can also goback a screen by typing ‘B’ to most prompts, or youcan Quit at any menu by entering ‘Q’.
     [You may also type B for back, or Q to Quit]

AipsWiz: ===&gt; Press  or  to get started:
回车即可开始安装。
只要确保你在正确的目录下,目前我的目录为~/aips/，且有31DEC23.tar.gz文件即可。如果没有，脚本会提示你下载。
If you have run the wizard before from this account, and have let it unpack the tarball, you will get a different menu:## Screen 0: Re-IntroductionWelcome back to the AIPS Install Wizard (AipsWiz).It would appear you’ve been here before.
If you REALLY want to start over, you may want to removethe .AIPSRC file in this account’s home directory.
Otherwise, you can skip forward to a specific screen byentering its number at the prompt.  The default actionis to simply start at screen 1.  Screens are:

Optionally download 31DEC03 tarball

Confirm that tarball is correct

Choose AIPS_ROOT, optionally unpack tarball

Group ownership, group write enable/disable

Site name, Architecture

Additional hosts

Data area definition

Printer setup

Tape drives

Choose Unix or INET services (for TV, etc)

Advanced settings

Final check before doing the install
   [You may also type B for back, or Q to Quit]


AipsWiz: ===&gt; Press  or , or enter a screen number:So if you interrupted a previous install attempt at, say, the adding additional hosts step, you can go directly to that screen and continue as if nothing had happened.
Screen 1: DOWNLOADScreen 1: DOWNLOADFound a ‘tarball’ /opt/aips/31DEC03.tar.gz         ………………Dated 2003.01.24:05:22.42 (UT)         ……… downloaded on 2003.01.24:18:34.24 (UT)         ……. current time is 2003.01.24:18:49.26 (UT)
You can:
   (G) Get a newer copy from NRAO’s ftp site,       (the file is generated nightly)   (S) Skip the download and use the existing tarball, or   (Q) Quit now.
NOTE: if by some chance the automatic ftp fetch fails, you      may want to fetch it yourself by hand, from
  ftp.aoc.nrao.edu/pub/software//aips/31DEC03/31DEC03.tar.gz


     [You may also type B for back, or Q to Quit]

AipsWiz: ===&gt; What do you want to do? [default S]What goes on behind the scenes here is some exploration: looking for the “tarball”, and checking the .AIPSRC file for when it thinks this was downloaded (note: if the wizard finds the tarball but does not download it itself, it applies the “now” date to the “downloaded” time).Most of the time you will simply want to use the Skip option; it’s usually only worth getting a new tarball if the one you have is more than a month or two out of date. Let’s assume that you’ve skipped ahead.
Screen 2: CONFIRMATIONProceeding with 31DEC03 install/upgrade.  Please check:
-rw-r–r–    1 aipsmgr  aipspgmr 46290244 Jan 24 00:22 /opt/aips/31DEC03.tar.gz
that this is the file you want (should be &gt;30 Mbytes)
     [You may also type B for back, or Q to Quit]

AipsWiz: ===&gt; Proceed [Y/N, default Y]As you can see, this is just a confirmation step that gives you yet another chance to bail out if necessary. Let’s assume you proceed.
Screen 3: Where to unpackPlease tell me where to unpack the 31DEC03 version of AIPS(This is the so-called AIPS_ROOT area).
The default is /home/aips/AIPS
     [You may also type B for back, or Q to Quit]

AipsWiz: ===&gt; AIPS Root area: /opt/aipsNOTE WELL: This screen will set where you want the AIPS_ROOT area to be. It defaults to the current directory. The example above shows the user entering (in red) the desired area.You may want to remove any existing TEXT area in the specified directory before proceeding. Once you enter the AIPS_ROOT value, the wizard proceeds to unpack the tarball with this dialog:AipsWiz: Unpacking the ‘tarball’ /home/myname/tmp/31DEC03.tar.gzAipsWiz: in the /opt/aips directoryAipsWiz: This may generate some errors if you are overwriting, butAipsWiz: these (‘Cannot unlink: directory not empty’) are benign.AipsWiz: (printing a dot every 100 files for your amusement…………………………………………………….
AipsWiz: Unpacking apparently worked (total of 5769 files)AipsWiz: ==&gt; Press  to continue::The “dot printing” will not be at a uniform speed, as of course the size of each chunk of 100 files will vary. It will be slow near the end as the TEXT area has some very large files therein. If you have an existing TEXT area, you’ll likely get the “Cannot unlink” error mentioned in the menu.
Screen 4: Group OwnershipIf more than one account is going to be using AIPS, you shouldselect a ‘Unix group’ for these accounts.  This can,but need not be, their primary group.
     [You may also type B for back, or Q to Quit]

AipsWiz: ===&gt; What group should be used for AIPS? [aipspgmr]It’s important that you set your AIPS site up so that everyone who needs access to it can use it. As read/write privilege is required on some (but not all) of the system files, you need to decide now which mode of operation you are going to use:•	Either disallow “group write” and only allow “you” access; or•	Allow “group write” and set up a Unix group for AIPS users.Here “you” refers to the account you’re using to install AIPS. So the first thing to decide is whether you want to allow others to run your AIPS installation, and if so, you should have your systems administrator set up a Unix group for them. Here at NRAO we call this group aipsuser, but you can call it anything you want. Whatever name you choose, you should enter here. If you do not plan on allowing others access to your AIPS environment, just press .This menu is halfway smart: if you enter “foobar”, it will check if “foobar” is one of the groups that you are in (Unix users have one primary group and can be in many secondary groups as specified in /etc/group or the NIS or LDAP group map). If you enter a bad group, it will show you a list of valid groups, pause for a few seconds, then repaint the menu and ask again for a group name.Once you enter a valid group, a second menu appears:
在这里选择 prjg9600014
Screen 4b: Group WriteIf more than one account will use AIPS, and you are usinga group (aipsuser) to permit filesharing, you should also allowthis group write access to certain AIPS files.
     [You may also type B for back, or Q to Quit]

AipsWiz: ===&gt; Allow aipsuser to have write access? [YES]Don’t panic if you get here and realize you meant to specify a different group. The wizard does nothing (other than unpack the tarball) with your new AIPS installation until after screen 12, so you can easily go back, interrupt, restart, etc. until you are happy with the settings. So if you got the group wrong, just type Back now and you’ll be at Screen 4 again (not 4b).Othewise, just enter Yes or No, depending on your needs, and proceed.
Screen 5: Site NamePlease enter a single word to describe your AIPS site.This may be used as a directory name.  Example: at NRAO we usenames such as NRAOCV, NRAOAOC, etc.
     [You may also type B for back, or Q to Quit]

AipsWiz: ===&gt; Your site name: [required, no default]The “Site Name” is used by AIPS for several purposes, most of which are associated with allowing multiple computers run AIPS from the same area on a shared (NFS) disk. All AIPS machines in a given “site” have to be the same endian flavour (byte order), so you can mix and match Intel/Linux, Intel/Solaris, Alpha/Linux, Alpha/OSF1, and Max/Intel systems in a single site as these are all little-endian architecture. Likewise you can mix and match Sparc/Solaris, HP-UX, SGI, IBM RS/6000, and Mac PPC systems in a single site as they are all big endian. But you cannot have both little and big endian systems in the same AIPS site.It’s really an advanced topic beyond the scope of this document, but you can have different endian systems sharing the same AIPS_ROOT area. The trick is to assign each group of endian systems a different SITE name.Anyway, you should enter a site name like NRAOCV here. Choose a single word that best describes your installation. Once you do this, the wizard will now try to figure out your architecture by looking at various clues in its environment:
这里定义为 SHAO
Screen 5a: Site type:If your site consists of a single portable computerwhich may get different names at different times,it is best to force the name for AIPS to LOCALHOST.
     [You may also type B for back, or Q to Quit]

AipsWiz: ===&gt; If you want this, enter Y or y [N]AIPS depends on the computer’s name since it often runs in environments with 10’s of computers all sharing a single AIPS installation. The name is used to find the architecture and site name from HOSTS.LIST, to select the data areas to include from DADEVS.LIST, and to find the control files for that computer. Laptop computers often do not have a fixed name. Instead thay are assigned a dynamic name each time they are plugged in to the local area network. In this case, it is better to have AIPS use a a fixed name (LOCALHOST) for the computer rather than the changing name (returned by uname -n). If you are installing AIPS for use on a single computer which might have its name change, enter Y or y at this point. The LOGIN.SH and LOGIN.CSH files will be changed to reflect this choice and the computer and its data areas will be found under the name LOCALHOST.
Screen 5b: Architecture ConfirmationIf this is correct, press RETURN or ENTER.If not, enter the correct architecture (or ? for a list)
     [You may also type B for back, or Q to Quit]

AipsWiz: ===&gt; Enter the architecture for this system [LINUX]The script is pretty good about figuring this out, so you’ll likely just have to press  here. If by some chance you enter something silly like SOL for a Linux machine, this will be stored in the .AIPSRC file and will come back to haunt you later! The known architectures are: LINUX, AXLINUX for Alpha Linux, ALPHA for Alpha OSF1 (Tru64) systems,SOL for older Suns, SUL for Solaris on Sparc Ultras, SOL86 for Solaris on Intel, HP for older HP systems running HP-UX, HP2 for newer HP’s, SGI for SGI systems running Irix, MACPPC for MacIntosh computers with the PPC G3, G4, and G5 chips, and MACINT for MacIntosh computers with the Intel chips.A future feature of the wizard will be consistency checking of the specified architecture against what it thinks is right, and a dialog to query the user in an “are you sure?” manner.
Screen 6:Additional HostsScreen 6: Additional hosts if anyYou may configure your installation so it runs on many systems,sharing the AIPS ROOT area via NFS.  The list of host(s) is now:
ORANGUTAN
Any new hosts will initially be set to arch=LINUX, but you canchange this by editing HOSTS.LIST in /home/aips/tmpwhen the install is finished.
     [You may also type B for back, or Q to Quit]

AipsWiz: ===&gt; Enter new hosts (no commas!) or ORANGUTAN to reset:This menu is pretty simple. If you are only installing AIPS on a single system, just press  to continue to the next screen, as there’s nothing to do here. If you intend on allowing several other hosts to your AIPS installation, you can pre-populate the HOSTS.LIST configuration file (kept in your AIPS_ROOT area) right here.
Screen 7: User Data AreasAIPS Manages the astronomical data users will read and write internally in “catalogs” which are stored in “disks”. In reality, each “disk” is simply a directory somewhere in the Unix file system hierarchy. These are specified in two or maybe three configuration files, all of which are kept in the $NET0 area (which is $AIPS_ROOT/DA00/). The purpose of this menu is to provide an easier, faster way of setting these files up.
Screen 7: User Data Areas
At least one data area needs to be defined for AIPS user data.It is important that the host name in caps appear in the data areaname.  Currently these area(s) are defined:
  (no data areas have been defined yet)
You can add to this list after installing by editing the two filesDADEVS.LIST and NETSP in the /opt/aips/DA00/ directory.
Please enter (additional) data area(s) now as a space-separatedlist, or the word RESET to re-set the list.
   (If you want to use symlinks, use the notation
   actual_directory_location:symbolic_link_location

instead of a simple directory location.)

The suggested data area is /opt/aips/DATA/ORANGUTAN_1
     [You may also type B for back, or Q to Quit]

AipsWiz: ===&gt; Data Areas:
这里设置为 /groups/vlbi_group/home/share/aips/data/
OK, there’s a lot to digest here, mainly because the menu tries to be both concise and flexible at the same time. Suppose you just wanted to add one area, and you like the suggested value. You can either type it in, or cut/paste it and then press . That’s it.When AIPS starts up it reads the DADEVS.LIST file to decide which disk areas to include. It will include all required areas and any area which has the current host name (in capital letters) in the disk area name, e.g. /DATA/ORANGUTAN_1. Normally, one only wants to include disk data areas local to the current host. Required areas on another computer will slow everything down quite remarkably. Note that the data area may be something like $AIPS_ROOT/DATA/ORANGUTAN_1 on the server computer, so long as that file is a link file to a real data area on orangutan itself.If you want to add more than one area, just enter all the areas on one line separated by spaces. If you want to wipe out all the disks defined and start over, just enter the magic string RESET and press . Poof! The definitions are gone.Finally, if you want to do something more sophisticated, such as putting entries in the configuration files that refer to $AIPS_ROOT/DATA/ and have symbolic links there pointing to actual directories elsewhere, you can do that. Just enter a series of areas separated by spaces, with each area actually being in the form mentioned, with a colon (:) separating the actual location from the symbolic link’s name. This feature is pretty esoteric and probably few people will want to use it.Here’s an example of what you might add:AipsWiz: ===&gt; Data Areas: /opt/aips/DATA/MINE_1 /tmp:/opt/aips/DATA/MINE_2This example shows adding two data areas. The first is a simple directory, while the second is a symbolic link pointing to /tmp but that will appear to the AIPS user as /opt/aips/DATA/MINE_2. We don’t recommend using /tmp to store AIPS data other than as a scratch disk; it’s just shown here as a nice concise example.Remember that you can always edit the text files such as $AIPS_ROOT/HOSTS.LIST, $NET0/DADEVS.LIST, $NET0/NETSP, $NET0/PRDEVS.LIST etc. later in order to add more computers running aips, more disk areas and printers, etc. You may find the old Postscript installation guide of use in this regard. In particular, it devotes some space to SYSETUP and other tools used to install additional computers, disks, and the like.
Screen 8: PrintersOne of the things you’ll surely do in AIPS is generate printout. AIPS will allow you to define many printers, and the users refer to them by number. The available printers will be presented to the user as a menu when they start AIPS itself up, and it’s up to you, the intrepid AIPS installer, to configure sensible AIPS names for these printers. This is fairly easy so don’t panic.This screen will do two things: first, get the printers and their types; and second, figure what size paper you’ll be using.
Screen 8: PrintersYou may define several printers for use with AIPS.These will appear on startup as numbered choices to the userAt least one printer must be defined.  Currently defined:
  (no printers are defined yet)
  Paper Format: A
You can modify printer definitions after the install byediting the file /home/aips/tmp/DA00/PRDEVS.LIST .
Please indicate whether you want to

add (N)ew printers
(D)iscover your system’s printers (may not work),
(A)ccept the current settings as is, or
(R)eset to clear the list.

(Paper format - A or A4 - will come next)
     [You may also type B for back, or Q to Quit]

AipsWiz: ===&gt; Your choice (default: Accept):The “(D)iscovery” option is one you’ll probably want to try. It’s actually pretty good about trying things, including looking at printcap and lpstat information. It will balk somewhat, however, if it finds more than 15 printers and revert to the “(N)ew” mode instead.Suppose we find that there are 34 printers available, and we only want to add three of them to the AIPS printer configuration. Here’s what that session might look like:AipsWiz: Configuring 3 printers.  For each, you will be asked if youAipsWiz: want to configure AIPS to use it, its type, options, and aAipsWiz: description.  AIPS priner types are:
AipsWiz:   PS       Black-and-white PostScript printerAipsWiz:   COLOR    (or COLOUR) Color/Colour PostScrip printertAipsWiz:   TEXT     Plain text printers (including line printers)AipsWiz:   QMS      QUIC format (QMS [not QMS PS!], Talaris) printersAipsWiz:   PREVIEW  Screen Previewers, e.g. gv, ghostview, pageview
AipsWiz: And the valid AIPS printer options are:
AipsWiz:   NONE     (default), nothing special.AipsWiz:   DUP      Printer will print on both sides of the paperAipsWiz:   DEF      This will be the default AIPS printerAipsWiz:   BIG=nnn  Force use of this printer for jobs &gt; nnn lines
AipsWiz: If you want to specify multiple options for a printer,AipsWiz: separate them with commas (NO SPACES!)
AipsWiz: ==&gt; –Name (‘xxx’ in ‘lpr -Pxxx’) for printer 1: ps1AipsWiz: ==&gt;   Printer    type for ps1 (N to skip) [PS]:AipsWiz: ==&gt;   Printer options for ps1 (N to skip) [NONE]: DUPAipsWiz: ==&gt;   Description for ps1 (N to skip): Main printer (duplex)AipsWiz: ==&gt; –Name (‘xxx’ in ‘lpr -Pxxx’) for printer 2: ps2AipsWiz: ==&gt;   Printer    type for ps2 (N to skip) [PS]:AipsWiz: ==&gt;   Printer options for ps2 (N to skip) [NONE]: DUP,DEFAipsWiz: ==&gt;   Description for ps2(N to skip): 2nd floor printerAipsWiz: ==&gt; –Name (‘xxx’ in ‘lpr -Pxxx’) for printer 3: pscolorAipsWiz: ==&gt;   Printer    type for pscolor (N to skip) [PS]: COLORAipsWiz: ==&gt;   Printer options for pscolor (N to skip) [NONE]:AipsWiz: ==&gt;   Description for pscolor (N to skip): Color printerRight after entering your printer information, you will be asked:AipsWiz: ==&gt; Do your printer(s) use A or A4 paper? [A]:For reference, US “A” standard size paper is 8.5 by 11 inches, and the European and Australian standard “A4” size is about 8.25 x 11.75 inches.
Screen 9: Tape DrivesIf you use AIPS, you’ll almost certainly want it to read and write data to/from at least one type of tape drive. This is where you specify the details of the drives and set the device names (AIPS users refer to tapes by AIPS tape number).## Screen 9: Tape DrivesIf your network has any tape drives you would like to use for AIPS,you can specify those now.  You need to configure each tape drivemachine to run AIPS (or a subset of it).  Current definitions:
(no tape drives are defined yet)

You can add to this list after the install by editing TPDEVS.LISTin the /home/aips/tmp/DA00 area.Please indicate whether you want to
    add (N)ew tape drive(s)
    (D)iscover tape drives on ORANGUTAN (may not work)
    (A)ccept the current settings as is, or
    (R)eset to clear the list.

     [You may also type B for back, or Q to Quit]

AipsWiz: ===&gt; Your choice (default: Accept):The “(D)iscovery” option is limited and for the most part will “sniff” out SCSI tape drives on various platforms. On some (e.g., Linux) it will find files in /dev/ if they have been configured, even if you don’t have any physical drive attached (or even a SCSI card). For each one it finds, it asks you for a description of it, or you press “N” to skip and not include it. Here’s a typical dialog:AipsWiz: ===&gt; Your choice (default: Accept):D
AipsWiz: Found SCSI tape drive /dev/nst0AipsWiz: Found SCSI tape drive /dev/nst1AipsWiz: Found SCSI tape drive /dev/nst2AipsWiz: Found SCSI tape drive /dev/nst3AipsWiz: Found SCSI tape drive /dev/nst4AipsWiz: Found SCSI tape drive /dev/nst5AipsWiz: Found SCSI tape drive /dev/nst6AipsWiz: Found SCSI tape drive /dev/nst7AipsWiz: Found 8 possible tape drives on this host
AipsWiz: ==&gt; Description for nst0 (or N to skip): 4mm DDS-4 DATAipsWiz: ==&gt; Description for nst1 (or N to skip): NAipsWiz: ==&gt; Description for nst2 (or N to skip): NAipsWiz: ==&gt; Description for nst3 (or N to skip): NAipsWiz: ==&gt; Description for nst4 (or N to skip): NAipsWiz: ==&gt; Description for nst5 (or N to skip): NAipsWiz: ==&gt; Description for nst6 (or N to skip): NAipsWiz: ==&gt; Description for nst7 (or N to skip): N(Note: the text above has been shortened here for readability and clarity; the wizard actually spells out, e.g., Description for ORANGUTAN tape drive /dev/nst0).After this comes an important section. It’s long, and the screen occupies almost 40 lines, but you need to read and understand it. It affects who can access your AIPS resources over the network. Here is the screen:
Screen 9B: Tape Hosts
THIS IS IMPORTANT:  READ ME!
The TPMON daemons that are automatically started or restartedwith each AIPS session are servers that give remote systemsaccess to your local tape drives (TPMON2,3,…) and FITSdisk area (TPMON1).  There is a mechanism to restrict connectionsto a set of hosts and/or IP addresses.  You need to indicate whatremote system(s) if any are allowed to use your tapesand FITS disk area.  The default configuration is to ONLY allowyour local host (127.0.0.1).  The list of hosts and/or IP addressesis currently set to:

127.0.0.1


You can modify this list after the install by editing file TPHOSTSin the /home/aips/tmp/DA00 area.  Each line in thefile can be
    - an IP address, e.g. 192.33.115.11
    - a fully qualified domain name, e.g. orangutan.cv.nrao.edu,
    - a limited IP address wildcard, e.g. 192.33.115.\*, or
    - a limited domain name wildcard, e.g. \*.cv.nrao.edu.

Please indicate whether you want to
    add (N)ew entries
    (A)ccept the current settings as is, or
    (R)eset to the default.

     [You may also type B for back, or Q to Quit]

AipsWiz: ===&gt; Your choice (default: Accept):The default setting is the most secure, as it limits remote access to the local host. If you are in any doubt at all, use our default. The danger is in opening up your systems and networks too widely. System Administrators should refer to the next section for a brief discussion about TCP ports used by AIPS for additional security measures.
Unix/Internet service discussionAIPS uses “sockets” so the main AIPS engine can talk to the image display (called the “TV”), a lock daemon for the TV, a graphics display, message display, and remote TPMON tape servers. For all except the last, you have the choice of whether to use INET (network based) sockets, or UNIX (file based) sockets. This menu allows you to choose what the default will be; your users can always override this on the command line when they start AIPS itself.Between screens 9 and 10, install.pl does a quick check on whether some of the AIPS services are already defined, either in /etc/services, or in a NIS (YP) services map. It found they were, so no warning was issued. If you are going to be running AIPS on a single machine, and not accessing it over a network from other AIPS machines, then you may want to use UNIX sockets. Doing so means you don’t have to edit the services file or map, and it also allows AIPS users to have multiple TV’s on screen if they want. You must add tv=local to the aips command line every time you start AIPS. The default is always Inet sockets.For sysadmins, the TCP ports used by the TPMON tape/disk servers (daemons) are usually 5010 through 5017. In addition, if INET sockets are chosen in this menu, AIPS will use four ports in the range 5000-5009 as well. If you do not want remote AIPS access to your site, you may want to block these (or permit them to defined systems or networks) at your router or firewall.
增加以下内容到 /etc/services
sssin		5000/tcp	SSSIN		# AIPS TVssslock		5002/tcp	SSSLOCK		# AIPS TV Lockmsgserv		5008/tcp	MSGSERV		# AIPS Message Servertekserv		5009/tcp	TEKSERV		# AIPS TekServeraipsmt0		5010/tcp	AIPSMT0aipsmt1		5011/tcp	AIPSMT1aipsmt2		5012/tcp	AIPSMT2aipsmt3		5013/tcp	AIPSMT3aipsmt4		5014/tcp	AIPSMT4aipsmt5		5015/tcp	AIPSMT5aipsmt6		5016/tcp	AIPSMT6aipsmt7		5017/tcp	AIPSMT7

Screen 10: Advanced Settings
In most cases, you will simply want to scan through this screen and accept the defaults. This is a smorgasbord of options that covers all sorts of AIPS settings, but they are usually rather esoteric and not of much interest to the Astronomer who just wants to run the system and analyse their data. The location of an acceptable compiler (e.g. version 2.95.3 of gcc and g77) may force you to modify some of the defaults. Note that the .AIPSRC file retains this information; if you are installing a later release all will be known. Screen 10 is skipped for binary installations since you will not be recompiling AIPS.
Screen 10: Advanced Settings
In general, the default settings for these advanced options will be OK.Please review the settings, and then decide if you want to change them.
    AP settings are in PAPC.INC (cf $SYSLOCAL/INCS.SH)
    Fortran settings are in $SYSLOCAL/FDEFAULT.SH
    C settings are in $SYSLOCAL/CCOPTS.SH, and
    Link settings are stored in $SYSLOCAL/LDOPTS.SH

Current settings of advanced parameters:
AP Size (MB): 5 (for your memory size 127792 KB, use 20 MB)FORTRAN Compiler: /usr/bin/g77 (default /usr/bin/g77)     and options: -c -fno-automatic -fno-globals -Wno-globals \                  -malign-double -Wimplicit -Wall default options: -c -fno-automatic -fno-globals -Wno-globals \                  -malign-double -Wimplicit -Wall          Linker: /usr/bin/g77 (default /usr/bin/g77)      C Compiler: /usr/bin/gcc (default /usr/bin/gcc)     and options: -c -O3 -fomit-frame-pointer -funroll-loops \                  -I/opt/aips/31DEC03/INC -DHAVE_LINUX_GLIBC default options: -c -O3 -fomit-frame-pointer -funroll-loops \                  -I/opt/aips/31DEC03/INC -DHAVE_LINUX_GLIBCReadline Library: /usr/lib/libreadline.a  Debug Libs too: NO         [You may also type B for back, or Q to Quit]

AipsWiz: ===&gt; [M]odify or [A]ccept (default Accept):Let’s look briefly at some of these settings:-	AP Size: Size of an internal “buffer” or array in AIPS that simulates the old array processor. Some tasks benefit significantly from making this larger. Changing it requires a (re)compile of AIPS. It is therefore not offered for binary installations either from the network or CD. Here the wizard recommends an increase based on the (Linux) system’s available memory.-	Compilers and Options: These are pre-set for most common architectures. You should only have to alter them if (a) you are recompiling [e.g., for a different AP size]; and (b) you have a different compiler. Solaris (SOL, SUL) defaults assume the Sun Compilers so if you use gcc/g77 on Solaris, you need to change the settings. The linker should be the same as the Fortran compiler. The only “gotcha” here might be that the procedure expands the $INC setting in the configuration files; this is for the most part benign. If you have installed a compiler such as GNU 2.95.3 to avoid the defective 2.96 and 3.0+ compilers, then you must enter the path to this compiler in FORT, LINK, and CCOM.-	Readline Library: If you have a Linux system, the wizard will tell AIPS to use your library for any recompiles. Otherwise, unless the system detects a libreadline.a in an obvious place, it will default to the LIBR/GNU/ location and will be built (or used if pre-supplied, e.g. on CD).-	Debug Libs too: If you are doing code development in AIPS, you may want to have two sets of AIPS libraries: one with optimized routines, the other with non-optimized and debug (-g) capabilities. Only set this to YES if you need to use a debugger like dbx or gdb in AIPS tasks.If you choose to change any of these, you will get a dialog like this:AipsWiz: ===&gt; [M]odify or [A]ccept (default Accept):M
AipsWiz: ==&gt; Change item [APSIZE, FORT, FORTOPT, LINK, CCOM, CCOMOPT,                        DEBUGLIBS, READLINE, or (default) END]: APSIZEAipsWiz: ==&gt; AP Size in MB (1-512):: 20AipsWiz: ==&gt; Change item [APSIZE, FORT, FORTOPT, LINK, CCOM, CCOMOPT,                        DEBUGLIBS, READLINE, or (default) END]:This shows the installer changing the AP Size to 20 Megabytes from its default value of 5. After finishing this, you are brought back to screen 11 so you can double-check your changes.
Screen 11: Final ReviewScreen 11: FINAL REVIEW before installing!
This is your last, best hope for checking the settings beforecommitting to the install.  Please check thesesettings, andmake sure they are what you want:
   AIPS_ROOT (screen 3): /opt/aips       Group (screen 4): aipsuser Group Write (screen 4): YESArchitecture (screen 5): LINUX   Site name (screen 5): CVTEST  AIPS hosts (screen 6): ORANGUTAN  Data areas (screen 7): /DATA/ORANGUTAN_1    Printers (screen 8): pscolor   PS-CMYK  NONE    Color printer                         ps1dup    PS       DUP     Main printer                         ps2dup    PS       DUP,DEF 2nd floor printer  Paper type (screen 8): A Tape drives (screen 9): host ORANGUTAN, tape drive /dev/nst0: 4mm DDS-4  Tape hosts (screen 9): 127.0.0.1   Advanced (screen 10): (not listed here)
You can skip back to a previous menu by entering its number,or use the phrase ‘start over’ to go back  to the beginning.         [You may also type B for back, or Q to Quit]
AipsWiz: ===&gt; [A]ccept (default) or menu number:This screen attempts to give a review of the main settings you have entered, and allows you to back up to any given screen so you can fix things. The only annoying feature is that once you go back to a screen, the only way to get back to screen 11 is to advance one screen at a time. In effect this just means pressing  at each intervening screen. A shortcut mechanism will likely be added to the wizard in the near future.
Applying the SettingsYou will be given one last chance to change your mind after accepting the values in the menu. Then the script proceeds to deploy the decisions you have made by altering various system files, creating directories, and so on. From a non-binary installation, a typical session might look like this:AipsWiz: ==&gt; Confirm: start the install with these settings [Y]:AipsWiz:  =====&gt; Creating or updating HOSTS.LIST fileAipsWiz:         – Done.AipsWiz:  =====&gt; Configuring your AIPS_ROOT area…AipsWiz:  =====&gt; Running 31DEC03/SYSTEM/UNIX/AIPSROOT.DEFINE                          /home/aips/tmpAipsWiz:         – Done.AipsWiz:  =====&gt; changing LOGIN.SH to LAPTOP=”YES”AipsWiz:  =====&gt; changing LOGIN.CSH to LAPTOP=”YES”AipsWiz:         – Done.AipsWiz:  =====&gt; Adjusting AP size to 20 MBytesAipsWiz:         No /opt/aips/31DEC03/INC/NOTST/LINUX/PAPC.INC foundAipsWiz:         - trying /opt/aips/31DEC03/INC/PAPC.INCAipsWiz:         – Done.AipsWiz:  =====&gt; Setting up LINUX-specific areas and SYSLOCAL…AipsWiz:         – Done.AipsWiz:  =====&gt; Configuring AIPS for your printers…AipsWiz:         Text printing set up for ‘A’ size paperAipsWiz:         – doneAipsWiz:  =====&gt; Configure AIPS data areas …AipsWiz:         – doneAipsWiz:  =====&gt; Configure AIPS Tape drives…AipsWiz:         – doneAipsWiz:  =====&gt; Create DA00/hostname/ directories…AipsWiz:         – done.AipsWiz:  =====&gt; Deploying your compiler options in script files…AipsWiz:         CCOPTS.SH done (C Compiler and options)AipsWiz:         LDOPTS.SH done (Linker)AipsWiz:         FDEFAULT.SH done (Fortran compiler and options)WARNING!  The structure of /opt/aips/31DEC03/SYSTEM/UNIX/FDEFAULT.SH          is very complex, and while this wizard install          tries VERY hard to change the right section,          it may have failed.  Please, PLEASE inspect the          file and compare it to the original (saved as          FDEFAULT.SH.dist in /opt/aips/31DEC03/SYSTEM/UNIX)          to make sure the settings are right.  Do this          BEFORE you proceed any further.          THIS IS REQUIRED FOR THE 2.95.3 COMPILER IN LINUXAipsWiz: ==&gt; Press  after you have verified FDEFAULT.SH::(The messages about LOGIN.SH appear only if you ask to change the host name to LOCALHOST for a single-computer installation.) Note the pause here, asking for the OK to proceed. If you haven’t changed the settings, don’t worry about it. Even if you have, chances are that it will get the changes made in the right place. However, doing this sort of change automatically in as complex a file as FDEFAULT.SH is tricky, so it can’t hurt to look at the architecture-specific section for your system and make sure it’s not totally messed up! In the worst case scenario, you can always restore the original from the FDEFAULT.SH.dist file.Linux sites may have to modify the $SYSLOCAL/FDEFAULT.SH file. It is now set for the GNU 3.2 and later compilers, with OPT2=”-O2”. If you are using the GNU 2.95.3 compiler, a different set of OPT2 options is present in the file. Comment out the -O2 one and remove the comment symbols from the 3 lines of OPT2’s designed for 2.95.3. Note “-O2” works with 2.95.3 but produces somewhat slower code.The process will then continue (after you press , of course):AipsWiz: ==&gt; Press  after you have verified FDEFAULT.SH::AipsWiz:  =====&gt; Compile Utility Programs in                 /opt/aips/31DEC03/LINUX/SYSTEM/CVTEST…AipsWiz: Compiling F2PS…AipsWiz: Compiling F2TEXT…AipsWiz: Compiling NEWEST…AipsWiz: Compiling PRINTENV…AipsWiz: Compiling PWD…AipsWiz: Compiling REVENV…AipsWiz:         - Compiling ZTRLOP.c…AipsWiz:         - that seemed to work.AipsWiz:  =====&gt; Make the XAS TV Server from source…AipsWiz: About to unpack the XAS.SHR archive.AipsWiz: Building the UNSHR program for LINUX…AipsWiz: UNSHR.LINUX built in pwdAipsWiz: About to run XAS.SHR through UNSHR (ignore the prompt)…  Enter the name of the archive:AipsWiz: Done.AipsWiz: About to try to make XAS…All of this is reasonably routine and automatic. The messages that follow have to do with building XAS (note: if your install freezes after announcing that it’s going to make the XAS server, you need a newer version of install.pl).Extra messages reporting intermediate steps are likely to appear. On a binary installation, you will see something like:AipsWiz: ==&gt; Confirm: start the install with these settings [Y]:AipsWiz:  =====&gt; Creating or updating HOSTS.LIST fileAipsWiz:         – Done.AipsWiz:  =====&gt; Configuring your AIPS_ROOT area…AipsWiz:  =====&gt; Running 31DEC03/SYSTEM/UNIX/AIPSROOT.DEFINE                          /home/aips/tmpAipsWiz:         – Done.AipsWiz:  =====&gt; changing LOGIN.SH to LAPTOP=”YES”AipsWiz:  =====&gt; changing LOGIN.CSH to LAPTOP=”YES”AipsWiz:         – Done.AipsWiz:  =====&gt; Setting up LINUX-specific areas and SYSLOCAL…AipsWiz:         – Done.AipsWiz:  =====&gt; Configuring AIPS for your printers…AipsWiz:         Text printing set up for ‘A’ size paperAipsWiz:         – doneAipsWiz:  =====&gt; Configure AIPS data areas …AipsWiz:         – doneAipsWiz:  =====&gt; Configure AIPS Tape drives…AipsWiz:         – doneAipsWiz:  =====&gt; Create DA00/hostname/ directories…AipsWiz:         – done.AipsWiz:  =====&gt; and populating area for $THISHOST from rsync server
The Midnight JobOnce the utility programs and XAS are built, the wizard will start preparing for a possible recompile and for the Midnight Job. You do not need to actually run one (though we recommend it if you wish to stay current with the latest bug fixes), but setting up the infrastructure to support a midnight job is now a standard feature of the AIPS install process. Here’s what the dialog will tell you:AipsWiz:  =====&gt; Preparing for INSTEP2 and INSTEP4 (building AIPS)…AipsWiz:  =====&gt; Preparing for the “Midnight Job”…
The AIPS Midnight Job is a way to keep your AIPS installation up todate.  It is secure, relatively easy, and can be done on demand or ina cron job (i.e. periodically, daily or weekly or whenever).  It doesrequire that you have the code versioning system (cvs) installed onyour system.  The MNJ is of no use with AIPS versions that arealready frozen when you install them and is useful only once after wefreeze a particular version.  When installing a frozen version - ormaintaining a version that is now frozen, you should periodicallycheck the patches that may have been issued forthat release.
This script will set up the infrastructure for you to be able to runthe Midnight Job (MNJ), but you have the power to make it run or not.
Should you choose to run the Midnight Job, the ‘begin date’ will beset to YYYYMMDD, which is ONE day before the generation time of the31DEC03.tar.gz file.
AipsWiz: ==&gt; If you want a different date, enter it now::This date is used by the midnight job as the zero point for incremental updates, so it should be before the timestamp on the file. Due to possible timezone ambiguities, it’s best to accept the one-day-before default the wizard offers.For binary installations, it is a bit simpler:AipsWiz:  =====&gt; Preparing for the “Midnight Job”…
The AIPS Midnight Job is a way to keep your AIPS installation up todate.  It is secure, relatively easy, and can be done on demand or ina cron job (i.e. periodically, daily or weekly or whenever).  It doesrequire that you have the code versioning system (cvs) installed onyour system.  The MNJ is of no use with AIPS versions that arealready frozen when you install them and is useful only once after wefreeze a particular version.  When installing a frozen version - ormaintaining a version that is now frozen, you should periodicallycheck the patches that may have been issued forthat release.
This script will set up the infrastructure for you to be able to runthe Midnight Job (MNJ), but you have the power to make it run or not.At this stage, the wizard hands off control temporarily to the MAKE.MNJ script which will compile some programs, set up some .OLD and .DAT files, and set up the mailing lists for midnight job output and error messages. It gives you a chance to examine these settings and change them by hand before proceeding.The midnight job only runs under the code versioning system (cvs) now. You no longer need to contact us to ask about running a midnight job. The MAKE.MNJ script will attempt to “prime” the cvs setup by accessing our server. When it asks for a password, simply hit Enter. The process creates a file .cvspass in your home directory enabling cvs to run without passwords henceforth.
RegistrationThe registration system has fallen into disuse. It required special database software which the CV Computer Division no longer maintains. As a consequence, the wizard no longer runs the REGISTER script. You may run this fairly primitive script after the installation if you want. It will obtain registration information from you, and put it in the REGISTER.INFO file in your home directory. You have the option of sending this information to NRAO, but we now just file it. Registration is no longer a requirement to receive help with AIPS. Usage statistics are now obtained only via monitors of tarball downloads and cvs accesses.
Compiling - INSTEP2, INSTEP4If you are doing a binary installation (from CD or network), you will not be prompted for this step. Otherwise, the wizard will ask if you want it to start INSTEP2, which compiles all AIPS subroutines, and INSTEP4, which builds all the programs. This can take several hours, even on fairly fast hardware. If you choose to defer this, the script gives simple instructions on what to do next. If you go ahead at this point, the script will not only do INSTEP2 and INSTEP4, but also run the programs described below.If you are installing a frozen version of AIPS, you should check the patches page for the release before telling INSTEP2 and INSTEP4 to begin. 31DEC02 at least has patches that need to be applied at this point on RedHat version 8 and 9 systems.
Running FILAIP, POPSGN, SETPARFinally, you may need or want to run these. If building from source, FILAIP and POPSGN have to be run. This is done for you, if you opt to run INSTEP2 and INSTEP4 from the install.pl script. If you are doing a re-installation, you may be prompted for a password when running install.pl. The default password is AMANAGER which can be changed in AIPS, but is usually left as it is shipped. If installing from CD, FILAIP and POPSGN should not need to be run. In either case, you may want to examine system defaults with SETPAR. All of these are run by defining the AIPS environment and using the RUN shell script. What follows here is a typical session with the recommended values, with some text omitted for clarity (the GPL notice, and the disk selection dialog in RUN):
bash$ . ./LOGIN.SHbash$ $CDTSTAIPS_VERSION=/opt/aips/31DEC03bash$ RUN FILAIP  (GNU Copyleft shows up here - also a prompt for a password when  re-installing a new version)Password:                             (default is AMANAGER)
disks, # cat entries/disk (&lt;0 =&gt; private catlgs) (2 I)35 -100
interactive AIPS, # batch queues (2 I)8 2
tape drives (I)4FILAI1: Init POPS memory files 1 through 12 with program POPSGNFILAI1: Done!bash$ RUN POPSGNEnter Idebug, Mname, Version (1 I, 2 A’s) (NO COMMAS)0 POPSDAT TST

                            (press &lt;RETURN&gt; here)

POPSG1: Popsgen completePOPSG1: orangutan    31DEC03 TST: Cpu=       0.2  Real=      74bash$ RUN SETPARStarting up SETPAR (RELEASE OF 31DEC03)Enter:  1=Start Over, 2=Change parameters, 3=Change DEVTAB, 4=Quit2  (many options shown, including this:) 35  Computer speed rating (AIPSmarks)   1.00  Enter number to change or  0 = Print, -1 = Return35 35  Computer speed rating (AIPSmarks)    1.0020Enter number to change or  0 = Print, -1 = Return-1Password:                             (default is AMANAGER)Enter:  1=Start Over, 2=Change parameters, 3=Change DEVTAB, 4=Quit4SETPA1: orangutan    31DEC03 TST: Cpu=       0.0  Real=     106bash$The above dialog shows an installer running all three utility programs, so that the system files are created (FILAIP), initialized (POPSGN), and customized (SETPAR). The customization shown is to set the “speed” parameter to something close to the actual expected performance of the machine. This parameter is used to figure out reasonable delays in task startup, termination and management, and can make quite a (bad) difference if set too low or too high. Refer to the AIPS Benchmark page for some tests we’ve done and to figure out what value to use for your system. For most newer (modest) machines, 20 is probably a good starting point.There are a couple of things that may need to be done to your operating system controls files in order to run AIPS. You probably need to be root to do these. The first is to add to /etc/services the linessssin           5000/tcp        SSSIN      # AIPS TV serverssslock         5002/tcp        SSSLOCK    # AIPS TV Lockmsgserv         5008/tcp        MSGSERV    # AIPS Message Servertekserv         5009/tcp        TEKSERV    # AIPS TekServeraipsmt0         5010/tcp        AIPSMT0    # AIPS remote FITS disk accessaipsmt1         5011/tcp        AIPSMT1    # AIPS remote tape 1aipsmt2         5012/tcp        AIPSMT2    # AIPS remote tape 2aipsmt3         5013/tcp        AIPSMT3aipsmt4         5014/tcp        AIPSMT4aipsmt5         5015/tcp        AIPSMT5aipsmt6         5016/tcp        AIPSMT6aipsmt7         5017/tcp        AIPSMT7Comment out the obsolete “radio free ethernet” (5002) service. Your X Windows needs to operate in either 8-bit PseudoColor or 24-bit TrueColor mode. The 16-bit TrueColor mode that is the default on many systems does not have enough dynamic range for scientific imaging. The file /etc/X11/XF86Config-4 is used to control this in RedHat installations.The AIPS Manager FAQ may be of help in solving residual installation problems.That’s about all we can cover here. The installation wizard is a vast improvement over the old INSTEP1 way of doing things, and we welcome feedback on it, both for bug reports and suggested improvements.Patches to frozen versionsAfter a version of AIPS is “frozen”, no more changes will be made to the code. If a serious bug is found, a “patch” for the bug will be announced and made available through the patches web page. You must download the files from the page for your version of AIPS and follow the instructions to apply the patches, even if you fetched the tar ball for your version of AIPS long after the patch was announced.When a patch is made available, it is usually announced on the “bananas” mail list. This is a closed, moderated mailing list that serves as a conduit for important announcements pertaining to AIPS, as well as an occasional forum for questions and discussion about the software. You can subscribe yourself to this list on-line.Rarely, a patch may need to be applied before the installation will work. The one case so far is a set of changes to Z routines caused by changes to Linux appearing in the RedHat versions 8 and 9. The installation script stops before starting INSTEP2 and INSTEP4, giving a convenient point to do the file downloads. See the 31DEC02 patch page for details.

=============================
参考网址
http://www.aips.nrao.edu/Mac.shtml
http://www.aips.nrao.edu/dec20.shtml
installation detailshttp://www.aips.nrao.edu/install.shtml
MacOSXOn Macs, you may need to create an /etc/sysctl.conf filePut in it the following lines
 kern.sysv.shmmax=10485760
 kern.sysv.shmmin=1
 kern.sysv.shmmni=32
 kern.sysv.shmseg=8
 kern.sysv.shmall=4096

重启后可以使用 sysctl kern.sysv来查看状态。
代码参考 https://www.github.com/shaoguangleo/radio_astronomy
]]></content>
      <categories>
        <category>射电天文</category>
      </categories>
      <tags>
        <tag>astronomy</tag>
        <tag>aips</tag>
        <tag>天文</tag>
        <tag>射电</tag>
        <tag>radio</tag>
        <tag>radio astronomy</tag>
      </tags>
  </entry>
  <entry>
    <title>aips trouble shooting</title>
    <url>/2011/01/19/radio_astronomy_install_aips_troubleshooting/</url>
    <content><![CDATA[AIPS trouble shooting如果你选择将AIPS的tar包下载下来安装，可能会碰到诸多问题，譬如编辑器的问题，这里就涉及到了你必须要安装Intel的FORTRAN编辑器和C、C++编辑器，并且这些都不是免费的，虽然有30天的试用评估版本，还是会有很多的问题的，所以这种方式不推荐。    两者的安装与Intel IPP类似，方法雷同，见：http://guoshaoguang.com/blog/2011/05/10/如何下载-intel-integrated-performance-primitives-intel-ipp/
START_AIPS: AIPS_ROOT is not a directory; cannot start AIPS.The solutions
$ cd /the/directory/of/aips     $ . LOGIN.SH$ AIPSROOT.DEFINEThe current directory is /the/directory/of/aips — is this what you want to be AIPS_ROOT?  (y/n) y



还有一种情况是对比一下两个文件，估计AIPS_ROOT不一致，修改即可
$ vim /home/aips/LOGIN.SH# and$ vim /home/aips/START_AIPS# check what is the AIPS_ROOT area. 







AIPS troubleshooting, Data directory undefined默认情况在AIPS/DA00/DADEVS.LIST是可以看到这个信息的，不过如果希望使用不同的，或者有这个问题，可以通过创建文件$HOME/.dadevs.always进行解决，内容如下：
+  /the/path/you/want/to/store/AIPS/LUSTRE_1-  /the/path/you/want/to/store/AIPS/LUSTRE_2



FILAIP / POPSDAT 出错解决方法为
$ source LOGIN.SH$ RUN FILAIP # 然后输入YES，输入8 2$ RUN POPSGN # 然后输入YES，输入0 POPSDAT TST





参考参考 https://www.github.com/shaoguangleo/radio_astronomy
]]></content>
      <categories>
        <category>射电天文</category>
      </categories>
      <tags>
        <tag>astronomy</tag>
        <tag>aips</tag>
        <tag>天文</tag>
        <tag>射电</tag>
        <tag>radio</tag>
        <tag>radio astronomy</tag>
      </tags>
  </entry>
  <entry>
    <title>SMILI 安装说明</title>
    <url>/2024/04/09/radio_astronomy_install_smili/</url>
    <content><![CDATA[SMILI 安装说明安装依赖
$ sudo apt install x11*$ sudo apt install libxt-dev$ sudo apt install libopenblas-dev





安装 OpenBLAS# Clone the current repositorygit clone https://github.com/xianyi/OpenBLAS# Compile and install#   macOS MacPorts users may not use USE_OPENMP=1 option, and need to omit it.cd OpenBLASmake USE_OPENMP=1 CC=gcc FC=gfortranmake PREFIX="~/local" install# 确认是否安装正确# 是否有输出$ pkg-config --debug openblas# 如果没有，增加pkg的pathexport PKG_CONFIG_PATH=~/local/lib/pkgconfig:$PKG_CONFIG_PATH

安装FFTW3$ apt install fftw*# 确认是否安装正确# 是否有输出$ pkg-config --debug fftw3



安装 FINUFFT# 下载源码$ cd ~/local$ git clone https://github.com/flatironinstitute/finufft$ cd finufft



准备make.inc文件，内容如下：
# CompilersCXX=g++CC=gccFC=gfortran# (compile flags for use with GCC are as in linux makefile)CFLAGS +=# If you're getting warning messages of the form:#    ld: warning: object file (lib-static/libfinufft.a(finufft1d.o)) was built for#    newer OSX version (10.13) than being linked (10.9)# Then you can uncomment the following two lines with the older version number# (in this example -mmacosx-version-min=10.9)##CFLAGS += "-mmacosx-version-min=&lt;OLDER OSX VERSION NUMBER&gt;"# if you are macOS homebrew users, uncomment this.# (assuming that /usr/local is your homebrew's PREFIX)#CFLAGS += -I src -I/usr/local/include#LIBS += -L/usr/local/lib# if you are macOS MacPorts users, uncomment this.# (assuming that /opt/local is your MacPorts' PREFIX)#CFLAGS += -I src -I/opt/local/include#LIBS += -L/opt/local/lib# Your FFTW3's installation PREFIXCFLAGS += -I$HOME/local/includeLIBS += -L$HOME/local/lib# You can keep themFFLAGS   = $(CFLAGS)CXXFLAGS = $(CFLAGS) -DNEED_EXTERN_C# OpenMP with GCC on OSX needs following...OMPFLAGS = -fopenmpOMPLIBS = -lgomp# since fftw3_omp doesn't work in OSX, you need to uncomment this#FFTWOMPSUFFIX=threads

开始编译库
$ make lib



新建finufft.pc文件，内容如下：
# This is an example pkg-config file. Here is an brief instruction.# (1) Please change finufftdir depending on your install directory.# (2) please change its filename to finufft.sample.pc and#     copy to a directory specified in $PKG_CONFIG_PATHfinufftdir=$(HOME)/local/finufftlibdir=${finufftdir}/lib-staticincludedir=${finufftdir}/includeName: FINUFFTDescription: Flatiron Institute Nonuniform Fast Fourier Transform librariesVersion: githubLibs: -L${libdir} -lfinufftCflags: -I${includedir}



确认是否安装完毕
# 确认是否安装正确# 是否有输出$ pkg-config --debug finufft# 如果没有，增加pkg的pathexport PKG_CONFIG_PATH=~/local/finufft/:$PKG_CONFIG_PATH

安装SMILI# Clone the repository$ git clone https://github.com/astrosmili/smili$ cd smili# 通过conda创建虚拟环境，不然编译会有问题$ ./configure$ make install

]]></content>
      <categories>
        <category>射电天文</category>
      </categories>
      <tags>
        <tag>astronomy</tag>
        <tag>天文</tag>
        <tag>射电</tag>
        <tag>radio</tag>
        <tag>radio astronomy</tag>
        <tag>smili</tag>
      </tags>
  </entry>
  <entry>
    <title>Redhat使用CentOS的源</title>
    <url>/2011/05/06/redhat-using-centos-yum-source/</url>
    <content><![CDATA[将Redhat的源更改为CentOS的源。
# 下载CentOS的yum安装包wget http://ftp.nara.wide.ad.jp/pub/Linux/centos/6.4/os/x86_64/Packages/python-iniparse-0.3.1-2.1.el6.noarch.rpmwget http://ftp.nara.wide.ad.jp/pub/Linux/centos/6.4/os/x86_64/Packages/yum-metadata-parser-1.1.2-16.el6.x86_64.rpmwget http://ftp.nara.wide.ad.jp/pub/Linux/centos/6.4/os/x86_64/Packages/yum-3.2.29-40.el6.centos.noarch.rpmwget http://ftp.nara.wide.ad.jp/pub/Linux/centos/6.4/os/x86_64/Packages/yum-plugin-fastestmirror-1.1.30-14.el6.noarch.rpm# 安装yum包rpm -ivh python-iniparse-0.3.1-2.1.el6.noarch.rpm yum-metadata-parser-1.1.2-16.el6.x86_64.rpm yum-3.2.29-40.el6.centos.noarch.rpm yum-plugin-fastestmirror-1.1.30-14.el6.noarch.rpm# 添加163的yum源cd /etc/yum.repos.dwget http://mirrors.163.com/.help/CentOS6-Base-163.reposed -i ‘s/\$releasever/6/g’ CentOS6-Base-163.repo# 清理yum缓存yum clean all# 将服务器上的软件包信息缓存到本地，以提高速度yum makecache
]]></content>
      <categories>
        <category>Linux</category>
        <category>CentOS</category>
        <category>Redhat</category>
      </categories>
      <tags>
        <tag>yum</tag>
        <tag>Redhat</tag>
        <tag>centos</tag>
        <tag>wget</tag>
      </tags>
  </entry>
  <entry>
    <title>使用结构化命令</title>
    <url>/2012/01/07/shell-9-struct-command/</url>
    <content><![CDATA[使用结构化命令原因：许多程序在脚本命令之间需要某种逻辑流控制。
使用if-then语句最基本的结构化命令类型为if-then语句，格式为：
if commandthen       commandfi


这里有一些困惑，如果if后面的命令运行成功（即返回的是0值），就会执行then后面的command的，相反，就会跳过。
比如，你可以搜索你的名字是否在passwd中
if grep leo /etc/passwdthen       echo “yeah , you are in the /etc/passwd file”fi

if-then-else语句上面的if-then只有一个选择，而这个可以有多个选择。
格式为：
if commandthen       commandelse       commandfi

嵌套if语句使用else部分的另一种版本，成为elif
if commandthen       commandelif commandthen       commandelif commandthen       command……fi

test命令test命令提供了一种检测if-then语句中不同条件的方法。
if test conditionthen       commandsfi或者if [condition]then       commandsfi

test命令能够评估以下3类条件：

数值比较
字符串比较
文件比较

数值比较test命令最常用于比较两个数值。

test int1 -eq int2 判断是否相等
test int1 -ne int2 判断是否不等
test int1 -lt int2 判断是否小于
test int1 -le int2 判断是否不小于
test int1 -gt int2 判断是否大于
test int1 -ge int2 判断是否不大于

字符串比较test也允许对字符串进行比较，执行字符串比较可能有点复杂。

test –n 字符串 字符串的长度非零
test –z 字符串 字符串的长度为零
test 字符串1＝字符串2 字符串相等
test 字符串1！＝字符串2 字符串不等
test 字符串1&gt;字符串2 字符串1大于字符串2
test 字符串1&lt;字符串2字符串1小于字符串2

字符串比较：

大于和小于符号一定要转义，否则shell会将他们当做重定向符号，将字符串值看做文件名；
大于和小于顺序与在sort命令中的顺序不同

文件比较Shell脚本中最强大和最常用的一类比较。test命令能够测试linux文件系统上的文件状态和路径。
文件比较：-

-d file 检查file是否存在并且是一个目录
-e file 检查file是否存在
-f file 检查file是否存在并且是一个文件
-r file 检查file是否存在并且可读
-s file 检查file是否存在并且不为空
-w file 检查file是否存在并且可写
-x file 检查file是否存在并且可执行
-0 file 检查file是否存在并且被当前用户拥有
-G file 检查file是否存在并且默认组是否为当前用户组
file1 -nt file2 检查file1是否比file2新
file1 -ot file2 检查file1是否比file2旧

复合条件检查if-then语句可以使用布尔逻辑来合并检查条件，可以使用两个布尔操作符：

[condition1] &amp;&amp; [condition2]
[condition1] || [condition2]

if-then的高级特征Bash shell中最近增加了两个比较新的功能，它们提供了可以在if-then语句中使用的高级功能：

双圆括号表示数学表达式
双方括号表示高级字符串处理函数

使用双圆括号双圆括号命令允许在比较中包含高级数学公式。双圆括号命令提供更多的数学符号，这些符号是其他语言程序员习惯使用的符号。格式为：
((expression))
双圆括号命令符号

val++    后增量
val–      前减量
++val    前增量
–val      后减量
!    逻辑否定
~    逐位取反
**    取幂
&lt;&lt;    逐位左移


   逐位右移



&amp;    逐位布尔逻辑与
|    逐位布尔逻辑或
&amp;&amp;    逻辑与
||     逻辑或

使用双方括号双方括号命令为字符串比较提供了高级功能，它提供了test命令没有的另一个功能，即模式匹配。例如
if [[ $USER == r*]]then       echo “hello $USER”else       echo “Sorry, I do not know you”fi

case命令替代if-then-elif，提供了一种为每个可能的变量值指定不同选项的更清楚的方法。
格式为：
case variable inpattern1 | pattern2) command1;pattern3) command2;……patternN) commandN;*) default commands;esac
]]></content>
      <categories>
        <category>Shell</category>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>if</tag>
        <tag>case</tag>
        <tag>shell</tag>
        <tag>command</tag>
        <tag>esac</tag>
        <tag>then</tag>
        <tag>elif</tag>
        <tag>structure</tag>
        <tag>test</tag>
      </tags>
  </entry>
  <entry>
    <title>Shell 监视系统统计信息</title>
    <url>/2012/01/14/shell-system-information/</url>
    <content><![CDATA[监视系统统计信息功能：监视磁盘空间，并在超过预定值以后发送邮件

df输出
提取出根目录所在的行，也就是以/结尾的行：使用$df | sed –n ‘//$/p’
分离出此行上的百分比：$ df | sed –n ‘//$/p’ | gawk ‘{print $5}’
删除掉%，$ df | sed –n ‘//$/p’ | gawk ‘{print $5}’|sed ‘s/%//‘

所以我们可以创建一个脚本：
#!/bin/bash#monitor available disk spaceSPACE=`df | sed -n '/\/$/p' | gawk '{print $5}'|sed 's/%//'`if [ $SPACE -ge 90 ]then       echo "Disk space on root at $SPACE% used" | mail -s "Disk Warning" leofiecho "Disk space on root at $SPACE% used"

然后我们就可以在cron中写入这个脚本的一些信息，保证每天或者每个月统计一下信息来查看是否已经超过了预警值而发送信息到邮箱。
谁在霸占资源如果我们负责Linux服务器上的许多用户，需要经常查看谁在使用所有的磁盘空间。
第一步：使用du -s /home/命令，来列出各个文件和目录的磁盘使用情况。第二部：其中的test不是我们需要的内容，则使用du -s /home/ |grep –v test第三步，为了查看用户名，我们去掉路径：du -s /home/* |grep –v test |sed ‘//home///p’
接下来，如果有多个用户，可以使用du -s /home/* |grep –v test |sed ‘//home///p’|sort –g –r来排序，确定那个用户占用了较多的空间。
监视CPU和内存使用情况#!/bin/bash#script to capture system statisticsOUTFILE=/home/leo/capstats.csvDATE=`date +%Y/%m/%d`TIME=`date +%k:%M:%S`TIMEOUT=`uptime`VMOUT=`vmstat 1 2`USERS=`echo $TIMEOUT | gawk ‘{print $4}’`LOAD=`echo $TIMEOUT | gawk ‘{print $9}’ | sed ‘s/,//’`FREE=`echo $VMOUT | sed -n ‘/[0-9]/p’ |sed -n ‘2p’ | gawk ‘{print $4}’`IDLE=`echo $VMOUT | sed -n ‘/[0-9]/p’ |sed -n ‘2p’ | gawk ‘{print $15}’`echo "$DATE,$TIME,$USER,$LOAD,$FREE,$IDLE" &gt;&gt; $OUTFILE

从这个脚本，我们就可以设置一些定期运行来查看系统状态的信息，然后我们就可以使用HTML的格式生成一些比较优雅好看的文档格式。这同样可以使用echo命令生成HTML头部的代码，使用gawk命令生成HTML代码数据，然后再次使用echo命令关闭表。
生成的报告，可以使用Mutt命令轻松发送到电子邮件。
小结当你负责管理Linux系统时，不管是大型的多用户系统，还是自己的系统，都有许多需要监视的内容。与其大量搜索日志文件和手动运行命令，不如创建shell脚本来完成这些任务。
]]></content>
      <categories>
        <category>Shell</category>
      </categories>
      <tags>
        <tag>shell</tag>
        <tag>grep</tag>
        <tag>sed</tag>
        <tag>sort</tag>
        <tag>gawk</tag>
        <tag>mutt</tag>
        <tag>vmstat</tag>
      </tags>
  </entry>
  <entry>
    <title>信号与系统 卷积</title>
    <url>/2009/08/06/signal_and_system_conv/</url>
    <content><![CDATA[卷积的性质
交换律
分配律
结合律
平移特性
展缩特性

平移特性已知 $f_1(t) \ast f_2(t) =y(t)$，则  $f_1(t-t_1) \ast f_2(t-t_2) =y(t-t_1-t_2)$
证明：
$f_1(t-t_1) \ast (t-t_2)$ =
展缩特性已知 $f_1(t) \ast f_2(t) =y(t)$，则  $f_1(at) \ast f_2(at) =\frac{1}{|a|}y(at)$
证明：
参考代码参考 https://www.github.com/shaoguangleo/signal_and_system
]]></content>
      <categories>
        <category>信号与系统</category>
        <category>Signal and System</category>
      </categories>
      <tags>
        <tag>signal</tag>
        <tag>system</tag>
      </tags>
  </entry>
  <entry>
    <title>相关 与 卷积</title>
    <url>/2006/08/06/signal_and_system_conv_corr/</url>
    <content><![CDATA[相关 与 卷积卷积可以通过下面几个步骤完成：①将x(n)和h(n)用x(m)和h(m)表示，并将h(m)进行反转，形成h(−m)；②将h(−m)移位n，得到h(n−m)，当n&gt;0时，序列右移，n&lt;0时，序列左移；③将x(m)和h(n−m)相同m的序列值对应相乘后，再相加。这样就得到当前n样本点位置处的输出y(n)。
所以卷积运算中的主要运算是反转、移位、相乘和相加，此类卷积又称为线性卷积。
对于两个序列x(n)和h(n)，若它们的非零值长度分别是N和M，则卷积结果y(n)=x(n)*h(n)的非零值长度为M +N−1。
相关相关函数反映了信号之间的相似程度。
卷积卷积是表示线性时不变系统的输入、输出和单位脉冲响应之间的一个基本关系。
性质如下：

交换律
分配律
结合律
平移特性
展缩特性

对于卷积的计算方法主要有图解法、解析法、不进位乘法、矩阵表示方法和Z变换方法。
平移特性已知 $f_1(t) \ast f_2(t) =y(t)$，则  $f_1(t-t_1) \ast f_2(t-t_2) =y(t-t_1-t_2)$
证明：
$f_1(t-t_1) \ast (t-t_2)$ =
展缩特性已知 $f_1(t) \ast f_2(t) =y(t)$，则  $f_1(at) \ast f_2(at) =\frac{1}{|a|}y(at)$
证明：
卷积 和 相关的关系相关的函数定义：
$r_{x y}(m)=\sum_{n=-\infty}^{+\infty} x(n) y(n+m)$
卷积的函数定义：
$g(n)=\sum_{m=-\infty}^{+\infty} x(m) y(n-m)$
卷积是表示线性时不变系统的输入、输出和单位脉冲响应之间的一个基本关系；相关是表示两信号之间的相关性，与系统无关。
计算x(n)和y(n)的互相关时，两个序列都不反转，只是将y(n)在时间轴上移位后与x(n)对应相乘再相加即可；而计算二者卷积时，需要先将一个序列反转后再移位，为了要用卷积表示相关，则需要将其中一个序列先反转一次，作卷积时会再反转一次，这样两次反转相抵消，相当于没有进行反转。
参考代码参考 https://www.github.com/shaoguangleo/signal_and_system
]]></content>
      <categories>
        <category>信号与系统</category>
        <category>Signal and System</category>
      </categories>
      <tags>
        <tag>signal</tag>
        <tag>system</tag>
      </tags>
  </entry>
  <entry>
    <title>离散傅里叶变换</title>
    <url>/2006/08/06/signal_and_system_dft/</url>
    <content><![CDATA[离散傅里叶变换离散傅里叶变换(discrete Fourier transform) 傅里叶分析方法是信号分析的最基本方法，傅里叶变换是傅里叶分析的核心，通过它把信号从时间域变换到频率域，进而研究信号的频谱结构和变化规律。但是它的致命缺点是：计算量太大，时间复杂度太高，当采样点数太高的时候，计算缓慢，由此出现了DFT的快速实现，即下面的快速傅里叶变换FFT。
参考代码参考 https://www.github.com/shaoguangleo/signal_and_system
]]></content>
      <categories>
        <category>信号与系统</category>
        <category>Signal and System</category>
      </categories>
      <tags>
        <tag>signal</tag>
        <tag>system</tag>
        <tag>dft</tag>
        <tag>discrete fourier transform</tag>
        <tag>DFT</tag>
        <tag>DTFT</tag>
      </tags>
  </entry>
  <entry>
    <title>微分方程和差分方程</title>
    <url>/2009/07/04/signal_and_system_equation/</url>
    <content><![CDATA[系统的分类连续时间系统 与 离散时间系统
连续时间系统：输入、输出、系统内部信号都是模拟信号
离散时间系统：输入、输出信号都是序列的系统

即时系统 与 动态系统根据有没有储能元件来区分

即时系统：无记忆系统，系统的输出只与当时时刻的输入有关，与其他时刻的输入无关，用代数方程描述
动态系统：记忆系统，系统的输出不只与当前时刻的输入有关，用微分方程或者差分方程描述

线性系统 与 非线性系统如果一个系统既满足叠加性也满足齐次性就称为线性系统，否则为非线性系统。
时变系统 与 时不变系统如果一个系统当输入信号有一个时移时，输出相应也有一个对应的时移，信号的波形并不发生变化为时不变系统。反之即为时变系统。
可逆系统 与 不可逆系统如果一个系统对任何不同的输入都能产生不同的输出，即输入与输出是一一对应的关系，这称为可逆系统，否则为不可逆系统。
因果系统 与 非因果系统如果一个系统的任何时刻的输出只与当时这个时刻的输入以及以前的输入有关，而和该时刻以后的输入无关，称为因果系统，否则为非因果系统。
稳定系统 与 非稳定系统
稳定系统：BIBO及输入有界时，产生的输出也是有界的，反之为非稳定系统

参考代码参考 https://www.github.com/shaoguangleo/signal_and_system
]]></content>
      <categories>
        <category>信号与系统</category>
        <category>Signal and System</category>
      </categories>
      <tags>
        <tag>function</tag>
        <tag>signal</tag>
        <tag>system</tag>
        <tag>graph</tag>
        <tag>signal and system</tag>
      </tags>
  </entry>
  <entry>
    <title>快速傅里叶变换</title>
    <url>/2006/08/07/signal_and_system_fft/</url>
    <content><![CDATA[快速傅里叶变换有限长度序列的离散傅里叶变换实现了对序列傅里叶变换的频率域采样，从而实现了信号在频域的离散化。
但是其计算复杂度为$N^{2}$，随着N的增加，计算负载度会急剧增多，比如在N=1024时，需要完成一百多万次的运算。
此时就需要找到一些可以减小计算量的方法，最简单的可以通过把N个序列，分为M份，直接可以减低计算量，只需要在组合的时候进行一些操作即可。
而考虑到离散傅里叶变换的对称性、周期性，可以有一些通用的方法可以进行简化。详细的可以参考1965年库利和图基的《An algorithm for the machine calculation of complex Fourier series》开创性的工作。
后面推进数字信号快速发展并得到应用的即为快速傅里叶变换。
在对序列本身进行处理的过程中，有不同的FFT算法，有基于时间的基于频率的。
参考代码参考 https://www.github.com/shaoguangleo/signal_and_system
]]></content>
      <categories>
        <category>信号与系统</category>
        <category>Signal and System</category>
      </categories>
      <tags>
        <tag>signal</tag>
        <tag>system</tag>
        <tag>dft</tag>
        <tag>discrete fourier transform</tag>
        <tag>DFT</tag>
        <tag>FFT</tag>
        <tag>快速傅里叶变换</tag>
      </tags>
  </entry>
  <entry>
    <title>信号与系统公式集锦及性质</title>
    <url>/2006/07/06/signal_and_system_formulas/</url>
    <content><![CDATA[信号与系统公式集锦



连续傅里叶变换
连续拉普拉斯变换（单边 ）
离散Z变换（单边）
离散傅里叶变换




时域到频域
时域到复频域 $s=\sigma + j \omega$
离散化 $z = e^{s}$
四种组合形式



$F(j \omega)=\int_{-\infty}^{\infty} x(t) e^{-j \omega t} d t$
$F(s)=\int_{0_{-}}^{\infty} x(t) e^{-s t} d t$
$X(z)=\sum_{n=0}^{\infty} x(n) z^{-n}$
$X(e^{jw})=\sum_{n=-\infty}^{\infty} x[n] e^{-jwn}$



$ x(t)=\frac{1}{2 \pi} \int_{-\infty}^{\infty} F(\omega) e^{j w t} d \omega$
$x(t)=\frac{1}{2 \pi j} \int_{\sigma-j \infty}^{\sigma+j \infty} F(s) e^{s t} d s $
$x(n)=\frac{1}{2 \pi j} \oint X(z) z^{n-1} d z$
$x(n)=\frac{1}{2\pi} \int X(e^{jw}) e^{jwn} dw$


1
$2\pi \delta(w)$





冲激$\delta(t)$

1




阶跃$u(t)$

$\frac{1}{s}$




$e^{jw_0t}$
$2\pi \delta(w-w_0)$





$e^{-jw_0t}$
$2\pi \delta(w+w_0)$





$e^{-at}$

$\frac{1}{s+a}$




$t^{n}$

$\frac{n!}{s^{n+1}}$




$sin(wt)$
$j\pi [\delta (w+w_0) - \delta (w-w_0)]$
$\frac{w}{s^{2}+w^{2}}$




$cos(wt)$
$\pi [\delta (w+w_0) + \delta (w-w_0)]$
$\frac{s}{s^{2}+w^{2}}$




$e^{-at}sin(wt)$

$\frac{w}{(s+a)^{2}+w^{2}}$




$e^{-at}cos(wt)$

$\frac{s+a}{(s+a)^{2}+w^{2}}$




$te^{-at}$

$\frac{1}{(s+a)^{2}}$




$t^{n}e^{-at}$

$\frac{n!}{(s+a)^{n+1}}$




$tsin(wt)$

$\frac{2ws}{(s^{2}+w^{2})^2}$




$tsin(wt)$

$\frac{s^2-w^2}{(s^{2}+w^{2})^2}$




时域卷积$f(t)\ast g(t)$
$F(w) \times G(w)$





时域乘积$f(t)\times g(t)$
$\frac{1}{2\pi}F(w) \times G(w)$















































性质


性质
时域
傅里叶变换





对称性
$F(t)$
$2\pi f(-w)$




傅里叶变换的四种表示形式参考代码参考 https://www.github.com/shaoguangleo/signal_and_system
]]></content>
      <categories>
        <category>信号与系统</category>
        <category>Signal and System</category>
      </categories>
      <tags>
        <tag>function</tag>
        <tag>signal</tag>
        <tag>system</tag>
        <tag>signal and system</tag>
        <tag>Fourier transform</tag>
        <tag>Laplace</tag>
        <tag>拉普拉斯</tag>
        <tag>Fourier</tag>
        <tag>傅里叶</tag>
      </tags>
  </entry>
  <entry>
    <title>信号的频谱分析</title>
    <url>/2006/07/06/signal_and_system_frequency_spectrum/</url>
    <content><![CDATA[信号的频谱分析正交函数集合傅里叶级数傅里叶变换傅里叶变换：
$F(\omega)=\int_{-\infty}^{\infty} f(t) e^{-j \omega t} d t$
傅里叶反变换：
$f(t)=\frac{1}{2 \pi} \int_{-\infty}^{\infty} F(\omega) e^{j \omega t} d \omega$
交换存在的条件：

绝对可积
极值点有有限个
间断点有限

典型信号的傅里叶变换傅里叶变换的性质周期信号的傅里叶变换参考代码参考 https://www.github.com/shaoguangleo/signal_and_system
]]></content>
      <categories>
        <category>信号与系统</category>
        <category>Signal and System</category>
      </categories>
      <tags>
        <tag>function</tag>
        <tag>signal</tag>
        <tag>system</tag>
        <tag>graph</tag>
        <tag>signal and system</tag>
      </tags>
  </entry>
  <entry>
    <title>傅里叶变换</title>
    <url>/2006/08/06/signal_and_system_ft/</url>
    <content><![CDATA[傅里叶变换
在对信号、系统进行频域分析过程中，傅里叶变换起着非常重要的作用。
首先可以通过对信号的频谱分析，来掌握信号的特征，以进一步确定处理信号的方法，从而实现信号的检测和估计，在通信、语音与图像处理、雷达等工程领域得到广泛的应用；另外还可以通过对系统单位脉冲响应的频谱分析得到系统的频率响应，从而得到输入信号通过系统后的幅度和相位的变化，从而确定系统的性质，在滤波器设计有重要的应用。
非周期连续时间信号傅里叶变换傅里叶变换为：
$X_{\mathrm{a}}(\mathrm{j} \Omega)=\sum^{+\infty} x_{\mathrm{a}}(t) \mathrm{e}^{-\mathrm{j} \Omega t} \mathrm{d} t$
傅里叶逆变换为：
$x_{\mathrm{a}}(t)=\frac{1}{2 \pi} \sum_{-\infty}^{+\infty} X_{\mathrm{a}}(j \Omega) \mathrm{e}^{\mathrm{j} \Omega t} \mathrm{d} \Omega$
周期连续时间信号傅里叶级数傅里叶级数：
$X\left(\mathrm{j} k \Omega_{0}\right)=\frac{1}{T_{0}} \int_{-T_{0} / 2}^{T_{0} / 2} \tilde{x}(t) \mathrm{e}^{-\mathrm{j} k \Omega_{0} t} \mathrm{d} t$
傅里叶逆级数：
$\tilde{x}(t)=\sum_{k=-\infty}^{+\infty} X\left(j k \Omega_{0}\right) e^{\mathrm{j} k \Omega_{0} t}$
非周期序列的离散时间傅里叶变换傅里叶变换：
$X\left(\mathrm{e}^{\mathrm{j} \omega}\right)=\sum_{n=-\infty}^{+\infty} x(n) \mathrm{e}^{-\mathrm{j} \omega n}$
傅里叶逆变换：
$x(n)=\frac{1}{2 \pi} \int_{-\pi}^{\pi} X\left(\mathrm{e}^{\mathrm{j} \omega}\right) \mathrm{e}^{\mathrm{j} \omega n} \mathrm{d} \omega$
周期序列的傅里叶级数对一个周期序列而言，它的一个周期的信号其实包含着原始周期序列的全部信息，也就是只要研究一个周期内的信号的信号，整个信号的性质也就知道了。
$\begin{aligned}&amp;\tilde{X}(k)=\operatorname{DFS}[\tilde{x}(n)]=\sum_{n=0}^{N-1} \tilde{x}(n) \mathrm{e}^{-\mathrm{j} \frac{2 \pi}{N} k n}\end{aligned}$
$\begin{aligned}&amp;\tilde{x}(n)=\operatorname{IDFS}[\tilde{X}(k)]=\frac{1}{N} \sum_{k=0}^{N-1} \tilde{X}(k) \mathrm{e}^{j \frac{2 \pi}{N} k n}\end{aligned}$
频域混叠现象对实际信号进行采样时，为了使采样信号不发生频域混叠现象，要求采样满足时域采样定理，即采样频率 fs(=1 T)大于或等于信号所含最高频率 fh的2倍
频谱泄露由于信号本身无限长，因此其理想采样信号也为无限长序列，故需要对其进行截断处理，即相当于将理想采样序列与矩形序列相乘，其对应的频域应为两序列傅里叶变换的卷积。对信号进行截断处理，等价于在一个有限长矩形窗内看原始信号，因此称截断处理为加窗处理，这种处理不可避免地会产生频谱泄漏现象。为减小频谱泄漏，应尽可能减小旁瓣，为此需要寻找其他的具有较小旁瓣的窗函数来替代矩形序列（或称为矩形窗），其中，可用的窗函数包括有汉明窗（Hamming）、汉宁窗（Hanning）、三角窗等。
有效带宽即信号带宽，是从零频率开始到需要考虑的信号最高频率分量之间的频率范围。
一个信号时域的能力等于频域的能力，满足时域频域能力守恒，即为帕斯瓦尔定理Parseval Theorem。
参考代码参考 https://www.github.com/shaoguangleo/signal_and_system
]]></content>
      <categories>
        <category>信号与系统</category>
        <category>Signal and System</category>
      </categories>
      <tags>
        <tag>signal</tag>
        <tag>system</tag>
        <tag>fourier transform</tag>
        <tag>FT</tag>
      </tags>
  </entry>
  <entry>
    <title>奇异函数 - 冲激信号</title>
    <url>/2006/08/04/signal_and_system_impulse/</url>
    <content><![CDATA[奇异函数 - 冲激信号单位冲激函数δ的基本特性
$\int_{-\infty}^{\infty} x(t) \delta\left(t-t_{0}\right) \mathrm{d} t=\int_{-\infty}^{\infty} x\left(t+t_{0}\right) \delta(t) \mathrm{d} t=x\left(t_{0}\right)$
$\delta(a t)=\frac{1}{|a|} \delta(t)$
$x(t) \delta\left(t-t_{0}\right)=x\left(t_{0}\right) \delta\left(t-t_{0}\right)$
$x(t) * \delta\left(t-t_{0}\right)=x\left(t-t_{0}\right)$
$\delta\left(t-t_{1}\right) * \delta\left(t-t_{2}\right)=\delta\left(t-t_{1}-t_{2}\right)$
$\frac{\mathrm{d} u(t)}{\mathrm{d} t}=\delta(t)$

参考代码参考 https://www.github.com/shaoguangleo/signal_and_system
]]></content>
      <categories>
        <category>信号与系统</category>
        <category>Signal and System</category>
      </categories>
      <tags>
        <tag>function</tag>
        <tag>signal</tag>
        <tag>system</tag>
        <tag>signal and system</tag>
        <tag>δ信号</tag>
      </tags>
  </entry>
  <entry>
    <title>信号与系统 简介</title>
    <url>/2006/07/01/signal_and_system_introduction/</url>
    <content><![CDATA[简介定义
信号：一个或多个自变量的函数，这些变量携带了某些信息，是传递信息的物质载体，表现形式
系统：通常用来处理信号，由若干相互作用和相互依赖的事物组合而成的具有特定功能的整体
相互作用：
信号是促使系统发生变化，或者系统之间相互联系的作用量
系统是对信号进行采集、传输处理、存储等操作功能，能够对于输入信号产生相应的输出



维度
一维信号：正余弦波形
二维信号：图像

连续特性
连续时间函数 ： 随时间联系
离散时间函数 ： 只有某些时间点有值

变化特性
线性时不变系统 ： LTI
线性时变系统

系统系统的定义框图

连接
串行系统
并行系统
反馈系统

域
时域：time domain
x(t)
x(n)


频域：frequency domain
傅里叶变换
拉普拉斯变换
z变换



参考
奥本海姆《信号与系统》
郑君里 《信号与系统》
王文渊 《信号与系统》
清华大学自动化系卓晴“信号与系统”视频
卢光跃《数字信号处理及应用》

代码参考 https://www.github.com/shaoguangleo/signal_and_system
]]></content>
      <categories>
        <category>信号与系统</category>
        <category>Signal and System</category>
      </categories>
      <tags>
        <tag>signal</tag>
        <tag>system</tag>
      </tags>
  </entry>
  <entry>
    <title>LTI系统时域分析</title>
    <url>/2006/07/04/signal_and_system_lti/</url>
    <content><![CDATA[LTI系统时域分析
用脉冲表示离散时间信号
离散时间LTI系统对单位脉冲$\delta[n]$的响应$h(n)$称为离散时间LTI系统的单位脉冲响应。

时间阈分析方法直接分析时间变量的函数，研究系统的时间相应特性，或者成为时域特性。
系统分析的一般过程：
通过实际物理系统或者系统框图构建模型，求解该模型，并进行分析。
方程求解经典求解
微分方程 $\sum_{k=0}^{N} a_{k} \frac{\mathrm{d}^{k} y(t)}{\mathrm{d} t^{k}}=\sum_{k=0}^{M} b_{k} \frac{\mathrm{d}^{k} x(t)}{\mathrm{d} t^{k}}$
电路系统
力学系统
系统框图


差分方程 $\sum_{k=0}^{N} a_{k} y[n-k]=\sum_{k=0}^{M} b_{k} x[n-k]$
微分方程离散化
物理系统建立
系统框图建立



解的分析
自由(齐次解，反映系统本身的特性)、强迫（特解，对输入信号的反应）
稳态（时间无限大时，保留下来的部分）、瞬态（时间无限大时，趋于0的部分）
零状态、零输入
零状态：系统在起始条件为零的情况下的系统对于输出信号的输出响应
零输入：系统在没有外部输入信号的情况下，由内部起始条件所产生的响应



卷积和卷积和使用卷积的前提，系统为LTI，并且为零状态响应。

这里还设计到相关的概念，如果是复数，为第二个函数的共轭，所以不具备交换律。

特性
交换律
分配律
结合律
积分 $\int_{-\infty}^{t}[x(\tau) * h(\tau)] \mathrm{d} \tau=x(t) * \int_{-\infty}^{t} h(\tau) \mathrm{d} \tau=\left[\int_{-\infty}^{t} x(\tau) \mathrm{d} \tau\right] * h(t)$
微分 $\frac{\mathrm{d}}{\mathrm{d} t}[x(t) * h(t)]=x(t) * \frac{\mathrm{d}}{\mathrm{d} t} h(t)=\frac{\mathrm{d}}{\mathrm{d} t} x(t) * h(t)$
延时计算 若$x(t) * h(t) = y(t)$， 则$x(t-t_1) * h(t-t_2) = y(t-t_1-t_2)$

应用滤波信号中的噪声往往造成信号在真实值附近的快速拨动，可以通过对该时刻附近的取值进行加权平均达到去噪的目的。这个过程可以看做将信号与平滑滤波函数的卷积过程。
参考代码参考 https://www.github.com/shaoguangleo/signal_and_system
]]></content>
      <categories>
        <category>信号与系统</category>
        <category>Signal and System</category>
      </categories>
      <tags>
        <tag>function</tag>
        <tag>signal</tag>
        <tag>system</tag>
        <tag>graph</tag>
        <tag>signal and system</tag>
      </tags>
  </entry>
  <entry>
    <title>采样定理</title>
    <url>/2006/08/08/signal_and_system_sampling/</url>
    <content><![CDATA[采样定理对连续时间信号$x_a(t)$以间隔T对它进行等间隔采样，得到的采样信号$\hat{x}{\mathrm{a}}(t)$的频谱$\hat{X}{\mathrm{a}}(\mathrm{j} \Omega)$是原模拟信号$x_a(t)$的频谱 $X_a(j\Omega)$ 以 $\Omega_s(\Omega_s=2\pi f)_s$为周期进行周期延拓而成的。
设连续时间信号$x_a(t)$是一个带限模拟信号，其频谱的最高频率为 $f_c$，上述采样信号$\hat{x}_a(t)$只有在采样频率 $f_s(f_s=1/T)≥2 f_c$时，才可不失真地恢复$x_a(t)$，否则会造成采样信号中的频谱混叠现象，不可能无失真地恢复原模拟信号。一般称 $f_s/2$为折叠频率，只要信号的最高频率不超过该频率，就不会出现频谱混叠现象，否则超过 $f_s/2$的频谱会“折叠”回来形成混叠现象。
通常把最低允许的采样频率 $f_s=2f_c$称为奈奎斯特（Nyquist）频率，最大允许的采样间隔T称为奈奎斯特间隔。
参考代码参考 https://www.github.com/shaoguangleo/signal_and_system
]]></content>
      <categories>
        <category>信号与系统</category>
        <category>Signal and System</category>
      </categories>
      <tags>
        <tag>signal</tag>
        <tag>system</tag>
      </tags>
  </entry>
  <entry>
    <title>信号的表示方法</title>
    <url>/2006/07/02/signal_and_system_signal/</url>
    <content><![CDATA[信号的表示方法信号是带有信息（比如语言、音乐、图像、数据等等）的随着时间（和空间）变换的物理量或者物理现象，其图像称为信号的波形。
信号的时间特性即为信号随着信号变化快慢的特性，体现为信号的周期和信号中单个脉冲的持续时间及上升时间和下降时间的不同。
信号有四种方法的表现形式，如下所示：

函数
图形、波形
变换域表示
分配函数

举个例子如下，比如函数的形式为(包含三个频率，分别为200，300和400Hz)：
$y = 2 \times sin(2\times\pi \times 200 \times x) + 3 \times sin(2\times\pi \times 300 \times x) + 4 \times sin(2\times\pi \times 400 \times x) $
而图形的形式如下，在我们从0到1进行100个采样点的时候，如下：

多进行一些采样设置，如下图：

可知在不同的采样率上，展示的图形也是不同的。这里的主要原因为按照奈奎斯特采样定理，采样点数至少为400Hz的2倍，即800Hz，即在1s内采样800个点，我们再来绘制一幅图，采样更多的点数。

由图可知，在采样点数超过800后，采样的图形基本一致，所以低于800点的采样其实无法还原原始函数或者图形的。
频域表示信号的频率特性可以由频谱来描述。
比如有一个信号如下：
$Y=A1+A2cos(2\piω2+φ2）+A3cos(2\piω3+φ3）+A4*cos(2\piω4+φ4）$
经过FFT之后，得到的“振幅图”中，
第一个峰值（频率位置）的模是A1的N倍，N为采样点，
第二个峰值（频率位置）的模是A2的N/2倍，N为采样点，
第三个峰值（频率位置）的模是A3的N/2倍，N为采样点，
第四个峰值（频率位置）的模是A4的N/2倍，N为采样点，
依次下去……
进行归一化处理，既然第一个峰值是A1的N倍，那么将每一个振幅值都除以N即可
FFT具有对称性，一般只需要用N的一半，前半部分即可。

其实fft都是离散的一些点，如果不使用连线，可以得到如下图像：

参考代码参考 https://www.github.com/shaoguangleo/signal_and_system
]]></content>
      <categories>
        <category>信号与系统</category>
        <category>Signal and System</category>
      </categories>
      <tags>
        <tag>function</tag>
        <tag>signal</tag>
        <tag>system</tag>
        <tag>graph</tag>
        <tag>signal and system</tag>
      </tags>
  </entry>
  <entry>
    <title>信号的变化</title>
    <url>/2006/07/03/signal_and_system_signal_change/</url>
    <content><![CDATA[信号的变化这里主要看看信号的倍乘放大、缩小以及反转的效果。

参考代码参考 https://www.github.com/shaoguangleo/signal_and_system
]]></content>
      <categories>
        <category>信号与系统</category>
        <category>Signal and System</category>
      </categories>
      <tags>
        <tag>function</tag>
        <tag>signal</tag>
        <tag>system</tag>
        <tag>graph</tag>
        <tag>signal and system</tag>
      </tags>
  </entry>
  <entry>
    <title>信号的分类</title>
    <url>/2006/07/03/signal_and_system_signal_classify/</url>
    <content><![CDATA[信号的分类确定性信号 与 随机信号按照函数值的确定性。

确定性信号：在任意时刻都有确定的取值 （一般为人工设计）
随机信号：每一刻取值都为随机



连续时间信号 与 离散时间信号按照信号按照时间是否连续。

连续时间函数 ： 随时间联系
离散时间函数 ： 只有某些时间点有值

按照自变量和函数取值的情况，分为：

模拟信号：信号的自变量和函数值的幅值连续
离散时间信号：信号只能在规定的离散点取值，自变量的取值离散，而函数值是连续的
数字信号：函数值和自变量的幅值均离散

模拟信号的数字处理方法就是将待处理的模拟信号经过采样、量化和编码形成数字信号。
能量信号 与 功率信号根据能量的特性。

连续功率信号 $P=\lim {T \rightarrow \infty} \frac{1}{T} \int{-\frac{T}{2}}^{-\frac{1}{2}}|f(t)|^{2} d t$
连续能力信号 $E=\int_{-\infty}^{\infty}|f(t)|^{2} d t$
离散功率信号 $P=\lim {n \rightarrow \infty} \frac{1}{2 N+1} \sum{n=-N}^{N}|x[n]|^{2}$
离散能量信号 $E=\sum_{n=\infty}^{\infty}|x[n]|^{2}$

周期信号 与 非周期信号确定信号按照函数值的重复性来区分。
$f(t)=f(t+\delta t)$
周期信号的复合可能是周期信号也可能是非周期信号。
参考代码参考 https://www.github.com/shaoguangleo/signal_and_system
]]></content>
      <categories>
        <category>信号与系统</category>
        <category>Signal and System</category>
      </categories>
      <tags>
        <tag>function</tag>
        <tag>signal</tag>
        <tag>system</tag>
        <tag>graph</tag>
        <tag>signal and system</tag>
      </tags>
  </entry>
  <entry>
    <title>离散时间信号</title>
    <url>/2006/07/07/signal_and_system_signal_discrete/</url>
    <content><![CDATA[离散时间信号在对模拟信号与系统进行时域分析时，信号用连续时间函数表示，系统则用微分方程描述；在进行频域分析时，往往采用傅里叶变换或拉普拉斯变换方法。
Z变换在离散时间信号与LTI系统分析中扮演的作用，正如拉普拉斯变换在连续时间信号与LTI系统分析中扮演的作用一样。
单位采样序列单位采样序列Unit Sample Sequence，表示为$\delta(n)$，定义如下所示：
$\delta(n)=\left{\begin{array}{ll}{1,} &amp; {n=0} \{0,} &amp; {n \neq 0}\end{array}\right.$
即单位采样序列除了在n=0处的值为1外，其他处的值均为0，也称其为单位脉冲序列。

单位阶跃序列单位阶跃序列Unit Step Sequence，表示为$u(n)$，定义如下所示：
$u(n)=\left{\begin{array}{ll}{1,} &amp; {n=0} \{0,} &amp; {n \neq 0}\end{array}\right.$
$u(n-m)$在n&gt;=m时值为1，取其他值时为0。

由上图可以知道，单位采样序列和单位阶跃序列的关系为：
$\delta(n)=u(n)-u(n-1)$
$u(n)=\sum_{l=0}^{\infty} \delta(n-l)$
矩形序列只有其中一部分为1，其他部分全部为0，如下图所示：

指数序列指数的底数在大于1时为发散序列，小于1时为收敛序列


正弦序列
复指数序列$x(n)=\mathrm{e}^{\mathrm{j} \omega n}=\cos (\omega n)+\mathrm{i} \sin (\omega n)$
根据欧拉公式可知，复指数序列具有以2$\pi$为周期的周期性。
周期信号如果对所有的n，存在一个最小的正整数N，使关系式x(n)=x(n+N)成立，则称x(n)是周期为N的周期序列（Periodic Sequence），周期信号也可记为。
序列的运算包括：

加法
减法
移位
反转
尺度变换

参考代码参考 https://www.github.com/shaoguangleo/signal_and_system
]]></content>
      <categories>
        <category>信号与系统</category>
        <category>Signal and System</category>
      </categories>
      <tags>
        <tag>function</tag>
        <tag>signal</tag>
        <tag>system</tag>
        <tag>graph</tag>
        <tag>signal and system</tag>
      </tags>
  </entry>
  <entry>
    <title>信号的分解</title>
    <url>/2006/07/03/signal_and_system_signal_divide/</url>
    <content><![CDATA[信号的分解直流分量 与 交流分量
偶分量 与 奇分量
实分量 与 虚分量脉冲分量周期信号级数分解复指数信号分解参考代码参考 https://www.github.com/shaoguangleo/signal_and_system
]]></content>
      <categories>
        <category>信号与系统</category>
        <category>Signal and System</category>
      </categories>
      <tags>
        <tag>function</tag>
        <tag>signal</tag>
        <tag>system</tag>
        <tag>graph</tag>
        <tag>signal and system</tag>
      </tags>
  </entry>
  <entry>
    <title>系统</title>
    <url>/2006/07/02/signal_and_system_system/</url>
    <content><![CDATA[信号的建模系统是由互相关联的单元组合而成的具有某种功能以用来达到某些特定目的的有机整体。
系统的功能是对输入的信号进行“加工”以及“处理”并输出信号。
系统物理特性的数学抽象，以数学表达式或具有理想特性的符号组合图形来表示系统特性。
可以通过电路、数学方程和方框图来表达。

微分方程差分方程线性时不变系统的直接描述方法是用单位脉冲响应进行的；而描述系统输入和输出之间的关系则利用差分方程Difference Equation实现。
求解差分方程的基本方法有以下3种。

经典解法：这种方法类似于模拟系统中求解微分方程的方法，它包括齐次解与特解，由边界条件求待定系数，但较麻烦，实际中很少采用。
递推解法：这种方法简单，且适合于用计算机求解，但只能得到数值解，对于阶次较高的线性常系数差分方程不容易得到封闭解。
变换域方法：这种方法是将差分方程变换到Z域进行求解，方法简单有效。

子系统互联
串联或级联
并联
反馈连接
复合或混合连接

参考代码参考 https://www.github.com/shaoguangleo/signal_and_system
]]></content>
      <categories>
        <category>信号与系统</category>
        <category>Signal and System</category>
      </categories>
      <tags>
        <tag>function</tag>
        <tag>signal</tag>
        <tag>system</tag>
        <tag>graph</tag>
        <tag>signal and system</tag>
      </tags>
  </entry>
  <entry>
    <title>离散时间系统</title>
    <url>/2006/07/07/signal_and_system_system_discrete/</url>
    <content><![CDATA[离散时间系统设系统的输入为序列x(n)，经过运算或变换得到一个输出序列y(n)，这个运算或者变换就是离散时间系统（Discrete time System）。
齐次性若$x(t) -&gt; y(t)$，则$kx(t) -&gt; ky(t)$
叠加性若$x_1(t) -&gt; y_1(t), x_1(t) -&gt; y_1(t)$，则$x_1(t) + x_2(t) -&gt; y_1(t) + y_2(t)$
线性系统满足叠加性和齐次性。
若$x_1(t) -&gt; y_1(t), x_1(t) -&gt; y_1(t)$，则$k_1x_1(t) + x2(t) -&gt; y_1(t) + y_2(t)$
时不变系统如果系统的输出相应随输入的移位而移位，即为时不变系统。
若$x(t) -&gt; y(t)$，则$x(t-t_0) -&gt; y(t-t_0)$
因果性指系统的响应不应该出现在激励之前，只对自变量是时间的系统有意义。
参考代码参考 https://www.github.com/shaoguangleo/signal_and_system
]]></content>
      <categories>
        <category>信号与系统</category>
        <category>Signal and System</category>
      </categories>
      <tags>
        <tag>function</tag>
        <tag>signal</tag>
        <tag>system</tag>
        <tag>graph</tag>
        <tag>signal and system</tag>
      </tags>
  </entry>
  <entry>
    <title>系统的分类</title>
    <url>/2006/07/03/signal_and_system_system_classify/</url>
    <content><![CDATA[系统的分类连续时间系统 与 离散时间系统
连续时间系统：输入、输出、系统内部信号都是模拟信号
离散时间系统：输入、输出信号都是序列的系统

按照输入输出信号的类型，分为：

模拟系统
离散时间系统
数字系统

即时系统 与 动态系统根据有没有储能元件来区分

即时系统：无记忆系统，系统的输出只与当时时刻的输入有关，与其他时刻的输入无关，用代数方程描述
动态系统：记忆系统，系统的输出不只与当前时刻的输入有关，用微分方程或者差分方程描述

线性系统 与 非线性系统如果一个系统既满足叠加性也满足齐次性就称为线性系统，否则为非线性系统。
时变系统 与 时不变系统如果一个系统当输入信号有一个时移时，输出相应也有一个对应的时移，信号的波形并不发生变化为时不变系统。反之即为时变系统。
可逆系统 与 不可逆系统如果一个系统对任何不同的输入都能产生不同的输出，即输入与输出是一一对应的关系，这称为可逆系统，否则为不可逆系统。
因果系统 与 非因果系统如果一个系统的任何时刻的输出只与当时这个时刻的输入以及以前的输入有关，而和该时刻以后的输入无关，称为因果系统，否则为非因果系统。
稳定系统 与 非稳定系统
稳定系统：BIBO（Bound Input Bound Output）及输入有界时，产生的输出也是有界的，反之为非稳定系统

参考代码参考 https://www.github.com/shaoguangleo/signal_and_system
]]></content>
      <categories>
        <category>信号与系统</category>
        <category>Signal and System</category>
      </categories>
      <tags>
        <tag>function</tag>
        <tag>signal</tag>
        <tag>system</tag>
        <tag>graph</tag>
        <tag>signal and system</tag>
      </tags>
  </entry>
  <entry>
    <title>系统的频域分析</title>
    <url>/2006/07/08/signal_and_system_system_frequency_domain/</url>
    <content><![CDATA[系统的频域分析传输函数与系统函数$H(e^{jω})$称为系统的传输函数（或系统频率响应函数），它表征系统的频率特性；$H(z)$称为系统的系统函数，它表征系统的复频率特性。
如果$H(z)$的收敛域包含单位圆z=1，则$H(z)$与$H(e^{jω})$的关系如下所示：
$H\left(\mathrm{e}^{\mathrm{j} \omega}\right)=\left.H(z)\right|_{z=\mathrm{e}^{\mathrm{j\omega}}}$
参考代码参考 https://www.github.com/shaoguangleo/signal_and_system
]]></content>
      <categories>
        <category>信号与系统</category>
        <category>Signal and System</category>
      </categories>
      <tags>
        <tag>function</tag>
        <tag>signal</tag>
        <tag>system</tag>
        <tag>graph</tag>
        <tag>signal and system</tag>
      </tags>
  </entry>
  <entry>
    <title>Z变换</title>
    <url>/2006/08/07/signal_and_system_zt/</url>
    <content><![CDATA[Z变换在离散时间傅里叶分析中，将复指数信号$e^{j \omega n}$作为基本信号单元。然而，对于不满足绝对可和的信号，其傅里叶变换不存在，无法实现对其的频域分析。若把复指数信号$e^{j \omega n}$扩展为信号$z^n（z=re^{j\omega}）$，就有可能对其进行复频域分析，此时就得到信号的Z变换，显然，Z变换是离散时间傅里叶变换的推广，离散时间傅里叶变换是Z变换的特例。
在求解系统的差分方程时，如果系统的起始状态为0，而且激励信号是因果系统，则可以用单边或者双边Z变换来求解；如果系统起始状态不为0，或者激励信号不是因果信号，则只能用单边Z变换来求解。
零输入响应由系统起始状态确定，而与系统激励无关；零状态响应由系统激励信号确定，而与系统起始状态无关；完全响应等于零输入响应及零状态响应之和。
参考代码参考 https://www.github.com/shaoguangleo/signal_and_system
]]></content>
      <categories>
        <category>信号与系统</category>
        <category>Signal and System</category>
      </categories>
      <tags>
        <tag>signal</tag>
        <tag>system</tag>
        <tag>dft</tag>
        <tag>discrete fourier transform</tag>
        <tag>DFT</tag>
        <tag>ZT</tag>
        <tag>Z变换</tag>
      </tags>
  </entry>
  <entry>
    <title>Sublime Text 的 Package Control 安装使用</title>
    <url>/2017/09/01/sublime-package-control/</url>
    <content><![CDATA[package control不得不说，sublime是一个神器，并且支持N多扩展和插件。
其中Package Control包管理插件就特别赞。
支持添加／删除／禁用／查找插件的功能。
安装方法参考 https://packagecontrol.io/installation
命令行打开sublime如果是在默认shell下,
sudo ln -s "/Applications/Sublime\ Text.app/Contents/SharedSupport/bin/subl" /usr/bin/subl

使用zsh的可以使用以下命令
alias subl="'/Applications/Sublime Text.app/Contents/SharedSupport/bin/subl'"alias nano="subl"export EDITOR="subl"
]]></content>
      <categories>
        <category>Sublime</category>
      </categories>
      <tags>
        <tag>sublime</tag>
        <tag>package control</tag>
      </tags>
  </entry>
  <entry>
    <title>Swift 简介</title>
    <url>/2016/09/03/swift-1-introduction/</url>
    <content><![CDATA[REPL执行下面的命令可以进入Swift的交互终端。
$ xcrun swiftWelcome to Apple Swift version 3.1 (swiftlang-802.0.53 clang-802.0.42). Type :help for assistance.  1&gt;  

然后可以输入:help打印帮助信息，:quit来退出交互环境。
常量 与 变量let x = 12 // 常量var y = 12.3 // 常量

类型


类型
特征



Bool
true或者false


Int/Int32/Int64
32/64位整数


Int8/Int16
8/16位整数


UInt/UInt32/UInt64
32/64位正整数


UInt8/UInt16
8/16位正整数


Float/Double
可正可负的浮点数


Character
用双引号括起的单个字符、数字或者其他符号


String
用双括号括起的一系列字符


检查上限和下限15&gt; Int8.max$R3: Int8 = 12716&gt; Int16.max$R4: Int16 = 3276717&gt; UInt8.max$R5: UInt8 = 255

显式地声明类型22&gt; var number : Double = 3number: Double = 3

数值表示各种进制48&gt; let b = 0b110 // 二进制b: Int = 649&gt; let b = 0o11  // 八进制b: Int = 950&gt; let b = 0x11  // 十六进制

大数字表示法53&gt; let big = 1_000_000_000big: Int = 1000000000

轻松显示59&gt; let city = "shanghai"city: String = "shanghai"60&gt; let food = "noodle"food: String = "noodle"61&gt; let restaurant = "KFC"restaurant: String = "KFC"62&gt; let year = 5year: Int = 563&gt; print ("When I visited \(city) \(year) years ago, I went to \(restaurant) and ordered \(food)")When I visited shanghai 5 years ago, I went to KFC and ordered noodle
使用类型别名72&gt; typealias EightBits = UInt873&gt; var reg : EightBits = 0reg: EightBits = 074&gt; typealias NewBits = UInt875&gt; var reg : NewBits = 0reg: NewBits = 0

元祖79&gt; let car = (2014,"Mercedes-Benz","S-Class")car: (Int, String, String) = { 0 = 2014 1 = "Mercedes-Benz" 2 = "S-Class"}80&gt; car.0$R28: Int = 201481&gt; car.1$R29: String = "Mercedes-Benz"82&gt; car.2$R30: String = "S-Class"

可选类型在swift显示的类型说明中，有一个问号，可以表明变量的类型是可选类型。
83&gt; var s="123"s: String = "123"84&gt; Int(s)$R31: Int? = 12385&gt; var s="abc"s: String = "abc"86&gt; Int(s)$R32: Int? = nil
]]></content>
      <categories>
        <category>Swift</category>
      </categories>
      <tags>
        <tag>swift</tag>
        <tag>repl</tag>
        <tag>xcrun</tag>
        <tag>let</tag>
        <tag>var</tag>
        <tag>typealias</tag>
      </tags>
  </entry>
  <entry>
    <title>Swift 集合</title>
    <url>/2016/09/03/swift-2-set/</url>
    <content><![CDATA[数组93&gt; let color = ["red","orange","yellow","green"]color: [String] = 4 values { [0] = "red" [1] = "orange" [2] = "yellow" [3] = "green"}94&gt; color[0]$R36: String = "red"95&gt; color[1]$R37: String = "orange"96&gt; color[2]$R38: String = "yellow"97&gt; color[3]$R39: String = "green"

字典126&gt; var dict = ["name":"hello", "age":"10", "sex":"Female"]dict: [String : String] = 3 key/value pairs { [0] = {   key = "name"   value = "hello" } [1] = {   key = "age"   value = "10" } [2] = {   key = "sex"   value = "Female" }}
数组的数组var array [String : [String]]

创建空数组142&gt; var empty_array : Array&lt;Int&gt; = []empty_array: [Int] = 0 values143&gt; var empty_array = [Int]()empty_array: [Int] = 0 values

创建空字典151&gt; var empty_dictionary = Dictionary&lt;String,Double&gt;()empty_dictionary: [String : Double] = 0 key/value pairs
]]></content>
      <categories>
        <category>Swift</category>
      </categories>
      <tags>
        <tag>swift</tag>
        <tag>let</tag>
        <tag>var</tag>
      </tags>
  </entry>
  <entry>
    <title>Swift 流程控制</title>
    <url>/2016/09/04/swift-3-flow-control/</url>
    <content><![CDATA[for 循环及指定范围语法167&gt; for i in 0...5 { print (i) }012345

游乐场对于REPL，测试简单的代码是绰绰有余的，但是对于比较复杂一点的就需要使用Xcode的新特性游乐场了playground。
]]></content>
      <categories>
        <category>Swift</category>
      </categories>
      <tags>
        <tag>swift</tag>
      </tags>
  </entry>
  <entry>
    <title>ubuntu10.4的更新源因过期无法更新的解决方法</title>
    <url>/2016/09/06/ubuntu-old-release-update/</url>
    <content><![CDATA[ubuntu10.4到2016年早已停止了更新支持，ubuntu也不再维护了。官方源以及第三方源包括163，sohu等也不再维护。那是不是意味着这个版本的ubuntu只能放弃使用？
当然不是的！！！
为了解决这个问题，ubuntu提供了old-release的方案，通过命令行更新源如下：
sudo gedit /etc/apt/sources.list

打开源列表文件，把里面的地址全删除，然后换上如下的地址，如果你是其他版本的，把lucid替换即可。
deb http://old-releases.ubuntu.com/ubuntu lucid main restricted universe multiverse   deb http://old-releases.ubuntu.com/ubuntu lucid-security main restricted universe multiverse   deb http://old-releases.ubuntu.com/ubuntu lucid-updates main restricted universe multiverse   deb http://old-releases.ubuntu.com/ubuntu lucid-proposed main restricted universe multiverse   deb http://old-releases.ubuntu.com/ubuntu lucid-backports main restricted universe multiverse   deb-src http://old-releases.ubuntu.com/ubuntu lucid main restricted universe multiverse   deb-src http://old-releases.ubuntu.com/ubuntu lucid-security main restricted universe multiverse   deb-src http://old-releases.ubuntu.com/ubuntu lucid-updates main restricted universe multiverse   deb-src http://old-releases.ubuntu.com/ubuntu lucid-proposed main restricted universe multiverse   deb-src http://old-releases.ubuntu.com/ubuntu lucid-backports main restricted universe multiverse  

然后再运行
sudo apt-get update。

Enjoy.
]]></content>
      <categories>
        <category>Linux</category>
        <category>Ubuntu</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>ubuntu</tag>
        <tag>update</tag>
        <tag>lucid</tag>
      </tags>
  </entry>
  <entry>
    <title>Ubuntu 问题集锦</title>
    <url>/2013/12/03/ubuntu-troubleshooting/</url>
    <content><![CDATA[Ubuntu 问题集锦perl: warning: Setting locale failed有时apt-get install的时候，会出现下面的错误：
perl: warning: Setting locale failed.perl: warning: Please check that your locale settings:       LANGUAGE = “en_US:en”,       LC_ALL = (unset),       LC_CTYPE = “en_US.UTF-8”,       LC_COLLATE = “en_US.UTF-8”,       LC_MESSAGES = “en_US.UTF-8”,       LANG = “en_US”    are supported and installed on your system.perl: warning: Falling back to the standard locale (“C”).

解决方法上面也有了提示就是：Falling back to the standard locale。所以解决办法是：：
vi /root/.bashrc
在最底部添加上一句
export LC_ALL=C
或者直接运行
#echo “export LC_ALL=C” &gt;&gt; /root/.bashrc
然后执行一下：
source /root/.bashrc
其中LC_ALL=C 是为了去除所有本地化的设置，让命令能正确执行。
修改ubuntu命令行语言环境ubuntu 安装时候选择的是中文环境，但是其实中文支持不是很完全，在使用ssh连接上后发现一些中文在securecrt中显示是乱码，所以还是改回英文方便点
修改Ubuntu的命令行语言环境的2个步骤：
1、修改/etc/default/locale
如不存在则新建一个
如下：
LANG=’en_US’ #中文可以用zh_CNLANGUAGE=’en_US:en’ #中文可以用zh_CN:zh

2、reboot即可
locale命令可以列出当前系统所用的所有语言设置
]]></content>
      <categories>
        <category>Linux</category>
        <category>Ubuntu</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>locale</tag>
        <tag>ubuntu</tag>
        <tag>perl</tag>
      </tags>
  </entry>
  <entry>
    <title>Vim高级导航</title>
    <url>/2011/01/02/vim-advance-navigate/</url>
    <content><![CDATA[Vim高级导航屏幕导航移动光标到屏幕的顶部、中间和底部，如下说明：

H    移动到当前屏幕的第一行
M    移动到当前屏幕的中间行
L     移动到当前屏幕的最后一行

重画在顶部、底部或者中间的当前行的屏幕
z   重画屏幕顶部光标位置的当前行的屏幕
z-（小写z和减号）    重画屏幕底部光标位置的当前行的屏幕
z.(小写z和点号)  重画屏幕中间光标位置的当前行的屏幕

导航到文件的开始和结束
:0    移动到文件的顶部–方法1
gg   移动到文件的顶部–方法2
1G   移动到文件的顶部–方法3
:$    移动到文件的底部–方法1
G     移动到文件的底部–方法2

导航到文件的第N个字符或百分之N处
50%       移动到文件的50%处，跳转到文件的中间
75%       移动到文件的75%处，跳转到文件的3/4处
100l       导航键是100后面跟l，从当前位置移动100字符
100       导航键是100后面跟空格

另外一种方法从当前位置移动100个字符

:goto 25       移动到文件开始位置的第25个字符处
25|  导航键是25后面跟管道符，移动到当前行中的25个字符处

行号导航
:set number
:set nu   显示行号
:set nonumber
:set nonu     不显示行号
:set numberwidth=5 缺省的行号宽度为4个字符，使用numberwith可以改变为5个字符
:50  移动到第50行
50gg      另一种跳转到第50行的方法
50G 另一种跳转到第50行的方法

源代码导航
%    移动到匹配的字符对处，跳转到匹配的括号()，或者大括号{}或方括号[]处。
[(     移动到前一个不匹配的左括号(
[)     移动到前一个不匹配的右括号)
[{     移动到前一个不匹配的左大括号(
[}     移动到前一个不匹配的右大括号)

从插入模式下导航
SHIFT-      在插入模式下逐个单词的向右移动
SHIFT-  在插入模式下逐个单词的向左移动

]]></content>
      <categories>
        <category>Vim</category>
      </categories>
      <tags>
        <tag>vim</tag>
        <tag>navigate</tag>
      </tags>
  </entry>
  <entry>
    <title>Vim 补全</title>
    <url>/2011/01/02/vim-auto-completion/</url>
    <content><![CDATA[vim 补全自动文件名补全使用快捷键“CTRL-X CTRL-F”插入当前用户可以看到的Linux系统中任何文件名。
CTRL-X CTRL-F



自动行补全如果你希望插入一个已有行的拷贝，输入行的前几个词/字符串，然后输入Vim快捷键“CTRL-X CTRL-L”，它会显示所有符合模式的行。
CTRL-X CTRL-L



自动补全单词在Vim中使用CTRL-X你可以在插入或者添加模式下执行自动补全单词功能。通过输入词的前几个字符，你可以从字典、同义词字典或者编辑文件中已经出现的关键词中获得整个单词。
你可以使用下面的Vim快捷键来选择指定关键词的已有的扩展形式。



键
描述



CTRL-X CTRL-N
关键词的自动完成–向前


CTRL-X CTRL-P
关键词的自动完成–向后


词典补全首先在~/.vimrc中设置: set dictionary+=/usr/share/dict/words
然后使用CTRL-X CTRL-K 就可以搜索到符合词典中单次的项。
同义词补全​      这个功能可以使得使用vim会变得更高效。使能一个同义词的方法：

定义一个同义词文件，比如：在文件/home/leo/mythesaurus.txt中输入important,valuable,substantial,significant；

然后在~/.vimrc中添加该文件路径，即:set thesaurus+=/home/leo/mythesaurus.txt；

使用方法为：CTRL-X CTRL-T，在我们输入important的时候就会出现valuable等剩下的三个单词；


相比较与自己定义一个同义词文件，我们可以下载自定义好的巨大（moby）单词量的thesaurus，方法为：
wget http://www.gutenberg.org/dirs/etext02/mthes10.zip$ unzip mthes10.zipArchive: mthes10.zipinflating: aaREADME.txtinflating: roget13a.txtinflating: mthesaur.txt



然后把mtheaur.txt添加到vimrc中，
set thesaurus+=/home/jsmith/mthesaur.txt
程序员如何使用该项特性​      比如PHP程序需要，就可以创建一个php-function.txt文件并添加到vimrc文件中，比如文件内容为：
math abs acos acosh asin asinh atan atan2 atanh
base_convert bindec ceil cos
errors debug_backtrace debug_print_backtrace
error_get_last error_log error_reporting
restore_error_handler
自动打开一个补全的弹出菜单首先要下载autocomplpop.vim
mkdir –p ~/.vim/plugincd ~/.vim/pluginwget –O autocomplpop.zip http://www.vim.org/scripts/download_script.php?src_id=11894开启filetype plugin on





默认情况下，安装了该插件以后，弹出菜单会在我们输入单词的时候自动显示，而不再需要我们输入命令，这种情况同样适用于文件名的自动补全，还可以提供对omni tags标记的支持，比如在输入HTML、XHTML、CSS、Ruby和Python代码的时候，例如输入后在输入&lt;/就会自动弹出body&gt;。
自动提供单词的补全首先需要安装word_complete.vim插件。
两种开启自动补全插件的方法：

在使用vim打开文件后，输入:call DoWordComplete()即可；

在vimrc中文件中，添加:autocmd BufEnter * call DoWordComplete()即可。


如果想禁用该特性，使用:call EndWordComplete()即可。
在输入的过程中，如果弹出的单词所示我们需要的，直接输入TAB即可，如果不是，那么我们只需要继续输入即可匹配。
]]></content>
      <categories>
        <category>Vim</category>
      </categories>
      <tags>
        <tag>auto</tag>
        <tag>completion</tag>
      </tags>
  </entry>
  <entry>
    <title>Vim书签命令的快速总结</title>
    <url>/2011/02/04/vim-bookmark/</url>
    <content><![CDATA[Vim书签命令的快速总结
ma – 创建一个书签a
`a –跳转到书签a的精确位置（行和列）
‘a – 调整到书签a所在行的起始位置
:marks — 显示所有的书签；
:marks a – 显示名称为a书签的详细信息；
`. – 跳转到最后一次执行改变的精确位置（行和列）。
‘. – 跳转到最后一次执行改变的行起始位置。

如果书签名称为大写字符，那么它就是一个全局书签。
如何显示所有书签如果你创建几个书签，忘记了它们的名称，你可以很容易的获得书签列表，输入:marks，显示如下：
:marks
除了局部书签、全局书签以外，在Vim内部任何时候输入:marks，你可以获得下面几行。这些标识‘单引号，”双引号，[，]，^和.点号由Vim创建和管理。你不需要直接控制它们。
:marks
你可以使用上面显示的缺省标识，如下：



缺省标识
描述



`”
到退出之前最后一次编辑的位置


`[
到先前改变或者复制文本的第一个字符


`]
到先前改变或复制文本的最后一个字符


‘&lt;
到先前选择可视化区域的第一行


‘&gt;
到先前选择可视化区域的最后一行


‘.
到最后一次该标的位置


‘^
到最后一次插入模式停止的光标所在位置


]]></content>
      <categories>
        <category>Vim</category>
      </categories>
      <tags>
        <tag>Vim</tag>
        <tag>bookmark</tag>
        <tag>marks</tag>
      </tags>
  </entry>
  <entry>
    <title>Vim改变大小写</title>
    <url>/2011/03/22/vim-case/</url>
    <content><![CDATA[改变大小写Vim中使用下面的方法改变文本的大小写。



CTRL键
描述



~
正常模式：改变光标下的字符的大小写，移动到下一个字符上;如果你继续按下~，你会继续一个个的改变字符直到行的结束;可视化模式：这回改变所有高亮显示的文本


5~
改变下5个字符的大小写


g~{motion-key}
改变从光标到整个指定移动位置的字符的大小写


g~~
改变整个当前行的大小写


gUU
改变整个行文本为大写


guu
改变整个当前行的文本为小写


gUaw
改变当前词为大写


guaw
改变当前词为小写


U
可视化模式：改变当前高亮文本为大写


U
可视化模式：改变当前高亮文本为小写


guG
改变从当前位置到文件结束的文本为小写


gUG
改变从当前位置到文件结束的文本为大写


]]></content>
      <categories>
        <category>Vim</category>
      </categories>
      <tags>
        <tag>vim</tag>
        <tag>casesentive</tag>
        <tag>lower</tag>
        <tag>upper</tag>
      </tags>
  </entry>
  <entry>
    <title>Vim 中文乱码</title>
    <url>/2011/11/22/vim-chinese/</url>
    <content><![CDATA[gvim打开中文乱码可以使用:set encoding=gb2312来支持。
]]></content>
      <categories>
        <category>Vim</category>
      </categories>
      <tags>
        <tag>chinese</tag>
        <tag>encoding</tag>
      </tags>
  </entry>
  <entry>
    <title>Vim 改变配置颜色</title>
    <url>/2011/03/22/vim-color/</url>
    <content><![CDATA[改变Vim颜色 首先查看在Vim编辑器中所有可用的颜色方案。
:!ls $VIMRUNTIME/colors



例如：如果你看到在列表中有blue.vim或者evening.vim，你可以改变这些颜色方案，如下：
:colorscheme evening



（或者）
:colorschmeme blue



颜色高亮搜索结果当你搜索一个关键词，你可能希望自动高亮所有符合的单词。使用:hlsearch选择。
为了启用搜索结果高亮
:set hlsearch
在设置之后，当你使用/keyword进行关键词搜索时，在当前文件中的所有匹配的关键词汇自动高亮。



键
描述



:set hlsearch
启用搜索结果高亮显示注意：添加这个到~/.vimrc中永远启用


:set nohlsearch
关闭搜索结果高亮显示


:nohlsearch
清除掉当前的搜索高亮显示


]]></content>
      <categories>
        <category>Vim</category>
      </categories>
      <tags>
        <tag>colorscheme</tag>
        <tag>color</tag>
        <tag>VIMRUNTIME</tag>
        <tag>hlsearch</tag>
      </tags>
  </entry>
  <entry>
    <title>Vim 配置文件</title>
    <url>/2011/03/22/vim-configure/</url>
    <content><![CDATA[Vim 配置文件
在使用vim编辑文件的时候，对vim所作的配置全部只是对当前的会话有效，关闭文件后，配置不再有效；

如果希望对vim的配置永久有效，可以尝试在~/.vimrc中，写入自己的配置文件，也可以将该文件拷贝至不同的Linux 发行版。


对于目前个人账户而言，修改文件为：



操作系统
文件位置



UNIX/Linux
$HOME/.vimrc


Windows
$HOME/_vimrc


对于系统管理员而言，如果想修改对所有的用户都起作用的配置，可以在如下文件中进行修改。



操作系统
文件位置



UNIX/Linux
$VIM/.vimrc


Windows
$ VIM /_vimrc


]]></content>
      <categories>
        <category>Vim</category>
      </categories>
      <tags>
        <tag>vim</tag>
        <tag>configure</tag>
      </tags>
  </entry>
  <entry>
    <title>Vim命令行导航</title>
    <url>/2011/01/22/vim-commandline-navigator/</url>
    <content><![CDATA[Vim命令行导航当从命令行打开一个文件，你可以通过指定命令行参数来导航到一个特殊的位置，如下：



导航键
描述



$ vim +142 
打开文件到143行


$ vim +/search-term 
打开文件移动到向下搜索到指定词语的位置


$ vim +?search-term 
打开文件移动到向上搜索到指定词语的位置


$ vim -t TAG 
移动到指定的TAG处


]]></content>
      <categories>
        <category>Vim</category>
      </categories>
      <tags>
        <tag>search</tag>
      </tags>
  </entry>
  <entry>
    <title>在拷贝行/词/其它之后或之前粘贴</title>
    <url>/2011/02/19/vim-copy-and-paste/</url>
    <content><![CDATA[| 键 |  描述 ||  p（小写的p） | 立即粘贴到当前光标位置之后 || P（大写的P） |  立即粘贴到当前光标位置之前 |
如果你执行几次的删除操作，如果你希望粘贴这些删除的字符，使用下面的方法。
首先，查看寄存器，使用下面的命令：
:reg
最近的删除内容会显示在0-9寄存器中，记下你想粘贴的删除词语的寄存器位置。
如果你想粘贴寄存器标号为N的词组，执行下面命令：
“Np
]]></content>
      <categories>
        <category>Vim</category>
      </categories>
      <tags>
        <tag>register</tag>
        <tag>vim</tag>
        <tag>copy</tag>
        <tag>paste</tag>
      </tags>
  </entry>
  <entry>
    <title>从文件中插入内容到剪切板</title>
    <url>/2011/02/25/vim-copy-content-to-paster-board/</url>
    <content><![CDATA[从文件中插入内容到剪切板你希望把当前文件的文本插入到剪切板中。当你的文笔传输到剪切板上，你可以粘贴它到另外一个应用中。



剪切板拷贝
描述



:%y+
拷贝整个文件到剪切板


:y+
拷贝文件中当前行到剪切板上


:N,My+
拷贝文件中指定范围的行到剪切板中


为了拷贝可视化选择的行到剪切板上，首先可视化选择行，:y+会显示为:’&lt;,’&gt;y+。
在拷贝之后，你可以使用传统的&lt;CTRL+V&gt;操作粘贴这些内容到任意其它应用中。
]]></content>
      <categories>
        <category>Vim</category>
      </categories>
      <tags>
        <tag>vim</tag>
      </tags>
  </entry>
  <entry>
    <title>使用CTRL键来增加和减少数量</title>
    <url>/2011/03/07/vim-ctrl-add-minus-number/</url>
    <content><![CDATA[CTRL+A : 增加数量，将光标放置到vim编辑器上的数字上，然后使用CTRL+A，可以将该数值增加1CTRL+X : 减少数量，将光标放置到vim编辑器上的数字上，然后使用CTRL+A，可以将该数值减少1
其实也可以在数字前面的字符上，可以自行验证一下。
]]></content>
      <categories>
        <category>Vim</category>
      </categories>
      <tags>
        <tag>vim</tag>
      </tags>
  </entry>
  <entry>
    <title>vim中的删除操作大全</title>
    <url>/2011/02/20/vim-delete/</url>
    <content><![CDATA[vim中的删除操作大全删除单个字符、词或者行删除类似于拷贝，然而你必须使用d替代y。



键
描述



x
删除当前字符


dw
删除当前词


dj
删除当前行和下一行


这里应该可以出来以及技巧，x是删除，p是粘贴，所以xp不是系统而是交互两个字符。
VI下删除文本中的^M关于回车与换行
很久以前，老式的电传打字机使用两个字符来另起新行。一个字符把滑动架移回首位 (称为回车,ASCII码为0D)，另一个字符把纸上移一行 (称为换行, ASCII码为0A)。当计算机问世以后，存储曾经非常昂贵。有些人就认定没必要用两个字符来表示行尾。UNIX 开发者决定他们可以用一个字符来表示行尾,linux沿袭Unix，也是如此。而Apple 开发者规定了用r，MS-DOS以及Windows 则继续使用rn表示，所以换行就有了3种方法。
三种行尾格式如下:

unix : n
dos: rn
mac : r

这意味着，如果你试图把一个文件从一种系统移到另一种系统，那么你就有换行符方面的麻烦。
​      因为MS-DOS及Windows是回车＋换行来表示换行，因此在Linux下用Vim查看在Windows下写的代码，行尾后“^M”符号。
在Vim中解决这个问题，很简单，在Vim中利用替换功能就可以将“^M”都删掉，键入如下替换命令行：
:%s/^M//g



 注意：
上述命令行中的“^M”符，不是“^”再加上“M”，而是由“Ctrl+v”、“Ctrl+M”键生成的，或者Ctrl+v，再按回车。
 或者使用这个命令：
:% s/r//g

vim删除包含指定字符串的行在命令模式中，使用如下指令删除包含指定字符串的行：
:g/string/d

vim删除不包含指定字符串的行在命令模式中，使用如下指令删除不包含指定字符串的行：
:v/xxx/d

删除缺失的字符 There is no ‏ (U+200F)$ sed -i "s/$(echo -ne '\u200b')//g" file

或者在vim中如此操作：
%s/\%u200b//



vim删除重复行使用vim内建的功能，如下即可快速在排序后删除重复的行：
:sort u


删除空行  :g/^$/d
删除空行以及只有空格的行  :g/^\s*$/d
删除以 # 开头或 空格# 或 tab#开头的行  :g/^\s*#/d
删除以 ; 开头或 空格; 或 tab;开头的行  :g/^\s*;/d
使用正则表达式删除行
如果当前行包含 hello ，则删除当前行:/hello/d
删除从第二行到包含 hello 的区间行:2,/hello/d
删除从包含 hello 的行到最后一行区间的行:/hello/,$d
删除所有包含 hello 的行:g/hello/d
删除匹配 hello 且前面只有一个字符的行:g/.hello/d
删除匹配 hello 且以它开头的行:g/^hello/d
删除匹配 hello 且以它结尾的行:g/hello$/d
.ini 的注释是以 ; 开始的，如果注释不在行开头，那么删除 ; 及以后的字符:%s/\;.\+//g
删除 # 之后所有字符%s/\#.*//g

Vim 删除所有行的指定字符到每行末尾的字符:%s/ABCD.*$//g  ： 删除所有行的指定字符ABCD到每行末尾的字符
]]></content>
      <categories>
        <category>Vim</category>
      </categories>
      <tags>
        <tag>vim</tag>
        <tag>delete</tag>
      </tags>
  </entry>
  <entry>
    <title>vim .(点)命令的强大功能</title>
    <url>/2011/03/03/vim-dot/</url>
    <content><![CDATA[.(点)命令的强大功能 .(点)命令是简单的，也是强大的。.命令重复最后一次文件内容影响命令。下面的例子说明.命令的使用。

在文件中搜索字符串，使用：/one
使用one替换two，使用：cwone
搜索下一个one出现地方，使用：n
使用two替换one，使用：.(点号)

在上面的例子中，第4步，你不需要再次输入cwtwo。替代的，简单的输入.(点号)，它会执行最后一次改变命令，也就是cwtwo。
]]></content>
      <categories>
        <category>Vim</category>
      </categories>
      <tags>
        <tag>vim</tag>
        <tag>dot</tag>
      </tags>
  </entry>
  <entry>
    <title>在Vim 加密解密文件：</title>
    <url>/2011/03/13/vim-encryption/</url>
    <content><![CDATA[在Vim 加密解密文件有些时候想玩点小把戏，比如加密一下编辑的文件。
:X

当你使用:X加密一个文件时，下一次打开这个文件，Vim会提示你输入加密关键词。
比如编辑文件hello.c，加密之前与之后的文件格式如下所示：
$ file hello.hello.c: C source, ASCII text

加密后可以看到如下信息：
$ file hello.hello.c: Vim encrypted file data
]]></content>
      <categories>
        <category>Vim</category>
      </categories>
      <tags>
        <tag>vim</tag>
        <tag>encryption</tag>
      </tags>
  </entry>
  <entry>
    <title>Vim gVim</title>
    <url>/2011/04/02/vim-gvim/</url>
    <content><![CDATA[关于gvimgVim是Vim的图形前端，它是跨平台的编辑器，基本上主流的操作系统上面都有它的版本。
##显示或隐藏gvim的菜单和工具栏
使用:set guioptions命令。
例如隐藏工具栏*:set guioptions-=T，再次显示工具栏为:set guioptions+=T*



UI元素命令
描述



:set guioptions+=TmrlRL
显示所有gvim的GUI元素


:set guioptions-=TmrlRL
隐藏所有gvim的GUI元素


:set guioptions-=T
隐藏gvim工具栏


:set guioptions-=m
隐藏gvim菜单栏


:set guioptions-=r
隐藏gvim右边的滚动栏


:set guioptions-=l
隐藏gvim左边的滚动栏


:set guioptions-=R
Hide gVim Right side scroll bar that appears when window is split vertically


:set guioptions-=L
Hide gVim Left side scroll bar that appears when window is split vertically


gVim中改变字体你可能不喜欢gVim的缺省字体，你可以使用下面两种方法来修改它。
方法1：该例子设置字体类型为Courier New，大小为10。对于这种方式，你应该已经知道字体的名称。
:set guifont=Courier\ New:h10

方法2：下面的方法将打开一个字体选择UI，在对话框中你可以选择字体类型和大小。
:set guifont=*
]]></content>
      <categories>
        <category>Vim</category>
      </categories>
      <tags>
        <tag>gvim</tag>
        <tag>guifont</tag>
      </tags>
  </entry>
  <entry>
    <title>Vim 帮助信息</title>
    <url>/2011/03/20/vim-help/</url>
    <content><![CDATA[Vim的帮助信息
可以输入:help查看vim提供的内建帮助文档
可以使用*:helpgrep pattern：*使用模式匹配来查找帮助信息，可以使用:cn来查找下一个匹配的模式
可以使用*:help ‘option’*来查找命令:set option的意思
可以使用*:help CTRL+X来查找CTRL+X*命令
可以使用*:help  &lt;CTRL+D&gt;*来自动补全要查找的命令

]]></content>
      <categories>
        <category>Vim</category>
      </categories>
      <tags>
        <tag>help</tag>
        <tag>helpgrep</tag>
      </tags>
  </entry>
  <entry>
    <title>在插入模式下执行一个Vim命令</title>
    <url>/2011/03/20/vim-insert-command/</url>
    <content><![CDATA[在插入模式下执行一个Vim命令当你在插入模式下，如果你想执行一个单个Vim命令，你不需要按下切换到命令行模式。
为了在插入模式下执行单个Vim命令。
CTRL-O  — 会暂时进入到命令模式
下面是步骤：

在插入模式下输入字符
按下CTRL-O，它会暂时进入到命令模式
按下任何Vim命令（例如，5j跳转到第5行）
执行单个Vim命令之后，自动到返回到插入模式。

]]></content>
      <categories>
        <category>Vim</category>
      </categories>
      <tags>
        <tag>vim</tag>
        <tag>insert</tag>
      </tags>
  </entry>
  <entry>
    <title>vim 插入操作</title>
    <url>/2011/03/20/vim-insert/</url>
    <content><![CDATA[vim 插入操作vim在每行行首或行尾添加/删除内容在每行行首添加相同的内容：
:%s/^/要添加的内容  

在每行行尾添加相同的内容：
:%s/$/要添加的内容  
]]></content>
      <categories>
        <category>Vim</category>
      </categories>
      <tags>
        <tag>vim</tag>
        <tag>insert</tag>
      </tags>
  </entry>
  <entry>
    <title>vim使用跳转列表来跟踪导航</title>
    <url>/2011/01/15/vim-jumps/</url>
    <content><![CDATA[使用CTRL-o和CTRL-I跳转Vim使用跳转列表来跟踪你的导航，你可以通过这个列表来向前或者向后导航。
跳转列表保留所有地方的轨迹，它可以跟踪文件名、行号和列号。
查看调整列表：:jumps



导航键
描述



CTRL-o
跳转到上一个位置点


CTRL-I
跳转到下一个位置点


5CTRL-o
跳转到显示在位置0上面的位置5


5CTRL-I
跳转到显示在位置0下面的位置5


其余类推即可。
]]></content>
      <categories>
        <category>Vim</category>
      </categories>
      <tags>
        <tag>vim</tag>
      </tags>
  </entry>
  <entry>
    <title>vim的一些基础知识</title>
    <url>/2011/03/20/vim-introduction/</url>
    <content><![CDATA[Vim的一些基础知识文本编辑器有很多，图形模式下有gedit、kwrite等编辑器，文本模式下的编辑器有vi、vim（vi的增强版本）和nano。vi和vim是Linux系统中最常用的编辑器。
直到Emacs的出现（1984年以后），vi几乎是所有“黑客”所使用的标准UNIX编辑器。
vi编辑器是Unix的世界中一个相当强大的可视化编辑器，vi编辑器是所有Linux系统的标准编辑器，用于编辑任何ASCII文本，对于编辑源程序尤其有用。它功能非常强大，通过使用vi编辑器，可以对文本进行创建、查找、替换、删除、复制和粘贴等操作。
有人曾这样的说过在世界上有三种人：一种是使用Vi的，另一种是使用是Emacs的，剩下的是第三种人。
 Vim(就是Vi Improved)是从 vi 发展出来的一个文本编辑器, 是Vi的改进版本。代码补完、编译及错误跳转等方便编程的功能特别丰富，在程序员中被广泛使用。和Emacs并列成为类Unix系统用户最喜欢的编辑器。
为什么使用Vim跨平台性无论在Windows，Linux, Solaris, FreeBSD等等操作系统上，以及一些名都 没有听过的系统上，你都可以找到它。这样就保证了你的学习投资的保值性，就拿UltraEdit做对比吧，即使你在UltraEdit上学会灵活运用许多功能，到了Linux上，你在这部分学习投资就没有价值了，你可能需要找其他称手的编辑器，然后再进行学习一些功能。特别在一些古老的大型机上的系统上，即使没有Vim，一般来说，还有Vi的，这样一般简单的操作命令还是可复用的。如果你确定你一直只呆在Windows上可忽略这一点。
开源免费Vim是开源软件，意味着你可以自由使用，修改，查看它的代码。对于自由查看，修改程序代的保证，有总比没有好。对于盗版软件，你有能力还是不要使用的好。正是这一特性，也是促使我放弃UE,投向Vim的重要原因。如果你对于使用盗版软件蛮不在乎，或你有财力购买正版软件，也可忽视这一条。
支持多种编程语言Vim是程序员的编辑器，当然对程序员是非常友好的。它对 C,C++, Python, Perl, Tcl, Ruby, PHP等等，以及一大堆我没有听过见过的语言，以语法着色，代码缩进等基本支持，还有一些其他特性。比如，我在编辑XML时，它能提供自动封闭标记的支持。因此如果你有对多种格式的文本编辑需要，那么你就有了一个编辑的大平台，不需要再装一大堆针对某个格式特定的编辑器了。正如跨平台性一样，你只要一次投资，多次回报。如果你专注于某一格式文件的工作，那这一点同样对于你来说是没有用的。
高效地编辑Vim的操作方式相对于Windows上呆久了的人来说，是蛮奇特的，这一点我深有体会。但是正如很多人讲的那样，你掌握了其操作后，发现它会大大增进你的编辑速度。你的双手根本不用离开键盘，就完成了许多事情，可以让鼠标歇会儿了。如果你特别钟爱鼠标，或只偶尔打打字，那么我说的这点，同样对你没有用。
灵活的设置vim可自定义的地方太多了，你可以自定义键盘映射，语法着色，缩进，格式等等。所以你在网上可以看到许多人贴着自己的vimrc配置文件，配置自己喜欢的作业环境。如果你需要开盒即用的工具，那么这点对你的吸引力就不大了。
]]></content>
      <categories>
        <category>Vim</category>
      </categories>
      <tags>
        <tag>emacs</tag>
        <tag>vim</tag>
      </tags>
  </entry>
  <entry>
    <title>Vim 记录和使用宏</title>
    <url>/2012/03/03/vim-macro/</url>
    <content><![CDATA[Vim 记录和使用宏该技巧使用一个例子来解释在Vim中如何执行记录和使用宏。
前面几步用于在vim中记录和使用宏。

第一步：键入q开始记录宏，后面跟小写字符是宏的名称。
第二步：在Vim编辑器中执行任何类型的编辑操作，它们将会被记录。
第三步：按下q停止记录宏。
第四步：通过按下@后面跟宏名称来使用记录的宏。
第五步：为了多次重复宏，按下NN@宏名，NN为重复次数

]]></content>
      <categories>
        <category>Vim</category>
      </categories>
      <tags>
        <tag>macro</tag>
      </tags>
  </entry>
  <entry>
    <title>Vim 工作模式</title>
    <url>/2012/03/03/vim-mode/</url>
    <content><![CDATA[工作模式vi编辑器有3种基本工作模式，分别是命令模式、插入模式和可视模式。在使用时，一般将可视模式也算入命令行模式。各模式的功能区分如下。
命令行模式控制屏幕光标的移动，字符、字或行的删除，移动、复制某区域及进入插入模式，或者到末行模式。
插入模式只有在插入模式下才可以做文本输入，按“ESC”键可回到命令行模式。
可视模式将文件保存或退出vi编辑器，也可以设置编辑环境，如寻找字符串、列出行号等
]]></content>
      <categories>
        <category>Vim</category>
      </categories>
      <tags>
        <tag>command</tag>
        <tag>insert</tag>
        <tag>visual</tag>
      </tags>
  </entry>
  <entry>
    <title>vim 移动操作</title>
    <url>/2012/03/20/vim-move/</url>
    <content><![CDATA[vim 插入操作vim如何倒序文件执行下面的命令
:g/.*/mo0

或者
:g/^/mo0 




从第一行开始，匹配每一行，然后执行mo（move）操作移动到第0行。如此处理每一行，直到文本末行。执行完毕文本逆序化成功！

比如，原来的文件为：
123456789



经过操作后，会更新为：
987654321



]]></content>
      <categories>
        <category>Vim</category>
      </categories>
      <tags>
        <tag>vim</tag>
        <tag>move</tag>
      </tags>
  </entry>
  <entry>
    <title>vim 导航</title>
    <url>/2013/07/19/vim-navigator/</url>
    <content><![CDATA[基本的导航如果你只是使用h，j，k，l字符来导航，那你就太弱了，如果让你到有万行代码的第5500行你如何操作呢，如果让你去第10屏你将如何操作呢？下面的几个技巧教你在很少击打键盘情况下非常高效的导航文件内容。
滚动整屏或半屏请使用下面的页导航按键：

CTRL-F   向下滚动整页（Forward）
CTRL-B  向上滚动整页（Back）
CTRL-D  向下滚动半页（Down）
CTRL-U  向上滚动半页（Up）

词导航
w    移动到下一个单词的开始
W    移动到下一个WORD的开始
e     移动到当前单词的结尾
E     移动到当前单词的结尾
b     移动到前一个词的开始
B     移动到前一个词的开始

在一行中特殊位置上的位置光标
0（zero）     移动到当前行的开始位置
$(美元符号)   移动到当前行的结束位置
^(…)      移动到当前行的第一个非空字符
g_   移动到当前行的最后一个非空字符

快速跳转至文件首尾导航键 描述
:0 跳转至文件头–方法1
gg 跳转至文件头–方法2
1G 跳转至文件头–方法3
:$ 跳转至文件尾–方法1
G 跳转至文件尾–方法2
段落、章节和句子导航
{      移动到当前段落的开始
}      移动到下一个段落的开始
[[     移动到当前章节的开始
]]     移动到下一个章节的开始
(      移动到前一个句子的开始
)      移动到下一个句子的开始

使用CTRL-o和CTRL-I跳转Vim使用跳转列表来跟踪你的导航，你可以通过这个列表来向前或者向后导航。
跳转列表保留所有地方的轨迹，它可以跟踪文件名、行号和列号。
查看调整列表：:jumps



导航键
描述



CTRL-o
跳转到上一个位置点


CTRL-I
跳转到下一个位置点


5CTRL-o
跳转到显示在位置0上面的位置5


5CTRL-I
跳转到显示在位置0下面的位置5


Vim命令行导航当从命令行打开一个文件，你可以通过指定命令行参数来导航到一个特殊的位置，如下：



导航键
描述



$ vim +142 
打开文件到143行


$ vim +/search-term 
打开文件移动到向下搜索到指定词语的位置


$ vim +?search-term 
打开文件移动到向上搜索到指定词语的位置


$ vim -t TAG 
移动到指定的TAG处


在非常长的行中导航当你遇到非常长的行（没有任何新的行）时，Vim对待它作为单个行。因此，当你对这一行输入j键后，它将跳到下一行上。然而，你会觉得它跳过了好多行。但实际上它只是跳过一个长行。
可视化行：让我们假设有一个非常长的行，它回绕成5个可视化行。为了讨论的目的，让我们称每一单独的行为可视化行。
下面的快捷方式可以帮我们有效地导航一个非常长的行，只需要在前面的基础上加上一个g即可。



导航键
描述



gj
向下滚动一个可视化行


gk
向上滚动一个可视化行


g^
移动到当前可视化行的开始位置


g$
移动到当前可视化行的结束位置


gm
移动到当前可视化行的中间位置


文本编辑下面说明各种改变文件中文本的方法。



键
描述



cc
改变当前整行；与S键一样, 它会删除掉整行，并且进入到插入模式等待输入新文本


C
从当前光标位置改变当前行, 这会使出当前行中光标位置之后的文本，进入插入模式等待输入新的文本。


替换文本这个与r的区别是，s会提前删除掉字符然后进入输入模式。



键
描述



s
使用新的字符替换当前字符


S
使用新的文本替换当前行


4s
使用新的文本替换4个字符（从当前位置开始）


4S
使用新的文本替换4行（从当前行开始）


插入文本下面解释各种插入文本到文件的方法。



键
描述



i
在当前位置插入文本


I
在行的开始位置插入文本，键：大写的I，例如India


o
在当前行之后插入一行，并且插入文本，键：小写o，例如：orange


O
在当前行之前插入一行，并且插入文本键：大写O，例如：Orange


:r FILENAME
插入另外一个文件内容到当前文件的当前行之后


:r! COMMAND
插入执行命令的输出到当前文件的当前行之后


例如：你可以插入当前的日期和时间到你编辑的文件中，执行下面的命令：
:r! date
恢复删除的文本如果你有与误操作删除文本，你可以恢复它。你可以恢复到9个删除文本的片段。



恢复删除
描述



“1p
恢复第一次删除


“2p
恢复第二次到最后一次删除


“3p
恢复第三次到最后一次删除


如果你不确切知道你删除的东西，你可以通过下面的方式浏览所有9次删除的缓冲区。当你看到你希望恢复的文笔，只需要在这一步停止。
浏览所有删除的内容，直到你找到正确的一个。
“1pu.u.u.u.u.
你也可以使用:reg查看寄存器0到9中（删除寄存器）的文本，这会告诉你每个寄存器中使什么内容。
以只读模式打开使用-R选项在只读模式下打开文件，如下所示：
vim -R filename.txt

或者
view filename.txt

当你不想编辑一个文件时，使用上面的方法中的一个是习惯问题。这帮助你避免造成不必要的文件修改。
文件保存当你执行:w时，它会保存文件。:w的主要问题是当你输入:w时，不管文件有没有改变，它都会更新文件时间戳。
幸运的是，:up可以保存文件，并且只是在文件存在改变时修改时间戳。



可视化模式类型
描述



v 小写的v
开始正常的可视化模式,在可视化模式下使用箭头导航选择文本


V（大写）
开始行可视化模式


CTRL-V
开始可视化块模式


vim 自动补全自动单词不全
CRTL+X CRTL+N ：单词前向补全；
CRTL+X CRTL+P ：单词后向补全；

自动行补全
CRTL+X CRTL+L ：自动行补全；

自动文件名补全
CRTL+X CRTL+F ：文件名自动补全；

字典补全只需要在vimrc中设置:set dictionary+=/usr/share/dict/words即可补全words中的单词。也可以使用CTRL+X CTRL+K来显示匹配的单词。
词典自动补全设置:set thesaurus+=/the/path/of/thesaurus文件，然后使用CTRL+X CTRL+T就可以找到相关单词的同义词。
可视化下面是可视化模式下集中不同的类型：



可视化模式命令
描述




退出可视化模式


d
仅删除高亮的文本，例如，如果只是选择一行的部分，它只是删除该行上选择的部分。


D
删除高亮文本下的行，例如，如果只选择行的部分，它会删除整行。


y
仅拷贝（yank）高亮的文本


Y
拷贝高亮文本所在的行


c
删除高亮文本，进入插入模式


C
删除高亮文本所在的行，进入插入模式


窗口
:split file    —打开水平的两个窗口
:vsplit file   —打开垂直的两个窗口
CTRL+WW来移动到下一个窗口，或者使用CTRL+W{h/j/k/l}按照方向移动到相应的窗口；
CTRL+W (+/-)来增加或减小当前的窗口所占比例大小；
:N split filename来打开占用N列的窗口文件。

更改窗口显示标题:set title titlestring=’I\ am\ coding\ now’
更改配色方案可以使用:!ls $VIMRUNTIME/colors来查看支持的配色方案并更改。
Press ENTER or type command to continueREADME.txt	default.vim	elflord.vim	koehler.vim	pablo.vim	shine.vim	zellner.vimblue.vim	delek.vim	evening.vim	morning.vim	peachpuff.vim	slate.vimdarkblue.vim	desert.vim	industry.vim	murphy.vim	ron.vim		torte.vimPress ENTER or type command to continue

编辑文件使用vim –p file1 file2 file3 …. fileN可以打开多个文件，与不加-p的区别在于，这些文件全部显示在一个tab上。
然后我们就可以使用:tabn :tabp来到下一个tab或者上一个tab可以使用:help tab来查看详情。
如何在插入状态下输入命令先输入CTRL+O，然后就可以输入命令了，比如5j，就会跳转5行，然后重新进入插入状态。注意，这里只能执行一次哟。
查看当前文件细节使用CTRL+G或者gCTRL+G，得到的信息分别为基本信息和更详细信息。
数字增加或减少的快捷键可以使用CTRL+A或者CTRL+X来将某位数字加1或者减1。
跳转到变量定义处可以使用gd或者gD来跳转到变量定义处，一个为local定义，一个是global定义，在跳转过程中，会将该变量高亮显示。
标签使用标签来创建的书签有两种类型的书签：局部书签和全局书签。
这里我们介绍下局部书签：



标签命令
描述



ma
在当前位置处创建一个名为“a”的标签


`a(反引号 a)
跳转到书签“a”的精确位置


‘a(单引号 a)
跳转到包含标签“a”哪行的开始


在单个文件中，当你希望跳转到特殊位置或者行上，你可以使用本地标签。如果你的标签名称是小写字符，那么它是个局部标签。
注意：Vim与Vi不同的是在编辑器推出之后该标签还是存在的，这是一个让许多UNIX用户吃惊的强大特征。
文件加密在vim中使用:X然后输入密码就可是设置每次打开文件都要输入设置的密码，同时可以使用:set key=来取消密码。
保存会话如果在编辑当前文件的时候，想编辑另外一个文件，可以使用:mksession来保存当前对话，等回来的时候，重新使用vim –S Session.vim即可打开原来保存的会话，这个会话会保存buffer、窗口大小、自定义选项、文件夹、当前目录等。
在vim中执行shell命令使用方式为:!cmd即可。
比如在修改源码的时候，我比较喜欢使用:!date这样就可以快速注释修改的时间了。
vimbook–OPL –official publications library又大概看了一遍VIM-OPL，大概记了一些还不是很熟的知识点。
1 Basic Editingx—删除字符
u—撤销
Ctrl+U—还原
ZZ—保存退出
o—在当前行下方新建一行
O—在当前行上方新建一行
CTRL+] &amp;&amp; CTRL+T：浏览器间前进后退
帮助前缀What                                         Prefix             Example
Normal-mode commands     (nothing)                 :help x
Control character CTRL-        :help                          CTRL-u
Visual-mode commands       v                                :help v_u
Insert-mode commands        i                               :help i_
ex-mode commands             :                               :help :quit
Command-line editing          c                          :help c_
Vim command arguments           –              :help -r
Options                      ‘ (both ends)        :help ‘textwidth’
​      特殊键需要使用尖括号括起来，例如向上的键:help 
移动到行首行尾使用$移动到行尾，如果是2$就是移动到当前光标所在的下一行的行尾；
0是移动到行首
^是移动到第一个非空的字符上。
搜索字符fx：即为从光标开始向前搜索字符x的所在；
Fx：即为从光标开始向后搜索字符x的所在；
与之相同的为tx和Tx，不过只是在前一个字符停下而已。
我在哪里使用CTRL+G可以显示出你位于那里
向上或向下卷动CTRL+U：向上移动半屏
CTRL+D：向下移动半屏
组合的威力如果对于，当光标在&lt;时，使用df&gt;将会把整体删除，然后使用.就可以进行相同的编辑操作。
改变大小写~
键盘宏–处理更复杂的操作将
stdio.h
fcntl.h
unistd.h
stdlib.h
修改为
#include “stdio.h”
#include “fcntl.h”
#include “unistd.h”
#include “stdlib.h”
方法如下：
qa   开始录制宏到寄存器a
^   移动到行首
i#include “ 在行首插入字符串#include”
$   移动到行尾
a”  在行尾添加”
j  移动到下一行
q   停止录制宏
然后我们就可以使用@a来重复刚才的动作。
输入图标或键盘上没有的符号可以使用:digraphs来查看可以输入的符号，输入方法为CTRL-Kat****，即可输入@。
正则表达式搜索/^include：只搜索每行中的第一个include
/include$：只搜索每行中的最后一个include
/^include$：只搜索准确的include，而不显示诸如includeaaa等。
正则表达式总结x The literal character x
^ 行的开始
$  行的结尾
.  匹配单个字符
character  诸如.*[]ˆ%/?~$需要来搜索
使用标记mark
使用：mark a来标记a

移动到另一个位置

执行d’a就可以删除从当前位置到a的文本


使用标记的好处是它可以为你一直保持，你可以随时跳转回去。
使用标记后，可以使用y’a来复制当前位置到标记的地方。
!!的妙用！！date就是把当前 时间插入，同样地！！ls就是把当前文件夹列表的内容插入到当前行。
直接在vim中打开另一个文件​      如果你已经使用vim打开了一个文件，又想打开另外一个文件，可以先退出在打开另一个，但是还有一个比较快捷的方法，就是直接:vi filename，就可以自动关闭原来的文件，打开filename。
我位于那个文件​      输入:args可以在打开过个文件的时候定位到底在那个文件。
三种visual模式l  V：选择整行；
l  v：按照字符选择；
l  CTRL+V：矩形块选择；
Visual模式中连接多行在V模式下，使用J可以连接各行，而gJ可以不让连接的各行有空格。
Visual模式下平移选定文本后，使用SHIFT+&gt;来平移文本。
多行插入相同文本使用CTRL+V选定文本后，使用I即可插入在选定的地方插入相同文本（光标其实）；而A在选定的区域之后。
如果c程序的后缀名不是c可以使用:set filetype=c来强制默认为c类型
自动缩进有三个缩进
l  cindent
l  smartindent
l  autoindent
程序中定位*：可以定位到光标下的单词；
gd：移动到变量的定义处；
[d：显示宏定义
匹配对%：用于匹配（）、/*  */、｛｝或[]；
查找man信息在关键词上直接敲K就可以打开man帮助信息。
在文件中直接make我们可以在文件中直接使用:make来编译程序，这样就可以自动定位到错误的地方。:cc可以列出所有的编译信息，:cnext或这:clist可以到下一个报警错误或者列出所有信息。
进入命令行模式按下Q即可进入。
文本格式命令:range center/right/left width可以居中
自动补全我们可以使使用CTRL+N或者CTRL+P来自动搜索匹配的词。
显示字符的ascii码输入ga就可以显示出光标下字符的各个进制数。
]]></content>
      <categories>
        <category>Vim</category>
      </categories>
      <tags>
        <tag>vim</tag>
        <tag>sort</tag>
        <tag>shello</tag>
        <tag>undo</tag>
      </tags>
  </entry>
  <entry>
    <title>Vim 打开文件</title>
    <url>/2011/03/06/vim-open-file/</url>
    <content><![CDATA[打开光标下的文件
gf ：在光标位于一个文件名上时，如果该文件就在当前目录，就可以打开该文件，但是会覆盖原来的文件；

当然，就算没有绝对路径，vim也可以打开一些文件，比如c头文件和perl模块
打开多个文件使用vim file1 file2 file3….可以打开多个文件，但是同一时刻只能显示一个文件。
在一个session中，还可以使用:e anotherFile打开另一个文件。
在多个文件中，可以使用CTRL+^来切换，或者使用:next :previous来切换。
]]></content>
      <categories>
        <category>Vim</category>
      </categories>
      <tags>
        <tag>vim</tag>
        <tag>file</tag>
      </tags>
  </entry>
  <entry>
    <title>从Vim中访问Unix的函数帮助页</title>
    <url>/2011/03/06/vim-open-unix-man-page/</url>
    <content><![CDATA[从Vim中访问Unix的函数帮助页在Vim编辑器中，在你想阅读帮助（man）页的函数名上按K键。
K
为了访问其他章节的Man页按{n}K。例如，为了访问man页的第2章，执行下面命令：
2K
例如：sleep是一个命令，也是库中的函数，因此，C编程时你想查看它的man页，那么你需要使用3K。
]]></content>
      <categories>
        <category>Vim</category>
      </categories>
      <tags>
        <tag>man</tag>
        <tag>help</tag>
        <tag>vim,</tag>
      </tags>
  </entry>
  <entry>
    <title>vim 插件</title>
    <url>/2011/07/20/vim-plugins/</url>
    <content><![CDATA[[TOC]
暂时跳过加载插件如果安装了很多的vim插件，需要很干净的启动时，可以使用：
vim –noplugin filename

ctags​	首先需要安装ctags，可以使用apt-get、yum或者源码安装。
​	Ctags是一个用于从程序源代码树产生索引文件（或tag文件)，从而便于文本编辑器来实现快速定位的实用工具。在产生的tag文件中，每一个tag的入口指向了一个编程语言的对象。这个对象可以是变量定义、函数、类或其他的物件。
​	Ctags是开放源代码的程序。支持下列的编程语言:汇编，AWK, ASP, BETA, Bourne/Korn/Zsh Shell, C, C++, COBOL, Eiffel, Fortran, Java, Lisp, Lua, Make, Pascal, Perl, PHP, Python, REXX, Ruby, S-Lang, Scheme, Tcl, Vim, and YACC。
​	支持Ctags产生的tag文件的编辑器以及编辑器插件包括:Vim，Vile，Lemmy，等等。
步骤进入需要创建索引文件的文件夹，执行ctags *.c即可将所有的c源文件创建索引文件tags。
​       可以通过cat tags来查看一下tags的内容。
​      
导航到function的方法：

可以使用:ta function直接跳转到function；
当光标为function上时，使用CTRL+]也可以直接跳转到function

返回原来的使用它CTRL+T即可。
Ta跳转也支持正则表达式，比如:ta /^get就会搜索以get开始的函数。
Ctags的vim命令及描述



:ts
显示tag list



:tn
跳到list中的下一个


:tp
跳到list中的上一个


:tf
跳到list中的第一个


:tl
跳到list中的最后一个


]]></content>
      <categories>
        <category>Vim</category>
      </categories>
      <tags>
        <tag>noplugin</tag>
        <tag>plugins</tag>
      </tags>
  </entry>
  <entry>
    <title>Vim 退出</title>
    <url>/2011/04/12/vim-quit/</url>
    <content><![CDATA[退出vim
: x   :wq  ZZ  保存文件并且退出
:q! :qa 退出但不保存文件

]]></content>
      <categories>
        <category>Vim</category>
      </categories>
      <tags>
        <tag>write</tag>
        <tag>update</tag>
        <tag>quit</tag>
        <tag>autowrite</tag>
      </tags>
  </entry>
  <entry>
    <title>VIM 重绘窗口</title>
    <url>/2011/04/08/vim-redraw/</url>
    <content><![CDATA[使用当前行重绘屏幕


导航键
描述



z然后ENTER
将光标行移到屏幕顶端并滚动屏幕


z.
将光标行移到屏幕中心并滚动屏幕


z-
将光标行移到屏幕底端并滚动屏幕


200z然后ENTER
会把第200行移到屏幕顶端


]]></content>
      <categories>
        <category>Vim</category>
      </categories>
      <tags>
        <tag>vim</tag>
        <tag>redraw</tag>
      </tags>
  </entry>
  <entry>
    <title>VIM 重复命令</title>
    <url>/2011/04/08/vim-repeat/</url>
    <content><![CDATA[VIM 重复命令
@@ ： 重复上一个执行宏
n：以相同的方向重复上一个搜索命令；
N：以相反的方向重复上一个搜索命令；
. ：重复上一个编辑命令；
@：重复上一个命令行

]]></content>
      <categories>
        <category>Vim</category>
      </categories>
      <tags>
        <tag>vim</tag>
        <tag>macro</tag>
        <tag>repeat</tag>
      </tags>
  </entry>
  <entry>
    <title>替换文本</title>
    <url>/2011/02/06/vim-replace-character/</url>
    <content><![CDATA[


键
描述



r{c}
使用字符{c}来替换单个字符（当前光标所在的位置上）


R
替换字符直到你按下注意：当移动到一行的最后时，该动作如同A一样，而不是回绕替换下一行的字符。


示例一：整个文件替换:%s/old-text/new-text/g     这条命令将把old-text替换为new-text。
示例二：单行替换并提示:s/old-text/new-text/gi      这条命令将把当前行的old-text替换为new-text并在替换前提示确认；
示例三：指定行内替换:N,Ms/old-text/new-text/g    这条指令将把第N行到第M行的old-text替换为new-text。
示例四：指定可视块内替换:’&lt;,’&gt;s/old-text/new-text/g  这条指令将选定可视区域内的old-text替换为new-text。
示例五：替换从当前行开始的N行文本:s/old-text/new-text/g N             这条指令将替换从当前行开始的N行之内的old-text为new-text。
示例六：替换全匹配单词对于前面的技巧，可能会在his替换为her的时候，This也替换为Ther，这就不是我们的本意了，此时我们可以使用：
:s/&lt;old-text&gt;/new-text/    来替换整个单词，而不会截取其中的一部分。
示例七：使用正则表达式同时替换两个单词:s/(old-text1|old-text2)/new-text/g           这条指令将会同时替换old-text1和old-text2为new-text。
示例八：交互式的查找替换:s/old-text/new-text/gc        这条指令将会在替换每一个单词的时候提示时候替换，这对于只是希望替换其中一部分的还是蛮有用处的。
]]></content>
      <categories>
        <category>Vim</category>
      </categories>
      <tags>
        <tag>vim</tag>
        <tag>replace</tag>
      </tags>
  </entry>
  <entry>
    <title>VIM快速选中并复制粘贴替换一个单词</title>
    <url>/2011/04/08/vim-replace/</url>
    <content><![CDATA[VIM快速选中并复制粘贴替换一个单词
比如准备用bbb替换aaa
光标移动到aaa的开头，按 v 按e 按y
光标移动到bbb的开头，按 v 按e 按p

]]></content>
      <categories>
        <category>Vim</category>
      </categories>
      <tags>
        <tag>vim</tag>
        <tag>copy</tag>
        <tag>paste</tag>
        <tag>replace</tag>
      </tags>
  </entry>
  <entry>
    <title>Vim 保存文件</title>
    <url>/2011/04/12/vim-save/</url>
    <content><![CDATA[保存文件使用*:w* 和 :u 都可以保存文件，其中w代表write，u代表update的含义。
如果只是输入上述命令，则直接保存文件，当然也可以使用*:w anotherFilename*来另存为另一个新的文件。
自动保存文件当你试图切换缓冲区或者文件时，如果你没有保存改变时Vim通常会给出错误消息。
启用切换缓冲区/文件时自动写入文件，命令如下：
:set autowrite

使用单个命令写入所有文件（这可能在宏中非常有用）
:wall

保存文件时发生的问题
尝试保存文件已存在，可以输入*:w! file用来覆盖现有的文件，或者:w newfile*将编辑的结果写入新的文件；
得到文件系统已满的消息，可以输入*:!rm junkfile来删除一个不需要的打文件，空出一些空间（在冒号后加上感叹号，然后就可以执行shell命令），或者输入:!df看看其他文件系统有没有空间，如果有，先放入其他文件系统，用:w pathname*来写入你的文件。
系统进入开放模式并且显示文件系统已满的消息，可以输入*:!ls /tmp来查看有无可以移除的文件，以腾出一些空间。如果有的话，可以先创建一个临时的unix shell，以便移除，直接输入:sh可以打开一个新的暂时的shell*，移除后，可以输入exit返回到vi，或者使用CTRL+Z来将vi暂停，放到后端，使用fg即可以回到vi。
尝试写入文件，却得到磁盘限额已满的消息，可以实时*:pre(:preserve)*的缩写，强迫系统保存你的缓冲区。

]]></content>
      <categories>
        <category>Vim</category>
      </categories>
      <tags>
        <tag>write</tag>
        <tag>save</tag>
        <tag>update</tag>
        <tag>autowrite</tag>
      </tags>
  </entry>
  <entry>
    <title>vim搜索技巧</title>
    <url>/2013/07/24/vim-search/</url>
    <content><![CDATA[简单搜索技巧
/search-term ：前向搜索
?search-term ：后向搜索
n ： 查找下一个
N ：查找前一个
// 或 ?? ：重复上一个搜索

当前词的搜索当光标在一个单词上时，输入下述：


：搜索当前光标所在单词的下一个（完全匹配）


：搜索当前光标所在单词的上一个（完全匹配）
g* ：搜索当前光标所在单词的下一个（部分匹配即可）
g# ：搜索当前光标所在单词的上一个（部分匹配即可）

搜索当前行的一个字符
fX ：搜索当前行的下一个X
FX ：搜索当前行的上一个X
tX ：搜索当前行的下一个X，并定位到前一个字符
TX ：搜索当前行的上一个X，并定位到前一个字符
；：重复上面的命令
，：重复上面的命令（反向）

使用vimgrep搜索多个文件可以在vim环境中使用:vimgrep hello *.c来搜索当前文件夹下所有c文件中包含hello的行，然后可以使用:cn或者:cN查看前一个或后一个文件。
高亮显示搜索结果使用:set hlsearch或者:set nohlsearch来显示或者取消搜索到匹配模式的高亮显示。
:match的使用可以使用类似:match color-scheme /word/来讲word设置为搜索到时显示为color-scheme的模式。
其中color-scheme有ErrorMsg、WarningMsg、ModeMsg和MoreMsg等。
放置光标在匹配的最后当你在Vim内使用/pattern搜索时，缺省光标位于匹配的开始。
但是，如果你希望光标放置在匹配的结尾，你可以使用/pattern\zs。
光标在模式的开始位置：
/pattern
光标在模式的结尾处：
/pattern\zs
快捷搜索如果要搜索,一般命令是:   “:/thisisaverylongword”，但是这样输入thisisaverylongword, 这个很长的单词很难输入, 所以有更简单的办法:把光标置于thisisaverylongword之上, 然后按*键,或者#键即可直接进行搜索.*键是向下搜索, #键是向上搜索。
vim增量搜索设置:set incsearch就可以在输入任何字符的时候自动匹配，而不需要输入完以后回车才匹配。
Vim增量搜索当你使用增量搜索后，在Vim中不能没有它。
为了使用增量搜索
:set incsearch

增量搜索会在输入的时候就开始搜索关键词。
关闭增量搜索，
:set noincsearch
]]></content>
      <categories>
        <category>Vim</category>
      </categories>
      <tags>
        <tag>search</tag>
        <tag>Vim</tag>
        <tag>hlsearch</tag>
        <tag>match</tag>
        <tag>vimgrep</tag>
      </tags>
  </entry>
  <entry>
    <title>vim出错warning setlocale LC_CTYPE cannot change locale</title>
    <url>/2011/07/19/vim-setlocale/</url>
    <content><![CDATA[vim出错warning setlocale LC_CTYPE cannot change locale在终端命令行下面，为了放置出现乱码，将LANG设置为en，不过在vim的时候却出现了如下提示信息：
warning: setlocale: LC_CTYPE: cannot change locale (en)

估计就是语系的问题吧。
解决方法：
在bashrc中将设置的LANG的语句注释就正常了。
]]></content>
      <categories>
        <category>Vim</category>
      </categories>
      <tags>
        <tag>bashrc</tag>
        <tag>LANG</tag>
      </tags>
  </entry>
  <entry>
    <title>Vim排序文件内容</title>
    <url>/2011/03/18/vim-sort/</url>
    <content><![CDATA[vim排序文件内容从Vim版本7开始，Vim内建排序命令可以使用。这个指令在需要排序的时候还是蛮有用的。
比如按照姓名排序，按照学号排序等等。
Vim中排序文件内容如下所示：
:sort

文件内容的排序操作如下所示：

按下v进入到可视化模式；
使用箭头选择需要排序的多行；
按下:,在Vim的底部它会显示:’&lt;,’&gt;’。
在排序选择的最后增加!sort

:’&lt;,’&gt;!sort

:sort Vim命令还有下面一些可用的选项：



:sort选项
描述



:sort
以升序排序


:sort!
以降序排序


:sort i
忽略大小写


:sort u
删除重复行，u表示唯一


:sort! ui
也可以组合所有排序命令选项


逆序排列要求
示例：将文本1234123121转换成1121231234
命令:g/.*/mo0# 或者:g/^/mo0
]]></content>
      <categories>
        <category>Vim</category>
      </categories>
      <tags>
        <tag>vim</tag>
        <tag>sort</tag>
      </tags>
  </entry>
  <entry>
    <title>Vim swap文件</title>
    <url>/2011/03/26/vim-swap/</url>
    <content><![CDATA[Swap文件使用-r选项来列出当前目录下的Swap文件，~/tmp、/var/tmp、/tmp。
下面的命令显示所有的swap文件。
$ vim -r

当一个swap文件存在时，如果你试图打开它的原始文件，你会得到覆盖swap文件的消息,原因是：

一些人正在编辑文件；
基于为什么会发生下面Vim提示中的一种，如下所示：
打开只读文件（查看文件内容）；
任何地方进行编辑（编辑文件内容）；
恢复（使用交换文件来替代文件内容）；
退出或崩溃。

]]></content>
      <categories>
        <category>Vim</category>
      </categories>
      <tags>
        <tag>swap</tag>
      </tags>
  </entry>
  <entry>
    <title>交换相邻的字符</title>
    <url>/2011/02/27/vim-swap-adjacent-characters/</url>
    <content><![CDATA[如果你遇到一个简单输入错误，错误放置相邻的字符，你可以使用xp。例如你输入the替代teh，导航到e，按下xp，它会自动修正输入。

xp

实际上，xp不是真的修正输入，含义如下：

x – 删除当前的e字符，也移动光标到下一个字符h处；
p – 在当前的字符h之后粘贴前一个删除的字符e。

xp的含义就是“位置交换”。又到了XP的年代吗，错了。
]]></content>
      <categories>
        <category>Vim</category>
      </categories>
      <tags>
        <tag>vim</tag>
        <tag>xp</tag>
      </tags>
  </entry>
  <entry>
    <title>让Vim智能的高亮你的代码</title>
    <url>/2011/03/05/vim-syntax/</url>
    <content><![CDATA[让Vim智能的高亮你的代码


命令
描述



:syn on
打开语法高亮显示


:syn off
关闭语法高亮显示


注：Vim通过文件名的后缀来识别使用哪种编程语言的语法高亮的模版。
]]></content>
      <categories>
        <category>Vim</category>
      </categories>
      <tags>
        <tag>sync</tag>
        <tag>highlight</tag>
        <tag>syntax</tag>
      </tags>
  </entry>
  <entry>
    <title>gvim技巧</title>
    <url>/2013/07/21/vim-tips-about-gvim/</url>
    <content><![CDATA[gvim介绍gVim是Vim的图形前端，它是跨平台的编辑器，基本上主流的操作系统上面都有它的版本。
显示或者隐藏gvim的菜单和工具栏隐藏工具栏为:set guioptions-=T
相反地，如果希望显示相应的组件，可以将-=改为+=即可。GUI的GUI元素有下面几种



设置代码
描述



:set guioptions-=TmrlRL
隐藏gvim的所有GUI元素


:set guioptions+=TmrlRL
显示gvim的所有GUI元素


:set guioptions-=T
隐藏gvim的工具栏


:set guioptions-=m
隐藏gvim的菜单栏


:set guioptions-=r
隐藏gvim的右侧滚动条


:set guioptions-=l
隐藏gvim的左侧滚动条


:set guioptions-=R
隐藏gvim的右侧滚动条，当分割窗口时


:set guioptions-=L
隐藏gvim的左侧滚动条，当分割窗口时


修改gvim的字体可以使用:set guifont=*来调出字体选择窗口，或者使用:set guifont=Courier\ New:h10。
]]></content>
      <categories>
        <category>Vim</category>
      </categories>
      <tags>
        <tag>vim</tag>
        <tag>set</tag>
        <tag>guifont</tag>
        <tag>guioptions</tag>
      </tags>
  </entry>
  <entry>
    <title>vim 额外小技巧</title>
    <url>/2013/07/28/vim-tips-bonus-hacks/</url>
    <content><![CDATA[重绘屏幕在一些情况下，如果屏幕出现了问题，可以使用CTRL+L来重绘屏幕。
插入非键盘字符对于非键盘字符，可以参考:digraphs来查看，比如我们就可以使用CTRL+K Co来输入版权的符号©。
进入vim的ex模式输入大写的Q就可以进入vim的ex模式，在这种模式下，我们可以一直执行命令，回到原来的模式，只需输入vim即可。
定位在匹配单词的末尾通常我们使用/pattern后，光标会停留在单词p上，如果我们希望光标停留在pattern的最后一个字母，只需使用/pattern\ns即可
查看字符的ASCII码表想查看一个字符的ASCII码时，只需输入ga就可以看到。
编辑二进制文件使用vim –b filename即可。
]]></content>
      <categories>
        <category>Vim</category>
      </categories>
      <tags>
        <tag>redraw</tag>
        <tag>binaray</tag>
        <tag>digraphs</tag>
        <tag>ex</tag>
      </tags>
  </entry>
  <entry>
    <title>vim 命令行技巧</title>
    <url>/2013/07/20/vim-tips-comand-line-hacks/</url>
    <content><![CDATA[以只读模式打开vim –R filename
这种模式打开的文件不能修改。
查看swap文件vim –r

可以查看当前文件夹，~/tmp，/var/tmp以及/tmp的临时文件。
出现swap文件有两种情况：

其他人正在编辑该文件
上一个会话非正常退出

打开文件时执行命令vim –c ‘cmd’ filename

可以通过-c参数在打开filename的时候就执行命令cmd，比如cmd为:50就是打开文件后就跳转到50行，而/hello就是打开文件就搜索hello的所在。当然我们可以同时执行多个命令，格式为：
vim –c ‘cmd1’ –c ‘cmd2’ –c ‘cmd3’ … filename

执行文件中的命令vim –w cmdfile filedata

打开filedata的时候直接执行cmdfile中的命令。
进入vim的受限模式使用vim –Z filename后，就会进入vim的受限模式，所有的外部shell命令会被禁用。
]]></content>
      <categories>
        <category>Vim</category>
      </categories>
      <tags>
        <tag>readonly</tag>
      </tags>
  </entry>
  <entry>
    <title>vim寄存器、文件浏览器、大小写转换</title>
    <url>/2013/07/29/vim-tips-register-file-navigator-change-case/</url>
    <content><![CDATA[寄存器 在删除、替换、拷贝文本的时候，这些信息都会保存到你可以访问的寄存器中。
 下面的是一些默认的寄存器：



寄存器名称
描述



%
当前文件名


:
最近执行的命令


/
上一次的搜索


“
最近一次使用的寄存器


使用方法为”&lt;Register Name&gt;p就可以经寄存器中的内容粘贴出来。比如”%p就可以将当前文件名粘贴到文件中。同时也可以使用:registers来查看寄存器中的内容。
文件浏览器使用vim directory的会将目录及文件列出来。
在把vim当做文件浏览器的时候可以进行下面的操作：



键
描述




打开文件或者进入文件目录


D
删除光标下的文件


R
重命名光标下的文件名


X
执行光标下的文件


o
在一个水平窗口中打开文件


同样地，在vim编辑文件的时候也可以打开vim文件浏览器。比如使用:Sex或者:Vex就可以切分出一个水平或者垂直的先窗口；而使用:Tex则可以打开一个新的tab页。
大小写转换| 按键|描述|||大小写转换，并将光标移动到下一个字符||N|将接下来的N的字符大小写互换||g~~|将当前行大小写互换||gUU|将当前行全部转化为大写||guu|将当前行全部转换为小写||gUaw|将当前word转换为大写||guaw|将当前word转换为小写||U|可视模式下全部转换为大写||u|可视模式下全部转换为小写||guG/gUG|从当前行开始到最后一行转换为小写/大写|
空格和tab|:set expandtab      |   将tab自动转换为空格||:set tabstop=4      |   将tab转换为4个空格||:retab              |   通过上面的两个配置将tab转换为相应的空格||:set shiftwidth=4   |   设置缩进时的空格数目||:set ai             |   自动缩进|
]]></content>
      <categories>
        <category>Vim</category>
      </categories>
      <tags>
        <tag>vim</tag>
        <tag>expandtab</tag>
        <tag>registers</tag>
        <tag>shiftwidth</tag>
        <tag>tabstop</tag>
        <tag>ai</tag>
        <tag>retab</tag>
        <tag>sex</tag>
        <tag>vex</tag>
        <tag>tex</tag>
      </tags>
  </entry>
  <entry>
    <title>Vim 入门联系</title>
    <url>/2011/03/20/vim-tutuor/</url>
    <content><![CDATA[使用vimtutor来练习在安装vim的时候都会附加地安装上vimtutor，这个程序是用来一步一步地学习vim编辑器的。
可以使用vimtutor直接打开教程，当然也可以通过加上后缀来打开其他语言的教程，比如vimtutor fr是法语的，vimtutor es是西班牙语的。
]]></content>
      <categories>
        <category>Vim</category>
      </categories>
      <tags>
        <tag>tutorial</tag>
        <tag>vimtutor</tag>
      </tags>
  </entry>
  <entry>
    <title>Vim 编程工具</title>
    <url>/2013/04/04/vim-tools/</url>
    <content><![CDATA[
indent ： changes the appearance of a C program by inserting or deleting whitespace.能够按照预先定义好的或者自定义的标准调整源代码以及代码缩进的格式以达到所需要的风格；
etags, ctags – generate tag file for Emacs, vi。生成的文件能够增强编辑器浏览和分析源代码的风格；

]]></content>
      <categories>
        <category>Vim</category>
      </categories>
      <tags>
        <tag>emacs</tag>
        <tag>ctags</tag>
        <tag>etags</tag>
        <tag>indent</tag>
      </tags>
  </entry>
  <entry>
    <title>VIM 撤销和重做</title>
    <url>/2011/04/08/vim-undo-redo/</url>
    <content><![CDATA[VIM 撤销和重做
u：可以撤销上次的操作；
Nu：可以撤销前N次的操作；
U：撤销当前行的所有修改；
:red或者CTRL+R：可以撤销还原；

]]></content>
      <categories>
        <category>Vim</category>
      </categories>
      <tags>
        <tag>vim</tag>
        <tag>macro</tag>
        <tag>repeat</tag>
      </tags>
  </entry>
  <entry>
    <title>Vim 使用vimdiff查看文件之间的不同</title>
    <url>/2011/04/14/vim-vimdiff/</url>
    <content><![CDATA[使用vimdiff查看文件之间的不同与Unix diff命令一样，vimdiff用于显示文件之间的不同的地方。不像Unix的diff命令，vimdiff有更多的颜色和用户友好性。
在下面的例子中，很容易可视化的看到两个文件中哪些地方文本被改变和添加。
$ vimdiff employee.txt new-employee.txt




vimdiff命令
描述



$ vimdiff file1 file2
使用垂直窗口分割显示文件的不同


$ vim -d file1 file1



$ vimdiff -o file1 file1
使用水平窗口分割显示文件的不同


$ vim -d -o file1 file1



$vim filel &amp; :diffsplit file1
如果你已经打开一个文件，使用:diffsplit以水平方式加载的不同点


$vim file1 &amp; :vert diffsplit file1
如果你已经打开一个文件使用:vert diffsplit以垂直方式加载的不同点


[c
移动到vimdiff中下一个改变处


]c
移动到vimdiff中前一个改变处


]]></content>
      <categories>
        <category>Vim</category>
      </categories>
      <tags>
        <tag>diff</tag>
        <tag>vimdiff</tag>
      </tags>
  </entry>
  <entry>
    <title>Vim 为什么使用vim</title>
    <url>/2012/03/03/vim-why-use-vim/</url>
    <content><![CDATA[为什么使用Vim其实只要试用一下Final_Vim就知道为什么了。
跨平台性无论在Windows，Linux, Solaris, FreeBSD等等操作系统上，以及一些名都 没有听过的系统上，你都可以找到它。这样就保证了你的学习投资的保值性，特别在一些古老的大型机上的系统上，即使没有Vim，一般来说，还有Vi的，这样一般简单的操作命令还是可复用的。如果你确定你一直只呆在Windows上可忽略这一点。
开源免费Vim是开源软件，意味着你可以自由使用，修改，查看它的代码。对于自由查看，修改程序代的保证，有总比没有好。
支持多种编程语言Vim是程序员的编辑器，当然对程序员是非常友好的。它对 C,C++, Python, Perl, Tcl, Ruby, PHP等等，以及一大堆我没有听过见过的语言，以语法着色，代码缩进等基本支持，还有一些其他特性。
高效地编辑Vim的操作方式相对于Windows上呆久了的人来说，是蛮奇特的，这一点我深有体会。但是正如很多人讲的那样，你掌握了其操作后，发现它会大大增进你的编辑速度。你的双手根本不用离开键盘，就完成了许多事情，可以让鼠标歇会儿了。
灵活的设置vim可自定义的地方太多了，你可以自定义键盘映射，语法着色，缩进，格式等等。所以你在网上可以看到许多人贴着自己的vimrc配置文件，配置自己喜欢的作业环境。如果你需要开盒即用的工具，那么这点对你的吸引力就不大了。
]]></content>
      <categories>
        <category>Vim</category>
      </categories>
      <tags>
        <tag>free</tag>
        <tag>cross platform</tag>
        <tag>open source</tag>
      </tags>
  </entry>
  <entry>
    <title>Vim 写文件的部分内容到另一个文件</title>
    <url>/2011/03/01/vim-write-file/</url>
    <content><![CDATA[写文件的部分内容到另一个文件为了写文件的一部分到新的文件中，你可以使用下面方法中的任意一种。
方法1：在可视化模式下选择特殊的几行。进入可视化模式（使用v或者V），导航到希望的行上，然后执行：
:w newfilename

方法2：写入文件的部分到另外一个文件，你可以指定范围，如下所示。它写入当前文件的5到10行到一个新的文件。
:5,10w newfilename
]]></content>
      <categories>
        <category>Vim</category>
      </categories>
      <tags>
        <tag>write</tag>
      </tags>
  </entry>
  <entry>
    <title>Windows7下设置VirtualBox共享文件夹</title>
    <url>/2011/12/16/virtualbox-share-folder-with-windows7/</url>
    <content><![CDATA[Windows7下设置VirtualBox共享文件夹
 在主机windows上设一个目录，比如 D:/sharedfolder_windows；


 在虚拟机上，通过设备–共享文件夹添加刚才我们设的文件夹；


 在linux中，打开终端，创建一个文件比如mkdir /mnt/sharefolder_linux;


 运行命令：`sudo mount -t vboxsf sharedfolder_windows /mnt/ sharefolder_linux`；


 第四个命令也可以写入/etc/fstab，这样开机就会挂载，写入内容为：`sharedfolder_windows /mnt/ sharefolder_linux  vboxsf default 0 0`


 此时写入文件就可以实现共享了。



]]></content>
      <categories>
        <category>VirtualBox</category>
        <category>Windows7</category>
      </categories>
      <tags>
        <tag>VirtualBox</tag>
        <tag>mount</tag>
        <tag>Windows7</tag>
        <tag>fstab</tag>
      </tags>
  </entry>
  <entry>
    <title>VirtualBox 5.0即将到来</title>
    <url>/2015/04/16/virtualbox5.0-is-coming/</url>
    <content><![CDATA[VirtualBox 5.0即将到来如果你能看到这篇文章，证明我这里不需要解释什么是VirtualBox了，而确实我已经用VirtualBox接近5年的时间了。从最开始的Vmvare转到VirtualBox的。

谁让VirtalBox开源嘞

话说，VirtualBox最开始由以德国公司InnoTek开发，后买买个Sun公司，最后买给了Oracle，话说甲骨文你财大气粗，为嘛收购后总是维护维护呢，都不来个重大升级，你不造Linux都从2.x蹭蹭蹭来到了不断电更新的4.0年代了吗？加油吧，man。
不过也别对这个版本抱希望太大，因为VirtualBox只是在视觉上和技术上都做了一些改进。
其实对于它的升级我到时不是特别在意，因为目前的功能已经足够我使用了。
说到为什么用VirtualBox，原因如下：

Virtual挺好用的，支持但不限于Windows、Linux、MacOSX和Solaris等，所以，支持平台多。


我有MacBook Pro，而我又想在适当的情况下用下我搭建好的具备各种开发测试环境的Linux和偶尔看看文档的Windows，所以我选VirtualBox。


我喜欢开源，我不喜欢黑盒子。


我不想买Vmvare，也不想用盗版的。


我喜欢VirtualBox的无缝功能。

所以我就一直给大家推荐，如果用就推荐VB，是VirtualBox，可不是Visual Basic哈。
喜欢开源，在开源的路上越走越远，最近在马6呢，所以加油吧。
↖(^ω^)↗
下面摘自VB官网，主要介绍支持平台：

Presently, VirtualBox runs on Windows, Linux, Macintosh, and Solaris hosts and supports a large number of guest operating systems including but not limited to Windows (NT 4.0, 2000, XP, Server 2003, Vista, Windows 7, Windows 8), DOS/Windows 3.x, Linux (2.4, 2.6 and 3.x), Solaris and OpenSolaris, OS/2, and OpenBSD.

]]></content>
      <categories>
        <category>Linux</category>
        <category>VirtualBox</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>MacOSX</tag>
        <tag>Windows</tag>
        <tag>VirtualBox</tag>
        <tag>Macintosh</tag>
        <tag>Oracle</tag>
        <tag>Solaris</tag>
        <tag>Vmware</tag>
      </tags>
  </entry>
  <entry>
    <title>win10系统中断占用cpu高使用率怎么解决?</title>
    <url>/2021/09/08/windows-11-cpu-100%25/</url>
    <content><![CDATA[win10系统中断占用cpu高使用率怎么解决?此电脑（右键）——管理——系统工具——设备管理器——系统设备——可编程中断控制器（ Programmable interrupt controller）——禁用设备
]]></content>
      <categories>
        <category>Windows</category>
      </categories>
      <tags>
        <tag>Windows</tag>
        <tag>CPU</tag>
      </tags>
  </entry>
  <entry>
    <title>Windows MSYS2</title>
    <url>/2018/07/08/windows-MSYS2/</url>
    <content><![CDATA[Windows下的软件 msys2Software Distribution and Building Platform for Windows
MSYS2 is a collection of tools and libraries providing you with an easy-to-use environment for building, installing and running native Windows software.
详细的参考：
https://www.msys2.org/
]]></content>
      <categories>
        <category>Linux</category>
        <category>Windows</category>
      </categories>
      <tags>
        <tag>cmder</tag>
        <tag>conemu</tag>
        <tag>msysgit</tag>
        <tag>clink</tag>
      </tags>
  </entry>
  <entry>
    <title>Windows 7开启NFS共享</title>
    <url>/2013/08/08/windows-connect-linux-desktop/</url>
    <content><![CDATA[Windows远程登陆Linux桌面的方法
Putty
其实这个工具并不是桌面客户端，它只不过是一个远程登陆Linux的命令提示工具，但是我们知道，在Linux中，命令基本上就是一切，所以用这个客户端还是能够做到你想要的任何事情。
Cygwin
这个工具能够做很多事情，登陆Linux桌面只是其中一件。关于这个软件的教程，网上有个达人已经写的非常详细了，详情看这里。这个工具在Linux端是不需要任何配置的。另外要说明的是，你的Linux桌面环境，如果是KDE，那么打开窗口的命令是startkde，如果你不装这个，它会说你的命令无效；如果你装的是Gnome，那么应该使用的命令是gnome-session，详情可以查阅Gnome官方网站。
Xming
我估计这是最简单的登陆Linux桌面的方式了。可以到Xming的网站下载Xming软件，因为是Windows软件，所以安装非常简单。安装完成后会有两个快捷方式，一个是Xming，这个是做服务器的，一个是XLaunch，当你启动XLaunch的时候会自动启动服务器。
使用方法也是非常简单的，双击XLaunch图标打开，选择OneWindow-下一步-选择Start a porgram -下一步-输入gnome-session（或者startkde，取决于你的桌面软件）-选择Using PuTTY-输入主机地址、用户名和密码-下一步-下一步-这时候可以选择保存一下快捷方式，以后就不用每次输入了-下一步。完成了，这时候就可以看到桌面了。
开启ssh服务
注：所有上述软件都是几乎SSh协议，如果Linux没有开启这个协议的话，那么是无法连接到桌面的。可以用这样的方法打开SSh服务，在终端中输入ntsysv命令，在打开的窗口中找到SSHD服务，确保SSHD被选中，如果没有则按空格选中，按确定退出：
telnet
Xshell
Xshell 是一个强大的安全终端模拟软件，它支持SSH1, SSH2, 以及Microsoft Windows 平台的TELNET 协议。Xshell 通过互联网到远程主机的安全连接以及它创新性的设计和特色帮助用户在复杂的网络环境中享受他们的工作。
Xshell 和SecureCRT的比较：
Screen下的会话不会闪屏，而且可以回滚，这个功能太无敌了Script的执行顺序可以调整，SecureCRT的这个功能实在太呆可以同时发送指令到多个session，这个也不错键盘映射的兼容性要好一些，不用去自己改映射可以展现tunnel等的情况支持布局切换，像gnome-terminal缺憾是对Unicode制表符支持不够好，内置的sftp不怎么好使（该公司有另外的xftp）许可相对便宜，对个人、教育用户是免费的！XShell 和Putty&amp; Pietty的比较：
　　支持ZModem协议，putty虽有leputty据说可以实现，但我一直没成功 :(Session保存在文件中而非注册表，管理方便支持tab、自定义脚本、保存密码、多机管理…putty是自由软件，和商用的XShell比较不是很合适。putty也有很多插件可以实现部分有缺憾的功能，用起来会麻烦一些就是了。个人平常还是以putty为主，功能够用，速度飞快。大量机器的管理还是XShell合适。
　　注意，XShell在商业环境使用下是需要买许可的。
SecureCRT
基本定义
SecureCRT是一款支持SSH（SSH1和SSH2）的终端仿真程序，同时支持Telnet和rlogin协议。SecureCRT是一款用于连接运行包括Windows、UNIX和VMS的远程系统的理想工具。通过使用内含的VCP命令行程序可以进行加密文件的传输。有流行CRTTelnet客户机的所有特点,包括:自动注册、对不同主机保持不同的特性、打印功能、颜色设置、可变屏幕尺寸、用户定义的键位图和优良的VT100,VT102,VT220和ANSI竞争.能从命令行中运行或从浏览器中运行.其它特点包括文本手稿、易于使用的工具条、用户的键位图编辑器、可定制的ANSI颜色等.SecureCRT的SSH协议支持DES,3DES和RC4密码和密码与RSA鉴别.
概念解释
SSH的英文全称是 Secure Shell。
　　传统的网络服务程序，如：ftp 和telnet 在本质上都是不安全的，因为它们在网络上用明文传送口令和数据别有用心的人非常容易就可以截获这些口令和数据。而通过使用 SSH客户端与服务器端通讯时，用户名及口令均进行了加密，有效防止了对口令的窃听。同时通过 SSH的数据传输是经过压缩的，所以可以提高数据的传输速度，既然如此我们为什么不使用它呢。SSH是由客户端和服务端的软件组成的，有两个不兼容的版本分别是：1.x 和 2.x。至于具体如何安装服务器端，普通用户就不需要关心了
putty
简介
Putty
　　随着Linux在服务器端应用的普及，Linux系统管理越来越依赖于远程。在各种远
程登录工具中，Putty是
　　出色的工具之一。
Putty是一个免费的、Windows 32平台下的telnet、rlogin和ssh客户端，但是功能丝毫不逊色于商业的telnet类工具。
　　用它来远程管理Linux十分好用，其主要优点如下：
◆ 完全免费;
◆ 在Windows9x/NT/2000下运行的都非常好;
◆ 全面支持ssh1和ssh2；
◆ 绿色软件，无需安装，下载后在桌面建个快捷方式即可使用；
◆ 体积很小，仅364KB(0.54 beta版本)；
◆ 操作简单，所有的操作都在一个控制面板中实现。
把Putty下载到机器上，双击putty.exe，就出现如图1的配置界面。
　　选择“Session”，在“Host Name (or IP address)”输入框中输入欲访问的主机名或IP，比如server1或192.168.9.4。端口号（Port）根据使用的协议有所区别，ssh默认使用22，telnet默认使用23，rlogin默认使用513。
　　在“Protocol”单选栏中选择使用的协议，一般是telnet或ssh，这取决于服务器提供的服务。
　　在“Saved Session”输入栏中输入任务的名字，单击“Save”按钮，就可以把任务配置保存起来了。
　　配置完成后单击“Open”按钮，出现如图2的登录界面，就可以使用Putty连接Linux主机了。
pietty
PieTTY 是由林弘德（Hung-TeLin, piaip）以PuTTY 源代码为基础，在 Windows 上发展的 Telnet/SSH 安全远端连线程式，修正与完整支援亚洲语系字符，可切换多种 Unicode 字符显示方式，提供简易 scp 上传界面，并增加透明视窗、无边框模式等视觉效果。PieTTY 与 PuTTY 同样采用 MIT License，但 PieTTY 目前并没有释出源代码，如果您有非常高度的安全需求，请自行斟酌是否使用 PieTTY。
VNC
VNC (Virtual Network Computing)是虚拟网络计算机的缩写。VNC是一款优秀的远程控制工具软件，由著名的AT&amp;T的欧洲研究实验室开发的。VNC是在基于UNIX和Linux操作系统的免费的开放源码软件，远程控制能力强大，高效实用，其性能可以和Windows和MAC中的任何远程控制软件媲美。 在Linux中，VNC包括以下四各命令：vncserver，vncviewer，vncpasswd，和vncconnect。大多数情况下我只需要其中的两个命令：vncserver和vncviewer。
简介
VNC基本上是属于一种显示系统,也就是说他能将完整的窗口界面通过网络,传输到另一台计算机的屏幕上. Windows服务器中包含的”Terminal Server”、Symantec公司开发的收费软件PCAnywhere、近期流行的Teamviewer、国内的协通XT800、快递通KDT都是属于这种原理的设计，同时这些软件又在VNC的原理基础上做了各自相应改进，提高了易用性、连通率和可穿透内网（Teamviewer、协通XT800、KDT）.
特点
　　同样可能远程连入UNIX、Linux进行图形化操作的还有流行的Xmanager，VNC与之相比——两者工作原理不一样，后者是远程连入操作系统，所有操作在UNIX、Linux主机服务端进行，即使操作过程中“本地电脑与操作主机网络断开”，也不影响操作的顺利进行；而后者（Xmanager）是通过端口将主机服务器的UI界面引导到本地电脑进行展现，如操作过程出现“本地电脑与操作主机网络断开”，操作将中断失败！如果操作都进行的工作任务非常重要，不能中断，如ORACLE RAC实施，结果是灾难性的！更重要的是，VNC是免费的、开源的，Xmanager你一定是用的破解注册版的。
组成部分
VNC基本上是由两部分组成：一部分是客户端的应用程序(vncviewer)；另外一部分是服务器端的应用程序(vncserver)。VNC的基本运行原理和一些Windows下的远程控制软件很相象。VNC的服务器端应用程序在UNIX和Linux操作系统中适应性很强，图形用户界面十分友好，看上去和Windows下的软件界面也很类似。在任何安装了客户端的应用程序(vncviewer)的Linux平台的计算机都能十分方便的和安装了服务器端的应用程序(vncserver)的计算机相互连接。另外，服务器端 (vncserver)还内建了Java Web接口，这样用户通过服务器端对其他计算机的操作就能通过Netscape显示出来了，这样的操作过程和显示方式比较直观方便。
命令描述
vncserver
　　此服务程序必须在在主（或遥控）计算机上运行。你只能作为使用者（不需要根用户身份）使用此项服务。
vncviewer
　　本地应用程序，用于远程接入运行vncserver的计算机并显示其环境。你需要知道远程计算机的IP地址和vncserver设定的密码。
vncpasswd
vncserver的密码设置工具。vncserver服务程序没有设置密码将不能运行（好习惯）。如果你没有设置，运行vncserver时它会提示你输入一个密码。所以，一般我不会单独运行这个命令来设置密码。
vncconnect
　　告诉vncserver连接到远程一个运行vncviewer的计算机的IP和端口号。这样我就可以避免给其他人一个接入的密码。
Xvnc
　　一个vnc“主控”程序，一般来说不需要直接运行。（vncserver和vncviewer实际上是Xvnc的脚本）
　　查找所有可用的选项，运行：
Xvnc –help
出于安全的考虑，一般不建议直接以超级用户帐号运行vncserver程序。如果你需要超级用户的环境，请以一般用户登录后再使用su命令登录到超级用户帐号。
Vnc****配置(阿斌提供)
打开ssh ,root登陆
sudo service  iptables stop
vncserver :1
关闭
打开ssh，zzb登陆
vncserver :2
要关闭的话需先看清各自的用户权限
&amp;——————————————————————————
环境：RedHat Linux 5企业版。
Xwindows：gnome （红帽默认安装的图形界面）
尽管我们可以使用SSH连接远程通过字符界面来操作Linux，但是对于更多熟悉图形人来说是很不方便的，因此开启Linux的远程桌面还是很有必要的。目前有两种比较流行的方式：XDM(X display manager）方案和VNC方案，而我个人比较倾向于VNC方案，一是因为VNC方案配置起来相对比较容易，二是VNC方案支持多种连接方式，比如通过浏览器访问Linux桌面，免去需要安装客户端的麻烦。
接下来进入具体配置说明：
一，确认及安装VNCSERVER。
1，首先确认你服务器是否配置了VNCSERVER，可以在命令行下敲入以下命令查看：
[root@localhost: ~]#rpm -qa |grep vnc
vnc-server-4.1.2-14.el5    #返回VNCSEVER服务器端版本说明你已经安装了VNCSERVER。
2，如果没有安装VNCSEVER，那么从光盘找到安装包进行安装。
首先将光盘挂载(也叫解压)到某个目录这里是在/var/ftp/pub/下面建立了rhel5-64目录
mount -o looprhel-server-5.3-x86_64-dvd.iso /var/ftp/pub/rhel5-64/
然后在/var/ftp/pub/rhel5-64/Server目录下找到vnc-server-4.1.2-14.el5.x86_64.rpm安装包，使用RPM命令直接安装；
rpm -ivh vnc-server-4.1.2-14.el5.x86_64.rpm
二，开始配置VNCSERVER
1，启动VNCSERVER，第一次启动VNCSERVER会提示输入密码，这里分为管理员账户及普通账户，启动方式略有所不同。
管理员：
[root@localhost /]# vncserver
You will require a password to access yourdesktops.
Password: 123456            #输入vnc 连接密码
Verify: 123456                 #确认vnc密码
xauth: creating new authority file/root/.Xauthority
New ‘localhost.localdomain:1 (root)’desktop is localhost.localdomain:1
Creating default startup script/root/.vnc/xstartup
Starting applications specified in/root/.vnc/xstartup
Log file is/root/.vnc/localhost.localdomain:1.log
普通用户：
[root@localhost /]#su leo    #leo 是用户名
[leo@localhost /]$ vncserver
You will require a password to access yourdesktops.
Password: 123456            #输入vnc 连接密码
Verify: 123456                 #确认vnc密码
xauth: creating new authority file /home/leo/.Xauthority
New ‘localhost.localdomain:2 (leo)’ desktopis localhost.localdomain:2
Creating default startup script /home/leo/.vnc/xstartup
Starting applications specified in /home/leo/.vnc/xstartup
Log file is /home/leo/.vnc/localhost.localdomain:2.log
#这里要注意：每个用户都可以启动自己的VNCSERVER远程桌面，同时每个用户可以启动多个VNCSERVER远程桌面，它们用ip加端口号：ip:1、ip:2、ip:3 来标识、区分，使用同一端口会使另外登录的用户自动退出。另，VNCSERVER的大部分配置文件及日志文件都在用户home目录下.vnc目录下。
用户可以自定义启动号码如：
[leo@localhost /]$ vncserver :2        #注意:2前面一定要有空格。
A VNC server is already running as :2
三，相关桌面配置，RedHat Linux支持两种图形模式：KDE模式和gnome模式。
1，你的RH使用的什么图形模式这个一般只有登录到图形界面查看一下才能知道，或者通过ps -A命令列出所有当前运行的程序，看看有没有KDE或者gnome字样来判断一下。
如果你是gnome桌面，那么你需要修改/root/.vnc/xstartup的配置文件。
[root@localhost .vnc]# vi xstartup
#!/bin/sh
# Uncomment the following two lines fornormal desktop:
# unset SESSION_MANAGER        #将此行的注释去掉
# exec /etc/X11/xinit/xinitrc        #将此行的注释去掉
[ -x /etc/vnc/xstartup ] &amp;&amp; exec/etc/vnc/xstartup
[ -r $HOME/.Xresources ] &amp;&amp; xrdb$HOME/.Xresources
xsetroot -solid grey
vncconfig -iconic &amp;
xterm -geometry 80×24+10+10 -ls -title“$VNCDESKTOP Desktop” &amp;
gnome-session gnome           #添加这一句是连接时使用gnome 桌面环境
twm &amp;
设置修改完毕最好是重启一次系统，否则设置不会生效。我采用的方法是杀死VNCSERVER进程再重运行VNCSERVER。
[root@localhost .vnc]#vncserver -kill:1      #这里你启动vncserver时是什么端口号要对应上。
[root@localhost .vnc]#vncserver :1           #重启VNCSERVER，注意:1前面一定要有空格。
2，设置用户信息及分辨率。
[root@localhost: ~]#vi/etc/sysconfig/vncservers
# The VNCSERVERS variable is a list ofdisplay:user pairs.
#
# Uncomment the lines below to start a VNCserver on display :2
# as my ‘myusername’ (adjust this to yourown). You will also
# need to set a VNC password; run ‘manvncpasswd’ to see how
# to do that.
#
# DO NOT RUN THIS SERVICE if your localarea network is
# untrusted! For a secure way of using VNC,see
#&lt;URL:http://www.uk.research.att.com/archive/vnc/sshvnc.html &gt;.
# Use “-nolisten tcp” to prevent Xconnections to your VNC server via TCP.
# Use “-nohttpd” to prevent web-based VNCclients connecting.
# Use “-localhost” to prevent remote VNCclients connecting except when
# doing so through a secure tunnel. See the“-via” option in the
# `man vncviewer’ manual page.
VNCSERVERS=”1:root 2:leo”            #此处添加用户，一般只添加一个1:root也就行了。
VNCSERVERARGS[1]=”-geometry 800×600-nolisten tcp -nohttpd -localhost”
VNCSERVERARGS[2]=”-geometry 1024×768-nolisten tcp -nohttpd -localhost”
#注意：上面是分别设置的root和leo两个用户的分辨率，注意是用端口号区分的。
另外也可以通过命令行临时修改分辨率及色深，这种方式重启后就会丢失，这里暂时用不到，命令如下：
[root@localhost: ~]#vncserver -geometry 800×600        #设置vncserver的分辨率
[root@localhost: ~]#vncserver -depth16           #设置vncserver的色深
到这里VNCSERVER服务器端就配置完成了。
四，客户端连接及使用。
1，访问方式
a、在linux下，运行vncviewer命令即可，服务器地址的写法形如192.168.1.11:1
b、在windows下，运行windows版本的vncviewer即可，用法与linux下相近。
c、用浏览器（平台无关），作为javaapplet来实现，以形如http://192.168.1.11:5801 的方式来启动 （vnc 端口从5800 开始依次类推，一般会是5800，5900）
以下为一些常识：
2，修改密码
运行vncpasswd即可
3，停止vncserver
#vncserver -kill :1
#vncserver -kill :2
注意到vncserver只能由启动它的用户来关闭，即时是root也不能关闭其它用户开启的vncserver，只能用kill命令暴力杀死进程。
4，稳定性设置
vncserver默认在多个客户机连接同一个vncserver的显示端口时，vncserver端口旧连接，而为新连接服务，可通过-dontdisconnect拒绝新连接请求而保持旧的连接。
5，同一个显示器可以连接多个客户机
#vncserver -alwaysshared
6，重启服务
service vncserver restart
7，让系统启动时自动启动VNCSERVER。
使用VNC连接登录到RedHat Linux图形界面，点击“系统”——“管理”——“服务器设置”——“服务”，在“后台服务”中找到VNCSERVER后勾选它，点击保存即可。
解决连接不上问题的方法：
1、防火墙开启 不能连接
关闭防火墙    service  iptables stop
查看防火墙状态   service iptables status
查看进程     ps axf | grepvnc/iptables
XManager
Xmanager 是全新标准的跨平台集成解决方案。它是一个一站式解决方案，这个软件包含有以下一些产品：Xmanager3D(OpenGL)，Xshell，Xftp和Xlpd。
Xmanager PCX Server
Xmanager是一个运行于MS Windows平台上的高性能的X window服务器。你可以在你的本地PC上同时运行Unix/Linux和Windows图形应用程序。
Xshell
Xshell是一个用于MS Windows平台的强大的SSH，TELNET，和RLOGIN终端仿真软件。它使得用户能轻松和安全地从WindowsPC上访问Unix/Linux主机。
Xftp
Xftp是一个用于MS Windows平台的强大的FTP和SFTP文件传输程序。Xftp让你能安全地在Unix/Linux和Windows PC之间传输文件。
Xlpd
Xlpd是一个用于MS Windows平台的LPD(行式打印机虚拟后台程序)应用程序。安装了Xlpd后，你的带有打印机的本地PC就成为了一个打印服务器，来自不同远程系统的打印任务都能在网络环境中得到请求和处理。(共享软件)
Xstart
Xstart是一个窗口化的登陆界面，要求填入session，host，protocol，user name， password。可进行远程登陆。
Xmanager 配置
我用的是RedHat Enterprise Linux 5.4和最新的Xmanager Enterprise3.0。首先先来了解一下什么是Xmanager。Xmanager全称Netsarang Xmanager，是国外一套非常优秀的远程监控软件。在UNIX/Linux和Windows网络环境中，Xmanager是最好的连通解决方案。我推荐大家下载Enterprise版本，企业版带的工具更多功能更强大。我们通过Xmanager连接Linux远程桌面进行图形化管理其实就是利用了Xmanager套装里面的Xbrowser程序。当然Linux远程图形化管理除了Xbrowser，还有同样优秀的VNC。下面介绍用Xbrowser连接Linux远程桌面的详细配置。都是我亲自测试过的，放心往下看吧！
一、如果你查过网上的资料你就会发现：RedHatEnterprise Linux 5与RedHatEnterprise Linux 4对于Xmanager的配置是不同的，前者没有/etc/X11/gdm/这个目录，它的gdm的配置文件放在/usr/share/gdm/custom.conf。
其实网上的写错了！！这里不是custom.conf，而是defaults.conf！反正我的RedHatEnterprise Linux 5.4是这样的，可能其它5系列版本不一样也没数的。
在/usr/share/gdm/defaults.conf里确保有以下几句配置(我在最后面直接加了这几句)：
Enable=trueDisplaysPerHost=10Port=177
二、在/etc/inittab里把默认级别改为5：id:5:initdefault:
再把最后一句里x:5:respawn:/etc/X11/prefdm -nodaemon改成x:5:respawn:/usr/sbin/gdm（注意这里是sbin，不是bin，网上的又错了，害得我前几次都没能成功，妈的！还好我后来自己发现了这个问题。)
三、让Root登陆Xmanager
以上修改之后，root用户还不能通过Xmanager远程登录Linux，还要继续修改/usr/share/gdm/defaults.conf文件，在[security]字段里开启以下两项：AllowRoot=trueAllowRemoteRoot=true我发现AllowRemoteRoot这一项可以不开启，看我的配置，它还是false，如下图：
四、开启Linux防火墙的177 UDP端口。
Xmanager连接gdm用的是UDP的177端口，所以防火墙上一定要打开这个端口，如下图：
　　最后是重启系统。这样就小功告成了！在Windows系统上运行xmanager3里的Xbrowser程序，在里面新建一个Xmanager Session，在Host这里输入ip地址，其它配置都不要改变（包括端口号），确定退出。
　　然后双击这个New Xmanager Session，进入登录界面，输入用户名和密码以后就可以登录到Linux的远程桌面了。
　　最后再给大家几个用于检测和测试的Linux命令：
lsof -i:177查看是否运行成功了！
etc/hosts查看ip。有的时候连接不上可能是因为你的hosts文件里配置的IP地址不对。
/usr/sbin/gdm-restart重启gdm。
Xming + PuTTY 在Windows下远程Linux主机使用图形界面的程序
2008-04-1813:31
使用cygwin X server实现Linux远程桌面 (forwindows)
在windows上访问linux有多种方法：
对于习惯使用命令行的人来说，可以使用终端的方式进行访问，也就是通过telnet, ssh等方法远程登录到linux主机，对其进行访问。至于登录软件，既可以使用windows自带的命令行界面，也可以使用专门的终端软件，例如putty, secureCRT等。其中putty是免费软件，而secureCRT并不是。
对于习惯使用图形界面的人来说，更希望以图形界面的方式来访问linux主机。主要有以下几种方法：
·        使用vnc技术。网上这方面的文档很多，我也写过一篇：用VNC实现远程桌面共享(支持Windows,Linux, …)
·        在windows上提供一个X server，linux主机上X client程序通过XDMCP协议 (X Display Manager Control Protocol)使自己显示在windows上。
今天我主要介绍第二种方法。
有很多软件在windows上实现了X server的功能，例如Xmanager，HummingbirdExceed，cygwinX server，以及XmingX Server for Windows。前两个都是商业软件，需要付费使用；cygwin和Xming是免费软件。本文主要介绍如何使用cygwin X实现Linux的远程桌面。关于Xming X server的使用请参见其主页。
先调动一下大家的积极性，看看最终的效果图：
点击查看大图
[ 背景知识 ]
网络上有很多关于X的背景知识，如果你想对X了解的深入一些，去网上搜索一下吧。
这里是王垠写的”理解Xwindow“，介绍了X server, X client, 窗口管理器，桌面环境相关的知识，读一下对理解本文也有帮助。
好了，现在我们开始配置。
[ 安装cygwin ]
Cygwin项目的目的是在windows主机上提供一个类UNIX的环境，网络也有很多相关的资料。大家可以看一下这一篇：Cygwin使用指南，这篇文章在网络上流行比较广，作者未知，上面提供的仅是其中一个链接。
如果你的计算机上还没有cygwin，首先需要安装它。
这个过程很简单，先到cygwin的主页去下载setup.exe，然后使用setup.exe进行安装。在安装的过程中需要选择要安装的组件，此时需要把X server组件选上。
在这里有一个安装指南，虽然是英文的，不过看抓图就可以了。
选择X server组件时，其实只需要选择xorg-x11-base，选中它之后，其它相关组件会自动被选中。
在安装cygwin时，记得把expect这个软件装上，它位于interpreters类别下面。我会在后面的章节中说明为什么要安装这个组件。
[ 运行cygwin X server]
在运行X server前，先假定一下我们的组网。
我们假设X server运行在一台windows XP计算机上，此机器的IP地址是192.168.190.91。
我们的Linux主机上将运行X client程序，它的IP地址是192.168.190.15。
在你的安装目录中找到c:cygwinusrX11R6binstartxwin.bat(假设你把cygwin安装在c:cygwin目录)，双击它就会启动X server，同时会启动一个终端(这个终端运行在Windows本地)，效果如下图：
点击查看大图
现在，我们要允许远程的X client对X server进行访问，因此，在终端中输入下面的命令，
xhost + 192.168.190.15
接下来，我们要到X client所在的计算机上进行配置，使用telnet或ssh登录Linux主机(192.168.190.15)，然后运行下面的命令，
export DISPLAY=192.168.190.91:0.0
xterm &amp;
gvim &amp;
上面第一条命令设置DISPLAY变量，它表示X客户端将使用192.168.190.91上的0.0来显示自己。192.168.190.91是运行cygwin X server的Windows计算机(它的防火墙要打开X server所监听的端口，通常为6000)。
后面两条命令则在Linux主机上(192.168.190.15)启动了两个程序，一个是xterm，另外一个是gvim，我们发现这两个程序启动后，并没有显示在Linux主机上，相反，它们显示在了windows主机上。下图是执行完上述命令的效果图，我使用putty远程登录到Linux主机上，然后执行上述命令：
点击查看大图
用这种方法，你可以在Linux主机上运行任何图形程序，并把它显示到windows上。
如果你想把诸如KDE、GNOME这样的桌面环境也显示到windows上，就需要做些调整。
[ 运行桌面环境 ]
在此我以KDE桌面为例。要把KDE桌面环境显示到windows上的X server中，需要更改一下X server的启动批处理。
首先备份一下c:cygwinusrX11R6binstartxwin.bat，然后使用文本编辑器打开此文件，找到下面这行：
%RUN% XWin -multiwindow -clipboard -silent-dup-error
去掉”*-multiwindow*“参数：
%RUN% XWin -clipboard -silent-dup-error
我们通常不需要启动一个xterm窗口，因此找到下面这行：
%RUN% xterm -e /usr/bin/bash –l
把它注释掉：
REM %RUN% xterm -e /usr/bin/bash –l
好了，批处理文件改完了。
回想一下上面的操作，在启动了X server后，我们执行了xhost命令来设置允许哪些计算机连接到X server，现在我们可以在配置文件中设置它。打开一个cygwin窗口，输入下面的命令：
echo “192.168.190.15” &gt;&gt; /etc/X0.hosts
上面的命令会在/etc/X0.hosts文件中加入你想允许的X client，你可以在此文件中加入你的X客户端。因为我们使用的DISPLAY是0，所以在文件/etc/X0.hosts中增加；如果使用DISPLAY 1，则需要修改文件/etc/X1.hosts文件。现在启动X server后，192.168.190.15就被自动允许接入了。
现在我们再次双击startxwin.bat批处理，执行后就会出现一个丑陋的空白窗口，这就是所谓的根窗口。之所以是空白的，是因为现在还没有运行任何窗口管理器。别急，我们使用telnet或ssh远程登录Linux主机，执行命令：
startkde &amp;
哈哈~~~本文开头所展示的KDE窗口出来了！！！现在你在KDE中运行任何程序，它们都运行在Linux主机上，却把结果显示在Windows主机上。
[ 创建快捷方式 ]
在上面的操作中，启动X server后，需要使用telnet或ssh登录到Linux主机，才能启动自己想要的X client程序，有没有更简单的方法？
现在我们就需要用到expect软件了。这是一个如此有用的软件，以至于我忍不住要在这里插一段广告。
Expect为用户提供一种机制，使用户能够自动执行一些交互式的任务。例如，通常我们在使用telnet的时候，都需要手动输入用户名、密码才能登录。而使用Expect，我们就可以实现全自动的telnet交互，不需用户干预。Expect由Don Libes开发，基于TCL内核，它的主页在http://expect.nist.gov/。
广告时间结束，我们继续。我使用expect编写了如下的TCL/EXPECT脚本，它可以使用ssh自动登录到指定Linux主机，然后启动我们需要的程序。程序如下：
#! /bin/expect -f
# Change these variable to yours
set user {easwy}
set host {192.168.190.15}
set xserver {192.168.190.91}
set password {123456}
set program {startkde}
set timeout 5
set done 0
spawn ssh “$user@$host”
while {!$done} {
​    expect {
​        “*(yes/no)?*”{
​            # If the 1st timerun ssh, it will prompt continue or not
​            # answer yes
​            exp_send”yesn”
​        }
​        “assword*” {
​            # Answer password
​            exp_send”$passwordn”
​        }
​        “$*” {
​            # Exit the loop
​            incr done
​        }
​        “#*” {
​            # Exit the loop
​            incr done
​        }
​        timeout {
​            # Timeout
​            exp_send_user”Login timeout, please check!”
​        }
​    }
}
# Set DISPLAY environment variable
exp_send “export DISPLAY=$xserver:0n”
# Start your program
exp_send “nohup $program &amp;n”
expect -regexp {[[0-9]] [0-9]}
exp_send “n”
# Finished
把上面的内容保存为一个文件，例如，保存为cygwin的~/login.exp。注意：把脚本起始处的5个变量替换成你自己的，只需要替换大括号中间的内容。使用telnet的朋友请自行修改此脚本。
下面我们再改一下c:cygwinusrX11R6binstartxwin.bat文件，在此文件的最后增加：
REM Start your X client program
%CYGWIN_ROOT%binrun -p /bin expect -f ~/login.exp
我们使用expect来执行刚才保存的~/login.exp。
现在，我们右击startxwin.bat文件，选择“发送到桌面快捷方式”。以后，只要你双击此快捷方式，就能立刻在Windows上使用Linux主机上的程序了。
在上图中共开了三个终端，它们分别运行在不同的主机上，却都在Windows主机上进行输入输出。这就是X window的魅力了，如果你愿意，你还可以把其它Windows及Linux主机上的程序显示到这个X server中，正所谓一”桥”飞架南北，天堑变通途。
在本文完成后，经网友jiachunyu介绍，才知道有一个名为XWinLogon的软件，它也是使用cygwin的X server实现Linux的远程桌面。相比之下，它的安装和使用都简单了很多。这个软件的主页在：http://sourceforge.net/projects/xwinlogon/
或者
http://www.calcmaster.net/visual-c++/xwinlogon/
有兴趣可以试一下。
上述方法大多经过试验。
如果各位有更好的方法，请告诉我一声。
]]></content>
      <categories>
        <category>Linux</category>
        <category>Windows</category>
      </categories>
      <tags>
        <tag>ssh</tag>
        <tag>vnc</tag>
        <tag>putty</tag>
        <tag>cygwin</tag>
      </tags>
  </entry>
  <entry>
    <title>Windows 搜索利器 Everything</title>
    <url>/2016/06/28/windows-everything/</url>
    <content><![CDATA[Windows 搜索利器 EverythingMacOSX上好用的工具不少，相信大家对 spotlight 和 alfred 印象很深刻。
今天推荐一款在Windows上使用的软件 Everything，用过MacOSX的童鞋应该都知道Spotlight的绚丽功能，至少这个功能我是一直在使用的，快速的搜索，方便（捉急）的快捷键，把输入法切换给占用了。
这个也是为数不多经常给大家推荐提高工作效率的软件。
Everything应该是为唯一一个民用的Haskell编写的软件，其他都是军用的^_^。
Everything体积小巧，界面简洁易用，快速建立索引，快速搜索，同时占用极低的系统资源，实时跟踪文件变化，并且还可以通过http或ftp形式分享搜索。
在搜索框输入文字，它就会只显示过滤后的文件和目录。Everything搜索只基于文件和文件夹的名称，所以它创建数据库很快。
快到啥程度呢，官方的说明是一个刚安装完的Windows XP SP2系统(约20,000份文件)，需要一秒钟。索引一百万份文件则需要一分钟。
我积攒到现在接近600多GB的数据,400多万个文件，第一次索引只用了2分钟，确实快如闪电。
最关键的是，这个软件只有几百KB，只有几百KB，最新版本不倒500KB，你晓得什么概念吧。。。。你估计不晓得什么概念，21世纪初的软盘可以放几份拷贝在上面。
一句话， Everything是速度最快的文件搜索软件，和windows自带搜索功能相比，简直是一个天上一个地下了。当然也可以使用 Total Commander 或其他 ，不过我还是会推荐这款体积小巧、免安装、免费、速度极快（比Locate32更快）的文件搜索工具Everything.
常用的普通搜索就可以了，进阶版的可以使用正则表达式。
搜索技巧可以通过正则表达式更加高效地使用Everything，比如下面的一些技巧。
比如我希望找到一个2016年访问过的，文件超过1GB大小的视频，该视频包含了family字样，就可以用下面的搜索技巧搜索：
video: size:&gt;1GB dateaccessed:2016 family



其他一些比较常用的为：
操作符
hello world : 将搜索包含hello 和 world的文件或文件夹
hello | world : 将搜索包含hello 或 world的文件或文件夹
hello !world : 将搜索包含hello 不包含world 的文件或文件夹

通配符
20??01 ：因为?表示一个字符，所以这个表示搜索包含20??01的文件或文件夹，其中20与01之间包含2个字符
20*01：因为*表示匹配0或多个字符，所以搜索的范围比较广

宏有一些有用的宏，比较方便使用，如下：

audio:	搜索音频文件
zip:	搜索压缩文件.
doc:	搜索文档文件.
exe:	搜索可执行文件.
pic:	搜索图片文件.
video:	搜索视频文件.

修饰符
case:	区分大小写.
file:	仅匹配文件.
folder:	仅匹配文件夹.
nocase:	不区分大小写.
path:	匹配路径和文件名.
regex:	启用正则表达式.
wholefilename:	匹配完整文件名.

几个常用函数​	

dateaccessed:&lt;date&gt;	搜索指定访问时间的文件和文件夹.
datecreated:&lt;date&gt;	搜索指定创建日期的文件和文件夹.
datemodified:&lt;date&gt;	搜索指定修改日期的文件和文件夹.
size:&lt;size&gt;	搜索指定大小的文件 (以字节为单位)，可以指定为kb，mb和gb


 接下来的就是开始下载使用吧。

]]></content>
      <categories>
        <category>Windows</category>
      </categories>
      <tags>
        <tag>windows</tag>
        <tag>everything</tag>
        <tag>搜索</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux换行符和Windows换行符的区别与转换</title>
    <url>/2015/07/08/windows-linux-return/</url>
    <content><![CDATA[Linux换行符和Windows换行符的区别与转换不同系统文本文件的行尾换行符不同，可能会导致在不同的系统打开有问题。
主要原因如下：

Windows为一个回车’r’（CR或^M）和一个换行’n’(NL或LF)（括号内是其它显示方法）
Linux为一个换行’n’
Mac为一个回车’r’

如何查看文件是否含有Windows换行符：

Windows：Notepad++ ==&gt;视图 ==&gt;显示所有符号
Linux：file test.txt
test.txt: ASCII text, with CRLF line terminators
Vim:命令模式下输入:e ++ff=unix，^M就是Windows换行符



如何转换：

Windows下Notepad++ ==&gt;编辑 ==&gt; 文档格式转换 ==&gt; 转为Unix

Linux：

sed -i ‘s/\r//‘ filename
dos2unix filename


Linux批量转换：find -type f | xargs dos2unix -o

Vim：命令模式下输入:%s/^M//g或者:g/^M/s/^M//

Vim：命令模式输入:set ff?如果出现fileforma＝dos 表示是Windows上的换行符。继续输入:set fileformat=unix 保存即可/


]]></content>
      <categories>
        <category>Linux</category>
        <category>Windows</category>
      </categories>
      <tags>
        <tag>CR</tag>
      </tags>
  </entry>
  <entry>
    <title>远程计算机或设备将不接受连接</title>
    <url>/2021/07/08/windows-network/</url>
    <content><![CDATA[远程计算机或设备将不接受连接windows系统升级重启以后，网络正常，就是打不开浏览器，解决方法为：

在桌面按下“win+r” 快捷键打开运行窗口，输入 inetcpl.cpl 点击确定，打开Internet选项
然后切换到“连接”选项卡，点击下方的局域网设置按钮
来到“局域网（LAN）设置”窗口后，取消所有复选框的勾选，点击确定即可

]]></content>
      <categories>
        <category>Windows</category>
      </categories>
      <tags>
        <tag>network</tag>
      </tags>
  </entry>
  <entry>
    <title>Windows定时关机</title>
    <url>/2020/07/08/windows-shutdown/</url>
    <content><![CDATA[Windows定时关机使用Win+R呼出运行对话框，输入一下命令即可：
$ shutdown -s -t xxxx



其中xxxx为希望的秒数，比如shutdown -s -t 60 将在60秒即1分钟后关机。
取消关机可以输入shutdown -a取消关机
]]></content>
      <categories>
        <category>Windows</category>
      </categories>
      <tags>
        <tag>network</tag>
      </tags>
  </entry>
  <entry>
    <title>Windows下使用Ubuntu</title>
    <url>/2020/06/08/windows-ubuntu/</url>
    <content><![CDATA[Windows下使用Ubuntu目前Ubuntu20.04和18.04可用，可以在Microsoft Store直接安装。
启动ubuntu报错 参考的对象类型不支持尝试的操作解决方法如下: 以管理员身份打开Windows PowerShell, 然后执行netsh winsock reset, 重启电脑即可解决。
Win10中Vmmem程序资源占用过高解决办法有个叫做Vmmem程序占用不少资源，此时可能是wsl引起的问题，解决方法为，在推出wsl以后，需要通过以下命令来shutdown
wsl --shutdown	

]]></content>
      <categories>
        <category>Windows</category>
      </categories>
      <tags>
        <tag>ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title>Windows 终端软件cmder</title>
    <url>/2018/07/08/windows-terminal-cmder/</url>
    <content><![CDATA[Windows下的客户端软件 cmderCmder把conemu，msysgit和clink打包在一起，解压即可使用无需配置。可以在 官网 下载。
下载的时候，有两个版本，分别是mini与full版；唯一的差别在于有没有内建msysgit工具，这是Git for Windows的标配。我们的Linux子系统中工具齐全，所以下载mini版即可。
将cmder 添加到右键菜单
把 cmder 加到环境变量，然后打开一个cmder命令行窗口，ctrl+T，勾选 Run as administrator，点击Start就打开了一个管理员权限的终端，在新终端中输入以下命令，就可以使用右键打开cmder窗口了。
Cmder.exe /REGISTER ALL


设置启动 cmder 时直接运行 bash
打开一个cmder窗口，
点击右下角的目录按钮——&gt;Settings——&gt;Startup——&gt;Command line，输入“bash -cur_console:p”]]></content>
      <categories>
        <category>Linux</category>
        <category>Windows</category>
      </categories>
      <tags>
        <tag>cmder</tag>
        <tag>conemu</tag>
        <tag>msysgit</tag>
        <tag>clink</tag>
      </tags>
  </entry>
  <entry>
    <title>Windows下访问wsl的数据</title>
    <url>/2023/06/08/windows-wsl2-data/</url>
    <content><![CDATA[Windows下访问wsl的数据
有些人感受到的是雨，而很多人感受到的只有淋湿。

Windows下的wsl说实话还是挺不错的，对于开发而言，效果相当的可以。
比如在某个文件夹，Windows编辑好代码后，直接右键打开wsl，就可以进行编译，而不用把代码再同步到开发环境了。
不过如果直接任务栏打开的wsl，有了一些处理数据，该怎么来共享呢，可以通过文件管理器来访问：

在地址栏中输入\\wsl$，然后按回车键。这将打开一个显示WSL可用发行版的窗口。
找到并点击进入你想要访问的WSL发行版，例如Ubuntu2204。
在打开的发行版文件资源管理器窗口中，你可以看到类似于Linux文件系统的目录结构。转到/home目录，那里包含了WSL发行版中用户的home目录。
在/home目录下，你可以找到对应于WSL用户的文件夹，例如/home/username。

]]></content>
      <categories>
        <category>Windows</category>
      </categories>
      <tags>
        <tag>ubuntu</tag>
        <tag>windows</tag>
        <tag>wsl</tag>
      </tags>
  </entry>
  <entry>
    <title>Windows 7开启NFS共享</title>
    <url>/2014/08/08/windows7-open-nfs/</url>
    <content><![CDATA[Windows 7开启NFS共享安装在卸载或更改程序-&gt;打开或关闭windows的功能-&gt; 安装nfs服务
安装完成后，就可以在Windows的命令行窗口中通过mount以及showmount命令使用NFS的共享了。
使用直接使用mount nfsServer1/vol/vol0 Z:即可挂载。
1）showmount
C:\&gt;showmount /?用法: showmount -e [server]       showmount -a [server]       showmount -d [server]

执行showmount命令行将显示到指定nfs服务器的所有mount信息。
您必须提供以下选项之一：

-e 显示指定nfs服务器上的所有文件系统。
-a 显示每个已挂载的nfs服务器上的所有网络文件系统 (NFS) 客户端和目录
-d 显示当前NFS客户端挂载的nfs服务器上的所有目录。

2）mount
C:\&gt;mount ?用法:  mount [-o options] [-u:username] [-p:&lt;password | *&gt;] &lt;\\computername\shaename&gt; &lt;devicename | *&gt;-o rsize=size                 设置读取缓冲区的大小(以 KB 为单位)。-o wsize=size                设置写入缓冲区的大小(以 KB 为单位)。-o timeout=time            设置 RPC 调用的超时值(以秒为单位)。-o retry=number           设置软装载的重试次数。-o mtype=soft|hard       设置装载类型。-o lang=euc-jp|euc-tw|euc-kr|shift-jis|big5|ksc5601|gb2312-80|ansi                                   指定用于文件和目录名称的编码。-o fileaccess=mode        指定文件的权限模式。                                   这些模式用于在 NFS 服务器上创建的新文件。使用 UNIX 样式模式位指定。-o anon                        作为匿名用户装载。-o nolock                      禁用锁定。-o casesensitive=yes|no     指定在服务器上执行区分大小写的文件查找。-o sec=sys|krb5|krb5i


3）umount
C:\&gt;umount用法:  [-f] &lt;-a | drive_letters | network_mounts&gt;-a      删除所有 NFS 网络装入点-f       强制删除 NFS 网络装入点


实例C:&gt;showmount -e nfsServer1
导出列表在nfsServer1:
/vol/volz                          所有计算机
/vol/volx                          所有计算机
/vol/Do_NOT_Delete        所有计算机
/vol/vol7                          所有计算机
/vol/vol0                         nfs_cli1
/vol/vol0/home                所有计算机
/vol/isan                          所有计算机
/vol/vsc                           所有计算机
/vol/nfs_smvi                  nfs_cli1
/vol/vol_t1                        所有计算机
C:&gt;mount //nfsServer1/vol/vol0 Z:
Z: 现已成功连接到 //nfsServer1/vol/vol0
C:&gt;mount
本地    远程                                 属性
——————————————————————————-
Z:       //10.128.132.175/vol/vol0              UID=-2, GID=-2
                                            rsize=32768, wsize=32768

                                            mount=soft, timeout=1.6

                                            retry=1, locking=yes

                                            fileaccess=755, lang=GB2312-80

                                            casesensitive=no

                                            sec=sys

需要注意的是，mount point和Linux和UNIX有所不同，不是使用一个目录作为挂载点，而是使用一个未使用的盘符。
例如上例中的“Z:”。这样就可以通过Z:盘访问你的共享了。非常方便。比起CIFS的方式更加快捷。
使用完后，可以用umount命令卸载共享。
C:&gt;umount Z:
正在断开                Z:      //nfsServer1/vol/vol0
连接上存在打开的文件和/或未完成的目录搜索。
要继续此操作吗? (Y/N) [N]:y
命令已成功完成。
]]></content>
      <categories>
        <category>Windows</category>
      </categories>
      <tags>
        <tag>windows</tag>
        <tag>nfs</tag>
        <tag>mount</tag>
      </tags>
  </entry>
</search>
